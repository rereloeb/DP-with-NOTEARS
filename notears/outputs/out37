samples  5000  graph  10 20 ER mlp  minibatch size  100  noise  0.4  minibatches per NN training  250 quantile adaptive clipping
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.0688901749925357
iteration 1 in outer loop, alpha = 1.0688901749925357, rho = 1.0, h = 1.0688901749925357
cuda
iteration 1 in inner loop,alpha 1.0688901749925357 rho 1.0 h 0.7233456598648633
iteration 2 in inner loop,alpha 1.0688901749925357 rho 10.0 h 0.3056982596331217
iteration 3 in inner loop,alpha 1.0688901749925357 rho 100.0 h 0.08818886525359204
iteration 2 in outer loop, alpha = 9.88777670035174, rho = 100.0, h = 0.08818886525359204
cuda
iteration 1 in inner loop,alpha 9.88777670035174 rho 100.0 h 0.044379478478735024
iteration 2 in inner loop,alpha 9.88777670035174 rho 1000.0 h 0.017095075044052166
iteration 3 in outer loop, alpha = 26.982851744403906, rho = 1000.0, h = 0.017095075044052166
cuda
iteration 1 in inner loop,alpha 26.982851744403906 rho 1000.0 h 0.01057367200959547
iteration 2 in inner loop,alpha 26.982851744403906 rho 10000.0 h 0.003667638346712465
iteration 4 in outer loop, alpha = 63.659235211528554, rho = 10000.0, h = 0.003667638346712465
cuda
iteration 1 in inner loop,alpha 63.659235211528554 rho 10000.0 h 0.000619809293391782
iteration 5 in outer loop, alpha = 69.85732814544637, rho = 10000.0, h = 0.000619809293391782
cuda
iteration 1 in inner loop,alpha 69.85732814544637 rho 10000.0 h 0.00025937885709481634
iteration 2 in inner loop,alpha 69.85732814544637 rho 100000.0 h 0.00016523241346177997
iteration 6 in outer loop, alpha = 235.08974160722636, rho = 1000000.0, h = 0.00016523241346177997
Threshold 0.3
[[0.002 0.002 0.388 0.    0.926 0.071 0.248 0.031 0.    3.018]
 [1.082 0.008 2.849 0.001 0.106 0.351 1.427 0.053 0.    3.14 ]
 [0.    0.001 0.003 0.    0.182 0.    1.917 0.    0.    0.004]
 [0.267 4.181 0.482 0.002 0.129 1.687 0.337 1.465 0.041 0.156]
 [0.    0.    0.001 0.    0.002 0.    0.001 0.    0.    0.   ]
 [0.013 0.007 2.569 0.    0.352 0.002 2.354 0.    0.    0.268]
 [0.001 0.    0.    0.    0.562 0.    0.004 0.    0.    0.002]
 [0.038 0.029 0.376 0.    0.142 2.064 0.187 0.003 0.017 0.233]
 [0.258 3.463 0.25  0.035 1.004 0.115 1.873 0.071 0.001 0.194]
 [0.    0.    0.279 0.    1.122 0.001 0.274 0.001 0.    0.003]]
[[0.    0.    0.388 0.    0.926 0.    0.    0.    0.    3.018]
 [1.082 0.    2.849 0.    0.    0.351 1.427 0.    0.    3.14 ]
 [0.    0.    0.    0.    0.    0.    1.917 0.    0.    0.   ]
 [0.    4.181 0.482 0.    0.    1.687 0.337 1.465 0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    2.569 0.    0.352 0.    2.354 0.    0.    0.   ]
 [0.    0.    0.    0.    0.562 0.    0.    0.    0.    0.   ]
 [0.    0.    0.376 0.    0.    2.064 0.    0.    0.    0.   ]
 [0.    3.463 0.    0.    1.004 0.    1.873 0.    0.    0.   ]
 [0.    0.    0.    0.    1.122 0.    0.    0.    0.    0.   ]]
{'fdr': 0.20833333333333334, 'tpr': 0.95, 'fpr': 0.2, 'f1': 0.8636363636363635, 'shd': 6, 'npred': 24, 'ntrue': 20}
[2.184e-03 3.881e-01 3.027e-04 9.260e-01 7.099e-02 2.482e-01 3.066e-02
 6.237e-05 3.018e+00 1.082e+00 2.849e+00 5.845e-04 1.055e-01 3.513e-01
 1.427e+00 5.303e-02 9.626e-05 3.140e+00 2.591e-04 6.038e-04 9.577e-05
 1.823e-01 2.424e-04 1.917e+00 2.055e-04 1.451e-05 3.604e-03 2.673e-01
 4.181e+00 4.820e-01 1.288e-01 1.687e+00 3.373e-01 1.465e+00 4.063e-02
 1.557e-01 1.088e-04 2.432e-04 8.215e-04 3.790e-06 2.054e-04 7.251e-04
 6.681e-05 6.926e-07 3.948e-04 1.327e-02 7.233e-03 2.569e+00 3.687e-04
 3.525e-01 2.354e+00 1.391e-04 4.959e-04 2.680e-01 8.186e-04 4.125e-04
 1.601e-04 4.249e-05 5.624e-01 6.046e-05 1.684e-05 1.655e-05 1.924e-03
 3.830e-02 2.921e-02 3.756e-01 4.551e-04 1.420e-01 2.064e+00 1.869e-01
 1.729e-02 2.335e-01 2.577e-01 3.463e+00 2.504e-01 3.478e-02 1.004e+00
 1.155e-01 1.873e+00 7.116e-02 1.940e-01 2.790e-04 1.593e-04 2.791e-01
 4.006e-05 1.122e+00 7.039e-04 2.735e-01 8.293e-04 6.597e-06]
[[0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 1. 1. 0. 0. 1. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9942857142857142, 0.9857142857142858)
cuda
noise_multiplier  0.4  noise_multiplier_b  5.0  noise_multiplier_delta  0.40032038451271784
cuda
Objective function 493.46 = squared loss an data 316.40 + 0.5*rho*h**2 176.710652 + alpha*h 0.000000 + L2reg 0.19 + L1reg 0.16 ; SHD = 55 ; DAG False
total norm for a microbatch 71.48332525343253 clip 9.383352533628253
total norm for a microbatch 43.43290696398594 clip 26.641406122532022
total norm for a microbatch 37.397241016813524 clip 33.100603500883466
total norm for a microbatch 41.54425675339538 clip 25.89954685130095
total norm for a microbatch 42.95600154991687 clip 25.817726870744472
total norm for a microbatch 40.287706454549614 clip 25.104494564724618
total norm for a microbatch 26.139056605308888 clip 25.51181358364182
total norm for a microbatch 27.940975227879587 clip 25.51181358364182
total norm for a microbatch 51.224124034781205 clip 28.075416206343164
total norm for a microbatch 30.581660305096577 clip 27.729739658724508
total norm for a microbatch 20.439361567860935 clip 27.740085523580984
total norm for a microbatch 46.05926451532836 clip 27.90058667367927
total norm for a microbatch 74.66152049389618 clip 26.927228539467514
total norm for a microbatch 31.821030768143196 clip 27.04611632797056
total norm for a microbatch 44.380671311046356 clip 29.220331693611435
total norm for a microbatch 58.31030738088629 clip 28.40291875221457
total norm for a microbatch 30.721621505991987 clip 28.630697355949145
total norm for a microbatch 38.03885157158741 clip 26.180449967765362
total norm for a microbatch 47.06526892537671 clip 26.492310439187353
total norm for a microbatch 37.03364494106058 clip 28.3721246496818
total norm for a microbatch 67.27586167135775 clip 27.39530198390871
total norm for a microbatch 29.74640894044136 clip 27.783557229355196
total norm for a microbatch 34.58249202029593 clip 27.82457131296382
total norm for a microbatch 60.88155990429531 clip 28.050149934682636
total norm for a microbatch 54.59210579792823 clip 29.044542178574194
total norm for a microbatch 15.623490139001275 clip 27.27596890068208
cuda
Objective function 8.65 = squared loss an data 7.29 + 0.5*rho*h**2 0.575393 + alpha*h 0.000000 + L2reg 0.71 + L1reg 0.08 ; SHD = 19 ; DAG False
Proportion of microbatches that were clipped  0.8089452016467484
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 1.072746621463338
iteration 1 in outer loop, alpha = 1.072746621463338, rho = 1.0, h = 1.072746621463338
cuda
noise_multiplier  0.4  noise_multiplier_b  5.0  noise_multiplier_delta  0.40032038451271784
cuda
Objective function 9.80 = squared loss an data 7.29 + 0.5*rho*h**2 0.575393 + alpha*h 1.150785 + L2reg 0.71 + L1reg 0.08 ; SHD = 19 ; DAG False
total norm for a microbatch 38.40904344511981 clip 1.0
total norm for a microbatch 37.471822498288105 clip 2.2974965007934824
total norm for a microbatch 53.146323185935735 clip 3.0072297243133117
total norm for a microbatch 47.454622076250935 clip 3.0072297243133117
total norm for a microbatch 32.3783970750893 clip 4.001024043660969
total norm for a microbatch 103.74585675393422 clip 11.823476602187657
total norm for a microbatch 45.78827943742753 clip 20.23118040135166
total norm for a microbatch 123.11709684171022 clip 32.65200210127781
total norm for a microbatch 72.90031608203411 clip 35.59944720234341
total norm for a microbatch 50.73872237847993 clip 34.015041309537004
total norm for a microbatch 45.64936618026213 clip 35.61642569116282
total norm for a microbatch 55.278167745226334 clip 37.286246123169406
total norm for a microbatch 54.61504112519821 clip 33.646268648322206
total norm for a microbatch 50.54947983001824 clip 36.353775887110345
total norm for a microbatch 30.871106401831256 clip 37.16468861880896
total norm for a microbatch 46.34337782076141 clip 36.849266119694974
total norm for a microbatch 45.698162856473765 clip 35.62574643326757
total norm for a microbatch 34.58501585322882 clip 39.23953234438721
total norm for a microbatch 39.280405420041895 clip 35.868598279307584
total norm for a microbatch 42.944993919544274 clip 36.66728836703089
total norm for a microbatch 58.87545987209805 clip 36.54511923676412
total norm for a microbatch 28.111500565766114 clip 36.1598410332936
total norm for a microbatch 32.01476056990174 clip 36.40619906214668
total norm for a microbatch 41.54191651142703 clip 36.58062223529107
total norm for a microbatch 60.820581366760635 clip 37.93661054175914
total norm for a microbatch 45.50375596094013 clip 37.08019579337559
total norm for a microbatch 58.07601017276616 clip 36.691728213716
cuda
Objective function 7.17 = squared loss an data 5.10 + 0.5*rho*h**2 0.210400 + alpha*h 0.695882 + L2reg 1.08 + L1reg 0.08 ; SHD = 20 ; DAG False
Proportion of microbatches that were clipped  0.8071952355872463
iteration 1 in inner loop, alpha 1.072746621463338 rho 1.0 h 0.6486916974649226
noise_multiplier  0.4  noise_multiplier_b  5.0  noise_multiplier_delta  0.40032038451271784
cuda
Objective function 9.07 = squared loss an data 5.10 + 0.5*rho*h**2 2.104005 + alpha*h 0.695882 + L2reg 1.08 + L1reg 0.08 ; SHD = 20 ; DAG False
total norm for a microbatch 58.08354765778556 clip 5.46266520446207
total norm for a microbatch 81.64684368370497 clip 11.28516056164898
total norm for a microbatch 117.46173909062233 clip 14.836917372787273
total norm for a microbatch 51.40895853209437 clip 46.42975903594832
total norm for a microbatch 43.47673183052263 clip 43.02131395549989
total norm for a microbatch 42.71315485104715 clip 44.14746335421732
total norm for a microbatch 74.9499917989808 clip 43.65350564483793
total norm for a microbatch 73.09194679515612 clip 46.22488634187116
total norm for a microbatch 64.0414224395847 clip 47.03507999221556
total norm for a microbatch 51.629336603439654 clip 44.54145890686344
total norm for a microbatch 54.681831478030674 clip 44.54145890686344
total norm for a microbatch 79.24669959818854 clip 46.12528118089893
total norm for a microbatch 31.254633277207503 clip 42.807332236934826
total norm for a microbatch 26.096887235380613 clip 44.3077316096963
total norm for a microbatch 45.018208531814196 clip 43.34862036910974
total norm for a microbatch 140.749741836212 clip 45.58038462595187
total norm for a microbatch 34.97710846729268 clip 43.343483761529896
total norm for a microbatch 84.01087861080687 clip 42.33291321791519
total norm for a microbatch 82.14266630708806 clip 44.62324690244901
total norm for a microbatch 89.90223217954308 clip 45.7833921781017
total norm for a microbatch 47.20622737620731 clip 45.72794502905413
total norm for a microbatch 59.411289155928216 clip 47.048744675253175
total norm for a microbatch 50.455274618415004 clip 46.3384150470649
total norm for a microbatch 93.92324817187198 clip 43.91087397356859
total norm for a microbatch 62.69693581780205 clip 43.78289181721081
total norm for a microbatch 69.93482807670233 clip 46.32460406217286
cuda
Objective function 7.46 = squared loss an data 5.42 + 0.5*rho*h**2 0.379601 + alpha*h 0.295581 + L2reg 1.28 + L1reg 0.09 ; SHD = 15 ; DAG True
Proportion of microbatches that were clipped  0.8129066149432255
iteration 2 in inner loop, alpha 1.072746621463338 rho 10.0 h 0.27553619454337586
noise_multiplier  0.4  noise_multiplier_b  5.0  noise_multiplier_delta  0.40032038451271784
cuda
Objective function 10.88 = squared loss an data 5.42 + 0.5*rho*h**2 3.796010 + alpha*h 0.295581 + L2reg 1.28 + L1reg 0.09 ; SHD = 15 ; DAG True
total norm for a microbatch 84.04433845052039 clip 1.7281591943711252
total norm for a microbatch 123.57128544724593 clip 1.9070756496060055
total norm for a microbatch 78.1927181236535 clip 4.390255103702349
total norm for a microbatch 115.29860195621393 clip 5.224302972909504
total norm for a microbatch 77.25822025732103 clip 26.253739156013342
total norm for a microbatch 56.99878296209842 clip 34.75464357310708
total norm for a microbatch 35.103070018585306 clip 43.04062775396086
total norm for a microbatch 51.47289045000449 clip 54.520608449597454
total norm for a microbatch 85.74074351600974 clip 55.14933500884082
total norm for a microbatch 72.91335275287572 clip 54.86663913495546
total norm for a microbatch 59.08483751409006 clip 56.75468890068015
total norm for a microbatch 49.85884398278066 clip 51.14991369374496
total norm for a microbatch 64.8883093167837 clip 53.78249439049055
total norm for a microbatch 160.8221726451765 clip 56.3332943503424
total norm for a microbatch 83.24665831782175 clip 53.86172681087973
total norm for a microbatch 48.16785689784034 clip 57.60439541555741
total norm for a microbatch 82.81432284957451 clip 54.435100907511085
total norm for a microbatch 120.6627508021941 clip 52.05404939978433
total norm for a microbatch 26.593486443589494 clip 52.42185897487307
total norm for a microbatch 151.52013659483137 clip 51.21819562330606
total norm for a microbatch 47.58004547104144 clip 53.73284361610791
total norm for a microbatch 79.95404262962691 clip 56.2078399322867
total norm for a microbatch 96.23095638575101 clip 54.09297879102983
total norm for a microbatch 98.98608289330505 clip 54.238806846240045
total norm for a microbatch 126.32140374912385 clip 53.48352714091186
cuda
Objective function 7.95 = squared loss an data 6.05 + 0.5*rho*h**2 0.349941 + alpha*h 0.089745 + L2reg 1.38 + L1reg 0.09 ; SHD = 16 ; DAG True
Proportion of microbatches that were clipped  0.8116304391660282
iteration 3 in inner loop, alpha 1.072746621463338 rho 100.0 h 0.08365889177846952
iteration 2 in outer loop, alpha = 9.43863579931029, rho = 100.0, h = 0.08365889177846952
cuda
noise_multiplier  0.4  noise_multiplier_b  5.0  noise_multiplier_delta  0.40032038451271784
cuda
Objective function 8.65 = squared loss an data 6.05 + 0.5*rho*h**2 0.349941 + alpha*h 0.789626 + L2reg 1.38 + L1reg 0.09 ; SHD = 16 ; DAG True
total norm for a microbatch 152.78401162712072 clip 2.4575446613286425
total norm for a microbatch 57.07609350802959 clip 27.226516870322932
total norm for a microbatch 87.32677380351791 clip 60.44405368669454
total norm for a microbatch 89.38476377862611 clip 58.87015704168654
total norm for a microbatch 123.7384629064965 clip 57.70790890211059
total norm for a microbatch 77.16120077218027 clip 58.90421157391409
total norm for a microbatch 72.35481078265852 clip 53.82724858998231
total norm for a microbatch 90.93329895604217 clip 54.1262436366407
total norm for a microbatch 32.908667717128594 clip 53.592101170458335
total norm for a microbatch 65.16048010737084 clip 54.228121148228006
total norm for a microbatch 117.80019955025523 clip 56.98484874304587
total norm for a microbatch 69.58375000996833 clip 54.84073491254278
total norm for a microbatch 78.76744619930257 clip 53.587414265904485
total norm for a microbatch 58.86616862222804 clip 53.705191438996536
total norm for a microbatch 38.041286635904484 clip 52.619161112095775
total norm for a microbatch 89.51181936825195 clip 51.933760118197945
total norm for a microbatch 75.17672317440423 clip 52.9134745041592
total norm for a microbatch 64.4537040282658 clip 54.175615454622864
total norm for a microbatch 70.39424966039246 clip 55.80712751869511
total norm for a microbatch 111.22919137570818 clip 55.80712751869511
total norm for a microbatch 79.89488968420106 clip 54.769936775301176
cuda
Objective function 8.28 = squared loss an data 6.11 + 0.5*rho*h**2 0.134959 + alpha*h 0.490371 + L2reg 1.46 + L1reg 0.09 ; SHD = 18 ; DAG True
Proportion of microbatches that were clipped  0.8151098237991793
iteration 1 in inner loop, alpha 9.43863579931029 rho 100.0 h 0.051953593913136586
noise_multiplier  0.4  noise_multiplier_b  5.0  noise_multiplier_delta  0.40032038451271784
cuda
Objective function 9.50 = squared loss an data 6.11 + 0.5*rho*h**2 1.349588 + alpha*h 0.490371 + L2reg 1.46 + L1reg 0.09 ; SHD = 18 ; DAG True
total norm for a microbatch 131.82856052014347 clip 1.5502416099917622
total norm for a microbatch 63.06406165547976 clip 1.8815970751525373
total norm for a microbatch 60.301264047019494 clip 3.885033375984963
total norm for a microbatch 84.55237414565873 clip 6.6887857917144675
total norm for a microbatch 60.10026386656361 clip 16.316340619529495
total norm for a microbatch 75.92443160464806 clip 58.84041119784769
total norm for a microbatch 64.86925332409164 clip 59.743451559040814
total norm for a microbatch 80.14719131929819 clip 56.6482438878595
total norm for a microbatch 48.93992761086462 clip 58.40856139488373
total norm for a microbatch 69.68121266095784 clip 57.752253134056616
total norm for a microbatch 59.07396048572974 clip 55.07095526921293
total norm for a microbatch 98.74127502308589 clip 55.336045899281835
total norm for a microbatch 49.78236701694166 clip 54.6040283307519
total norm for a microbatch 42.402133932770916 clip 56.856562939094516
total norm for a microbatch 146.48960706308114 clip 54.98628927982987
total norm for a microbatch 65.45652297373353 clip 55.48565659264416
total norm for a microbatch 82.96211828827032 clip 53.155698845826194
total norm for a microbatch 53.54135300183772 clip 54.886931714554876
total norm for a microbatch 53.923302347310745 clip 54.407637881572455
total norm for a microbatch 59.44000431401683 clip 55.03401899512386
total norm for a microbatch 65.69401030413974 clip 55.13499767545294
total norm for a microbatch 57.790657003554486 clip 55.74041541707146
cuda
Objective function 8.72 = squared loss an data 6.66 + 0.5*rho*h**2 0.253846 + alpha*h 0.212672 + L2reg 1.50 + L1reg 0.09 ; SHD = 18 ; DAG True
Proportion of microbatches that were clipped  0.8167999681668059
iteration 2 in inner loop, alpha 9.43863579931029 rho 1000.0 h 0.022532030872564945
noise_multiplier  0.4  noise_multiplier_b  5.0  noise_multiplier_delta  0.40032038451271784
cuda
Objective function 11.01 = squared loss an data 6.66 + 0.5*rho*h**2 2.538462 + alpha*h 0.212672 + L2reg 1.50 + L1reg 0.09 ; SHD = 18 ; DAG True
total norm for a microbatch 68.06297937864686 clip 3.599556464948024
total norm for a microbatch 72.6045941061167 clip 64.45411493222177
total norm for a microbatch 82.81310077739721 clip 55.41699094900419
total norm for a microbatch 86.7555759505553 clip 59.277459324158144
total norm for a microbatch 135.2887866895172 clip 57.912032341769084
total norm for a microbatch 125.79644678394226 clip 57.17562998990818
total norm for a microbatch 72.45318019817174 clip 58.18393264864816
total norm for a microbatch 64.41256011698731 clip 57.69743171436617
total norm for a microbatch 57.97211351042934 clip 57.04973526793262
total norm for a microbatch 117.25775441216621 clip 58.68033171005329
total norm for a microbatch 150.6517863956013 clip 54.7402603406391
total norm for a microbatch 58.90368593520648 clip 56.672276551804345
total norm for a microbatch 56.81402168800402 clip 56.37237194450884
total norm for a microbatch 96.98386885517279 clip 55.36614732160646
total norm for a microbatch 67.97777626293696 clip 55.36373432670922
total norm for a microbatch 56.92122927135631 clip 55.52107325128475
cuda
Objective function 8.58 = squared loss an data 6.77 + 0.5*rho*h**2 0.170188 + alpha*h 0.055067 + L2reg 1.48 + L1reg 0.10 ; SHD = 19 ; DAG True
Proportion of microbatches that were clipped  0.8147650476228115
iteration 3 in inner loop, alpha 9.43863579931029 rho 10000.0 h 0.005834177924683104
iteration 3 in outer loop, alpha = 67.78041504614133, rho = 10000.0, h = 0.005834177924683104
cuda
noise_multiplier  0.4  noise_multiplier_b  5.0  noise_multiplier_delta  0.40032038451271784
cuda
Objective function 8.92 = squared loss an data 6.77 + 0.5*rho*h**2 0.170188 + alpha*h 0.395443 + L2reg 1.48 + L1reg 0.10 ; SHD = 19 ; DAG True
total norm for a microbatch 231.29566023774095 clip 1.5818715662115517
total norm for a microbatch 182.3794643750925 clip 1.913680849559393
total norm for a microbatch 90.13236288193671 clip 3.5650297205976718
total norm for a microbatch 111.77184624379797 clip 4.704709635158743
total norm for a microbatch 63.536064911111765 clip 5.636075005293358
total norm for a microbatch 113.26429358882179 clip 8.930349544875375
total norm for a microbatch 89.26642070418785 clip 16.727545736011763
total norm for a microbatch 76.93410073142061 clip 24.49765569516629
total norm for a microbatch 47.206458046842734 clip 26.876393304476373
total norm for a microbatch 85.9429795025966 clip 46.01277567968494
total norm for a microbatch 66.63284150256426 clip 50.480590110516935
total norm for a microbatch 97.91554232467259 clip 60.417645228349414
total norm for a microbatch 37.38619826924983 clip 59.11701331502565
total norm for a microbatch 91.93195722535233 clip 57.19694995497495
total norm for a microbatch 52.284454457564216 clip 57.77754321801841
total norm for a microbatch 48.00449497081565 clip 51.149080360125716
total norm for a microbatch 78.0778640787138 clip 53.743937531047344
total norm for a microbatch 39.488619944152816 clip 52.48610908571174
total norm for a microbatch 108.68840456491202 clip 52.55577615490717
total norm for a microbatch 68.07232049008994 clip 53.10436774444991
total norm for a microbatch 80.11279348583555 clip 56.035963594343265
total norm for a microbatch 64.54269087142158 clip 54.9388706195526
total norm for a microbatch 59.34366473324878 clip 54.328176492714995
total norm for a microbatch 41.072053742237905 clip 57.42073395181285
total norm for a microbatch 87.85999441795549 clip 51.28061754320589
total norm for a microbatch 51.702003564393465 clip 53.29896535617411
total norm for a microbatch 114.18812793412802 clip 54.06293252686974
total norm for a microbatch 113.9291897548418 clip 53.39423284170245
total norm for a microbatch 27.301328889740866 clip 53.57543774784432
total norm for a microbatch 144.257445397041 clip 49.595849117932126
cuda
Objective function 8.48 = squared loss an data 6.56 + 0.5*rho*h**2 0.062419 + alpha*h 0.239484 + L2reg 1.51 + L1reg 0.11 ; SHD = 15 ; DAG True
Proportion of microbatches that were clipped  0.8160864727388333
iteration 1 in inner loop, alpha 67.78041504614133 rho 10000.0 h 0.0035332355071169275
noise_multiplier  0.4  noise_multiplier_b  5.0  noise_multiplier_delta  0.40032038451271784
cuda
Objective function 9.04 = squared loss an data 6.56 + 0.5*rho*h**2 0.624188 + alpha*h 0.239484 + L2reg 1.51 + L1reg 0.11 ; SHD = 15 ; DAG True
total norm for a microbatch 114.63135485143276 clip 1.0
total norm for a microbatch 230.83786790014577 clip 2.9709337222530334
total norm for a microbatch 77.61227467829843 clip 8.245577563906984
total norm for a microbatch 125.11042825381078 clip 55.40134748429431
total norm for a microbatch 102.79741488978364 clip 54.580676991921614
total norm for a microbatch 109.38568282166193 clip 53.01131469831074
total norm for a microbatch 45.177459966927835 clip 48.88056766141326
total norm for a microbatch 107.34276445070819 clip 49.9470052202388
total norm for a microbatch 73.73425410008475 clip 50.487364145650425
total norm for a microbatch 65.02658250954813 clip 49.058714278925756
total norm for a microbatch 50.06858427909873 clip 47.70902788984641
total norm for a microbatch 61.66986455161764 clip 48.15804484190449
total norm for a microbatch 66.50647256622128 clip 50.52662633982241
total norm for a microbatch 117.51565617707384 clip 51.65156546738446
total norm for a microbatch 77.42808415850762 clip 52.90424857269295
total norm for a microbatch 38.68077560125708 clip 50.90822415002015
total norm for a microbatch 84.08345698065087 clip 51.656170413143165
total norm for a microbatch 84.41782717172913 clip 53.50376043141478
cuda
Objective function 8.23 = squared loss an data 6.49 + 0.5*rho*h**2 0.063030 + alpha*h 0.076101 + L2reg 1.49 + L1reg 0.11 ; SHD = 16 ; DAG True
Proportion of microbatches that were clipped  0.8157632324199274
iteration 2 in inner loop, alpha 67.78041504614133 rho 100000.0 h 0.0011227608383155285
iteration 4 in outer loop, alpha = 180.0564988776942, rho = 100000.0, h = 0.0011227608383155285
cuda
noise_multiplier  0.4  noise_multiplier_b  5.0  noise_multiplier_delta  0.40032038451271784
cuda
Objective function 8.36 = squared loss an data 6.49 + 0.5*rho*h**2 0.063030 + alpha*h 0.202160 + L2reg 1.49 + L1reg 0.11 ; SHD = 16 ; DAG True
total norm for a microbatch 1612.5356224711259 clip 1.8823879458778614
total norm for a microbatch 345.9973237884892 clip 3.4586126502126597
total norm for a microbatch 122.99732799159214 clip 6.550023416447731
total norm for a microbatch 84.89553683319954 clip 14.948422136913674
total norm for a microbatch 144.10727582748427 clip 30.800496165692692
total norm for a microbatch 150.58037673554287 clip 57.67674043630323
total norm for a microbatch 240.8042490409771 clip 98.32578678696672
total norm for a microbatch 136.71785914758112 clip 119.58541860626742
total norm for a microbatch 65.25465177587635 clip 52.93627123740508
total norm for a microbatch 57.332059182020096 clip 51.913028133610716
total norm for a microbatch 89.93259759790871 clip 51.856020793732775
total norm for a microbatch 42.19803935037433 clip 52.82302789777385
total norm for a microbatch 61.071463499673605 clip 49.822770913238365
total norm for a microbatch 89.96866460302665 clip 49.093142855468066
total norm for a microbatch 119.6538520949641 clip 52.69236944734179
total norm for a microbatch 87.52997073789314 clip 51.103051194072385
total norm for a microbatch 83.98525253379496 clip 49.8796948834808
total norm for a microbatch 66.94101589952625 clip 50.99488316139696
total norm for a microbatch 62.77672287752524 clip 49.57912295785603
total norm for a microbatch 44.565167609908336 clip 51.70538776719551
total norm for a microbatch 52.60457365392437 clip 49.50731022158679
total norm for a microbatch 42.28369341812726 clip 53.35100672308773
total norm for a microbatch 72.40238655357508 clip 56.21510632872526
total norm for a microbatch 36.77781518363995 clip 51.383036531128546
total norm for a microbatch 82.20117516852216 clip 52.70978954788419
cuda
Objective function 8.27 = squared loss an data 6.47 + 0.5*rho*h**2 0.025353 + alpha*h 0.128215 + L2reg 1.53 + L1reg 0.11 ; SHD = 13 ; DAG True
Proportion of microbatches that were clipped  0.8122713200112581
iteration 1 in inner loop, alpha 180.0564988776942 rho 100000.0 h 0.0007120803603193337
iteration 5 in outer loop, alpha = 892.1368591970279, rho = 1000000.0, h = 0.0007120803603193337
Threshold 0.3
[[0.004 0.006 0.296 0.002 0.788 0.151 0.295 0.08  0.003 2.278]
 [0.685 0.008 2.544 0.001 0.499 0.517 1.137 0.107 0.001 2.574]
 [0.013 0.001 0.002 0.    0.295 0.001 0.76  0.002 0.001 0.061]
 [1.018 3.224 1.349 0.002 1.073 1.387 0.876 1.408 0.155 1.073]
 [0.003 0.002 0.013 0.001 0.003 0.004 0.012 0.003 0.002 0.008]
 [0.025 0.008 2.264 0.002 0.658 0.003 1.439 0.002 0.003 0.202]
 [0.009 0.001 0.007 0.001 0.471 0.002 0.005 0.003 0.002 0.014]
 [0.059 0.033 0.553 0.003 0.572 1.177 0.36  0.002 0.011 0.204]
 [0.658 1.966 1.    0.025 1.044 0.644 1.587 0.286 0.003 0.652]
 [0.001 0.001 0.067 0.    0.534 0.023 0.177 0.012 0.001 0.004]]
[[0.    0.    0.    0.    0.788 0.    0.    0.    0.    2.278]
 [0.685 0.    2.544 0.    0.499 0.517 1.137 0.    0.    2.574]
 [0.    0.    0.    0.    0.    0.    0.76  0.    0.    0.   ]
 [1.018 3.224 1.349 0.    1.073 1.387 0.876 1.408 0.    1.073]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    2.264 0.    0.658 0.    1.439 0.    0.    0.   ]
 [0.    0.    0.    0.    0.471 0.    0.    0.    0.    0.   ]
 [0.    0.    0.553 0.    0.572 1.177 0.36  0.    0.    0.   ]
 [0.658 1.966 1.    0.    1.044 0.644 1.587 0.    0.    0.652]
 [0.    0.    0.    0.    0.534 0.    0.    0.    0.    0.   ]]
{'fdr': 0.3939393939393939, 'tpr': 1.0, 'fpr': 0.52, 'f1': 0.7547169811320755, 'shd': 13, 'npred': 33, 'ntrue': 20}
[6.340e-03 2.960e-01 1.763e-03 7.885e-01 1.508e-01 2.949e-01 8.010e-02
 3.226e-03 2.278e+00 6.845e-01 2.544e+00 1.211e-03 4.985e-01 5.173e-01
 1.137e+00 1.071e-01 1.424e-03 2.574e+00 1.254e-02 8.943e-04 4.344e-04
 2.954e-01 1.167e-03 7.597e-01 2.387e-03 1.189e-03 6.069e-02 1.018e+00
 3.224e+00 1.349e+00 1.073e+00 1.387e+00 8.761e-01 1.408e+00 1.548e-01
 1.073e+00 2.640e-03 2.225e-03 1.328e-02 1.219e-03 3.882e-03 1.200e-02
 2.921e-03 2.239e-03 7.635e-03 2.526e-02 7.665e-03 2.264e+00 1.578e-03
 6.584e-01 1.439e+00 1.815e-03 2.871e-03 2.019e-01 8.664e-03 1.495e-03
 7.428e-03 1.426e-03 4.712e-01 1.706e-03 2.655e-03 1.599e-03 1.399e-02
 5.890e-02 3.298e-02 5.529e-01 2.574e-03 5.724e-01 1.177e+00 3.598e-01
 1.085e-02 2.038e-01 6.578e-01 1.966e+00 9.995e-01 2.480e-02 1.044e+00
 6.439e-01 1.587e+00 2.860e-01 6.516e-01 1.075e-03 1.283e-03 6.727e-02
 4.190e-04 5.340e-01 2.269e-02 1.770e-01 1.221e-02 9.545e-04]
[[0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 1. 1. 0. 0. 1. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9728571428571429, 0.9232615491337601)
Iterations 2500
Achieves (92.9799135797352, 1e-05)-DP
