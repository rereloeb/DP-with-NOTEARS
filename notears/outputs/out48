samples  5000  graph  12 24 ER mim  minibatch size  75  noise  0.5  minibatches per NN training  111 adaclip
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.3547868753222367
iteration 1 in outer loop, alpha = 1.3547868753222367, rho = 1.0, h = 1.3547868753222367
cuda
iteration 1 in inner loop,alpha 1.3547868753222367 rho 1.0 h 0.8318017776157465
iteration 2 in inner loop,alpha 1.3547868753222367 rho 10.0 h 0.3389919481792134
iteration 3 in inner loop,alpha 1.3547868753222367 rho 100.0 h 0.09244439604472277
iteration 2 in outer loop, alpha = 10.599226479794513, rho = 100.0, h = 0.09244439604472277
cuda
iteration 1 in inner loop,alpha 10.599226479794513 rho 100.0 h 0.04713402619085372
iteration 2 in inner loop,alpha 10.599226479794513 rho 1000.0 h 0.013466270810381431
iteration 3 in outer loop, alpha = 24.065497290175944, rho = 1000.0, h = 0.013466270810381431
cuda
iteration 1 in inner loop,alpha 24.065497290175944 rho 1000.0 h 0.006718631112031304
iteration 2 in inner loop,alpha 24.065497290175944 rho 10000.0 h 0.0020923810779098773
iteration 4 in outer loop, alpha = 44.98930806927471, rho = 10000.0, h = 0.0020923810779098773
cuda
iteration 1 in inner loop,alpha 44.98930806927471 rho 10000.0 h 0.000806323421986832
iteration 2 in inner loop,alpha 44.98930806927471 rho 100000.0 h 0.0002918026539457941
iteration 5 in outer loop, alpha = 74.16957346385412, rho = 100000.0, h = 0.0002918026539457941
cuda
iteration 1 in inner loop,alpha 74.16957346385412 rho 100000.0 h 0.000166000714653336
iteration 6 in outer loop, alpha = 240.17028811719013, rho = 1000000.0, h = 0.000166000714653336
Threshold 0.3
[[0.005 0.    0.689 0.004 0.564 0.    0.066 0.    0.    0.143 0.    0.003]
 [2.091 0.002 0.455 0.157 0.108 0.001 0.086 0.001 0.    0.782 0.272 1.287]
 [0.004 0.001 0.005 0.011 0.46  0.    0.047 0.    0.    0.581 0.002 0.003]
 [0.046 0.001 0.058 0.002 0.158 0.    0.811 0.    0.    0.933 0.    0.329]
 [0.004 0.001 0.004 0.005 0.004 0.    0.818 0.    0.    0.629 0.002 0.   ]
 [0.046 0.041 0.658 0.035 0.018 0.    0.057 0.013 0.007 0.025 0.019 0.088]
 [0.003 0.    0.002 0.001 0.001 0.    0.003 0.    0.    0.019 0.    0.001]
 [3.164 0.029 0.737 0.026 0.073 0.006 0.859 0.    0.009 0.02  0.029 0.082]
 [0.163 2.38  0.039 2.101 0.164 0.002 0.814 0.009 0.    0.993 3.47  0.042]
 [0.002 0.001 0.002 0.001 0.003 0.    0.014 0.    0.    0.004 0.    0.001]
 [0.173 0.005 0.023 2.478 0.029 0.008 0.076 0.001 0.    0.117 0.003 0.908]
 [0.227 0.001 0.016 0.001 0.027 0.    1.065 0.    0.    0.099 0.001 0.004]]
[[0.    0.    0.689 0.    0.564 0.    0.    0.    0.    0.    0.    0.   ]
 [2.091 0.    0.455 0.    0.    0.    0.    0.    0.    0.782 0.    1.287]
 [0.    0.    0.    0.    0.46  0.    0.    0.    0.    0.581 0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.811 0.    0.    0.933 0.    0.329]
 [0.    0.    0.    0.    0.    0.    0.818 0.    0.    0.629 0.    0.   ]
 [0.    0.    0.658 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [3.164 0.    0.737 0.    0.    0.    0.859 0.    0.    0.    0.    0.   ]
 [0.    2.38  0.    2.101 0.    0.    0.814 0.    0.    0.993 3.47  0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    2.478 0.    0.    0.    0.    0.    0.    0.    0.908]
 [0.    0.    0.    0.    0.    0.    1.065 0.    0.    0.    0.    0.   ]]
{'fdr': 0.08, 'tpr': 0.9583333333333334, 'fpr': 0.047619047619047616, 'f1': 0.9387755102040817, 'shd': 2, 'npred': 25, 'ntrue': 24}
[3.891e-04 6.891e-01 3.976e-03 5.638e-01 1.621e-04 6.595e-02 2.170e-06
 4.649e-06 1.427e-01 2.558e-04 3.003e-03 2.091e+00 4.547e-01 1.568e-01
 1.078e-01 1.286e-03 8.573e-02 8.950e-04 2.019e-05 7.816e-01 2.725e-01
 1.287e+00 3.526e-03 8.574e-04 1.148e-02 4.596e-01 5.818e-05 4.742e-02
 4.640e-05 7.629e-05 5.811e-01 2.183e-03 3.214e-03 4.581e-02 8.754e-04
 5.757e-02 1.577e-01 4.781e-04 8.114e-01 4.545e-04 6.886e-06 9.328e-01
 2.810e-04 3.288e-01 4.441e-03 1.122e-03 4.485e-03 5.034e-03 1.072e-04
 8.176e-01 3.937e-05 9.238e-05 6.294e-01 1.718e-03 2.790e-04 4.566e-02
 4.104e-02 6.580e-01 3.549e-02 1.838e-02 5.655e-02 1.251e-02 7.247e-03
 2.516e-02 1.894e-02 8.762e-02 3.429e-03 4.279e-04 2.064e-03 6.654e-04
 1.111e-03 3.385e-04 1.964e-05 4.703e-06 1.948e-02 2.821e-04 1.116e-03
 3.164e+00 2.921e-02 7.369e-01 2.588e-02 7.276e-02 6.495e-03 8.593e-01
 9.420e-03 1.957e-02 2.938e-02 8.226e-02 1.628e-01 2.380e+00 3.900e-02
 2.101e+00 1.643e-01 1.558e-03 8.143e-01 9.203e-03 9.927e-01 3.470e+00
 4.165e-02 1.685e-03 7.482e-04 2.080e-03 7.865e-04 2.790e-03 2.919e-04
 1.395e-02 1.205e-04 3.669e-06 2.767e-04 1.040e-03 1.727e-01 4.731e-03
 2.321e-02 2.478e+00 2.889e-02 7.628e-03 7.621e-02 1.421e-03 7.456e-06
 1.170e-01 9.080e-01 2.266e-01 6.598e-04 1.559e-02 5.696e-04 2.709e-02
 1.968e-04 1.065e+00 2.657e-04 2.644e-07 9.924e-02 1.228e-03]
[[0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0.
 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.976466049382716, 0.963253240653603)
cuda
1692
cuda
Objective function 178.80 = squared loss an data 15.69 + 0.5*rho*h**2 162.682537 + alpha*h 0.000000 + L2reg 0.22 + L1reg 0.21 ; SHD = 78 ; DAG False
||w||^2 11768316474.714542
exp ma of ||w||^2 746976173353.5339
||w|| 108481.87164090847
exp ma of ||w|| 474166.2426392735
||w||^2 64740.020048130464
exp ma of ||w||^2 1697187407.483253
||w|| 254.44060220045554
exp ma of ||w|| 1611.1628724433153
||w||^2 73.16973626862496
exp ma of ||w||^2 323.2164853560443
||w|| 8.553931041844152
exp ma of ||w|| 12.332092074520057
||w||^2 27.57850125726549
exp ma of ||w||^2 57.15487036436081
||w|| 5.251523708150377
exp ma of ||w|| 6.895532085001553
||w||^2 23.84232977897654
exp ma of ||w||^2 26.342406057286098
||w|| 4.882860819128121
exp ma of ||w|| 4.8044140254842285
||w||^2 1.1102888794805457
exp ma of ||w||^2 0.5153918313826898
||w|| 1.0537024625009404
exp ma of ||w|| 0.6751854894579722
||w||^2 0.3901201281373814
exp ma of ||w||^2 0.27068207851774834
||w|| 0.6245959719189529
exp ma of ||w|| 0.4952260882652331
||w||^2 0.04551672299074302
exp ma of ||w||^2 0.23156846675588982
||w|| 0.21334648577078325
exp ma of ||w|| 0.45342682418284663
||w||^2 0.08507798029988092
exp ma of ||w||^2 0.12223955331235481
||w|| 0.2916812991946534
exp ma of ||w|| 0.3306740351039556
||w||^2 0.0304152066053656
exp ma of ||w||^2 0.06366944895041912
||w|| 0.17439956022125055
exp ma of ||w|| 0.24165218081843393
||w||^2 0.06011203274910593
exp ma of ||w||^2 0.05550329266386974
||w|| 0.2451775535180697
exp ma of ||w|| 0.22492582938448702
cuda
Objective function 9.12 = squared loss an data 7.56 + 0.5*rho*h**2 1.139039 + alpha*h 0.000000 + L2reg 0.31 + L1reg 0.11 ; SHD = 43 ; DAG False
Proportion of microbatches that were clipped  0.5420686286481866
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 1.5093302560886777
iteration 1 in outer loop, alpha = 1.5093302560886777, rho = 1.0, h = 1.5093302560886777
cuda
1692
cuda
Objective function 11.40 = squared loss an data 7.56 + 0.5*rho*h**2 1.139039 + alpha*h 2.278078 + L2reg 0.31 + L1reg 0.11 ; SHD = 43 ; DAG False
||w||^2 2539039908.5953035
exp ma of ||w||^2 5021671300.860366
||w|| 50388.88675685645
exp ma of ||w|| 61984.61672501457
||w||^2 346815643.99941224
exp ma of ||w||^2 781265623.3337748
||w|| 18622.986978447152
exp ma of ||w|| 26319.418957811755
||w||^2 18439144.266765974
exp ma of ||w||^2 40283124.800347045
||w|| 4294.0824708854825
exp ma of ||w|| 5838.779663683136
||w||^2 1231396.2072842543
exp ma of ||w||^2 6969382.794864116
||w|| 1109.6829309691368
exp ma of ||w|| 2471.7798550368652
||w||^2 46449.82324984027
exp ma of ||w||^2 97948.20985788209
||w|| 215.52221057199714
exp ma of ||w|| 289.6971861312876
||w||^2 214.1681901247051
exp ma of ||w||^2 698.9360832877837
||w|| 14.634486329376411
exp ma of ||w|| 24.28087338646419
||w||^2 19.667395164410905
exp ma of ||w||^2 75.38722215604497
||w|| 4.4347937003214595
exp ma of ||w|| 8.02895006909787
cuda
Objective function 8.47 = squared loss an data 6.80 + 0.5*rho*h**2 0.163080 + alpha*h 0.861985 + L2reg 0.56 + L1reg 0.08 ; SHD = 19 ; DAG False
Proportion of microbatches that were clipped  1.0
iteration 1 in inner loop, alpha 1.5093302560886777 rho 1.0 h 0.5711041052206465
1692
cuda
Objective function 9.93 = squared loss an data 6.80 + 0.5*rho*h**2 1.630799 + alpha*h 0.861985 + L2reg 0.56 + L1reg 0.08 ; SHD = 19 ; DAG False
||w||^2 5064118118.018808
exp ma of ||w||^2 10291211496.245583
||w|| 71162.61741967344
exp ma of ||w|| 89877.417992838
||w||^2 36191319.31224251
exp ma of ||w||^2 28783166.04502418
||w|| 6015.922149782401
exp ma of ||w|| 4921.390535607975
||w||^2 17260501.95228935
exp ma of ||w||^2 24075702.687159695
||w|| 4154.576025575817
exp ma of ||w|| 4557.836355822503
||w||^2 422782.2232042858
exp ma of ||w||^2 981239.7288273253
||w|| 650.2170585306769
exp ma of ||w|| 905.7417613354986
||w||^2 227552.0264851938
exp ma of ||w||^2 221651.69447673095
||w|| 477.02413616628854
exp ma of ||w|| 432.4769050229465
||w||^2 13109.127857876218
exp ma of ||w||^2 79266.19457073387
||w|| 114.49509971119383
exp ma of ||w|| 262.170677493272
||w||^2 11222.686496467031
exp ma of ||w||^2 25251.434002225586
||w|| 105.93718184125454
exp ma of ||w|| 149.04578735001678
||w||^2 19869.713249447268
exp ma of ||w||^2 17062.998402183355
||w|| 140.95997037970486
exp ma of ||w|| 120.16505104356655
||w||^2 659.2847442076795
exp ma of ||w||^2 312.8254365849601
||w|| 25.67654073678305
exp ma of ||w|| 16.25140447563832
||w||^2 143.48689629914765
exp ma of ||w||^2 295.1033957119575
||w|| 11.97860160031828
exp ma of ||w|| 15.873269793668248
||w||^2 268.266182989437
exp ma of ||w||^2 259.0986501775176
||w|| 16.378833383041574
exp ma of ||w|| 14.924834469526814
||w||^2 120.63411501530922
exp ma of ||w||^2 228.31457063286229
||w|| 10.983356272802464
exp ma of ||w|| 14.028676968668083
cuda
Objective function 9.05 = squared loss an data 7.35 + 0.5*rho*h**2 0.448254 + alpha*h 0.451920 + L2reg 0.73 + L1reg 0.07 ; SHD = 20 ; DAG True
Proportion of microbatches that were clipped  1.0
iteration 2 in inner loop, alpha 1.5093302560886777 rho 10.0 h 0.2994174457198593
iteration 2 in outer loop, alpha = 4.5035047132872705, rho = 10.0, h = 0.2994174457198593
cuda
1692
cuda
Objective function 9.95 = squared loss an data 7.35 + 0.5*rho*h**2 0.448254 + alpha*h 1.348428 + L2reg 0.73 + L1reg 0.07 ; SHD = 20 ; DAG True
||w||^2 5220612692.36949
exp ma of ||w||^2 2896558778.555279
||w|| 72253.80745932694
exp ma of ||w|| 49622.93314718913
||w||^2 872772.1886223301
exp ma of ||w||^2 8111629.963650266
||w|| 934.2227724811305
exp ma of ||w|| 2588.391929554571
||w||^2 265674.5998824072
exp ma of ||w||^2 522682.9847934212
||w|| 515.436319910042
exp ma of ||w|| 673.1602704171763
||w||^2 17128.5916412757
exp ma of ||w||^2 37184.37263965904
||w|| 130.87624551948187
exp ma of ||w|| 178.23661617125717
||w||^2 24901.455005412943
exp ma of ||w||^2 36127.57484122896
||w|| 157.8019486743207
exp ma of ||w|| 175.39589365200362
||w||^2 4285.260874333488
exp ma of ||w||^2 6165.484448555258
||w|| 65.46190399257792
exp ma of ||w|| 72.11647791074398
||w||^2 32.32667987787004
exp ma of ||w||^2 113.8433449622026
||w|| 5.685655624276768
exp ma of ||w|| 9.912611905984978
cuda
Objective function 9.63 = squared loss an data 7.81 + 0.5*rho*h**2 0.156200 + alpha*h 0.795988 + L2reg 0.80 + L1reg 0.07 ; SHD = 20 ; DAG True
Proportion of microbatches that were clipped  1.0
iteration 1 in inner loop, alpha 4.5035047132872705 rho 10.0 h 0.17674854227812098
1692
cuda
Objective function 11.03 = squared loss an data 7.81 + 0.5*rho*h**2 1.562002 + alpha*h 0.795988 + L2reg 0.80 + L1reg 0.07 ; SHD = 20 ; DAG True
||w||^2 1142378897.7776673
exp ma of ||w||^2 2508721886.78001
||w|| 33799.09610888533
exp ma of ||w|| 46066.71751923231
||w||^2 1753725845.9538126
exp ma of ||w||^2 1790953619.9489417
||w|| 41877.51002571443
exp ma of ||w|| 38837.92832110975
||w||^2 338289086.3291895
exp ma of ||w||^2 1382865295.1739497
||w|| 18392.636742163682
exp ma of ||w|| 34147.91326708883
||w||^2 560563251.8406609
exp ma of ||w||^2 231626902.42857987
||w|| 23676.217008649437
exp ma of ||w|| 14013.878517225181
||w||^2 6387038.312146516
exp ma of ||w||^2 17292555.190076467
||w|| 2527.259051254247
exp ma of ||w|| 3847.2358498779204
||w||^2 52035.596436322754
exp ma of ||w||^2 98941.87940958772
||w|| 228.11312201695623
exp ma of ||w|| 286.80337978477513
||w||^2 8.771500003310969
exp ma of ||w||^2 36.428750988228565
||w|| 2.9616718257279904
exp ma of ||w|| 5.557999196006868
cuda
Objective function 10.09 = squared loss an data 8.55 + 0.5*rho*h**2 0.310206 + alpha*h 0.354724 + L2reg 0.82 + L1reg 0.06 ; SHD = 16 ; DAG True
Proportion of microbatches that were clipped  1.0
iteration 2 in inner loop, alpha 4.5035047132872705 rho 100.0 h 0.07876622391270516
1692
cuda
Objective function 12.88 = squared loss an data 8.55 + 0.5*rho*h**2 3.102059 + alpha*h 0.354724 + L2reg 0.82 + L1reg 0.06 ; SHD = 16 ; DAG True
||w||^2 227083473.77428654
exp ma of ||w||^2 942800374.0328641
||w|| 15069.289093195024
exp ma of ||w|| 28069.88561620353
||w||^2 147001392.47302747
exp ma of ||w||^2 147490807.46734005
||w|| 12124.413077465955
exp ma of ||w|| 11252.029552346861
||w||^2 1823485.188198815
exp ma of ||w||^2 2094167.8738551852
||w|| 1350.3648352200287
exp ma of ||w|| 1312.8002113800671
||w||^2 382319.8745023953
exp ma of ||w||^2 1848944.8150295832
||w|| 618.3202038607467
exp ma of ||w|| 1250.8583412752073
cuda
Objective function 10.67 = squared loss an data 9.19 + 0.5*rho*h**2 0.489479 + alpha*h 0.140907 + L2reg 0.79 + L1reg 0.05 ; SHD = 17 ; DAG True
Proportion of microbatches that were clipped  0.9644676206645646
iteration 3 in inner loop, alpha 4.5035047132872705 rho 1000.0 h 0.03128830154871309
iteration 3 in outer loop, alpha = 35.791806262000364, rho = 1000.0, h = 0.03128830154871309
cuda
1692
cuda
Objective function 11.64 = squared loss an data 9.19 + 0.5*rho*h**2 0.489479 + alpha*h 1.119865 + L2reg 0.79 + L1reg 0.05 ; SHD = 17 ; DAG True
||w||^2 647725022.0592043
exp ma of ||w||^2 15002605033.621561
||w|| 25450.442472758787
exp ma of ||w|| 107599.08092467522
||w||^2 869602982.3908736
exp ma of ||w||^2 1985395326.1711586
||w|| 29489.03156074939
exp ma of ||w|| 41043.11486089096
||w||^2 778902.4221195783
exp ma of ||w||^2 1967443.6087475556
||w|| 882.5544867709746
exp ma of ||w|| 1283.9107917871029
||w||^2 197399.00011929404
exp ma of ||w||^2 545128.4935211946
||w|| 444.2960725904451
exp ma of ||w|| 679.1929276213361
||w||^2 53471.3387520136
exp ma of ||w||^2 118380.11927725081
||w|| 231.23870513392347
exp ma of ||w|| 314.03800655038634
||w||^2 131.35890549692303
exp ma of ||w||^2 391.45205863905005
||w|| 11.461191277390105
exp ma of ||w|| 17.99646021146837
||w||^2 0.17804970670706982
exp ma of ||w||^2 0.2546422421320935
||w|| 0.42195936618005037
exp ma of ||w|| 0.4781308756349606
||w||^2 0.16006120564009174
exp ma of ||w||^2 0.233408284531684
||w|| 0.4000764997348529
exp ma of ||w|| 0.4602214132799162
cuda
Objective function 11.63 = squared loss an data 9.58 + 0.5*rho*h**2 0.336874 + alpha*h 0.929036 + L2reg 0.72 + L1reg 0.06 ; SHD = 17 ; DAG True
Proportion of microbatches that were clipped  0.8587906750849927
iteration 1 in inner loop, alpha 35.791806262000364 rho 1000.0 h 0.02595665649538681
1692
cuda
Objective function 14.66 = squared loss an data 9.58 + 0.5*rho*h**2 3.368740 + alpha*h 0.929036 + L2reg 0.72 + L1reg 0.06 ; SHD = 17 ; DAG True
||w||^2 1016482112.8919903
exp ma of ||w||^2 3113164866.461811
||w|| 31882.31661739765
exp ma of ||w|| 45282.44014906928
||w||^2 698946980.2325929
exp ma of ||w||^2 664421085.9004719
||w|| 26437.60541790033
exp ma of ||w|| 22763.220536130506
||w||^2 134362839.3573841
exp ma of ||w||^2 131428500.47253287
||w|| 11591.498581175088
exp ma of ||w|| 10431.326916987111
||w||^2 2543641.5837253598
exp ma of ||w||^2 11195744.05920412
||w|| 1594.8798022814633
exp ma of ||w|| 3029.603704787027
||w||^2 851.8868845059116
exp ma of ||w||^2 651.0404659652144
||w|| 29.187101337849764
exp ma of ||w|| 23.02329127993729
||w||^2 71.35904194850173
exp ma of ||w||^2 82.27080310545118
||w|| 8.447428126270252
exp ma of ||w|| 8.154996503652525
||w||^2 0.992790281768937
exp ma of ||w||^2 4.352651487766628
||w|| 0.9963886198511789
exp ma of ||w|| 1.9080863478236774
||w||^2 0.8588363779583906
exp ma of ||w||^2 0.8571058287692526
||w|| 0.9267342542273868
exp ma of ||w|| 0.8645882116861491
||w||^2 0.1609865344558206
exp ma of ||w||^2 0.31327669699048066
||w|| 0.4012312730281883
exp ma of ||w|| 0.5342941603013206
||w||^2 0.19762023062228712
exp ma of ||w||^2 0.17937575318184698
||w|| 0.4445449703036658
exp ma of ||w|| 0.40523152114228916
cuda
Objective function 11.56 = squared loss an data 9.87 + 0.5*rho*h**2 0.577801 + alpha*h 0.384758 + L2reg 0.67 + L1reg 0.05 ; SHD = 15 ; DAG True
Proportion of microbatches that were clipped  0.7149853085210578
iteration 2 in inner loop, alpha 35.791806262000364 rho 10000.0 h 0.010749888668774688
1692
cuda
Objective function 16.76 = squared loss an data 9.87 + 0.5*rho*h**2 5.778005 + alpha*h 0.384758 + L2reg 0.67 + L1reg 0.05 ; SHD = 15 ; DAG True
||w||^2 52874.8582294556
exp ma of ||w||^2 110561.94822935633
||w|| 229.94533748144494
exp ma of ||w|| 298.2112697167989
||w||^2 0.21279716753617697
exp ma of ||w||^2 0.23005274127802441
||w|| 0.4612994337045917
exp ma of ||w|| 0.4626932921022116
||w||^2 0.05588459868322211
exp ma of ||w||^2 0.16674071571876709
||w|| 0.23639923579238176
exp ma of ||w|| 0.39993619580946327
||w||^2 0.08887803420851519
exp ma of ||w||^2 0.1476676241281269
||w|| 0.2981241925918042
exp ma of ||w|| 0.37408235892377567
cuda
Objective function 11.19 = squared loss an data 9.82 + 0.5*rho*h**2 0.522430 + alpha*h 0.115695 + L2reg 0.67 + L1reg 0.06 ; SHD = 13 ; DAG True
Proportion of microbatches that were clipped  0.5054321583775954
iteration 3 in inner loop, alpha 35.791806262000364 rho 100000.0 h 0.003232430300350586
iteration 4 in outer loop, alpha = 359.034836297059, rho = 100000.0, h = 0.003232430300350586
cuda
1692
cuda
Objective function 12.23 = squared loss an data 9.82 + 0.5*rho*h**2 0.522430 + alpha*h 1.160555 + L2reg 0.67 + L1reg 0.06 ; SHD = 13 ; DAG True
||w||^2 6346406.64284315
exp ma of ||w||^2 1186405838.1521878
||w|| 2519.2075426298543
exp ma of ||w|| 6715.578672169106
||w||^2 487411.9456398267
exp ma of ||w||^2 18228945.840920538
||w|| 698.148942303737
exp ma of ||w|| 1176.2453769178321
||w||^2 3.8680299742072934
exp ma of ||w||^2 22.31996864943842
||w|| 1.9667307833578274
exp ma of ||w|| 3.6665443953705537
||w||^2 0.21854941593330057
exp ma of ||w||^2 0.5197265461942467
||w|| 0.4674926907806159
exp ma of ||w|| 0.6895631534341609
||w||^2 0.20351344164248275
exp ma of ||w||^2 0.19046855326078796
||w|| 0.45112464091698956
exp ma of ||w|| 0.429453518080127
||w||^2 0.2913371656822398
exp ma of ||w||^2 0.16873287013121951
||w|| 0.5397565800268115
exp ma of ||w|| 0.40086986082245835
||w||^2 0.1253633589246401
exp ma of ||w||^2 0.16051345061159117
||w|| 0.3540668848178831
exp ma of ||w|| 0.39254552760577605
||w||^2 0.09646874920872348
exp ma of ||w||^2 0.1625794018310101
||w|| 0.3105941873389189
exp ma of ||w|| 0.39651246406793667
||w||^2 0.38582502423187404
exp ma of ||w||^2 0.15884226646237593
||w|| 0.6211481499866791
exp ma of ||w|| 0.39188855988953314
v before min max tensor([[-2.396e+00, -1.202e+01,  6.560e+01,  ...,  2.485e+01, -1.124e+01,
          4.436e+00],
        [ 1.205e+02, -1.461e+01, -1.630e+01,  ..., -1.606e+01, -1.282e+01,
         -9.722e+00],
        [ 1.541e+02, -1.368e+01,  4.628e+01,  ..., -1.485e+01, -8.527e+00,
         -1.406e+01],
        ...,
        [-1.443e+01, -2.055e+01, -5.049e+00,  ..., -8.338e+00, -1.104e+01,
          5.492e+02],
        [-1.294e+01,  1.149e+01, -1.781e+01,  ..., -1.464e+01, -1.042e+01,
          3.008e+00],
        [-1.293e+01,  1.062e+01,  4.311e+01,  ...,  3.039e-01, -1.378e+01,
         -1.258e+01]], device='cuda:0')
v tensor([[1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         4.436e+00],
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e+01],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         3.008e+00],
        [1.000e-12, 1.000e+01, 1.000e+01,  ..., 3.039e-01, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([ -9.952, -11.027,  16.149,  34.083, -19.353,   2.478,  17.594,  15.020,
        -10.278,   0.645,   3.346,  -4.433,  13.043, -15.772,  -9.254, -11.519,
        -13.156, -11.212,  16.209,  37.096,  -5.658,  -3.642, -12.920, -13.152,
        -15.693,  16.399,  -5.690,  -5.718,  -9.417, -14.068,   7.514,  85.320,
        -10.546, -12.333, -14.816,  11.523,  11.402, -13.986, -17.943,  -9.935,
        -14.808,  -2.916, -15.472,  -0.366,  -1.825, -18.831,  -9.107,  11.800,
         -8.611, -18.371, -15.766,  24.889, -14.726,   9.437,  -7.136,  -3.464,
         67.443, -11.758,  -7.951,   7.177,  24.037,  -9.365, -17.167, -13.882,
         -8.316, -12.743,  -8.678,  -1.500,  -5.756,  63.525, -15.638,  -9.010,
         15.993,  -6.640, -15.348,   2.346, -11.656,  -7.690, -12.073,  -8.279,
        -11.209,  -7.793, -16.244,  18.734,  -9.696,  13.288,  37.914, -18.530,
         15.633,  -5.530, -11.553, -13.608, -12.428,  31.148,  15.877, -10.605,
        114.116, -13.549, -12.031,   3.613,  -2.000,  -0.243,  -8.873, 117.770,
         15.192, -12.354, -15.279,  -8.720,   4.640,  20.957,  -9.283, -13.459,
         10.938,  18.601, -11.103,  -5.974, -19.495,  -5.764,  85.769,   4.466],
       device='cuda:0')
v tensor([1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 2.478e+00,
        1.000e+01, 1.000e+01, 1.000e-12, 6.453e-01, 3.346e+00, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        7.514e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 9.437e+00,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 7.177e+00,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 2.346e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 3.613e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        4.640e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 4.466e+00],
       device='cuda:0')
v before min max tensor([[[ 2.728e+01],
         [-1.635e+01],
         [-1.068e+01],
         [-9.941e+00],
         [ 3.661e+01],
         [-1.670e+01],
         [-1.254e+01],
         [ 2.134e+00],
         [ 9.678e+01],
         [-1.474e+01]],

        [[-6.187e+00],
         [ 3.708e+00],
         [-4.607e+00],
         [-1.482e+01],
         [-5.474e-01],
         [ 2.451e+01],
         [-1.212e+01],
         [ 1.743e+01],
         [ 3.395e+00],
         [-1.178e+01]],

        [[-1.700e+01],
         [ 6.733e+00],
         [-4.204e+00],
         [-1.347e+01],
         [-1.270e+01],
         [ 4.777e+01],
         [ 3.374e+00],
         [ 2.007e+01],
         [-1.458e+01],
         [-1.640e+01]],

        [[-1.133e+01],
         [-8.216e+00],
         [-1.202e+01],
         [-5.933e+00],
         [-1.246e+01],
         [ 3.716e+00],
         [ 1.610e+01],
         [ 1.581e+01],
         [-6.671e+00],
         [-9.735e+00]],

        [[ 4.448e+01],
         [ 1.062e+02],
         [-9.430e+00],
         [-7.799e+00],
         [-9.428e-01],
         [ 1.059e+01],
         [-1.332e+01],
         [-4.572e+00],
         [ 7.771e+01],
         [-4.040e+00]],

        [[ 6.623e+01],
         [-2.057e+00],
         [-1.310e+01],
         [-1.236e+01],
         [-8.512e+00],
         [-1.902e+01],
         [-1.502e+01],
         [-1.270e+01],
         [-3.320e+00],
         [-1.069e+01]],

        [[-1.522e+01],
         [-1.458e+01],
         [-1.371e+01],
         [-7.658e+00],
         [-8.202e+00],
         [ 4.202e+01],
         [-1.449e+01],
         [-9.971e+00],
         [ 1.046e-01],
         [ 6.950e+01]],

        [[-1.787e+00],
         [-1.704e+01],
         [ 4.588e+01],
         [-1.041e+01],
         [-2.139e+00],
         [ 4.980e+01],
         [ 2.839e+01],
         [-1.206e+01],
         [-1.458e+01],
         [ 6.134e+00]],

        [[ 4.950e+00],
         [-1.355e+01],
         [-9.838e+00],
         [-9.645e+00],
         [-5.493e+00],
         [-6.164e+00],
         [-6.706e+00],
         [-1.550e+01],
         [ 1.304e+01],
         [ 3.536e+00]],

        [[-5.692e+00],
         [ 9.416e+01],
         [-1.051e+01],
         [-9.343e+00],
         [-1.429e+01],
         [-1.318e+01],
         [-1.771e+01],
         [-1.748e+01],
         [-3.562e+00],
         [ 3.397e+01]],

        [[-1.495e+01],
         [-8.441e+00],
         [-1.338e+01],
         [-1.763e+01],
         [-1.122e+01],
         [-1.498e+01],
         [ 1.031e+01],
         [-9.534e+00],
         [-1.403e+01],
         [-1.600e+01]],

        [[ 2.524e+00],
         [-1.255e+01],
         [-1.463e+01],
         [-5.253e+00],
         [-1.192e+01],
         [-4.323e+00],
         [ 7.787e+01],
         [-1.171e+01],
         [ 2.688e+01],
         [-1.757e+01]]], device='cuda:0')
v tensor([[[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [2.134e+00],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [3.708e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [3.395e+00],
         [1.000e-12]],

        [[1.000e-12],
         [6.733e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [3.374e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.716e+00],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.046e-01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [6.134e+00]],

        [[4.950e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [3.536e+00]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[2.524e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[ 12.537],
        [ -2.741],
        [-15.548],
        [  1.317],
        [124.953],
        [ 69.608],
        [-13.830],
        [ -9.350],
        [ -4.629],
        [ 75.579],
        [ 26.946],
        [-15.860]], device='cuda:0')
v tensor([[1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.317e+00],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-0.015,  0.014, -0.008,  ..., -0.011,  0.003,  0.026],
        [-0.008, -0.005,  0.008,  ..., -0.005,  0.011, -0.021],
        [ 0.018, -0.024,  0.002,  ...,  0.018,  0.004, -0.021],
        ...,
        [-0.004, -0.024,  0.009,  ..., -0.008,  0.034,  0.003],
        [ 0.005, -0.002,  0.006,  ...,  0.010,  0.034, -0.001],
        [-0.004, -0.032,  0.002,  ..., -0.008, -0.009,  0.006]],
       device='cuda:0')
s after update for 1 param tensor([[2.321, 1.232, 2.188,  ..., 1.476, 1.088, 1.067],
        [2.672, 1.432, 1.614,  ..., 1.743, 1.862, 1.934],
        [2.575, 1.356, 2.313,  ..., 1.511, 1.205, 1.407],
        ...,
        [1.391, 1.977, 1.338,  ..., 1.184, 1.178, 2.616],
        [1.665, 1.569, 1.739,  ..., 1.426, 1.053, 2.368],
        [1.314, 2.074, 1.795,  ..., 1.403, 1.390, 2.056]], device='cuda:0')
b after update for 1 param tensor([[83.064, 60.507, 80.656,  ..., 66.247, 56.863, 56.332],
        [89.117, 65.237, 69.267,  ..., 71.983, 74.392, 75.831],
        [87.494, 63.481, 82.917,  ..., 67.030, 59.860, 64.671],
        ...,
        [64.313, 76.659, 63.069,  ..., 59.324, 59.188, 88.185],
        [70.362, 68.297, 71.909,  ..., 65.116, 55.946, 83.908],
        [62.497, 78.525, 73.052,  ..., 64.587, 64.286, 78.183]],
       device='cuda:0')
a after update for 1 param tensor([-1.501e-02,  4.435e-02,  1.478e-03,  6.388e-03, -7.626e-02,  6.068e-03,
         8.583e-03,  2.406e-02,  1.163e-02,  1.580e-02,  1.617e-02,  8.905e-03,
         2.190e-02,  4.242e-02, -5.211e-03,  3.838e-02,  6.633e-03, -7.526e-03,
         8.946e-02, -2.245e-02, -3.145e-02, -3.380e-02, -6.191e-03,  1.928e-02,
         5.281e-03,  2.735e-02,  2.035e-02, -1.116e-02, -4.633e-02,  3.263e-02,
        -2.125e-02,  5.856e-02, -4.444e-03, -5.012e-03,  4.143e-02, -1.191e-04,
         1.920e-02, -9.636e-03,  1.055e-03, -1.915e-02,  1.785e-02, -2.553e-02,
        -3.416e-02, -2.210e-02, -1.010e-02,  7.503e-03,  1.114e-04, -6.310e-03,
        -3.348e-02,  1.684e-02,  2.544e-02,  3.239e-02, -1.266e-02, -6.084e-03,
         2.510e-03,  3.490e-02,  9.473e-03, -2.615e-02, -2.276e-02, -9.293e-04,
        -2.849e-02,  1.746e-02, -3.617e-02, -2.121e-02, -6.361e-03,  4.920e-02,
         2.580e-02,  1.178e-03, -2.302e-02,  1.077e-03, -1.174e-02, -3.930e-02,
         2.817e-02, -2.920e-04,  1.852e-02,  6.164e-03, -2.668e-02,  9.880e-03,
         6.927e-03, -9.575e-03, -1.163e-02, -1.009e-02, -8.069e-03, -1.184e-02,
         2.360e-02, -5.526e-02, -2.610e-03, -1.664e-02, -1.205e-02, -2.591e-02,
        -3.912e-02, -2.109e-02,  1.457e-02,  1.125e-02,  3.146e-02,  1.681e-02,
         1.496e-02, -4.204e-02,  4.043e-02,  3.075e-02, -6.921e-03,  1.858e-02,
         2.236e-02, -6.230e-02,  1.249e-03,  3.818e-03, -7.696e-03,  4.443e-02,
         1.531e-02, -4.606e-02,  9.326e-03, -2.761e-03, -3.368e-03,  2.603e-02,
         6.982e-05, -1.360e-02,  3.481e-02, -1.273e-03,  3.282e-02, -6.389e-03],
       device='cuda:0')
s after update for 1 param tensor([1.423, 1.200, 1.450, 1.721, 1.898, 1.176, 1.387, 1.886, 1.343, 1.440,
        0.739, 1.533, 2.030, 1.728, 0.934, 1.301, 1.338, 1.226, 1.997, 1.711,
        1.028, 1.297, 1.903, 1.503, 1.733, 1.582, 1.452, 1.451, 0.906, 1.492,
        1.723, 2.119, 1.177, 1.424, 1.501, 1.897, 1.648, 1.938, 1.772, 1.067,
        1.673, 1.555, 1.654, 1.867, 0.979, 2.029, 1.293, 1.806, 1.380, 1.767,
        1.621, 1.896, 1.470, 1.898, 0.688, 1.459, 1.837, 1.178, 1.512, 1.779,
        1.824, 1.300, 1.661, 2.082, 1.143, 1.251, 1.199, 0.786, 1.620, 1.714,
        1.499, 1.905, 2.084, 0.643, 1.502, 1.005, 1.122, 1.463, 1.182, 1.154,
        1.171, 1.132, 1.673, 1.782, 1.449, 1.703, 1.774, 1.812, 1.552, 1.477,
        1.142, 1.455, 1.744, 1.438, 1.821, 1.263, 1.756, 1.450, 1.534, 1.214,
        1.281, 1.624, 1.083, 1.841, 1.563, 1.214, 1.758, 1.538, 0.940, 1.547,
        1.033, 1.290, 1.934, 1.687, 1.366, 1.315, 1.925, 1.107, 2.134, 2.002],
       device='cuda:0')
b after update for 1 param tensor([65.033, 59.718, 65.663, 71.524, 75.118, 59.136, 64.222, 74.874, 63.183,
        65.431, 46.883, 67.499, 77.691, 71.668, 52.703, 62.197, 63.075, 60.380,
        77.041, 71.311, 55.292, 62.085, 75.214, 66.849, 71.785, 68.581, 65.708,
        65.669, 51.887, 66.590, 71.561, 79.370, 59.162, 65.061, 66.804, 75.092,
        70.000, 75.902, 72.583, 56.310, 70.518, 67.995, 70.126, 74.495, 53.945,
        77.670, 62.006, 73.272, 64.054, 72.477, 69.415, 75.079, 66.115, 75.117,
        45.213, 65.855, 73.893, 59.185, 67.052, 72.721, 73.638, 62.167, 70.263,
        78.675, 58.301, 60.985, 59.694, 48.348, 69.400, 71.387, 66.746, 75.248,
        78.701, 43.722, 66.816, 54.646, 57.745, 65.957, 59.265, 58.577, 59.010,
        58.008, 70.528, 72.779, 65.638, 71.143, 72.616, 73.403, 67.929, 66.257,
        58.253, 65.776, 71.999, 65.373, 73.579, 61.267, 72.248, 65.659, 67.523,
        60.082, 61.718, 69.484, 56.747, 73.979, 68.161, 60.083, 72.285, 67.617,
        52.866, 67.817, 55.402, 61.922, 75.829, 70.813, 63.727, 62.531, 75.648,
        57.360, 79.641, 77.142], device='cuda:0')
a after update for 1 param tensor([[[ 0.027],
         [ 0.001],
         [-0.011],
         [ 0.012],
         [ 0.036],
         [ 0.040],
         [-0.025],
         [-0.029],
         [-0.007],
         [ 0.028]],

        [[ 0.015],
         [-0.028],
         [ 0.064],
         [-0.020],
         [-0.019],
         [-0.020],
         [-0.055],
         [-0.016],
         [ 0.007],
         [-0.004]],

        [[-0.003],
         [ 0.008],
         [ 0.023],
         [ 0.005],
         [-0.011],
         [ 0.010],
         [ 0.023],
         [-0.001],
         [-0.006],
         [-0.036]],

        [[ 0.012],
         [-0.003],
         [-0.029],
         [-0.027],
         [-0.010],
         [ 0.017],
         [ 0.013],
         [ 0.029],
         [-0.024],
         [-0.009]],

        [[-0.005],
         [-0.068],
         [ 0.002],
         [ 0.001],
         [ 0.011],
         [-0.020],
         [ 0.002],
         [-0.003],
         [ 0.012],
         [-0.024]],

        [[ 0.014],
         [-0.012],
         [-0.008],
         [ 0.025],
         [ 0.010],
         [-0.023],
         [-0.026],
         [-0.002],
         [ 0.020],
         [-0.033]],

        [[-0.008],
         [ 0.044],
         [ 0.018],
         [-0.004],
         [-0.015],
         [ 0.024],
         [ 0.026],
         [ 0.032],
         [ 0.005],
         [ 0.019]],

        [[ 0.006],
         [ 0.033],
         [ 0.022],
         [-0.035],
         [-0.032],
         [ 0.002],
         [ 0.080],
         [-0.014],
         [-0.034],
         [ 0.006]],

        [[ 0.000],
         [-0.007],
         [-0.019],
         [ 0.020],
         [ 0.035],
         [-0.038],
         [ 0.010],
         [ 0.058],
         [ 0.035],
         [-0.000]],

        [[-0.027],
         [ 0.022],
         [-0.023],
         [ 0.033],
         [-0.015],
         [ 0.014],
         [-0.006],
         [-0.047],
         [ 0.036],
         [ 0.037]],

        [[ 0.035],
         [ 0.007],
         [ 0.034],
         [-0.021],
         [-0.024],
         [ 0.022],
         [ 0.012],
         [-0.033],
         [ 0.014],
         [ 0.042]],

        [[-0.044],
         [-0.006],
         [ 0.011],
         [ 0.024],
         [-0.021],
         [-0.020],
         [-0.009],
         [ 0.053],
         [ 0.013],
         [ 0.002]]], device='cuda:0')
s after update for 1 param tensor([[[1.954],
         [1.664],
         [1.340],
         [1.642],
         [1.314],
         [1.733],
         [1.524],
         [1.446],
         [2.309],
         [1.461]],

        [[0.786],
         [1.461],
         [1.269],
         [1.687],
         [1.749],
         [1.610],
         [1.469],
         [1.935],
         [2.073],
         [1.294]],

        [[1.632],
         [1.896],
         [1.130],
         [1.904],
         [1.559],
         [1.593],
         [1.515],
         [1.595],
         [1.774],
         [1.755]],

        [[1.231],
         [1.556],
         [1.542],
         [0.637],
         [1.455],
         [1.506],
         [1.976],
         [1.889],
         [0.769],
         [1.674]],

        [[2.029],
         [1.749],
         [1.632],
         [1.017],
         [1.749],
         [1.357],
         [1.689],
         [1.370],
         [1.496],
         [1.422]],

        [[2.003],
         [1.408],
         [1.489],
         [1.185],
         [1.244],
         [1.824],
         [1.479],
         [1.218],
         [0.827],
         [1.205]],

        [[1.587],
         [1.811],
         [1.314],
         [0.740],
         [0.930],
         [2.141],
         [1.673],
         [1.590],
         [1.985],
         [2.090]],

        [[1.267],
         [1.692],
         [1.445],
         [1.071],
         [1.713],
         [1.732],
         [1.854],
         [1.165],
         [1.427],
         [1.604]],

        [[1.813],
         [1.447],
         [1.142],
         [0.930],
         [0.982],
         [1.123],
         [0.673],
         [1.489],
         [1.763],
         [1.392]],

        [[0.546],
         [1.635],
         [1.782],
         [1.213],
         [1.491],
         [1.533],
         [1.927],
         [1.713],
         [1.723],
         [1.797]],

        [[1.547],
         [1.894],
         [1.302],
         [1.700],
         [1.526],
         [1.615],
         [1.588],
         [1.340],
         [1.358],
         [1.544]],

        [[1.661],
         [1.420],
         [1.824],
         [1.869],
         [1.373],
         [1.130],
         [2.116],
         [1.137],
         [1.722],
         [1.706]]], device='cuda:0')
b after update for 1 param tensor([[[76.220],
         [70.322],
         [63.104],
         [69.869],
         [62.487],
         [71.775],
         [67.300],
         [65.560],
         [82.857],
         [65.897]],

        [[48.329],
         [65.907],
         [61.418],
         [70.816],
         [72.112],
         [69.180],
         [66.088],
         [75.850],
         [78.507],
         [62.027]],

        [[69.658],
         [75.074],
         [57.961],
         [75.227],
         [68.076],
         [68.815],
         [67.101],
         [68.855],
         [72.619],
         [72.228]],

        [[60.489],
         [68.001],
         [67.712],
         [43.505],
         [65.775],
         [66.918],
         [76.644],
         [74.940],
         [47.821],
         [70.542]],

        [[77.657],
         [72.110],
         [69.642],
         [54.984],
         [72.100],
         [63.523],
         [70.852],
         [63.809],
         [66.684],
         [65.016]],

        [[77.156],
         [64.686],
         [66.540],
         [59.349],
         [60.816],
         [73.629],
         [66.305],
         [60.185],
         [49.573],
         [59.847]],

        [[68.677],
         [73.379],
         [62.497],
         [46.896],
         [52.580],
         [79.783],
         [70.531],
         [68.752],
         [76.816],
         [78.814]],

        [[61.365],
         [70.921],
         [65.549],
         [56.425],
         [71.352],
         [71.760],
         [74.240],
         [58.860],
         [65.129],
         [69.052]],

        [[73.420],
         [65.590],
         [58.257],
         [52.575],
         [54.039],
         [57.772],
         [44.734],
         [66.538],
         [72.386],
         [64.336]],

        [[40.283],
         [69.708],
         [72.789],
         [60.060],
         [66.575],
         [67.516],
         [75.677],
         [71.360],
         [71.561],
         [73.082]],

        [[67.806],
         [75.028],
         [62.213],
         [71.096],
         [67.350],
         [69.295],
         [68.703],
         [63.117],
         [63.533],
         [67.746]],

        [[70.272],
         [64.966],
         [73.635],
         [74.545],
         [63.878],
         [57.954],
         [79.310],
         [58.131],
         [71.551],
         [71.221]]], device='cuda:0')
a after update for 1 param tensor([[ 0.011],
        [ 0.012],
        [-0.002],
        [ 0.003],
        [-0.003],
        [ 0.009],
        [-0.007],
        [-0.029],
        [ 0.039],
        [-0.005],
        [ 0.026],
        [ 0.000]], device='cuda:0')
s after update for 1 param tensor([[1.808],
        [1.148],
        [1.595],
        [1.694],
        [1.386],
        [1.700],
        [1.652],
        [1.360],
        [1.530],
        [1.801],
        [2.010],
        [1.547]], device='cuda:0')
b after update for 1 param tensor([[73.310],
        [58.428],
        [68.865],
        [70.969],
        [64.180],
        [71.082],
        [70.069],
        [63.595],
        [67.435],
        [73.171],
        [77.302],
        [67.813]], device='cuda:0')
cuda
Objective function 11.53 = squared loss an data 9.88 + 0.5*rho*h**2 0.218296 + alpha*h 0.750196 + L2reg 0.62 + L1reg 0.05 ; SHD = 13 ; DAG True
Proportion of microbatches that were clipped  0.4056661375015264
iteration 1 in inner loop, alpha 359.034836297059 rho 100000.0 h 0.0020894806700795243
iteration 5 in outer loop, alpha = 2448.5155063765833, rho = 1000000.0, h = 0.0020894806700795243
Threshold 0.3
[[0.004 0.008 0.342 0.044 0.016 0.095 0.135 0.03  0.008 0.116 0.098 0.03 ]
 [0.562 0.005 0.223 0.177 0.273 0.049 0.207 0.046 0.005 0.227 0.197 0.569]
 [0.011 0.018 0.005 0.071 0.012 0.01  0.081 0.012 0.007 0.323 0.026 0.032]
 [0.105 0.022 0.071 0.006 0.098 0.069 0.226 0.073 0.005 0.502 0.009 0.097]
 [0.354 0.02  0.385 0.054 0.005 0.029 0.28  0.095 0.01  0.358 0.033 0.09 ]
 [0.069 0.076 0.302 0.066 0.156 0.006 0.205 0.06  0.037 0.145 0.13  0.086]
 [0.04  0.026 0.06  0.03  0.021 0.025 0.004 0.033 0.011 0.079 0.028 0.03 ]
 [0.227 0.104 0.408 0.084 0.068 0.122 0.196 0.004 0.015 0.169 0.039 0.213]
 [0.33  1.268 0.253 0.816 0.373 0.14  0.336 0.247 0.004 0.599 1.765 0.54 ]
 [0.05  0.014 0.02  0.009 0.014 0.026 0.098 0.024 0.007 0.006 0.017 0.074]
 [0.067 0.025 0.161 0.474 0.115 0.034 0.16  0.127 0.002 0.18  0.004 0.48 ]
 [0.09  0.007 0.173 0.075 0.035 0.055 0.284 0.032 0.005 0.063 0.013 0.003]]
[[0.    0.    0.342 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.562 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.569]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.323 0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.502 0.    0.   ]
 [0.354 0.    0.385 0.    0.    0.    0.    0.    0.    0.358 0.    0.   ]
 [0.    0.    0.302 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.408 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.33  1.268 0.    0.816 0.373 0.    0.336 0.    0.    0.599 1.765 0.54 ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.474 0.    0.    0.    0.    0.    0.    0.    0.48 ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]]
{'fdr': 0.3, 'tpr': 0.5833333333333334, 'fpr': 0.14285714285714285, 'f1': 0.6363636363636365, 'shd': 13, 'npred': 20, 'ntrue': 24}
[0.008 0.342 0.044 0.016 0.095 0.135 0.03  0.008 0.116 0.098 0.03  0.562
 0.223 0.177 0.273 0.049 0.207 0.046 0.005 0.227 0.197 0.569 0.011 0.018
 0.071 0.012 0.01  0.081 0.012 0.007 0.323 0.026 0.032 0.105 0.022 0.071
 0.098 0.069 0.226 0.073 0.005 0.502 0.009 0.097 0.354 0.02  0.385 0.054
 0.029 0.28  0.095 0.01  0.358 0.033 0.09  0.069 0.076 0.302 0.066 0.156
 0.205 0.06  0.037 0.145 0.13  0.086 0.04  0.026 0.06  0.03  0.021 0.025
 0.033 0.011 0.079 0.028 0.03  0.227 0.104 0.408 0.084 0.068 0.122 0.196
 0.015 0.169 0.039 0.213 0.33  1.268 0.253 0.816 0.373 0.14  0.336 0.247
 0.599 1.765 0.54  0.05  0.014 0.02  0.009 0.014 0.026 0.098 0.024 0.007
 0.017 0.074 0.067 0.025 0.161 0.474 0.115 0.034 0.16  0.127 0.002 0.18
 0.48  0.09  0.007 0.173 0.075 0.035 0.055 0.284 0.032 0.005 0.063 0.013]
[[0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0.
 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.8614969135802467, 0.7377243260605011)
Iterations 1110
Achieves (23.82233853610087, 1e-05)-DP
