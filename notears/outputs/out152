samples  5000  graph  30 120 ER mlp  minibatch size  50  noise  1.0  minibatches per NN training  250 quantile adaptive clipping
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 2.416300551076283
iteration 1 in outer loop, alpha = 2.416300551076283, rho = 1.0, h = 2.416300551076283
cuda
iteration 1 in inner loop,alpha 2.416300551076283 rho 1.0 h 1.528882620576404
iteration 2 in inner loop,alpha 2.416300551076283 rho 10.0 h 0.6614471465036686
iteration 3 in inner loop,alpha 2.416300551076283 rho 100.0 h 0.2147624765341014
iteration 2 in outer loop, alpha = 23.892548204486424, rho = 100.0, h = 0.2147624765341014
cuda
iteration 1 in inner loop,alpha 23.892548204486424 rho 100.0 h 0.1210624984339681
iteration 2 in inner loop,alpha 23.892548204486424 rho 1000.0 h 0.042835028814131704
iteration 3 in outer loop, alpha = 66.72757701861812, rho = 1000.0, h = 0.042835028814131704
cuda
iteration 1 in inner loop,alpha 66.72757701861812 rho 1000.0 h 0.021715285526958894
iteration 2 in inner loop,alpha 66.72757701861812 rho 10000.0 h 0.007707708854400863
iteration 4 in outer loop, alpha = 143.80466556262675, rho = 10000.0, h = 0.007707708854400863
cuda
iteration 1 in inner loop,alpha 143.80466556262675 rho 10000.0 h 0.003447501302900946
iteration 2 in inner loop,alpha 143.80466556262675 rho 100000.0 h 0.0011366236494936288
iteration 5 in outer loop, alpha = 257.4670305119896, rho = 100000.0, h = 0.0011366236494936288
cuda
iteration 1 in inner loop,alpha 257.4670305119896 rho 100000.0 h 0.0005399015625471293
iteration 6 in outer loop, alpha = 797.3685930591189, rho = 1000000.0, h = 0.0005399015625471293
Threshold 0.3
[[0.002 0.    0.001 1.905 0.005 0.086 0.221 0.    0.    0.    0.    0.007
  0.    0.    0.    0.908 0.    0.    0.768 0.152 0.    0.    0.225 0.
  0.    0.    0.068 0.    0.253 0.   ]
 [0.426 0.003 0.078 0.115 0.243 1.638 0.226 0.    1.015 0.    0.    0.13
  0.    0.    0.    0.855 0.    1.208 0.29  0.605 0.    0.001 1.129 0.001
  0.    0.    0.163 0.    0.235 0.149]
 [0.171 0.009 0.001 0.45  0.175 0.371 0.166 0.005 0.118 0.    0.    0.165
  0.    0.    0.    0.779 0.    0.334 0.099 0.101 0.    0.    0.2   0.
  0.    0.002 0.197 0.    0.247 0.182]
 [0.    0.    0.    0.003 0.001 0.002 0.115 0.    0.    0.    0.    0.
  0.    0.    0.    0.884 0.    0.    0.208 0.61  0.    0.    0.142 0.
  0.    0.    0.    0.    0.242 0.   ]
 [0.069 0.002 0.002 0.205 0.003 0.003 0.317 0.    0.108 0.    0.    0.007
  0.    0.    0.    0.156 0.    0.001 0.718 0.187 0.    0.    1.501 0.
  0.    0.    0.001 0.    0.215 0.001]
 [0.003 0.    0.    0.181 0.184 0.002 1.563 0.    0.005 0.    0.    0.
  0.    0.    0.    0.23  0.    0.    0.146 0.145 0.    0.    0.337 0.
  0.    0.    0.    0.    0.802 0.   ]
 [0.    0.    0.    0.001 0.    0.    0.003 0.    0.001 0.    0.    0.
  0.    0.    0.    1.039 0.    0.    0.016 0.001 0.    0.    0.    0.
  0.    0.    0.    0.    0.186 0.   ]
 [0.438 0.811 0.104 0.15  2.225 0.114 0.264 0.002 1.393 0.    0.    0.16
  0.    0.    0.    0.588 0.    0.298 0.2   0.709 0.    0.001 0.325 0.001
  0.    0.005 0.079 0.    0.427 0.257]
 [1.226 0.    0.001 0.244 0.007 0.065 0.096 0.    0.002 0.    0.    0.147
  0.    0.    0.    0.077 0.    0.    0.258 0.824 0.    0.    0.129 0.
  0.    0.    0.048 0.    0.164 0.   ]
 [0.293 0.772 0.228 0.236 0.182 0.327 0.268 0.311 1.044 0.001 0.    0.229
  2.239 0.137 0.008 0.314 0.001 0.371 0.27  0.104 0.002 0.482 0.464 0.086
  0.    0.131 0.218 0.001 0.341 1.872]
 [1.694 1.775 0.25  0.162 0.158 0.374 0.209 1.956 0.276 1.28  0.002 0.066
  0.14  0.291 0.004 1.09  0.    0.288 0.136 0.245 0.021 0.088 0.212 0.022
  0.    0.191 0.135 0.016 1.066 0.402]
 [0.115 0.001 0.001 0.133 0.072 0.114 0.938 0.001 0.015 0.    0.    0.001
  0.    0.    0.    0.336 0.    0.    0.233 0.1   0.    0.    0.155 0.
  0.    0.    0.907 0.    0.161 0.   ]
 [0.147 1.781 0.137 0.185 2.383 0.297 0.215 1.374 0.852 0.    0.    1.839
  0.001 0.    0.    0.247 0.    0.19  0.59  0.108 0.    2.587 0.488 0.003
  0.    0.023 1.08  0.001 0.371 0.261]
 [0.212 0.204 2.903 1.146 0.126 1.74  0.386 0.156 0.353 0.002 0.002 0.507
  0.304 0.001 0.    0.488 0.    1.771 0.429 0.234 0.    0.088 0.278 2.625
  0.    0.52  0.366 0.006 0.206 2.356]
 [0.186 0.947 0.046 0.249 0.197 0.323 0.348 0.279 0.266 0.025 0.018 0.637
  2.52  0.082 0.002 0.277 0.    0.178 0.172 0.183 0.378 0.629 0.98  3.59
  0.007 0.095 0.446 0.003 0.474 0.276]
 [0.    0.    0.    0.    0.001 0.    0.001 0.    0.    0.    0.    0.
  0.    0.    0.    0.005 0.    0.    0.006 0.001 0.    0.    0.    0.
  0.    0.    0.    0.    0.161 0.   ]
 [0.206 0.248 0.162 0.062 0.367 1.17  0.544 0.344 0.569 0.131 0.077 0.133
  1.081 0.094 3.045 0.489 0.001 0.016 0.234 0.037 0.742 1.372 0.228 0.336
  0.001 0.051 0.146 0.004 0.274 0.117]
 [0.119 0.    0.001 0.244 0.164 0.249 0.206 0.    1.129 0.    0.    0.204
  0.    0.    0.    0.227 0.    0.001 0.726 0.308 0.    0.    0.388 0.
  0.    0.    0.641 0.    0.172 0.001]
 [0.001 0.    0.001 0.001 0.    0.001 0.097 0.    0.    0.    0.    0.
  0.    0.    0.    0.164 0.    0.    0.011 0.    0.    0.    0.009 0.
  0.    0.    0.001 0.    0.014 0.   ]
 [0.    0.001 0.001 0.004 0.001 0.002 0.193 0.001 0.    0.    0.    0.001
  0.    0.    0.    0.31  0.    0.    0.797 0.003 0.    0.    0.181 0.
  0.    0.    0.    0.    0.462 0.   ]
 [0.182 0.525 0.212 0.404 1.849 1.069 0.334 1.108 0.179 0.082 0.025 0.218
  0.236 3.751 0.001 0.187 0.001 0.235 0.261 0.074 0.001 1.73  0.708 0.072
  0.002 2.426 0.225 0.001 0.252 0.102]
 [0.085 0.242 2.609 1.078 1.636 0.226 0.659 0.403 0.475 0.    0.    0.334
  0.    0.    0.    0.254 0.    2.25  0.387 0.273 0.    0.001 0.429 0.
  0.    0.002 0.281 0.    0.597 2.181]
 [0.001 0.001 0.    0.002 0.    0.    1.049 0.    0.002 0.    0.    0.
  0.    0.    0.    0.23  0.    0.    0.534 0.004 0.    0.    0.005 0.
  0.    0.    0.001 0.    0.118 0.   ]
 [2.063 0.271 0.097 0.163 0.149 0.182 1.034 0.174 0.534 0.002 0.    2.168
  0.274 0.    0.    0.823 0.    0.086 0.811 0.939 0.    0.258 0.552 0.002
  0.    0.01  1.531 0.    0.141 0.12 ]
 [0.252 0.388 0.8   0.139 0.17  0.569 0.594 0.276 0.105 1.16  4.366 0.155
  0.19  2.178 0.042 0.147 0.011 0.457 0.173 0.093 0.028 0.129 0.943 0.098
  0.001 2.877 0.107 0.002 0.238 0.862]
 [0.224 1.729 0.121 0.077 0.163 0.2   0.159 0.11  0.189 0.004 0.005 0.108
  0.024 0.    0.    0.092 0.    0.11  0.353 0.19  0.    0.14  1.322 0.042
  0.    0.002 0.065 0.    0.09  0.13 ]
 [0.009 0.    0.001 1.535 0.179 1.75  0.321 0.    0.004 0.    0.    0.
  0.    0.    0.    0.799 0.    0.    0.962 0.195 0.    0.    1.4   0.
  0.    0.    0.003 0.    0.796 0.   ]
 [2.101 0.348 0.189 0.259 0.116 0.223 0.129 0.092 0.248 0.013 0.005 0.993
  0.006 0.016 0.022 0.191 0.02  0.133 0.201 0.081 0.001 0.057 0.925 0.032
  0.003 3.032 0.119 0.    0.147 0.113]
 [0.001 0.    0.001 0.007 0.002 0.001 0.008 0.001 0.001 0.    0.    0.001
  0.    0.    0.    0.045 0.    0.    0.098 0.009 0.    0.    0.003 0.
  0.    0.001 0.001 0.    0.01  0.   ]
 [0.255 0.004 0.005 0.399 0.182 0.174 0.419 0.002 0.531 0.    0.    1.981
  0.    0.    0.    0.201 0.    0.304 0.68  0.22  0.    0.    0.156 0.
  0.    0.001 0.671 0.    0.105 0.002]]
[[0.    0.    0.    1.905 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.908 0.    0.    0.768 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.426 0.    0.    0.    0.    1.638 0.    0.    1.015 0.    0.    0.
  0.    0.    0.    0.855 0.    1.208 0.    0.605 0.    0.    1.129 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.45  0.    0.371 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.779 0.    0.334 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.884 0.    0.    0.    0.61  0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.317 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.718 0.    0.    0.    1.501 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    1.563 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.337 0.
  0.    0.    0.    0.    0.802 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    1.039 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.438 0.811 0.    0.    2.225 0.    0.    0.    1.393 0.    0.    0.
  0.    0.    0.    0.588 0.    0.    0.    0.709 0.    0.    0.325 0.
  0.    0.    0.    0.    0.427 0.   ]
 [1.226 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.824 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.772 0.    0.    0.    0.327 0.    0.311 1.044 0.    0.    0.
  2.239 0.    0.    0.314 0.    0.371 0.    0.    0.    0.482 0.464 0.
  0.    0.    0.    0.    0.341 1.872]
 [1.694 1.775 0.    0.    0.    0.374 0.    1.956 0.    1.28  0.    0.
  0.    0.    0.    1.09  0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    1.066 0.402]
 [0.    0.    0.    0.    0.    0.    0.938 0.    0.    0.    0.    0.
  0.    0.    0.    0.336 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.907 0.    0.    0.   ]
 [0.    1.781 0.    0.    2.383 0.    0.    1.374 0.852 0.    0.    1.839
  0.    0.    0.    0.    0.    0.    0.59  0.    0.    2.587 0.488 0.
  0.    0.    1.08  0.    0.371 0.   ]
 [0.    0.    2.903 1.146 0.    1.74  0.386 0.    0.353 0.    0.    0.507
  0.304 0.    0.    0.488 0.    1.771 0.429 0.    0.    0.    0.    2.625
  0.    0.52  0.366 0.    0.    2.356]
 [0.    0.947 0.    0.    0.    0.323 0.348 0.    0.    0.    0.    0.637
  2.52  0.    0.    0.    0.    0.    0.    0.    0.378 0.629 0.98  3.59
  0.    0.    0.446 0.    0.474 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.367 1.17  0.544 0.344 0.569 0.    0.    0.
  1.081 0.    3.045 0.489 0.    0.    0.    0.    0.742 1.372 0.    0.336
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    1.129 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.726 0.308 0.    0.    0.388 0.
  0.    0.    0.641 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.31  0.    0.    0.797 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.462 0.   ]
 [0.    0.525 0.    0.404 1.849 1.069 0.334 1.108 0.    0.    0.    0.
  0.    3.751 0.    0.    0.    0.    0.    0.    0.    1.73  0.708 0.
  0.    2.426 0.    0.    0.    0.   ]
 [0.    0.    2.609 1.078 1.636 0.    0.659 0.403 0.475 0.    0.    0.334
  0.    0.    0.    0.    0.    2.25  0.387 0.    0.    0.    0.429 0.
  0.    0.    0.    0.    0.597 2.181]
 [0.    0.    0.    0.    0.    0.    1.049 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.534 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [2.063 0.    0.    0.    0.    0.    1.034 0.    0.534 0.    0.    2.168
  0.    0.    0.    0.823 0.    0.    0.811 0.939 0.    0.    0.552 0.
  0.    0.    1.531 0.    0.    0.   ]
 [0.    0.388 0.8   0.    0.    0.569 0.594 0.    0.    1.16  4.366 0.
  0.    2.178 0.    0.    0.    0.457 0.    0.    0.    0.    0.943 0.
  0.    2.877 0.    0.    0.    0.862]
 [0.    1.729 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.353 0.    0.    0.    1.322 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    1.535 0.    1.75  0.321 0.    0.    0.    0.    0.
  0.    0.    0.    0.799 0.    0.    0.962 0.    0.    0.    1.4   0.
  0.    0.    0.    0.    0.796 0.   ]
 [2.101 0.348 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.993
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.925 0.
  0.    3.032 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.399 0.    0.    0.419 0.    0.531 0.    0.    1.981
  0.    0.    0.    0.    0.    0.304 0.68  0.    0.    0.    0.    0.
  0.    0.    0.671 0.    0.    0.   ]]
{'fdr': 0.34285714285714286, 'tpr': 0.9583333333333334, 'fpr': 0.19047619047619047, 'f1': 0.7796610169491525, 'shd': 65, 'npred': 175, 'ntrue': 120}
[2.317e-04 5.742e-04 1.905e+00 4.882e-03 8.638e-02 2.211e-01 2.112e-05
 4.337e-04 1.481e-05 1.494e-05 6.847e-03 1.201e-05 3.345e-05 3.818e-05
 9.082e-01 2.301e-05 7.510e-05 7.683e-01 1.518e-01 7.509e-07 3.631e-05
 2.252e-01 1.994e-04 2.150e-06 7.134e-05 6.838e-02 2.550e-05 2.530e-01
 1.503e-04 4.257e-01 7.797e-02 1.147e-01 2.426e-01 1.638e+00 2.263e-01
 1.925e-04 1.015e+00 7.034e-05 5.397e-05 1.304e-01 1.910e-04 1.073e-04
 8.166e-05 8.553e-01 4.220e-05 1.208e+00 2.902e-01 6.046e-01 1.088e-05
 1.484e-03 1.129e+00 5.375e-04 2.653e-07 4.135e-04 1.631e-01 2.193e-05
 2.347e-01 1.493e-01 1.706e-01 9.391e-03 4.503e-01 1.755e-01 3.714e-01
 1.657e-01 5.251e-03 1.180e-01 2.208e-06 1.629e-05 1.646e-01 2.259e-05
 1.788e-04 3.881e-06 7.786e-01 5.090e-06 3.343e-01 9.915e-02 1.012e-01
 1.628e-05 1.043e-04 2.000e-01 2.556e-04 1.603e-05 2.000e-03 1.971e-01
 1.062e-04 2.471e-01 1.823e-01 1.568e-04 9.641e-05 1.430e-04 8.576e-04
 1.799e-03 1.147e-01 4.984e-05 1.405e-04 2.345e-05 1.771e-05 8.657e-05
 2.548e-05 2.080e-05 2.111e-06 8.843e-01 4.370e-06 3.170e-05 2.085e-01
 6.102e-01 6.460e-06 1.362e-05 1.416e-01 2.110e-05 1.099e-05 1.819e-05
 9.722e-05 1.172e-05 2.417e-01 2.072e-05 6.922e-02 2.192e-03 2.375e-03
 2.051e-01 3.018e-03 3.169e-01 2.962e-04 1.084e-01 2.555e-05 3.100e-05
 6.593e-03 6.441e-05 1.046e-05 1.459e-05 1.565e-01 1.331e-06 5.833e-04
 7.184e-01 1.873e-01 2.350e-05 4.977e-04 1.501e+00 2.358e-04 7.823e-07
 3.394e-04 9.708e-04 1.033e-04 2.151e-01 1.485e-03 3.113e-03 3.491e-04
 1.403e-04 1.807e-01 1.843e-01 1.563e+00 4.048e-04 5.383e-03 5.363e-06
 1.830e-05 8.772e-05 2.129e-05 7.207e-05 6.903e-06 2.303e-01 2.994e-06
 1.839e-04 1.464e-01 1.450e-01 2.859e-06 6.430e-05 3.374e-01 3.123e-05
 1.594e-06 7.696e-05 1.313e-04 8.243e-06 8.024e-01 7.271e-05 3.374e-04
 1.985e-04 1.758e-04 1.430e-03 6.169e-05 3.599e-04 1.160e-04 1.274e-03
 3.802e-06 1.240e-05 8.535e-05 4.803e-05 6.378e-06 1.410e-05 1.039e+00
 1.004e-05 2.528e-04 1.595e-02 7.584e-04 1.966e-06 1.375e-05 3.803e-04
 1.079e-04 3.551e-06 6.694e-05 4.184e-05 4.732e-06 1.863e-01 1.884e-05
 4.385e-01 8.106e-01 1.035e-01 1.498e-01 2.225e+00 1.137e-01 2.640e-01
 1.393e+00 3.343e-05 2.126e-05 1.599e-01 1.725e-04 1.127e-04 1.923e-05
 5.876e-01 2.068e-05 2.984e-01 2.004e-01 7.086e-01 6.087e-06 1.209e-03
 3.253e-01 9.829e-04 5.819e-06 5.232e-03 7.851e-02 1.382e-04 4.266e-01
 2.570e-01 1.226e+00 2.528e-04 9.966e-04 2.436e-01 6.676e-03 6.480e-02
 9.594e-02 8.338e-05 4.603e-05 2.581e-05 1.472e-01 5.030e-05 9.507e-06
 8.999e-06 7.668e-02 1.111e-05 1.253e-04 2.577e-01 8.241e-01 4.722e-06
 5.946e-05 1.292e-01 1.620e-04 5.786e-07 1.796e-04 4.787e-02 1.340e-05
 1.643e-01 1.986e-04 2.927e-01 7.723e-01 2.285e-01 2.360e-01 1.816e-01
 3.271e-01 2.677e-01 3.108e-01 1.044e+00 9.507e-05 2.292e-01 2.239e+00
 1.373e-01 7.958e-03 3.137e-01 6.071e-04 3.710e-01 2.700e-01 1.040e-01
 2.462e-03 4.821e-01 4.643e-01 8.553e-02 5.165e-05 1.312e-01 2.184e-01
 1.136e-03 3.415e-01 1.872e+00 1.694e+00 1.775e+00 2.497e-01 1.618e-01
 1.575e-01 3.737e-01 2.086e-01 1.956e+00 2.759e-01 1.280e+00 6.556e-02
 1.397e-01 2.905e-01 4.357e-03 1.090e+00 3.916e-04 2.883e-01 1.360e-01
 2.446e-01 2.108e-02 8.842e-02 2.117e-01 2.216e-02 2.657e-04 1.911e-01
 1.349e-01 1.624e-02 1.066e+00 4.017e-01 1.148e-01 1.341e-03 1.028e-03
 1.329e-01 7.165e-02 1.142e-01 9.380e-01 6.268e-04 1.493e-02 2.539e-05
 1.543e-05 3.286e-05 1.212e-05 3.462e-06 3.362e-01 2.082e-05 2.649e-04
 2.328e-01 9.962e-02 2.259e-06 3.177e-05 1.551e-01 5.069e-05 4.221e-06
 4.880e-04 9.066e-01 5.117e-05 1.612e-01 2.091e-04 1.471e-01 1.781e+00
 1.368e-01 1.850e-01 2.383e+00 2.972e-01 2.151e-01 1.374e+00 8.517e-01
 1.695e-04 3.759e-05 1.839e+00 1.207e-04 7.626e-05 2.469e-01 2.372e-05
 1.900e-01 5.898e-01 1.084e-01 3.017e-05 2.587e+00 4.878e-01 2.831e-03
 8.615e-06 2.305e-02 1.080e+00 6.185e-04 3.706e-01 2.608e-01 2.119e-01
 2.044e-01 2.903e+00 1.146e+00 1.258e-01 1.740e+00 3.859e-01 1.563e-01
 3.531e-01 2.107e-03 1.578e-03 5.065e-01 3.039e-01 9.768e-05 4.878e-01
 1.409e-04 1.771e+00 4.293e-01 2.344e-01 8.240e-05 8.772e-02 2.784e-01
 2.625e+00 2.682e-04 5.195e-01 3.658e-01 6.270e-03 2.057e-01 2.356e+00
 1.856e-01 9.474e-01 4.562e-02 2.487e-01 1.975e-01 3.229e-01 3.483e-01
 2.793e-01 2.656e-01 2.518e-02 1.767e-02 6.373e-01 2.520e+00 8.246e-02
 2.774e-01 2.640e-04 1.783e-01 1.723e-01 1.830e-01 3.777e-01 6.289e-01
 9.799e-01 3.590e+00 6.609e-03 9.482e-02 4.463e-01 2.529e-03 4.741e-01
 2.764e-01 4.320e-05 3.296e-04 3.619e-04 2.512e-04 5.174e-04 2.042e-04
 1.312e-03 4.805e-05 4.791e-05 2.258e-05 3.689e-05 1.276e-04 5.760e-05
 1.107e-05 4.613e-06 7.748e-06 1.363e-04 5.746e-03 6.082e-04 2.979e-06
 1.315e-05 1.896e-04 3.064e-05 2.575e-06 1.330e-04 2.008e-04 1.175e-05
 1.611e-01 2.154e-05 2.060e-01 2.478e-01 1.620e-01 6.153e-02 3.672e-01
 1.170e+00 5.442e-01 3.440e-01 5.694e-01 1.313e-01 7.718e-02 1.329e-01
 1.081e+00 9.369e-02 3.045e+00 4.892e-01 1.612e-02 2.338e-01 3.699e-02
 7.419e-01 1.372e+00 2.279e-01 3.361e-01 8.718e-04 5.141e-02 1.457e-01
 3.522e-03 2.738e-01 1.174e-01 1.191e-01 4.113e-04 5.007e-04 2.436e-01
 1.640e-01 2.487e-01 2.057e-01 9.725e-05 1.129e+00 5.601e-06 5.712e-06
 2.035e-01 1.558e-05 1.182e-04 4.831e-06 2.270e-01 3.529e-07 7.265e-01
 3.075e-01 1.943e-05 1.482e-04 3.884e-01 9.162e-05 6.724e-06 1.408e-04
 6.406e-01 9.897e-06 1.716e-01 9.286e-04 7.148e-04 4.248e-04 9.670e-04
 6.408e-04 4.002e-04 1.001e-03 9.678e-02 4.454e-05 4.098e-04 2.824e-05
 1.042e-05 4.160e-04 1.429e-05 4.569e-05 5.745e-05 1.642e-01 4.498e-05
 2.195e-04 3.020e-04 3.970e-06 6.138e-05 8.931e-03 2.480e-04 8.998e-07
 3.924e-04 1.032e-03 1.459e-05 1.364e-02 1.159e-04 4.253e-04 5.541e-04
 5.640e-04 3.746e-03 1.087e-03 1.986e-03 1.932e-01 5.389e-04 4.672e-04
 8.063e-06 1.468e-05 7.582e-04 2.358e-05 5.582e-05 4.937e-05 3.096e-01
 2.862e-05 6.898e-05 7.975e-01 1.636e-05 5.453e-06 1.809e-01 2.306e-04
 1.767e-05 1.349e-04 7.648e-05 2.406e-05 4.622e-01 1.174e-04 1.823e-01
 5.246e-01 2.124e-01 4.035e-01 1.849e+00 1.069e+00 3.337e-01 1.108e+00
 1.786e-01 8.234e-02 2.499e-02 2.177e-01 2.358e-01 3.751e+00 7.021e-04
 1.872e-01 6.354e-04 2.348e-01 2.612e-01 7.446e-02 1.730e+00 7.081e-01
 7.151e-02 1.682e-03 2.426e+00 2.251e-01 1.134e-03 2.520e-01 1.022e-01
 8.505e-02 2.421e-01 2.609e+00 1.078e+00 1.636e+00 2.262e-01 6.588e-01
 4.027e-01 4.748e-01 1.962e-05 4.756e-06 3.344e-01 2.973e-05 8.848e-05
 3.695e-05 2.542e-01 5.798e-06 2.250e+00 3.871e-01 2.730e-01 5.313e-05
 4.294e-01 2.177e-04 1.194e-06 2.320e-03 2.810e-01 3.520e-05 5.969e-01
 2.181e+00 7.128e-04 7.375e-04 3.656e-04 2.329e-03 2.429e-04 4.634e-04
 1.049e+00 4.103e-05 1.737e-03 6.783e-06 5.717e-05 1.517e-04 1.805e-05
 6.438e-06 3.290e-06 2.303e-01 2.459e-06 7.663e-05 5.345e-01 3.543e-03
 2.650e-06 4.665e-05 1.898e-05 6.862e-06 6.328e-05 7.716e-04 3.253e-06
 1.179e-01 6.523e-05 2.063e+00 2.710e-01 9.721e-02 1.629e-01 1.485e-01
 1.823e-01 1.034e+00 1.738e-01 5.342e-01 1.719e-03 7.493e-05 2.168e+00
 2.744e-01 9.626e-05 1.833e-04 8.233e-01 6.258e-05 8.593e-02 8.115e-01
 9.391e-01 5.925e-06 2.576e-01 5.520e-01 3.701e-05 9.986e-03 1.531e+00
 7.059e-05 1.415e-01 1.195e-01 2.524e-01 3.876e-01 7.999e-01 1.387e-01
 1.696e-01 5.686e-01 5.943e-01 2.764e-01 1.050e-01 1.160e+00 4.366e+00
 1.552e-01 1.897e-01 2.178e+00 4.162e-02 1.469e-01 1.132e-02 4.566e-01
 1.733e-01 9.318e-02 2.778e-02 1.286e-01 9.433e-01 9.763e-02 2.877e+00
 1.072e-01 1.737e-03 2.382e-01 8.621e-01 2.241e-01 1.729e+00 1.205e-01
 7.666e-02 1.630e-01 1.997e-01 1.589e-01 1.097e-01 1.888e-01 4.500e-03
 5.160e-03 1.078e-01 2.401e-02 3.528e-04 1.336e-04 9.198e-02 8.134e-05
 1.101e-01 3.527e-01 1.903e-01 4.196e-05 1.405e-01 1.322e+00 4.152e-02
 3.441e-04 6.531e-02 7.721e-05 9.031e-02 1.300e-01 9.337e-03 2.106e-04
 7.019e-04 1.535e+00 1.790e-01 1.750e+00 3.206e-01 4.822e-04 4.432e-03
 2.288e-05 1.835e-05 3.348e-04 5.129e-05 5.499e-05 5.433e-06 7.993e-01
 7.064e-06 1.636e-04 9.623e-01 1.951e-01 3.928e-06 5.334e-05 1.400e+00
 5.116e-05 1.335e-06 3.203e-04 1.860e-05 7.962e-01 4.735e-05 2.101e+00
 3.484e-01 1.889e-01 2.585e-01 1.163e-01 2.234e-01 1.287e-01 9.245e-02
 2.482e-01 1.253e-02 5.012e-03 9.926e-01 5.998e-03 1.639e-02 2.203e-02
 1.909e-01 1.972e-02 1.334e-01 2.013e-01 8.058e-02 1.148e-03 5.742e-02
 9.251e-01 3.231e-02 3.226e-03 3.032e+00 1.192e-01 1.470e-01 1.127e-01
 1.190e-03 4.267e-04 7.051e-04 6.809e-03 1.852e-03 1.298e-03 7.635e-03
 9.489e-04 9.410e-04 1.357e-05 1.512e-04 8.371e-04 5.173e-05 3.308e-05
 4.626e-05 4.476e-02 4.522e-05 3.197e-04 9.838e-02 9.497e-03 3.282e-06
 1.302e-04 2.525e-03 1.698e-04 6.877e-05 1.016e-03 1.379e-03 5.188e-06
 2.359e-04 2.548e-01 4.283e-03 4.589e-03 3.992e-01 1.823e-01 1.741e-01
 4.189e-01 1.806e-03 5.313e-01 3.518e-05 9.793e-06 1.981e+00 4.320e-05
 1.113e-04 1.261e-06 2.006e-01 4.894e-06 3.044e-01 6.796e-01 2.197e-01
 2.059e-05 9.798e-05 1.562e-01 2.641e-04 2.232e-05 6.561e-04 6.711e-01
 2.029e-04 1.054e-01]
[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 1.]
 [1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 0. 1.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.
  0. 1. 1. 0. 0. 0.]
 [0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
  0. 1. 0. 0. 0. 1.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1.
 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0.]
aucroc, aucpr (0.9874111111111112, 0.9645747712764909)
cuda
noise_multiplier  1.0  noise_multiplier_b  2.5  noise_multiplier_delta  1.0206207261596576
cuda
Objective function 1220.30 = squared loss an data 964.29 + 0.5*rho*h**2 254.631624 + alpha*h 0.000000 + L2reg 0.55 + L1reg 0.82 ; SHD = 397 ; DAG False
total norm for a microbatch 143.41091926769533 clip 1.8511579101054196
total norm for a microbatch 107.57687505635023 clip 91.6634221559791
total norm for a microbatch 131.1043146139302 clip 100.02762336482688
total norm for a microbatch 236.0600516246157 clip 102.03771488213077
total norm for a microbatch 96.56672028452253 clip 115.28991611450589
total norm for a microbatch 178.34123637596323 clip 110.58899597844413
total norm for a microbatch 193.93368471235334 clip 116.098146876164
total norm for a microbatch 156.07510351604287 clip 116.28594224418389
total norm for a microbatch 204.22470584026408 clip 145.37209575155305
total norm for a microbatch 179.46363083349004 clip 141.95113272753707
total norm for a microbatch 298.65764554152764 clip 147.02606921348857
total norm for a microbatch 190.46648523766353 clip 147.2303871442312
cuda
Objective function 113.66 = squared loss an data 86.93 + 0.5*rho*h**2 24.383709 + alpha*h 0.000000 + L2reg 1.71 + L1reg 0.64 ; SHD = 273 ; DAG False
Proportion of microbatches that were clipped  0.8242370418214112
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 6.983367234466002
iteration 1 in outer loop, alpha = 6.983367234466002, rho = 1.0, h = 6.983367234466002
cuda
noise_multiplier  1.0  noise_multiplier_b  2.5  noise_multiplier_delta  1.0206207261596576
cuda
Objective function 162.43 = squared loss an data 86.93 + 0.5*rho*h**2 24.383709 + alpha*h 48.767418 + L2reg 1.71 + L1reg 0.64 ; SHD = 273 ; DAG False
total norm for a microbatch 206.3739539471986 clip 2.9274048785051345
total norm for a microbatch 157.96515170979083 clip 9.827362307325945
total norm for a microbatch 126.31204281290358 clip 12.751562309647179
total norm for a microbatch 236.54133797260818 clip 197.19081317634195
total norm for a microbatch 169.28327926676423 clip 209.59112286637668
total norm for a microbatch 216.97169354935588 clip 201.82657213708688
total norm for a microbatch 310.6593624950143 clip 199.4286375532611
total norm for a microbatch 186.57932054445482 clip 191.33846751631316
cuda
Objective function 121.91 = squared loss an data 75.21 + 0.5*rho*h**2 11.078417 + alpha*h 32.871440 + L2reg 2.15 + L1reg 0.60 ; SHD = 260 ; DAG False
Proportion of microbatches that were clipped  0.8259099421871183
iteration 1 in inner loop, alpha 6.983367234466002 rho 1.0 h 4.707104621585849
noise_multiplier  1.0  noise_multiplier_b  2.5  noise_multiplier_delta  1.0206207261596576
cuda
Objective function 221.61 = squared loss an data 75.21 + 0.5*rho*h**2 110.784170 + alpha*h 32.871440 + L2reg 2.15 + L1reg 0.60 ; SHD = 260 ; DAG False
total norm for a microbatch 269.7241271915194 clip 3.259756890234208
total norm for a microbatch 243.9079909702601 clip 235.16753178200145
total norm for a microbatch 548.2033687585316 clip 287.2869774754947
total norm for a microbatch 378.11822596312567 clip 261.961905957878
total norm for a microbatch 290.6683213988368 clip 264.4207367604409
total norm for a microbatch 494.4361205972653 clip 252.69423614432625
total norm for a microbatch 342.2635936593678 clip 247.352929885384
total norm for a microbatch 397.3582836837872 clip 250.10955735550246
total norm for a microbatch 228.36694173478406 clip 258.8745826792744
total norm for a microbatch 597.1397539758021 clip 255.64220823631027
total norm for a microbatch 289.6150691361758 clip 259.12494401192254
total norm for a microbatch 344.1219798025713 clip 258.07699280242014
total norm for a microbatch 477.67222763283513 clip 246.8538805747135
cuda
Objective function 120.93 = squared loss an data 77.17 + 0.5*rho*h**2 25.142342 + alpha*h 15.659675 + L2reg 2.41 + L1reg 0.55 ; SHD = 233 ; DAG False
Proportion of microbatches that were clipped  0.8304389773275446
iteration 2 in inner loop, alpha 6.983367234466002 rho 10.0 h 2.2424246573831255
noise_multiplier  1.0  noise_multiplier_b  2.5  noise_multiplier_delta  1.0206207261596576
cuda
Objective function 347.21 = squared loss an data 77.17 + 0.5*rho*h**2 251.423417 + alpha*h 15.659675 + L2reg 2.41 + L1reg 0.55 ; SHD = 233 ; DAG False
total norm for a microbatch 537.7797479692872 clip 1.0
total norm for a microbatch 300.4277535646838 clip 6.895783329617075
total norm for a microbatch 396.42834284387357 clip 6.895783329617075
total norm for a microbatch 895.5931808516488 clip 18.477762008719147
total norm for a microbatch 307.232504360373 clip 31.29476782379229
total norm for a microbatch 369.038903432296 clip 131.53104764267604
total norm for a microbatch 498.6848890236121 clip 310.3495018728245
total norm for a microbatch 486.2629152426795 clip 335.9998815647868
total norm for a microbatch 317.17847862702524 clip 314.2028864921262
total norm for a microbatch 446.63529956597733 clip 297.6236702067201
total norm for a microbatch 341.70502948421137 clip 302.70494614228954
total norm for a microbatch 521.387901552348 clip 310.16653965766693
total norm for a microbatch 336.71427110741155 clip 314.88136326841
total norm for a microbatch 611.7759292281461 clip 318.141950031916
total norm for a microbatch 347.14628353908756 clip 306.5334194523786
total norm for a microbatch 304.78987784297846 clip 293.6565614851478
total norm for a microbatch 243.804436948757 clip 310.51809949087
cuda
Objective function 134.01 = squared loss an data 83.19 + 0.5*rho*h**2 41.398485 + alpha*h 6.354364 + L2reg 2.59 + L1reg 0.48 ; SHD = 208 ; DAG True
Proportion of microbatches that were clipped  0.8324802989682346
iteration 3 in inner loop, alpha 6.983367234466002 rho 100.0 h 0.9099284059961299
iteration 2 in outer loop, alpha = 97.97620783407899, rho = 100.0, h = 0.9099284059961299
cuda
noise_multiplier  1.0  noise_multiplier_b  2.5  noise_multiplier_delta  1.0206207261596576
cuda
Objective function 216.81 = squared loss an data 83.19 + 0.5*rho*h**2 41.398485 + alpha*h 89.151335 + L2reg 2.59 + L1reg 0.48 ; SHD = 208 ; DAG True
total norm for a microbatch 311.76949247764503 clip 1.2929899128129856
total norm for a microbatch 660.9888933469949 clip 2.2065959255337204
total norm for a microbatch 422.1938240750192 clip 2.883073826190332
total norm for a microbatch 517.2173574614984 clip 9.253742714706249
total norm for a microbatch 329.5647120516238 clip 46.044480722296804
total norm for a microbatch 415.712941380262 clip 380.9848809586221
total norm for a microbatch 449.4861166164076 clip 389.49417559677715
total norm for a microbatch 286.8558186345917 clip 372.8369872406738
total norm for a microbatch 469.38518024825544 clip 366.6487423315788
total norm for a microbatch 558.6326066095362 clip 358.8492491906087
total norm for a microbatch 378.9550349103308 clip 365.6588432463924
total norm for a microbatch 541.783159447688 clip 353.51646795362245
total norm for a microbatch 436.42099513060435 clip 352.89830702518157
total norm for a microbatch 555.78986211488 clip 348.13870451221874
total norm for a microbatch 411.8869804824578 clip 336.417556772041
cuda
Objective function 159.11 = squared loss an data 84.28 + 0.5*rho*h**2 16.084063 + alpha*h 55.569119 + L2reg 2.73 + L1reg 0.45 ; SHD = 196 ; DAG True
Proportion of microbatches that were clipped  0.8305029920750445
iteration 1 in inner loop, alpha 97.97620783407899 rho 100.0 h 0.5671695185087096
noise_multiplier  1.0  noise_multiplier_b  2.5  noise_multiplier_delta  1.0206207261596576
cuda
Objective function 303.86 = squared loss an data 84.28 + 0.5*rho*h**2 160.840631 + alpha*h 55.569119 + L2reg 2.73 + L1reg 0.45 ; SHD = 196 ; DAG True
total norm for a microbatch 470.9922918049665 clip 1.6994152444932447
total norm for a microbatch 491.8964837808743 clip 3.737997185022944
total norm for a microbatch 444.4107035187238 clip 396.609833001943
total norm for a microbatch 546.1824744996495 clip 396.609833001943
total norm for a microbatch 487.52359481364294 clip 466.64582907932964
total norm for a microbatch 425.35408819183823 clip 492.9455153728793
total norm for a microbatch 476.68613791782644 clip 495.5547600451367
total norm for a microbatch 606.3098064837791 clip 512.7863471731024
total norm for a microbatch 635.9952118369474 clip 438.26116541846824
total norm for a microbatch 502.1884394655121 clip 417.3437913678918
total norm for a microbatch 342.78630417241857 clip 423.52758812787073
total norm for a microbatch 580.8102170652755 clip 423.52758812787073
total norm for a microbatch 387.180243706991 clip 386.15328114453234
total norm for a microbatch 469.4132758352216 clip 394.5512932317309
cuda
Objective function 161.12 = squared loss an data 86.16 + 0.5*rho*h**2 42.853014 + alpha*h 28.683115 + L2reg 2.99 + L1reg 0.44 ; SHD = 203 ; DAG True
Proportion of microbatches that were clipped  0.8373556352050976
iteration 2 in inner loop, alpha 97.97620783407899 rho 1000.0 h 0.29275591790361233
noise_multiplier  1.0  noise_multiplier_b  2.5  noise_multiplier_delta  1.0206207261596576
cuda
Objective function 546.80 = squared loss an data 86.16 + 0.5*rho*h**2 428.530137 + alpha*h 28.683115 + L2reg 2.99 + L1reg 0.44 ; SHD = 203 ; DAG True
total norm for a microbatch 1088.894503613193 clip 1.3285360296189497
total norm for a microbatch 532.7217543712544 clip 2.342497264749504
total norm for a microbatch 695.8316317236245 clip 87.65018397465717
total norm for a microbatch 921.2294432435149 clip 114.91415144227943
total norm for a microbatch 779.5793759512919 clip 124.55547421293674
total norm for a microbatch 1239.76580043818 clip 1040.0122103094488
total norm for a microbatch 774.4965905822612 clip 780.2912875606809
total norm for a microbatch 716.5575387788369 clip 655.2433707675078
total norm for a microbatch 957.1825810061102 clip 454.8646480798586
total norm for a microbatch 619.9498141389006 clip 464.43171876484377
total norm for a microbatch 447.1930452110956 clip 476.86041466747525
total norm for a microbatch 476.7570755233354 clip 476.86041466747525
cuda
Objective function 143.11 = squared loss an data 88.91 + 0.5*rho*h**2 41.667799 + alpha*h 8.944085 + L2reg 3.18 + L1reg 0.41 ; SHD = 205 ; DAG True
Proportion of microbatches that were clipped  0.8377322382585121
iteration 3 in inner loop, alpha 97.97620783407899 rho 10000.0 h 0.09128833330110098
iteration 3 in outer loop, alpha = 1010.8595408450888, rho = 10000.0, h = 0.09128833330110098
cuda
noise_multiplier  1.0  noise_multiplier_b  2.5  noise_multiplier_delta  1.0206207261596576
cuda
Objective function 226.44 = squared loss an data 88.91 + 0.5*rho*h**2 41.667799 + alpha*h 92.279683 + L2reg 3.18 + L1reg 0.41 ; SHD = 205 ; DAG True
total norm for a microbatch 645.7700552326698 clip 1.0
total norm for a microbatch 836.7822339153398 clip 64.33751086047766
total norm for a microbatch 1179.981871772279 clip 1069.520886404067
total norm for a microbatch 1429.6238691591382 clip 1324.6624572512644
total norm for a microbatch 758.1738152134658 clip 743.1166479477325
total norm for a microbatch 523.2248588384925 clip 539.3918253644946
total norm for a microbatch 732.3752567086615 clip 482.1828180556225
total norm for a microbatch 612.2229287209483 clip 493.06013997829376
total norm for a microbatch 624.098605024564 clip 486.81525861530747
total norm for a microbatch 462.0245941455475 clip 464.68875732515124
total norm for a microbatch 549.8073242514067 clip 503.33915825687154
cuda
Objective function 153.57 = squared loss an data 88.41 + 0.5*rho*h**2 11.976580 + alpha*h 49.473453 + L2reg 3.30 + L1reg 0.40 ; SHD = 219 ; DAG True
Proportion of microbatches that were clipped  0.8373718916342258
iteration 1 in inner loop, alpha 1010.8595408450888 rho 10000.0 h 0.048941965435403745
noise_multiplier  1.0  noise_multiplier_b  2.5  noise_multiplier_delta  1.0206207261596576
cuda
Objective function 261.35 = squared loss an data 88.41 + 0.5*rho*h**2 119.765799 + alpha*h 49.473453 + L2reg 3.30 + L1reg 0.40 ; SHD = 219 ; DAG True
total norm for a microbatch 2384.4810943418565 clip 35.839554808996
total norm for a microbatch 3474.019479160337 clip 125.24951506921897
total norm for a microbatch 6606.83049935883 clip 959.7479506671381
total norm for a microbatch 7650.855622467757 clip 1058.3237124612149
total norm for a microbatch 7649.598946116829 clip 1058.3237124612149
total norm for a microbatch 20185.461251351036 clip 16021.51325191865
total norm for a microbatch 15691.872194500513 clip 14135.773013169586
total norm for a microbatch 1345.0636853716462 clip 1210.2256974278193
total norm for a microbatch 703.2583196925764 clip 506.70309389299723
total norm for a microbatch 498.3924746361484 clip 506.9123789924932
total norm for a microbatch 776.2446794836102 clip 438.6634977118801
total norm for a microbatch 593.465651591136 clip 432.6189003138216
total norm for a microbatch 386.742776164916 clip 435.0098061113561
cuda
Objective function 143.08 = squared loss an data 125.08 + 0.5*rho*h**2 4.552173 + alpha*h 9.645288 + L2reg 3.41 + L1reg 0.39 ; SHD = 219 ; DAG True
Proportion of microbatches that were clipped  0.8358867409962301
iteration 2 in inner loop, alpha 1010.8595408450888 rho 100000.0 h 0.009541670084768583
iteration 4 in outer loop, alpha = 1965.0265493219472, rho = 100000.0, h = 0.009541670084768583
cuda
noise_multiplier  1.0  noise_multiplier_b  2.5  noise_multiplier_delta  1.0206207261596576
cuda
Objective function 152.19 = squared loss an data 125.08 + 0.5*rho*h**2 4.552173 + alpha*h 18.749635 + L2reg 3.41 + L1reg 0.39 ; SHD = 219 ; DAG True
total norm for a microbatch 7834.250161102986 clip 1.5800104281720568
total norm for a microbatch 6994.969615809244 clip 2.0639977664832068
total norm for a microbatch 4000.3818610104663 clip 3.2480238231413754
total norm for a microbatch 7711.011756797235 clip 1102.0409157606516
total norm for a microbatch 13839.823159891173 clip 8048.398480362954
total norm for a microbatch 21827.855603362215 clip 13755.772078299275
total norm for a microbatch 21853.29912951755 clip 17848.435075057674
total norm for a microbatch 19546.971574773623 clip 21458.57861770427
total norm for a microbatch 19218.387495683422 clip 17056.93000494094
total norm for a microbatch 15609.763134683295 clip 17363.48444420042
total norm for a microbatch 15312.023761986044 clip 13811.772324103173
total norm for a microbatch 2757.474901849479 clip 2512.268476437863
total norm for a microbatch 583.4725251821791 clip 531.7327175230668
total norm for a microbatch 750.6594786275474 clip 502.62870573367496
cuda
Objective function 148.26 = squared loss an data 126.18 + 0.5*rho*h**2 2.958484 + alpha*h 15.115343 + L2reg 3.59 + L1reg 0.42 ; SHD = 224 ; DAG True
Proportion of microbatches that were clipped  0.8342967244701349
iteration 1 in inner loop, alpha 1965.0265493219472 rho 100000.0 h 0.0076921827342602
iteration 5 in outer loop, alpha = 9657.209283582148, rho = 1000000.0, h = 0.0076921827342602
Threshold 0.3
[[0.002 0.088 0.142 0.01  0.263 0.011 0.049 0.004 0.1   0.021 0.013 0.204
  0.004 0.004 0.003 0.152 0.005 0.009 0.005 0.007 0.006 0.01  0.004 0.054
  0.01  0.004 0.011 0.004 0.086 0.068]
 [0.079 0.003 0.453 0.006 0.101 0.011 0.066 0.006 0.197 0.012 0.02  0.163
  0.002 0.003 0.003 0.043 0.003 0.008 0.01  0.006 0.012 0.006 0.009 0.056
  0.037 0.011 0.038 0.019 0.048 0.039]
 [0.028 0.005 0.002 0.003 0.128 0.004 0.019 0.002 0.019 0.004 0.007 0.044
  0.001 0.001 0.001 0.006 0.002 0.002 0.004 0.003 0.005 0.004 0.002 0.01
  0.006 0.003 0.003 0.003 0.015 0.014]
 [0.255 0.289 0.684 0.002 0.627 0.146 0.321 0.009 0.216 0.123 0.115 0.502
  0.014 0.055 0.01  0.253 0.015 0.152 0.075 0.108 0.048 0.101 0.014 0.183
  0.372 0.072 0.089 0.063 0.248 0.246]
 [0.015 0.028 0.038 0.003 0.003 0.003 0.015 0.003 0.013 0.004 0.008 0.037
  0.001 0.002 0.001 0.012 0.002 0.002 0.004 0.003 0.007 0.005 0.001 0.005
  0.007 0.002 0.006 0.003 0.008 0.019]
 [0.198 0.342 0.504 0.024 0.677 0.001 0.379 0.027 0.313 0.221 0.312 0.686
  0.003 0.068 0.017 0.421 0.027 0.138 0.176 0.04  0.042 0.118 0.018 0.183
  0.39  0.13  0.182 0.149 0.188 0.3  ]
 [0.102 0.106 0.21  0.006 0.212 0.01  0.002 0.006 0.162 0.003 0.017 0.133
  0.001 0.002 0.004 0.02  0.004 0.007 0.017 0.005 0.007 0.01  0.005 0.048
  0.016 0.012 0.009 0.005 0.219 0.036]
 [0.393 0.495 0.864 0.287 0.963 0.168 0.502 0.003 0.462 0.132 0.226 1.227
  0.053 0.081 0.056 0.462 0.093 0.169 0.158 0.134 0.201 0.158 0.274 0.296
  0.312 0.096 0.224 0.198 0.589 0.587]
 [0.082 0.018 0.202 0.014 0.209 0.008 0.031 0.006 0.002 0.007 0.022 0.129
  0.002 0.002 0.002 0.03  0.003 0.007 0.008 0.008 0.005 0.009 0.004 0.015
  0.022 0.003 0.01  0.029 0.086 0.072]
 [0.151 0.254 0.623 0.052 0.54  0.016 0.527 0.023 0.362 0.002 0.128 0.309
  0.003 0.007 0.006 0.171 0.021 0.017 0.044 0.039 0.06  0.03  0.013 0.273
  0.202 0.074 0.102 0.099 0.37  0.186]
 [0.202 0.224 0.475 0.047 0.321 0.007 0.221 0.01  0.19  0.036 0.004 0.559
  0.005 0.017 0.004 0.109 0.01  0.008 0.041 0.017 0.059 0.032 0.01  0.071
  0.309 0.008 0.065 0.082 0.166 0.148]
 [0.015 0.033 0.126 0.005 0.141 0.004 0.041 0.002 0.036 0.006 0.006 0.002
  0.001 0.003 0.002 0.04  0.001 0.003 0.005 0.005 0.007 0.004 0.004 0.032
  0.025 0.001 0.007 0.005 0.027 0.016]
 [0.616 1.415 1.806 0.24  1.79  0.668 1.011 0.101 0.961 0.708 0.475 1.463
  0.003 0.142 0.152 0.974 0.466 0.419 0.724 0.368 0.785 0.533 0.466 0.45
  0.464 0.638 0.258 0.83  0.861 0.855]
 [0.813 0.56  1.056 0.075 0.683 0.088 0.927 0.093 0.852 0.242 0.299 0.601
  0.038 0.002 0.06  0.977 0.175 0.204 0.296 0.275 0.538 0.141 0.159 0.45
  0.427 0.224 0.3   0.317 0.774 0.849]
 [0.641 0.749 1.404 0.239 1.273 0.205 0.633 0.13  0.765 0.305 0.634 1.138
  0.045 0.127 0.003 0.593 0.109 0.271 0.709 0.337 0.288 0.292 0.233 0.568
  0.877 0.142 0.438 0.339 0.502 0.602]
 [0.03  0.118 0.344 0.009 0.289 0.005 0.178 0.005 0.15  0.016 0.055 0.144
  0.002 0.001 0.005 0.002 0.004 0.007 0.012 0.01  0.008 0.015 0.003 0.01
  0.033 0.006 0.021 0.012 0.046 0.05 ]
 [0.616 0.535 0.696 0.213 0.915 0.158 1.031 0.058 0.563 0.157 0.311 1.353
  0.006 0.027 0.054 0.424 0.002 0.148 0.096 0.124 0.181 0.28  0.059 0.804
  0.328 0.185 0.236 0.171 0.64  0.672]
 [0.267 0.463 0.756 0.029 0.387 0.033 0.429 0.029 0.396 0.23  0.246 0.667
  0.006 0.016 0.007 0.337 0.033 0.002 0.065 0.022 0.047 0.07  0.048 0.165
  0.212 0.052 0.062 0.07  0.123 0.27 ]
 [0.526 0.46  0.571 0.101 0.544 0.02  0.175 0.015 0.36  0.107 0.126 0.553
  0.003 0.01  0.005 0.217 0.051 0.099 0.005 0.08  0.034 0.154 0.012 0.188
  0.325 0.012 0.091 0.087 0.392 0.145]
 [0.397 0.331 0.67  0.049 0.786 0.155 0.495 0.052 0.357 0.093 0.195 0.458
  0.006 0.012 0.008 0.303 0.045 0.178 0.069 0.003 0.102 0.109 0.073 0.149
  0.41  0.051 0.182 0.095 0.332 0.329]
 [0.322 0.401 0.484 0.114 0.452 0.109 0.444 0.014 0.533 0.099 0.107 0.426
  0.002 0.005 0.008 0.312 0.016 0.083 0.142 0.07  0.003 0.088 0.016 0.267
  0.23  0.031 0.125 0.118 0.112 0.335]
 [0.23  0.305 0.499 0.062 0.429 0.05  0.286 0.027 0.313 0.161 0.157 0.488
  0.003 0.035 0.011 0.204 0.009 0.101 0.034 0.067 0.083 0.002 0.015 0.105
  0.234 0.034 0.103 0.093 0.235 0.246]
 [0.525 0.465 0.94  0.224 1.25  0.238 0.477 0.013 0.597 0.267 0.427 0.69
  0.007 0.034 0.011 0.558 0.094 0.098 0.26  0.075 0.228 0.221 0.004 0.135
  0.342 0.125 0.16  0.097 0.464 0.346]
 [0.12  0.124 0.32  0.024 0.537 0.02  0.131 0.007 0.217 0.009 0.086 0.158
  0.005 0.007 0.004 0.245 0.004 0.023 0.048 0.029 0.01  0.052 0.026 0.004
  0.079 0.014 0.049 0.034 0.069 0.228]
 [0.292 0.139 0.489 0.007 0.377 0.008 0.2   0.009 0.237 0.01  0.008 0.197
  0.003 0.005 0.003 0.139 0.008 0.013 0.011 0.004 0.015 0.014 0.008 0.074
  0.002 0.01  0.015 0.02  0.125 0.06 ]
 [0.533 0.339 0.831 0.072 0.707 0.052 0.241 0.064 0.568 0.086 0.446 1.074
  0.004 0.012 0.025 0.356 0.025 0.094 0.242 0.104 0.145 0.128 0.068 0.207
  0.339 0.004 0.179 0.119 0.539 0.369]
 [0.29  0.201 0.841 0.072 0.378 0.024 0.34  0.014 0.393 0.067 0.087 0.441
  0.011 0.008 0.007 0.208 0.017 0.072 0.077 0.019 0.042 0.067 0.042 0.082
  0.251 0.024 0.002 0.018 0.184 0.224]
 [0.532 0.211 0.819 0.101 0.617 0.041 0.392 0.022 0.155 0.057 0.078 0.353
  0.003 0.011 0.011 0.279 0.03  0.084 0.07  0.05  0.065 0.072 0.057 0.124
  0.18  0.042 0.19  0.003 0.28  0.349]
 [0.053 0.154 0.269 0.013 0.29  0.017 0.021 0.005 0.081 0.008 0.047 0.206
  0.001 0.003 0.004 0.147 0.003 0.028 0.006 0.01  0.026 0.012 0.004 0.116
  0.036 0.008 0.021 0.009 0.004 0.033]
 [0.103 0.143 0.235 0.013 0.21  0.01  0.173 0.006 0.087 0.018 0.039 0.278
  0.002 0.003 0.004 0.086 0.004 0.012 0.035 0.008 0.011 0.016 0.015 0.021
  0.092 0.012 0.021 0.01  0.172 0.003]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.453 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.684 0.    0.627 0.    0.321 0.    0.    0.    0.    0.502
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.372 0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.342 0.504 0.    0.677 0.    0.379 0.    0.313 0.    0.312 0.686
  0.    0.    0.    0.421 0.    0.    0.    0.    0.    0.    0.    0.
  0.39  0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.393 0.495 0.864 0.    0.963 0.    0.502 0.    0.462 0.    0.    1.227
  0.    0.    0.    0.462 0.    0.    0.    0.    0.    0.    0.    0.
  0.312 0.    0.    0.    0.589 0.587]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.623 0.    0.54  0.    0.527 0.    0.362 0.    0.    0.309
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.37  0.   ]
 [0.    0.    0.475 0.    0.321 0.    0.    0.    0.    0.    0.    0.559
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.309 0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.616 1.415 1.806 0.    1.79  0.668 1.011 0.    0.961 0.708 0.475 1.463
  0.    0.    0.    0.974 0.466 0.419 0.724 0.368 0.785 0.533 0.466 0.45
  0.464 0.638 0.    0.83  0.861 0.855]
 [0.813 0.56  1.056 0.    0.683 0.    0.927 0.    0.852 0.    0.    0.601
  0.    0.    0.    0.977 0.    0.    0.    0.    0.538 0.    0.    0.45
  0.427 0.    0.    0.317 0.774 0.849]
 [0.641 0.749 1.404 0.    1.273 0.    0.633 0.    0.765 0.305 0.634 1.138
  0.    0.    0.    0.593 0.    0.    0.709 0.337 0.    0.    0.    0.568
  0.877 0.    0.438 0.339 0.502 0.602]
 [0.    0.    0.344 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.616 0.535 0.696 0.    0.915 0.    1.031 0.    0.563 0.    0.311 1.353
  0.    0.    0.    0.424 0.    0.    0.    0.    0.    0.    0.    0.804
  0.328 0.    0.    0.    0.64  0.672]
 [0.    0.463 0.756 0.    0.387 0.    0.429 0.    0.396 0.    0.    0.667
  0.    0.    0.    0.337 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.526 0.46  0.571 0.    0.544 0.    0.    0.    0.36  0.    0.    0.553
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.325 0.    0.    0.    0.392 0.   ]
 [0.397 0.331 0.67  0.    0.786 0.    0.495 0.    0.357 0.    0.    0.458
  0.    0.    0.    0.303 0.    0.    0.    0.    0.    0.    0.    0.
  0.41  0.    0.    0.    0.332 0.329]
 [0.322 0.401 0.484 0.    0.452 0.    0.444 0.    0.533 0.    0.    0.426
  0.    0.    0.    0.312 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.335]
 [0.    0.305 0.499 0.    0.429 0.    0.    0.    0.313 0.    0.    0.488
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.525 0.465 0.94  0.    1.25  0.    0.477 0.    0.597 0.    0.427 0.69
  0.    0.    0.    0.558 0.    0.    0.    0.    0.    0.    0.    0.
  0.342 0.    0.    0.    0.464 0.346]
 [0.    0.    0.32  0.    0.537 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.489 0.    0.377 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.533 0.339 0.831 0.    0.707 0.    0.    0.    0.568 0.    0.446 1.074
  0.    0.    0.    0.356 0.    0.    0.    0.    0.    0.    0.    0.
  0.339 0.    0.    0.    0.539 0.369]
 [0.    0.    0.841 0.    0.378 0.    0.34  0.    0.393 0.    0.    0.441
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.532 0.    0.819 0.    0.617 0.    0.392 0.    0.    0.    0.    0.353
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.349]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]]
{'fdr': 0.8315217391304348, 'tpr': 0.25833333333333336, 'fpr': 0.4857142857142857, 'f1': 0.20394736842105263, 'shd': 224, 'npred': 184, 'ntrue': 120}
[8.759e-02 1.418e-01 9.548e-03 2.626e-01 1.125e-02 4.947e-02 4.307e-03
 1.001e-01 2.069e-02 1.295e-02 2.039e-01 3.708e-03 3.659e-03 2.750e-03
 1.515e-01 4.954e-03 8.991e-03 5.451e-03 7.395e-03 6.364e-03 9.770e-03
 3.648e-03 5.422e-02 1.025e-02 3.531e-03 1.058e-02 3.613e-03 8.643e-02
 6.842e-02 7.861e-02 4.525e-01 5.976e-03 1.010e-01 1.073e-02 6.618e-02
 5.697e-03 1.966e-01 1.154e-02 1.990e-02 1.632e-01 1.716e-03 3.312e-03
 2.528e-03 4.265e-02 2.916e-03 7.764e-03 9.650e-03 5.829e-03 1.224e-02
 5.922e-03 8.795e-03 5.622e-02 3.654e-02 1.131e-02 3.772e-02 1.886e-02
 4.782e-02 3.892e-02 2.775e-02 5.142e-03 3.102e-03 1.284e-01 3.537e-03
 1.912e-02 2.015e-03 1.924e-02 4.071e-03 7.139e-03 4.359e-02 1.224e-03
 1.443e-03 1.357e-03 5.894e-03 2.195e-03 2.497e-03 3.918e-03 3.045e-03
 5.080e-03 4.063e-03 1.985e-03 1.001e-02 5.665e-03 3.062e-03 3.082e-03
 3.094e-03 1.517e-02 1.407e-02 2.551e-01 2.895e-01 6.841e-01 6.269e-01
 1.461e-01 3.207e-01 9.124e-03 2.162e-01 1.229e-01 1.150e-01 5.023e-01
 1.373e-02 5.539e-02 9.746e-03 2.530e-01 1.545e-02 1.524e-01 7.476e-02
 1.077e-01 4.766e-02 1.013e-01 1.399e-02 1.830e-01 3.721e-01 7.196e-02
 8.866e-02 6.314e-02 2.483e-01 2.456e-01 1.526e-02 2.849e-02 3.840e-02
 3.013e-03 3.248e-03 1.462e-02 2.587e-03 1.281e-02 4.127e-03 8.024e-03
 3.727e-02 7.177e-04 2.163e-03 9.919e-04 1.186e-02 2.094e-03 2.372e-03
 3.878e-03 3.177e-03 6.769e-03 4.851e-03 1.297e-03 4.905e-03 7.048e-03
 1.660e-03 5.567e-03 3.001e-03 8.296e-03 1.892e-02 1.980e-01 3.422e-01
 5.045e-01 2.405e-02 6.768e-01 3.794e-01 2.684e-02 3.135e-01 2.212e-01
 3.123e-01 6.856e-01 3.059e-03 6.826e-02 1.741e-02 4.214e-01 2.714e-02
 1.382e-01 1.757e-01 4.007e-02 4.195e-02 1.176e-01 1.812e-02 1.829e-01
 3.905e-01 1.296e-01 1.817e-01 1.486e-01 1.884e-01 2.998e-01 1.021e-01
 1.056e-01 2.097e-01 6.194e-03 2.123e-01 9.791e-03 5.777e-03 1.623e-01
 3.102e-03 1.660e-02 1.329e-01 1.400e-03 2.074e-03 4.134e-03 2.001e-02
 3.522e-03 6.687e-03 1.665e-02 4.810e-03 7.020e-03 9.621e-03 5.407e-03
 4.761e-02 1.566e-02 1.241e-02 9.452e-03 4.804e-03 2.194e-01 3.571e-02
 3.934e-01 4.947e-01 8.643e-01 2.870e-01 9.630e-01 1.685e-01 5.023e-01
 4.623e-01 1.324e-01 2.258e-01 1.227e+00 5.347e-02 8.144e-02 5.560e-02
 4.621e-01 9.325e-02 1.686e-01 1.577e-01 1.343e-01 2.014e-01 1.580e-01
 2.737e-01 2.959e-01 3.121e-01 9.559e-02 2.244e-01 1.980e-01 5.894e-01
 5.871e-01 8.230e-02 1.804e-02 2.019e-01 1.369e-02 2.095e-01 8.122e-03
 3.060e-02 5.641e-03 6.598e-03 2.160e-02 1.293e-01 2.163e-03 1.533e-03
 2.459e-03 2.959e-02 3.458e-03 6.749e-03 8.082e-03 7.991e-03 4.600e-03
 9.137e-03 3.535e-03 1.492e-02 2.182e-02 3.337e-03 1.015e-02 2.892e-02
 8.557e-02 7.232e-02 1.512e-01 2.542e-01 6.230e-01 5.249e-02 5.397e-01
 1.577e-02 5.270e-01 2.293e-02 3.623e-01 1.281e-01 3.087e-01 3.242e-03
 6.912e-03 5.676e-03 1.715e-01 2.133e-02 1.744e-02 4.379e-02 3.874e-02
 5.987e-02 3.000e-02 1.258e-02 2.728e-01 2.023e-01 7.421e-02 1.020e-01
 9.924e-02 3.700e-01 1.860e-01 2.023e-01 2.243e-01 4.747e-01 4.736e-02
 3.212e-01 7.417e-03 2.213e-01 1.010e-02 1.902e-01 3.604e-02 5.589e-01
 5.108e-03 1.681e-02 4.020e-03 1.091e-01 1.006e-02 8.313e-03 4.120e-02
 1.673e-02 5.932e-02 3.214e-02 9.765e-03 7.129e-02 3.090e-01 8.121e-03
 6.485e-02 8.240e-02 1.663e-01 1.482e-01 1.487e-02 3.306e-02 1.259e-01
 5.498e-03 1.411e-01 3.586e-03 4.138e-02 1.634e-03 3.637e-02 6.303e-03
 5.670e-03 1.478e-03 2.710e-03 2.098e-03 4.034e-02 1.416e-03 3.472e-03
 5.346e-03 4.641e-03 7.244e-03 4.197e-03 4.265e-03 3.152e-02 2.520e-02
 1.404e-03 6.921e-03 5.496e-03 2.711e-02 1.601e-02 6.160e-01 1.415e+00
 1.806e+00 2.404e-01 1.790e+00 6.680e-01 1.011e+00 1.008e-01 9.612e-01
 7.081e-01 4.747e-01 1.463e+00 1.417e-01 1.517e-01 9.742e-01 4.665e-01
 4.192e-01 7.238e-01 3.680e-01 7.847e-01 5.334e-01 4.663e-01 4.498e-01
 4.645e-01 6.378e-01 2.584e-01 8.297e-01 8.611e-01 8.554e-01 8.128e-01
 5.602e-01 1.056e+00 7.504e-02 6.828e-01 8.786e-02 9.266e-01 9.278e-02
 8.519e-01 2.417e-01 2.991e-01 6.006e-01 3.783e-02 5.992e-02 9.770e-01
 1.750e-01 2.044e-01 2.965e-01 2.755e-01 5.382e-01 1.412e-01 1.589e-01
 4.503e-01 4.271e-01 2.244e-01 2.996e-01 3.167e-01 7.743e-01 8.487e-01
 6.406e-01 7.492e-01 1.404e+00 2.390e-01 1.273e+00 2.054e-01 6.333e-01
 1.302e-01 7.651e-01 3.055e-01 6.344e-01 1.138e+00 4.480e-02 1.268e-01
 5.926e-01 1.089e-01 2.707e-01 7.088e-01 3.372e-01 2.884e-01 2.923e-01
 2.326e-01 5.677e-01 8.772e-01 1.420e-01 4.381e-01 3.395e-01 5.022e-01
 6.016e-01 2.972e-02 1.176e-01 3.438e-01 8.933e-03 2.886e-01 5.193e-03
 1.785e-01 4.976e-03 1.496e-01 1.551e-02 5.452e-02 1.436e-01 2.178e-03
 1.406e-03 4.992e-03 3.650e-03 7.462e-03 1.243e-02 1.048e-02 7.787e-03
 1.504e-02 2.585e-03 9.511e-03 3.308e-02 6.304e-03 2.115e-02 1.177e-02
 4.569e-02 4.991e-02 6.159e-01 5.350e-01 6.963e-01 2.134e-01 9.154e-01
 1.581e-01 1.031e+00 5.840e-02 5.629e-01 1.572e-01 3.114e-01 1.353e+00
 6.088e-03 2.732e-02 5.421e-02 4.241e-01 1.482e-01 9.639e-02 1.242e-01
 1.812e-01 2.795e-01 5.854e-02 8.037e-01 3.283e-01 1.853e-01 2.365e-01
 1.711e-01 6.404e-01 6.721e-01 2.670e-01 4.632e-01 7.561e-01 2.901e-02
 3.872e-01 3.278e-02 4.287e-01 2.886e-02 3.956e-01 2.304e-01 2.462e-01
 6.671e-01 6.176e-03 1.583e-02 7.198e-03 3.366e-01 3.338e-02 6.536e-02
 2.190e-02 4.737e-02 7.002e-02 4.771e-02 1.648e-01 2.122e-01 5.182e-02
 6.232e-02 6.962e-02 1.230e-01 2.702e-01 5.261e-01 4.596e-01 5.712e-01
 1.009e-01 5.444e-01 1.982e-02 1.745e-01 1.529e-02 3.601e-01 1.071e-01
 1.264e-01 5.533e-01 3.350e-03 9.521e-03 4.646e-03 2.166e-01 5.135e-02
 9.888e-02 8.016e-02 3.368e-02 1.543e-01 1.206e-02 1.884e-01 3.250e-01
 1.228e-02 9.123e-02 8.683e-02 3.917e-01 1.453e-01 3.972e-01 3.309e-01
 6.704e-01 4.946e-02 7.856e-01 1.551e-01 4.949e-01 5.237e-02 3.575e-01
 9.290e-02 1.948e-01 4.582e-01 6.077e-03 1.192e-02 7.984e-03 3.032e-01
 4.496e-02 1.776e-01 6.852e-02 1.023e-01 1.085e-01 7.330e-02 1.489e-01
 4.105e-01 5.069e-02 1.823e-01 9.461e-02 3.319e-01 3.292e-01 3.222e-01
 4.012e-01 4.836e-01 1.140e-01 4.520e-01 1.095e-01 4.443e-01 1.406e-02
 5.329e-01 9.950e-02 1.071e-01 4.261e-01 2.030e-03 4.784e-03 8.302e-03
 3.124e-01 1.604e-02 8.282e-02 1.424e-01 6.989e-02 8.764e-02 1.614e-02
 2.667e-01 2.303e-01 3.106e-02 1.253e-01 1.182e-01 1.124e-01 3.350e-01
 2.296e-01 3.045e-01 4.989e-01 6.246e-02 4.288e-01 4.964e-02 2.857e-01
 2.746e-02 3.133e-01 1.612e-01 1.570e-01 4.879e-01 2.532e-03 3.550e-02
 1.126e-02 2.041e-01 8.618e-03 1.014e-01 3.419e-02 6.682e-02 8.264e-02
 1.540e-02 1.049e-01 2.337e-01 3.389e-02 1.034e-01 9.344e-02 2.355e-01
 2.455e-01 5.250e-01 4.652e-01 9.402e-01 2.243e-01 1.250e+00 2.377e-01
 4.768e-01 1.287e-02 5.966e-01 2.665e-01 4.273e-01 6.905e-01 7.132e-03
 3.363e-02 1.064e-02 5.581e-01 9.373e-02 9.776e-02 2.596e-01 7.537e-02
 2.282e-01 2.207e-01 1.352e-01 3.420e-01 1.250e-01 1.598e-01 9.661e-02
 4.642e-01 3.462e-01 1.201e-01 1.238e-01 3.203e-01 2.396e-02 5.374e-01
 1.988e-02 1.311e-01 7.101e-03 2.174e-01 8.596e-03 8.644e-02 1.578e-01
 5.386e-03 7.482e-03 4.191e-03 2.453e-01 3.676e-03 2.313e-02 4.846e-02
 2.889e-02 1.010e-02 5.204e-02 2.560e-02 7.905e-02 1.390e-02 4.898e-02
 3.439e-02 6.880e-02 2.279e-01 2.923e-01 1.389e-01 4.891e-01 6.932e-03
 3.767e-01 8.205e-03 1.995e-01 8.570e-03 2.374e-01 1.023e-02 7.686e-03
 1.971e-01 3.344e-03 5.181e-03 2.646e-03 1.394e-01 7.709e-03 1.314e-02
 1.132e-02 4.464e-03 1.522e-02 1.433e-02 8.082e-03 7.427e-02 9.579e-03
 1.509e-02 2.006e-02 1.254e-01 5.999e-02 5.331e-01 3.389e-01 8.310e-01
 7.236e-02 7.074e-01 5.191e-02 2.412e-01 6.424e-02 5.684e-01 8.588e-02
 4.457e-01 1.074e+00 4.124e-03 1.232e-02 2.478e-02 3.563e-01 2.534e-02
 9.430e-02 2.417e-01 1.043e-01 1.453e-01 1.283e-01 6.822e-02 2.070e-01
 3.390e-01 1.793e-01 1.188e-01 5.393e-01 3.688e-01 2.895e-01 2.007e-01
 8.408e-01 7.179e-02 3.784e-01 2.374e-02 3.405e-01 1.353e-02 3.928e-01
 6.653e-02 8.724e-02 4.405e-01 1.051e-02 8.065e-03 6.675e-03 2.081e-01
 1.714e-02 7.214e-02 7.675e-02 1.852e-02 4.183e-02 6.664e-02 4.182e-02
 8.205e-02 2.511e-01 2.409e-02 1.786e-02 1.838e-01 2.244e-01 5.317e-01
 2.107e-01 8.194e-01 1.012e-01 6.170e-01 4.060e-02 3.918e-01 2.201e-02
 1.551e-01 5.678e-02 7.799e-02 3.529e-01 3.317e-03 1.058e-02 1.062e-02
 2.786e-01 2.982e-02 8.350e-02 7.021e-02 5.016e-02 6.521e-02 7.212e-02
 5.658e-02 1.244e-01 1.798e-01 4.154e-02 1.901e-01 2.797e-01 3.492e-01
 5.260e-02 1.536e-01 2.693e-01 1.272e-02 2.904e-01 1.685e-02 2.143e-02
 4.809e-03 8.133e-02 7.937e-03 4.688e-02 2.059e-01 1.278e-03 2.665e-03
 4.215e-03 1.471e-01 3.124e-03 2.787e-02 6.226e-03 9.525e-03 2.617e-02
 1.233e-02 4.063e-03 1.157e-01 3.562e-02 8.083e-03 2.056e-02 9.366e-03
 3.306e-02 1.027e-01 1.426e-01 2.350e-01 1.278e-02 2.097e-01 1.046e-02
 1.727e-01 5.751e-03 8.689e-02 1.848e-02 3.861e-02 2.782e-01 2.351e-03
 2.664e-03 3.695e-03 8.621e-02 4.448e-03 1.220e-02 3.457e-02 8.185e-03
 1.105e-02 1.553e-02 1.538e-02 2.124e-02 9.188e-02 1.156e-02 2.088e-02
 9.910e-03 1.724e-01]
[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 1.]
 [1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 0. 1.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.
  0. 1. 1. 0. 0. 0.]
 [0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
  0. 1. 0. 0. 0. 1.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1.
 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0.]
aucroc, aucpr (0.5821111111111111, 0.18755463210558865)
Iterations 2500
Achieves (3.6993101023104464, 1e-05)-DP
