samples  5000  SCM  10 2 RE mim  minibatch size  50  noise  0.6  minibatches per NN training  250  DP methodology  group_clipping_and_adap_quantile 0.0  box penalty  1
cpu
max degree  2.0  complexity indicator 1  625.0  complexity indicator 2  1086.9565217391305
model created with box penalty
model created with box penalty
cpu
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 0.2855731205864114
iteration 1 in outer loop, alpha = 0.2855731205864114, rho = 1.0, h = 0.2855731205864114
model created with box penalty
cpu
iteration 1 in inner loop,alpha 0.2855731205864114 rho 1.0 h 0.15778945700017388
iteration 2 in inner loop,alpha 0.2855731205864114 rho 10.0 h 0.057422677149482126
iteration 2 in outer loop, alpha = 0.8597998920812326, rho = 10.0, h = 0.057422677149482126
model created with box penalty
cpu
iteration 1 in inner loop,alpha 0.8597998920812326 rho 10.0 h 0.0378950349318643
iteration 2 in inner loop,alpha 0.8597998920812326 rho 100.0 h 0.016471852091774153
iteration 3 in inner loop,alpha 0.8597998920812326 rho 1000.0 h 0.001737601982998882
iteration 3 in outer loop, alpha = 2.5974018750801147, rho = 1000.0, h = 0.001737601982998882
model created with box penalty
cpu
iteration 1 in inner loop,alpha 2.5974018750801147 rho 1000.0 h 0.0009355762507770038
iteration 2 in inner loop,alpha 2.5974018750801147 rho 10000.0 h 0.0003313582199417908
iteration 4 in outer loop, alpha = 5.910984074498023, rho = 10000.0, h = 0.0003313582199417908
model created with box penalty
cpu
iteration 1 in inner loop,alpha 5.910984074498023 rho 10000.0 h 0.0001902268167022214
iteration 2 in inner loop,alpha 5.910984074498023 rho 100000.0 h 7.034699317998161e-05
iteration 5 in outer loop, alpha = 12.945683392496184, rho = 100000.0, h = 7.034699317998161e-05
model created with box penalty
cpu
iteration 1 in inner loop,alpha 12.945683392496184 rho 100000.0 h 4.035102040589322e-05
iteration 6 in outer loop, alpha = 53.29670379838941, rho = 1000000.0, h = 4.035102040589322e-05
Threshold 0.3
[[0.    0.    2.425 0.    0.139 0.    0.096 0.    0.    0.013]
 [2.391 0.    0.    0.    0.    0.    0.    0.    0.    0.013]
 [0.002 0.    0.    0.    0.    0.    1.048 0.    0.    0.   ]
 [2.185 0.    0.026 0.    0.79  0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.003]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.001 0.    0.002 0.    0.    0.    0.    0.    0.    0.021]
 [0.001 0.    0.    0.    0.062 0.    0.    0.    0.    2.961]
 [0.015 0.    0.    0.    0.    0.    1.416 0.    0.    2.676]
 [0.    0.    0.    0.    1.826 0.    0.02  0.    0.    0.   ]]
[[0.    0.    2.425 0.    0.    0.    0.    0.    0.    0.   ]
 [2.391 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    1.048 0.    0.    0.   ]
 [2.185 0.    0.    0.    0.79  0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    2.961]
 [0.    0.    0.    0.    0.    0.    1.416 0.    0.    2.676]
 [0.    0.    0.    0.    1.826 0.    0.    0.    0.    0.   ]]
{'fdr': 0.0, 'tpr': 1.0, 'fpr': 0.0, 'f1': 1.0, 'shd': 0, 'npred': 9, 'ntrue': 9}
[0.000e+00 2.425e+00 0.000e+00 1.392e-01 0.000e+00 9.592e-02 0.000e+00
 0.000e+00 1.287e-02 2.391e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00
 0.000e+00 0.000e+00 0.000e+00 1.278e-02 1.605e-03 0.000e+00 0.000e+00
 0.000e+00 0.000e+00 1.048e+00 0.000e+00 0.000e+00 0.000e+00 2.185e+00
 0.000e+00 2.555e-02 7.895e-01 0.000e+00 0.000e+00 0.000e+00 0.000e+00
 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00
 0.000e+00 0.000e+00 2.520e-03 0.000e+00 0.000e+00 0.000e+00 0.000e+00
 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.360e-03 0.000e+00
 1.796e-03 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 2.051e-02
 1.132e-03 0.000e+00 0.000e+00 0.000e+00 6.220e-02 0.000e+00 0.000e+00
 0.000e+00 2.961e+00 1.497e-02 0.000e+00 0.000e+00 0.000e+00 0.000e+00
 0.000e+00 1.416e+00 0.000e+00 2.676e+00 0.000e+00 0.000e+00 0.000e+00
 0.000e+00 1.826e+00 0.000e+00 2.029e-02 0.000e+00 0.000e+00]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (1.0, 1.0)
model created with box penalty
number of groups for clipping  6  noise multiplier modified for group clipping  1.4696938456699067
cpu
noise_multiplier  1.4696938456699067  noise_multiplier_b  2.5  noise_multiplier_delta  1.5376193302972219
cpu
[0.677 0.971 0.689 0.72  0.572 0.805 0.858 0.756 0.945 0.892 0.832 0.999
 0.701 0.819 0.962 0.884 0.92  0.795 0.857 0.662 0.911 0.542 1.    0.831
 0.714 0.796 0.787 0.638 0.895 0.724 0.98  0.773 0.774 1.043 0.695 0.666
 0.874 0.634 0.669 0.644 1.119 0.724 0.793 0.718 0.874 0.939 0.946 0.811
 0.665 0.591 0.727 0.612 0.705 0.758 0.93  0.992 1.106 0.61  0.742 1.111
 0.988 0.962 0.805 0.585 0.422 0.708 0.696 1.144 0.799 0.772 0.964 0.851
 0.734 0.693 0.799 0.876 0.556 0.783 0.827 0.857 0.498 0.664 0.728 0.759
 0.857 0.843 0.79  1.055 0.884 0.778]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.5747599451303156, 0.13480677069860666)
Objective function 18342.84 = squared loss an data 10.47 + 0.5*rho*h**2 14845.719911 + alpha*h 0.000000 + L2reg 0.36 + L1reg -0.10 + box penalty 3486.40 ; SHD = 55 ; DAG False
Grad norm per param group for one microbatch
norm  14877.756707412125  clip  tensor([1.098])
norm  0.46472614437230286  clip  tensor([0.743])
norm  14919.636004288699  clip  tensor([1.084])
norm  0.46472614437230286  clip  tensor([0.744])
norm  5.533155843954944  clip  tensor([1.103])
norm  3.2201140681589706  clip  tensor([1.093])
Grad norm per param group for one microbatch
norm  1009.9004437755879  clip  tensor([1.724])
norm  0.3507930376610273  clip  tensor([0.478])
norm  1035.2211846606556  clip  tensor([1.685])
norm  0.3507930376610273  clip  tensor([0.466])
norm  4.026410502681104  clip  tensor([1.702])
norm  2.5792492213675877  clip  tensor([1.707])
Grad norm per param group for one microbatch
norm  494.2648986734269  clip  tensor([3.663])
norm  0.613760834159151  clip  tensor([0.427])
norm  499.48947711621383  clip  tensor([3.369])
norm  0.613760834159151  clip  tensor([0.428])
norm  8.027575916152495  clip  tensor([3.543])
norm  4.5091407610940895  clip  tensor([3.033])
Grad norm per param group for one microbatch
norm  268.347208485861  clip  tensor([7.107])
norm  0.881553935270021  clip  tensor([0.470])
norm  270.41298438095055  clip  tensor([6.293])
norm  0.881553935270021  clip  tensor([0.476])
norm  10.099667664766686  clip  tensor([4.999])
norm  6.179217579513339  clip  tensor([3.243])
Grad norm per param group for one microbatch
norm  177.43052766684298  clip  tensor([9.365])
norm  0.46396682663795696  clip  tensor([0.478])
norm  179.21403013131453  clip  tensor([8.387])
norm  0.46396682663795696  clip  tensor([0.479])
norm  4.70698400445117  clip  tensor([5.105])
norm  2.9698236907878854  clip  tensor([3.263])
Grad norm per param group for one microbatch
norm  4.366151682381476  clip  tensor([2.110])
norm  0.8053370710769636  clip  tensor([0.531])
norm  4.2556515138040085  clip  tensor([2.034])
norm  0.8053370710769636  clip  tensor([0.535])
norm  8.610296172737147  clip  tensor([4.951])
norm  5.152975176239049  clip  tensor([3.085])
Grad norm per param group for one microbatch
norm  1.896744386896053  clip  tensor([2.043])
norm  0.48757269531026337  clip  tensor([0.590])
norm  1.7024013913417313  clip  tensor([2.166])
norm  0.48757269531026337  clip  tensor([0.584])
norm  4.222199357419571  clip  tensor([4.973])
norm  2.7562154737060474  clip  tensor([3.141])
Grad norm per param group for one microbatch
norm  1.9238767565317305  clip  tensor([2.112])
norm  0.6066418033956043  clip  tensor([0.594])
norm  2.0688910889832326  clip  tensor([2.137])
norm  0.6066418033956043  clip  tensor([0.586])
norm  4.735757340767039  clip  tensor([4.938])
norm  3.072650093118571  clip  tensor([3.131])
Grad norm per param group for one microbatch
norm  5.448025029096327  clip  tensor([2.160])
norm  1.0741529685313245  clip  tensor([0.622])
norm  5.450645234929902  clip  tensor([2.184])
norm  1.0741529685313245  clip  tensor([0.636])
norm  8.008175889679876  clip  tensor([5.023])
norm  5.206911312814027  clip  tensor([3.167])
Grad norm per param group for one microbatch
norm  3.026623319271074  clip  tensor([2.263])
norm  0.7918049814607141  clip  tensor([0.639])
norm  3.014365676957912  clip  tensor([2.231])
norm  0.7918049814607141  clip  tensor([0.637])
norm  6.103678925848439  clip  tensor([4.721])
norm  3.7864095149556887  clip  tensor([2.979])
Grad norm per param group for one microbatch
norm  2.6102773263004324  clip  tensor([2.553])
norm  0.675311827945314  clip  tensor([0.728])
norm  2.4235327984807933  clip  tensor([2.575])
norm  0.675311827945314  clip  tensor([0.729])
norm  4.438525703036734  clip  tensor([4.590])
norm  2.74243263266085  clip  tensor([2.941])
Grad norm per param group for one microbatch
norm  4.648019505183565  clip  tensor([3.558])
norm  1.010811722682523  clip  tensor([0.906])
norm  4.717929826971651  clip  tensor([3.449])
norm  1.010811722682523  clip  tensor([0.926])
norm  5.304145181870123  clip  tensor([4.160])
norm  3.51955372370131  clip  tensor([2.628])
Grad norm per param group for one microbatch
norm  4.1265208979559  clip  tensor([3.962])
norm  1.023495016207142  clip  tensor([0.981])
norm  4.161102977173027  clip  tensor([3.864])
norm  1.023495016207142  clip  tensor([0.988])
norm  4.209609655779985  clip  tensor([3.991])
norm  2.7542953268277706  clip  tensor([2.561])
Grad norm per param group for one microbatch
norm  10.438952381410747  clip  tensor([3.924])
norm  1.787607432893032  clip  tensor([1.016])
norm  10.601556912370214  clip  tensor([3.971])
norm  1.787607432893032  clip  tensor([1.028])
norm  6.997393260331941  clip  tensor([4.091])
norm  4.338391139464233  clip  tensor([2.618])
Grad norm per param group for one microbatch
norm  3.885344418784185  clip  tensor([4.629])
norm  0.7598745721411507  clip  tensor([1.207])
norm  3.700252550047046  clip  tensor([4.707])
norm  0.7598745721411507  clip  tensor([1.184])
norm  2.6396654934913393  clip  tensor([4.467])
norm  1.6655053909889328  clip  tensor([2.817])
cpu
[0.175 0.375 0.198 0.121 0.194 0.245 0.176 0.111 0.147 0.413 0.265 0.23
 0.228 0.175 0.138 0.184 0.215 0.128 0.354 0.133 0.19  0.2   0.177 0.264
 0.214 0.157 0.116 0.598 0.164 0.184 0.214 0.237 0.144 0.174 0.206 0.267
 0.211 0.115 0.103 0.194 0.122 0.198 0.156 0.185 0.36  0.142 0.135 0.126
 0.151 0.126 0.336 0.136 0.268 0.303 0.164 0.136 0.352 0.196 0.269 0.151
 0.19  0.157 0.188 0.231 0.244 0.228 0.163 0.313 0.277 0.169 0.159 0.656
 0.227 0.32  0.132 0.183 0.166 0.168 0.461 0.122 0.395 0.131 0.214 0.124
 0.103 0.41  0.079 0.082 0.249 0.248]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9492455418381344, 0.8516339869281047)
Objective function 7.38 = squared loss an data 5.34 + 0.5*rho*h**2 0.398719 + alpha*h 0.000000 + L2reg 0.21 + L1reg 1.37 + box penalty 0.06 ; SHD = 12 ; DAG False
Proportion of microbatches that were clipped  [0.7910617243896504, 0.7788141779544164, 0.7928461351285587, 0.7800308216400357, 0.7915483818638981, 0.7869251358585448]
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 0.8929933580641212
iteration 1 in outer loop, alpha = 0.8929933580641212, rho = 1.0, h = 0.8929933580641212
cpu
noise_multiplier  1.4696938456699067  noise_multiplier_b  2.5  noise_multiplier_delta  1.5376193302972219
cpu
[0.175 0.375 0.198 0.121 0.194 0.245 0.176 0.111 0.147 0.413 0.265 0.23
 0.228 0.175 0.138 0.184 0.215 0.128 0.354 0.133 0.19  0.2   0.177 0.264
 0.214 0.157 0.116 0.598 0.164 0.184 0.214 0.237 0.144 0.174 0.206 0.267
 0.211 0.115 0.103 0.194 0.122 0.198 0.156 0.185 0.36  0.142 0.135 0.126
 0.151 0.126 0.336 0.136 0.268 0.303 0.164 0.136 0.352 0.196 0.269 0.151
 0.19  0.157 0.188 0.231 0.244 0.228 0.163 0.313 0.277 0.169 0.159 0.656
 0.227 0.32  0.132 0.183 0.166 0.168 0.461 0.122 0.395 0.131 0.214 0.124
 0.103 0.41  0.079 0.082 0.249 0.248]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9492455418381344, 0.8516339869281047)
Objective function 8.17 = squared loss an data 5.34 + 0.5*rho*h**2 0.398719 + alpha*h 0.797437 + L2reg 0.21 + L1reg 1.37 + box penalty 0.06 ; SHD = 12 ; DAG False
Grad norm per param group for one microbatch
norm  10.247595596572728  clip  tensor([4.855])
norm  2.1112105827157697  clip  tensor([1.262])
norm  10.331222409997558  clip  tensor([4.402])
norm  2.1112105827157697  clip  tensor([1.257])
norm  5.882985849015926  clip  tensor([4.090])
norm  3.5227240324496516  clip  tensor([2.695])
Grad norm per param group for one microbatch
norm  6.715488558630847  clip  tensor([4.855])
norm  1.444379159541154  clip  tensor([1.262])
norm  6.798672844000648  clip  tensor([4.402])
norm  1.444379159541154  clip  tensor([1.257])
norm  5.056636383454851  clip  tensor([4.090])
norm  3.2322299724873957  clip  tensor([2.695])
Grad norm per param group for one microbatch
norm  6.2317974218978405  clip  tensor([4.739])
norm  1.506968605464024  clip  tensor([1.176])
norm  5.932159097727363  clip  tensor([4.595])
norm  1.506968605464024  clip  tensor([1.163])
norm  4.449258306581194  clip  tensor([3.967])
norm  2.7221907636256435  clip  tensor([2.465])
Grad norm per param group for one microbatch
norm  3.9623425433574124  clip  tensor([5.107])
norm  1.2047321391255281  clip  tensor([1.265])
norm  3.9712328506148324  clip  tensor([4.974])
norm  1.2047321391255281  clip  tensor([1.260])
norm  3.63559131372844  clip  tensor([4.191])
norm  2.3447612277842023  clip  tensor([2.704])
Grad norm per param group for one microbatch
norm  10.545424566321355  clip  tensor([4.949])
norm  2.0362315397013084  clip  tensor([1.331])
norm  10.250027191231027  clip  tensor([4.907])
norm  2.0362315397013084  clip  tensor([1.319])
norm  5.10344467087181  clip  tensor([3.946])
norm  3.207924998701487  clip  tensor([2.474])
Grad norm per param group for one microbatch
norm  8.829858903830688  clip  tensor([5.536])
norm  2.0029297487671274  clip  tensor([1.456])
norm  8.771852350370496  clip  tensor([5.603])
norm  2.0029297487671274  clip  tensor([1.472])
norm  5.1542303769726265  clip  tensor([4.097])
norm  3.3067122073151167  clip  tensor([2.579])
Grad norm per param group for one microbatch
norm  10.708636364125246  clip  tensor([5.841])
norm  2.4684810424858745  clip  tensor([1.475])
norm  10.695223773025681  clip  tensor([5.519])
norm  2.4684810424858745  clip  tensor([1.496])
norm  4.887268695312841  clip  tensor([4.011])
norm  3.019150779365503  clip  tensor([2.527])
Grad norm per param group for one microbatch
norm  11.207862428785546  clip  tensor([5.784])
norm  2.030336656942946  clip  tensor([1.468])
norm  11.01843623048742  clip  tensor([5.528])
norm  2.030336656942946  clip  tensor([1.474])
norm  5.57618043096096  clip  tensor([3.897])
norm  3.4366767745622195  clip  tensor([2.432])
cpu
[0.242 0.316 0.323 0.273 0.199 0.156 0.142 0.195 0.229 0.338 0.196 0.195
 0.288 0.286 0.125 0.225 0.14  0.208 0.218 0.184 0.158 0.206 0.199 0.3
 0.165 0.165 0.307 0.409 0.163 0.247 0.307 0.184 0.183 0.172 0.158 0.209
 0.225 0.205 0.112 0.247 0.202 0.169 0.185 0.136 0.29  0.161 0.206 0.181
 0.333 0.184 0.167 0.388 0.221 0.112 0.225 0.202 0.244 0.16  0.186 0.165
 0.265 0.222 0.174 0.194 0.175 0.208 0.161 0.161 0.256 0.099 0.14  0.376
 0.171 0.263 0.127 0.183 0.28  0.276 0.428 0.279 0.257 0.121 0.206 0.166
 0.166 0.421 0.228 0.274 0.27  0.269]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9615912208504801, 0.7807407407407407)
Objective function 7.62 = squared loss an data 4.66 + 0.5*rho*h**2 0.238698 + alpha*h 0.617004 + L2reg 0.44 + L1reg 1.64 + box penalty 0.03 ; SHD = 8 ; DAG False
Proportion of microbatches that were clipped  [0.7936751860239405, 0.7827563895179553, 0.7962633451957295, 0.7800873503720479, 0.7902782271109673, 0.7864768683274022]
iteration 1 in inner loop, alpha 0.8929933580641212 rho 1.0 h 0.6909387061553698
noise_multiplier  1.4696938456699067  noise_multiplier_b  2.5  noise_multiplier_delta  1.5376193302972219
cpu
[0.242 0.316 0.323 0.273 0.199 0.156 0.142 0.195 0.229 0.338 0.196 0.195
 0.288 0.286 0.125 0.225 0.14  0.208 0.218 0.184 0.158 0.206 0.199 0.3
 0.165 0.165 0.307 0.409 0.163 0.247 0.307 0.184 0.183 0.172 0.158 0.209
 0.225 0.205 0.112 0.247 0.202 0.169 0.185 0.136 0.29  0.161 0.206 0.181
 0.333 0.184 0.167 0.388 0.221 0.112 0.225 0.202 0.244 0.16  0.186 0.165
 0.265 0.222 0.174 0.194 0.175 0.208 0.161 0.161 0.256 0.099 0.14  0.376
 0.171 0.263 0.127 0.183 0.28  0.276 0.428 0.279 0.257 0.121 0.206 0.166
 0.166 0.421 0.228 0.274 0.27  0.269]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9615912208504801, 0.7807407407407407)
Objective function 9.77 = squared loss an data 4.66 + 0.5*rho*h**2 2.386981 + alpha*h 0.617004 + L2reg 0.44 + L1reg 1.64 + box penalty 0.03 ; SHD = 8 ; DAG False
Grad norm per param group for one microbatch
norm  12.050137865440751  clip  tensor([8.036])
norm  2.6386949795519357  clip  tensor([2.015])
norm  11.3815558823961  clip  tensor([7.876])
norm  2.6386949795519357  clip  tensor([1.990])
norm  4.931539124523147  clip  tensor([4.381])
norm  3.2095911249932607  clip  tensor([2.755])
Grad norm per param group for one microbatch
norm  6.615375822799767  clip  tensor([6.943])
norm  2.381128299402426  clip  tensor([1.866])
norm  6.580879270186654  clip  tensor([7.071])
norm  2.381128299402426  clip  tensor([1.861])
norm  4.302505655585191  clip  tensor([3.971])
norm  2.6628671426578694  clip  tensor([2.546])
Grad norm per param group for one microbatch
norm  17.373750942085827  clip  tensor([6.671])
norm  3.1819672871990825  clip  tensor([1.799])
norm  17.23730932105219  clip  tensor([6.703])
norm  3.1819672871990825  clip  tensor([1.812])
norm  6.513681087271233  clip  tensor([4.032])
norm  4.090353875983423  clip  tensor([2.617])
Grad norm per param group for one microbatch
norm  13.894786140772897  clip  tensor([7.173])
norm  3.2515830687439498  clip  tensor([1.962])
norm  13.91778123554813  clip  tensor([7.213])
norm  3.2515830687439498  clip  tensor([1.955])
norm  5.58243896157115  clip  tensor([4.125])
norm  3.440077030665047  clip  tensor([2.613])
Grad norm per param group for one microbatch
norm  10.85119276688267  clip  tensor([7.461])
norm  2.6077178789080033  clip  tensor([2.048])
norm  10.637844489702521  clip  tensor([7.551])
norm  2.6077178789080033  clip  tensor([2.004])
norm  4.936607966660626  clip  tensor([4.085])
norm  3.0263032182875786  clip  tensor([2.552])
Grad norm per param group for one microbatch
norm  11.93192713645489  clip  tensor([7.355])
norm  2.626473177171035  clip  tensor([2.017])
norm  11.89472992928945  clip  tensor([7.487])
norm  2.626473177171035  clip  tensor([1.989])
norm  3.8953470946870072  clip  tensor([4.135])
norm  2.4382023471346317  clip  tensor([2.616])
Grad norm per param group for one microbatch
norm  18.79848921046452  clip  tensor([7.331])
norm  3.5724052483819624  clip  tensor([1.967])
norm  19.035524702047034  clip  tensor([7.449])
norm  3.5724052483819624  clip  tensor([1.974])
norm  6.206457644922424  clip  tensor([3.883])
norm  3.8881798646458323  clip  tensor([2.570])
Grad norm per param group for one microbatch
norm  11.212590024670014  clip  tensor([7.722])
norm  2.4597172506266336  clip  tensor([2.073])
norm  11.10565986003517  clip  tensor([7.942])
norm  2.4597172506266336  clip  tensor([2.033])
norm  5.101721082171786  clip  tensor([4.162])
norm  3.2626776801950395  clip  tensor([2.674])
cpu
[0.221 0.419 0.179 0.287 0.271 0.187 0.183 0.119 0.252 0.267 0.157 0.211
 0.28  0.134 0.146 0.284 0.136 0.25  0.154 0.23  0.216 0.16  0.15  0.21
 0.244 0.124 0.181 0.328 0.148 0.15  0.244 0.195 0.125 0.247 0.155 0.215
 0.106 0.152 0.206 0.225 0.187 0.134 0.261 0.253 0.224 0.169 0.218 0.167
 0.117 0.142 0.163 0.12  0.136 0.201 0.193 0.088 0.247 0.213 0.257 0.155
 0.184 0.223 0.1   0.138 0.162 0.136 0.113 0.243 0.297 0.156 0.14  0.339
 0.38  0.28  0.215 0.206 0.168 0.377 0.287 0.328 0.346 0.087 0.159 0.191
 0.175 0.26  0.188 0.203 0.25  0.202]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.8916323731138546, 0.5024060906413848)
Objective function 8.44 = squared loss an data 5.35 + 0.5*rho*h**2 0.401824 + alpha*h 0.253152 + L2reg 0.59 + L1reg 1.77 + box penalty 0.07 ; SHD = 8 ; DAG True
Proportion of microbatches that were clipped  [0.7995790836975878, 0.7854945766553343, 0.794641411688522, 0.7844422858993039, 0.791403593977659, 0.7872753763963088]
iteration 2 in inner loop, alpha 0.8929933580641212 rho 10.0 h 0.2834867647955992
noise_multiplier  1.4696938456699067  noise_multiplier_b  2.5  noise_multiplier_delta  1.5376193302972219
cpu
[0.221 0.419 0.179 0.287 0.271 0.187 0.183 0.119 0.252 0.267 0.157 0.211
 0.28  0.134 0.146 0.284 0.136 0.25  0.154 0.23  0.216 0.16  0.15  0.21
 0.244 0.124 0.181 0.328 0.148 0.15  0.244 0.195 0.125 0.247 0.155 0.215
 0.106 0.152 0.206 0.225 0.187 0.134 0.261 0.253 0.224 0.169 0.218 0.167
 0.117 0.142 0.163 0.12  0.136 0.201 0.193 0.088 0.247 0.213 0.257 0.155
 0.184 0.223 0.1   0.138 0.162 0.136 0.113 0.243 0.297 0.156 0.14  0.339
 0.38  0.28  0.215 0.206 0.168 0.377 0.287 0.328 0.346 0.087 0.159 0.191
 0.175 0.26  0.188 0.203 0.25  0.202]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.8916323731138546, 0.5024060906413848)
Objective function 12.05 = squared loss an data 5.35 + 0.5*rho*h**2 4.018237 + alpha*h 0.253152 + L2reg 0.59 + L1reg 1.77 + box penalty 0.07 ; SHD = 8 ; DAG True
Grad norm per param group for one microbatch
norm  21.699890236636715  clip  tensor([2.245])
norm  3.9745351068930863  clip  tensor([2.033])
norm  21.936528800170137  clip  tensor([2.306])
norm  3.9745351068930863  clip  tensor([2.028])
norm  7.064674957161201  clip  tensor([2.186])
norm  4.582302350372039  clip  tensor([2.091])
Grad norm per param group for one microbatch
norm  10.129028906015789  clip  tensor([2.954])
norm  2.392763277443819  clip  tensor([2.322])
norm  10.565787773742079  clip  tensor([2.987])
norm  2.392763277443819  clip  tensor([2.308])
norm  4.36054501283577  clip  tensor([2.811])
norm  2.8921598450977917  clip  tensor([2.613])
Grad norm per param group for one microbatch
norm  12.11750152407645  clip  tensor([3.503])
norm  2.7930082955851083  clip  tensor([2.308])
norm  11.928086806930235  clip  tensor([3.590])
norm  2.7930082955851083  clip  tensor([2.280])
norm  5.521430862127101  clip  tensor([3.308])
norm  3.629125324103756  clip  tensor([2.851])
Grad norm per param group for one microbatch
norm  8.988058371896118  clip  tensor([9.370])
norm  1.727959007038407  clip  tensor([2.300])
norm  8.617049093721866  clip  tensor([9.446])
norm  1.727959007038407  clip  tensor([2.345])
norm  4.790733240763523  clip  tensor([4.363])
norm  3.204120480691921  clip  tensor([2.773])
Grad norm per param group for one microbatch
norm  14.336705382694618  clip  tensor([8.822])
norm  3.57278110006454  clip  tensor([2.360])
norm  14.456026584905715  clip  tensor([8.635])
norm  3.57278110006454  clip  tensor([2.383])
norm  5.81961869614777  clip  tensor([4.478])
norm  3.6226057385020676  clip  tensor([2.834])
Grad norm per param group for one microbatch
norm  7.968459406375423  clip  tensor([7.808])
norm  2.3720855982611644  clip  tensor([2.207])
norm  7.888850786723211  clip  tensor([8.060])
norm  2.3720855982611644  clip  tensor([2.216])
norm  3.557854474871672  clip  tensor([4.058])
norm  2.2566649010702564  clip  tensor([2.630])
Grad norm per param group for one microbatch
norm  11.592246316105665  clip  tensor([8.702])
norm  3.0001527414333236  clip  tensor([2.384])
norm  12.135003593258524  clip  tensor([8.665])
norm  3.0001527414333236  clip  tensor([2.359])
norm  5.873483548496464  clip  tensor([4.402])
norm  3.812340867135903  clip  tensor([2.885])
Grad norm per param group for one microbatch
norm  11.742265900103291  clip  tensor([8.912])
norm  3.0477753510578376  clip  tensor([2.404])
norm  11.760635108732416  clip  tensor([9.283])
norm  3.0477753510578376  clip  tensor([2.450])
norm  5.549570491751959  clip  tensor([4.594])
norm  3.5733946250892887  clip  tensor([2.989])
Grad norm per param group for one microbatch
norm  11.405862807230218  clip  tensor([8.825])
norm  3.5617906094505773  clip  tensor([2.568])
norm  11.857851323195732  clip  tensor([8.798])
norm  3.5617906094505773  clip  tensor([2.554])
norm  5.659320468841441  clip  tensor([4.755])
norm  3.6283241261540162  clip  tensor([3.067])
Grad norm per param group for one microbatch
norm  16.303009818290235  clip  tensor([7.854])
norm  3.492552723115023  clip  tensor([2.210])
norm  16.13491676422971  clip  tensor([7.976])
norm  3.492552723115023  clip  tensor([2.162])
norm  6.280399840210941  clip  tensor([4.313])
norm  3.941371503075595  clip  tensor([2.756])
Grad norm per param group for one microbatch
norm  9.842915551397684  clip  tensor([8.449])
norm  2.1802089715980166  clip  tensor([2.297])
norm  9.48759568368519  clip  tensor([8.344])
norm  2.1802089715980166  clip  tensor([2.316])
norm  4.818939522408324  clip  tensor([4.390])
norm  3.1197967697357267  clip  tensor([2.790])
Grad norm per param group for one microbatch
norm  12.044449696452732  clip  tensor([8.802])
norm  2.7907203356734067  clip  tensor([2.266])
norm  12.25003365015505  clip  tensor([8.886])
norm  2.7907203356734067  clip  tensor([2.296])
norm  5.27881733685713  clip  tensor([4.515])
norm  3.4094913280952865  clip  tensor([2.944])
cpu
[0.095 0.282 0.072 0.159 0.118 0.092 0.157 0.229 0.11  0.392 0.187 0.099
 0.115 0.206 0.108 0.109 0.113 0.119 0.204 0.177 0.138 0.121 0.204 0.239
 0.191 0.135 0.134 0.497 0.178 0.216 0.299 0.09  0.214 0.166 0.228 0.157
 0.126 0.13  0.081 0.062 0.116 0.167 0.16  0.197 0.189 0.171 0.112 0.103
 0.275 0.193 0.14  0.106 0.083 0.256 0.195 0.187 0.125 0.118 0.124 0.227
 0.142 0.123 0.256 0.133 0.181 0.124 0.221 0.149 0.338 0.153 0.12  0.446
 0.112 0.204 0.188 0.077 0.146 0.317 0.442 0.2   0.282 0.128 0.144 0.152
 0.104 0.27  0.108 0.086 0.096 0.097]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.98079561042524, 0.8457992624659292)
Objective function 9.36 = squared loss an data 6.40 + 0.5*rho*h**2 0.302790 + alpha*h 0.069492 + L2reg 0.59 + L1reg 1.95 + box penalty 0.05 ; SHD = 7 ; DAG True
Proportion of microbatches that were clipped  [0.8037583254043768, 0.7890104662226451, 0.8018553758325404, 0.7906755470980019, 0.7979701871233745, 0.7916270218839201]
iteration 3 in inner loop, alpha 0.8929933580641212 rho 100.0 h 0.07781903490200115
iteration 2 in outer loop, alpha = 8.674896848264236, rho = 100.0, h = 0.07781903490200115
cpu
noise_multiplier  1.4696938456699067  noise_multiplier_b  2.5  noise_multiplier_delta  1.5376193302972219
cpu
[0.095 0.282 0.072 0.159 0.118 0.092 0.157 0.229 0.11  0.392 0.187 0.099
 0.115 0.206 0.108 0.109 0.113 0.119 0.204 0.177 0.138 0.121 0.204 0.239
 0.191 0.135 0.134 0.497 0.178 0.216 0.299 0.09  0.214 0.166 0.228 0.157
 0.126 0.13  0.081 0.062 0.116 0.167 0.16  0.197 0.189 0.171 0.112 0.103
 0.275 0.193 0.14  0.106 0.083 0.256 0.195 0.187 0.125 0.118 0.124 0.227
 0.142 0.123 0.256 0.133 0.181 0.124 0.221 0.149 0.338 0.153 0.12  0.446
 0.112 0.204 0.188 0.077 0.146 0.317 0.442 0.2   0.282 0.128 0.144 0.152
 0.104 0.27  0.108 0.086 0.096 0.097]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.98079561042524, 0.8457992624659292)
Objective function 9.96 = squared loss an data 6.40 + 0.5*rho*h**2 0.302790 + alpha*h 0.675072 + L2reg 0.59 + L1reg 1.95 + box penalty 0.05 ; SHD = 7 ; DAG True
Grad norm per param group for one microbatch
norm  16.9685080293049  clip  tensor([5.562])
norm  3.7616035251348743  clip  tensor([2.495])
norm  16.986911469238983  clip  tensor([5.699])
norm  3.7616035251348743  clip  tensor([2.470])
norm  6.112499682984024  clip  tensor([4.301])
norm  3.9114378151984064  clip  tensor([2.964])
Grad norm per param group for one microbatch
norm  13.75885887793607  clip  tensor([8.574])
norm  3.4186437727105883  clip  tensor([2.264])
norm  13.745138545569883  clip  tensor([8.422])
norm  3.4186437727105883  clip  tensor([2.278])
norm  6.393725059017149  clip  tensor([4.569])
norm  3.9871137317783987  clip  tensor([2.789])
Grad norm per param group for one microbatch
norm  10.317379819843303  clip  tensor([9.329])
norm  2.5551190110840505  clip  tensor([2.400])
norm  9.73269769141358  clip  tensor([8.958])
norm  2.5551190110840505  clip  tensor([2.383])
norm  4.299672708867645  clip  tensor([4.533])
norm  2.7345706369112284  clip  tensor([2.852])
Grad norm per param group for one microbatch
norm  9.330588803189977  clip  tensor([9.665])
norm  1.9445108350216225  clip  tensor([2.411])
norm  9.75725419556717  clip  tensor([9.676])
norm  1.9445108350216225  clip  tensor([2.371])
norm  4.626285669936301  clip  tensor([4.850])
norm  3.0837270503566714  clip  tensor([3.041])
Grad norm per param group for one microbatch
norm  9.044632091905587  clip  tensor([8.933])
norm  2.3834995479568124  clip  tensor([2.350])
norm  8.174706265375344  clip  tensor([8.721])
norm  2.3834995479568124  clip  tensor([2.402])
norm  4.344809693149332  clip  tensor([4.481])
norm  2.84136251252569  clip  tensor([2.814])
Grad norm per param group for one microbatch
norm  15.70924476463609  clip  tensor([8.854])
norm  3.613816245981477  clip  tensor([2.312])
norm  15.466039447510713  clip  tensor([8.719])
norm  3.613816245981477  clip  tensor([2.243])
norm  5.404392459963048  clip  tensor([4.621])
norm  3.3893393799136358  clip  tensor([2.905])
Grad norm per param group for one microbatch
norm  10.697462102580415  clip  tensor([8.847])
norm  2.7635581111329244  clip  tensor([2.402])
norm  10.914057931840533  clip  tensor([8.671])
norm  2.7635581111329244  clip  tensor([2.407])
norm  4.84896517772933  clip  tensor([4.709])
norm  2.9355746213651814  clip  tensor([2.984])
Grad norm per param group for one microbatch
norm  16.40219108478553  clip  tensor([7.976])
norm  3.656947671669323  clip  tensor([2.228])
norm  16.586520961704874  clip  tensor([8.286])
norm  3.656947671669323  clip  tensor([2.182])
norm  7.442886011102792  clip  tensor([4.593])
norm  4.648165664666944  clip  tensor([2.823])
Grad norm per param group for one microbatch
norm  8.345952844286646  clip  tensor([8.952])
norm  1.9191784525354383  clip  tensor([2.204])
norm  8.439044883990627  clip  tensor([8.716])
norm  1.9191784525354383  clip  tensor([2.223])
norm  4.930259063015245  clip  tensor([4.645])
norm  3.240153299872916  clip  tensor([2.914])
Grad norm per param group for one microbatch
norm  15.487385997028424  clip  tensor([8.952])
norm  3.3567410998729255  clip  tensor([2.204])
norm  15.677677785723239  clip  tensor([8.716])
norm  3.3567410998729255  clip  tensor([2.223])
norm  6.305248637882545  clip  tensor([4.645])
norm  3.884414898958377  clip  tensor([2.914])
cpu
[0.063 0.207 0.107 0.21  0.092 0.21  0.067 0.196 0.146 0.488 0.145 0.108
 0.097 0.096 0.147 0.105 0.102 0.113 0.188 0.143 0.241 0.187 0.125 0.291
 0.156 0.197 0.186 0.489 0.174 0.113 0.276 0.237 0.151 0.152 0.166 0.202
 0.112 0.197 0.123 0.07  0.165 0.176 0.127 0.147 0.198 0.196 0.21  0.2
 0.138 0.227 0.094 0.043 0.102 0.267 0.129 0.147 0.151 0.154 0.106 0.145
 0.071 0.027 0.088 0.149 0.246 0.141 0.173 0.252 0.368 0.189 0.186 0.526
 0.125 0.235 0.141 0.106 0.115 0.145 0.652 0.104 0.348 0.211 0.163 0.119
 0.133 0.239 0.099 0.105 0.057 0.054]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9725651577503429, 0.8454924704924707)
Objective function 9.91 = squared loss an data 6.63 + 0.5*rho*h**2 0.151939 + alpha*h 0.478205 + L2reg 0.58 + L1reg 2.02 + box penalty 0.04 ; SHD = 5 ; DAG True
Proportion of microbatches that were clipped  [0.8030278884462151, 0.7888446215139442, 0.8022310756972112, 0.789800796812749, 0.7947410358565737, 0.7917928286852589]
iteration 1 in inner loop, alpha 8.674896848264236 rho 100.0 h 0.055125193221861934
noise_multiplier  1.4696938456699067  noise_multiplier_b  2.5  noise_multiplier_delta  1.5376193302972219
cpu
[0.063 0.207 0.107 0.21  0.092 0.21  0.067 0.196 0.146 0.488 0.145 0.108
 0.097 0.096 0.147 0.105 0.102 0.113 0.188 0.143 0.241 0.187 0.125 0.291
 0.156 0.197 0.186 0.489 0.174 0.113 0.276 0.237 0.151 0.152 0.166 0.202
 0.112 0.197 0.123 0.07  0.165 0.176 0.127 0.147 0.198 0.196 0.21  0.2
 0.138 0.227 0.094 0.043 0.102 0.267 0.129 0.147 0.151 0.154 0.106 0.145
 0.071 0.027 0.088 0.149 0.246 0.141 0.173 0.252 0.368 0.189 0.186 0.526
 0.125 0.235 0.141 0.106 0.115 0.145 0.652 0.104 0.348 0.211 0.163 0.119
 0.133 0.239 0.099 0.105 0.057 0.054]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9725651577503429, 0.8454924704924707)
Objective function 11.27 = squared loss an data 6.63 + 0.5*rho*h**2 1.519393 + alpha*h 0.478205 + L2reg 0.58 + L1reg 2.02 + box penalty 0.04 ; SHD = 5 ; DAG True
Grad norm per param group for one microbatch
norm  10.520802416987813  clip  tensor([1.444])
norm  2.0512794717436424  clip  tensor([1.481])
norm  9.961349644132891  clip  tensor([1.431])
norm  2.0512794717436424  clip  tensor([1.404])
norm  4.981353266543866  clip  tensor([1.468])
norm  3.080786412326956  clip  tensor([1.426])
Grad norm per param group for one microbatch
norm  13.507989659449057  clip  tensor([2.054])
norm  2.835188504971819  clip  tensor([2.008])
norm  13.680041154730878  clip  tensor([2.041])
norm  2.835188504971819  clip  tensor([1.926])
norm  6.555776374950938  clip  tensor([2.099])
norm  4.201003629767084  clip  tensor([2.029])
Grad norm per param group for one microbatch
norm  8.361500114232387  clip  tensor([10.006])
norm  1.6095050876883485  clip  tensor([2.406])
norm  8.77376422112551  clip  tensor([10.779])
norm  1.6095050876883485  clip  tensor([2.473])
norm  3.9298092204652053  clip  tensor([4.796])
norm  2.5087526045514372  clip  tensor([3.049])
Grad norm per param group for one microbatch
norm  11.94898398420486  clip  tensor([10.295])
norm  2.554216662667697  clip  tensor([2.463])
norm  11.102769624093593  clip  tensor([10.587])
norm  2.554216662667697  clip  tensor([2.502])
norm  5.546428154750801  clip  tensor([4.902])
norm  3.561959783061997  clip  tensor([3.088])
Grad norm per param group for one microbatch
norm  8.416166365519441  clip  tensor([9.090])
norm  1.9941681131774098  clip  tensor([2.476])
norm  8.632509384986578  clip  tensor([9.425])
norm  1.9941681131774098  clip  tensor([2.451])
norm  4.596410896956693  clip  tensor([4.864])
norm  2.9557153059949166  clip  tensor([3.017])
Grad norm per param group for one microbatch
norm  6.90831589468791  clip  tensor([9.123])
norm  1.5079919891314697  clip  tensor([2.323])
norm  7.655440210031873  clip  tensor([9.104])
norm  1.5079919891314697  clip  tensor([2.340])
norm  4.061949754402662  clip  tensor([4.635])
norm  2.6534493842608304  clip  tensor([2.913])
Grad norm per param group for one microbatch
norm  22.91926644650683  clip  tensor([9.066])
norm  3.7987177262620024  clip  tensor([2.443])
norm  22.95844057294854  clip  tensor([9.108])
norm  3.7987177262620024  clip  tensor([2.468])
norm  7.956410398307366  clip  tensor([4.868])
norm  5.129020525644275  clip  tensor([2.984])
Grad norm per param group for one microbatch
norm  18.073386770802365  clip  tensor([9.908])
norm  3.8374040337253397  clip  tensor([2.376])
norm  17.81611569631514  clip  tensor([9.711])
norm  3.8374040337253397  clip  tensor([2.343])
norm  7.437707039328703  clip  tensor([4.756])
norm  4.534481455290445  clip  tensor([2.992])
Grad norm per param group for one microbatch
norm  7.084868114090187  clip  tensor([9.655])
norm  1.9570422829462795  clip  tensor([2.380])
norm  7.727425768238193  clip  tensor([9.831])
norm  1.9570422829462795  clip  tensor([2.398])
norm  3.366460256984799  clip  tensor([4.710])
norm  2.173630616395393  clip  tensor([3.057])
Grad norm per param group for one microbatch
norm  19.205938501176345  clip  tensor([9.323])
norm  4.074210551918691  clip  tensor([2.468])
norm  19.44423111278614  clip  tensor([9.400])
norm  4.074210551918691  clip  tensor([2.477])
norm  6.900222574113683  clip  tensor([4.858])
norm  4.013303457047554  clip  tensor([3.041])
cpu
[0.051 0.156 0.05  0.139 0.069 0.117 0.071 0.066 0.08  0.47  0.219 0.187
 0.235 0.169 0.113 0.154 0.098 0.133 0.216 0.1   0.074 0.115 0.114 0.127
 0.129 0.057 0.159 0.424 0.08  0.215 0.274 0.161 0.18  0.207 0.065 0.141
 0.113 0.06  0.158 0.064 0.108 0.104 0.074 0.124 0.227 0.322 0.087 0.097
 0.068 0.18  0.161 0.065 0.075 0.171 0.098 0.129 0.228 0.077 0.15  0.11
 0.069 0.03  0.159 0.286 0.097 0.096 0.049 0.212 0.308 0.243 0.068 0.741
 0.217 0.074 0.229 0.195 0.127 0.197 0.645 0.262 0.404 0.218 0.096 0.133
 0.11  0.131 0.1   0.1   0.024 0.032]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.8600823045267489, 0.6947550034506556)
Objective function 10.25 = squared loss an data 7.07 + 0.5*rho*h**2 0.230268 + alpha*h 0.186164 + L2reg 0.56 + L1reg 2.17 + box penalty 0.04 ; SHD = 6 ; DAG True
Proportion of microbatches that were clipped  [0.8008084074373484, 0.7864187550525464, 0.7986257073565077, 0.7860953920776071, 0.7921584478577203, 0.7860953920776071]
iteration 2 in inner loop, alpha 8.674896848264236 rho 1000.0 h 0.02146011600028075
noise_multiplier  1.4696938456699067  noise_multiplier_b  2.5  noise_multiplier_delta  1.5376193302972219
cpu
[0.051 0.156 0.05  0.139 0.069 0.117 0.071 0.066 0.08  0.47  0.219 0.187
 0.235 0.169 0.113 0.154 0.098 0.133 0.216 0.1   0.074 0.115 0.114 0.127
 0.129 0.057 0.159 0.424 0.08  0.215 0.274 0.161 0.18  0.207 0.065 0.141
 0.113 0.06  0.158 0.064 0.108 0.104 0.074 0.124 0.227 0.322 0.087 0.097
 0.068 0.18  0.161 0.065 0.075 0.171 0.098 0.129 0.228 0.077 0.15  0.11
 0.069 0.03  0.159 0.286 0.097 0.096 0.049 0.212 0.308 0.243 0.068 0.741
 0.217 0.074 0.229 0.195 0.127 0.197 0.645 0.262 0.404 0.218 0.096 0.133
 0.11  0.131 0.1   0.1   0.024 0.032]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.8600823045267489, 0.6947550034506556)
Objective function 12.33 = squared loss an data 7.07 + 0.5*rho*h**2 2.302683 + alpha*h 0.186164 + L2reg 0.56 + L1reg 2.17 + box penalty 0.04 ; SHD = 6 ; DAG True
Grad norm per param group for one microbatch
norm  16.156552543372587  clip  tensor([12.956])
norm  3.223425601611544  clip  tensor([2.390])
norm  16.00166125090708  clip  tensor([12.631])
norm  3.223425601611544  clip  tensor([2.390])
norm  6.538580457749912  clip  tensor([4.600])
norm  4.3183978493951765  clip  tensor([2.981])
Grad norm per param group for one microbatch
norm  9.829983458752952  clip  tensor([13.238])
norm  1.823550837993847  clip  tensor([2.339])
norm  9.28994724043184  clip  tensor([13.286])
norm  1.823550837993847  clip  tensor([2.374])
norm  3.6782854184084384  clip  tensor([4.679])
norm  2.4207599882697277  clip  tensor([3.017])
Grad norm per param group for one microbatch
norm  21.257364122162716  clip  tensor([13.557])
norm  3.4865860342551507  clip  tensor([2.475])
norm  21.31283635170246  clip  tensor([13.662])
norm  3.4865860342551507  clip  tensor([2.469])
norm  7.5641319772664  clip  tensor([4.924])
norm  4.8501907618682  clip  tensor([3.189])
Grad norm per param group for one microbatch
norm  14.863790872053304  clip  tensor([11.671])
norm  2.6485398243571283  clip  tensor([2.560])
norm  14.827973135441324  clip  tensor([11.666])
norm  2.6485398243571283  clip  tensor([2.498])
norm  6.477235201555943  clip  tensor([5.000])
norm  4.116194677461395  clip  tensor([3.237])
Grad norm per param group for one microbatch
norm  16.413597480734655  clip  tensor([9.456])
norm  3.7335041753133584  clip  tensor([2.154])
norm  16.551322383805516  clip  tensor([9.298])
norm  3.7335041753133584  clip  tensor([2.148])
norm  7.383750016585125  clip  tensor([4.361])
norm  4.710378898953581  clip  tensor([2.826])
Grad norm per param group for one microbatch
norm  14.949073975337933  clip  tensor([9.679])
norm  3.134703228160285  clip  tensor([2.326])
norm  14.917566268246238  clip  tensor([9.509])
norm  3.134703228160285  clip  tensor([2.399])
norm  6.05412741806575  clip  tensor([4.563])
norm  3.6761621083943488  clip  tensor([2.913])
Grad norm per param group for one microbatch
norm  12.80865123912856  clip  tensor([10.122])
norm  3.024529599115062  clip  tensor([2.377])
norm  12.989248297412582  clip  tensor([10.206])
norm  3.024529599115062  clip  tensor([2.399])
norm  4.674135517697922  clip  tensor([4.837])
norm  2.908004753974  clip  tensor([3.120])
Grad norm per param group for one microbatch
norm  11.551009069869703  clip  tensor([9.522])
norm  3.40896232879521  clip  tensor([2.272])
norm  11.301602902018407  clip  tensor([9.749])
norm  3.40896232879521  clip  tensor([2.251])
norm  5.133458338198371  clip  tensor([4.597])
norm  3.3603349839179315  clip  tensor([3.023])
Grad norm per param group for one microbatch
norm  14.56586208173462  clip  tensor([9.871])
norm  3.223170521751824  clip  tensor([2.285])
norm  14.35860821336674  clip  tensor([9.769])
norm  3.223170521751824  clip  tensor([2.268])
norm  5.564227374362031  clip  tensor([4.621])
norm  3.5116339240145686  clip  tensor([3.024])
Grad norm per param group for one microbatch
norm  23.721647606865254  clip  tensor([10.654])
norm  4.03009242100379  clip  tensor([2.401])
norm  23.657013675129935  clip  tensor([10.601])
norm  4.03009242100379  clip  tensor([2.364])
norm  8.472912804553447  clip  tensor([5.124])
norm  5.408568183012335  clip  tensor([3.195])
Grad norm per param group for one microbatch
norm  10.602752086898803  clip  tensor([10.221])
norm  2.231755030557752  clip  tensor([2.237])
norm  10.43855225846877  clip  tensor([10.083])
norm  2.231755030557752  clip  tensor([2.248])
norm  4.24115758763474  clip  tensor([4.657])
norm  2.614077129830023  clip  tensor([3.080])
Grad norm per param group for one microbatch
norm  16.620312963436966  clip  tensor([10.157])
norm  3.3694319941281465  clip  tensor([2.291])
norm  16.689119649761064  clip  tensor([10.025])
norm  3.3694319941281465  clip  tensor([2.268])
norm  6.73542372533014  clip  tensor([4.692])
norm  4.23625051056904  clip  tensor([2.993])
Grad norm per param group for one microbatch
norm  10.13221645626776  clip  tensor([9.731])
norm  2.862630962491319  clip  tensor([2.268])
norm  10.008066398692744  clip  tensor([9.660])
norm  2.862630962491319  clip  tensor([2.231])
norm  5.351172976460377  clip  tensor([4.680])
norm  3.4944171804673902  clip  tensor([2.993])
Grad norm per param group for one microbatch
norm  13.59322761500952  clip  tensor([10.639])
norm  3.0077927613024387  clip  tensor([2.377])
norm  13.452296467842052  clip  tensor([10.765])
norm  3.0077927613024387  clip  tensor([2.336])
norm  5.427513771389851  clip  tensor([4.926])
norm  3.4790900478206472  clip  tensor([3.133])
cpu
[0.02  0.055 0.028 0.066 0.062 0.054 0.073 0.039 0.203 0.533 0.206 0.12
 0.188 0.108 0.238 0.059 0.152 0.251 0.313 0.061 0.028 0.078 0.196 0.262
 0.055 0.046 0.117 0.554 0.074 0.367 0.105 0.101 0.052 0.087 0.05  0.197
 0.135 0.06  0.121 0.104 0.097 0.062 0.046 0.052 0.429 0.161 0.11  0.055
 0.133 0.071 0.122 0.054 0.057 0.123 0.203 0.076 0.046 0.135 0.107 0.087
 0.083 0.025 0.127 0.103 0.141 0.165 0.1   0.317 0.198 0.128 0.101 0.996
 0.222 0.084 0.18  0.226 0.175 0.245 0.553 0.096 0.451 0.062 0.033 0.089
 0.056 0.033 0.073 0.079 0.011 0.024]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.7558299039780522, 0.6649911816578484)
Objective function 10.52 = squared loss an data 7.46 + 0.5*rho*h**2 0.237909 + alpha*h 0.059839 + L2reg 0.52 + L1reg 2.21 + box penalty 0.03 ; SHD = 6 ; DAG True
Proportion of microbatches that were clipped  [0.8005661140315407, 0.7843105539830166, 0.8000808734330772, 0.7852001617468661, 0.7942579862515163, 0.7873028710068742]
iteration 3 in inner loop, alpha 8.674896848264236 rho 10000.0 h 0.00689795089417089
iteration 3 in outer loop, alpha = 77.65440578997314, rho = 10000.0, h = 0.00689795089417089
cpu
noise_multiplier  1.4696938456699067  noise_multiplier_b  2.5  noise_multiplier_delta  1.5376193302972219
cpu
[0.02  0.055 0.028 0.066 0.062 0.054 0.073 0.039 0.203 0.533 0.206 0.12
 0.188 0.108 0.238 0.059 0.152 0.251 0.313 0.061 0.028 0.078 0.196 0.262
 0.055 0.046 0.117 0.554 0.074 0.367 0.105 0.101 0.052 0.087 0.05  0.197
 0.135 0.06  0.121 0.104 0.097 0.062 0.046 0.052 0.429 0.161 0.11  0.055
 0.133 0.071 0.122 0.054 0.057 0.123 0.203 0.076 0.046 0.135 0.107 0.087
 0.083 0.025 0.127 0.103 0.141 0.165 0.1   0.317 0.198 0.128 0.101 0.996
 0.222 0.084 0.18  0.226 0.175 0.245 0.553 0.096 0.451 0.062 0.033 0.089
 0.056 0.033 0.073 0.079 0.011 0.024]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.7558299039780522, 0.6649911816578484)
Objective function 10.99 = squared loss an data 7.46 + 0.5*rho*h**2 0.237909 + alpha*h 0.535656 + L2reg 0.52 + L1reg 2.21 + box penalty 0.03 ; SHD = 6 ; DAG True
Grad norm per param group for one microbatch
norm  14.466833913953021  clip  tensor([1.])
norm  3.042811600501179  clip  tensor([1.])
norm  14.57117761568544  clip  tensor([1.])
norm  3.042811600501179  clip  tensor([1.])
norm  4.638470196431057  clip  tensor([1.])
norm  2.9358212031082793  clip  tensor([1.])
Grad norm per param group for one microbatch
norm  28.7917927462082  clip  tensor([12.903])
norm  4.057793402319638  clip  tensor([2.315])
norm  28.461706089185945  clip  tensor([13.307])
norm  4.057793402319638  clip  tensor([2.327])
norm  8.955102279071442  clip  tensor([5.106])
norm  5.716046789813824  clip  tensor([3.256])
Grad norm per param group for one microbatch
norm  17.006730941682015  clip  tensor([14.482])
norm  3.4602233513327274  clip  tensor([2.291])
norm  16.74110116602308  clip  tensor([13.701])
norm  3.4602233513327274  clip  tensor([2.299])
norm  6.717710351699913  clip  tensor([4.811])
norm  4.191853943062026  clip  tensor([3.125])
Grad norm per param group for one microbatch
norm  18.816894187978743  clip  tensor([10.466])
norm  3.1683257146954986  clip  tensor([2.161])
norm  18.71558696190825  clip  tensor([10.460])
norm  3.1683257146954986  clip  tensor([2.193])
norm  6.624318156967699  clip  tensor([4.482])
norm  4.151477372073828  clip  tensor([2.843])
Grad norm per param group for one microbatch
norm  11.297030987172324  clip  tensor([10.461])
norm  2.5823288027443905  clip  tensor([2.306])
norm  11.08549092407427  clip  tensor([10.741])
norm  2.5823288027443905  clip  tensor([2.270])
norm  4.954050180047035  clip  tensor([4.842])
norm  3.2802328717409543  clip  tensor([3.025])
Grad norm per param group for one microbatch
norm  8.960862103872184  clip  tensor([9.052])
norm  2.0757450458143305  clip  tensor([1.992])
norm  8.788791114460219  clip  tensor([9.092])
norm  2.0757450458143305  clip  tensor([1.990])
norm  4.334818520691785  clip  tensor([4.640])
norm  2.681083243059796  clip  tensor([2.963])
Grad norm per param group for one microbatch
norm  11.680748540245594  clip  tensor([11.264])
norm  2.710377967043875  clip  tensor([2.314])
norm  11.572818209079944  clip  tensor([11.178])
norm  2.710377967043875  clip  tensor([2.311])
norm  5.618111969982177  clip  tensor([4.944])
norm  3.383104657501426  clip  tensor([3.095])
Grad norm per param group for one microbatch
norm  9.736246315504838  clip  tensor([10.770])
norm  1.5159428187152717  clip  tensor([2.223])
norm  9.315014488255109  clip  tensor([10.518])
norm  1.5159428187152717  clip  tensor([2.268])
norm  4.054379402786837  clip  tensor([4.999])
norm  2.669757138367434  clip  tensor([3.198])
Grad norm per param group for one microbatch
norm  12.619777247890143  clip  tensor([10.294])
norm  2.389391815571797  clip  tensor([2.151])
norm  12.507345755576104  clip  tensor([10.269])
norm  2.389391815571797  clip  tensor([2.162])
norm  5.8490664756763175  clip  tensor([4.950])
norm  3.693104322324784  clip  tensor([3.040])
Grad norm per param group for one microbatch
norm  10.797240694689691  clip  tensor([10.370])
norm  2.3198219649163048  clip  tensor([2.203])
norm  10.996138944742068  clip  tensor([10.357])
norm  2.3198219649163048  clip  tensor([2.214])
norm  4.7961058596944754  clip  tensor([5.006])
norm  3.026958947659364  clip  tensor([3.139])
Grad norm per param group for one microbatch
norm  8.178955012145062  clip  tensor([9.207])
norm  1.7964443500527745  clip  tensor([2.132])
norm  8.24947783042577  clip  tensor([9.191])
norm  1.7964443500527745  clip  tensor([2.133])
norm  3.166179664480957  clip  tensor([4.724])
norm  1.9922518104635207  clip  tensor([2.986])
cpu
[0.015 0.029 0.016 0.06  0.067 0.096 0.043 0.04  0.046 0.453 0.238 0.117
 0.051 0.116 0.217 0.082 0.091 0.174 0.378 0.063 0.016 0.057 0.112 0.368
 0.03  0.076 0.063 0.55  0.074 0.338 0.177 0.056 0.256 0.077 0.065 0.215
 0.111 0.132 0.165 0.049 0.233 0.038 0.031 0.068 0.422 0.106 0.09  0.068
 0.141 0.04  0.077 0.045 0.058 0.055 0.09  0.037 0.035 0.033 0.106 0.118
 0.083 0.013 0.115 0.225 0.15  0.28  0.116 0.309 0.18  0.081 0.091 0.881
 0.194 0.088 0.136 0.113 0.155 0.156 0.645 0.088 0.435 0.129 0.047 0.091
 0.033 0.031 0.061 0.082 0.01  0.024]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.7750342935528123, 0.7005226480836237)
Objective function 10.66 = squared loss an data 7.44 + 0.5*rho*h**2 0.118250 + alpha*h 0.377643 + L2reg 0.45 + L1reg 2.22 + box penalty 0.06 ; SHD = 5 ; DAG True
Proportion of microbatches that were clipped  [0.8067837190742219, 0.7878691141260974, 0.8063048683160415, 0.7871508379888268, 0.7958499600957701, 0.7916201117318435]
iteration 1 in inner loop, alpha 77.65440578997314 rho 10000.0 h 0.004863118646456499
noise_multiplier  1.4696938456699067  noise_multiplier_b  2.5  noise_multiplier_delta  1.5376193302972219
cpu
[0.015 0.029 0.016 0.06  0.067 0.096 0.043 0.04  0.046 0.453 0.238 0.117
 0.051 0.116 0.217 0.082 0.091 0.174 0.378 0.063 0.016 0.057 0.112 0.368
 0.03  0.076 0.063 0.55  0.074 0.338 0.177 0.056 0.256 0.077 0.065 0.215
 0.111 0.132 0.165 0.049 0.233 0.038 0.031 0.068 0.422 0.106 0.09  0.068
 0.141 0.04  0.077 0.045 0.058 0.055 0.09  0.037 0.035 0.033 0.106 0.118
 0.083 0.013 0.115 0.225 0.15  0.28  0.116 0.309 0.18  0.081 0.091 0.881
 0.194 0.088 0.136 0.113 0.155 0.156 0.645 0.088 0.435 0.129 0.047 0.091
 0.033 0.031 0.061 0.082 0.01  0.024]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.7750342935528123, 0.7005226480836237)
Objective function 11.73 = squared loss an data 7.44 + 0.5*rho*h**2 1.182496 + alpha*h 0.377643 + L2reg 0.45 + L1reg 2.22 + box penalty 0.06 ; SHD = 5 ; DAG True
Grad norm per param group for one microbatch
norm  40.20665252376124  clip  tensor([45.869])
norm  1.174741855386777  clip  tensor([2.248])
norm  40.63391565556632  clip  tensor([42.639])
norm  1.174741855386777  clip  tensor([2.191])
norm  3.330700088234556  clip  tensor([4.836])
norm  2.2283781068251676  clip  tensor([3.048])
Grad norm per param group for one microbatch
norm  30.062407683988518  clip  tensor([35.139])
norm  2.0264877880705523  clip  tensor([2.030])
norm  29.977024030084777  clip  tensor([37.421])
norm  2.0264877880705523  clip  tensor([2.034])
norm  5.23247795541504  clip  tensor([4.880])
norm  3.4375151074206896  clip  tensor([3.139])
Grad norm per param group for one microbatch
norm  28.21428091699529  clip  tensor([36.935])
norm  1.9964016013321768  clip  tensor([2.160])
norm  28.12373738038252  clip  tensor([37.158])
norm  1.9964016013321768  clip  tensor([2.147])
norm  5.377661793194208  clip  tensor([5.202])
norm  3.4705838347720523  clip  tensor([3.282])
Grad norm per param group for one microbatch
norm  25.488000322989638  clip  tensor([24.069])
norm  1.9826728896326167  clip  tensor([2.223])
norm  25.435292710963857  clip  tensor([22.969])
norm  1.9826728896326167  clip  tensor([2.213])
norm  4.152490192480071  clip  tensor([5.185])
norm  2.669768952593759  clip  tensor([3.356])
Grad norm per param group for one microbatch
norm  17.572991190664258  clip  tensor([17.034])
norm  3.109277621666364  clip  tensor([1.871])
norm  17.79920964069502  clip  tensor([17.277])
norm  3.109277621666364  clip  tensor([1.899])
norm  4.957591911694849  clip  tensor([4.581])
norm  3.185178499706275  clip  tensor([2.993])
Grad norm per param group for one microbatch
norm  30.70651123311433  clip  tensor([15.809])
norm  5.527199366934862  clip  tensor([1.925])
norm  30.777119948931393  clip  tensor([16.235])
norm  5.527199366934862  clip  tensor([1.934])
norm  7.459155604316271  clip  tensor([4.761])
norm  5.159211606054853  clip  tensor([3.041])
Grad norm per param group for one microbatch
norm  19.06274395019429  clip  tensor([8.940])
norm  3.352705666075287  clip  tensor([2.116])
norm  19.118424551135035  clip  tensor([8.912])
norm  3.352705666075287  clip  tensor([2.106])
norm  8.354619660109973  clip  tensor([4.791])
norm  5.130397836874132  clip  tensor([3.037])
Grad norm per param group for one microbatch
norm  9.285445790496878  clip  tensor([8.940])
norm  1.562726049199629  clip  tensor([2.116])
norm  9.346676551827445  clip  tensor([8.912])
norm  1.562726049199629  clip  tensor([2.106])
norm  5.365097716127847  clip  tensor([4.791])
norm  3.553647641484762  clip  tensor([3.037])
Grad norm per param group for one microbatch
norm  12.885157789867607  clip  tensor([8.759])
norm  2.6976750485009373  clip  tensor([2.046])
norm  12.698752170998345  clip  tensor([8.621])
norm  2.6976750485009373  clip  tensor([2.026])
norm  7.32422698213645  clip  tensor([5.047])
norm  4.6070004974717325  clip  tensor([3.167])
Grad norm per param group for one microbatch
norm  12.157481384372273  clip  tensor([7.993])
norm  2.9255799973011944  clip  tensor([1.925])
norm  12.222022903918273  clip  tensor([8.162])
norm  2.9255799973011944  clip  tensor([1.936])
norm  6.572961059324294  clip  tensor([4.644])
norm  4.0619422801086715  clip  tensor([2.911])
Grad norm per param group for one microbatch
norm  13.168135465211021  clip  tensor([8.071])
norm  2.653336762277668  clip  tensor([1.920])
norm  13.33853796542343  clip  tensor([8.324])
norm  2.653336762277668  clip  tensor([1.928])
norm  7.122527621504641  clip  tensor([4.960])
norm  4.587187457753098  clip  tensor([3.149])
cpu
[0.008 0.011 0.004 0.04  0.032 0.082 0.017 0.027 0.05  0.642 0.169 0.037
 0.09  0.062 0.091 0.051 0.054 0.14  0.563 0.042 0.008 0.058 0.095 0.448
 0.045 0.079 0.147 0.724 0.1   0.439 0.128 0.086 0.196 0.104 0.117 0.207
 0.131 0.054 0.067 0.04  0.083 0.068 0.01  0.044 0.537 0.108 0.073 0.059
 0.036 0.064 0.055 0.012 0.05  0.106 0.058 0.035 0.008 0.016 0.085 0.111
 0.016 0.01  0.078 0.281 0.102 0.075 0.05  0.394 0.375 0.189 0.064 0.989
 0.136 0.064 0.077 0.044 0.099 0.121 0.574 0.069 0.622 0.093 0.027 0.042
 0.024 0.008 0.044 0.062 0.005 0.008]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.7695473251028807, 0.6982634991894251)
Objective function 10.43 = squared loss an data 7.47 + 0.5*rho*h**2 0.066169 + alpha*h 0.089333 + L2reg 0.41 + L1reg 2.39 + box penalty 0.02 ; SHD = 6 ; DAG True
Proportion of microbatches that were clipped  [0.8042492241585104, 0.7865043367549932, 0.8022598870056498, 0.7896077027134559, 0.7971671838943264, 0.792233627755232]
iteration 2 in inner loop, alpha 77.65440578997314 rho 100000.0 h 0.0011503858907850883
iteration 4 in outer loop, alpha = 192.69299486848197, rho = 100000.0, h = 0.0011503858907850883
cpu
noise_multiplier  1.4696938456699067  noise_multiplier_b  2.5  noise_multiplier_delta  1.5376193302972219
cpu
[0.008 0.011 0.004 0.04  0.032 0.082 0.017 0.027 0.05  0.642 0.169 0.037
 0.09  0.062 0.091 0.051 0.054 0.14  0.563 0.042 0.008 0.058 0.095 0.448
 0.045 0.079 0.147 0.724 0.1   0.439 0.128 0.086 0.196 0.104 0.117 0.207
 0.131 0.054 0.067 0.04  0.083 0.068 0.01  0.044 0.537 0.108 0.073 0.059
 0.036 0.064 0.055 0.012 0.05  0.106 0.058 0.035 0.008 0.016 0.085 0.111
 0.016 0.01  0.078 0.281 0.102 0.075 0.05  0.394 0.375 0.189 0.064 0.989
 0.136 0.064 0.077 0.044 0.099 0.121 0.574 0.069 0.622 0.093 0.027 0.042
 0.024 0.008 0.044 0.062 0.005 0.008]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.7695473251028807, 0.6982634991894251)
Objective function 10.57 = squared loss an data 7.47 + 0.5*rho*h**2 0.066169 + alpha*h 0.221671 + L2reg 0.41 + L1reg 2.39 + box penalty 0.02 ; SHD = 6 ; DAG True
Grad norm per param group for one microbatch
norm  229.06683931956476  clip  tensor([1.298])
norm  3.1917214869531225  clip  tensor([1.336])
norm  229.96947652594886  clip  tensor([1.312])
norm  3.1917214869531225  clip  tensor([1.327])
norm  9.125835190300196  clip  tensor([1.322])
norm  5.3972367433907245  clip  tensor([1.304])
Grad norm per param group for one microbatch
norm  368.2800766205885  clip  tensor([1.570])
norm  4.116791449943391  clip  tensor([1.560])
norm  369.17200186813756  clip  tensor([1.554])
norm  4.116791449943391  clip  tensor([1.575])
norm  8.968550307703614  clip  tensor([1.603])
norm  5.46093910802844  clip  tensor([1.568])
Grad norm per param group for one microbatch
norm  38.3299307679111  clip  tensor([38.367])
norm  2.448233384562993  clip  tensor([1.973])
norm  37.50896045799141  clip  tensor([35.512])
norm  2.448233384562993  clip  tensor([1.966])
norm  6.335126805674457  clip  tensor([4.836])
norm  3.942252771825837  clip  tensor([3.119])
Grad norm per param group for one microbatch
norm  26.93589690782059  clip  tensor([33.783])
norm  2.051242589688829  clip  tensor([1.830])
norm  26.84081091012444  clip  tensor([30.545])
norm  2.051242589688829  clip  tensor([1.834])
norm  5.45863338535403  clip  tensor([4.624])
norm  3.352279567783418  clip  tensor([2.894])
Grad norm per param group for one microbatch
norm  13.809306414022211  clip  tensor([14.288])
norm  1.9128916569921492  clip  tensor([2.038])
norm  13.773138641418537  clip  tensor([14.140])
norm  1.9128916569921492  clip  tensor([1.989])
norm  5.01023966131233  clip  tensor([5.025])
norm  3.12961302303062  clip  tensor([3.179])
Grad norm per param group for one microbatch
norm  29.434051904554707  clip  tensor([9.318])
norm  4.934100966011274  clip  tensor([1.842])
norm  29.424671843359764  clip  tensor([9.432])
norm  4.934100966011274  clip  tensor([1.834])
norm  8.382988687057964  clip  tensor([4.578])
norm  5.386803294240677  clip  tensor([2.882])
Grad norm per param group for one microbatch
norm  14.458098127564497  clip  tensor([8.444])
norm  2.6932014876395023  clip  tensor([1.823])
norm  14.41919009861121  clip  tensor([8.599])
norm  2.6932014876395023  clip  tensor([1.845])
norm  7.473285362109626  clip  tensor([4.795])
norm  4.5726517601227705  clip  tensor([2.951])
Grad norm per param group for one microbatch
norm  22.58467871893354  clip  tensor([9.068])
norm  4.432693198161055  clip  tensor([1.977])
norm  22.645298991679386  clip  tensor([9.083])
norm  4.432693198161055  clip  tensor([1.952])
norm  8.720848448861823  clip  tensor([4.918])
norm  5.548181992154695  clip  tensor([3.168])
Grad norm per param group for one microbatch
norm  8.03202660783522  clip  tensor([8.253])
norm  2.2833291539674008  clip  tensor([1.894])
norm  8.177469710581462  clip  tensor([8.291])
norm  2.2833291539674008  clip  tensor([1.911])
norm  4.866334594237217  clip  tensor([4.951])
norm  3.0415433206535383  clip  tensor([3.121])
Grad norm per param group for one microbatch
norm  10.173631866250066  clip  tensor([8.655])
norm  2.320127603428819  clip  tensor([1.947])
norm  10.224722666108807  clip  tensor([8.581])
norm  2.320127603428819  clip  tensor([1.918])
norm  6.119089388621271  clip  tensor([4.879])
norm  3.9952463093747594  clip  tensor([3.107])
Grad norm per param group for one microbatch
norm  7.183312064395614  clip  tensor([8.779])
norm  1.397016070232391  clip  tensor([1.791])
norm  7.290077898563853  clip  tensor([8.867])
norm  1.397016070232391  clip  tensor([1.825])
norm  3.823924440833839  clip  tensor([4.716])
norm  2.5214744491123526  clip  tensor([2.938])
cpu
[0.004 0.006 0.006 0.044 0.063 0.07  0.026 0.02  0.131 0.723 0.206 0.042
 0.109 0.153 0.035 0.051 0.042 0.182 0.519 0.016 0.012 0.088 0.074 0.456
 0.085 0.081 0.107 0.797 0.073 0.291 0.255 0.069 0.094 0.051 0.033 0.161
 0.113 0.037 0.035 0.018 0.052 0.03  0.012 0.018 0.528 0.057 0.031 0.079
 0.043 0.049 0.074 0.043 0.04  0.138 0.082 0.07  0.011 0.029 0.127 0.061
 0.027 0.005 0.149 0.188 0.089 0.054 0.046 0.388 0.081 0.235 0.064 1.043
 0.161 0.086 0.041 0.084 0.273 0.066 0.67  0.077 0.656 0.029 0.017 0.029
 0.025 0.009 0.02  0.031 0.003 0.006]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.7805212620027435, 0.7259136212624586)
Objective function 10.55 = squared loss an data 7.48 + 0.5*rho*h**2 0.037255 + alpha*h 0.166331 + L2reg 0.39 + L1reg 2.47 + box penalty 0.01 ; SHD = 4 ; DAG True
Proportion of microbatches that were clipped  [0.8016515673855528, 0.7852160667040808, 0.8019722600817767, 0.784815200833801, 0.7946765012426842, 0.7906678425398862]
iteration 1 in inner loop, alpha 192.69299486848197 rho 100000.0 h 0.00086319338979024
iteration 5 in outer loop, alpha = 1055.886384658722, rho = 1000000.0, h = 0.00086319338979024
Threshold 0.3
[[0.005 0.004 0.006 0.006 0.044 0.063 0.07  0.026 0.02  0.131]
 [0.723 0.003 0.206 0.042 0.109 0.153 0.035 0.051 0.042 0.182]
 [0.519 0.016 0.002 0.012 0.088 0.074 0.456 0.085 0.081 0.107]
 [0.797 0.073 0.291 0.003 0.255 0.069 0.094 0.051 0.033 0.161]
 [0.113 0.037 0.035 0.018 0.004 0.052 0.03  0.012 0.018 0.528]
 [0.057 0.031 0.079 0.043 0.049 0.004 0.074 0.043 0.04  0.138]
 [0.082 0.07  0.011 0.029 0.127 0.061 0.004 0.027 0.005 0.149]
 [0.188 0.089 0.054 0.046 0.388 0.081 0.235 0.005 0.064 1.043]
 [0.161 0.086 0.041 0.084 0.273 0.066 0.67  0.077 0.003 0.656]
 [0.029 0.017 0.029 0.025 0.009 0.02  0.031 0.003 0.006 0.005]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.723 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.519 0.    0.    0.    0.    0.    0.456 0.    0.    0.   ]
 [0.797 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.528]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.388 0.    0.    0.    0.    1.043]
 [0.    0.    0.    0.    0.    0.    0.67  0.    0.    0.656]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]]
{'fdr': 0.3333333333333333, 'tpr': 0.6666666666666666, 'fpr': 0.08333333333333333, 'f1': 0.6666666666666666, 'shd': 4, 'npred': 9, 'ntrue': 9}
[0.004 0.006 0.006 0.044 0.063 0.07  0.026 0.02  0.131 0.723 0.206 0.042
 0.109 0.153 0.035 0.051 0.042 0.182 0.519 0.016 0.012 0.088 0.074 0.456
 0.085 0.081 0.107 0.797 0.073 0.291 0.255 0.069 0.094 0.051 0.033 0.161
 0.113 0.037 0.035 0.018 0.052 0.03  0.012 0.018 0.528 0.057 0.031 0.079
 0.043 0.049 0.074 0.043 0.04  0.138 0.082 0.07  0.011 0.029 0.127 0.061
 0.027 0.005 0.149 0.188 0.089 0.054 0.046 0.388 0.081 0.235 0.064 1.043
 0.161 0.086 0.041 0.084 0.273 0.066 0.67  0.077 0.656 0.029 0.017 0.029
 0.025 0.009 0.02  0.031 0.003 0.006]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.7805212620027435, 0.7259136212624586)
Iterations 2500
Achieves (13.610683049707138, 1e-05)-DP
