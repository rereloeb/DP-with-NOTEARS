samples  5000  graph  10 20 ER mim  minibatch size  50  noise  1.0  minibatches per NN training  250 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.2478778610411254
iteration 1 in outer loop, alpha = 1.2478778610411254, rho = 1.0, h = 1.2478778610411254
cuda
iteration 1 in inner loop,alpha 1.2478778610411254 rho 1.0 h 0.8084888745241194
iteration 2 in inner loop,alpha 1.2478778610411254 rho 10.0 h 0.33057833071344156
iteration 3 in inner loop,alpha 1.2478778610411254 rho 100.0 h 0.08917599829296385
iteration 2 in outer loop, alpha = 10.16547769033751, rho = 100.0, h = 0.08917599829296385
cuda
iteration 1 in inner loop,alpha 10.16547769033751 rho 100.0 h 0.04477612329798397
iteration 2 in inner loop,alpha 10.16547769033751 rho 1000.0 h 0.01475614729775998
iteration 3 in outer loop, alpha = 24.92162498809749, rho = 1000.0, h = 0.01475614729775998
cuda
iteration 1 in inner loop,alpha 24.92162498809749 rho 1000.0 h 0.006747604373583016
iteration 2 in inner loop,alpha 24.92162498809749 rho 10000.0 h 0.0009845269108446075
iteration 4 in outer loop, alpha = 34.76689409654357, rho = 10000.0, h = 0.0009845269108446075
cuda
iteration 1 in inner loop,alpha 34.76689409654357 rho 10000.0 h 0.0006367139972880409
iteration 2 in inner loop,alpha 34.76689409654357 rho 100000.0 h 0.0002659665090032348
iteration 5 in outer loop, alpha = 300.7334030997784, rho = 1000000.0, h = 0.0002659665090032348
Threshold 0.3
[[0.006 0.    0.    0.    0.497 0.    0.08  0.    0.    1.78 ]
 [2.764 0.006 0.577 0.    0.104 0.003 1.103 0.004 0.    0.993]
 [0.294 0.005 0.007 0.    0.075 0.004 1.208 0.011 0.    0.21 ]
 [1.782 2.985 1.099 0.    0.008 2.619 0.198 2.692 0.003 0.151]
 [0.    0.    0.001 0.    0.005 0.    0.002 0.    0.    0.002]
 [0.388 0.281 0.722 0.    0.043 0.005 0.959 1.04  0.004 0.132]
 [0.009 0.001 0.002 0.    0.983 0.001 0.005 0.001 0.    0.019]
 [0.247 0.252 0.02  0.    0.007 0.001 0.236 0.002 0.008 0.036]
 [0.247 2.116 0.013 0.008 1.483 0.074 0.527 0.043 0.    0.041]
 [0.001 0.    0.002 0.    0.89  0.    0.055 0.001 0.    0.005]]
[[0.    0.    0.    0.    0.497 0.    0.    0.    0.    1.78 ]
 [2.764 0.    0.577 0.    0.    0.    1.103 0.    0.    0.993]
 [0.    0.    0.    0.    0.    0.    1.208 0.    0.    0.   ]
 [1.782 2.985 1.099 0.    0.    2.619 0.    2.692 0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.388 0.    0.722 0.    0.    0.    0.959 1.04  0.    0.   ]
 [0.    0.    0.    0.    0.983 0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    2.116 0.    0.    1.483 0.    0.527 0.    0.    0.   ]
 [0.    0.    0.    0.    0.89  0.    0.    0.    0.    0.   ]]
{'fdr': 0.09523809523809523, 'tpr': 0.95, 'fpr': 0.08, 'f1': 0.9268292682926829, 'shd': 2, 'npred': 21, 'ntrue': 20}
[2.171e-04 2.542e-04 2.300e-05 4.968e-01 3.873e-04 7.987e-02 4.451e-04
 4.830e-06 1.780e+00 2.764e+00 5.767e-01 7.075e-06 1.041e-01 3.219e-03
 1.103e+00 3.582e-03 3.383e-05 9.934e-01 2.938e-01 5.236e-03 3.577e-05
 7.537e-02 3.724e-03 1.208e+00 1.112e-02 1.032e-04 2.100e-01 1.782e+00
 2.985e+00 1.099e+00 7.782e-03 2.619e+00 1.983e-01 2.692e+00 3.356e-03
 1.509e-01 1.818e-04 1.041e-04 9.311e-04 5.426e-06 4.511e-04 1.769e-03
 4.062e-04 1.140e-05 1.845e-03 3.883e-01 2.813e-01 7.218e-01 1.448e-05
 4.333e-02 9.593e-01 1.040e+00 4.466e-03 1.322e-01 8.833e-03 1.071e-03
 1.816e-03 1.383e-05 9.827e-01 7.567e-04 9.749e-04 7.131e-05 1.913e-02
 2.470e-01 2.522e-01 2.039e-02 5.639e-06 6.898e-03 1.284e-03 2.361e-01
 7.577e-03 3.593e-02 2.469e-01 2.116e+00 1.302e-02 7.793e-03 1.483e+00
 7.386e-02 5.273e-01 4.265e-02 4.053e-02 9.944e-04 1.665e-04 2.056e-03
 6.416e-06 8.901e-01 3.087e-04 5.540e-02 6.418e-04 8.262e-06]
[[0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 1. 1. 0. 0. 1. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9657142857142857, 0.9419402177200167)
cuda
1210
cuda
Objective function 188.58 = squared loss an data 11.52 + 0.5*rho*h**2 176.710652 + alpha*h 0.000000 + L2reg 0.19 + L1reg 0.16 ; SHD = 55 ; DAG False
||w||^2 0.18351444585655025
exp ma of ||w||^2 0.17087017529774134
||w|| 0.4283858609437877
exp ma of ||w|| 0.3963040456154914
||w||^2 0.0855116403674731
exp ma of ||w||^2 0.17154778428996498
||w|| 0.2924237342752347
exp ma of ||w|| 0.39443569585324534
||w||^2 0.3143028029180723
exp ma of ||w||^2 0.19189616398629256
||w|| 0.5606271514278204
exp ma of ||w|| 0.4147917188090546
||w||^2 0.08452353611409591
exp ma of ||w||^2 0.18155068580368358
||w|| 0.29072931760332654
exp ma of ||w|| 0.406507214978479
||w||^2 0.2480373690332815
exp ma of ||w||^2 0.17512522322153803
||w|| 0.49803350191857726
exp ma of ||w|| 0.401371318017417
cuda
Objective function 7.59 = squared loss an data 6.89 + 0.5*rho*h**2 0.458538 + alpha*h 0.000000 + L2reg 0.17 + L1reg 0.07 ; SHD = 27 ; DAG False
Proportion of microbatches that were clipped  0.7605486083098023
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 0.95764061791958
iteration 1 in outer loop, alpha = 0.95764061791958, rho = 1.0, h = 0.95764061791958
cuda
1210
cuda
Objective function 8.51 = squared loss an data 6.89 + 0.5*rho*h**2 0.458538 + alpha*h 0.917076 + L2reg 0.17 + L1reg 0.07 ; SHD = 27 ; DAG False
||w||^2 14644976.660405591
exp ma of ||w||^2 332823313.5920322
||w|| 3826.8755741996097
exp ma of ||w|| 12330.015935085072
||w||^2 0.04016434120870965
exp ma of ||w||^2 30.369437397556936
||w|| 0.20041043188594163
exp ma of ||w|| 0.23411771641698315
||w||^2 0.10970630510829363
exp ma of ||w||^2 0.17018109423040217
||w|| 0.3312194213935735
exp ma of ||w|| 0.38212935364887
||w||^2 0.28068729664433395
exp ma of ||w||^2 0.16494963247489736
||w|| 0.5297992984558718
exp ma of ||w|| 0.3884177603703252
||w||^2 0.2252299549806184
exp ma of ||w||^2 0.17491817401306284
||w|| 0.47458398095660415
exp ma of ||w|| 0.39921809480848586
||w||^2 0.38721609160381976
exp ma of ||w||^2 0.19962072274801426
||w|| 0.6222668974032122
exp ma of ||w|| 0.42033867328620944
||w||^2 0.01739688767165378
exp ma of ||w||^2 0.1836824789510037
||w|| 0.1318972618049889
exp ma of ||w|| 0.4021474655566205
||w||^2 0.49646046567165775
exp ma of ||w||^2 0.19579993549038982
||w|| 0.704599507288827
exp ma of ||w|| 0.4176156150484921
cuda
Objective function 7.49 = squared loss an data 6.38 + 0.5*rho*h**2 0.189337 + alpha*h 0.589299 + L2reg 0.27 + L1reg 0.06 ; SHD = 14 ; DAG True
Proportion of microbatches that were clipped  0.7586347013409184
iteration 1 in inner loop, alpha 0.95764061791958 rho 1.0 h 0.6153652272579198
1210
cuda
Objective function 9.19 = squared loss an data 6.38 + 0.5*rho*h**2 1.893372 + alpha*h 0.589299 + L2reg 0.27 + L1reg 0.06 ; SHD = 14 ; DAG True
||w||^2 265.33824851393956
exp ma of ||w||^2 2383690.6420177184
||w|| 16.289206503508375
exp ma of ||w|| 226.30675318441217
||w||^2 0.05249441845625415
exp ma of ||w||^2 34999.499935792
||w|| 0.22911660449704238
exp ma of ||w|| 4.049560165829309
||w||^2 0.08873965987099693
exp ma of ||w||^2 0.43719708707044747
||w|| 0.29789202720280533
exp ma of ||w|| 0.3335450293495044
||w||^2 0.0956925326165653
exp ma of ||w||^2 0.20464262450856385
||w|| 0.30934209641845595
exp ma of ||w|| 0.42144255726649527
||w||^2 0.1380796901413771
exp ma of ||w||^2 0.21842118502546923
||w|| 0.3715907562647073
exp ma of ||w|| 0.43725669002377227
||w||^2 0.044363205549685016
exp ma of ||w||^2 0.2085062461683429
||w|| 0.21062574759436467
exp ma of ||w|| 0.4234073773700543
||w||^2 0.041133853785353086
exp ma of ||w||^2 0.19422524485654724
||w|| 0.20281482634500142
exp ma of ||w|| 0.4135798999657646
||w||^2 0.10121181443157422
exp ma of ||w||^2 0.20833754795767612
||w|| 0.31813804304354143
exp ma of ||w|| 0.42764729881491625
||w||^2 0.2670800409420257
exp ma of ||w||^2 0.1856690169373463
||w|| 0.516797872424051
exp ma of ||w|| 0.40196257709891464
||w||^2 0.06775762203743654
exp ma of ||w||^2 0.18809210456569303
||w|| 0.2603029428136312
exp ma of ||w|| 0.4024784478946191
||w||^2 0.07257639331896881
exp ma of ||w||^2 0.24806031035721038
||w|| 0.26940006183920745
exp ma of ||w|| 0.46542314275857527
||w||^2 0.18404112574561576
exp ma of ||w||^2 0.20507988008456843
||w|| 0.4290001465566367
exp ma of ||w|| 0.415376843498378
cuda
Objective function 7.79 = squared loss an data 6.80 + 0.5*rho*h**2 0.336174 + alpha*h 0.248313 + L2reg 0.35 + L1reg 0.06 ; SHD = 9 ; DAG True
Proportion of microbatches that were clipped  0.7605633802816901
iteration 2 in inner loop, alpha 0.95764061791958 rho 10.0 h 0.25929675156348075
1210
cuda
Objective function 10.81 = squared loss an data 6.80 + 0.5*rho*h**2 3.361740 + alpha*h 0.248313 + L2reg 0.35 + L1reg 0.06 ; SHD = 9 ; DAG True
||w||^2 0.35267803661212727
exp ma of ||w||^2 0.4408870591478122
||w|| 0.5938670192998827
exp ma of ||w|| 0.346534064921512
||w||^2 0.04839206439444406
exp ma of ||w||^2 0.21867471922778256
||w|| 0.21998196379349844
exp ma of ||w|| 0.4363686962234502
||w||^2 0.6895036394156489
exp ma of ||w||^2 0.20382385250103438
||w|| 0.8303635585788004
exp ma of ||w|| 0.4250158552000814
v before min max tensor([[-8.978e-01, -1.487e-01, -1.845e-01, -1.243e+00, -1.400e+00, -1.006e+00,
         -2.354e+00, -1.286e+00, -1.089e-01, -1.320e+00],
        [ 1.049e+00, -1.184e+00,  5.737e-01, -9.072e-01, -1.944e+00, -1.255e+00,
         -7.288e-01,  6.960e-01, -8.808e-01, -5.911e-01],
        [-2.469e-01, -2.058e+00, -4.544e-01, -1.919e+00,  3.035e+00,  6.176e+00,
         -1.553e+00,  7.004e-02, -3.121e-01, -6.978e-01],
        [-1.288e+00, -2.321e+00, -2.970e-01, -2.509e+00,  1.116e+00,  2.673e-01,
          2.339e+00, -1.628e+00,  2.327e+00,  6.257e-01],
        [-2.516e+00,  4.384e-02, -1.025e+00, -1.061e+00, -8.092e-02, -1.787e+00,
         -1.426e+00, -9.656e-01, -1.164e+00,  1.376e+01],
        [-2.782e+00, -1.388e+00, -2.589e+00, -1.409e+00,  7.557e-01, -1.129e+00,
          3.273e+00, -1.045e+00,  1.331e+00, -1.662e+00],
        [-1.067e+00,  1.261e+00,  5.176e-01,  2.470e+00,  2.005e+00, -4.927e-01,
          4.627e+00,  7.007e-03, -3.353e-01, -1.837e+00],
        [-1.435e+00, -1.430e+00, -1.325e+00, -1.553e+00, -1.985e+00, -1.587e+00,
         -1.528e+00,  2.032e+00, -1.496e+00,  1.350e-01],
        [ 1.077e+01,  2.561e+00, -2.973e-01, -6.957e-01,  6.897e-01,  3.905e+00,
         -2.549e+00, -3.152e+00, -9.520e-01, -1.411e-01],
        [-4.232e-01, -1.746e+00, -2.408e+00, -6.031e-01, -8.410e-01,  4.925e+00,
          4.281e+00,  8.962e-01, -4.846e-01, -2.031e+00],
        [ 6.702e+00, -1.837e+00, -1.559e+00, -1.568e-01,  1.168e+00, -1.568e+00,
         -1.874e+00, -1.027e-01, -1.873e+00, -2.297e+00],
        [-2.773e-01, -6.608e-01, -5.146e-02, -3.795e+00,  9.257e-01, -9.608e-01,
          1.017e+01, -3.660e-01, -5.049e-01, -3.053e-01],
        [-1.696e+00,  4.692e+00, -1.191e+00, -2.418e+00, -1.072e+00,  5.547e-01,
          2.718e+00,  6.913e-01, -8.038e-01, -2.096e+00],
        [ 6.305e+00, -1.507e+00, -1.358e+00, -1.066e+00, -2.031e+00, -1.364e+00,
          1.058e+00,  1.060e+00,  3.989e+00, -9.718e-01],
        [ 1.579e-01, -1.399e+00, -1.815e+00, -1.788e+00, -1.088e+00, -8.923e-01,
         -1.651e+00, -6.241e-01,  2.243e+00, -2.311e-01],
        [-1.175e+00,  3.520e-01, -2.275e-01,  2.217e+00, -1.727e+00, -2.016e+00,
         -1.340e-01, -2.455e+00, -6.476e-01, -8.932e-01],
        [-1.825e+00,  8.089e-01,  1.216e+00,  4.589e+00,  4.877e+00, -1.279e+00,
         -2.151e+00, -8.329e-01,  4.991e+00,  3.294e-01],
        [-1.674e+00,  1.057e+00, -1.559e+00, -1.796e+00, -1.716e+00,  4.765e-01,
         -2.028e+00, -8.786e-01, -6.826e-01, -1.295e+00],
        [-1.219e+00, -2.401e+00,  2.794e+00, -1.308e+00, -2.552e+00,  6.539e-01,
         -1.294e+00, -2.079e-01, -1.183e+00,  7.915e-01],
        [-2.742e-01, -1.178e+00, -1.199e+00,  4.069e+00, -7.900e-01, -4.404e-01,
         -2.108e+00,  5.131e-01, -2.591e+00, -1.337e+00],
        [-1.638e+00, -1.955e+00, -7.962e-01,  5.814e-01,  1.817e+00, -1.686e+00,
         -8.608e-01, -9.705e-01, -1.076e+00,  6.867e-01],
        [-1.990e+00, -1.426e+00,  4.088e+00, -7.173e-01, -3.324e-02, -1.901e+00,
         -2.932e-01, -9.454e-01,  1.105e+00, -9.792e-01],
        [ 5.854e+00, -1.901e+00,  1.777e+00,  5.191e-01,  1.286e-01, -1.698e+00,
         -1.485e+00, -1.286e+00, -3.470e-01,  1.019e+01],
        [-1.184e+00, -3.277e-01,  2.913e-01, -1.071e+00, -9.576e-01, -1.421e+00,
         -1.256e+00,  1.018e+00, -1.099e-01,  5.028e-01],
        [-2.260e+00, -1.150e+00, -4.652e-01,  1.591e-01, -1.381e+00, -7.866e-01,
         -1.087e+00,  4.104e+00, -1.829e+00,  3.535e+00],
        [-4.134e-01, -8.425e-01,  3.769e+00, -9.643e-01,  3.080e+00, -8.007e-01,
         -1.073e+00, -1.260e+00,  3.010e+00, -1.942e+00],
        [ 3.030e+00, -1.125e+00, -1.380e+00, -1.707e-01,  6.718e-01, -1.387e-01,
         -1.619e+00, -1.621e+00, -6.361e-01, -2.230e+00],
        [ 1.325e+01,  4.644e+00,  9.425e-01, -5.532e-01,  5.880e-02, -1.995e+00,
          6.882e+00, -1.593e+00, -1.594e+00, -5.910e-01],
        [-4.028e-01, -1.063e+00, -3.131e+00, -1.361e+00, -1.476e+00, -1.726e-01,
          9.826e-01, -7.074e-01, -1.584e+00,  5.515e-01],
        [-8.013e-01,  2.990e-01, -2.207e+00,  6.607e+00, -8.610e-01, -1.293e+00,
         -2.837e-01,  3.948e-01, -7.506e-01, -2.151e+00],
        [ 1.106e+00, -1.501e+00, -2.053e+00, -8.034e-01, -1.783e+00, -1.919e+00,
         -1.029e+00, -3.909e-01,  2.166e+00, -9.318e-01],
        [-9.760e-01, -6.565e-01, -8.051e-01, -1.846e+00,  1.070e+00,  1.775e-01,
          2.214e-01, -9.733e-02, -7.492e-01,  1.632e+00],
        [-1.455e+00, -1.492e+00,  1.503e+00, -3.310e-01, -2.144e+00, -1.156e+00,
         -6.407e-01, -1.749e+00,  4.453e-01, -8.469e-01],
        [-8.213e-01,  1.439e+00, -1.736e+00, -1.934e+00, -4.628e-01, -2.308e+00,
         -1.946e+00,  4.500e+00, -8.917e-01, -2.192e+00],
        [ 1.068e+00,  2.239e+00, -1.569e+00, -1.265e+00, -1.853e+00, -1.056e-01,
         -2.548e+00,  1.244e-01, -2.106e+00, -2.446e+00],
        [-2.093e+00,  1.200e-01, -6.197e-01, -2.345e+00, -4.641e-02,  7.503e-01,
         -7.121e-01, -1.432e+00, -1.300e+00, -1.187e+00],
        [-1.601e+00, -1.765e+00, -1.564e+00,  7.539e+00, -2.581e+00, -2.052e+00,
         -8.401e-01, -2.941e-02, -6.095e-01,  3.330e-01],
        [-7.511e-01,  3.774e+00, -1.488e+00, -9.407e-01, -8.249e-01, -7.990e-01,
         -1.115e+00, -1.220e+00,  5.559e+00, -3.586e-01],
        [ 2.564e+00,  5.104e+00,  1.094e+00, -1.974e+00, -1.625e+00, -3.359e-02,
         -1.397e+00, -6.259e-01, -2.552e+00, -6.820e-01],
        [-1.855e+00, -1.868e+00,  8.380e-01, -1.207e+00,  1.282e+00,  1.253e-01,
          9.325e-01, -1.780e+00,  1.206e+00,  1.409e+00],
        [-1.144e+00,  3.987e-01,  2.231e+00, -1.884e+00, -1.077e+00, -1.027e+00,
         -1.374e+00, -7.028e-01, -1.004e+00, -1.622e+00],
        [ 8.319e+00, -2.224e+00,  2.293e+00,  6.884e-01, -2.885e+00, -2.678e-01,
          1.406e+00,  1.663e+00,  7.572e+00,  1.614e+00],
        [-7.862e-01, -3.343e-01, -1.571e+00, -1.488e+00,  5.409e-01, -7.118e-01,
         -7.941e-01, -1.844e+00,  7.438e+00, -1.244e+00],
        [-9.558e-01,  2.591e+00,  1.860e+00,  2.868e-01, -1.182e+00, -1.242e-01,
         -6.857e-01, -1.602e+00,  2.814e+00, -1.409e+00],
        [ 7.747e-01, -1.559e+00, -4.519e-01, -1.250e+00, -3.123e-01,  2.649e+00,
         -1.049e+00, -1.114e-01, -1.536e+00, -7.109e-01],
        [ 7.641e-01, -1.904e+00,  5.136e-01, -8.975e-01, -1.909e+00, -2.212e+00,
         -2.987e-01,  2.071e+00, -7.829e-01, -2.213e+00],
        [-1.663e+00,  2.842e+01, -4.593e-01, -5.986e-01, -2.281e+00,  4.099e-03,
          6.267e-01, -1.944e+00, -2.775e-01, -6.308e-01],
        [-2.922e-01,  8.745e-01,  1.658e+00, -2.329e+00, -4.491e-01, -1.166e+00,
          4.927e-01,  7.974e-01, -9.543e-01, -1.085e+00],
        [-1.905e+00,  3.556e+00,  9.518e-01, -8.108e-01, -1.629e+00,  5.140e+00,
         -1.805e+00, -6.974e-01, -5.600e-01,  8.567e-01],
        [-8.074e-01, -5.809e-01, -1.536e+00,  3.561e+00, -1.401e+00,  7.198e-01,
          3.064e-01,  3.229e-01,  1.402e+01, -3.528e-01],
        [-1.022e+00, -2.008e+00, -1.062e+00, -8.491e-02, -2.373e+00,  5.807e+00,
         -1.929e+00, -6.551e-01,  1.006e+00, -1.343e+00],
        [-1.515e+00, -2.694e+00, -1.580e+00, -9.534e-01, -2.313e+00, -7.952e-01,
          1.697e-01,  3.967e+00, -1.223e+00, -3.447e-01],
        [ 1.195e+01,  5.589e-01,  9.013e-01,  4.230e+00, -1.041e+00,  5.028e-01,
         -2.215e+00, -5.101e-01, -1.034e+00,  1.843e+00],
        [-1.699e+00, -1.896e+00, -2.831e+00, -4.013e-01, -1.241e+00, -1.470e+00,
          4.841e+00,  2.286e-01,  1.218e+00, -3.337e-01],
        [-1.857e+00, -2.468e-01, -1.694e+00,  4.029e-01, -3.994e-01, -2.718e+00,
         -2.353e+00,  1.054e+00, -6.499e-01,  5.976e+00],
        [-3.782e-01, -1.837e+00, -1.441e+00, -9.815e-01, -1.161e+00,  3.632e+00,
         -1.129e-02, -4.352e-01,  6.513e-01, -1.647e+00],
        [ 6.429e-01, -1.689e+00,  1.395e-01, -2.078e+00,  1.119e+00, -1.416e+00,
         -1.565e+00,  1.775e+00, -1.444e+00, -8.613e-01],
        [-1.450e+00, -1.331e+00, -2.960e+00, -1.645e+00,  5.467e-01, -1.118e+00,
         -1.549e+00,  8.674e-01, -9.420e-01,  1.469e+00],
        [-1.196e+00, -1.226e+00, -1.675e+00,  2.057e+00,  2.906e-01,  1.506e+00,
          3.272e+00, -2.175e+00,  2.359e-01,  4.151e-01],
        [ 2.072e+00, -2.142e+00,  5.498e+00, -2.619e+00, -1.656e+00,  2.305e+00,
         -2.066e+00,  3.552e-01, -5.246e-01, -1.434e+00],
        [ 1.107e+00,  7.436e+00, -1.489e+00, -1.593e+00,  3.473e+00,  3.971e-01,
         -1.757e+00,  5.244e+00, -1.558e+00, -5.307e-01],
        [-2.591e+00, -4.221e-01,  8.748e+00, -7.572e-01,  4.303e-01,  4.787e-01,
         -2.396e+00, -9.828e-01, -1.149e+00, -5.542e-01],
        [ 1.137e+00, -1.537e+00,  3.827e-01, -1.798e+00,  1.524e-01, -1.948e+00,
          7.305e+00,  5.513e-02, -1.470e+00,  1.909e+00],
        [-2.946e-01, -2.253e+00, -1.177e+00, -1.712e+00, -6.275e-01, -1.478e-01,
         -2.611e+00, -2.912e-01, -1.158e+00,  4.690e-01],
        [-4.532e-01, -2.030e+00, -2.254e+00, -4.241e-01, -1.595e+00, -2.091e+00,
          2.214e+00, -1.457e+00, -1.668e+00, -7.516e-01],
        [ 1.075e+01, -1.371e+00, -1.278e+00, -7.136e-01,  1.034e+00, -1.383e+00,
         -1.869e+00, -8.885e-02,  3.059e+00,  1.147e-01],
        [-2.475e+00, -2.200e+00, -2.560e-01,  6.935e-01, -1.841e+00, -1.008e+00,
          1.843e+00,  8.744e+00, -1.413e+00, -1.883e+00],
        [ 1.252e+01,  2.768e+00,  7.451e-01, -1.854e-01,  2.376e+00, -1.878e+00,
         -4.991e-01, -1.770e+00,  9.931e-02,  2.467e-01],
        [ 3.043e+00,  5.546e+00, -2.017e+00, -1.034e+00,  5.315e+00, -1.120e+00,
          1.661e+01,  6.603e-02,  2.093e-01, -3.140e+00],
        [-1.775e+00, -1.731e+00, -4.780e-01,  2.305e+00,  9.045e-01, -1.514e+00,
          1.420e+00, -1.314e+00, -1.788e+00, -1.311e+00],
        [-1.036e+00, -5.190e-01, -9.024e-01,  2.447e+00,  4.085e+00, -1.408e+00,
         -2.073e+00,  3.556e-01, -1.418e+00, -1.300e+00],
        [ 1.695e+00,  7.882e-01, -1.471e+00, -1.814e+00,  2.295e-01, -9.893e-01,
          1.230e+00, -1.997e+00,  1.589e+00, -2.272e+00],
        [-2.899e-01, -8.351e-01, -9.450e-01, -6.951e-01, -1.527e+00,  3.690e+00,
         -1.699e+00, -9.259e-01,  7.475e+00, -9.774e-01],
        [ 6.788e+00, -2.364e-01, -1.308e+00, -5.801e-01,  1.921e+00, -2.715e+00,
         -2.180e+00, -1.911e+00, -1.355e+00, -7.157e-01],
        [-6.247e-01, -1.244e-01,  5.488e+00,  1.990e+00, -1.279e+00, -2.623e+00,
         -6.085e-01, -3.837e-01, -1.764e+00,  6.471e-01],
        [-1.472e+00, -5.422e-01,  1.894e-01, -1.132e+00, -9.155e-01,  6.535e-01,
         -1.176e+00, -2.061e+00,  2.126e+00, -8.456e-01],
        [-2.214e+00, -1.369e+00,  4.301e+00, -9.521e-01, -2.439e-01, -2.037e+00,
         -2.557e-01,  1.973e+00,  3.020e+00, -1.810e+00],
        [-1.407e+00, -8.855e-01,  1.943e+00, -4.229e-01, -1.992e+00, -1.826e+00,
         -2.761e+00,  3.642e+00, -2.184e+00, -1.204e+00],
        [-7.929e-01, -2.044e+00,  8.451e+00, -5.112e-01,  2.876e-02,  2.082e+00,
         -2.224e+00, -1.014e+00,  1.059e+01, -2.517e+00],
        [ 2.728e-01, -2.599e+00, -5.927e-01, -7.702e-01, -1.531e+00, -8.848e-01,
         -4.609e-02,  2.400e+00,  1.491e+00, -1.038e+00],
        [ 4.850e+00,  2.318e+00,  2.729e+00, -1.262e+00, -1.700e+00, -8.488e-01,
          5.420e-01,  1.281e+00, -2.033e+00,  1.746e+00],
        [ 6.181e+00,  5.266e+00,  6.409e+00, -8.292e-01, -5.608e-01,  2.124e+00,
         -2.720e+00,  1.765e+00, -2.029e+00, -9.132e-01],
        [-1.754e+00, -1.680e+00,  3.230e-01,  1.992e+00,  7.444e-02, -1.464e+00,
         -1.281e+00,  2.744e-01,  8.628e-02, -1.272e+00],
        [-2.644e-01,  9.715e-01,  3.473e+00, -2.566e+00,  5.262e+00,  1.524e+00,
         -1.440e+00, -2.314e+00, -8.902e-01,  2.120e+00],
        [-1.668e+00,  1.241e+00, -2.339e-01, -1.501e+00, -2.141e+00,  1.765e+01,
         -1.466e+00, -3.712e-01, -2.006e+00, -1.215e+00],
        [ 1.810e-01, -8.721e-01,  3.100e-01, -2.171e-02,  8.129e-01,  4.009e+00,
         -6.909e-01,  2.514e+00, -1.438e+00,  1.830e-01],
        [-2.318e-01, -6.857e-01,  3.534e-02, -1.265e+00, -8.273e-01, -6.270e-01,
         -7.670e-01, -2.576e-01, -1.949e+00,  7.980e+00],
        [-1.434e+00, -1.749e+00,  3.324e-01,  2.821e+00, -3.207e+00, -2.541e-01,
         -7.918e-01, -9.197e-01, -9.587e-01,  8.736e+00],
        [-1.379e+00,  7.155e-01, -3.730e-01,  7.261e-02, -1.145e+00,  1.558e+00,
         -2.097e+00,  7.128e-01,  1.892e+00, -8.597e-01],
        [-2.411e+00, -1.923e+00,  1.497e-02, -1.665e+00, -6.916e-01, -1.180e+00,
         -9.170e-01, -7.614e-01,  2.280e+00,  1.138e-01],
        [ 5.781e-02, -2.189e+00, -9.398e-01, -1.079e+00, -3.345e+00, -2.081e+00,
         -6.119e-01, -1.987e+00, -7.354e-01, -2.877e+00],
        [ 1.297e+01,  4.435e-01, -3.488e-02, -1.842e+00, -1.127e+00, -1.428e+00,
         -3.013e-01,  1.831e+00,  3.433e-01,  3.647e+00],
        [-2.966e-01, -2.383e+00, -5.544e-01, -5.595e-01, -7.572e-01, -1.646e+00,
         -1.381e+00,  8.189e-01,  1.093e+01, -1.729e+00],
        [-2.600e+00, -4.599e-01, -1.341e+00,  1.524e+00, -1.054e+00, -1.304e+00,
         -2.368e+00,  1.161e+01, -8.336e-01, -1.939e+00],
        [-9.932e-01, -1.354e+00,  3.699e+00,  3.029e-01,  1.157e+00, -2.011e+00,
          5.067e+00,  3.065e-01,  4.924e+00, -2.032e+00],
        [ 8.867e-01, -1.172e+00, -1.196e+00,  2.928e+00,  1.194e+01, -1.216e+00,
         -9.991e-01, -1.562e-01, -1.949e+00,  2.620e+00],
        [ 1.550e+01, -1.335e+00,  3.092e-01, -2.124e+00, -6.114e-01, -8.861e-01,
         -1.046e+00, -1.635e+00, -1.395e+00,  8.202e-01],
        [ 1.049e+00, -1.598e-01,  1.291e+00, -1.996e+00,  8.719e-01,  1.353e-01,
         -4.098e-01, -2.085e+00, -6.293e-01, -1.500e+00],
        [-1.536e+00,  1.461e+00,  1.519e+01,  1.129e+00, -1.347e+00,  1.110e+00,
         -1.166e+00, -9.505e-01,  3.919e+00, -6.606e-01],
        [-2.013e+00,  7.009e-01,  4.076e+00, -1.615e+00,  2.880e+00,  7.094e+00,
         -1.026e+00,  2.057e+00,  1.057e+00,  8.244e+00]], device='cuda:0')
v tensor([[1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.049e+00, 1.000e-12, 5.737e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 6.960e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.035e+00, 6.176e+00,
         1.000e-12, 7.004e-02, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.116e+00, 2.673e-01,
         2.339e+00, 1.000e-12, 2.327e+00, 6.257e-01],
        [1.000e-12, 4.384e-02, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 7.557e-01, 1.000e-12,
         3.273e+00, 1.000e-12, 1.331e+00, 1.000e-12],
        [1.000e-12, 1.261e+00, 5.176e-01, 2.470e+00, 2.005e+00, 1.000e-12,
         4.627e+00, 7.007e-03, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 2.032e+00, 1.000e-12, 1.350e-01],
        [1.000e+01, 2.561e+00, 1.000e-12, 1.000e-12, 6.897e-01, 3.905e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 4.925e+00,
         4.281e+00, 8.962e-01, 1.000e-12, 1.000e-12],
        [6.702e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.168e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 9.257e-01, 1.000e-12,
         1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 4.692e+00, 1.000e-12, 1.000e-12, 1.000e-12, 5.547e-01,
         2.718e+00, 6.913e-01, 1.000e-12, 1.000e-12],
        [6.305e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.058e+00, 1.060e+00, 3.989e+00, 1.000e-12],
        [1.579e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 2.243e+00, 1.000e-12],
        [1.000e-12, 3.520e-01, 1.000e-12, 2.217e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 8.089e-01, 1.216e+00, 4.589e+00, 4.877e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 4.991e+00, 3.294e-01],
        [1.000e-12, 1.057e+00, 1.000e-12, 1.000e-12, 1.000e-12, 4.765e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 2.794e+00, 1.000e-12, 1.000e-12, 6.539e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 7.915e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 4.069e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 5.131e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 5.814e-01, 1.817e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 6.867e-01],
        [1.000e-12, 1.000e-12, 4.088e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.105e+00, 1.000e-12],
        [5.854e+00, 1.000e-12, 1.777e+00, 5.191e-01, 1.286e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e-12, 1.000e-12, 2.913e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.018e+00, 1.000e-12, 5.028e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.591e-01, 1.000e-12, 1.000e-12,
         1.000e-12, 4.104e+00, 1.000e-12, 3.535e+00],
        [1.000e-12, 1.000e-12, 3.769e+00, 1.000e-12, 3.080e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 3.010e+00, 1.000e-12],
        [3.030e+00, 1.000e-12, 1.000e-12, 1.000e-12, 6.718e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e+01, 4.644e+00, 9.425e-01, 1.000e-12, 5.880e-02, 1.000e-12,
         6.882e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         9.826e-01, 1.000e-12, 1.000e-12, 5.515e-01],
        [1.000e-12, 2.990e-01, 1.000e-12, 6.607e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 3.948e-01, 1.000e-12, 1.000e-12],
        [1.106e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 2.166e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.070e+00, 1.775e-01,
         2.214e-01, 1.000e-12, 1.000e-12, 1.632e+00],
        [1.000e-12, 1.000e-12, 1.503e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 4.453e-01, 1.000e-12],
        [1.000e-12, 1.439e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 4.500e+00, 1.000e-12, 1.000e-12],
        [1.068e+00, 2.239e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.244e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.200e-01, 1.000e-12, 1.000e-12, 1.000e-12, 7.503e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 7.539e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 3.330e-01],
        [1.000e-12, 3.774e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 5.559e+00, 1.000e-12],
        [2.564e+00, 5.104e+00, 1.094e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 8.380e-01, 1.000e-12, 1.282e+00, 1.253e-01,
         9.325e-01, 1.000e-12, 1.206e+00, 1.409e+00],
        [1.000e-12, 3.987e-01, 2.231e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [8.319e+00, 1.000e-12, 2.293e+00, 6.884e-01, 1.000e-12, 1.000e-12,
         1.406e+00, 1.663e+00, 7.572e+00, 1.614e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.409e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 7.438e+00, 1.000e-12],
        [1.000e-12, 2.591e+00, 1.860e+00, 2.868e-01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 2.814e+00, 1.000e-12],
        [7.747e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.649e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [7.641e-01, 1.000e-12, 5.136e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 2.071e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 4.099e-03,
         6.267e-01, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 8.745e-01, 1.658e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         4.927e-01, 7.974e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 3.556e+00, 9.518e-01, 1.000e-12, 1.000e-12, 5.140e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 8.567e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 3.561e+00, 1.000e-12, 7.198e-01,
         3.064e-01, 3.229e-01, 1.000e+01, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.807e+00,
         1.000e-12, 1.000e-12, 1.006e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.697e-01, 3.967e+00, 1.000e-12, 1.000e-12],
        [1.000e+01, 5.589e-01, 9.013e-01, 4.230e+00, 1.000e-12, 5.028e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.843e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         4.841e+00, 2.286e-01, 1.218e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 4.029e-01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.054e+00, 1.000e-12, 5.976e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.632e+00,
         1.000e-12, 1.000e-12, 6.513e-01, 1.000e-12],
        [6.429e-01, 1.000e-12, 1.395e-01, 1.000e-12, 1.119e+00, 1.000e-12,
         1.000e-12, 1.775e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.467e-01, 1.000e-12,
         1.000e-12, 8.674e-01, 1.000e-12, 1.469e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 2.057e+00, 2.906e-01, 1.506e+00,
         3.272e+00, 1.000e-12, 2.359e-01, 4.151e-01],
        [2.072e+00, 1.000e-12, 5.498e+00, 1.000e-12, 1.000e-12, 2.305e+00,
         1.000e-12, 3.552e-01, 1.000e-12, 1.000e-12],
        [1.107e+00, 7.436e+00, 1.000e-12, 1.000e-12, 3.473e+00, 3.971e-01,
         1.000e-12, 5.244e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 8.748e+00, 1.000e-12, 4.303e-01, 4.787e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.137e+00, 1.000e-12, 3.827e-01, 1.000e-12, 1.524e-01, 1.000e-12,
         7.305e+00, 5.513e-02, 1.000e-12, 1.909e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 4.690e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         2.214e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.034e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 3.059e+00, 1.147e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 6.935e-01, 1.000e-12, 1.000e-12,
         1.843e+00, 8.744e+00, 1.000e-12, 1.000e-12],
        [1.000e+01, 2.768e+00, 7.451e-01, 1.000e-12, 2.376e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 9.931e-02, 2.467e-01],
        [3.043e+00, 5.546e+00, 1.000e-12, 1.000e-12, 5.315e+00, 1.000e-12,
         1.000e+01, 6.603e-02, 2.093e-01, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 2.305e+00, 9.045e-01, 1.000e-12,
         1.420e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 2.447e+00, 4.085e+00, 1.000e-12,
         1.000e-12, 3.556e-01, 1.000e-12, 1.000e-12],
        [1.695e+00, 7.882e-01, 1.000e-12, 1.000e-12, 2.295e-01, 1.000e-12,
         1.230e+00, 1.000e-12, 1.589e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.690e+00,
         1.000e-12, 1.000e-12, 7.475e+00, 1.000e-12],
        [6.788e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.921e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 5.488e+00, 1.990e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 6.471e-01],
        [1.000e-12, 1.000e-12, 1.894e-01, 1.000e-12, 1.000e-12, 6.535e-01,
         1.000e-12, 1.000e-12, 2.126e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 4.301e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.973e+00, 3.020e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.943e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 3.642e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 8.451e+00, 1.000e-12, 2.876e-02, 2.082e+00,
         1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12],
        [2.728e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 2.400e+00, 1.491e+00, 1.000e-12],
        [4.850e+00, 2.318e+00, 2.729e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         5.420e-01, 1.281e+00, 1.000e-12, 1.746e+00],
        [6.181e+00, 5.266e+00, 6.409e+00, 1.000e-12, 1.000e-12, 2.124e+00,
         1.000e-12, 1.765e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 3.230e-01, 1.992e+00, 7.444e-02, 1.000e-12,
         1.000e-12, 2.744e-01, 8.628e-02, 1.000e-12],
        [1.000e-12, 9.715e-01, 3.473e+00, 1.000e-12, 5.262e+00, 1.524e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 2.120e+00],
        [1.000e-12, 1.241e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.810e-01, 1.000e-12, 3.100e-01, 1.000e-12, 8.129e-01, 4.009e+00,
         1.000e-12, 2.514e+00, 1.000e-12, 1.830e-01],
        [1.000e-12, 1.000e-12, 3.534e-02, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 7.980e+00],
        [1.000e-12, 1.000e-12, 3.324e-01, 2.821e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 8.736e+00],
        [1.000e-12, 7.155e-01, 1.000e-12, 7.261e-02, 1.000e-12, 1.558e+00,
         1.000e-12, 7.128e-01, 1.892e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.497e-02, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 2.280e+00, 1.138e-01],
        [5.781e-02, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e+01, 4.435e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.831e+00, 3.433e-01, 3.647e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 8.189e-01, 1.000e+01, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.524e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 3.699e+00, 3.029e-01, 1.157e+00, 1.000e-12,
         5.067e+00, 3.065e-01, 4.924e+00, 1.000e-12],
        [8.867e-01, 1.000e-12, 1.000e-12, 2.928e+00, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 2.620e+00],
        [1.000e+01, 1.000e-12, 3.092e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 8.202e-01],
        [1.049e+00, 1.000e-12, 1.291e+00, 1.000e-12, 8.719e-01, 1.353e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.461e+00, 1.000e+01, 1.129e+00, 1.000e-12, 1.110e+00,
         1.000e-12, 1.000e-12, 3.919e+00, 1.000e-12],
        [1.000e-12, 7.009e-01, 4.076e+00, 1.000e-12, 2.880e+00, 7.094e+00,
         1.000e-12, 2.057e+00, 1.057e+00, 8.244e+00]], device='cuda:0')
v before min max tensor([ 9.407e-01, -9.746e-01, -2.627e+00,  8.650e-01, -1.719e+00, -1.180e-01,
        -3.784e-01, -1.100e+00, -1.092e+00, -8.286e-01, -6.276e-01,  8.406e-01,
         1.579e-01, -1.416e+00,  7.333e-01,  4.893e+00, -3.052e+00,  4.547e-03,
         2.209e+00,  2.110e+00, -1.133e+00, -3.928e-01, -1.853e+00, -1.191e+00,
        -1.773e+00, -1.113e+00, -1.604e+00, -1.972e+00,  2.206e+00, -4.814e-01,
        -2.445e+00, -3.204e+00, -2.093e+00,  6.344e-02, -1.037e+00, -1.415e+00,
        -4.153e-01,  6.040e+00, -1.196e+00, -2.698e+00, -2.030e+00, -1.210e+00,
        -1.608e+00, -1.792e+00, -1.583e+00,  1.881e+00, -1.777e+00, -6.636e-01,
        -1.822e+00,  6.116e+00, -1.311e+00, -1.875e+00, -1.349e+00, -1.659e+00,
        -2.159e-01, -1.892e+00,  5.515e-01, -8.159e-01,  2.035e+00, -2.307e+00,
        -5.623e-01, -5.010e-01, -3.658e-01, -1.455e+00, -1.957e+00, -1.714e+00,
         4.905e-01, -2.251e+00,  1.654e+00, -1.901e+00, -1.074e+00, -1.980e+00,
        -8.049e-01, -1.545e+00, -2.326e+00, -1.400e+00, -1.709e+00, -1.020e+00,
        -1.162e+00,  1.592e+00, -4.559e-01,  6.973e-01,  6.460e-01, -1.173e+00,
        -1.804e+00,  1.841e-02,  4.981e-01, -1.342e+00,  6.581e+00, -2.560e+00,
        -2.676e+00, -1.569e+00, -1.126e+00, -1.778e+00, -7.705e-01, -5.865e-01,
        -1.797e+00, -1.263e+00,  1.098e+00, -4.363e-01], device='cuda:0')
v tensor([9.407e-01, 1.000e-12, 1.000e-12, 8.650e-01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 8.406e-01,
        1.579e-01, 1.000e-12, 7.333e-01, 4.893e+00, 1.000e-12, 4.547e-03,
        2.209e+00, 2.110e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.206e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 6.344e-02, 1.000e-12, 1.000e-12,
        1.000e-12, 6.040e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.881e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 6.116e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 5.515e-01, 1.000e-12, 2.035e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        4.905e-01, 1.000e-12, 1.654e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.592e+00, 1.000e-12, 6.973e-01, 6.460e-01, 1.000e-12,
        1.000e-12, 1.841e-02, 4.981e-01, 1.000e-12, 6.581e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.098e+00, 1.000e-12], device='cuda:0')
v before min max tensor([[[ 0.964],
         [-1.561],
         [-0.831],
         [15.803],
         [-1.067],
         [-0.358],
         [ 2.733],
         [-1.628],
         [ 1.016],
         [ 0.043]],

        [[-1.817],
         [-0.161],
         [-2.759],
         [ 2.147],
         [ 0.226],
         [-0.821],
         [-1.848],
         [ 1.119],
         [-2.109],
         [ 6.988]],

        [[-1.891],
         [-2.150],
         [ 1.305],
         [-0.909],
         [-1.219],
         [-1.247],
         [-1.675],
         [-0.847],
         [10.808],
         [-2.237]],

        [[ 1.959],
         [ 3.001],
         [ 0.229],
         [-1.541],
         [-1.945],
         [ 4.077],
         [-2.928],
         [-1.891],
         [ 2.903],
         [ 0.901]],

        [[-0.062],
         [ 0.283],
         [-0.134],
         [-0.164],
         [ 1.920],
         [-1.692],
         [-1.204],
         [-0.430],
         [-0.735],
         [-1.064]],

        [[-1.265],
         [-1.365],
         [-0.800],
         [ 0.507],
         [-1.236],
         [-1.836],
         [ 1.050],
         [-2.802],
         [ 0.155],
         [ 4.776]],

        [[-1.212],
         [-1.229],
         [ 3.111],
         [-0.394],
         [ 0.657],
         [-0.785],
         [ 0.418],
         [-1.866],
         [-0.994],
         [-2.441]],

        [[-0.068],
         [-3.005],
         [ 0.541],
         [-1.247],
         [-1.949],
         [-1.138],
         [ 1.195],
         [-0.834],
         [-1.441],
         [-0.267]],

        [[-1.293],
         [ 3.673],
         [ 0.493],
         [-2.008],
         [-0.804],
         [-1.544],
         [ 0.240],
         [ 1.342],
         [-0.930],
         [-1.455]],

        [[-0.266],
         [-0.636],
         [-1.676],
         [-0.843],
         [ 0.854],
         [-1.464],
         [ 1.757],
         [ 0.168],
         [-1.957],
         [-1.036]]], device='cuda:0')
v tensor([[[9.636e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [2.733e+00],
         [1.000e-12],
         [1.016e+00],
         [4.313e-02]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.147e+00],
         [2.259e-01],
         [1.000e-12],
         [1.000e-12],
         [1.119e+00],
         [1.000e-12],
         [6.988e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.305e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.959e+00],
         [3.001e+00],
         [2.292e-01],
         [1.000e-12],
         [1.000e-12],
         [4.077e+00],
         [1.000e-12],
         [1.000e-12],
         [2.903e+00],
         [9.013e-01]],

        [[1.000e-12],
         [2.832e-01],
         [1.000e-12],
         [1.000e-12],
         [1.920e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.071e-01],
         [1.000e-12],
         [1.000e-12],
         [1.050e+00],
         [1.000e-12],
         [1.552e-01],
         [4.776e+00]],

        [[1.000e-12],
         [1.000e-12],
         [3.111e+00],
         [1.000e-12],
         [6.575e-01],
         [1.000e-12],
         [4.179e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [5.408e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.195e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [3.673e+00],
         [4.926e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.396e-01],
         [1.342e+00],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [8.543e-01],
         [1.000e-12],
         [1.757e+00],
         [1.680e-01],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[-0.414],
        [ 5.811],
        [ 0.528],
        [-2.467],
        [ 1.701],
        [12.315],
        [17.963],
        [-0.508],
        [-1.160],
        [-2.812]], device='cuda:0')
v tensor([[1.000e-12],
        [5.811e+00],
        [5.276e-01],
        [1.000e-12],
        [1.701e+00],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 1.532e-02, -8.932e-03,  3.146e-02,  8.758e-03,  1.918e-02,  2.608e-02,
         -4.529e-02,  4.652e-02, -5.972e-04, -3.246e-02],
        [-2.381e-03,  2.398e-02, -2.644e-03, -7.077e-03,  4.803e-03,  3.992e-02,
          1.326e-02,  5.171e-03, -1.538e-02, -3.390e-03],
        [-6.547e-04, -3.022e-02,  1.683e-02,  1.681e-02, -1.580e-02,  2.582e-02,
          7.285e-03,  5.100e-03, -3.644e-02, -1.635e-02],
        [-3.186e-04, -4.028e-03,  6.958e-03, -9.328e-03,  5.787e-02,  4.097e-02,
         -7.496e-02, -1.352e-02, -3.935e-02, -3.752e-04],
        [-1.697e-03, -4.387e-02, -8.500e-03,  3.121e-03, -1.326e-02,  3.561e-02,
         -1.431e-02, -7.249e-03,  2.972e-02, -1.251e-02],
        [-1.069e-02,  6.438e-02,  1.329e-02,  4.558e-02, -1.059e-02, -1.972e-02,
         -1.656e-03,  6.002e-03, -1.281e-02, -1.706e-02],
        [ 1.643e-03,  4.910e-02, -1.427e-02,  8.115e-03,  5.232e-03,  4.769e-02,
          3.427e-02,  1.168e-02, -9.729e-03,  5.490e-03],
        [-2.213e-03,  8.135e-03,  3.677e-02, -1.870e-03, -1.300e-02,  1.148e-02,
          1.475e-02, -1.477e-02, -1.072e-02,  2.667e-03],
        [ 9.828e-03,  1.236e-02, -1.928e-02,  5.391e-02, -3.798e-02,  2.112e-02,
         -1.228e-02, -7.303e-02,  9.886e-04, -3.392e-03],
        [ 1.119e-02, -2.769e-02, -3.668e-02,  1.795e-02,  7.302e-05,  1.331e-02,
         -3.828e-02,  6.299e-03,  2.317e-02, -8.120e-03],
        [ 2.258e-02,  1.759e-04,  2.560e-02, -2.959e-02, -4.769e-03, -2.550e-03,
          2.057e-02,  2.516e-02, -1.791e-02,  1.879e-02],
        [ 2.674e-02, -1.606e-03,  2.467e-02,  3.858e-02,  8.883e-03, -1.652e-02,
         -4.643e-02, -1.690e-02, -2.342e-02, -4.199e-04],
        [-4.791e-02,  6.758e-03,  4.607e-03,  9.262e-03, -7.094e-03, -1.037e-02,
         -2.062e-02,  4.038e-02, -3.397e-02,  3.954e-02],
        [ 2.782e-02, -4.355e-03,  1.056e-02,  2.118e-02,  3.242e-02, -8.451e-03,
         -1.143e-02,  2.908e-02,  2.711e-03, -1.017e-03],
        [-1.053e-02, -1.373e-02,  8.644e-03,  1.249e-03,  3.680e-02,  2.492e-02,
          1.216e-02,  3.349e-02,  1.473e-02,  8.958e-03],
        [-2.371e-02,  1.102e-02, -5.020e-03,  1.573e-02, -9.794e-02, -1.225e-02,
          2.384e-03, -1.967e-03,  3.598e-02, -3.820e-02],
        [ 4.142e-03, -1.715e-02, -1.205e-02, -3.981e-03, -2.215e-02,  1.678e-02,
         -4.375e-02, -1.936e-03, -5.648e-03,  9.228e-03],
        [ 1.023e-02,  2.378e-03, -2.339e-02, -2.309e-02,  6.105e-03,  1.010e-02,
          7.463e-03,  2.068e-03,  4.474e-02, -2.186e-02],
        [ 1.390e-02,  7.435e-03, -7.507e-03,  4.773e-02,  1.078e-02,  1.422e-02,
         -9.758e-03, -3.125e-03, -2.966e-02, -3.057e-02],
        [ 3.229e-03, -9.479e-03, -3.382e-02,  8.011e-03, -1.677e-02,  3.017e-02,
          3.316e-02, -8.140e-03,  6.063e-02,  4.346e-04],
        [-1.697e-02,  2.630e-03, -3.491e-03,  4.547e-02,  7.117e-03, -7.357e-04,
         -2.737e-03,  2.989e-02, -2.970e-02, -3.099e-02],
        [-3.758e-02,  7.114e-04,  2.995e-03, -1.301e-02, -5.139e-03,  2.426e-02,
         -1.324e-02, -8.708e-03, -1.150e-02,  1.430e-02],
        [-5.770e-03,  1.695e-02, -1.207e-02, -5.778e-02,  8.165e-03, -1.568e-02,
         -1.016e-02,  4.415e-02, -1.039e-02,  4.435e-02],
        [ 2.568e-02, -2.293e-02, -5.279e-03,  1.310e-02, -8.628e-03, -1.092e-02,
         -9.874e-03,  1.203e-02, -7.722e-04, -1.972e-04],
        [-8.087e-02, -4.417e-03, -5.437e-04,  3.662e-02,  1.206e-02, -1.689e-02,
         -1.011e-02, -5.109e-02,  4.311e-02,  1.847e-02],
        [ 8.096e-03, -4.887e-03,  2.360e-03,  1.166e-02, -4.014e-03, -4.049e-02,
         -2.074e-02,  2.636e-02, -7.950e-03,  1.582e-03],
        [-4.582e-02,  1.957e-02, -1.891e-02, -2.189e-02,  3.624e-03,  1.219e-03,
          1.531e-02,  1.837e-02, -2.856e-02, -1.747e-02],
        [ 2.704e-02, -1.657e-02,  1.188e-02, -1.742e-03, -4.933e-02, -3.285e-03,
          9.150e-03, -8.744e-03, -1.525e-02, -1.217e-02],
        [ 9.138e-03,  3.273e-03, -1.937e-02,  5.056e-02,  1.757e-03,  5.106e-02,
         -5.278e-03,  1.045e-02, -3.703e-02, -5.719e-02],
        [ 6.192e-03, -1.722e-03, -4.248e-03, -4.377e-02, -1.449e-02,  6.786e-02,
          9.021e-03,  2.103e-02, -1.048e-02,  1.002e-01],
        [ 1.145e-02, -7.169e-03, -5.693e-03,  6.333e-03,  2.404e-02, -1.361e-02,
          5.964e-03, -5.126e-04, -7.308e-02, -2.279e-02],
        [ 5.449e-03,  1.863e-03,  1.625e-03,  1.916e-03, -7.590e-04,  8.275e-03,
         -1.479e-02, -1.743e-03, -5.227e-02, -1.639e-02],
        [ 9.677e-03, -1.030e-03,  1.075e-02,  5.903e-04,  1.932e-02, -6.648e-04,
         -1.103e-02,  6.464e-03, -1.375e-02,  4.790e-03],
        [ 1.286e-03, -8.573e-03, -1.026e-02,  1.479e-02, -9.601e-03, -3.937e-05,
          2.876e-02, -1.400e-02, -7.512e-03,  7.887e-03],
        [ 9.327e-03, -5.273e-03, -6.935e-03, -9.638e-03,  2.434e-03, -1.170e-02,
          1.410e-02,  8.842e-04,  2.716e-03, -4.444e-03],
        [ 7.994e-03, -3.427e-03, -1.347e-02, -3.260e-04, -4.536e-03,  4.506e-03,
         -1.206e-02,  1.022e-02, -2.262e-02, -1.993e-02],
        [-3.150e-03,  4.757e-03,  7.242e-03,  2.027e-02, -2.337e-02,  8.615e-03,
          6.415e-03, -2.642e-02,  2.301e-03, -7.424e-03],
        [-7.436e-03,  4.340e-03,  8.033e-03, -2.549e-03,  1.789e-03, -2.202e-03,
          3.031e-04, -1.183e-02, -1.539e-02, -2.208e-02],
        [ 2.817e-02, -1.299e-02, -1.853e-02,  6.960e-03,  4.685e-03, -5.336e-03,
          1.295e-03, -4.936e-02, -2.466e-02,  1.536e-03],
        [-4.696e-02, -2.095e-02, -6.481e-03,  6.270e-03,  1.961e-02,  1.307e-03,
         -4.261e-03,  1.472e-02, -1.219e-02,  3.273e-03],
        [-3.017e-03, -3.516e-02, -1.204e-02,  3.337e-02,  4.945e-04, -2.950e-02,
          3.691e-02, -5.354e-03, -3.359e-02,  4.628e-02],
        [-3.372e-02, -3.969e-02, -9.708e-03, -2.299e-02,  1.831e-02,  9.135e-03,
         -1.310e-02,  3.540e-02,  1.358e-03,  2.113e-02],
        [-2.164e-03,  9.672e-03,  1.742e-02, -4.317e-02, -2.604e-02, -9.420e-03,
         -2.076e-02, -5.238e-03,  2.921e-02, -4.462e-03],
        [-2.334e-02, -6.102e-02, -4.571e-02, -1.922e-02, -7.253e-03, -5.482e-03,
          2.099e-02, -1.543e-02, -9.218e-03,  2.754e-02],
        [ 2.687e-02,  3.117e-03,  2.890e-02,  1.952e-02, -8.936e-03, -3.788e-02,
          7.772e-04, -5.604e-02,  4.806e-02, -1.755e-02],
        [ 7.679e-02,  9.770e-03,  1.987e-02,  2.403e-02,  4.119e-03, -1.217e-02,
          2.758e-02,  4.956e-02,  1.970e-02, -1.696e-02],
        [ 3.179e-02, -2.459e-02, -3.146e-04,  4.584e-02, -2.237e-04,  1.105e-02,
          5.161e-03,  8.681e-03, -2.227e-02,  6.093e-02],
        [-1.432e-02, -4.558e-03, -1.955e-03, -2.123e-02,  2.140e-02,  5.575e-03,
         -3.281e-03, -1.938e-02, -2.117e-02, -4.708e-03],
        [-3.106e-02,  5.892e-02, -3.480e-02, -2.302e-02, -1.642e-02,  2.554e-03,
         -2.123e-03,  1.228e-02,  1.181e-02,  1.654e-02],
        [-2.247e-02, -5.199e-02, -2.443e-02, -7.760e-03,  2.257e-03,  2.359e-04,
         -2.813e-02,  3.985e-02, -3.254e-02, -1.135e-02],
        [-7.497e-03, -3.983e-02,  1.337e-02,  4.345e-02,  2.503e-03,  2.053e-02,
          1.035e-02,  7.493e-03,  4.005e-02, -4.094e-02],
        [-2.748e-02,  2.613e-02, -6.659e-03,  1.153e-02, -8.776e-03, -4.040e-04,
          1.114e-02,  2.393e-02,  1.145e-03,  1.111e-02],
        [-2.882e-02, -6.360e-02,  4.802e-02,  1.473e-02,  1.528e-02, -1.906e-03,
          5.994e-03, -1.623e-02, -3.827e-02,  1.955e-04],
        [ 2.966e-02,  3.154e-02,  1.455e-02,  6.199e-02,  4.479e-03,  2.230e-03,
          3.202e-02, -3.279e-02, -2.565e-02, -1.802e-02],
        [-2.230e-04, -2.665e-02, -6.622e-03,  4.749e-02,  2.165e-02, -1.296e-02,
          1.113e-01, -2.012e-02, -3.301e-02, -6.219e-03],
        [ 4.509e-03,  1.890e-02,  6.449e-03,  3.181e-02, -2.899e-03, -4.669e-03,
         -3.165e-03,  1.093e-02,  1.826e-02, -8.285e-03],
        [-9.360e-03, -1.980e-03, -3.050e-02, -5.063e-02,  2.296e-02,  1.514e-02,
         -8.269e-02,  5.294e-03, -2.916e-02,  6.906e-03],
        [-2.019e-03,  1.529e-02, -8.359e-03,  2.001e-02, -7.365e-03, -4.861e-03,
          2.030e-02, -2.776e-02,  3.753e-03, -4.428e-02],
        [ 6.450e-03, -3.340e-02, -1.937e-02,  5.146e-02, -1.657e-02,  3.571e-03,
         -6.466e-03,  2.283e-03,  4.050e-02, -1.389e-02],
        [ 2.131e-02,  1.846e-02,  3.648e-02,  4.745e-02,  2.040e-02, -1.196e-02,
         -1.198e-03,  5.914e-02, -2.133e-03, -2.123e-02],
        [ 1.150e-02, -5.158e-03, -3.211e-03,  5.255e-02, -2.543e-04,  1.211e-02,
         -8.841e-03,  3.085e-02,  3.417e-02, -9.500e-03],
        [ 8.993e-03, -2.785e-04, -6.696e-03,  8.396e-03, -3.335e-03, -1.099e-02,
         -7.705e-03, -1.515e-02, -1.885e-02, -1.963e-02],
        [-1.164e-02,  1.397e-02, -1.965e-02,  1.529e-02,  7.233e-04, -1.475e-02,
         -2.762e-03, -1.728e-02,  1.400e-02,  5.972e-02],
        [ 1.748e-02,  1.673e-02,  5.860e-02,  4.677e-02,  1.421e-02, -4.142e-02,
         -5.732e-03, -1.990e-03, -1.948e-02, -2.537e-02],
        [-2.317e-02, -1.652e-02, -2.763e-02, -3.939e-02, -5.763e-03,  2.139e-02,
         -1.080e-02, -4.049e-02,  1.691e-03,  2.783e-03],
        [-8.340e-03, -1.921e-02, -2.938e-03,  3.058e-02,  9.207e-03,  6.501e-03,
         -6.647e-03, -2.051e-03, -6.770e-03, -4.096e-02],
        [ 1.082e-02, -2.730e-03,  3.759e-03,  5.995e-03, -5.954e-03,  2.319e-02,
         -8.057e-03,  8.122e-03,  3.725e-03, -5.746e-03],
        [ 3.744e-02, -1.445e-02, -2.615e-02, -3.955e-02,  8.342e-03,  2.517e-02,
          3.132e-03,  2.849e-03,  1.161e-02,  9.385e-03],
        [ 5.872e-02, -1.135e-02, -1.318e-02, -1.022e-02, -1.496e-02,  9.729e-03,
          8.962e-03, -1.557e-02, -6.288e-03, -4.307e-02],
        [ 1.057e-02,  1.014e-03, -2.464e-03,  4.973e-02, -2.114e-02,  1.883e-02,
         -1.220e-03, -4.982e-02, -1.381e-02,  6.195e-03],
        [ 4.027e-04, -2.370e-03, -1.319e-02,  6.951e-03,  4.622e-03,  7.009e-03,
          4.186e-02,  8.614e-03,  7.130e-03, -9.257e-03],
        [ 1.809e-03, -1.792e-02, -5.972e-03, -1.944e-03,  1.974e-02, -5.688e-03,
          5.045e-02,  1.281e-02,  1.995e-02,  1.435e-03],
        [-2.201e-02, -7.928e-03, -1.969e-02, -1.641e-02,  1.133e-02, -1.298e-03,
         -3.603e-02,  7.997e-03, -2.812e-03, -1.584e-02],
        [-1.681e-02, -2.481e-03,  6.362e-03, -2.976e-02, -1.144e-02, -6.856e-03,
          3.096e-02, -5.007e-03,  4.136e-02, -4.881e-02],
        [-1.243e-02,  1.242e-02,  8.542e-03, -2.576e-03, -1.011e-03, -1.656e-02,
          7.278e-03,  7.270e-03, -1.404e-02,  1.037e-02],
        [ 2.587e-02,  4.065e-03,  9.386e-03,  5.298e-02, -2.482e-02, -1.302e-02,
         -9.973e-03,  1.841e-03, -1.077e-02, -3.044e-02],
        [-4.755e-02,  3.816e-02,  1.496e-02,  1.507e-02,  4.224e-02,  1.999e-02,
          2.131e-02, -1.550e-03,  3.499e-03, -5.756e-03],
        [-2.149e-02, -1.763e-02,  7.179e-03,  9.494e-03,  9.738e-03,  3.000e-03,
          1.250e-03, -1.388e-03, -1.871e-02, -3.553e-02],
        [-7.470e-03, -4.262e-02, -3.865e-03,  6.136e-03, -1.238e-02,  1.446e-02,
          1.205e-03, -7.336e-03,  9.691e-03, -1.474e-02],
        [ 3.938e-03,  3.365e-04, -3.078e-02,  5.346e-03, -1.934e-02,  5.875e-04,
         -1.355e-02,  1.781e-04, -1.441e-02, -7.499e-03],
        [ 1.233e-02, -2.498e-03,  3.107e-02,  6.291e-03, -1.675e-02,  1.293e-02,
         -6.230e-02,  2.079e-02, -1.006e-02,  4.598e-03],
        [-9.712e-03,  4.137e-03,  2.809e-02, -4.372e-02,  3.094e-02, -1.652e-02,
          2.872e-02, -2.800e-02,  4.385e-03, -1.602e-02],
        [ 3.115e-02, -1.077e-02,  2.707e-04, -1.501e-02, -4.021e-03, -3.957e-02,
          4.005e-02, -2.789e-02,  1.003e-02, -9.082e-03],
        [-1.786e-02,  2.264e-02, -1.898e-02, -1.571e-02,  1.024e-02, -1.780e-02,
          8.946e-02,  7.752e-04,  3.044e-02,  4.501e-03],
        [ 1.699e-02, -9.319e-03, -1.079e-02,  1.160e-02,  2.478e-02, -2.681e-02,
         -1.464e-03,  2.044e-02, -9.146e-04, -8.164e-04],
        [-2.039e-02,  6.292e-03, -4.514e-03,  1.084e-02, -2.703e-03,  8.668e-03,
          1.380e-02, -9.127e-03, -2.642e-03,  1.713e-02],
        [-2.025e-02,  1.020e-02, -2.761e-02, -8.151e-03, -7.102e-03, -1.521e-02,
         -6.821e-03, -7.484e-03, -5.041e-04, -3.603e-03],
        [-5.416e-03,  1.750e-02, -3.717e-03, -3.644e-03, -2.228e-02,  1.207e-03,
         -2.392e-02,  1.362e-02,  9.090e-03, -1.310e-02],
        [ 5.068e-04, -2.241e-03,  1.846e-02,  1.589e-02,  5.435e-03, -3.831e-02,
          3.577e-02, -1.886e-03, -7.859e-03,  5.887e-03],
        [-4.104e-03,  9.968e-03, -2.155e-02, -2.631e-02,  6.772e-03, -2.561e-02,
         -3.618e-03,  3.281e-02,  1.928e-02, -8.714e-04],
        [ 1.484e-02, -8.241e-03, -3.790e-02,  3.210e-03,  2.658e-03,  3.083e-04,
         -2.584e-02,  1.601e-02,  1.594e-02,  2.353e-02],
        [ 2.020e-02, -3.808e-03, -8.469e-03, -5.617e-02, -2.862e-02, -1.217e-03,
          1.922e-02, -3.322e-02, -1.948e-02,  1.555e-02],
        [ 1.928e-02, -5.237e-02, -1.345e-05, -1.312e-02, -8.258e-03, -1.085e-02,
          4.024e-02,  4.767e-03,  1.301e-02,  1.080e-02],
        [-1.956e-02, -1.057e-03,  1.570e-02,  2.110e-02,  1.763e-03,  6.774e-03,
          2.048e-02,  1.894e-02, -2.546e-02, -2.421e-02],
        [ 3.242e-03,  9.195e-03, -1.959e-02, -8.768e-03,  9.972e-03, -1.169e-02,
          1.626e-02, -4.438e-03,  6.169e-02, -3.763e-03],
        [-3.774e-02,  6.687e-02, -5.245e-03, -2.064e-02,  8.681e-03, -4.948e-02,
          2.715e-02,  4.921e-03, -5.777e-02,  1.168e-02],
        [ 5.768e-03, -2.818e-02, -1.319e-02, -2.605e-02, -1.443e-02,  4.474e-02,
          2.381e-02,  2.300e-02,  5.710e-02,  4.620e-03],
        [ 1.395e-02, -7.397e-03, -1.882e-02,  1.682e-03, -2.413e-02,  4.347e-03,
         -1.389e-02,  1.377e-02, -3.927e-02,  7.373e-04],
        [-2.385e-03,  4.418e-02, -9.154e-04, -1.184e-03, -2.454e-02,  8.681e-03,
          2.753e-02,  4.629e-03, -4.883e-02,  3.196e-03],
        [ 5.842e-02, -4.448e-02, -2.669e-02,  8.511e-03, -3.352e-04, -3.630e-02,
         -4.386e-02,  1.022e-02, -2.480e-02, -5.262e-04]], device='cuda:0')
s after update for 1 param tensor([[0.929, 0.878, 0.884, 0.659, 0.834, 0.626, 1.120, 0.611, 1.418, 0.635],
        [0.648, 0.702, 0.707, 0.608, 1.146, 1.063, 0.720, 1.177, 0.640, 0.399],
        [0.767, 1.036, 1.085, 0.934, 1.021, 1.618, 0.953, 1.090, 0.998, 1.021],
        [0.621, 1.177, 1.651, 1.315, 0.765, 0.369, 1.047, 0.766, 0.708, 1.330],
        [1.470, 0.434, 0.834, 0.780, 0.422, 0.894, 0.933, 0.592, 0.875, 1.448],
        [1.313, 0.674, 1.284, 0.849, 0.559, 0.719, 0.711, 0.701, 0.941, 0.948],
        [0.807, 0.732, 1.601, 0.921, 0.695, 0.428, 0.935, 0.600, 0.254, 0.895],
        [0.727, 1.238, 0.624, 0.739, 1.029, 1.076, 0.738, 0.768, 0.709, 1.360],
        [1.345, 0.795, 0.979, 0.610, 1.133, 1.198, 1.220, 1.483, 0.665, 0.817],
        [1.208, 0.861, 1.134, 1.049, 0.907, 1.130, 0.793, 1.125, 0.886, 1.294],
        [1.126, 1.097, 0.948, 0.639, 1.021, 1.515, 0.890, 0.550, 0.885, 1.104],
        [0.665, 1.059, 0.599, 1.817, 0.881, 0.482, 1.534, 1.110, 0.386, 0.685],
        [0.831, 0.853, 1.187, 1.273, 0.697, 0.869, 1.790, 0.702, 0.506, 1.065],
        [1.931, 0.753, 0.865, 0.502, 1.040, 0.742, 0.629, 1.098, 0.934, 0.548],
        [1.016, 0.987, 1.097, 1.024, 0.524, 0.667, 0.946, 0.734, 0.740, 0.602],
        [0.561, 0.939, 0.916, 1.255, 0.814, 1.073, 0.761, 1.173, 0.339, 0.702],
        [0.863, 0.886, 1.115, 1.062, 1.378, 0.607, 1.065, 0.440, 1.094, 0.685],
        [1.085, 0.998, 0.808, 1.041, 0.838, 1.292, 0.991, 1.195, 0.402, 0.623],
        [0.609, 1.133, 0.950, 0.652, 1.270, 1.326, 0.706, 0.846, 0.559, 0.872],
        [1.072, 0.601, 1.403, 0.849, 0.802, 0.516, 0.994, 0.947, 1.308, 0.657],
        [0.795, 1.003, 1.318, 0.633, 0.802, 0.795, 0.914, 0.865, 0.640, 0.815],
        [0.936, 0.743, 1.222, 0.368, 0.502, 1.194, 0.576, 0.610, 0.972, 0.718],
        [1.030, 0.906, 0.929, 0.959, 0.995, 0.801, 0.726, 1.172, 0.908, 1.240],
        [0.753, 0.437, 0.897, 0.544, 0.487, 0.786, 0.732, 0.712, 0.241, 1.361],
        [1.315, 0.617, 0.559, 1.148, 0.658, 0.406, 0.675, 0.931, 0.933, 0.979],
        [0.598, 0.771, 0.922, 0.802, 0.627, 0.654, 0.509, 0.737, 0.927, 1.030],
        [1.096, 0.600, 1.301, 0.573, 0.945, 0.928, 0.788, 0.763, 0.328, 1.177],
        [1.437, 1.047, 1.458, 0.676, 0.632, 0.970, 1.390, 0.759, 0.751, 0.719],
        [0.821, 0.691, 1.587, 0.710, 0.792, 0.748, 0.951, 0.572, 0.745, 0.668],
        [0.451, 0.280, 1.045, 0.949, 0.964, 1.248, 0.476, 0.687, 0.443, 1.080],
        [0.834, 0.767, 0.966, 0.394, 0.869, 0.909, 1.051, 0.573, 1.249, 0.708],
        [0.481, 0.686, 0.393, 1.177, 0.788, 0.849, 0.761, 0.626, 0.678, 1.063],
        [1.048, 0.736, 0.772, 0.841, 1.020, 0.607, 0.721, 1.280, 0.559, 0.410],
        [0.446, 0.828, 0.880, 1.112, 1.017, 1.087, 1.076, 1.061, 0.477, 1.099],
        [1.043, 1.162, 0.739, 0.912, 0.985, 1.262, 1.199, 0.487, 1.059, 1.253],
        [1.114, 0.689, 0.447, 1.118, 0.886, 1.179, 0.346, 0.677, 0.788, 0.912],
        [0.959, 0.876, 0.982, 1.658, 1.520, 1.123, 0.854, 1.329, 0.634, 0.851],
        [0.571, 0.900, 0.715, 1.152, 0.407, 0.672, 0.557, 0.612, 1.048, 0.831],
        [1.067, 1.642, 0.793, 1.111, 0.878, 1.092, 0.738, 1.196, 1.265, 0.734],
        [1.019, 0.887, 0.680, 0.846, 1.104, 0.780, 0.783, 0.856, 0.999, 0.793],
        [0.884, 0.832, 0.880, 1.051, 0.661, 0.656, 1.048, 0.445, 0.678, 1.060],
        [1.270, 1.047, 1.154, 1.420, 1.398, 0.892, 0.611, 0.908, 1.372, 0.637],
        [0.997, 0.949, 0.744, 1.075, 1.351, 1.206, 0.385, 0.927, 1.102, 0.698],
        [0.454, 0.847, 0.810, 1.020, 0.816, 0.544, 1.023, 0.812, 0.837, 0.684],
        [0.458, 0.908, 0.697, 0.691, 1.104, 1.133, 0.922, 0.793, 0.821, 0.909],
        [0.665, 0.904, 0.571, 0.468, 0.926, 1.049, 0.731, 0.725, 1.127, 1.080],
        [0.886, 1.661, 0.305, 1.721, 1.073, 0.825, 0.810, 1.236, 0.760, 1.209],
        [1.048, 0.555, 0.781, 1.270, 0.776, 0.617, 1.117, 1.606, 1.176, 0.515],
        [1.372, 0.863, 0.716, 0.491, 1.552, 1.199, 0.923, 1.187, 0.615, 1.035],
        [0.538, 0.768, 0.830, 0.800, 0.661, 1.243, 1.069, 0.372, 1.625, 0.590],
        [0.770, 1.075, 0.564, 0.580, 1.474, 1.134, 0.949, 1.176, 0.747, 0.648],
        [0.893, 1.378, 0.767, 0.595, 1.137, 0.762, 0.853, 1.001, 0.957, 1.169],
        [1.437, 0.989, 0.881, 0.859, 0.921, 0.448, 1.187, 0.655, 0.564, 1.401],
        [0.804, 0.966, 1.334, 0.700, 1.129, 0.695, 1.116, 0.502, 0.678, 0.286],
        [0.890, 0.780, 0.801, 0.684, 0.693, 1.298, 1.126, 1.333, 0.591, 1.114],
        [0.207, 0.916, 0.695, 1.080, 1.120, 1.066, 1.322, 1.193, 1.018, 1.024],
        [0.571, 0.870, 0.826, 1.033, 1.234, 0.964, 1.006, 0.851, 0.700, 1.470],
        [0.775, 0.709, 1.420, 0.837, 0.883, 0.703, 0.851, 0.517, 0.457, 1.209],
        [0.568, 0.996, 0.791, 0.961, 0.817, 0.898, 0.950, 1.134, 0.682, 0.386],
        [0.805, 1.019, 1.488, 1.238, 1.346, 0.965, 0.979, 0.979, 0.379, 0.712],
        [0.467, 1.328, 0.712, 0.781, 1.108, 1.131, 1.001, 1.461, 0.749, 0.542],
        [1.400, 1.326, 1.694, 0.418, 1.166, 0.776, 1.218, 0.810, 0.804, 0.503],
        [0.867, 0.865, 0.548, 0.978, 0.985, 1.234, 1.361, 1.034, 0.786, 0.735],
        [0.312, 1.190, 1.293, 0.962, 0.345, 0.376, 1.239, 0.575, 0.630, 1.078],
        [1.131, 1.137, 1.332, 0.729, 1.337, 1.034, 1.348, 0.826, 1.204, 0.493],
        [1.391, 0.665, 0.612, 0.353, 0.628, 1.005, 0.891, 1.084, 1.252, 0.947],
        [1.264, 1.332, 0.390, 0.623, 1.367, 0.518, 0.637, 1.437, 0.835, 0.908],
        [1.418, 0.989, 0.829, 0.944, 1.040, 0.919, 0.782, 1.551, 0.847, 1.255],
        [1.233, 1.203, 0.953, 0.694, 1.217, 0.583, 1.601, 0.812, 0.568, 1.532],
        [0.836, 0.820, 0.446, 0.791, 0.767, 0.724, 0.797, 0.896, 1.192, 0.917],
        [0.549, 0.795, 0.461, 1.056, 1.123, 1.113, 0.978, 0.820, 0.804, 0.949],
        [0.728, 0.531, 1.037, 0.959, 1.418, 0.468, 0.657, 1.206, 0.820, 1.070],
        [1.431, 0.417, 0.837, 1.010, 0.725, 0.921, 0.866, 0.947, 1.274, 0.663],
        [1.188, 1.336, 0.716, 0.284, 0.745, 1.372, 1.359, 1.055, 0.678, 0.762],
        [0.332, 0.706, 1.296, 0.730, 0.602, 1.475, 0.454, 0.636, 0.842, 0.842],
        [0.767, 0.636, 1.716, 0.872, 0.441, 0.551, 0.630, 0.985, 0.843, 0.469],
        [1.323, 0.821, 1.108, 0.457, 0.738, 1.186, 1.039, 0.928, 0.986, 1.442],
        [0.732, 0.686, 1.002, 0.297, 1.097, 0.995, 1.459, 1.085, 1.107, 0.868],
        [0.428, 0.962, 1.436, 0.634, 0.706, 0.995, 1.300, 1.058, 1.592, 1.214],
        [0.503, 1.226, 0.499, 0.457, 1.001, 0.606, 0.719, 1.140, 0.674, 0.516],
        [0.927, 1.231, 0.639, 0.608, 0.809, 0.451, 0.920, 0.575, 0.957, 1.169],
        [1.055, 0.958, 1.388, 0.401, 0.863, 0.976, 1.386, 0.990, 0.954, 0.715],
        [0.834, 0.790, 0.440, 0.630, 0.739, 1.340, 0.635, 0.688, 0.803, 0.792],
        [0.349, 1.165, 0.753, 1.312, 1.015, 0.714, 1.177, 1.112, 0.910, 0.990],
        [0.799, 0.894, 0.569, 0.709, 1.490, 1.478, 0.690, 0.622, 1.037, 0.899],
        [0.839, 0.572, 0.411, 0.925, 0.568, 1.067, 0.538, 0.947, 0.711, 0.654],
        [0.768, 0.739, 0.683, 1.077, 0.931, 0.775, 0.579, 0.662, 1.245, 1.472],
        [0.676, 1.163, 0.537, 0.677, 1.539, 0.461, 0.445, 0.762, 0.704, 1.553],
        [0.836, 0.835, 0.492, 0.410, 0.835, 0.770, 0.996, 0.572, 1.115, 0.539],
        [1.206, 1.408, 0.539, 0.792, 1.003, 0.788, 0.432, 1.054, 0.925, 0.548],
        [0.749, 1.063, 0.452, 0.731, 1.584, 1.147, 0.982, 0.940, 1.166, 1.415],
        [1.506, 0.940, 0.982, 1.493, 0.932, 0.769, 0.730, 0.784, 0.420, 1.389],
        [0.408, 1.134, 0.918, 0.412, 0.497, 0.794, 1.092, 0.450, 1.254, 1.264],
        [1.295, 0.787, 0.811, 1.111, 0.873, 0.642, 1.601, 1.481, 0.658, 1.298],
        [0.803, 0.959, 1.275, 0.531, 0.542, 1.039, 0.892, 0.296, 1.618, 1.279],
        [1.239, 0.863, 0.699, 0.815, 1.301, 0.618, 0.733, 0.582, 1.001, 1.458],
        [1.787, 0.677, 0.942, 1.123, 0.747, 1.031, 0.857, 0.817, 0.752, 1.076],
        [0.857, 0.286, 0.863, 1.390, 0.453, 0.843, 0.372, 1.055, 0.429, 0.715],
        [0.840, 1.083, 1.492, 0.960, 0.644, 0.793, 0.874, 0.667, 0.974, 0.983],
        [0.969, 0.967, 1.319, 0.893, 1.043, 1.292, 0.892, 1.024, 0.922, 1.194]],
       device='cuda:0')
b after update for 1 param tensor([[31.909, 31.005, 31.113, 26.874, 30.233, 26.188, 35.032, 25.867, 39.410,
         26.365],
        [26.635, 27.722, 27.821, 25.815, 35.435, 34.116, 28.078, 35.907, 26.473,
         20.901],
        [28.980, 33.680, 34.475, 31.990, 33.450, 42.106, 32.314, 34.549, 33.056,
         33.438],
        [26.090, 35.913, 42.521, 37.956, 28.948, 20.101, 33.860, 28.972, 27.857,
         38.163],
        [40.127, 21.808, 30.224, 29.237, 21.509, 31.287, 31.962, 25.475, 30.966,
         39.822],
        [37.926, 27.174, 37.507, 30.495, 24.756, 28.055, 27.908, 27.704, 32.111,
         32.220],
        [29.725, 28.317, 41.872, 31.763, 27.586, 21.662, 32.010, 25.642, 16.671,
         31.306],
        [28.225, 36.821, 26.135, 28.454, 33.568, 34.329, 28.441, 28.999, 27.867,
         38.604],
        [38.391, 29.511, 32.751, 25.839, 35.222, 36.232, 36.561, 40.310, 26.989,
         29.925],
        [36.379, 30.705, 35.238, 33.904, 31.514, 35.183, 29.474, 35.108, 31.152,
         37.645],
        [35.115, 34.661, 32.226, 26.467, 33.449, 40.736, 31.225, 24.555, 31.140,
         34.774],
        [26.983, 34.063, 25.615, 44.619, 31.061, 22.976, 40.986, 34.870, 20.565,
         27.385],
        [30.165, 30.577, 36.059, 37.350, 27.628, 30.861, 44.287, 27.739, 23.543,
         34.156],
        [45.991, 28.721, 30.790, 23.461, 33.760, 28.507, 26.247, 34.685, 31.978,
         24.500],
        [33.356, 32.876, 34.663, 33.491, 23.951, 27.038, 32.192, 28.359, 28.472,
         25.681],
        [24.789, 32.065, 31.672, 37.085, 29.856, 34.278, 28.879, 35.841, 19.259,
         27.740],
        [30.743, 31.146, 34.944, 34.108, 38.859, 25.777, 34.148, 21.944, 34.612,
         27.383],
        [34.482, 33.068, 29.757, 33.769, 30.295, 37.616, 32.956, 36.178, 20.990,
         26.117],
        [25.824, 35.237, 32.267, 26.719, 37.297, 38.116, 27.813, 30.444, 24.753,
         30.898],
        [34.268, 25.664, 39.208, 30.502, 29.631, 23.786, 33.004, 32.207, 37.848,
         26.825],
        [29.518, 33.140, 37.999, 26.340, 29.644, 29.513, 31.634, 30.781, 26.472,
         29.879],
        [32.025, 28.536, 36.583, 20.076, 23.454, 36.165, 25.115, 25.852, 32.638,
         28.040],
        [33.590, 31.495, 31.893, 32.415, 33.021, 29.624, 28.206, 35.836, 31.547,
         36.853],
        [28.717, 21.880, 31.353, 24.404, 23.104, 29.335, 28.309, 27.930, 16.235,
         38.607],
        [37.958, 25.999, 24.741, 35.465, 26.839, 21.076, 27.191, 31.932, 31.975,
         32.745],
        [25.590, 29.055, 31.775, 29.642, 26.218, 26.772, 23.604, 28.420, 31.869,
         33.583],
        [34.645, 25.647, 37.745, 25.046, 32.176, 31.890, 29.389, 28.903, 18.967,
         35.903],
        [39.681, 33.870, 39.962, 27.208, 26.312, 32.589, 39.022, 28.825, 28.689,
         28.066],
        [29.995, 27.514, 41.690, 27.888, 29.460, 28.625, 32.270, 25.023, 28.571,
         27.050],
        [22.233, 17.503, 33.831, 32.242, 32.493, 36.970, 22.835, 27.424, 22.021,
         34.390],
        [30.225, 28.990, 32.522, 20.774, 30.858, 31.558, 33.930, 25.052, 36.995,
         27.855],
        [22.962, 27.410, 20.740, 35.901, 29.381, 30.490, 28.869, 26.178, 27.246,
         34.122],
        [33.882, 28.389, 29.086, 30.352, 33.426, 25.794, 28.108, 37.446, 24.738,
         21.202],
        [22.109, 30.112, 31.055, 34.904, 33.373, 34.509, 34.338, 34.086, 22.849,
         34.701],
        [33.794, 35.675, 28.451, 31.611, 32.849, 37.182, 36.237, 23.103, 34.055,
         37.047],
        [34.928, 27.478, 22.119, 34.995, 31.162, 35.942, 19.468, 27.232, 29.388,
         31.609],
        [32.417, 30.974, 32.796, 42.617, 40.805, 35.066, 30.589, 38.162, 26.360,
         30.537],
        [25.003, 31.402, 27.994, 35.523, 21.119, 27.128, 24.705, 25.901, 33.888,
         30.164],
        [34.184, 42.412, 29.465, 34.884, 31.021, 34.581, 28.437, 36.203, 37.220,
         28.353],
        [33.414, 31.179, 27.301, 30.435, 34.780, 29.230, 29.285, 30.613, 33.080,
         29.471],
        [31.112, 30.185, 31.040, 33.934, 26.902, 26.801, 33.879, 22.086, 27.244,
         34.080],
        [37.293, 33.874, 35.561, 39.438, 39.131, 31.256, 25.865, 31.536, 38.764,
         26.418],
        [33.040, 32.235, 28.541, 34.320, 38.469, 36.349, 20.549, 31.869, 34.751,
         27.659],
        [22.309, 30.454, 29.780, 33.430, 29.899, 24.412, 33.472, 29.822, 30.287,
         27.366],
        [22.399, 31.531, 27.623, 27.514, 34.771, 35.231, 31.787, 29.471, 29.984,
         31.549],
        [26.995, 31.473, 25.013, 22.637, 31.846, 33.893, 28.307, 28.176, 35.134,
         34.396],
        [31.145, 42.657, 18.266, 43.418, 34.287, 30.056, 29.786, 36.802, 28.847,
         36.391],
        [33.889, 24.654, 29.244, 37.297, 29.156, 25.992, 34.974, 41.946, 35.892,
         23.749],
        [38.762, 30.747, 27.998, 23.184, 41.237, 36.234, 31.793, 36.062, 25.965,
         33.664],
        [24.277, 29.014, 30.157, 29.599, 26.912, 36.905, 34.218, 20.180, 42.185,
         25.420],
        [29.046, 34.309, 24.853, 25.197, 40.180, 35.240, 32.242, 35.899, 28.610,
         26.641],
        [31.277, 38.851, 28.984, 25.539, 35.292, 28.887, 30.567, 33.106, 32.375,
         35.780],
        [39.676, 32.918, 31.062, 30.680, 31.770, 22.156, 36.057, 26.791, 24.864,
         39.173],
        [29.684, 32.524, 38.231, 27.696, 35.174, 27.584, 34.957, 23.441, 27.258,
         17.695],
        [31.223, 29.221, 29.615, 27.364, 27.544, 37.709, 35.119, 38.209, 25.452,
         34.936],
        [15.044, 31.674, 27.591, 34.403, 35.024, 34.177, 38.055, 36.147, 33.401,
         33.499],
        [25.012, 30.878, 30.077, 33.636, 36.761, 32.494, 33.195, 30.533, 27.701,
         40.128],
        [29.133, 27.876, 39.440, 30.286, 31.101, 27.741, 30.533, 23.800, 22.362,
         36.393],
        [24.954, 33.030, 29.437, 32.447, 29.921, 31.371, 32.259, 35.243, 27.339,
         20.566],
        [29.701, 33.409, 40.372, 36.826, 38.393, 32.520, 32.742, 32.752, 20.366,
         27.923],
        [22.608, 38.139, 27.932, 29.243, 34.833, 35.192, 33.109, 40.010, 28.646,
         24.365],
        [39.167, 38.110, 43.077, 21.406, 35.733, 29.150, 36.534, 29.791, 29.673,
         23.483],
        [30.812, 30.775, 24.496, 32.731, 32.854, 36.772, 38.614, 33.653, 29.338,
         28.369],
        [18.485, 36.106, 37.634, 32.463, 19.438, 20.287, 36.844, 25.089, 26.274,
         34.365],
        [35.195, 35.285, 38.203, 28.249, 38.267, 33.661, 38.433, 30.074, 36.313,
         23.249],
        [39.033, 26.999, 25.883, 19.656, 26.234, 33.184, 31.233, 34.454, 37.031,
         32.205],
        [37.212, 38.197, 20.674, 26.127, 38.693, 23.828, 26.418, 39.677, 30.240,
         31.534],
        [39.417, 32.909, 30.139, 32.161, 33.758, 31.731, 29.276, 41.222, 30.459,
         37.076],
        [36.749, 36.305, 32.310, 27.569, 36.509, 25.271, 41.877, 29.820, 24.954,
         40.965],
        [30.267, 29.962, 22.094, 29.427, 28.984, 28.159, 29.552, 31.337, 36.137,
         31.695],
        [24.529, 29.503, 22.464, 34.010, 35.080, 34.920, 32.734, 29.964, 29.686,
         32.239],
        [28.240, 24.110, 33.707, 32.416, 39.414, 22.630, 26.822, 36.343, 29.966,
         34.242],
        [39.590, 21.382, 30.276, 33.257, 28.190, 31.764, 30.808, 32.216, 37.362,
         26.956],
        [36.075, 38.257, 28.000, 17.651, 28.576, 38.768, 38.589, 33.994, 27.247,
         28.900],
        [19.073, 27.806, 37.674, 28.286, 25.683, 40.201, 22.302, 26.400, 30.365,
         30.369],
        [28.989, 26.403, 43.360, 30.915, 21.989, 24.569, 26.280, 32.840, 30.382,
         22.661],
        [38.071, 29.985, 34.840, 22.375, 28.437, 36.039, 33.744, 31.880, 32.860,
         39.746],
        [28.318, 27.420, 33.127, 18.029, 34.670, 33.015, 39.982, 34.470, 34.818,
         30.837],
        [21.647, 32.461, 39.667, 26.361, 27.806, 33.010, 37.731, 34.039, 41.754,
         36.463],
        [23.475, 36.654, 23.381, 22.379, 33.110, 25.760, 28.055, 35.333, 27.168,
         23.785],
        [31.858, 36.721, 26.453, 25.807, 29.763, 22.230, 31.750, 25.093, 32.374,
         35.790],
        [33.999, 32.387, 38.989, 20.949, 30.742, 32.694, 38.964, 32.930, 32.331,
         27.992],
        [30.226, 29.419, 21.966, 26.263, 28.446, 38.317, 26.366, 27.460, 29.661,
         29.459],
        [19.559, 35.724, 28.723, 37.906, 33.351, 27.966, 35.901, 34.897, 31.574,
         32.927],
        [29.576, 31.294, 24.964, 27.878, 40.400, 40.231, 27.493, 26.094, 33.703,
         31.374],
        [30.321, 25.039, 21.223, 31.830, 24.953, 34.192, 24.287, 32.207, 27.912,
         26.762],
        [28.996, 28.452, 27.348, 34.341, 31.938, 29.130, 25.188, 26.926, 36.924,
         40.152],
        [27.210, 35.694, 24.257, 27.232, 41.060, 22.465, 22.069, 28.895, 27.763,
         41.247],
        [30.255, 30.235, 23.226, 21.198, 30.239, 29.039, 33.027, 25.033, 34.943,
         24.290],
        [36.354, 39.278, 24.299, 29.463, 33.142, 29.382, 21.766, 33.982, 31.825,
         24.499],
        [28.653, 34.126, 22.255, 28.305, 41.655, 35.450, 32.796, 32.091, 35.734,
         39.372],
        [40.617, 32.090, 32.801, 40.443, 31.955, 29.031, 28.275, 29.308, 21.443,
         39.010],
        [21.145, 35.242, 31.717, 21.252, 23.339, 29.492, 34.588, 22.212, 37.065,
         37.209],
        [37.662, 29.371, 29.805, 34.891, 30.917, 26.510, 41.880, 40.273, 26.840,
         37.702],
        [29.652, 32.407, 37.372, 24.108, 24.371, 33.732, 31.256, 17.995, 42.104,
         37.427],
        [36.845, 30.754, 27.665, 29.883, 37.756, 26.022, 28.343, 25.254, 33.122,
         39.963],
        [44.246, 27.231, 32.124, 35.066, 28.613, 33.602, 30.640, 29.924, 28.706,
         34.328],
        [30.647, 17.697, 30.748, 39.026, 22.284, 30.391, 20.178, 33.993, 21.680,
         27.980],
        [30.330, 34.440, 40.423, 32.421, 26.564, 29.478, 30.947, 27.040, 32.668,
         32.819],
        [32.587, 32.554, 38.007, 31.269, 33.799, 37.616, 31.260, 33.485, 31.779,
         36.166]], device='cuda:0')
clipping threshold 0.29658215853614456
a after update for 1 param tensor([ 0.034, -0.034, -0.010, -0.020,  0.051,  0.004, -0.015,  0.030,  0.068,
         0.017, -0.015, -0.005, -0.073, -0.089,  0.006,  0.005, -0.031,  0.047,
         0.018, -0.066, -0.041, -0.026,  0.097,  0.014,  0.015, -0.053,  0.016,
         0.030,  0.053, -0.016,  0.018,  0.021, -0.071, -0.003, -0.034, -0.000,
        -0.031, -0.015,  0.004,  0.001, -0.079, -0.026,  0.008,  0.014, -0.043,
        -0.020,  0.015, -0.031,  0.029,  0.002,  0.019, -0.020,  0.011,  0.009,
         0.029, -0.002, -0.004,  0.014, -0.020, -0.042,  0.024,  0.018, -0.034,
        -0.045,  0.024, -0.027,  0.036, -0.081,  0.033, -0.002,  0.007, -0.032,
         0.014,  0.033, -0.022, -0.020,  0.023, -0.035,  0.007,  0.016, -0.015,
        -0.014,  0.048,  0.017,  0.033,  0.008, -0.049, -0.044,  0.069, -0.019,
         0.005,  0.039, -0.018, -0.041,  0.005, -0.016,  0.061,  0.038,  0.002,
         0.011], device='cuda:0')
s after update for 1 param tensor([0.977, 0.491, 1.260, 0.837, 0.898, 0.707, 1.003, 0.577, 0.515, 0.513,
        0.853, 0.578, 0.544, 0.836, 0.583, 0.948, 1.441, 0.274, 1.302, 0.893,
        1.082, 0.759, 1.002, 0.627, 0.847, 0.552, 0.784, 1.436, 0.871, 0.483,
        1.288, 1.510, 1.185, 0.556, 0.676, 0.700, 0.270, 1.343, 0.912, 1.332,
        1.174, 0.583, 0.759, 0.871, 0.785, 0.839, 0.836, 0.465, 0.863, 1.425,
        0.887, 0.921, 1.027, 0.886, 0.824, 1.217, 1.071, 0.520, 1.262, 1.085,
        0.890, 0.574, 0.782, 0.712, 0.927, 0.806, 1.670, 1.098, 0.753, 1.046,
        0.569, 0.978, 0.397, 0.792, 1.284, 0.777, 0.805, 0.484, 0.865, 0.757,
        0.861, 0.986, 0.572, 0.555, 0.884, 0.731, 1.098, 0.866, 1.410, 1.348,
        1.476, 0.978, 0.610, 0.907, 0.724, 0.698, 0.856, 0.633, 0.758, 0.666],
       device='cuda:0')
b after update for 1 param tensor([32.721, 23.181, 37.150, 30.276, 31.366, 27.837, 33.154, 25.139, 23.752,
        23.708, 30.564, 25.156, 24.415, 30.267, 25.277, 32.225, 39.726, 17.327,
        37.766, 31.282, 34.425, 28.834, 33.130, 26.202, 30.455, 24.593, 29.306,
        39.664, 30.894, 22.996, 37.567, 40.668, 36.024, 24.678, 27.218, 27.700,
        17.202, 38.355, 31.616, 38.191, 35.862, 25.278, 28.843, 30.897, 29.329,
        30.311, 30.266, 22.581, 30.749, 39.504, 31.179, 31.763, 33.542, 31.157,
        30.039, 36.509, 34.255, 23.864, 37.175, 34.482, 31.232, 25.075, 29.270,
        27.919, 31.860, 29.723, 42.767, 34.684, 28.721, 33.857, 24.965, 32.737,
        20.846, 29.457, 37.497, 29.179, 29.693, 23.017, 30.774, 28.801, 30.707,
        32.873, 25.037, 24.646, 31.110, 28.299, 34.686, 30.803, 39.308, 38.433,
        40.205, 32.732, 25.841, 31.516, 28.167, 27.657, 30.613, 26.339, 28.809,
        27.008], device='cuda:0')
clipping threshold 0.29658215853614456
a after update for 1 param tensor([[[-0.006],
         [-0.064],
         [ 0.017],
         [-0.013],
         [-0.004],
         [-0.013],
         [-0.007],
         [ 0.046],
         [ 0.054],
         [ 0.040]],

        [[ 0.086],
         [ 0.055],
         [ 0.045],
         [ 0.016],
         [-0.023],
         [ 0.057],
         [-0.056],
         [ 0.030],
         [-0.004],
         [-0.021]],

        [[-0.019],
         [-0.104],
         [-0.000],
         [ 0.009],
         [-0.015],
         [ 0.062],
         [ 0.018],
         [-0.004],
         [-0.003],
         [-0.005]],

        [[-0.014],
         [ 0.003],
         [ 0.001],
         [-0.008],
         [-0.056],
         [-0.014],
         [ 0.045],
         [ 0.004],
         [ 0.005],
         [ 0.009]],

        [[ 0.011],
         [-0.047],
         [ 0.011],
         [-0.057],
         [ 0.034],
         [ 0.053],
         [ 0.027],
         [ 0.052],
         [-0.057],
         [-0.070]],

        [[ 0.058],
         [-0.037],
         [ 0.013],
         [ 0.014],
         [-0.011],
         [-0.028],
         [-0.027],
         [ 0.021],
         [ 0.004],
         [ 0.037]],

        [[-0.036],
         [-0.080],
         [ 0.019],
         [-0.021],
         [-0.038],
         [-0.014],
         [-0.004],
         [-0.026],
         [ 0.066],
         [-0.029]],

        [[ 0.007],
         [-0.053],
         [-0.007],
         [-0.010],
         [ 0.014],
         [ 0.009],
         [ 0.041],
         [-0.109],
         [-0.071],
         [ 0.011]],

        [[ 0.008],
         [-0.018],
         [ 0.021],
         [ 0.047],
         [ 0.021],
         [ 0.016],
         [ 0.012],
         [-0.003],
         [-0.006],
         [-0.027]],

        [[ 0.035],
         [ 0.057],
         [ 0.066],
         [ 0.013],
         [-0.051],
         [-0.017],
         [-0.026],
         [-0.018],
         [ 0.039],
         [ 0.062]]], device='cuda:0')
s after update for 1 param tensor([[[0.678],
         [0.746],
         [0.486],
         [1.573],
         [0.683],
         [1.079],
         [1.312],
         [1.216],
         [1.092],
         [0.400]],

        [[1.204],
         [0.772],
         [1.298],
         [0.733],
         [0.457],
         [0.880],
         [1.274],
         [0.834],
         [1.210],
         [1.428]],

        [[0.894],
         [1.064],
         [0.867],
         [0.453],
         [0.974],
         [0.625],
         [1.290],
         [0.819],
         [1.473],
         [1.062]],

        [[0.948],
         [1.435],
         [0.962],
         [0.927],
         [1.107],
         [1.298],
         [1.385],
         [0.934],
         [1.757],
         [0.715]],

        [[0.405],
         [1.173],
         [0.750],
         [1.062],
         [0.867],
         [1.095],
         [1.209],
         [1.120],
         [0.994],
         [0.757]],

        [[0.975],
         [0.935],
         [0.950],
         [1.021],
         [0.583],
         [0.993],
         [0.663],
         [1.435],
         [0.859],
         [1.368]],

        [[0.629],
         [0.744],
         [1.252],
         [0.556],
         [1.431],
         [0.828],
         [0.932],
         [0.901],
         [0.546],
         [1.184]],

        [[1.175],
         [1.526],
         [0.839],
         [0.867],
         [1.102],
         [0.751],
         [0.837],
         [0.738],
         [1.376],
         [0.666]],

        [[0.827],
         [0.833],
         [0.636],
         [1.030],
         [0.443],
         [0.766],
         [0.709],
         [0.699],
         [0.440],
         [0.799]],

        [[0.568],
         [0.809],
         [1.004],
         [0.552],
         [0.618],
         [0.695],
         [0.716],
         [1.154],
         [1.014],
         [1.593]]], device='cuda:0')
b after update for 1 param tensor([[[27.253],
         [28.591],
         [23.068],
         [41.512],
         [27.363],
         [34.385],
         [37.904],
         [36.493],
         [34.592],
         [20.925]],

        [[36.311],
         [29.081],
         [37.703],
         [28.331],
         [22.363],
         [31.040],
         [37.357],
         [30.234],
         [36.402],
         [39.545]],

        [[31.299],
         [34.138],
         [30.825],
         [22.282],
         [32.666],
         [26.164],
         [37.597],
         [29.961],
         [40.168],
         [34.109]],

        [[32.225],
         [39.642],
         [32.465],
         [31.865],
         [34.824],
         [37.704],
         [38.944],
         [31.993],
         [43.875],
         [27.987]],

        [[21.054],
         [35.844],
         [28.668],
         [34.115],
         [30.810],
         [34.632],
         [36.388],
         [35.023],
         [32.998],
         [28.801]],

        [[32.678],
         [31.999],
         [32.252],
         [33.448],
         [25.265],
         [32.987],
         [26.945],
         [39.645],
         [30.683],
         [38.713]],

        [[26.245],
         [28.549],
         [37.041],
         [24.690],
         [39.589],
         [30.124],
         [31.946],
         [31.415],
         [24.451],
         [36.013]],

        [[35.874],
         [40.881],
         [30.318],
         [30.820],
         [34.749],
         [28.690],
         [30.273],
         [28.442],
         [38.818],
         [27.010]],

        [[30.098],
         [30.201],
         [26.393],
         [33.584],
         [22.023],
         [28.968],
         [27.867],
         [27.670],
         [21.946],
         [29.585]],

        [[24.938],
         [29.777],
         [33.161],
         [24.592],
         [26.015],
         [27.588],
         [28.011],
         [35.556],
         [33.325],
         [41.774]]], device='cuda:0')
clipping threshold 0.29658215853614456
a after update for 1 param tensor([[-0.038],
        [-0.070],
        [ 0.007],
        [-0.007],
        [ 0.011],
        [-0.018],
        [ 0.012],
        [-0.014],
        [-0.003],
        [-0.058]], device='cuda:0')
s after update for 1 param tensor([[0.946],
        [1.224],
        [1.689],
        [1.186],
        [1.759],
        [1.577],
        [1.781],
        [1.456],
        [0.977],
        [1.323]], device='cuda:0')
b after update for 1 param tensor([[32.193],
        [36.614],
        [43.008],
        [36.049],
        [43.898],
        [41.563],
        [44.174],
        [39.938],
        [32.712],
        [38.069]], device='cuda:0')
clipping threshold 0.29658215853614456
||w||^2 0.12448706218898863
exp ma of ||w||^2 0.22586644035139988
||w|| 0.35282724127962206
exp ma of ||w|| 0.441828642864003
v before min max tensor([[-1.778e+00,  1.812e+00, -8.494e-01,  1.147e+00,  2.423e-01, -1.425e+00,
          2.180e+00, -8.132e-01, -2.548e+00, -2.989e-01],
        [ 5.450e+00, -1.340e+00,  2.041e+01, -1.337e+00, -2.300e-01, -2.220e+00,
          1.495e+00, -1.212e+00, -2.108e+00,  2.032e-01],
        [ 2.511e+00,  2.776e+00,  7.164e+00,  4.115e-03, -3.178e+00, -2.479e+00,
         -2.937e+00,  7.446e-01, -2.511e+00, -2.377e-01],
        [ 2.494e+00, -2.337e+00, -1.726e+00, -1.939e+00, -2.444e+00,  5.739e-01,
         -2.074e+00, -7.422e-01, -2.288e+00, -1.345e+00],
        [-1.366e+00, -3.921e+00, -5.596e-01, -3.557e+00, -1.621e+00, -2.497e+00,
         -2.052e+00,  4.620e-01, -9.373e-01, -4.106e-01],
        [-2.553e+00, -3.750e+00, -1.339e+00, -1.707e+00, -1.615e+00, -1.995e+00,
         -1.601e+00,  1.251e+00, -1.198e+00, -4.419e-01],
        [ 2.372e-01,  4.906e+00, -1.237e+00, -9.187e-01, -1.062e+00, -2.367e+00,
          4.548e+00, -1.259e+00,  3.397e-01, -6.683e-01],
        [-1.420e-01, -1.326e+00,  1.326e+00,  4.539e-01,  2.078e+00, -2.081e+00,
         -8.023e-01, -8.594e-01, -9.182e-01,  3.490e-01],
        [ 1.242e-01, -1.745e+00,  2.311e-01, -1.608e+00, -1.533e+00, -1.851e+00,
         -2.175e+00, -2.169e+00,  1.450e+00, -4.425e-01],
        [ 8.159e+00,  6.416e+00, -2.217e+00,  3.847e+00,  1.173e+00, -9.451e-01,
         -1.547e+00,  1.397e+00,  8.661e-01, -3.536e+00],
        [ 3.096e+00, -1.588e+00, -1.728e+00,  1.289e-01, -1.162e+00,  7.860e+00,
          7.159e+00,  5.309e-01, -8.021e-01, -1.093e+00],
        [-2.723e+00, -2.936e+00, -8.079e-01, -1.765e+00, -1.186e+00, -2.026e+00,
         -2.295e+00, -1.249e+00, -5.197e-01,  2.491e+00],
        [-1.323e+00,  7.081e-01, -2.604e+00, -1.637e+00,  2.137e+00, -2.474e+00,
         -1.967e+00, -1.373e+00, -7.192e-01, -1.412e+00],
        [-3.211e+00, -1.343e+00, -1.782e+00, -9.972e-01, -3.385e+00, -1.615e+00,
         -1.677e-01, -3.116e+00,  8.857e-01, -1.983e+00],
        [-3.014e+00, -8.724e-02,  6.948e+00, -2.184e+00,  2.953e+00, -1.597e+00,
         -3.095e+00, -1.245e+00, -1.173e+00,  3.520e-01],
        [ 6.948e-01,  5.440e-02, -5.971e-01,  1.033e+00, -4.872e-01, -4.149e-01,
         -9.397e-01, -2.631e+00,  1.344e-01, -1.854e+00],
        [-1.607e+00, -1.352e+00, -1.514e+00, -6.536e-01,  1.693e+00,  1.394e+00,
         -1.522e+00, -1.281e-01, -9.626e-01, -1.787e+00],
        [-8.801e-01, -2.970e+00, -1.700e+00, -2.080e+00,  1.875e+00, -1.630e+00,
         -1.814e+00,  1.292e+00, -2.688e+00,  1.967e+00],
        [-2.308e+00, -2.453e+00, -1.438e+00, -1.447e-01, -7.703e-02, -1.201e+00,
          6.499e-01, -7.021e-01, -1.881e+00, -1.027e+00],
        [-2.581e+00, -2.207e+00, -2.149e+00, -2.134e-01,  8.180e-01, -1.627e+00,
         -9.177e-01, -2.319e+00,  3.061e+00, -1.835e+00],
        [-9.992e-01, -2.744e+00, -3.094e+00, -9.199e-02, -1.597e+00, -2.480e+00,
         -1.569e+00, -5.319e-01, -3.639e-02,  8.296e+00],
        [-3.210e+00,  2.900e+00,  5.301e-01, -1.631e+00,  2.613e+01, -2.325e+00,
         -4.646e-01, -6.649e-01,  1.270e+00,  1.793e+00],
        [ 1.293e-01, -1.085e+00,  1.904e+00,  2.157e-01,  6.547e-01, -6.412e-02,
         -1.662e+00, -1.928e+00, -1.094e+00,  1.813e+00],
        [-1.328e+00,  2.889e+00, -3.327e+00, -8.487e-01,  2.883e-01, -2.867e+00,
         -1.821e+00, -1.690e+00, -2.363e+00, -1.290e+00],
        [-2.112e+00,  1.265e+01,  3.546e+00, -9.477e-01, -2.580e+00,  6.720e-01,
          6.590e-01,  2.091e+00, -1.475e+00,  1.440e+01],
        [-7.579e-01, -6.261e-01, -1.835e+00,  1.720e+00, -3.815e-01, -1.630e+00,
         -2.596e+00,  2.139e+00, -2.126e+00, -1.399e+00],
        [ 4.266e+00, -9.256e-01,  9.580e-01,  3.500e-01, -2.118e+00, -2.318e+00,
         -3.343e+00, -2.705e+00, -1.892e+00, -2.972e+00],
        [-1.384e+00, -1.256e+00, -2.685e+00, -2.263e+00, -9.666e-01,  1.091e+01,
         -1.950e+00, -7.688e-02, -9.290e-01, -3.218e+00],
        [ 7.820e-01, -6.200e-01, -2.873e+00, -1.897e+00, -1.370e+00, -9.750e-02,
          1.862e+00,  1.065e+00,  6.434e+00, -8.354e-01],
        [-8.107e-01,  1.833e+00,  1.488e+00, -4.677e-01, -2.502e+00, -8.450e-01,
         -1.863e+00, -1.798e+00, -2.235e+00, -1.670e+00],
        [ 2.119e+00, -5.788e-01, -2.057e+00,  9.782e-01, -1.098e+00, -2.251e+00,
          4.743e-01, -2.010e+00, -1.964e+00, -8.365e-01],
        [-1.090e+00, -1.260e+00,  2.947e-01, -1.711e+00, -1.324e+00, -1.677e+00,
         -1.427e+00, -3.654e-01, -9.755e-01, -6.352e-01],
        [-1.045e+00, -1.654e+00,  1.927e+00, -2.363e+00, -9.101e-02,  4.870e+00,
         -1.342e+00, -2.469e+00, -1.636e-01, -1.806e+00],
        [ 2.785e-02, -1.051e+00, -2.245e+00, -2.307e+00, -2.492e+00, -2.263e+00,
         -1.567e+00, -1.471e+00,  3.140e+00, -1.626e+00],
        [ 3.279e-01, -7.355e-01,  3.606e-01, -3.306e+00,  8.046e-02,  1.730e+00,
         -6.405e-01, -2.626e+00, -1.400e+00, -2.635e+00],
        [-2.235e+00,  9.426e-01, -1.476e+00, -1.799e+00,  1.359e-01, -1.158e+00,
          1.791e+00, -9.199e-01, -1.489e+00,  1.199e-01],
        [-1.866e+00, -3.263e+00, -1.331e+00, -1.836e+00, -3.598e+00, -1.126e+00,
         -1.374e+00,  1.821e+00,  6.943e+00,  6.749e-01],
        [-4.725e-01, -2.088e+00, -1.297e+00, -4.397e-01, -2.030e+00, -1.345e+00,
         -1.073e+00, -1.621e+00,  1.976e+00,  5.407e+00],
        [-1.887e+00, -2.119e+00, -8.354e-01, -8.545e-01, -2.124e+00, -2.825e-01,
         -9.746e-01, -1.628e+00,  2.594e+00, -3.890e-01],
        [-1.903e+00,  1.120e+00, -1.178e+00, -1.994e+00, -2.760e+00, -2.521e+00,
         -1.569e+00, -8.249e-01,  1.835e+00, -1.194e+00],
        [ 5.505e-01,  5.738e-01, -2.342e-01, -2.774e+00,  2.261e+00,  1.402e+00,
         -1.202e+00, -1.751e+00,  4.938e+00,  1.943e+00],
        [-1.747e+00, -1.776e+00, -1.623e+00, -2.652e-01, -1.993e+00,  2.236e+00,
         -1.986e+00, -1.452e+00, -2.012e+00, -1.238e+00],
        [-1.246e+00, -3.029e+00, -1.442e+00, -1.653e+00, -1.367e+00, -2.309e+00,
         -1.183e+00, -1.631e+00, -3.463e+00,  6.905e+00],
        [ 3.444e+00, -1.155e+00, -4.903e-01, -1.836e+00, -3.526e+00, -5.205e-01,
         -7.511e-02,  8.204e+00,  3.212e+00, -1.702e-01],
        [-1.148e+00, -1.332e+00, -2.342e+00,  8.654e-01,  1.862e+00, -2.372e+00,
          3.000e+00, -9.750e-01, -2.405e+00,  5.820e+00],
        [ 2.092e+00, -1.875e+00, -1.116e+00, -1.052e+00, -1.115e+00,  1.904e+00,
         -1.354e+00, -3.451e-02, -1.484e+00,  7.225e-01],
        [-1.189e+00, -9.377e-01, -1.695e+00,  1.858e+00, -2.880e+00, -1.942e+00,
         -1.813e+00, -1.132e+00,  1.538e+00,  1.309e+00],
        [-1.788e+00,  4.259e+00, -1.034e+00,  4.153e+00,  2.327e+00, -3.994e+00,
         -8.099e-01, -1.642e+00,  8.289e-02, -2.526e+00],
        [ 5.329e+00, -1.502e+00,  4.762e+00, -2.091e+00, -2.224e+00,  3.612e-01,
         -2.626e+00, -1.355e+00, -9.470e-01, -6.609e-01],
        [-2.403e+00, -5.360e-01, -1.845e+00, -1.087e-01, -1.763e+00,  7.850e-01,
         -2.434e+00, -1.956e+00, -1.416e+00,  8.978e+00],
        [-1.321e+00,  8.935e-01, -1.699e+00, -3.225e+00,  2.781e-01, -1.729e+00,
          2.546e+00,  2.373e+00, -2.152e+00,  9.703e+00],
        [-7.221e-01,  2.259e+00,  6.905e-01, -2.611e-01, -2.142e+00, -9.977e-01,
         -6.535e-02, -2.210e+00,  9.616e-01, -1.353e+00],
        [-2.326e+00, -4.384e-01,  4.477e-01, -1.522e+00, -4.255e-01, -1.268e+00,
         -1.030e+00, -1.011e+00, -1.724e+00, -9.621e-01],
        [-1.419e+00,  1.348e+00, -1.463e+00,  5.247e-03, -4.387e-01, -2.365e+00,
          3.606e+00, -8.930e-01, -1.174e+00, -8.018e-01],
        [-1.103e+00, -1.062e+00, -1.898e+00, -2.968e-01, -7.112e-01, -1.682e+00,
         -2.618e+00, -1.159e+00, -9.862e-01, -1.543e+00],
        [ 1.784e+00, -1.554e+00, -1.668e+00, -1.336e+00,  8.539e+00,  2.477e+00,
         -2.929e+00, -2.959e+00, -1.053e+00,  4.738e-01],
        [-2.613e+00,  3.667e-01, -8.663e-01, -2.019e+00, -2.697e+00, -2.462e+00,
         -1.432e+00, -1.507e+00, -7.428e-01, -1.474e+00],
        [-7.573e-01, -1.099e+00, -2.702e+00, -9.311e-01, -1.757e+00,  1.963e+00,
          1.465e+00, -1.320e+00,  3.454e+00,  4.965e+00],
        [-1.369e+00, -2.123e+00,  6.021e+00, -1.655e+00,  1.791e+00, -1.909e+00,
          4.667e+00, -2.947e-01, -1.267e+00, -6.463e-01],
        [-2.359e+00, -1.979e+00, -2.268e+00,  1.279e+00,  9.777e-01, -2.335e+00,
         -1.498e+00, -1.604e+00, -1.497e+00, -2.018e+00],
        [-1.157e+00, -2.266e+00, -9.324e-01, -2.343e-01, -9.747e-01, -2.835e+00,
         -2.147e+00,  6.874e-01,  1.696e+00, -1.268e+00],
        [ 1.115e+00, -1.079e+00, -2.693e-01, -4.804e-01,  1.049e+00,  4.501e-02,
         -2.445e+00, -1.201e+00, -9.609e-01, -1.039e+00],
        [-1.484e+00, -1.712e+00, -1.389e+00, -4.224e-01, -1.329e+00, -1.102e+00,
         -7.531e-01, -1.544e+00, -3.118e+00,  5.561e+00],
        [-1.897e+00, -2.050e+00, -1.660e+00, -1.019e+00, -9.604e-01, -3.942e-01,
         -2.460e+00, -2.088e+00, -1.183e+00, -1.880e+00],
        [-7.784e-01, -2.336e+00,  4.189e-01,  7.529e-01, -2.481e-01, -1.565e+00,
         -1.844e+00,  3.686e-01,  3.208e+00,  1.283e+00],
        [ 4.739e-01, -1.533e+00, -1.061e+00, -9.359e-01,  4.996e+00, -1.076e+00,
         -9.017e-01, -7.496e-01, -1.055e+00, -2.995e-01],
        [ 5.128e-01, -1.225e+00, -8.522e-01,  6.004e+00, -1.036e+00, -3.661e+00,
         -2.038e+00,  1.162e+00, -3.231e+00, -2.168e+00],
        [-1.063e-03,  4.710e+00,  2.926e+00, -6.800e-01, -1.890e+00, -1.551e+00,
          5.711e+00, -2.362e+00, -1.442e+00, -2.456e+00],
        [-1.433e+00, -2.383e+00, -1.177e+00,  2.422e+00,  2.383e+00, -7.438e-01,
         -2.638e+00,  5.994e+00,  6.274e-01, -9.999e-01],
        [ 1.183e+00, -1.664e+00, -3.156e-01,  1.867e+00,  1.386e+00, -2.156e+00,
         -3.438e+00, -9.864e-01, -3.834e+00, -1.292e+00],
        [-1.720e+00,  4.202e+00,  2.440e+00, -2.362e+00, -2.015e+00,  1.144e+01,
          2.052e+00,  5.559e+00, -1.867e-01, -1.779e+00],
        [-8.413e-01, -7.873e-01, -4.104e-01, -4.139e-01,  1.712e+00, -1.456e+00,
         -2.458e+00, -1.304e+00,  2.446e+00, -1.097e+00],
        [-3.270e+00,  9.267e-01, -5.355e-01,  5.239e+00,  9.483e-01, -1.087e+00,
         -2.153e+00, -7.243e-01, -5.592e-01,  1.441e+00],
        [-1.968e+00, -1.355e+00, -1.680e+00, -3.754e-01, -1.957e+00, -1.438e+00,
         -1.336e+00,  5.597e-01, -6.886e-02, -8.875e-01],
        [-1.889e+00, -2.116e+00, -5.698e-01, -6.597e-01, -2.652e+00, -3.029e-01,
         -2.403e+00, -1.102e+00, -1.410e-01, -7.772e-01],
        [ 1.036e+00,  4.700e-01,  9.162e-01, -1.217e+00, -9.736e-02, -2.500e+00,
          7.218e+00,  3.669e-01, -8.293e-01,  3.526e+00],
        [-1.876e+00, -2.242e+00, -1.278e+00, -1.987e+00, -1.055e+00, -2.314e+00,
          1.774e+01, -1.435e+00, -1.569e+00,  8.113e-01],
        [-1.295e+00,  1.086e+01, -1.377e+00, -1.516e+00, -2.389e+00, -2.284e+00,
         -5.423e-01, -1.942e+00, -2.980e+00, -1.310e+00],
        [-7.061e-01, -2.037e+00,  2.057e-01, -1.576e+00, -2.343e-02, -1.277e+00,
          4.536e+00, -1.839e+00,  3.517e+00, -1.447e+00],
        [-1.779e+00, -2.363e+00, -7.044e-01, -2.976e+00,  2.123e+00, -5.651e-01,
         -5.990e-01, -1.869e+00,  1.311e+00, -3.113e+00],
        [ 1.882e+00, -2.935e+00, -1.238e+00, -2.044e+00, -8.743e-01, -9.620e-01,
         -3.749e+00, -4.901e-01,  1.310e+01,  1.673e+00],
        [-2.570e+00, -2.691e+00, -1.108e+00,  6.265e-01, -1.993e+00, -2.825e+00,
         -3.356e+00, -5.716e-01, -2.245e+00, -1.108e+00],
        [-2.858e+00, -1.863e+00, -2.740e+00, -1.745e+00, -2.391e+00, -1.274e+00,
         -1.196e+00,  2.449e+00, -8.733e-01, -1.576e+00],
        [-1.793e+00, -2.642e+00, -2.142e+00, -8.240e-01, -3.100e+00, -3.017e+00,
         -2.577e+00,  1.236e+01,  1.037e+00, -1.363e+00],
        [-7.028e-01, -3.179e+00, -2.278e+00, -9.206e-01, -2.756e+00, -2.408e+00,
          3.503e+00, -6.800e-01,  1.766e-01, -9.960e-01],
        [ 5.225e+00, -1.841e+00, -2.266e+00,  1.024e+00, -1.843e+00, -1.178e+00,
          2.695e+00, -1.081e+00, -1.233e+00,  1.979e-01],
        [-1.299e+00,  2.221e+00, -2.335e+00, -8.950e-01,  2.095e+00,  3.367e+00,
         -1.514e+00, -2.186e+00, -1.675e+00, -1.286e+00],
        [ 2.621e+00, -2.834e+00, -1.980e+00, -7.625e-01, -1.673e+00, -2.892e+00,
          5.800e+00, -1.355e+00, -1.843e+00, -1.639e+00],
        [-2.359e+00,  2.263e+00, -1.938e+00,  4.550e-01, -1.478e+00,  9.597e-01,
         -2.216e+00, -1.419e-01, -1.874e+00, -6.652e-01],
        [ 6.016e+00, -1.027e+00,  6.804e+00,  1.309e+00, -2.115e+00,  7.661e-01,
         -1.606e+00, -1.838e+00, -2.305e+00,  2.874e+00],
        [-4.420e-01, -5.513e-02,  6.510e-01, -1.387e+00,  2.134e+00,  6.093e+00,
         -6.537e-01, -4.197e-01,  9.135e-01,  3.202e+00],
        [-2.192e+00, -2.498e-01,  1.339e+00, -1.143e+00, -1.513e+00, -1.245e+00,
          1.615e-01, -4.185e-01, -2.261e+00,  2.020e+00],
        [-1.309e+00, -1.160e+00,  6.369e+00, -6.964e-01,  2.246e+00, -2.168e+00,
         -1.368e+00, -4.909e-01, -1.529e+00, -2.885e+00],
        [-1.116e+00, -8.980e-01, -2.543e+00, -2.772e+00,  1.399e+00, -2.088e+00,
         -2.137e+00,  1.043e+01, -1.926e-01,  4.517e+00],
        [ 2.552e-01, -5.049e-01, -4.869e-01, -9.923e-01, -1.647e+00,  5.752e-01,
         -2.062e+00,  1.813e+00,  3.034e+00, -2.973e+00],
        [-3.136e+00,  6.106e-01,  8.697e-01, -1.660e+00, -1.319e+00, -2.256e+00,
         -1.514e+00, -2.233e+00,  5.783e+00, -1.301e+00],
        [-2.128e+00, -2.376e+00, -6.002e-01,  4.432e+00, -1.981e+00, -4.098e+00,
          5.461e+00,  1.833e+00, -1.726e+00, -3.825e+00],
        [-1.467e+00, -1.046e+00, -1.008e+00, -7.848e-01, -1.391e+00, -1.611e-01,
         -2.941e+00, -2.589e+00, -2.466e+00, -1.235e+00],
        [ 7.951e+00, -1.097e+00, -2.040e+00, -2.398e+00, -1.919e+00,  1.091e+00,
         -1.957e+00, -1.582e+00, -9.127e-01, -1.074e+00],
        [-2.509e+00,  4.042e+00, -3.485e+00, -2.021e+00, -2.174e+00, -1.688e+00,
         -2.309e+00,  2.456e+00, -1.079e+00, -2.141e+00]], device='cuda:0')
v tensor([[1.000e-12, 1.812e+00, 1.000e-12, 1.147e+00, 2.423e-01, 1.000e-12,
         2.180e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [5.450e+00, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.495e+00, 1.000e-12, 1.000e-12, 2.032e-01],
        [2.511e+00, 2.776e+00, 7.164e+00, 4.115e-03, 1.000e-12, 1.000e-12,
         1.000e-12, 7.446e-01, 1.000e-12, 1.000e-12],
        [2.494e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.739e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 4.620e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.251e+00, 1.000e-12, 1.000e-12],
        [2.372e-01, 4.906e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         4.548e+00, 1.000e-12, 3.397e-01, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.326e+00, 4.539e-01, 2.078e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 3.490e-01],
        [1.242e-01, 1.000e-12, 2.311e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.450e+00, 1.000e-12],
        [8.159e+00, 6.416e+00, 1.000e-12, 3.847e+00, 1.173e+00, 1.000e-12,
         1.000e-12, 1.397e+00, 8.661e-01, 1.000e-12],
        [3.096e+00, 1.000e-12, 1.000e-12, 1.289e-01, 1.000e-12, 7.860e+00,
         7.159e+00, 5.309e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 2.491e+00],
        [1.000e-12, 7.081e-01, 1.000e-12, 1.000e-12, 2.137e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 8.857e-01, 1.000e-12],
        [1.000e-12, 1.000e-12, 6.948e+00, 1.000e-12, 2.953e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 3.520e-01],
        [6.948e-01, 5.440e-02, 1.000e-12, 1.033e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.344e-01, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.693e+00, 1.394e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.875e+00, 1.000e-12,
         1.000e-12, 1.292e+00, 1.000e-12, 1.967e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         6.499e-01, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 8.180e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 3.061e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 8.296e+00],
        [1.000e-12, 2.900e+00, 5.301e-01, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.270e+00, 1.793e+00],
        [1.293e-01, 1.000e-12, 1.904e+00, 2.157e-01, 6.547e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.813e+00],
        [1.000e-12, 2.889e+00, 1.000e-12, 1.000e-12, 2.883e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e+01, 3.546e+00, 1.000e-12, 1.000e-12, 6.720e-01,
         6.590e-01, 2.091e+00, 1.000e-12, 1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.720e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 2.139e+00, 1.000e-12, 1.000e-12],
        [4.266e+00, 1.000e-12, 9.580e-01, 3.500e-01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [7.820e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.862e+00, 1.065e+00, 6.434e+00, 1.000e-12],
        [1.000e-12, 1.833e+00, 1.488e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [2.119e+00, 1.000e-12, 1.000e-12, 9.782e-01, 1.000e-12, 1.000e-12,
         4.743e-01, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 2.947e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.927e+00, 1.000e-12, 1.000e-12, 4.870e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [2.785e-02, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 3.140e+00, 1.000e-12],
        [3.279e-01, 1.000e-12, 3.606e-01, 1.000e-12, 8.046e-02, 1.730e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 9.426e-01, 1.000e-12, 1.000e-12, 1.359e-01, 1.000e-12,
         1.791e+00, 1.000e-12, 1.000e-12, 1.199e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.821e+00, 6.943e+00, 6.749e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.976e+00, 5.407e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 2.594e+00, 1.000e-12],
        [1.000e-12, 1.120e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.835e+00, 1.000e-12],
        [5.505e-01, 5.738e-01, 1.000e-12, 1.000e-12, 2.261e+00, 1.402e+00,
         1.000e-12, 1.000e-12, 4.938e+00, 1.943e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.236e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 6.905e+00],
        [3.444e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 8.204e+00, 3.212e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 8.654e-01, 1.862e+00, 1.000e-12,
         3.000e+00, 1.000e-12, 1.000e-12, 5.820e+00],
        [2.092e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.904e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 7.225e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.858e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.538e+00, 1.309e+00],
        [1.000e-12, 4.259e+00, 1.000e-12, 4.153e+00, 2.327e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 8.289e-02, 1.000e-12],
        [5.329e+00, 1.000e-12, 4.762e+00, 1.000e-12, 1.000e-12, 3.612e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 7.850e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 8.978e+00],
        [1.000e-12, 8.935e-01, 1.000e-12, 1.000e-12, 2.781e-01, 1.000e-12,
         2.546e+00, 2.373e+00, 1.000e-12, 9.703e+00],
        [1.000e-12, 2.259e+00, 6.905e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 9.616e-01, 1.000e-12],
        [1.000e-12, 1.000e-12, 4.477e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.348e+00, 1.000e-12, 5.247e-03, 1.000e-12, 1.000e-12,
         3.606e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.784e+00, 1.000e-12, 1.000e-12, 1.000e-12, 8.539e+00, 2.477e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 4.738e-01],
        [1.000e-12, 3.667e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.963e+00,
         1.465e+00, 1.000e-12, 3.454e+00, 4.965e+00],
        [1.000e-12, 1.000e-12, 6.021e+00, 1.000e-12, 1.791e+00, 1.000e-12,
         4.667e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.279e+00, 9.777e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 6.874e-01, 1.696e+00, 1.000e-12],
        [1.115e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.049e+00, 4.501e-02,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 5.561e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 4.189e-01, 7.529e-01, 1.000e-12, 1.000e-12,
         1.000e-12, 3.686e-01, 3.208e+00, 1.283e+00],
        [4.739e-01, 1.000e-12, 1.000e-12, 1.000e-12, 4.996e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [5.128e-01, 1.000e-12, 1.000e-12, 6.004e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 1.162e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 4.710e+00, 2.926e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         5.711e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 2.422e+00, 2.383e+00, 1.000e-12,
         1.000e-12, 5.994e+00, 6.274e-01, 1.000e-12],
        [1.183e+00, 1.000e-12, 1.000e-12, 1.867e+00, 1.386e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 4.202e+00, 2.440e+00, 1.000e-12, 1.000e-12, 1.000e+01,
         2.052e+00, 5.559e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.712e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 2.446e+00, 1.000e-12],
        [1.000e-12, 9.267e-01, 1.000e-12, 5.239e+00, 9.483e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.441e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 5.597e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.036e+00, 4.700e-01, 9.162e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         7.218e+00, 3.669e-01, 1.000e-12, 3.526e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e-12, 1.000e-12, 8.113e-01],
        [1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 2.057e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         4.536e+00, 1.000e-12, 3.517e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.123e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.311e+00, 1.000e-12],
        [1.882e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e+01, 1.673e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 6.265e-01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 2.449e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e+01, 1.037e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         3.503e+00, 1.000e-12, 1.766e-01, 1.000e-12],
        [5.225e+00, 1.000e-12, 1.000e-12, 1.024e+00, 1.000e-12, 1.000e-12,
         2.695e+00, 1.000e-12, 1.000e-12, 1.979e-01],
        [1.000e-12, 2.221e+00, 1.000e-12, 1.000e-12, 2.095e+00, 3.367e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [2.621e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         5.800e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 2.263e+00, 1.000e-12, 4.550e-01, 1.000e-12, 9.597e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [6.016e+00, 1.000e-12, 6.804e+00, 1.309e+00, 1.000e-12, 7.661e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 2.874e+00],
        [1.000e-12, 1.000e-12, 6.510e-01, 1.000e-12, 2.134e+00, 6.093e+00,
         1.000e-12, 1.000e-12, 9.135e-01, 3.202e+00],
        [1.000e-12, 1.000e-12, 1.339e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         1.615e-01, 1.000e-12, 1.000e-12, 2.020e+00],
        [1.000e-12, 1.000e-12, 6.369e+00, 1.000e-12, 2.246e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.399e+00, 1.000e-12,
         1.000e-12, 1.000e+01, 1.000e-12, 4.517e+00],
        [2.552e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.752e-01,
         1.000e-12, 1.813e+00, 3.034e+00, 1.000e-12],
        [1.000e-12, 6.106e-01, 8.697e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 5.783e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 4.432e+00, 1.000e-12, 1.000e-12,
         5.461e+00, 1.833e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [7.951e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.091e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 4.042e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 2.456e+00, 1.000e-12, 1.000e-12]], device='cuda:0')
v before min max tensor([-0.416, -0.814, -1.703, -1.080, -1.434,  1.782, -1.781, -0.968,  0.469,
        -1.519, -1.214, -0.717,  1.236,  8.978, -2.276, -0.754,  1.693, -1.381,
         3.093, -0.587, -1.536, -0.434,  0.901, -1.286, -2.054,  0.030,  0.123,
         5.529, -0.921, -1.439, -1.595, -1.304,  0.182, -0.156, -0.790, -0.807,
        -1.601, -0.888,  0.133, -1.130,  0.670, -1.248, -1.003,  4.538,  0.965,
         0.505, -1.936, -2.366, -1.457,  1.285, 10.421, -0.142, -1.642,  5.896,
        -1.283,  3.352, -0.219, -1.328,  1.417, -1.040,  5.878, -0.132, -2.616,
         2.973, -1.993, -1.364,  3.896,  2.581,  4.631, -1.158,  8.886, -2.535,
        -0.183, -0.385,  3.030,  2.689, -1.859, -2.184, -3.315, -2.348,  3.011,
        -1.139,  2.429, -1.473, -1.009, -2.329,  0.175, -2.186, -2.113, -1.919,
        -1.176,  1.888,  6.645, -2.458,  3.783,  1.910,  4.966, -0.489,  2.406,
        -0.953], device='cuda:0')
v tensor([1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.782e+00,
        1.000e-12, 1.000e-12, 4.693e-01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.236e+00, 8.978e+00, 1.000e-12, 1.000e-12, 1.693e+00, 1.000e-12,
        3.093e+00, 1.000e-12, 1.000e-12, 1.000e-12, 9.013e-01, 1.000e-12,
        1.000e-12, 3.033e-02, 1.226e-01, 5.529e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.815e-01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.329e-01, 1.000e-12, 6.704e-01, 1.000e-12,
        1.000e-12, 4.538e+00, 9.649e-01, 5.046e-01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.285e+00, 1.000e+01, 1.000e-12, 1.000e-12, 5.896e+00,
        1.000e-12, 3.352e+00, 1.000e-12, 1.000e-12, 1.417e+00, 1.000e-12,
        5.878e+00, 1.000e-12, 1.000e-12, 2.973e+00, 1.000e-12, 1.000e-12,
        3.896e+00, 2.581e+00, 4.631e+00, 1.000e-12, 8.886e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 3.030e+00, 2.689e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 3.011e+00, 1.000e-12, 2.429e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.755e-01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.888e+00, 6.645e+00, 1.000e-12, 3.783e+00, 1.910e+00,
        4.966e+00, 1.000e-12, 2.406e+00, 1.000e-12], device='cuda:0')
v before min max tensor([[[-1.453],
         [30.481],
         [ 5.164],
         [-1.978],
         [ 8.771],
         [-3.038],
         [ 6.757],
         [-2.120],
         [-1.461],
         [ 1.537]],

        [[-1.961],
         [ 0.059],
         [ 2.841],
         [-2.944],
         [ 5.804],
         [-1.080],
         [-0.758],
         [ 1.594],
         [-0.410],
         [-0.176]],

        [[-2.797],
         [-2.350],
         [ 1.473],
         [-1.386],
         [ 0.677],
         [-2.646],
         [-2.181],
         [-1.288],
         [-2.340],
         [ 0.256]],

        [[-1.792],
         [-1.327],
         [-1.265],
         [ 2.177],
         [ 0.421],
         [-1.201],
         [-2.395],
         [-0.751],
         [-2.759],
         [-0.750]],

        [[-1.586],
         [ 4.000],
         [ 1.456],
         [ 0.259],
         [ 3.523],
         [-0.904],
         [-3.194],
         [-2.432],
         [-1.982],
         [-0.118]],

        [[-1.934],
         [-3.207],
         [-1.442],
         [ 1.654],
         [-2.859],
         [-2.544],
         [-3.326],
         [ 7.335],
         [-1.312],
         [-1.489]],

        [[-2.043],
         [-2.930],
         [-1.994],
         [-3.465],
         [ 0.158],
         [ 0.912],
         [-1.355],
         [ 8.628],
         [ 6.312],
         [-2.068]],

        [[-1.940],
         [-0.878],
         [-0.946],
         [-1.565],
         [-1.062],
         [-3.394],
         [ 6.713],
         [ 1.654],
         [ 7.569],
         [ 4.652]],

        [[-1.689],
         [-1.530],
         [-1.731],
         [ 2.994],
         [-1.378],
         [-1.997],
         [-0.096],
         [-1.225],
         [-2.105],
         [-3.471]],

        [[-0.395],
         [-1.998],
         [-1.515],
         [-1.078],
         [-1.602],
         [-0.472],
         [-1.330],
         [-2.012],
         [-1.075],
         [ 5.735]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e+01],
         [5.164e+00],
         [1.000e-12],
         [8.771e+00],
         [1.000e-12],
         [6.757e+00],
         [1.000e-12],
         [1.000e-12],
         [1.537e+00]],

        [[1.000e-12],
         [5.941e-02],
         [2.841e+00],
         [1.000e-12],
         [5.804e+00],
         [1.000e-12],
         [1.000e-12],
         [1.594e+00],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.473e+00],
         [1.000e-12],
         [6.769e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.563e-01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.177e+00],
         [4.210e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [4.000e+00],
         [1.456e+00],
         [2.591e-01],
         [3.523e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.654e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.335e+00],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.585e-01],
         [9.124e-01],
         [1.000e-12],
         [8.628e+00],
         [6.312e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.713e+00],
         [1.654e+00],
         [7.569e+00],
         [4.652e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.994e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.735e+00]]], device='cuda:0')
v before min max tensor([[25.105],
        [-1.368],
        [ 2.298],
        [ 2.202],
        [-1.336],
        [-1.087],
        [-0.489],
        [-0.653],
        [-2.235],
        [ 6.806]], device='cuda:0')
v tensor([[1.000e+01],
        [1.000e-12],
        [2.298e+00],
        [2.202e+00],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [6.806e+00]], device='cuda:0')
a after update for 1 param tensor([[ 8.370e-03, -4.792e-03,  2.721e-02,  1.478e-02,  1.981e-02,  2.343e-02,
         -2.084e-02,  1.014e-02,  5.215e-03, -3.269e-02],
        [ 5.205e-03, -4.176e-03,  2.060e-03,  9.405e-03,  3.676e-03,  9.893e-03,
         -6.452e-04, -5.316e-03, -2.646e-02, -3.551e-03],
        [ 1.061e-02, -1.119e-02,  1.220e-02,  1.707e-02, -9.286e-03,  2.239e-02,
         -1.358e-02,  4.633e-03, -1.889e-02,  2.841e-03],
        [-4.308e-03,  3.293e-03, -7.590e-03,  7.535e-03,  2.424e-02,  3.716e-02,
         -2.453e-02, -2.202e-03, -3.692e-02,  6.126e-03],
        [ 1.208e-02, -1.621e-02, -2.071e-02,  1.744e-02, -6.600e-03,  4.555e-02,
         -1.031e-02, -1.168e-03,  3.432e-02, -1.919e-02],
        [-7.123e-03,  4.511e-02,  1.999e-02,  3.459e-02, -1.744e-02, -1.294e-02,
          4.091e-03,  1.766e-02, -1.062e-02, -5.278e-05],
        [-5.466e-04,  2.151e-02, -1.015e-02,  2.115e-02,  1.757e-03,  2.004e-02,
          1.783e-02,  6.216e-03, -6.335e-03,  9.861e-04],
        [-3.790e-03,  1.926e-05,  2.465e-02,  2.428e-03,  2.714e-03,  1.408e-02,
          1.099e-02, -7.860e-03, -1.226e-03, -1.189e-02],
        [ 4.672e-03,  1.854e-02, -1.180e-02,  4.572e-02, -2.185e-02,  3.125e-02,
          1.380e-02, -5.348e-02, -6.519e-03, -1.081e-04],
        [ 7.341e-03, -1.383e-02, -2.534e-02, -1.800e-03, -1.183e-03,  9.114e-03,
         -2.969e-02,  8.473e-03,  1.863e-02, -1.121e-02],
        [ 4.978e-03,  5.421e-04,  3.213e-03, -2.124e-02,  4.870e-03,  6.548e-03,
          6.185e-03,  6.268e-03, -1.178e-02,  1.703e-02],
        [ 1.081e-02,  1.131e-03,  1.817e-02,  1.083e-02,  1.014e-02,  2.038e-03,
         -3.220e-02, -1.152e-02, -1.136e-02, -7.380e-03],
        [-1.808e-02,  1.834e-03,  6.219e-03,  1.370e-02, -9.285e-03, -1.373e-02,
          8.045e-03,  3.388e-02, -3.105e-02,  2.981e-02],
        [ 1.646e-02, -1.382e-03,  3.183e-03,  4.607e-03,  2.413e-02, -1.742e-02,
         -2.532e-03,  1.240e-02,  1.440e-03, -1.109e-02],
        [ 1.610e-03, -2.163e-02,  1.087e-02, -6.976e-03,  1.691e-02,  1.329e-02,
         -1.601e-03, -1.689e-03, -1.683e-03,  2.017e-02],
        [-3.685e-02,  1.044e-02, -1.550e-02,  2.252e-02, -7.570e-02, -1.155e-02,
          1.064e-03,  1.880e-03,  2.559e-02, -2.714e-02],
        [-4.806e-03, -2.102e-02, -9.338e-03,  2.096e-02, -2.475e-02,  1.435e-02,
         -2.033e-02, -6.419e-03, -8.952e-03,  8.977e-03],
        [ 1.675e-02,  7.911e-03, -2.502e-02,  6.336e-04,  8.828e-03, -4.068e-03,
         -2.689e-03,  1.819e-03,  1.310e-02, -2.145e-03],
        [-1.412e-03, -7.394e-03,  1.263e-02,  2.726e-02,  1.374e-02,  5.036e-04,
          1.694e-02, -1.415e-02, -2.632e-02, -1.571e-02],
        [ 7.311e-03, -5.575e-03, -2.792e-02,  9.485e-03, -1.721e-02,  2.343e-02,
          1.757e-02, -3.885e-02,  5.451e-02, -4.908e-03],
        [-8.010e-03, -4.002e-03, -5.840e-03,  2.677e-02, -3.937e-03,  3.505e-03,
          6.012e-03,  1.687e-02, -4.010e-02, -9.446e-03],
        [-2.327e-02,  9.051e-03, -3.144e-03, -2.306e-02,  8.024e-03,  9.175e-03,
         -6.827e-03, -1.035e-02, -1.677e-02,  1.352e-03],
        [ 1.292e-03,  1.913e-02, -3.956e-05, -2.435e-02,  2.536e-03, -1.880e-02,
          1.379e-02,  1.807e-02, -1.755e-03,  4.386e-02],
        [ 2.263e-02, -8.315e-03, -3.224e-03, -7.454e-04, -1.126e-03, -1.367e-02,
         -9.036e-03,  2.670e-02,  1.086e-03,  2.113e-02],
        [-4.935e-02, -1.620e-02,  7.106e-03,  1.374e-02,  2.069e-02, -1.917e-02,
         -1.415e-02, -4.626e-02,  2.748e-02, -6.566e-03],
        [ 8.707e-03,  1.361e-02,  7.076e-03, -3.977e-04,  8.484e-03, -1.149e-02,
         -1.117e-02,  1.306e-02,  1.274e-02, -1.823e-03],
        [-2.007e-02,  1.722e-02, -8.901e-03, -2.150e-02,  6.025e-05,  2.115e-02,
          4.909e-03,  2.707e-02, -2.745e-02, -3.057e-02],
        [ 2.422e-02, -5.944e-03, -8.927e-03, -3.777e-03, -4.280e-02, -9.034e-03,
          6.907e-04, -1.551e-02, -9.504e-03, -7.648e-03],
        [ 6.032e-03,  1.028e-02,  1.887e-03,  2.863e-02,  5.258e-03,  4.503e-02,
         -2.362e-02, -2.887e-03, -1.782e-02, -3.438e-02],
        [-2.935e-03, -5.220e-03,  7.819e-04, -3.430e-02, -1.284e-03,  5.522e-02,
          4.307e-03,  2.428e-02,  9.868e-03,  8.406e-02],
        [ 9.018e-03, -2.196e-03,  4.387e-03,  2.914e-03,  2.235e-02, -1.252e-02,
         -9.140e-03,  4.421e-03, -6.143e-02, -4.024e-02],
        [-3.977e-03,  6.603e-03, -1.800e-03, -1.219e-03,  1.437e-02, -1.874e-04,
          5.531e-04, -4.227e-03, -5.605e-02, -1.432e-02],
        [ 6.497e-03, -3.391e-04,  2.411e-03, -8.678e-03,  7.080e-03, -8.987e-03,
         -1.157e-02,  1.488e-02, -2.256e-02, -3.018e-03],
        [-9.811e-03, -6.511e-03,  1.173e-02,  5.656e-04,  1.343e-02, -1.193e-02,
          3.304e-02, -2.900e-04, -9.968e-03,  3.825e-03],
        [ 1.279e-02,  1.374e-03, -1.574e-02, -8.475e-03, -1.027e-03,  1.602e-02,
          5.580e-03,  3.721e-03, -1.674e-02,  2.709e-02],
        [ 5.392e-03,  3.513e-03, -1.027e-03,  2.390e-04, -1.754e-03, -5.229e-03,
         -1.550e-04,  4.117e-03, -2.004e-02, -7.493e-03],
        [ 3.714e-03,  1.827e-02,  1.644e-03, -3.533e-03, -2.086e-02,  3.798e-03,
          3.348e-05, -3.509e-02,  1.140e-03, -1.880e-02],
        [-1.178e-02,  2.121e-03, -4.323e-03,  3.532e-03, -1.274e-02,  5.882e-03,
          4.022e-03, -8.950e-03,  6.917e-03, -2.217e-02],
        [ 7.858e-03, -9.310e-03, -9.546e-03,  5.828e-04,  5.782e-03, -9.458e-03,
          6.230e-03, -3.876e-02, -1.942e-02,  1.531e-02],
        [-1.716e-02, -9.845e-03, -1.768e-04,  1.141e-02,  2.181e-02,  4.923e-03,
         -6.162e-03,  7.526e-03, -5.182e-03,  1.228e-02],
        [ 1.204e-03, -9.816e-03, -2.541e-02,  3.637e-02,  3.173e-03, -1.541e-02,
          3.201e-02,  7.834e-03, -4.059e-02,  2.393e-02],
        [-2.206e-02, -1.028e-02, -1.267e-02, -2.292e-02,  5.696e-03,  9.963e-03,
          3.750e-03,  2.811e-02, -2.699e-03,  2.355e-02],
        [ 9.624e-03,  2.749e-02, -2.907e-03, -3.197e-02, -5.268e-03, -1.206e-03,
         -2.207e-02, -3.153e-03,  3.451e-03, -9.987e-03],
        [-1.386e-02, -3.354e-02, -4.198e-02, -1.636e-02, -1.472e-02, -1.054e-02,
          9.363e-03, -8.557e-04, -1.003e-02,  2.390e-02],
        [-5.863e-03, -6.551e-03,  1.135e-02,  1.490e-02, -1.597e-02, -3.616e-02,
          5.418e-03, -4.288e-02,  2.398e-02, -2.280e-03],
        [ 6.212e-02,  1.170e-02,  3.566e-02,  1.290e-02, -1.162e-03,  3.479e-03,
          3.660e-02,  4.363e-02,  1.029e-02, -1.431e-02],
        [ 8.210e-03, -1.994e-02, -3.995e-03,  4.098e-02, -1.767e-03, -7.048e-03,
          9.675e-03,  1.552e-02, -2.099e-02,  4.182e-02],
        [-2.549e-02, -5.786e-03, -4.202e-03, -1.142e-02,  1.889e-02,  1.176e-02,
          1.395e-03, -2.793e-02, -1.189e-02, -3.413e-03],
        [-1.906e-03,  4.843e-02, -3.420e-02, -2.054e-02,  6.777e-04,  7.901e-04,
         -1.201e-02,  4.935e-03,  2.309e-02,  1.769e-02],
        [-1.118e-02, -3.421e-02, -3.651e-02, -1.207e-02, -5.956e-03, -1.302e-02,
         -1.383e-02,  3.010e-02, -2.679e-02, -8.243e-03],
        [ 3.174e-03, -3.040e-02, -1.466e-03,  3.241e-02, -5.448e-03,  2.004e-02,
         -1.430e-02, -1.623e-03,  3.115e-02, -3.895e-02],
        [-2.044e-02,  2.043e-02, -2.905e-03,  1.046e-02, -3.859e-03,  2.892e-03,
          1.063e-02,  6.619e-03, -7.314e-03, -2.389e-03],
        [-1.609e-02, -4.177e-02,  2.400e-02,  1.533e-02, -4.377e-03, -8.692e-04,
          1.890e-03, -1.087e-02, -4.182e-02,  1.098e-02],
        [ 5.004e-02,  1.994e-02,  1.458e-02,  4.244e-02, -1.933e-03,  4.873e-03,
          1.003e-02, -4.176e-02, -1.470e-02, -2.472e-02],
        [ 3.302e-03, -3.066e-02,  4.552e-03,  2.995e-02, -4.640e-03, -4.126e-03,
          7.792e-02, -8.969e-03, -1.344e-02, -7.339e-03],
        [ 1.125e-02,  9.169e-03, -1.747e-02,  2.740e-03,  1.913e-02,  7.070e-03,
          1.176e-02,  1.134e-02,  1.170e-02, -1.115e-02],
        [-4.329e-03,  1.620e-02, -8.344e-03, -5.034e-02,  1.457e-02,  1.324e-02,
         -4.947e-02, -1.504e-02, -1.168e-02,  1.196e-02],
        [ 1.273e-03,  1.631e-02, -1.325e-02,  1.821e-02,  9.932e-03, -5.869e-04,
          6.053e-03, -1.805e-02, -1.545e-03, -4.602e-02],
        [-5.080e-03, -2.388e-02,  4.048e-03,  4.915e-02,  9.015e-04, -9.068e-03,
         -1.547e-02, -3.094e-04,  3.314e-02, -1.514e-02],
        [ 2.256e-02,  1.869e-02,  6.141e-03,  5.749e-02,  3.029e-02, -3.701e-03,
          6.545e-03,  4.376e-02, -3.311e-03, -4.859e-03],
        [ 1.019e-02, -7.101e-03, -2.295e-03,  4.292e-02,  9.989e-03, -1.678e-02,
         -9.600e-03,  1.679e-02,  3.253e-02, -1.437e-02],
        [ 8.293e-03,  9.168e-03,  3.801e-03, -9.405e-04, -1.575e-02, -4.920e-03,
         -1.428e-02, -2.283e-02, -2.569e-02, -7.742e-03],
        [-8.832e-04,  2.040e-02, -1.298e-02,  3.099e-03,  9.066e-04, -1.035e-03,
          4.594e-04, -1.648e-02, -2.207e-03,  5.173e-02],
        [ 1.008e-02,  1.028e-02,  2.690e-02,  3.506e-02,  1.046e-03, -2.506e-02,
         -7.007e-03, -1.665e-02, -1.560e-02, -2.544e-02],
        [-1.853e-02, -2.019e-02, -1.781e-02, -4.227e-02,  5.690e-03,  5.982e-03,
         -2.111e-04, -1.271e-02,  8.262e-03, -5.586e-03],
        [-2.189e-02, -3.296e-05,  5.587e-04,  3.731e-04,  9.225e-03,  4.768e-03,
         -1.012e-02,  4.283e-03,  1.300e-03, -3.508e-02],
        [ 2.549e-02, -1.215e-02, -3.464e-03,  1.206e-02, -3.465e-03, -3.523e-03,
         -7.980e-03, -1.600e-02, -7.675e-03, -5.716e-03],
        [ 7.634e-03,  2.846e-03, -1.192e-02, -3.968e-02,  1.094e-02,  1.764e-02,
          1.542e-03,  1.186e-02,  1.075e-02,  1.955e-02],
        [ 4.048e-02, -2.557e-03, -2.610e-02, -4.963e-03,  1.883e-02,  9.399e-03,
          9.353e-03,  2.900e-03, -4.685e-03, -2.291e-02],
        [ 7.078e-03,  1.013e-02,  7.884e-03,  3.309e-02, -4.182e-03, -2.962e-03,
         -9.725e-03, -3.131e-02,  6.946e-04,  6.682e-03],
        [ 1.927e-02,  9.721e-03, -4.918e-03, -8.520e-04, -6.526e-03,  1.806e-02,
          1.696e-02,  2.668e-03,  3.446e-04, -2.259e-02],
        [ 6.478e-03, -9.772e-03, -2.513e-02, -8.630e-03,  1.354e-02,  6.693e-03,
          4.112e-02,  6.152e-03,  2.116e-02, -3.642e-03],
        [-1.725e-02, -6.311e-03, -1.108e-02, -1.368e-02, -1.188e-03, -7.320e-03,
         -2.530e-02, -6.891e-03, -5.656e-03, -1.178e-02],
        [ 5.941e-03, -8.424e-03,  3.744e-03, -1.894e-02, -2.223e-03,  3.585e-03,
          4.883e-02,  3.302e-04,  4.931e-03, -2.543e-02],
        [ 8.102e-03,  1.658e-02,  1.411e-02,  1.037e-02,  1.368e-03,  2.839e-03,
         -8.382e-03, -1.091e-03,  1.844e-03,  9.737e-03],
        [ 2.911e-02, -3.914e-03, -1.283e-02,  2.293e-02, -1.109e-02, -7.466e-03,
         -1.739e-02,  1.435e-02,  1.330e-03, -2.017e-02],
        [-2.277e-02,  1.159e-02,  1.743e-02, -1.247e-02,  1.779e-02,  1.412e-02,
          3.055e-03,  8.897e-03,  3.694e-03, -3.275e-03],
        [-6.400e-03,  5.748e-03, -2.627e-03, -3.230e-03,  1.716e-03,  8.156e-03,
         -9.314e-03,  1.515e-03, -1.181e-02, -3.262e-02],
        [-5.765e-03, -2.483e-02,  7.109e-03, -1.435e-02,  1.229e-03,  1.015e-02,
          5.331e-03, -9.983e-03, -1.102e-02,  5.784e-03],
        [ 1.660e-02, -1.157e-02, -1.959e-02, -2.858e-03, -9.317e-03,  1.075e-02,
         -1.250e-02,  1.931e-03, -1.207e-02, -1.246e-02],
        [-2.243e-03, -1.620e-03,  3.335e-02,  1.078e-03, -6.638e-03,  7.953e-03,
         -4.797e-02,  2.244e-02, -6.599e-03,  2.311e-03],
        [-1.535e-02, -5.779e-04,  1.737e-02, -3.570e-02,  9.844e-03, -9.846e-03,
          2.003e-02,  1.037e-03,  4.838e-03, -1.420e-02],
        [ 2.864e-02, -7.404e-03, -6.480e-04, -1.999e-02,  4.694e-03, -5.150e-03,
          1.969e-02, -8.184e-03,  1.058e-03, -3.840e-03],
        [-7.606e-03, -6.666e-04,  2.896e-03, -1.965e-02,  2.479e-02, -9.149e-05,
          6.274e-02,  5.912e-03,  1.301e-02,  9.793e-04],
        [ 1.023e-02, -3.616e-03, -1.259e-02,  1.747e-02,  1.400e-02, -3.321e-02,
         -6.039e-03,  2.230e-02,  1.936e-03, -9.147e-03],
        [-1.385e-03,  5.370e-03,  1.751e-02,  1.471e-03,  1.196e-04,  6.658e-03,
          1.461e-02,  1.021e-02, -2.952e-03, -8.796e-03],
        [-8.663e-03,  2.804e-03, -1.237e-02, -2.151e-02, -2.248e-02,  1.962e-03,
         -2.581e-03, -2.583e-03, -1.175e-03,  4.039e-03],
        [ 9.049e-03,  5.239e-03,  8.436e-03,  3.890e-03, -9.650e-03, -5.581e-03,
         -1.729e-02,  7.775e-03,  7.332e-03,  4.480e-03],
        [ 6.623e-03,  2.634e-03,  1.798e-02,  1.758e-02, -5.906e-04, -2.219e-02,
          1.177e-02, -7.029e-03, -2.383e-03, -4.688e-03],
        [-1.256e-02,  7.758e-03,  6.081e-03, -2.098e-02,  2.977e-04,  5.806e-03,
         -2.621e-03,  2.786e-02,  3.397e-03, -1.321e-04],
        [ 2.687e-02,  1.300e-03, -2.152e-02,  4.108e-03, -1.360e-03,  4.600e-03,
         -3.386e-02,  1.575e-02,  1.984e-02,  4.108e-03],
        [ 7.944e-03,  9.254e-03,  1.920e-03, -5.132e-02, -5.715e-03,  4.891e-03,
          1.862e-02, -4.167e-02, -1.442e-02,  1.321e-02],
        [ 2.107e-02, -2.230e-02, -1.487e-02, -8.265e-03, -7.341e-03,  9.920e-03,
          4.823e-02,  2.071e-03,  8.407e-03,  4.578e-03],
        [-2.213e-02,  5.477e-03,  1.438e-02,  3.556e-02, -1.261e-02,  9.350e-03,
          3.586e-02,  4.447e-03, -1.091e-02, -1.728e-02],
        [-1.569e-03,  2.620e-02, -1.516e-02, -1.152e-02,  4.053e-03, -1.107e-02,
          1.894e-02, -1.252e-02,  5.217e-02,  7.789e-04],
        [-1.541e-02,  6.667e-02, -5.730e-05, -1.381e-02,  1.567e-02, -4.214e-02,
          9.111e-03, -5.365e-03, -3.755e-02,  1.161e-02],
        [ 2.251e-03, -2.777e-02, -1.668e-02, -8.434e-03,  9.047e-03,  2.307e-02,
          2.216e-02,  2.029e-02,  6.193e-02,  8.626e-03],
        [ 1.439e-02,  2.947e-03, -1.646e-02,  2.781e-04, -1.506e-02,  2.952e-03,
         -9.241e-03,  1.306e-02, -2.722e-02,  4.989e-03],
        [-1.288e-02,  2.853e-02,  1.745e-02,  5.079e-03, -3.620e-02,  1.200e-02,
          2.516e-02, -1.150e-02, -4.413e-02, -3.428e-05],
        [ 3.680e-02, -4.145e-02, -2.249e-02,  1.918e-02, -8.808e-03, -2.914e-02,
         -1.431e-02,  6.570e-03, -4.038e-02,  3.975e-03]], device='cuda:0')
s after update for 1 param tensor([[0.709, 1.079, 0.402, 1.081, 0.524, 1.067, 1.262, 0.799, 1.408, 1.270],
        [1.518, 0.791, 1.336, 1.054, 0.575, 1.095, 0.568, 0.607, 0.968, 0.668],
        [1.276, 1.183, 1.384, 0.329, 1.302, 1.001, 1.194, 1.246, 1.032, 0.952],
        [1.066, 0.984, 0.695, 1.217, 1.028, 0.509, 1.570, 0.805, 0.912, 0.701],
        [0.636, 1.581, 0.990, 1.418, 0.735, 0.995, 0.829, 0.942, 0.449, 1.104],
        [1.260, 1.554, 0.734, 1.110, 0.662, 0.795, 0.770, 0.905, 0.901, 0.552],
        [0.726, 0.980, 0.967, 0.696, 0.613, 0.944, 0.834, 0.511, 1.149, 0.687],
        [1.047, 0.531, 0.746, 0.945, 0.751, 1.158, 0.710, 0.594, 0.635, 1.273],
        [0.958, 0.748, 0.784, 0.808, 1.241, 0.903, 1.243, 1.051, 1.453, 0.631],
        [1.326, 1.131, 0.943, 1.216, 0.855, 0.378, 0.628, 0.680, 0.917, 1.420],
        [1.179, 1.375, 0.786, 0.750, 0.845, 1.183, 1.188, 0.404, 0.497, 0.751],
        [1.092, 1.189, 0.324, 1.218, 0.627, 0.832, 0.989, 0.517, 0.790, 0.671],
        [0.576, 0.549, 1.113, 0.654, 0.898, 1.193, 1.027, 0.800, 0.416, 0.563],
        [1.424, 0.591, 0.854, 0.853, 1.348, 0.644, 0.547, 1.242, 0.757, 0.977],
        [1.222, 0.665, 1.211, 1.076, 1.119, 0.636, 1.263, 0.851, 0.880, 1.021],
        [1.386, 0.656, 1.023, 0.580, 0.738, 0.594, 0.463, 1.113, 0.531, 0.783],
        [0.722, 0.673, 1.108, 0.432, 0.857, 0.690, 0.732, 0.358, 0.575, 0.913],
        [0.637, 1.277, 0.688, 0.955, 0.578, 0.997, 0.763, 0.812, 1.168, 0.923],
        [1.347, 1.437, 0.738, 0.593, 0.529, 0.755, 0.734, 0.962, 0.787, 0.706],
        [1.053, 1.398, 0.917, 0.516, 0.720, 0.694, 0.582, 1.304, 0.770, 0.968],
        [0.535, 1.152, 1.291, 0.619, 1.145, 1.166, 0.687, 1.258, 0.703, 1.576],
        [1.279, 0.852, 1.083, 0.684, 1.488, 1.018, 0.563, 0.352, 1.017, 1.427],
        [0.745, 0.501, 1.052, 1.206, 1.019, 0.846, 0.736, 0.769, 0.506, 0.722],
        [0.609, 1.169, 1.563, 0.644, 0.311, 1.240, 0.738, 0.747, 1.031, 0.754],
        [1.180, 1.701, 1.770, 1.041, 1.036, 0.654, 0.935, 1.727, 0.816, 1.664],
        [0.352, 0.723, 1.203, 0.827, 0.490, 0.846, 1.247, 1.413, 0.847, 0.566],
        [1.460, 0.429, 1.338, 0.468, 1.398, 0.952, 1.408, 1.362, 1.010, 1.246],
        [0.844, 0.617, 1.074, 1.010, 0.387, 1.392, 1.241, 0.591, 0.458, 1.282],
        [0.560, 0.731, 1.166, 0.783, 0.592, 0.213, 1.352, 0.975, 1.230, 0.883],
        [0.323, 0.771, 1.313, 0.801, 1.275, 0.418, 0.764, 1.139, 0.890, 0.798],
        [1.065, 0.530, 1.015, 0.884, 0.894, 0.903, 1.044, 0.803, 0.949, 0.739],
        [0.444, 0.592, 0.572, 0.732, 0.664, 0.868, 0.691, 0.439, 0.971, 0.296],
        [0.522, 1.024, 0.953, 0.992, 1.110, 1.294, 0.620, 1.003, 0.581, 0.721],
        [1.070, 0.566, 0.946, 0.922, 1.207, 1.062, 1.037, 0.986, 0.629, 0.667],
        [0.625, 1.255, 1.164, 1.355, 0.698, 1.387, 0.985, 1.047, 0.566, 1.235],
        [0.986, 1.476, 0.628, 1.042, 1.057, 0.631, 1.316, 0.826, 0.656, 0.957],
        [0.748, 1.515, 0.939, 0.931, 1.573, 0.627, 0.564, 1.513, 1.154, 0.614],
        [0.691, 0.964, 0.536, 0.642, 0.985, 0.887, 0.596, 0.663, 0.778, 1.355],
        [0.924, 0.912, 0.883, 0.658, 0.849, 0.326, 0.921, 0.753, 0.774, 0.434],
        [0.800, 0.666, 0.488, 1.224, 1.218, 1.396, 0.846, 0.600, 0.941, 0.919],
        [0.670, 0.764, 0.903, 1.320, 0.861, 0.682, 1.265, 0.874, 1.048, 0.728],
        [0.709, 1.215, 0.649, 0.460, 1.159, 0.955, 0.797, 0.611, 0.943, 0.518],
        [0.496, 1.298, 0.575, 1.042, 0.545, 0.979, 0.500, 1.050, 1.456, 0.959],
        [0.943, 0.888, 0.643, 0.850, 1.445, 0.739, 0.519, 1.176, 1.216, 0.794],
        [1.074, 0.608, 0.934, 0.329, 0.999, 0.978, 1.332, 0.654, 1.195, 1.265],
        [1.323, 0.857, 1.041, 0.467, 0.958, 1.030, 0.839, 0.626, 0.626, 0.581],
        [0.573, 0.906, 0.939, 1.190, 1.183, 0.776, 0.793, 0.465, 0.587, 1.001],
        [1.259, 1.201, 0.444, 0.980, 1.251, 1.707, 1.410, 0.662, 0.591, 1.040],
        [1.261, 0.627, 1.265, 0.875, 0.889, 1.237, 1.056, 0.559, 0.442, 1.166],
        [1.269, 1.051, 0.796, 0.992, 0.769, 0.842, 0.979, 0.791, 0.987, 1.163],
        [0.569, 0.962, 1.109, 1.379, 0.442, 1.108, 1.102, 0.950, 1.279, 1.243],
        [0.294, 0.900, 0.517, 0.664, 0.861, 1.178, 0.376, 0.984, 0.496, 1.017],
        [1.047, 0.869, 0.676, 0.625, 0.900, 0.519, 0.423, 0.403, 1.212, 0.421],
        [0.710, 0.887, 0.585, 0.769, 0.644, 0.981, 0.771, 0.454, 0.721, 0.944],
        [0.535, 0.448, 0.800, 0.587, 0.600, 0.675, 1.043, 0.462, 0.424, 0.658],
        [0.515, 0.628, 0.890, 1.254, 1.404, 0.929, 1.198, 1.198, 0.752, 0.871],
        [1.262, 0.519, 1.158, 0.804, 1.077, 1.289, 0.968, 0.600, 0.771, 0.634],
        [0.635, 0.601, 1.103, 0.779, 0.702, 1.041, 0.777, 0.939, 0.875, 1.280],
        [0.662, 1.605, 1.500, 0.891, 0.918, 1.093, 0.781, 0.486, 0.748, 0.258],
        [1.225, 0.793, 1.074, 1.332, 0.780, 1.085, 1.090, 0.664, 0.688, 0.934],
        [0.834, 0.953, 0.684, 0.455, 0.584, 1.140, 1.529, 0.723, 0.681, 0.637],
        [1.384, 0.600, 1.289, 0.446, 0.888, 0.670, 1.108, 1.030, 0.607, 0.755],
        [0.870, 0.692, 0.611, 0.645, 0.639, 1.030, 0.760, 0.624, 1.279, 1.068],
        [0.767, 1.209, 1.073, 0.448, 0.452, 0.543, 1.030, 0.915, 0.578, 0.774],
        [0.328, 0.931, 0.740, 0.721, 0.720, 0.683, 0.953, 0.851, 1.461, 1.327],
        [1.042, 0.614, 0.448, 0.636, 0.906, 0.708, 0.512, 0.543, 0.986, 1.206],
        [1.140, 0.660, 0.351, 1.469, 0.427, 1.722, 0.861, 1.229, 1.661, 0.953],
        [1.078, 1.112, 1.105, 0.535, 1.174, 0.855, 0.918, 1.116, 0.625, 0.980],
        [0.966, 1.365, 0.866, 0.708, 1.837, 0.356, 1.068, 1.271, 0.535, 0.520],
        [1.062, 0.703, 0.869, 0.683, 0.767, 1.133, 1.372, 0.919, 1.688, 1.067],
        [0.875, 1.048, 0.995, 1.071, 0.916, 1.477, 0.721, 1.456, 0.324, 0.972],
        [0.522, 0.323, 0.852, 0.725, 1.448, 0.580, 0.991, 0.862, 0.590, 0.440],
        [1.319, 1.251, 0.460, 1.267, 0.748, 0.738, 0.940, 1.663, 0.703, 0.709],
        [0.797, 0.643, 0.738, 0.593, 0.788, 0.780, 0.866, 0.559, 0.969, 0.391],
        [0.761, 1.221, 0.923, 0.406, 1.170, 0.641, 1.015, 0.981, 0.859, 0.350],
        [0.836, 1.089, 1.175, 0.939, 0.843, 1.015, 1.081, 1.463, 0.409, 1.010],
        [0.812, 1.267, 0.868, 0.839, 0.800, 1.120, 1.531, 0.942, 0.630, 1.023],
        [0.517, 1.301, 1.074, 0.940, 1.032, 0.977, 0.787, 1.052, 1.635, 0.582],
        [0.305, 0.982, 1.306, 0.750, 0.734, 0.892, 0.983, 1.028, 0.888, 0.700],
        [0.799, 1.138, 0.343, 1.347, 1.331, 1.079, 0.242, 0.942, 0.761, 1.246],
        [1.067, 1.186, 0.718, 1.292, 0.584, 0.383, 1.524, 0.489, 1.404, 1.119],
        [1.037, 1.073, 0.622, 0.377, 0.807, 1.289, 1.360, 0.631, 1.604, 0.945],
        [1.246, 0.795, 1.346, 1.092, 1.065, 0.767, 1.058, 1.218, 0.750, 1.293],
        [0.734, 1.069, 1.016, 0.388, 1.264, 1.202, 1.108, 1.637, 0.879, 1.236],
        [0.589, 1.290, 1.415, 0.719, 1.098, 1.193, 0.776, 1.002, 0.681, 0.715],
        [1.191, 0.921, 0.905, 0.891, 0.799, 0.662, 0.789, 0.859, 0.492, 0.686],
        [0.837, 0.831, 0.943, 0.788, 0.793, 1.136, 1.141, 0.893, 0.667, 0.626],
        [1.021, 1.129, 0.926, 0.375, 0.889, 1.154, 0.937, 0.622, 0.812, 1.406],
        [1.058, 1.283, 1.103, 0.589, 0.717, 0.626, 1.157, 0.269, 0.855, 0.468],
        [0.904, 1.295, 0.987, 1.074, 0.908, 0.700, 0.640, 0.786, 0.932, 0.980],
        [0.783, 1.432, 1.223, 0.562, 1.074, 1.448, 0.650, 1.023, 1.007, 1.409],
        [0.957, 0.654, 1.051, 0.777, 0.626, 0.786, 1.034, 0.639, 0.911, 0.883],
        [0.521, 0.842, 1.263, 0.473, 0.544, 0.912, 0.573, 0.868, 0.612, 1.483],
        [0.725, 0.729, 1.042, 1.542, 0.753, 0.996, 0.868, 1.618, 0.991, 1.508],
        [1.017, 1.161, 0.761, 0.792, 1.283, 0.888, 1.014, 1.006, 1.416, 1.188],
        [1.389, 0.850, 0.704, 0.696, 0.583, 0.985, 0.609, 1.055, 0.961, 1.508],
        [1.144, 1.296, 0.480, 0.912, 1.137, 1.650, 0.852, 1.506, 0.982, 1.527],
        [0.981, 0.500, 0.563, 0.432, 0.838, 0.993, 1.172, 1.069, 0.996, 0.980],
        [1.159, 1.260, 1.042, 0.969, 0.918, 0.798, 0.789, 0.667, 0.545, 0.892],
        [1.325, 0.875, 1.388, 1.128, 1.091, 0.822, 0.920, 1.236, 1.062, 0.904]],
       device='cuda:0')
b after update for 1 param tensor([[28.026, 34.587, 21.103, 34.609, 24.111, 34.384, 37.397, 29.754, 39.509,
         37.519],
        [41.027, 29.607, 38.477, 34.174, 25.253, 34.832, 25.098, 25.948, 32.759,
         27.207],
        [37.609, 36.220, 39.170, 19.105, 37.993, 33.315, 36.381, 37.171, 33.823,
         32.488],
        [34.383, 33.030, 27.757, 36.735, 33.764, 23.744, 41.721, 29.873, 31.794,
         27.881],
        [26.553, 41.865, 33.121, 39.641, 28.541, 33.209, 30.310, 32.315, 22.316,
         34.989],
        [37.377, 41.510, 28.524, 35.083, 27.100, 29.683, 29.211, 31.672, 31.597,
         24.735],
        [28.377, 32.961, 32.745, 27.768, 26.059, 32.348, 30.403, 23.810, 35.691,
         27.603],
        [34.062, 24.266, 28.751, 32.361, 28.858, 35.835, 28.056, 25.663, 26.532,
         37.570],
        [32.595, 28.801, 29.478, 29.937, 37.091, 31.643, 37.123, 34.131, 40.130,
         26.456],
        [38.335, 35.401, 32.339, 36.713, 30.783, 20.474, 26.390, 27.447, 31.879,
         39.674],
        [36.158, 39.047, 29.527, 28.832, 30.607, 36.213, 36.288, 21.157, 23.470,
         28.851],
        [34.797, 36.311, 18.959, 36.752, 26.361, 30.360, 33.114, 23.947, 29.593,
         27.269],
        [25.274, 24.669, 35.133, 26.934, 31.549, 36.373, 33.735, 29.772, 21.477,
         24.972],
        [39.731, 25.586, 30.771, 30.746, 38.662, 26.728, 24.630, 37.107, 28.965,
         32.902],
        [36.812, 27.149, 36.642, 34.542, 35.228, 26.558, 37.421, 30.723, 31.236,
         33.639],
        [39.198, 26.964, 33.674, 25.355, 28.595, 25.664, 22.659, 35.126, 24.265,
         29.455],
        [28.292, 27.310, 35.052, 21.879, 30.823, 27.648, 28.495, 19.926, 25.258,
         31.805],
        [26.571, 37.618, 27.615, 32.538, 25.308, 33.252, 29.080, 29.997, 35.988,
         31.983],
        [38.643, 39.906, 28.599, 25.631, 24.211, 28.937, 28.524, 32.660, 29.546,
         27.976],
        [34.166, 39.361, 31.888, 23.927, 28.252, 27.733, 25.403, 38.013, 29.216,
         32.759],
        [24.344, 35.728, 37.835, 26.188, 35.621, 35.949, 27.598, 37.337, 27.912,
         41.798],
        [37.650, 30.726, 34.645, 27.543, 40.620, 33.589, 24.974, 19.752, 33.569,
         39.768],
        [28.731, 23.567, 34.148, 36.570, 33.617, 30.629, 28.565, 29.200, 23.690,
         28.295],
        [25.979, 36.005, 41.627, 26.720, 18.565, 37.074, 28.608, 28.776, 33.800,
         28.918],
        [36.168, 43.427, 44.301, 33.970, 33.889, 26.935, 32.202, 43.754, 30.074,
         42.946],
        [19.743, 28.316, 36.520, 30.271, 23.313, 30.620, 37.175, 39.583, 30.643,
         25.044],
        [40.228, 21.801, 38.515, 22.784, 39.365, 32.483, 39.503, 38.852, 33.454,
         37.172],
        [30.590, 26.157, 34.500, 33.456, 20.715, 39.286, 37.091, 25.606, 22.545,
         37.701],
        [24.914, 28.468, 35.951, 29.461, 25.612, 15.351, 38.713, 32.883, 36.923,
         31.282],
        [18.923, 29.233, 38.158, 29.804, 37.601, 21.533, 29.106, 35.532, 31.416,
         29.745],
        [34.354, 24.241, 33.541, 31.306, 31.488, 31.636, 34.012, 29.829, 32.432,
         28.621],
        [22.187, 25.613, 25.186, 28.484, 27.126, 31.024, 27.668, 22.068, 32.807,
         18.118],
        [24.050, 33.688, 32.504, 33.158, 35.079, 37.871, 26.223, 33.337, 25.371,
         28.271],
        [34.438, 25.039, 32.383, 31.965, 36.574, 34.314, 33.903, 33.054, 26.402,
         27.186],
        [26.325, 37.300, 35.917, 38.749, 27.826, 39.206, 33.037, 34.068, 25.042,
         37.005],
        [33.053, 40.447, 26.379, 33.992, 34.233, 26.457, 38.188, 30.251, 26.976,
         32.566],
        [28.801, 40.982, 32.256, 32.134, 41.761, 26.355, 25.000, 40.948, 35.766,
         26.097],
        [27.682, 32.687, 24.376, 26.684, 33.050, 31.360, 25.695, 27.101, 29.365,
         38.757],
        [32.004, 31.804, 31.280, 27.012, 30.683, 19.010, 31.959, 28.888, 29.299,
         21.942],
        [29.782, 27.177, 23.264, 36.832, 36.749, 39.345, 30.631, 25.791, 32.292,
         31.924],
        [27.258, 29.093, 31.647, 38.250, 30.893, 27.498, 37.454, 31.130, 34.079,
         28.401],
        [28.026, 36.695, 26.816, 22.579, 35.840, 32.543, 29.720, 26.022, 32.336,
         23.973],
        [23.456, 37.938, 25.255, 33.982, 24.572, 32.940, 23.544, 34.109, 40.172,
         32.597],
        [32.328, 31.370, 26.691, 30.688, 40.026, 28.629, 23.995, 36.103, 36.713,
         29.666],
        [34.511, 25.958, 32.175, 19.095, 33.284, 32.927, 38.429, 26.919, 36.389,
         37.451],
        [38.298, 30.820, 33.965, 22.746, 32.585, 33.793, 30.503, 26.339, 26.352,
         25.383],
        [25.196, 31.697, 32.264, 36.327, 36.211, 29.329, 29.642, 22.696, 25.509,
         33.315],
        [37.352, 36.485, 22.177, 32.968, 37.239, 43.505, 39.540, 27.099, 25.587,
         33.947],
        [37.395, 26.358, 37.453, 31.151, 31.387, 37.033, 34.212, 24.887, 22.123,
         35.951],
        [37.513, 34.135, 29.711, 33.167, 29.206, 30.543, 32.944, 29.611, 33.081,
         35.913],
        [25.111, 32.652, 35.057, 39.095, 22.136, 35.045, 34.948, 32.444, 37.659,
         37.113],
        [18.038, 31.577, 23.939, 27.129, 30.892, 36.136, 20.423, 33.032, 23.448,
         33.571],
        [34.070, 31.029, 27.372, 26.326, 31.594, 23.992, 21.655, 21.135, 36.660,
         21.592],
        [28.050, 31.366, 25.456, 29.192, 26.713, 32.974, 29.230, 22.438, 28.275,
         32.352],
        [24.343, 22.275, 29.781, 25.498, 25.785, 27.355, 34.007, 22.635, 21.691,
         27.017],
        [23.896, 26.394, 31.409, 37.286, 39.455, 32.086, 36.439, 36.449, 28.871,
         31.079],
        [37.402, 23.996, 35.823, 29.857, 34.547, 37.800, 32.756, 25.798, 29.238,
         26.518],
        [26.534, 25.808, 34.972, 29.386, 27.889, 33.962, 29.348, 32.256, 31.149,
         37.662],
        [27.096, 42.180, 40.771, 31.434, 31.909, 34.806, 29.429, 23.209, 28.795,
         16.907],
        [36.851, 29.644, 34.512, 38.424, 29.404, 34.688, 34.755, 27.121, 27.611,
         32.182],
        [30.415, 32.504, 27.536, 22.460, 25.451, 35.548, 41.167, 28.311, 27.466,
         26.576],
        [39.165, 25.788, 37.806, 22.234, 31.381, 27.256, 35.042, 33.797, 25.933,
         28.938],
        [31.056, 27.688, 26.034, 26.737, 26.610, 33.787, 29.017, 26.309, 37.651,
         34.408],
        [29.160, 36.603, 34.481, 22.279, 22.390, 24.527, 33.793, 31.843, 25.319,
         29.290],
        [19.082, 32.122, 28.639, 28.280, 28.242, 27.512, 32.495, 30.706, 40.242,
         38.358],
        [33.984, 26.096, 22.276, 26.544, 31.691, 28.022, 23.816, 24.531, 33.068,
         36.561],
        [35.554, 27.043, 19.736, 40.354, 21.753, 43.694, 30.892, 36.912, 42.916,
         32.510],
        [34.568, 35.108, 34.991, 24.346, 36.075, 30.785, 31.905, 35.167, 26.313,
         32.966],
        [32.720, 38.900, 30.989, 28.006, 45.127, 19.856, 34.410, 37.533, 24.364,
         24.006],
        [34.307, 27.919, 31.045, 27.508, 29.152, 35.435, 38.992, 31.915, 43.258,
         34.391],
        [31.151, 34.083, 33.212, 34.463, 31.873, 40.468, 28.266, 40.173, 18.951,
         32.832],
        [24.052, 18.935, 30.732, 28.342, 40.069, 25.357, 33.137, 30.916, 25.580,
         22.095],
        [38.244, 37.246, 22.593, 37.474, 28.800, 28.612, 32.274, 42.937, 27.920,
         28.042],
        [29.722, 26.707, 28.600, 25.629, 29.553, 29.404, 30.985, 24.902, 32.768,
         20.807],
        [29.042, 36.788, 31.993, 21.215, 36.008, 26.665, 33.551, 32.979, 30.863,
         19.700],
        [30.451, 34.745, 36.085, 32.258, 30.572, 33.543, 34.610, 40.277, 21.286,
         33.454],
        [29.995, 37.476, 31.012, 30.492, 29.785, 35.242, 41.192, 32.314, 26.436,
         33.679],
        [23.937, 37.980, 34.512, 32.285, 33.828, 32.911, 29.541, 34.155, 42.578,
         25.396],
        [18.391, 33.001, 38.053, 28.836, 28.525, 31.445, 33.010, 33.754, 31.367,
         27.850],
        [29.753, 35.525, 19.496, 38.641, 38.418, 34.579, 16.371, 32.308, 29.042,
         37.169],
        [34.388, 36.252, 28.206, 37.851, 25.449, 20.611, 41.105, 23.277, 39.447,
         35.227],
        [33.912, 34.484, 26.255, 20.454, 29.911, 37.800, 38.831, 26.444, 42.167,
         32.365],
        [37.164, 29.687, 38.625, 34.787, 34.359, 29.157, 34.249, 36.750, 28.826,
         37.857],
        [28.532, 34.431, 33.557, 20.732, 37.431, 36.501, 35.048, 42.596, 31.207,
         37.010],
        [25.560, 37.815, 39.609, 28.233, 34.883, 36.370, 29.325, 33.333, 27.467,
         28.151],
        [36.330, 31.954, 31.671, 31.422, 29.766, 27.084, 29.576, 30.864, 23.347,
         27.578],
        [30.468, 30.360, 32.334, 29.557, 29.646, 35.493, 35.565, 31.468, 27.199,
         26.345],
        [33.649, 35.379, 32.031, 20.388, 31.384, 35.764, 32.234, 26.255, 29.997,
         39.486],
        [34.254, 37.706, 34.974, 25.552, 28.191, 26.342, 35.815, 17.264, 30.777,
         22.766],
        [31.650, 37.884, 33.084, 34.507, 31.718, 27.859, 26.631, 29.522, 32.146,
         32.967],
        [29.461, 39.836, 36.813, 24.955, 34.510, 40.071, 26.842, 33.674, 33.410,
         39.525],
        [32.572, 26.927, 34.139, 29.347, 26.339, 29.517, 33.853, 26.624, 31.785,
         31.286],
        [24.042, 30.550, 37.414, 22.894, 24.552, 31.788, 25.204, 31.011, 26.045,
         40.542],
        [28.346, 28.436, 33.979, 41.342, 28.898, 33.221, 31.012, 42.357, 33.144,
         40.885],
        [33.580, 35.877, 29.051, 29.630, 37.707, 31.374, 33.529, 33.387, 39.620,
         36.288],
        [39.243, 30.696, 27.939, 27.783, 25.420, 33.050, 25.982, 34.201, 32.631,
         40.881],
        [35.615, 37.901, 23.073, 31.798, 35.509, 42.771, 30.731, 40.861, 32.988,
         41.140],
        [32.982, 23.536, 24.989, 21.885, 30.479, 33.184, 36.044, 34.417, 33.229,
         32.959],
        [35.850, 37.378, 33.991, 32.769, 31.903, 29.748, 29.583, 27.201, 24.584,
         31.439],
        [38.331, 31.147, 39.230, 35.367, 34.772, 30.189, 31.932, 37.017, 34.315,
         31.659]], device='cuda:0')
clipping threshold 0.32002273704151196
a after update for 1 param tensor([ 0.029, -0.026, -0.029, -0.017,  0.045,  0.019, -0.020,  0.020,  0.048,
        -0.004, -0.013, -0.004, -0.059, -0.058,  0.005,  0.024, -0.017,  0.033,
         0.010, -0.068, -0.049, -0.017,  0.077,  0.008,  0.018, -0.045,  0.016,
         0.037,  0.040, -0.002,  0.029,  0.019, -0.062, -0.001, -0.016,  0.001,
        -0.022,  0.003,  0.011,  0.012, -0.062, -0.022,  0.004,  0.020, -0.036,
        -0.018, -0.007, -0.015,  0.016, -0.006,  0.018, -0.016,  0.021,  0.005,
         0.037, -0.018, -0.014,  0.008, -0.030, -0.030, -0.008,  0.005, -0.010,
        -0.038,  0.008,  0.001,  0.025, -0.052,  0.032, -0.015,  0.000, -0.030,
         0.005,  0.021, -0.020, -0.024,  0.027, -0.023,  0.011,  0.012, -0.025,
        -0.019,  0.019,  0.007,  0.035, -0.012, -0.053, -0.044,  0.053, -0.003,
        -0.005,  0.036, -0.004, -0.017,  0.015, -0.023,  0.046,  0.030,  0.021,
         0.019], device='cuda:0')
s after update for 1 param tensor([0.687, 0.794, 0.880, 0.810, 0.581, 0.564, 0.743, 0.589, 0.725, 1.072,
        0.928, 0.714, 1.143, 1.333, 1.039, 0.891, 0.982, 0.716, 0.799, 0.491,
        0.615, 0.368, 1.059, 0.628, 0.885, 0.513, 0.817, 1.024, 0.518, 0.581,
        0.637, 0.520, 0.455, 0.557, 0.334, 0.762, 0.657, 0.994, 0.791, 0.821,
        0.705, 0.853, 0.676, 0.923, 0.927, 0.560, 1.074, 1.033, 0.809, 0.838,
        1.480, 1.164, 1.291, 1.311, 0.619, 1.271, 0.795, 0.569, 1.067, 0.799,
        1.179, 0.817, 1.043, 1.292, 1.106, 1.225, 1.568, 0.983, 1.003, 0.604,
        1.649, 1.044, 0.631, 0.396, 1.089, 0.837, 0.811, 0.903, 1.369, 0.935,
        1.131, 0.780, 1.023, 0.588, 1.029, 1.337, 1.339, 1.055, 0.842, 0.797,
        0.556, 1.272, 1.354, 1.227, 1.394, 1.345, 1.387, 0.921, 1.144, 0.655],
       device='cuda:0')
b after update for 1 param tensor([27.601, 29.670, 31.241, 29.960, 25.376, 24.996, 28.702, 25.548, 28.349,
        34.467, 32.076, 28.133, 35.598, 38.435, 33.934, 31.435, 32.991, 28.177,
        29.761, 23.319, 26.115, 20.197, 34.270, 26.384, 31.316, 23.845, 30.098,
        33.686, 23.955, 25.386, 26.578, 24.016, 22.466, 24.856, 19.247, 29.066,
        26.987, 33.187, 29.609, 30.164, 27.951, 30.756, 27.384, 31.985, 32.055,
        24.919, 34.500, 33.838, 29.946, 30.473, 40.502, 35.924, 37.823, 38.119,
        26.199, 37.539, 29.680, 25.124, 34.388, 29.763, 36.152, 30.088, 33.997,
        37.848, 35.015, 36.855, 41.696, 33.004, 33.352, 25.881, 42.760, 34.025,
        26.449, 20.950, 34.739, 30.457, 29.976, 31.635, 38.949, 32.199, 35.409,
        29.413, 33.671, 25.523, 33.768, 38.493, 38.531, 34.196, 30.543, 29.726,
        24.833, 37.545, 38.749, 36.884, 39.311, 38.620, 39.210, 31.946, 35.618,
        26.943], device='cuda:0')
clipping threshold 0.32002273704151196
a after update for 1 param tensor([[[-0.004],
         [-0.043],
         [ 0.026],
         [-0.009],
         [-0.001],
         [ 0.000],
         [ 0.019],
         [ 0.012],
         [ 0.047],
         [ 0.038]],

        [[ 0.046],
         [ 0.045],
         [ 0.046],
         [ 0.014],
         [-0.007],
         [ 0.051],
         [-0.043],
         [ 0.027],
         [-0.013],
         [-0.020]],

        [[-0.019],
         [-0.053],
         [ 0.002],
         [ 0.019],
         [ 0.012],
         [ 0.047],
         [ 0.010],
         [-0.004],
         [-0.015],
         [ 0.009]],

        [[-0.006],
         [ 0.004],
         [ 0.017],
         [ 0.001],
         [-0.025],
         [-0.002],
         [ 0.038],
         [-0.004],
         [-0.002],
         [ 0.005]],

        [[-0.007],
         [-0.039],
         [ 0.018],
         [-0.053],
         [ 0.019],
         [ 0.039],
         [ 0.014],
         [ 0.037],
         [-0.058],
         [-0.067]],

        [[ 0.063],
         [-0.026],
         [-0.003],
         [ 0.005],
         [-0.010],
         [-0.024],
         [-0.014],
         [ 0.015],
         [-0.005],
         [ 0.037]],

        [[-0.038],
         [-0.060],
         [ 0.037],
         [-0.022],
         [-0.046],
         [-0.019],
         [ 0.001],
         [-0.029],
         [ 0.042],
         [-0.032]],

        [[ 0.005],
         [-0.021],
         [-0.006],
         [-0.003],
         [ 0.011],
         [ 0.020],
         [ 0.031],
         [-0.070],
         [-0.072],
         [ 0.019]],

        [[-0.019],
         [-0.009],
         [ 0.001],
         [ 0.034],
         [ 0.004],
         [ 0.016],
         [ 0.015],
         [ 0.001],
         [ 0.002],
         [-0.027]],

        [[ 0.047],
         [ 0.029],
         [ 0.048],
         [ 0.006],
         [-0.032],
         [-0.021],
         [-0.016],
         [-0.005],
         [ 0.023],
         [ 0.071]]], device='cuda:0')
s after update for 1 param tensor([[[1.184],
         [1.541],
         [1.000],
         [0.907],
         [1.078],
         [1.235],
         [1.873],
         [1.361],
         [0.723],
         [0.858]],

        [[0.803],
         [0.360],
         [0.872],
         [1.247],
         [1.017],
         [0.441],
         [0.758],
         [1.165],
         [0.829],
         [1.382]],

        [[1.665],
         [0.940],
         [1.530],
         [0.739],
         [0.978],
         [1.125],
         [1.048],
         [0.717],
         [0.932],
         [0.851]],

        [[1.250],
         [1.288],
         [0.711],
         [0.884],
         [0.661],
         [0.900],
         [0.991],
         [0.619],
         [1.127],
         [0.552]],

        [[1.063],
         [0.919],
         [1.257],
         [0.520],
         [0.976],
         [0.609],
         [1.293],
         [0.979],
         [0.922],
         [1.410]],

        [[0.831],
         [1.362],
         [0.714],
         [1.009],
         [1.140],
         [1.079],
         [1.408],
         [1.416],
         [0.525],
         [0.606]],

        [[0.930],
         [1.173],
         [0.841],
         [1.459],
         [0.463],
         [1.028],
         [0.575],
         [1.392],
         [1.697],
         [0.865]],

        [[0.884],
         [0.431],
         [0.680],
         [0.623],
         [0.655],
         [1.499],
         [1.026],
         [1.238],
         [1.576],
         [1.089]],

        [[0.773],
         [0.676],
         [0.728],
         [1.232],
         [1.048],
         [0.824],
         [0.670],
         [1.247],
         [1.023],
         [1.637]],

        [[1.073],
         [0.984],
         [0.911],
         [0.698],
         [0.781],
         [0.909],
         [1.273],
         [1.254],
         [0.454],
         [1.412]]], device='cuda:0')
b after update for 1 param tensor([[[36.221],
         [41.336],
         [33.288],
         [31.714],
         [34.575],
         [36.995],
         [45.570],
         [38.847],
         [28.306],
         [30.838]],

        [[29.834],
         [19.986],
         [31.088],
         [37.173],
         [33.581],
         [22.099],
         [28.979],
         [35.937],
         [30.309],
         [39.142]],

        [[42.961],
         [32.272],
         [41.186],
         [28.631],
         [32.933],
         [35.315],
         [34.089],
         [28.192],
         [32.149],
         [30.709]],

        [[37.231],
         [37.786],
         [28.066],
         [31.302],
         [27.073],
         [31.585],
         [33.139],
         [26.187],
         [35.347],
         [24.745]],

        [[34.321],
         [31.917],
         [37.330],
         [24.001],
         [32.885],
         [25.976],
         [37.855],
         [32.936],
         [31.968],
         [39.530]],

        [[30.356],
         [38.852],
         [28.136],
         [33.441],
         [35.541],
         [34.589],
         [39.506],
         [39.613],
         [24.114],
         [25.924]],

        [[32.110],
         [36.053],
         [30.525],
         [40.216],
         [22.653],
         [33.752],
         [25.256],
         [39.288],
         [43.378],
         [30.969]],

        [[31.312],
         [21.862],
         [27.460],
         [26.289],
         [26.943],
         [40.768],
         [33.730],
         [37.048],
         [41.793],
         [34.743]],

        [[29.270],
         [27.376],
         [28.407],
         [36.957],
         [34.085],
         [30.217],
         [27.258],
         [37.180],
         [33.673],
         [42.599]],

        [[34.487],
         [33.028],
         [31.779],
         [27.815],
         [29.424],
         [31.738],
         [37.567],
         [37.283],
         [22.430],
         [39.559]]], device='cuda:0')
clipping threshold 0.32002273704151196
a after update for 1 param tensor([[-0.016],
        [-0.050],
        [ 0.007],
        [ 0.035],
        [-0.002],
        [ 0.008],
        [-0.002],
        [-0.014],
        [ 0.008],
        [-0.037]], device='cuda:0')
s after update for 1 param tensor([[1.319],
        [0.586],
        [0.744],
        [1.157],
        [1.059],
        [0.899],
        [1.332],
        [1.743],
        [0.910],
        [1.483]], device='cuda:0')
b after update for 1 param tensor([[38.236],
        [25.493],
        [28.728],
        [35.813],
        [34.260],
        [31.561],
        [38.428],
        [43.957],
        [31.768],
        [40.547]], device='cuda:0')
clipping threshold 0.32002273704151196
||w||^2 0.413119840649327
exp ma of ||w||^2 0.24597548406852318
||w|| 0.6427439930869265
exp ma of ||w|| 0.46404988642004846
||w||^2 0.2842190082579677
exp ma of ||w||^2 0.20256537668753616
||w|| 0.5331219450163046
exp ma of ||w|| 0.420707472007457
||w||^2 0.15000951145168254
exp ma of ||w||^2 0.22561413259158336
||w|| 0.3873106136574139
exp ma of ||w|| 0.4438286418387338
||w||^2 0.14804177047234746
exp ma of ||w||^2 0.2320072048504021
||w|| 0.3847619659898149
exp ma of ||w|| 0.4462327401969054
||w||^2 0.2724045672241208
exp ma of ||w||^2 0.22589066000380842
||w|| 0.5219239094198701
exp ma of ||w|| 0.44194135419776853
cuda
Objective function 8.35 = squared loss an data 7.53 + 0.5*rho*h**2 0.293495 + alpha*h 0.073370 + L2reg 0.41 + L1reg 0.05 ; SHD = 16 ; DAG True
Proportion of microbatches that were clipped  0.7600324939073924
iteration 3 in inner loop, alpha 0.95764061791958 rho 100.0 h 0.07661529146143664
iteration 2 in outer loop, alpha = 8.619169764063244, rho = 100.0, h = 0.07661529146143664
cuda
1210
cuda
Objective function 8.94 = squared loss an data 7.53 + 0.5*rho*h**2 0.293495 + alpha*h 0.660360 + L2reg 0.41 + L1reg 0.05 ; SHD = 16 ; DAG True
||w||^2 45.38716642779382
exp ma of ||w||^2 2292320.770786017
||w|| 6.736999809098545
exp ma of ||w|| 151.06187075244546
||w||^2 0.09801686602600973
exp ma of ||w||^2 12824.730273979107
||w|| 0.31307645396294137
exp ma of ||w|| 1.286109757062437
||w||^2 0.08183835434497698
exp ma of ||w||^2 50.08100005165123
||w|| 0.28607403647478563
exp ma of ||w|| 0.3262683038836105
||w||^2 0.13452663054333078
exp ma of ||w||^2 0.23444459170347814
||w|| 0.3667787214974865
exp ma of ||w|| 0.44557751919915745
||w||^2 0.19579497114310893
exp ma of ||w||^2 0.2361695140039676
||w|| 0.4424872553454042
exp ma of ||w|| 0.45144515386567263
||w||^2 0.26539379093415927
exp ma of ||w||^2 0.20932529852965057
||w|| 0.5151638486289185
exp ma of ||w|| 0.43248900034928456
cuda
Objective function 8.71 = squared loss an data 7.77 + 0.5*rho*h**2 0.093613 + alpha*h 0.372948 + L2reg 0.42 + L1reg 0.05 ; SHD = 19 ; DAG True
Proportion of microbatches that were clipped  0.7614389652384802
iteration 1 in inner loop, alpha 8.619169764063244 rho 100.0 h 0.04326956672037774
1210
cuda
Objective function 9.55 = squared loss an data 7.77 + 0.5*rho*h**2 0.936128 + alpha*h 0.372948 + L2reg 0.42 + L1reg 0.05 ; SHD = 19 ; DAG True
||w||^2 308046.39659839834
exp ma of ||w||^2 66241166.73956774
||w|| 555.0192758800349
exp ma of ||w|| 2803.9963451490357
||w||^2 0.9781929548633213
exp ma of ||w||^2 789062.1777138339
||w|| 0.9890363769160977
exp ma of ||w|| 45.22736726328257
||w||^2 0.3325394014049185
exp ma of ||w||^2 174739.8681037733
||w|| 0.5766622940724654
exp ma of ||w|| 10.642701988627186
||w||^2 0.19591067796430953
exp ma of ||w||^2 0.18363872464560138
||w|| 0.44261798197125873
exp ma of ||w|| 0.3991377453947186
||w||^2 0.13679045969039424
exp ma of ||w||^2 0.20078879040069758
||w|| 0.3698519429317551
exp ma of ||w|| 0.4179554434733779
||w||^2 0.0959467229022879
exp ma of ||w||^2 0.20453542034282304
||w|| 0.3097526802180861
exp ma of ||w|| 0.4241021131332019
||w||^2 0.1447296375288525
exp ma of ||w||^2 0.19149656504227872
||w|| 0.38043348634005986
exp ma of ||w|| 0.4142297348661363
||w||^2 0.06871151236794076
exp ma of ||w||^2 0.19296601703811797
||w|| 0.2621288087333034
exp ma of ||w|| 0.4107420632810906
||w||^2 0.2445301635972118
exp ma of ||w||^2 0.22362418553029184
||w|| 0.4944999126362024
exp ma of ||w|| 0.4392642496988627
||w||^2 0.16097598254935136
exp ma of ||w||^2 0.2125572420696086
||w|| 0.4012181234058992
exp ma of ||w|| 0.4336688350642507
||w||^2 0.306094855217421
exp ma of ||w||^2 0.1840505462075633
||w|| 0.5532583982348763
exp ma of ||w|| 0.4073768591639476
||w||^2 0.40132818786458857
exp ma of ||w||^2 0.18791092346150126
||w|| 0.6335046865371942
exp ma of ||w|| 0.411235109347957
||w||^2 0.4826728694015071
exp ma of ||w||^2 0.2139398058226768
||w|| 0.6947466224469948
exp ma of ||w|| 0.4310463180781132
cuda
Objective function 8.88 = squared loss an data 8.13 + 0.5*rho*h**2 0.123481 + alpha*h 0.135450 + L2reg 0.44 + L1reg 0.05 ; SHD = 14 ; DAG True
Proportion of microbatches that were clipped  0.7658865529551765
iteration 2 in inner loop, alpha 8.619169764063244 rho 1000.0 h 0.01571501278633569
iteration 3 in outer loop, alpha = 24.334182550398936, rho = 1000.0, h = 0.01571501278633569
cuda
1210
cuda
Objective function 9.13 = squared loss an data 8.13 + 0.5*rho*h**2 0.123481 + alpha*h 0.382412 + L2reg 0.44 + L1reg 0.05 ; SHD = 14 ; DAG True
||w||^2 0.18465054064501488
exp ma of ||w||^2 25299.280693475008
||w|| 0.4297098330792709
exp ma of ||w|| 1.9075627084106161
||w||^2 0.048746099461031256
exp ma of ||w||^2 0.17987989774950727
||w|| 0.22078518850011486
exp ma of ||w|| 0.39290028548715034
||w||^2 0.23953360279546135
exp ma of ||w||^2 0.23711726157559512
||w|| 0.4894217024156789
exp ma of ||w|| 0.4528569739542287
||w||^2 0.15314043475997338
exp ma of ||w||^2 0.19542094233068455
||w|| 0.3913316173783731
exp ma of ||w|| 0.4175928095329099
||w||^2 0.1637755040300824
exp ma of ||w||^2 0.2178904080151699
||w|| 0.4046918630638407
exp ma of ||w|| 0.4333232047800143
||w||^2 0.1190776567520057
exp ma of ||w||^2 0.20344886115344496
||w|| 0.3450763056948502
exp ma of ||w|| 0.41551233634370943
||w||^2 0.06278468140678907
exp ma of ||w||^2 0.21123111493257565
||w|| 0.250568715937942
exp ma of ||w|| 0.4265394548972791
||w||^2 0.12876616423441906
exp ma of ||w||^2 0.2256555793218358
||w|| 0.358840025964801
exp ma of ||w|| 0.445115695452535
||w||^2 0.23662770289570925
exp ma of ||w||^2 0.20526711084733412
||w|| 0.48644393602522096
exp ma of ||w|| 0.4270715859280665
||w||^2 0.13094258087963084
exp ma of ||w||^2 0.1952510011649591
||w|| 0.3618598912281255
exp ma of ||w|| 0.4127216780045115
cuda
Objective function 9.11 = squared loss an data 8.26 + 0.5*rho*h**2 0.066936 + alpha*h 0.281554 + L2reg 0.45 + L1reg 0.05 ; SHD = 16 ; DAG True
Proportion of microbatches that were clipped  0.7644950621216948
iteration 1 in inner loop, alpha 24.334182550398936 rho 1000.0 h 0.01157028949434391
1210
cuda
Objective function 9.71 = squared loss an data 8.26 + 0.5*rho*h**2 0.669358 + alpha*h 0.281554 + L2reg 0.45 + L1reg 0.05 ; SHD = 16 ; DAG True
||w||^2 2022107286.8459375
exp ma of ||w||^2 10229547841.035265
||w|| 44967.84725607773
exp ma of ||w|| 74507.61362785581
||w||^2 1022362.7237708997
exp ma of ||w||^2 382010177.92248404
||w|| 1011.1195398027376
exp ma of ||w|| 7307.721590093566
||w||^2 0.11771094788004538
exp ma of ||w||^2 0.177481091553943
||w|| 0.34309029114803785
exp ma of ||w|| 0.3507318949952186
||w||^2 0.1598018856061173
exp ma of ||w||^2 0.17001630771211165
||w|| 0.39975228030133525
exp ma of ||w|| 0.38484936774232403
||w||^2 0.09971986050912242
exp ma of ||w||^2 0.17255034320768187
||w|| 0.315784515942632
exp ma of ||w|| 0.3901651161371782
||w||^2 0.11123445610263309
exp ma of ||w||^2 0.17653708452767772
||w|| 0.33351829950189105
exp ma of ||w|| 0.3937289048800329
||w||^2 0.5855092477675448
exp ma of ||w||^2 0.17272457702309207
||w|| 0.7651857603010819
exp ma of ||w|| 0.3893215488569195
||w||^2 0.12442709081327256
exp ma of ||w||^2 0.22448257907535119
||w|| 0.35274224415750455
exp ma of ||w|| 0.4473821069914054
||w||^2 0.10058655805994193
exp ma of ||w||^2 0.20486887306630266
||w|| 0.3171538397370304
exp ma of ||w|| 0.4231395358993118
||w||^2 0.11422142191316802
exp ma of ||w||^2 0.19825307104212617
||w|| 0.3379665988129123
exp ma of ||w|| 0.41688806633648007
||w||^2 0.20107278478553345
exp ma of ||w||^2 0.2227473180721838
||w|| 0.4484114012662183
exp ma of ||w|| 0.44172239445090833
||w||^2 0.09598171913344263
exp ma of ||w||^2 0.184366129340513
||w|| 0.309809165670486
exp ma of ||w|| 0.4066985152187459
||w||^2 0.04305450219673291
exp ma of ||w||^2 0.18440430494804574
||w|| 0.20749578838312094
exp ma of ||w|| 0.3996137324225166
cuda
Objective function 9.12 = squared loss an data 8.44 + 0.5*rho*h**2 0.080331 + alpha*h 0.097538 + L2reg 0.46 + L1reg 0.05 ; SHD = 13 ; DAG True
Proportion of microbatches that were clipped  0.7607449856733525
iteration 2 in inner loop, alpha 24.334182550398936 rho 10000.0 h 0.004008268856873443
1210
cuda
Objective function 9.85 = squared loss an data 8.44 + 0.5*rho*h**2 0.803311 + alpha*h 0.097538 + L2reg 0.46 + L1reg 0.05 ; SHD = 13 ; DAG True
||w||^2 25549733.358003866
exp ma of ||w||^2 55315183478.11204
||w|| 5054.67440672531
exp ma of ||w|| 64665.53478439923
||w||^2 4936559.751896721
exp ma of ||w||^2 17072816348.11004
||w|| 2221.837021902534
exp ma of ||w|| 21737.73263254957
||w||^2 6.226383594809203
exp ma of ||w||^2 57213128.10663922
||w|| 2.4952722486352474
exp ma of ||w|| 86.0893467763909
||w||^2 0.47735373360503613
exp ma of ||w||^2 534394.4371998361
||w|| 0.690907905299278
exp ma of ||w|| 1.7185963380460896
||w||^2 0.20181800241616846
exp ma of ||w||^2 5745.833966874685
||w|| 0.4492415858045295
exp ma of ||w|| 0.500594795254163
||w||^2 0.1000211324158711
exp ma of ||w||^2 116.51052048159926
||w|| 0.3162611775350732
exp ma of ||w|| 0.38320398249835136
||w||^2 0.08204916254926697
exp ma of ||w||^2 25.63935146686748
||w|| 0.28644224993751705
exp ma of ||w|| 0.3507731704557645
||w||^2 0.055068063283290475
exp ma of ||w||^2 0.14671363982005536
||w|| 0.2346658545321208
exp ma of ||w|| 0.34524862052348854
||w||^2 0.0810160241512114
exp ma of ||w||^2 0.13776749807265193
||w|| 0.28463313958710323
exp ma of ||w|| 0.3512261529327103
||w||^2 0.1369519171633533
exp ma of ||w||^2 0.1503321358535865
||w|| 0.37007015167850715
exp ma of ||w|| 0.3640404625218414
||w||^2 0.06202994042614809
exp ma of ||w||^2 0.18978688742932504
||w|| 0.24905810652566218
exp ma of ||w|| 0.4103144597276048
||w||^2 0.31615979305817493
exp ma of ||w||^2 0.1849337618258164
||w|| 0.5622808844858368
exp ma of ||w|| 0.4051268673876156
||w||^2 0.07882210468705403
exp ma of ||w||^2 0.22190244066154277
||w|| 0.2807527465351925
exp ma of ||w|| 0.43917400993353295
||w||^2 0.3321974985428364
exp ma of ||w||^2 0.2217524454801361
||w|| 0.5763657680178763
exp ma of ||w|| 0.43566188618969653
||w||^2 0.2883863581593498
exp ma of ||w||^2 0.20975967100853218
||w|| 0.5370161619163336
exp ma of ||w|| 0.42879919310205117
||w||^2 0.37244353563987026
exp ma of ||w||^2 0.2211510899735748
||w|| 0.6102815216274128
exp ma of ||w|| 0.4392658059593544
||w||^2 0.2226595277289242
exp ma of ||w||^2 0.190856558217208
||w|| 0.47186812535805406
exp ma of ||w|| 0.41377595097210024
||w||^2 0.20354320041047017
exp ma of ||w||^2 0.17904177247082656
||w|| 0.45115762257826275
exp ma of ||w|| 0.4014921211734957
cuda
Objective function 9.09 = squared loss an data 8.44 + 0.5*rho*h**2 0.085001 + alpha*h 0.031728 + L2reg 0.48 + L1reg 0.05 ; SHD = 14 ; DAG True
Proportion of microbatches that were clipped  0.7616796217645645
iteration 3 in inner loop, alpha 24.334182550398936 rho 100000.0 h 0.0013038444999295962
iteration 4 in outer loop, alpha = 154.71863254335855, rho = 100000.0, h = 0.0013038444999295962
cuda
1210
cuda
Objective function 9.26 = squared loss an data 8.44 + 0.5*rho*h**2 0.085001 + alpha*h 0.201729 + L2reg 0.48 + L1reg 0.05 ; SHD = 14 ; DAG True
||w||^2 13028519332908.113
exp ma of ||w||^2 3783787033617.988
||w|| 3609504.028659355
exp ma of ||w|| 1090647.927722622
||w||^2 961987.9908223975
exp ma of ||w||^2 76757706887.146
||w|| 980.8098647660502
exp ma of ||w|| 33918.30151560234
||w||^2 22.673194930432693
exp ma of ||w||^2 1197011510.6980474
||w|| 4.7616378411669125
exp ma of ||w|| 573.903664921543
||w||^2 0.09161268841151779
exp ma of ||w||^2 0.1457849275109183
||w|| 0.3026758801284268
exp ma of ||w|| 0.3628918691350153
||w||^2 0.31255462978907134
exp ma of ||w||^2 0.16368666484933883
||w|| 0.5590658546084454
exp ma of ||w|| 0.3830297747385623
||w||^2 0.10344343715201339
exp ma of ||w||^2 0.16435654107035624
||w|| 0.32162623828290715
exp ma of ||w|| 0.38742947262973276
||w||^2 0.41084030762288726
exp ma of ||w||^2 0.16920193551471913
||w|| 0.6409682578902697
exp ma of ||w|| 0.38723678630073394
||w||^2 0.06257029127001891
exp ma of ||w||^2 0.16019503539917718
||w|| 0.2501405430353483
exp ma of ||w|| 0.37979704247879553
||w||^2 0.16260637475900708
exp ma of ||w||^2 0.1660589459370027
||w|| 0.4032448074792868
exp ma of ||w|| 0.3867228767561367
||w||^2 0.07029440998856934
exp ma of ||w||^2 0.18899630364743578
||w|| 0.2651309298979833
exp ma of ||w|| 0.41697751059044147
||w||^2 0.05364494396941784
exp ma of ||w||^2 0.16857957893114114
||w|| 0.23161378190733348
exp ma of ||w|| 0.38999975214874116
||w||^2 0.06868793649595746
exp ma of ||w||^2 0.18816125430698705
||w|| 0.2620838348619721
exp ma of ||w|| 0.41142314574048716
||w||^2 0.18620183000724788
exp ma of ||w||^2 0.17553831696761588
||w|| 0.43151110067673565
exp ma of ||w|| 0.3993209943696233
||w||^2 0.23723364397860308
exp ma of ||w||^2 0.16724923904319058
||w|| 0.48706636506599704
exp ma of ||w|| 0.39231568638374287
||w||^2 0.06778819614586923
exp ma of ||w||^2 0.1759137190764662
||w|| 0.2603616641248654
exp ma of ||w|| 0.40105991292016707
cuda
Objective function 9.20 = squared loss an data 8.46 + 0.5*rho*h**2 0.058597 + alpha*h 0.167493 + L2reg 0.47 + L1reg 0.05 ; SHD = 13 ; DAG True
Proportion of microbatches that were clipped  0.7625933959990359
iteration 1 in inner loop, alpha 154.71863254335855 rho 100000.0 h 0.0010825648747356809
iteration 5 in outer loop, alpha = 1237.2835072790394, rho = 1000000.0, h = 0.0010825648747356809
Threshold 0.3
[[0.003 0.021 0.239 0.003 0.269 0.03  0.129 0.008 0.015 0.95 ]
 [0.338 0.005 0.435 0.007 0.263 0.275 0.526 0.015 0.003 0.264]
 [0.028 0.011 0.003 0.003 0.116 0.007 0.493 0.009 0.007 0.195]
 [1.011 0.535 0.747 0.002 0.293 1.57  0.533 0.009 0.042 0.389]
 [0.012 0.013 0.022 0.012 0.005 0.026 0.012 0.01  0.004 0.461]
 [0.162 0.03  0.55  0.002 0.117 0.005 0.481 0.006 0.007 0.173]
 [0.038 0.009 0.009 0.005 0.332 0.007 0.004 0.008 0.007 0.186]
 [0.336 0.273 0.274 0.337 0.309 0.759 0.455 0.004 0.049 0.633]
 [0.202 1.219 0.513 0.111 0.712 0.563 0.455 0.137 0.003 0.393]
 [0.006 0.021 0.024 0.006 0.006 0.023 0.038 0.005 0.009 0.004]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.95 ]
 [0.338 0.    0.435 0.    0.    0.    0.526 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.493 0.    0.    0.   ]
 [1.011 0.535 0.747 0.    0.    1.57  0.533 0.    0.    0.389]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.461]
 [0.    0.    0.55  0.    0.    0.    0.481 0.    0.    0.   ]
 [0.    0.    0.    0.    0.332 0.    0.    0.    0.    0.   ]
 [0.336 0.    0.    0.337 0.309 0.759 0.455 0.    0.    0.633]
 [0.    1.219 0.513 0.    0.712 0.563 0.455 0.    0.    0.393]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]]
{'fdr': 0.4074074074074074, 'tpr': 0.8, 'fpr': 0.44, 'f1': 0.6808510638297872, 'shd': 13, 'npred': 27, 'ntrue': 20}
[0.021 0.239 0.003 0.269 0.03  0.129 0.008 0.015 0.95  0.338 0.435 0.007
 0.263 0.275 0.526 0.015 0.003 0.264 0.028 0.011 0.003 0.116 0.007 0.493
 0.009 0.007 0.195 1.011 0.535 0.747 0.293 1.57  0.533 0.009 0.042 0.389
 0.012 0.013 0.022 0.012 0.026 0.012 0.01  0.004 0.461 0.162 0.03  0.55
 0.002 0.117 0.481 0.006 0.007 0.173 0.038 0.009 0.009 0.005 0.332 0.007
 0.008 0.007 0.186 0.336 0.273 0.274 0.337 0.309 0.759 0.455 0.049 0.633
 0.202 1.219 0.513 0.111 0.712 0.563 0.455 0.137 0.393 0.006 0.021 0.024
 0.006 0.006 0.023 0.038 0.005 0.009]
[[0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 1. 1. 0. 0. 1. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.8685714285714285, 0.758129676784568)
Iterations 2500
Achieves (3.6993101023104464, 1e-05)-DP
