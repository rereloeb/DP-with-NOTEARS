samples  5000  graph  10 30 ER mlp  minibatch size  100  noise  0.6  minibatches per NN training  63 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.1229782946562032
iteration 1 in outer loop, alpha = 1.1229782946562032, rho = 1.0, h = 1.1229782946562032
cuda
iteration 1 in inner loop,alpha 1.1229782946562032 rho 1.0 h 0.7586153562268656
iteration 2 in inner loop,alpha 1.1229782946562032 rho 10.0 h 0.35052850700977345
iteration 3 in inner loop,alpha 1.1229782946562032 rho 100.0 h 0.11468940960946838
iteration 2 in outer loop, alpha = 12.591919255603042, rho = 100.0, h = 0.11468940960946838
cuda
iteration 1 in inner loop,alpha 12.591919255603042 rho 100.0 h 0.05177271318199317
iteration 2 in inner loop,alpha 12.591919255603042 rho 1000.0 h 0.015651355822457802
iteration 3 in outer loop, alpha = 28.243275078060844, rho = 1000.0, h = 0.015651355822457802
cuda
iteration 1 in inner loop,alpha 28.243275078060844 rho 1000.0 h 0.0076855114245848455
iteration 2 in inner loop,alpha 28.243275078060844 rho 10000.0 h 0.0014289170876846669
iteration 4 in outer loop, alpha = 42.532445954907516, rho = 10000.0, h = 0.0014289170876846669
cuda
iteration 1 in inner loop,alpha 42.532445954907516 rho 10000.0 h 0.0007810909223238127
iteration 2 in inner loop,alpha 42.532445954907516 rho 100000.0 h 0.0003082940036058801
iteration 5 in outer loop, alpha = 73.36184631549553, rho = 100000.0, h = 0.0003082940036058801
cuda
iteration 1 in inner loop,alpha 73.36184631549553 rho 100000.0 h 0.00018124117908691062
iteration 6 in outer loop, alpha = 254.60302540240616, rho = 1000000.0, h = 0.00018124117908691062
Threshold 0.3
[[0.004 0.    0.369 0.    1.151 0.    1.809 0.    0.001 0.006]
 [2.233 0.002 1.486 0.    0.875 0.014 0.114 0.102 0.011 2.624]
 [0.003 0.    0.007 0.    2.009 0.    1.925 0.    0.001 0.   ]
 [1.278 0.408 1.447 0.    0.834 0.431 1.184 0.249 2.716 2.815]
 [0.    0.    0.    0.    0.004 0.    0.    0.    0.    0.   ]
 [0.189 0.031 0.189 0.    0.255 0.001 0.317 0.006 0.011 2.98 ]
 [0.    0.    0.001 0.    1.626 0.    0.004 0.    0.    0.   ]
 [1.799 0.01  1.353 0.    1.751 0.103 0.279 0.002 0.    0.102]
 [2.33  0.042 2.302 0.    0.919 0.065 0.592 0.208 0.004 0.316]
 [0.182 0.    2.474 0.    1.744 0.    2.587 0.003 0.004 0.006]]
[[0.    0.    0.369 0.    1.151 0.    1.809 0.    0.    0.   ]
 [2.233 0.    1.486 0.    0.875 0.    0.    0.    0.    2.624]
 [0.    0.    0.    0.    2.009 0.    1.925 0.    0.    0.   ]
 [1.278 0.408 1.447 0.    0.834 0.431 1.184 0.    2.716 2.815]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.317 0.    0.    2.98 ]
 [0.    0.    0.    0.    1.626 0.    0.    0.    0.    0.   ]
 [1.799 0.    1.353 0.    1.751 0.    0.    0.    0.    0.   ]
 [2.33  0.    2.302 0.    0.919 0.    0.592 0.    0.    0.316]
 [0.    0.    2.474 0.    1.744 0.    2.587 0.    0.    0.   ]]
{'fdr': 0.12903225806451613, 'tpr': 0.9, 'fpr': 0.26666666666666666, 'f1': 0.8852459016393444, 'shd': 7, 'npred': 31, 'ntrue': 30}
[1.665e-04 3.691e-01 4.552e-05 1.151e+00 4.090e-04 1.809e+00 3.183e-04
 6.236e-04 6.330e-03 2.233e+00 1.486e+00 2.999e-04 8.754e-01 1.374e-02
 1.144e-01 1.018e-01 1.136e-02 2.624e+00 2.553e-03 4.792e-05 6.703e-06
 2.009e+00 1.796e-05 1.925e+00 4.488e-04 9.903e-04 3.584e-04 1.278e+00
 4.076e-01 1.447e+00 8.345e-01 4.314e-01 1.184e+00 2.487e-01 2.716e+00
 2.815e+00 1.070e-04 5.629e-06 1.077e-04 8.947e-06 4.270e-06 4.555e-04
 6.969e-05 7.054e-05 1.792e-05 1.886e-01 3.105e-02 1.885e-01 3.516e-04
 2.552e-01 3.174e-01 6.113e-03 1.131e-02 2.980e+00 2.187e-04 3.839e-05
 5.929e-04 1.143e-05 1.626e+00 2.956e-05 6.761e-05 1.257e-05 3.306e-04
 1.799e+00 9.932e-03 1.353e+00 4.005e-04 1.751e+00 1.031e-01 2.787e-01
 4.752e-04 1.018e-01 2.330e+00 4.170e-02 2.302e+00 1.215e-04 9.191e-01
 6.494e-02 5.915e-01 2.079e-01 3.161e-01 1.818e-01 2.387e-04 2.474e+00
 1.239e-04 1.744e+00 2.038e-04 2.587e+00 2.722e-03 3.747e-03]
[[0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [1. 0. 1. 0. 1. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [1. 1. 1. 0. 1. 1. 0. 0. 0. 0.]
 [1. 0. 1. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 1. 0. 1. 0. 0. 0.]]
[0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0.
 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.]
aucroc, aucpr (0.9788888888888889, 0.969600766232419)
cuda
1210
cuda
Objective function 461.65 = squared loss an data 284.59 + 0.5*rho*h**2 176.710652 + alpha*h 0.000000 + L2reg 0.19 + L1reg 0.16 ; SHD = 55 ; DAG False
||w||^2 0.8047434274883245
exp ma of ||w||^2 515.6954140278359
||w|| 0.8970749285808429
exp ma of ||w|| 0.7615676630358268
||w||^2 0.1271430284733843
exp ma of ||w||^2 0.41012557722424725
||w|| 0.35657121094303773
exp ma of ||w|| 0.6161338873764136
||w||^2 0.28150130040952015
exp ma of ||w||^2 0.2874930704642226
||w|| 0.5305669612871877
exp ma of ||w|| 0.5158073018465262
cuda
Objective function 63.20 = squared loss an data 62.28 + 0.5*rho*h**2 0.628145 + alpha*h 0.000000 + L2reg 0.21 + L1reg 0.08 ; SHD = 33 ; DAG False
Proportion of microbatches that were clipped  0.7366915620530748
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 1.1208435078593446
iteration 1 in outer loop, alpha = 1.1208435078593446, rho = 1.0, h = 1.1208435078593446
cuda
1210
cuda
Objective function 64.46 = squared loss an data 62.28 + 0.5*rho*h**2 0.628145 + alpha*h 1.256290 + L2reg 0.21 + L1reg 0.08 ; SHD = 33 ; DAG False
||w||^2 0.510239596888842
exp ma of ||w||^2 5.539568836370356
||w|| 0.7143105745324243
exp ma of ||w|| 0.8951099977707798
||w||^2 1.2866342438367546
exp ma of ||w||^2 0.4600595888466208
||w|| 1.1342990098897003
exp ma of ||w|| 0.6346716990292669
||w||^2 0.9724785657758832
exp ma of ||w||^2 0.8643223442187989
||w|| 0.9861432785228945
exp ma of ||w|| 0.8785408304250437
||w||^2 0.5781762680917678
exp ma of ||w||^2 0.7402848032884004
||w|| 0.7603790292293494
exp ma of ||w|| 0.8193631098867222
||w||^2 0.3153291667616666
exp ma of ||w||^2 0.7535329609951714
||w|| 0.5615417765061355
exp ma of ||w|| 0.8276759516215851
cuda
Objective function 15.89 = squared loss an data 13.92 + 0.5*rho*h**2 0.436080 + alpha*h 1.046750 + L2reg 0.41 + L1reg 0.08 ; SHD = 30 ; DAG False
Proportion of microbatches that were clipped  0.7534446425676771
iteration 1 in inner loop, alpha 1.1208435078593446 rho 1.0 h 0.9338946061171569
1210
cuda
Objective function 19.81 = squared loss an data 13.92 + 0.5*rho*h**2 4.360796 + alpha*h 1.046750 + L2reg 0.41 + L1reg 0.08 ; SHD = 30 ; DAG False
||w||^2 793651067.3705802
exp ma of ||w||^2 2370973237.013502
||w|| 28171.81334899442
exp ma of ||w|| 42098.96952119053
||w||^2 206485981.37677515
exp ma of ||w||^2 340745305.62280214
||w|| 14369.620084636028
exp ma of ||w|| 15863.786267128999
||w||^2 346.60993038973567
exp ma of ||w||^2 51844.44793436806
||w|| 18.617463049237823
exp ma of ||w|| 71.94022012379565
||w||^2 0.7316007568852023
exp ma of ||w||^2 14.863393281246937
||w|| 0.8553366336625612
exp ma of ||w|| 1.1278251633748064
||w||^2 1.153163947572745
exp ma of ||w||^2 1.010066708237645
||w|| 1.0738547143691017
exp ma of ||w|| 0.9599152762627645
||w||^2 1.4350663027531447
exp ma of ||w||^2 0.9341378571280791
||w|| 1.1979425289859045
exp ma of ||w|| 0.9144572527027586
||w||^2 1.1227643525277162
exp ma of ||w||^2 1.0892708358191001
||w|| 1.0596057533477798
exp ma of ||w|| 0.9823160395533669
||w||^2 0.3656890182784137
exp ma of ||w||^2 1.1675307297817163
||w|| 0.6047222654065366
exp ma of ||w|| 1.0081007092149328
||w||^2 0.17694152008849637
exp ma of ||w||^2 1.0629540534490345
||w|| 0.4206441727737309
exp ma of ||w|| 0.9668046238271183
||w||^2 1.6904898877046313
exp ma of ||w||^2 1.2551739828480108
||w|| 1.3001884046955008
exp ma of ||w|| 1.0453341217493044
cuda
Objective function 11.48 = squared loss an data 9.77 + 0.5*rho*h**2 0.677133 + alpha*h 0.412474 + L2reg 0.56 + L1reg 0.07 ; SHD = 24 ; DAG False
Proportion of microbatches that were clipped  0.7609725292074518
iteration 2 in inner loop, alpha 1.1208435078593446 rho 10.0 h 0.3680034541453736
1210
cuda
Objective function 17.58 = squared loss an data 9.77 + 0.5*rho*h**2 6.771327 + alpha*h 0.412474 + L2reg 0.56 + L1reg 0.07 ; SHD = 24 ; DAG False
||w||^2 12386954363.628717
exp ma of ||w||^2 74698848080.25098
||w|| 111296.69520533265
exp ma of ||w|| 243615.5396260335
||w||^2 433945507.2234853
exp ma of ||w||^2 3325178524.501102
||w|| 20831.358746454473
exp ma of ||w|| 49341.59833552881
||w||^2 46131.23557363596
exp ma of ||w||^2 2094423.0066079781
||w|| 214.7818325036733
exp ma of ||w|| 734.4526119059747
||w||^2 2.2171531795424513
exp ma of ||w||^2 9.589692483444866
||w|| 1.4890108057171552
exp ma of ||w|| 1.505776056399683
||w||^2 4.081570323106423
exp ma of ||w||^2 1.452636672532925
||w|| 2.0202896631687306
exp ma of ||w|| 1.1416391683095686
||w||^2 1.6380668399673672
exp ma of ||w||^2 1.6211781247405452
||w|| 1.2798698527457264
exp ma of ||w|| 1.20920782125963
||w||^2 3.8869231740908954
exp ma of ||w||^2 1.5397713179332926
||w|| 1.9715281317016238
exp ma of ||w|| 1.1704193799792386
cuda
Objective function 11.94 = squared loss an data 10.35 + 0.5*rho*h**2 0.754931 + alpha*h 0.137725 + L2reg 0.64 + L1reg 0.06 ; SHD = 17 ; DAG True
Proportion of microbatches that were clipped  0.7707620528771384
iteration 3 in inner loop, alpha 1.1208435078593446 rho 100.0 h 0.1228764147519179
iteration 2 in outer loop, alpha = 13.408484983051135, rho = 100.0, h = 0.1228764147519179
cuda
1210
cuda
Objective function 13.45 = squared loss an data 10.35 + 0.5*rho*h**2 0.754931 + alpha*h 1.647587 + L2reg 0.64 + L1reg 0.06 ; SHD = 17 ; DAG True
||w||^2 18726095575.086063
exp ma of ||w||^2 27263933642.51383
||w|| 136843.3249197273
exp ma of ||w|| 145473.55062608005
||w||^2 866460661.9913554
exp ma of ||w||^2 4438176839.710706
||w|| 29435.703864377956
exp ma of ||w|| 56938.56499153161
||w||^2 1053567781.4889854
exp ma of ||w||^2 3162268775.0875826
||w|| 32458.70886971608
exp ma of ||w|| 47702.09238131137
||w||^2 70872035.66373767
exp ma of ||w||^2 384715584.5476495
||w|| 8418.553062358023
exp ma of ||w|| 14453.235413934395
||w||^2 4.392696492137488
exp ma of ||w||^2 16.276633064202752
||w|| 2.0958760679337622
exp ma of ||w|| 1.6554282283541732
v before min max tensor([[-1.938e+01, -1.547e+01, -8.984e+00,  2.527e+00,  2.476e+00, -8.741e+00,
         -1.601e+01, -1.293e+01, -1.077e+01, -1.613e+01],
        [ 5.757e+01, -8.251e+00, -1.711e+01, -4.817e+00, -1.395e+01,  1.804e+01,
          5.170e+00, -1.846e+01, -5.324e+00, -8.883e+00],
        [-1.083e+01, -1.538e+01, -9.790e+00, -1.021e+01,  7.104e+00, -1.361e+01,
         -1.265e+01, -7.062e+00, -7.600e+00,  7.150e+00],
        [-1.899e+01, -5.023e-01, -9.366e+00, -6.808e-01, -1.611e+01, -1.938e+01,
          3.241e+01,  7.915e+00, -7.523e+00,  7.165e+00],
        [ 2.228e+01,  8.513e+01, -6.028e+00, -1.068e+01,  5.144e+00,  2.101e+01,
         -1.201e+01, -9.552e+00, -5.617e+00, -5.683e+00],
        [ 1.670e+01,  9.621e+01, -1.464e+01, -1.395e+01, -1.195e+01,  1.090e+01,
         -7.353e+00, -5.579e+00,  8.310e+00,  1.690e+01],
        [ 1.945e+01, -2.185e+00,  4.936e+01, -6.956e+00, -2.975e+00, -1.577e+01,
         -1.560e+01,  2.500e+00, -9.782e+00,  9.325e+00],
        [-1.823e+01, -1.208e+01, -3.259e+00, -1.873e+00,  1.903e+01,  1.335e+01,
          5.823e+00, -1.026e+01, -1.023e+01, -1.010e+01],
        [ 3.803e+01,  5.833e+00, -8.758e+00, -1.663e+01,  2.805e+01, -5.737e+00,
         -4.631e-01, -1.144e+01, -1.075e+01,  3.498e+00],
        [-1.956e+01,  3.307e+01, -1.531e+01, -1.030e+01, -1.300e+01, -8.983e+00,
         -1.133e+01, -1.633e+01,  3.620e+01, -1.643e+01],
        [-1.939e+01, -1.176e+01, -1.840e+00, -1.321e+01,  4.440e+00, -6.686e+00,
         -1.732e+00, -1.632e+01, -6.467e+00, -1.750e+01],
        [-1.250e+01, -1.706e+01, -3.553e+00,  2.281e+01,  5.143e+01, -1.078e+01,
         -1.014e+01, -1.145e+00, -1.205e-01, -5.781e+00],
        [-3.260e+00, -1.610e+00, -6.888e+00, -7.825e-01, -1.237e+01, -1.257e+01,
         -9.211e+00, -7.105e+00, -1.109e+01, -7.804e+00],
        [ 8.984e-01, -1.407e+01, -6.038e+00, -1.196e+01,  5.139e+01, -2.253e+00,
         -5.262e+00,  2.068e+01, -1.173e+01, -1.005e+01],
        [ 1.123e+01,  7.538e+01,  2.572e+01,  1.171e+01, -4.028e+00, -9.415e+00,
         -1.580e+01, -4.867e+00, -7.876e+00,  1.433e+01],
        [ 3.487e+01,  4.366e+01, -7.754e+00,  1.953e+01,  5.510e+01,  3.936e+00,
         -9.957e+00, -8.786e+00, -1.537e+01, -1.705e+01],
        [ 2.265e+01,  3.655e+01,  6.407e+01, -7.638e+00, -9.175e+00,  1.732e+01,
          3.170e+01,  1.884e+01,  4.915e-01,  1.787e+01],
        [-1.816e+00, -7.252e+00, -5.898e+00, -6.507e+00,  1.839e+01, -1.427e+01,
         -1.606e+01,  8.579e+00, -4.520e+00, -1.180e+01],
        [-2.498e+00,  2.202e+01, -1.462e+01, -1.349e+00,  4.796e+01, -6.465e+00,
         -1.686e+01, -9.278e+00,  3.076e+01,  1.922e+01],
        [ 1.581e+01, -1.584e+01, -1.230e+01,  6.284e+01,  1.495e-01, -1.162e+00,
         -1.136e+01, -5.790e+00, -5.205e-01, -1.366e+01],
        [ 1.509e+02, -1.778e+00, -1.311e+01, -1.301e+00,  1.428e+01, -1.551e+01,
          6.945e+01, -8.381e+00, -8.897e+00, -1.311e+01],
        [ 8.980e+00, -3.005e+00,  5.190e+00, -9.034e+00,  1.047e+02, -9.166e+00,
         -1.535e+01, -4.725e+00, -7.773e+00,  9.563e+01],
        [-1.074e+01,  1.094e+01,  1.560e+01,  3.095e+01, -1.543e+01, -9.139e+00,
         -1.448e+01,  3.452e+01, -9.003e+00, -8.599e+00],
        [ 6.003e+01,  3.330e+01,  1.389e+02,  8.600e+00, -4.159e-01,  2.242e+01,
         -1.474e+01, -1.027e+01, -2.898e+00,  4.241e+00],
        [ 7.328e+00, -1.330e+01,  4.342e+01,  4.913e+00, -3.840e+00,  2.851e+00,
         -3.934e+00, -1.219e+01, -8.440e+00, -1.327e+01],
        [ 2.469e+02, -1.333e+01, -9.175e+00,  2.494e+01,  2.298e+01,  9.943e+00,
          7.464e+01,  1.147e-01, -8.002e-01, -1.585e+01],
        [ 1.503e+02, -4.657e+00, -2.351e-01, -1.488e+01,  1.127e+02, -6.978e+00,
          6.448e+00,  1.117e+01, -6.224e+00, -1.540e+01],
        [ 8.123e+00,  6.502e-02,  1.012e+02, -3.064e+00,  1.724e+01, -9.686e+00,
         -1.444e+01,  2.563e+00, -1.573e+01, -8.445e+00],
        [ 3.421e+01, -3.782e-01, -1.388e+01, -7.933e+00, -1.794e+01, -1.810e+01,
         -1.900e+01, -9.638e+00, -2.935e+00, -1.771e+01],
        [-1.058e+01, -1.150e+01,  7.393e+01,  4.678e+01, -1.795e+01, -1.126e+01,
          5.216e+01, -1.154e+01, -4.333e+00, -1.262e+01],
        [ 7.718e+00, -1.098e+01, -6.435e+00,  9.699e+01,  9.244e+00, -6.918e+00,
         -1.131e+00,  6.344e+01, -2.762e+00, -6.742e+00],
        [ 2.327e+01, -7.491e+00,  2.483e+01,  3.143e-02,  4.973e+01,  2.634e+01,
          2.090e+02,  1.864e+01, -1.777e+00, -1.359e+01],
        [-1.156e+01,  2.550e+01, -5.452e+00,  3.370e+00, -1.042e+01, -1.406e+01,
         -1.321e+01,  1.319e+00,  2.430e+00, -9.639e+00],
        [-1.602e+01, -1.185e+01, -9.773e+00,  4.031e+00, -9.093e+00,  7.930e+01,
          3.912e+01, -9.422e+00, -1.091e+00, -4.631e+00],
        [-1.166e+01, -1.002e+01,  1.136e+01,  5.932e-01,  1.456e+01,  1.018e+01,
          5.495e-01,  2.629e+01,  3.636e+00, -9.237e+00],
        [-7.954e+00,  9.612e+00,  5.516e+00, -4.792e+00,  2.234e+02, -4.803e+00,
         -3.457e+00,  7.002e+00, -7.347e+00, -2.106e+00],
        [-1.741e+00,  5.395e+01,  7.761e+01,  1.668e-01, -5.514e+00,  5.272e+01,
          4.090e+01,  1.188e+01,  1.361e+01,  1.620e+01],
        [ 1.947e+01, -1.738e+01,  5.739e+00,  1.712e+00, -1.129e+01, -1.124e+01,
          7.591e+00, -1.717e+01,  3.086e+01,  1.707e+01],
        [-1.435e+01,  2.627e+01,  2.018e+01,  5.016e+01,  1.642e+00, -1.523e+01,
         -1.867e+01, -1.158e+01, -5.924e+00, -8.572e+00],
        [-1.529e+01,  2.695e+01,  8.081e+01, -1.304e+01,  1.707e+01, -9.762e+00,
         -1.128e+01, -1.424e+01, -3.570e+00, -1.854e+01],
        [ 4.232e+01, -6.794e+00, -1.207e+01, -4.675e+00,  6.664e+01,  5.434e+01,
         -1.331e+01, -5.396e+00, -1.005e+01,  8.614e+00],
        [ 3.041e+02,  5.615e+00,  3.680e+01,  3.136e+01,  1.733e+02, -1.848e+01,
          7.591e+01,  2.709e+01, -1.246e+01, -1.572e+00],
        [ 3.452e+01,  9.627e+00, -1.267e+01, -5.214e+00,  2.396e+01, -1.165e+01,
         -6.229e+00, -1.086e+01, -7.885e+00,  3.379e+00],
        [-1.303e+01, -1.506e+01,  1.725e+01, -1.471e+01, -9.184e+00,  4.131e+01,
          8.842e+00,  9.094e+00, -1.041e+01,  1.835e+01],
        [ 1.279e+01, -6.137e+00,  2.337e+01,  1.796e+01, -1.454e+01, -2.975e+00,
         -1.454e+01, -9.359e+00, -1.189e+01, -7.243e+00],
        [ 9.544e+00, -1.662e+01, -5.499e+00, -5.450e+00, -7.910e+00, -7.426e+00,
          5.406e+01,  6.906e+01, -7.287e+00, -1.031e+01],
        [ 1.821e+01, -1.116e+01, -9.864e+00, -1.145e+01, -2.507e+00, -1.732e+01,
         -3.522e+00, -4.370e+00,  1.085e+01,  2.468e+01],
        [ 7.364e+01,  1.861e+01,  1.000e+02, -5.019e+00,  1.842e+01,  3.512e+01,
         -8.893e+00,  5.077e+01, -8.572e+00,  4.416e+01],
        [ 1.054e+02,  2.752e+01,  4.807e+01, -1.374e+01,  2.764e+01,  1.308e+01,
          7.339e+00, -1.315e+01, -8.473e+00,  6.053e+01],
        [-1.303e+01,  2.554e+00, -1.046e+01, -5.468e+00, -1.593e+01, -6.826e+00,
          1.255e+01, -3.181e+00, -1.176e+01, -9.737e+00],
        [-1.239e+01, -8.045e+00, -9.375e+00,  2.903e+01, -7.814e-01,  6.698e+00,
         -4.563e+00, -1.252e+01, -6.277e+00, -5.865e+00],
        [ 4.237e+01, -3.890e-02,  7.824e+01,  2.427e+01,  9.087e+01, -1.050e+01,
         -1.094e+01, -1.233e+01, -1.044e+00,  3.798e+01],
        [-1.681e+01,  8.750e+00, -1.464e+01, -1.074e+01, -6.447e+00,  1.798e+00,
         -5.078e+00, -1.260e+01, -1.278e+01, -1.105e+01],
        [-1.086e+01, -4.291e+00,  1.925e+01, -1.261e+01,  4.111e+01,  6.838e+01,
         -1.447e+01,  5.619e+00, -1.123e+01, -1.351e+01],
        [ 2.141e-01,  1.784e+01, -8.683e+00,  6.155e+00,  2.124e+01, -1.069e+01,
         -1.370e+01, -4.507e+00, -3.201e+00, -3.745e+00],
        [-1.304e+01, -1.194e+01,  4.773e+01,  7.697e+00, -7.023e+00,  8.406e+01,
         -1.223e+01, -9.671e+00, -3.569e-01, -9.657e+00],
        [-1.210e+01, -3.298e+00,  2.017e+01, -7.846e+00, -4.915e+00,  5.405e+01,
         -1.599e+01,  4.951e+01, -6.980e+00, -4.929e+00],
        [-1.611e+01, -6.850e+00,  9.480e+01,  1.002e+01,  3.325e+00,  1.899e+01,
          5.247e+00,  9.968e-01, -4.893e+00, -1.568e+00],
        [-1.215e+01,  1.144e+01,  9.397e+00, -2.317e+00,  1.627e+01,  2.374e+01,
         -1.527e+01,  2.049e+01,  7.354e+01, -1.045e+01],
        [-1.151e+01, -4.318e+00, -5.223e+00, -5.292e+00,  2.046e+01, -4.589e+00,
         -5.428e+00,  7.580e+00, -1.681e+01, -1.501e+01],
        [-1.912e+01, -6.704e+00,  2.485e+00, -1.764e+00,  1.407e+01,  8.099e+00,
          1.324e+02, -9.690e+00,  3.586e+01, -1.888e+00],
        [ 1.263e+02, -1.494e+01, -1.349e+01,  9.839e+00, -1.597e+01,  2.057e+01,
          9.538e+01,  2.815e+01, -1.321e+01,  2.186e+01],
        [ 5.919e+01, -1.579e+01, -1.182e+01, -7.049e+00,  6.550e+01, -1.633e+01,
          2.664e+02, -1.546e+01,  2.036e+00,  1.389e+01],
        [ 2.171e+01,  2.322e+01,  3.607e+01,  3.046e+00, -1.219e+01,  7.400e-01,
         -1.775e+01,  2.470e+01,  9.177e-02,  1.674e+01],
        [ 1.426e+00,  1.904e+01, -1.046e+01, -9.383e+00,  1.498e+01, -1.169e+01,
          4.458e+01,  6.128e-02, -1.339e+01,  5.340e+01],
        [ 2.885e+01, -1.479e+01,  1.747e+01, -4.599e+00, -1.777e+01, -1.582e+01,
          2.613e+01,  1.125e+01, -7.807e+00, -1.221e+01],
        [-1.850e+01, -3.423e+00,  5.355e+01,  2.814e+01, -3.225e-03, -1.204e+01,
         -1.932e+01, -1.500e+01, -1.252e+01, -6.127e+00],
        [ 4.808e+00,  3.340e+01,  2.664e+01,  3.210e+01, -1.045e+01, -1.105e+01,
          1.153e+01,  4.822e+01, -1.706e+01,  1.124e+01],
        [-1.383e+01, -5.948e+00, -8.788e+00,  1.091e+01, -1.375e+01,  8.435e+01,
          1.620e+01,  2.126e+01, -1.136e+01, -6.318e+00],
        [ 5.808e+01,  9.173e+00,  2.103e+00, -1.218e+01, -4.831e+00,  8.954e+01,
         -1.842e+00, -7.247e+00, -1.047e+01, -5.339e+00],
        [-9.238e+00,  2.069e+01,  3.322e+00,  3.578e-01, -2.127e+00,  1.166e+01,
          2.241e+00, -8.762e+00, -1.194e+01, -1.116e+01],
        [ 1.302e+00, -8.364e+00,  3.082e+00, -1.370e+01, -1.130e+01,  6.834e+00,
          1.428e+01, -7.652e+00,  3.249e+01, -1.256e+01],
        [-5.665e+00, -9.659e+00,  4.127e+00, -1.402e+01, -1.297e+01, -1.009e+01,
          3.884e+01,  1.469e+01,  2.054e+00, -9.457e+00],
        [-1.643e+01, -1.087e+01, -8.748e+00,  5.349e+00,  1.780e+00,  2.276e+00,
         -1.032e+00,  4.079e+01,  1.055e+01, -1.284e+01],
        [-1.059e+01, -6.457e+00, -1.373e+01, -1.031e+01, -2.716e+00, -5.550e+00,
         -8.168e+00, -1.780e+01, -1.659e+01,  1.152e+01],
        [-1.518e+01, -5.559e+00,  1.407e+01, -5.901e+00,  4.821e+00,  4.710e+00,
          1.624e+01,  2.725e+00, -1.694e+01, -2.819e+00],
        [-4.574e+00, -1.052e+01,  5.665e+00, -6.551e+00,  1.551e+01, -1.199e+01,
          4.034e+00, -5.459e+00,  4.595e+00, -3.205e+00],
        [-1.065e+01, -1.467e+01, -1.507e+01, -9.636e+00, -1.374e+01, -1.251e+01,
          1.092e+01, -1.576e+01, -1.751e+00, -7.263e+00],
        [ 1.077e+01, -1.390e+01, -1.512e+01, -1.096e+01, -1.403e+01,  2.306e+01,
         -3.981e+00, -1.176e+01,  2.209e+01, -9.416e+00],
        [-1.324e+01, -9.981e+00, -5.812e+00,  5.646e+01, -5.819e+00, -9.375e-01,
         -6.895e+00,  8.120e+01,  2.399e+01, -1.327e+01],
        [ 1.437e+01, -9.400e+00, -1.006e+01, -1.181e+01,  1.082e+00,  1.701e+00,
         -1.046e+01, -5.805e+00, -6.488e+00,  9.559e+00],
        [ 2.685e+01,  7.541e+01, -1.797e+01, -1.309e+01, -1.574e+01, -7.197e+00,
         -1.144e+01, -9.638e+00, -1.749e+01,  2.348e+00],
        [ 1.158e+02,  5.652e+01, -5.697e+00,  3.596e+00,  2.559e+01,  9.388e+00,
          1.223e+02,  4.212e+01, -1.259e+01, -2.492e+00],
        [ 1.875e+02, -1.280e+01, -1.298e+01,  1.910e+01,  6.545e+01, -1.414e+01,
         -1.226e+01, -1.656e+01,  7.144e+00, -8.173e+00],
        [ 4.596e+01, -7.356e+00,  5.635e+00,  6.327e+00,  1.450e+01, -1.323e+01,
          3.672e+01,  8.651e+00,  2.847e+00, -5.933e+00],
        [ 4.470e+01,  2.082e+01,  5.197e+00, -5.825e+00, -1.577e+01, -1.132e+01,
         -9.500e+00,  2.303e+01,  2.894e+01,  1.031e+02],
        [ 6.184e+01,  7.249e-02,  2.503e+02, -9.699e+00,  2.534e+01, -9.749e+00,
          5.597e+00,  9.440e+00, -1.629e+01,  4.787e+01],
        [ 1.388e+02,  4.628e+01, -4.867e+00,  2.026e+01,  8.107e+00,  2.560e+01,
         -1.557e+01, -1.134e+01,  2.327e+01,  1.551e+01],
        [ 2.341e+00,  4.291e+01,  1.990e+01, -8.315e+00,  4.843e+00,  6.006e+01,
          3.250e+01,  4.539e+01,  2.354e+01,  2.171e+01],
        [-5.760e+00, -1.466e+01,  2.097e+01, -6.197e+00,  2.232e+01, -7.720e+00,
          1.249e+01, -1.085e+01, -1.314e+01, -1.112e+01],
        [-1.118e+01,  9.972e+00, -1.281e+01, -1.385e+01, -6.983e-01, -1.045e+01,
         -6.325e+00, -9.065e+00, -9.814e+00,  2.672e+01],
        [ 1.905e+01,  4.277e+00,  1.453e+00,  6.065e-01,  4.238e+01,  9.428e+00,
         -1.307e+01, -1.400e+01, -1.355e+01,  2.432e+01],
        [ 1.101e+02, -1.201e+01,  7.677e+01, -9.725e+00, -7.382e+00, -1.840e+01,
          5.577e+00, -1.388e+01,  2.634e+01, -4.647e+00],
        [ 3.545e+01,  1.574e-01, -8.025e+00,  4.186e+00, -1.588e+01, -5.220e+00,
          9.451e+01,  2.217e+01,  2.667e+01,  9.961e+01],
        [-9.950e+00, -1.555e+01,  1.380e+01,  2.237e+01,  1.759e+00, -3.745e+00,
          3.418e+01,  1.494e+01, -7.114e+00, -1.799e+01],
        [ 2.532e+02,  2.177e+02,  3.029e+01, -1.241e+01,  1.970e+01, -8.647e+00,
          1.478e+02,  5.292e+01,  6.317e+00, -1.120e+01],
        [-1.415e+01, -1.232e+00, -1.079e+01,  1.034e+00, -5.644e+00,  1.566e+01,
          2.022e+02,  4.831e+01,  2.797e+00, -7.090e+00],
        [ 1.593e+01,  6.827e+00,  8.319e-01, -1.102e+01,  3.602e+00,  2.295e+01,
         -4.502e+00,  2.143e+01, -6.885e-01, -1.197e+01],
        [ 6.013e+01,  2.357e+01,  4.528e+00, -5.871e+00, -9.824e+00, -1.003e+00,
          3.291e+01, -1.276e+01, -3.006e+00, -4.119e+00],
        [ 1.065e+02, -8.469e+00,  4.809e+01, -2.142e+00, -1.248e+01,  7.821e+01,
          6.184e+01,  6.973e+01, -1.535e+01,  5.648e+01]], device='cuda:0')
v tensor([[1.000e-12, 1.000e-12, 1.000e-12, 2.527e+00, 2.476e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
         5.170e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 7.104e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 7.150e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e+01, 7.915e+00, 1.000e-12, 7.165e+00],
        [1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 5.144e+00, 1.000e+01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
         1.000e-12, 1.000e-12, 8.310e+00, 1.000e+01],
        [1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 2.500e+00, 1.000e-12, 9.325e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
         5.823e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e+01, 5.833e+00, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 3.498e+00],
        [1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 4.440e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [8.984e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 3.936e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
         1.000e+01, 1.000e+01, 4.915e-01, 1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 8.579e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.495e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12],
        [8.980e+00, 1.000e-12, 5.190e+00, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e+01, 8.600e+00, 1.000e-12, 1.000e+01,
         1.000e-12, 1.000e-12, 1.000e-12, 4.241e+00],
        [7.328e+00, 1.000e-12, 1.000e+01, 4.913e+00, 1.000e-12, 2.851e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 9.943e+00,
         1.000e+01, 1.147e-01, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
         6.448e+00, 1.000e+01, 1.000e-12, 1.000e-12],
        [8.123e+00, 6.502e-02, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 2.563e+00, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12],
        [7.718e+00, 1.000e-12, 1.000e-12, 1.000e+01, 9.244e+00, 1.000e-12,
         1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e+01, 3.143e-02, 1.000e+01, 1.000e+01,
         1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12, 3.370e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 1.319e+00, 2.430e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 4.031e+00, 1.000e-12, 1.000e+01,
         1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01, 5.932e-01, 1.000e+01, 1.000e+01,
         5.495e-01, 1.000e+01, 3.636e+00, 1.000e-12],
        [1.000e-12, 9.612e+00, 5.516e+00, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 7.002e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e+01, 1.668e-01, 1.000e-12, 1.000e+01,
         1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01],
        [1.000e+01, 1.000e-12, 5.739e+00, 1.712e+00, 1.000e-12, 1.000e-12,
         7.591e+00, 1.000e-12, 1.000e+01, 1.000e+01],
        [1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.642e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
         1.000e-12, 1.000e-12, 1.000e-12, 8.614e+00],
        [1.000e+01, 5.615e+00, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
         1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e+01, 9.627e+00, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 3.379e+00],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
         8.842e+00, 9.094e+00, 1.000e-12, 1.000e+01],
        [1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [9.544e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01],
        [1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
         1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01],
        [1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
         7.339e+00, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e-12, 2.554e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 6.698e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e-12, 8.750e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.798e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
         1.000e-12, 5.619e+00, 1.000e-12, 1.000e-12],
        [2.141e-01, 1.000e+01, 1.000e-12, 6.155e+00, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01, 7.697e+00, 1.000e-12, 1.000e+01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
         1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 3.325e+00, 1.000e+01,
         5.247e+00, 9.968e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e+01, 9.397e+00, 1.000e-12, 1.000e+01, 1.000e+01,
         1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 7.580e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 2.485e+00, 1.000e-12, 1.000e+01, 8.099e+00,
         1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12, 9.839e+00, 1.000e-12, 1.000e+01,
         1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e+01, 1.000e-12, 2.036e+00, 1.000e+01],
        [1.000e+01, 1.000e+01, 1.000e+01, 3.046e+00, 1.000e-12, 7.400e-01,
         1.000e-12, 1.000e+01, 9.177e-02, 1.000e+01],
        [1.426e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e+01, 6.128e-02, 1.000e-12, 1.000e+01],
        [1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [4.808e+00, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
         1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e+01, 9.173e+00, 2.103e+00, 1.000e-12, 1.000e-12, 1.000e+01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e+01, 3.322e+00, 3.578e-01, 1.000e-12, 1.000e+01,
         2.241e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.302e+00, 1.000e-12, 3.082e+00, 1.000e-12, 1.000e-12, 6.834e+00,
         1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12],
        [1.000e-12, 1.000e-12, 4.127e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e+01, 2.054e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 5.349e+00, 1.780e+00, 2.276e+00,
         1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 4.821e+00, 4.710e+00,
         1.000e+01, 2.725e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 5.665e+00, 1.000e-12, 1.000e+01, 1.000e-12,
         4.034e+00, 1.000e-12, 4.595e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
         1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.082e+00, 1.701e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 9.559e+00],
        [1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 2.348e+00],
        [1.000e+01, 1.000e+01, 1.000e-12, 3.596e+00, 1.000e+01, 9.388e+00,
         1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 7.144e+00, 1.000e-12],
        [1.000e+01, 1.000e-12, 5.635e+00, 6.327e+00, 1.000e+01, 1.000e-12,
         1.000e+01, 8.651e+00, 2.847e+00, 1.000e-12],
        [1.000e+01, 1.000e+01, 5.197e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01],
        [1.000e+01, 7.249e-02, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
         5.597e+00, 9.440e+00, 1.000e-12, 1.000e+01],
        [1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 8.107e+00, 1.000e+01,
         1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01],
        [2.341e+00, 1.000e+01, 1.000e+01, 1.000e-12, 4.843e+00, 1.000e+01,
         1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 9.972e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e+01, 4.277e+00, 1.453e+00, 6.065e-01, 1.000e+01, 9.428e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
         5.577e+00, 1.000e-12, 1.000e+01, 1.000e-12],
        [1.000e+01, 1.574e-01, 1.000e-12, 4.186e+00, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.759e+00, 1.000e-12,
         1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e+01, 1.000e+01, 6.317e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.034e+00, 1.000e-12, 1.000e+01,
         1.000e+01, 1.000e+01, 2.797e+00, 1.000e-12],
        [1.000e+01, 6.827e+00, 8.319e-01, 1.000e-12, 3.602e+00, 1.000e+01,
         1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e+01, 4.528e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
         1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01]], device='cuda:0')
v before min max tensor([-15.674,  -9.673,  25.156,  -8.931,  -1.407,  -7.299,  -3.189,  -7.296,
          9.609, -14.778, -13.663,  25.525, -13.100,  -8.247,  -7.864, -13.657,
         -2.716,  -8.084,  -5.059,  -5.312,  12.390,   4.766,  -2.132, -17.436,
        -13.586,  -1.815,  -7.899,  -0.411, -10.472,  10.162, -13.720, -11.615,
         -9.010, -13.291,  -5.766,   0.156,  -0.705,   3.347,  48.392,  -9.250,
         -4.895,  -8.590,  -1.669,  -7.752, -15.105, 132.148,  -6.900,  -4.797,
         -7.640,  -6.513,   4.933,  -6.757,  -9.597,  -1.431, -13.052, -12.023,
         -0.464, -11.744,   9.372,  -8.477,  -5.410,   2.971, -14.100,  42.519,
        -19.009,  35.211,  -2.417,   2.885,  -5.353,  31.851, -11.016,  -9.361,
         -0.309, -15.280,  -0.795,  -9.210,  -9.179,   7.865,  59.061,  -7.991,
         -8.693,  -8.191,  -4.632,  -4.263,  -2.247,  -8.950,  -1.055, -11.625,
         -6.710,  -7.001,  73.426,  -7.401, -13.733,  13.245, -15.175,   0.472,
         34.492,   4.881,   8.456,  14.563], device='cuda:0')
v tensor([1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 9.609e+00, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 4.766e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.565e-01,
        1.000e-12, 3.347e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 4.933e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 9.372e+00, 1.000e-12,
        1.000e-12, 2.971e+00, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 2.885e+00, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 7.865e+00,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 4.716e-01,
        1.000e+01, 4.881e+00, 8.456e+00, 1.000e+01], device='cuda:0')
v before min max tensor([[[ 12.318],
         [-17.630],
         [ 61.522],
         [-13.330],
         [ 28.073],
         [ 20.025],
         [ 14.569],
         [ -4.691],
         [ 26.984],
         [ 22.761]],

        [[ 10.024],
         [  1.597],
         [-15.668],
         [ -5.694],
         [ -9.091],
         [ 39.164],
         [ 41.720],
         [ 22.162],
         [-14.426],
         [-13.697]],

        [[-11.681],
         [ -4.946],
         [120.937],
         [-11.009],
         [ -6.496],
         [ 78.289],
         [ -7.598],
         [  7.427],
         [-10.358],
         [-17.661]],

        [[ 17.955],
         [  3.438],
         [-10.854],
         [ -4.973],
         [ -1.954],
         [ -9.655],
         [ -0.674],
         [ -9.773],
         [ 19.393],
         [ 50.702]],

        [[ -3.654],
         [-10.509],
         [ 11.013],
         [-13.384],
         [-12.504],
         [ 25.221],
         [ -9.907],
         [-13.718],
         [ 12.627],
         [ -8.729]],

        [[ -7.206],
         [  1.862],
         [ -7.282],
         [ -1.217],
         [-17.314],
         [  2.500],
         [ -5.177],
         [-18.737],
         [ -0.517],
         [ 22.649]],

        [[ -9.825],
         [ -6.027],
         [ 11.649],
         [-12.572],
         [-12.394],
         [ -9.783],
         [-15.159],
         [ -7.720],
         [ -7.174],
         [ 39.856]],

        [[  7.734],
         [  7.450],
         [ -3.846],
         [-13.192],
         [ -2.450],
         [  9.469],
         [-18.120],
         [ -4.732],
         [ -8.747],
         [ 40.459]],

        [[ -6.287],
         [ -2.097],
         [  9.262],
         [ -7.035],
         [-14.497],
         [ -5.315],
         [ -5.891],
         [ -1.059],
         [ -0.537],
         [ -1.128]],

        [[  7.143],
         [ -8.285],
         [ -3.532],
         [-14.810],
         [  2.137],
         [-13.805],
         [ -4.722],
         [  8.603],
         [-12.233],
         [ 11.381]]], device='cuda:0')
v tensor([[[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [1.597e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [7.427e+00],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [3.438e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.862e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.500e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[7.734e+00],
         [7.450e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [9.469e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [9.262e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[7.143e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.137e+00],
         [1.000e-12],
         [1.000e-12],
         [8.603e+00],
         [1.000e-12],
         [1.000e+01]]], device='cuda:0')
v before min max tensor([[ 15.460],
        [  2.188],
        [ -4.919],
        [ -5.863],
        [ -7.568],
        [-11.870],
        [ -6.692],
        [ -9.267],
        [  2.713],
        [ 32.927]], device='cuda:0')
v tensor([[1.000e+01],
        [2.188e+00],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [2.713e+00],
        [1.000e+01]], device='cuda:0')
a after update for 1 param tensor([[-7.453e-02, -8.627e-03, -3.015e-02, -1.397e-02, -1.291e-02,  9.433e-04,
         -5.226e-02,  1.932e-02,  2.619e-04, -5.188e-02],
        [ 1.397e-02,  4.327e-02, -3.809e-02,  4.594e-03, -7.445e-03, -3.538e-03,
          2.812e-02, -3.902e-02, -1.580e-02, -1.068e-02],
        [-3.106e-02, -6.791e-03,  2.909e-03, -1.615e-02,  1.129e-02, -7.032e-03,
         -4.280e-02,  5.970e-02,  1.383e-02,  2.620e-02],
        [-1.135e-02,  4.194e-02,  1.894e-02, -7.999e-03,  1.556e-02, -5.437e-03,
          5.813e-02,  5.427e-04,  1.020e-02,  2.707e-03],
        [ 2.581e-02, -4.174e-02,  7.099e-03,  2.785e-02, -7.960e-03,  3.493e-03,
         -2.027e-02,  2.034e-02,  1.182e-02, -2.692e-05],
        [ 2.395e-02,  3.618e-02,  2.693e-02,  3.902e-02, -2.209e-02, -2.832e-02,
          8.437e-03, -3.147e-02,  1.125e-02, -1.648e-02],
        [-3.479e-02, -2.260e-02,  2.006e-02,  5.937e-03, -4.683e-02, -2.190e-02,
         -1.675e-02,  1.495e-03,  3.918e-03,  1.052e-02],
        [ 1.759e-02, -2.537e-02,  3.532e-03, -1.034e-02,  1.015e-02,  6.770e-03,
          6.141e-03,  5.444e-03, -9.490e-03, -2.136e-02],
        [-1.506e-02,  2.128e-03,  1.984e-02, -3.000e-02,  1.560e-02,  2.062e-02,
         -4.793e-03,  5.329e-03, -2.057e-03, -3.534e-05],
        [-1.255e-02, -2.954e-04,  3.353e-02, -2.752e-02, -6.507e-03,  2.286e-02,
         -1.746e-02, -5.028e-02,  2.508e-03,  1.358e-02],
        [-1.497e-02, -2.871e-02,  3.654e-02, -7.145e-03, -8.196e-03, -3.946e-02,
         -5.627e-03,  3.113e-03, -2.439e-02,  2.896e-03],
        [-1.137e-02,  1.135e-02,  8.673e-03,  4.158e-02, -1.916e-02, -1.791e-02,
         -3.718e-02,  1.022e-02,  3.145e-02,  6.218e-03],
        [ 2.941e-02, -1.891e-03,  2.417e-02,  1.156e-03,  2.969e-02, -7.775e-03,
         -1.027e-03, -1.648e-03, -1.129e-02,  5.950e-03],
        [-4.924e-03, -1.456e-02,  2.126e-02, -9.383e-03,  4.149e-03,  4.837e-04,
          3.519e-02,  3.155e-02, -9.272e-03,  2.230e-02],
        [-3.697e-03,  1.435e-03,  1.551e-02,  1.787e-02,  8.306e-03, -1.821e-03,
         -1.886e-02, -4.637e-03,  3.009e-02,  5.166e-04],
        [-4.646e-03,  1.626e-02,  1.169e-03,  1.434e-02,  1.128e-02,  3.555e-02,
          7.151e-03,  7.555e-03,  9.171e-03, -3.502e-02],
        [-2.166e-03, -1.029e-02, -7.925e-03, -1.795e-02,  9.296e-03,  1.988e-03,
          1.442e-02, -3.898e-03, -2.340e-02, -8.490e-03],
        [ 2.141e-03,  4.840e-03, -2.392e-02,  1.310e-02,  4.493e-03,  1.810e-03,
          1.182e-02,  1.133e-02,  1.181e-03, -1.889e-03],
        [-1.841e-02,  1.861e-02, -2.292e-03, -2.446e-04, -8.192e-03,  9.567e-03,
         -1.493e-02, -5.976e-02,  3.087e-02,  3.467e-03],
        [-2.368e-02,  2.589e-02, -8.297e-04,  7.445e-03,  9.387e-03,  2.649e-02,
         -3.821e-02, -7.599e-03, -4.729e-03,  8.582e-03],
        [-1.270e-02,  8.467e-03,  2.052e-04, -1.781e-02,  4.345e-03, -1.315e-03,
         -5.542e-03,  4.475e-02,  4.085e-02, -4.782e-03],
        [-2.388e-02,  5.310e-03, -9.074e-04,  1.316e-02, -3.180e-02, -5.994e-03,
         -2.039e-03,  1.699e-02, -1.483e-02, -3.070e-02],
        [-2.642e-03,  2.790e-02,  8.101e-03, -7.454e-03,  1.166e-02,  7.390e-03,
         -6.225e-03,  1.445e-02,  1.234e-02,  1.257e-03],
        [ 2.226e-02,  1.281e-02, -5.564e-02, -1.031e-02,  4.793e-03, -1.143e-02,
         -5.822e-03, -4.312e-02, -8.247e-04,  3.763e-03],
        [-7.320e-03, -2.956e-02, -2.748e-02,  6.466e-04,  1.373e-02,  1.799e-02,
          1.032e-02,  5.598e-03,  7.913e-03, -1.975e-02],
        [-2.283e-02,  4.542e-02,  2.693e-03,  4.124e-02,  8.217e-03, -3.720e-03,
         -6.020e-03,  5.829e-04,  3.191e-03,  1.503e-02],
        [ 1.591e-02,  1.094e-02,  2.979e-02, -5.555e-03,  2.125e-02,  1.700e-02,
         -1.785e-02, -6.897e-03,  1.097e-02,  8.692e-03],
        [-8.350e-03,  5.054e-02,  1.247e-02,  4.376e-03,  8.792e-03,  1.877e-02,
          3.668e-03,  2.682e-03,  2.298e-02,  2.503e-02],
        [ 2.463e-02, -9.866e-04,  1.423e-03, -3.326e-02,  9.656e-03,  2.724e-02,
         -2.121e-02, -1.571e-02,  1.075e-02,  1.637e-02],
        [-2.321e-03,  2.003e-02, -3.955e-02,  1.843e-02,  3.548e-02,  9.187e-03,
         -1.699e-03, -1.622e-02, -9.690e-03, -2.398e-02],
        [ 1.150e-02, -2.222e-02, -1.987e-02, -1.697e-02, -9.803e-03,  3.062e-03,
         -9.875e-03, -7.801e-03, -1.542e-02,  7.904e-03],
        [-3.653e-04, -4.378e-05, -8.939e-03, -4.460e-03,  2.041e-02, -1.950e-02,
         -1.240e-02, -1.937e-02, -3.093e-03, -1.253e-03],
        [-2.154e-02,  3.250e-02, -2.979e-03,  1.188e-02, -1.274e-02, -2.202e-02,
         -1.703e-02, -8.432e-03,  9.120e-03, -5.097e-04],
        [-1.272e-02,  2.718e-02,  3.453e-03,  2.316e-02,  1.367e-03,  1.432e-02,
         -3.845e-03,  1.871e-03,  6.460e-03, -4.314e-02],
        [-2.635e-03,  1.974e-02, -1.941e-02,  2.529e-03, -1.194e-02, -1.600e-02,
         -3.746e-02, -1.465e-02, -4.781e-02,  1.515e-03],
        [ 5.181e-02, -5.652e-03,  8.692e-03, -1.224e-03, -1.903e-02, -9.330e-03,
          2.284e-03, -4.418e-03, -7.063e-03,  1.283e-02],
        [-2.967e-03, -1.565e-02,  4.590e-02,  2.446e-02, -1.337e-02, -4.996e-03,
          1.916e-02, -3.778e-03,  3.492e-02, -1.253e-02],
        [-3.212e-02, -4.304e-02,  3.573e-02,  2.500e-03, -2.160e-02, -7.396e-03,
         -1.897e-02,  3.752e-02,  1.187e-02,  1.561e-02],
        [-1.757e-02, -1.428e-02,  1.196e-02,  2.977e-03,  1.571e-02, -2.184e-03,
          1.424e-02,  1.272e-03, -2.640e-02,  6.324e-03],
        [ 2.607e-03, -2.655e-03, -2.976e-03,  1.568e-02,  8.883e-03,  2.109e-02,
          8.405e-04, -3.677e-02,  2.516e-02,  6.252e-03],
        [-2.923e-02,  6.379e-03, -1.640e-02,  1.660e-03,  2.381e-02, -2.495e-02,
          2.641e-02, -7.628e-03,  1.926e-02,  4.697e-02],
        [ 1.598e-02,  1.261e-03,  1.748e-02,  2.711e-02,  3.372e-02, -3.372e-02,
          1.588e-02,  4.740e-02,  5.741e-03, -8.456e-03],
        [-2.081e-02, -1.563e-02,  1.170e-02, -2.902e-03,  1.615e-04,  5.851e-02,
         -4.176e-04, -1.567e-03, -2.672e-03,  8.616e-04],
        [ 3.628e-02, -2.296e-02,  2.358e-02, -2.464e-03, -1.733e-02, -2.323e-03,
          9.407e-02,  4.741e-04,  2.498e-03, -1.424e-02],
        [ 1.158e-02, -2.851e-03, -2.498e-02,  2.196e-02,  8.745e-03,  3.811e-03,
         -7.825e-03,  8.596e-03,  2.082e-02, -1.428e-02],
        [-2.494e-02, -3.317e-03, -1.202e-03, -3.489e-02,  2.047e-04,  1.114e-02,
         -1.720e-02,  7.226e-03,  4.416e-02, -2.743e-04],
        [-3.281e-02,  2.534e-03,  6.488e-04,  2.887e-03,  1.599e-02,  1.423e-03,
         -1.221e-02, -6.276e-03,  2.559e-02, -2.843e-03],
        [ 4.720e-02,  1.145e-02,  3.246e-02,  1.384e-02, -1.336e-02, -1.329e-02,
          2.669e-03, -2.462e-02, -1.879e-02, -7.506e-03],
        [-5.145e-02,  5.097e-02,  3.741e-02,  3.670e-03, -1.366e-02, -1.528e-02,
         -6.312e-02,  3.140e-02, -3.403e-02, -8.659e-03],
        [-9.831e-03,  7.136e-03,  3.522e-02, -2.522e-03, -2.640e-02, -4.598e-02,
         -4.616e-03, -7.646e-03,  7.246e-03, -1.561e-02],
        [-2.179e-03, -9.194e-03,  3.482e-03, -2.928e-02,  1.237e-02, -2.086e-02,
         -7.334e-04,  4.345e-02,  1.234e-03, -1.151e-02],
        [-2.598e-04, -2.253e-02,  8.753e-02, -3.533e-02,  1.952e-03, -1.052e-03,
          5.423e-03, -3.029e-02,  7.024e-04,  7.672e-03],
        [-2.206e-02, -3.096e-02,  2.630e-02,  3.664e-02, -1.605e-02, -5.101e-03,
         -1.191e-02,  1.945e-02, -2.110e-02, -3.121e-03],
        [-1.460e-02, -3.707e-02,  5.028e-03,  2.813e-02, -1.488e-02, -2.434e-03,
         -1.600e-02,  2.344e-02, -9.020e-03, -4.593e-04],
        [-1.247e-02,  3.460e-02, -1.700e-02, -6.255e-04, -1.011e-02, -1.408e-02,
         -3.955e-02,  7.739e-03,  4.214e-03,  3.513e-03],
        [-6.942e-03, -9.667e-03, -1.753e-02, -4.529e-02,  1.020e-02, -8.614e-03,
         -2.073e-02, -2.913e-02,  1.589e-02,  3.396e-02],
        [ 1.601e-02,  7.922e-03, -2.778e-02, -2.853e-03,  9.975e-03,  1.448e-02,
         -6.085e-03, -1.400e-03, -1.783e-02,  1.661e-02],
        [-3.498e-03,  4.839e-03,  4.610e-02,  4.172e-03, -8.359e-03, -2.807e-02,
          1.677e-02, -3.622e-03, -6.852e-03,  1.832e-02],
        [-1.232e-02, -3.908e-02, -3.026e-02, -1.137e-02, -2.677e-02, -2.699e-03,
          9.119e-03, -2.467e-02, -1.435e-03,  3.061e-02],
        [-4.782e-03, -1.119e-02, -2.104e-03, -1.071e-02, -1.721e-02, -8.032e-03,
         -6.276e-03,  7.135e-03,  4.135e-02, -1.604e-02],
        [-6.607e-02, -1.004e-02,  9.328e-03,  5.193e-03, -1.128e-02,  3.287e-03,
          4.832e-02, -4.142e-02, -2.557e-02, -2.760e-02],
        [-5.353e-02,  7.951e-03,  6.874e-03,  7.941e-03,  6.380e-03, -1.982e-02,
          6.440e-02, -4.837e-02, -1.448e-02,  3.390e-02],
        [ 4.049e-03,  1.045e-02, -1.251e-02,  1.052e-02,  6.849e-03, -3.786e-02,
          4.436e-02, -7.525e-02, -2.816e-02, -7.352e-03],
        [ 8.913e-03,  3.113e-02,  2.779e-02, -7.246e-03,  7.318e-03, -1.476e-02,
          6.399e-02, -1.083e-02, -2.912e-02, -3.023e-03],
        [ 2.064e-02, -1.152e-02,  1.224e-02, -1.291e-02,  9.475e-03, -6.780e-04,
          1.734e-02, -1.245e-02, -8.234e-04,  2.961e-02],
        [-3.416e-03,  1.581e-02,  1.873e-02,  8.903e-03,  3.023e-02,  1.763e-03,
          6.080e-02, -1.085e-02,  1.952e-02,  2.443e-02],
        [-4.740e-02,  1.329e-02, -3.402e-03, -1.125e-02,  1.382e-02, -2.671e-02,
          2.051e-02,  1.135e-02,  7.207e-03, -1.595e-02],
        [-3.107e-02,  2.118e-02,  6.861e-02,  4.612e-02,  1.292e-02, -3.973e-02,
          3.791e-02, -7.886e-03, -6.061e-03, -1.709e-02],
        [-1.770e-02,  2.487e-02, -1.679e-02, -1.160e-02,  4.580e-02,  2.112e-02,
          1.845e-02, -5.125e-02, -1.203e-02,  5.576e-03],
        [ 5.010e-03, -2.126e-02,  5.514e-02,  3.454e-03,  2.907e-02,  1.402e-02,
         -3.640e-03, -3.378e-02, -6.662e-03, -9.572e-03],
        [-2.424e-03, -3.592e-03,  1.881e-03, -2.104e-02, -7.565e-03,  6.279e-02,
         -5.467e-03,  1.243e-02, -8.371e-03, -2.253e-02],
        [ 4.845e-03, -1.751e-02, -5.879e-03,  7.791e-04,  1.868e-03, -6.001e-04,
          1.571e-02,  1.929e-03,  3.318e-02, -2.512e-02],
        [-2.036e-02, -1.777e-02,  6.682e-04, -1.640e-02, -1.803e-03,  8.670e-03,
          2.845e-02,  1.430e-03, -4.192e-02,  4.256e-03],
        [ 5.814e-03, -6.814e-04, -5.859e-02, -1.157e-02, -7.499e-03,  7.449e-03,
          1.237e-02,  1.442e-02,  1.826e-02, -1.177e-02],
        [ 2.452e-02, -3.603e-02, -1.557e-02, -1.345e-02,  1.716e-02, -6.340e-03,
         -1.870e-02, -1.043e-02, -1.153e-02,  3.651e-03],
        [ 7.364e-03,  7.159e-03,  2.464e-02, -4.202e-03,  6.376e-03,  4.116e-02,
          1.931e-02,  5.102e-02,  1.408e-03,  1.274e-02],
        [-4.430e-03,  3.989e-02, -9.031e-03,  1.410e-02, -6.898e-03, -4.126e-03,
         -1.505e-03, -1.229e-03,  1.225e-02,  1.978e-02],
        [-4.109e-03,  3.519e-02, -1.692e-02,  1.388e-02,  2.637e-02, -3.306e-02,
         -1.034e-02,  2.223e-02,  1.380e-03,  3.746e-03],
        [-4.546e-03,  8.000e-03,  1.140e-02,  5.058e-03, -9.602e-03,  2.499e-02,
         -2.387e-02, -3.634e-03,  1.202e-02, -2.667e-03],
        [-4.367e-02, -3.478e-03, -5.752e-03,  1.800e-02, -6.721e-03,  7.455e-03,
          2.982e-02, -1.321e-02,  2.147e-03, -2.171e-02],
        [-3.786e-02,  5.285e-03,  5.186e-03,  2.553e-03,  5.704e-03, -4.982e-03,
         -8.619e-03,  2.820e-03, -2.812e-03, -3.724e-03],
        [ 1.883e-02,  9.150e-03, -9.677e-03,  1.759e-02, -3.210e-04,  3.111e-02,
          1.996e-02, -3.535e-02,  3.258e-02,  2.024e-02],
        [-7.177e-03, -1.192e-02, -3.019e-03,  1.585e-02, -2.879e-02, -5.944e-03,
          2.499e-02, -1.129e-03,  4.628e-03, -3.402e-03],
        [ 1.754e-02,  1.368e-02,  3.782e-02,  4.940e-03,  7.471e-03,  2.592e-02,
          1.586e-02, -3.658e-02, -3.066e-03,  4.064e-02],
        [ 2.564e-02,  1.030e-03, -4.146e-03,  2.762e-03,  1.522e-02,  3.471e-02,
          8.473e-03, -2.214e-02, -2.447e-02,  1.045e-02],
        [-1.275e-02,  4.582e-02,  2.169e-02,  1.196e-02,  1.092e-02,  5.543e-03,
          2.490e-03, -3.671e-03, -2.557e-02,  3.894e-02],
        [-1.362e-03,  7.186e-03, -3.878e-02, -3.118e-02,  4.083e-03,  4.848e-03,
         -1.170e-02,  2.056e-02,  2.711e-02, -1.515e-02],
        [ 2.804e-03, -1.982e-02,  1.846e-02, -6.927e-03,  2.224e-03, -9.882e-03,
         -1.357e-02, -3.864e-02, -2.647e-02, -1.492e-02],
        [ 3.362e-02,  3.774e-03,  5.525e-02, -6.380e-03, -5.426e-03, -1.804e-02,
         -2.289e-02, -3.653e-02,  9.914e-03, -1.706e-02],
        [ 1.092e-02,  1.554e-02, -2.528e-03, -4.668e-03, -1.588e-02,  1.051e-02,
          3.027e-03, -3.068e-02,  1.968e-02,  1.323e-02],
        [ 2.271e-03,  9.654e-03, -4.013e-03, -1.247e-02,  3.654e-04, -5.210e-02,
         -1.048e-02, -1.574e-05,  3.297e-02,  1.210e-02],
        [ 9.349e-03, -5.803e-03, -3.466e-02, -8.862e-03, -1.556e-02,  1.499e-02,
         -6.298e-03,  4.642e-03, -3.391e-02, -1.712e-02],
        [ 1.274e-02, -8.071e-03,  6.138e-03, -2.218e-02, -1.058e-02,  4.908e-02,
         -1.374e-02, -4.174e-02, -8.927e-05, -1.856e-02],
        [ 4.935e-03, -4.189e-03, -5.693e-03,  1.053e-02, -1.610e-02, -1.090e-02,
         -3.003e-02, -6.668e-03, -2.515e-02,  1.500e-04],
        [ 3.073e-02,  7.749e-03, -1.909e-02,  1.277e-02,  7.510e-03,  1.259e-02,
         -1.072e-03,  7.479e-03, -2.701e-02,  7.615e-03],
        [ 2.131e-02, -1.371e-02, -4.041e-03,  3.688e-02,  7.611e-03, -2.810e-02,
          4.161e-02, -8.309e-03,  2.307e-02,  1.965e-02],
        [ 1.123e-04,  6.394e-03, -1.070e-02, -1.526e-03, -1.557e-02,  9.970e-03,
         -1.401e-02,  2.107e-02, -1.308e-02, -7.173e-03],
        [ 1.001e-02,  1.512e-02, -3.629e-02,  1.463e-02,  2.161e-05,  5.225e-03,
         -4.780e-02,  9.941e-03,  6.341e-03, -8.434e-03],
        [ 6.943e-03, -9.873e-03, -2.113e-02,  1.130e-02,  2.197e-03,  1.533e-02,
         -2.740e-02,  1.833e-02,  2.764e-03,  2.372e-03],
        [-1.431e-02,  3.084e-02, -2.111e-03, -2.257e-02, -3.563e-02, -2.502e-02,
          1.842e-02,  1.620e-02,  4.429e-02,  1.079e-02]], device='cuda:0')
s after update for 1 param tensor([[2.440, 1.856, 1.903, 0.900, 1.998, 2.000, 1.979, 1.890, 1.254, 2.194],
        [2.251, 1.648, 2.009, 1.250, 2.073, 2.342, 2.034, 2.116, 1.416, 1.698],
        [2.101, 2.058, 1.666, 1.236, 2.191, 1.563, 1.466, 1.535, 0.852, 1.996],
        [2.200, 1.956, 2.103, 1.527, 2.191, 2.145, 2.430, 2.224, 1.229, 1.894],
        [2.320, 1.975, 1.627, 1.268, 1.875, 1.410, 1.404, 1.546, 1.266, 0.682],
        [2.257, 2.036, 1.638, 1.574, 1.498, 2.134, 1.946, 1.899, 1.558, 1.682],
        [2.534, 1.717, 1.868, 0.782, 1.974, 1.938, 2.003, 2.294, 1.091, 1.874],
        [2.037, 1.402, 1.420, 1.557, 1.797, 1.267, 1.484, 1.798, 1.241, 1.127],
        [2.028, 1.157, 1.451, 1.839, 1.786, 1.419, 1.512, 1.386, 1.321, 0.937],
        [2.227, 2.039, 2.203, 1.166, 1.436, 1.912, 2.250, 1.863, 2.009, 1.816],
        [2.244, 1.342, 1.561, 1.752, 1.812, 0.955, 1.766, 2.013, 1.203, 1.936],
        [1.533, 1.899, 1.263, 2.377, 1.789, 1.542, 1.794, 1.961, 1.587, 0.689],
        [1.652, 1.238, 1.467, 0.090, 1.368, 1.420, 1.452, 0.826, 1.248, 0.883],
        [1.960, 1.759, 1.587, 1.689, 2.041, 1.536, 1.613, 1.859, 1.371, 1.114],
        [1.675, 1.712, 1.628, 1.444, 1.688, 1.946, 1.763, 1.079, 1.390, 1.695],
        [1.774, 1.785, 1.347, 1.149, 1.585, 1.431, 1.475, 1.296, 1.701, 2.003],
        [1.982, 1.425, 1.699, 1.321, 1.599, 1.564, 1.430, 1.781, 1.108, 1.063],
        [1.885, 1.705, 1.499, 1.276, 2.075, 1.878, 1.890, 1.889, 0.551, 1.366],
        [1.757, 1.985, 2.029, 0.219, 1.961, 0.731, 1.870, 1.231, 1.397, 1.851],
        [1.977, 2.034, 1.811, 1.811, 1.635, 1.521, 1.474, 1.418, 1.550, 1.545],
        [2.218, 1.248, 1.449, 0.881, 1.252, 1.718, 1.755, 1.663, 1.408, 1.560],
        [2.245, 0.910, 2.176, 1.006, 2.025, 1.035, 1.878, 1.557, 1.601, 1.633],
        [1.694, 1.747, 1.923, 1.299, 1.894, 1.506, 1.712, 1.671, 1.140, 1.044],
        [2.023, 2.052, 2.275, 1.968, 1.695, 1.783, 1.901, 1.345, 0.882, 1.094],
        [1.951, 1.977, 2.271, 1.503, 1.378, 0.993, 1.051, 1.420, 0.987, 1.687],
        [1.885, 1.592, 1.364, 2.185, 1.714, 1.969, 2.003, 1.577, 1.210, 1.784],
        [1.899, 1.395, 1.874, 1.650, 1.682, 1.582, 1.880, 2.038, 1.377, 1.744],
        [2.176, 1.550, 2.363, 0.489, 1.632, 1.375, 1.804, 1.805, 1.745, 1.588],
        [2.013, 0.588, 1.554, 1.533, 1.983, 2.092, 2.099, 1.442, 0.950, 1.962],
        [1.652, 1.291, 1.917, 1.429, 1.988, 1.339, 2.100, 1.314, 1.048, 1.765],
        [1.569, 1.423, 1.536, 2.196, 1.849, 0.976, 1.292, 1.718, 1.270, 1.330],
        [1.757, 1.099, 1.847, 1.529, 1.859, 1.343, 2.527, 1.446, 1.580, 1.698],
        [1.370, 2.137, 0.980, 1.201, 1.199, 1.587, 2.013, 1.762, 1.591, 1.638],
        [1.878, 1.458, 1.174, 2.023, 1.011, 1.467, 1.975, 1.639, 1.348, 1.947],
        [1.462, 1.348, 2.098, 1.022, 1.664, 1.615, 1.535, 1.480, 2.168, 1.581],
        [1.438, 1.779, 0.960, 1.502, 1.889, 0.905, 1.015, 1.316, 1.124, 2.203],
        [1.701, 1.197, 2.140, 1.820, 1.812, 2.017, 2.053, 1.871, 1.805, 2.064],
        [2.277, 1.926, 1.184, 1.249, 1.794, 1.246, 1.947, 2.049, 1.890, 1.818],
        [1.727, 1.854, 1.702, 2.285, 2.105, 1.682, 2.129, 1.353, 1.649, 1.390],
        [1.911, 2.073, 2.022, 1.486, 1.537, 1.232, 1.246, 1.693, 1.433, 2.053],
        [1.622, 1.505, 1.584, 0.569, 2.022, 1.584, 1.476, 1.073, 1.448, 1.945],
        [1.723, 1.632, 1.391, 1.697, 2.351, 2.066, 2.115, 1.781, 1.600, 1.254],
        [1.831, 1.985, 1.553, 1.397, 1.770, 1.941, 1.121, 1.501, 1.448, 2.048],
        [1.516, 1.882, 1.745, 1.791, 1.880, 1.792, 2.077, 1.844, 1.346, 1.557],
        [1.367, 1.218, 1.707, 1.622, 1.621, 1.312, 2.153, 1.123, 1.436, 1.098],
        [1.614, 1.836, 1.359, 1.644, 1.541, 0.864, 1.928, 1.910, 1.779, 1.175],
        [1.543, 1.251, 1.480, 1.267, 1.911, 1.999, 1.510, 0.872, 1.428, 2.072],
        [2.210, 1.430, 1.521, 1.451, 1.878, 1.537, 1.367, 2.139, 0.954, 1.943],
        [2.419, 1.674, 2.358, 1.519, 2.106, 1.356, 2.212, 1.828, 1.075, 1.759],
        [1.809, 0.783, 1.399, 0.735, 2.018, 1.305, 1.852, 1.120, 1.422, 1.619],
        [1.375, 0.984, 1.270, 2.097, 2.093, 1.864, 1.687, 1.466, 1.010, 0.778],
        [2.060, 1.234, 2.172, 1.424, 1.760, 1.302, 1.555, 1.371, 0.342, 2.243],
        [1.967, 1.750, 1.650, 1.672, 1.366, 1.416, 1.403, 1.398, 1.844, 1.379],
        [1.467, 1.900, 1.693, 1.482, 1.746, 1.911, 1.678, 1.470, 1.608, 1.492],
        [1.223, 1.512, 1.375, 1.223, 1.683, 2.115, 1.527, 0.511, 0.390, 1.134],
        [1.445, 1.378, 2.131, 1.523, 1.524, 1.549, 1.616, 1.662, 0.795, 1.399],
        [1.494, 1.393, 2.120, 1.049, 0.842, 1.575, 1.794, 1.477, 0.850, 1.418],
        [1.787, 1.184, 2.119, 1.924, 1.719, 1.883, 1.998, 1.250, 1.058, 1.198],
        [1.500, 2.111, 1.645, 1.477, 2.190, 1.685, 1.723, 1.911, 2.014, 1.484],
        [1.394, 1.427, 0.660, 1.385, 2.109, 1.725, 0.719, 1.599, 1.938, 1.727],
        [2.112, 1.918, 2.008, 1.744, 2.235, 2.337, 2.374, 2.150, 1.864, 1.811],
        [2.156, 2.115, 1.856, 1.686, 1.953, 2.153, 2.335, 2.231, 1.784, 2.073],
        [2.340, 1.920, 2.054, 0.801, 2.306, 1.925, 2.315, 1.988, 1.826, 1.939],
        [2.415, 2.267, 2.190, 0.608, 1.695, 1.655, 2.013, 2.233, 1.958, 2.161],
        [2.111, 1.895, 1.347, 1.187, 1.631, 1.335, 2.182, 1.942, 1.717, 1.847],
        [2.395, 1.637, 2.016, 0.582, 2.371, 1.840, 2.550, 2.193, 1.112, 1.675],
        [2.045, 2.087, 2.289, 1.433, 1.420, 1.980, 2.473, 1.996, 1.444, 1.987],
        [2.243, 2.194, 2.152, 1.624, 1.696, 1.818, 2.461, 2.415, 1.893, 2.022],
        [1.729, 1.609, 1.957, 1.517, 1.547, 1.868, 2.169, 1.682, 1.360, 1.062],
        [2.368, 2.222, 2.390, 1.349, 2.040, 2.291, 2.306, 2.126, 2.016, 1.895],
        [1.762, 1.978, 1.345, 1.235, 0.370, 2.055, 1.099, 1.952, 1.336, 1.661],
        [1.364, 1.358, 1.495, 1.594, 1.603, 0.834, 1.796, 1.796, 1.632, 1.491],
        [1.341, 1.394, 1.503, 1.703, 1.637, 1.267, 1.641, 1.502, 1.865, 1.092],
        [1.960, 1.320, 1.691, 1.233, 0.880, 1.730, 1.847, 2.333, 1.818, 1.517],
        [1.368, 1.911, 1.530, 1.491, 1.665, 0.684, 1.455, 1.999, 1.911, 1.723],
        [1.697, 0.684, 2.109, 1.487, 1.709, 1.823, 1.827, 2.138, 1.877, 1.256],
        [1.172, 1.265, 0.821, 0.949, 2.011, 2.026, 0.800, 0.911, 1.475, 1.998],
        [1.504, 1.790, 1.781, 1.434, 1.887, 1.386, 2.098, 1.755, 0.773, 1.194],
        [2.210, 1.718, 1.671, 1.389, 1.553, 1.668, 1.390, 1.462, 1.861, 1.220],
        [1.804, 1.106, 1.768, 1.829, 0.661, 1.142, 1.689, 2.484, 1.209, 1.743],
        [2.005, 1.363, 1.345, 1.782, 1.439, 0.723, 1.243, 0.650, 1.722, 1.925],
        [1.815, 1.317, 2.031, 1.456, 1.908, 1.493, 1.624, 1.104, 1.948, 1.858],
        [2.491, 1.664, 1.836, 1.377, 1.998, 1.560, 2.251, 1.976, 1.743, 1.000],
        [2.152, 1.782, 2.114, 1.975, 2.097, 1.649, 1.675, 1.837, 1.966, 1.895],
        [2.161, 0.970, 1.758, 1.483, 1.704, 1.487, 1.470, 1.909, 1.966, 1.780],
        [2.051, 2.054, 1.930, 1.442, 1.908, 1.386, 1.636, 1.931, 2.248, 2.008],
        [2.011, 1.810, 2.091, 1.081, 2.173, 1.582, 1.869, 2.033, 2.149, 1.763],
        [2.239, 1.832, 2.027, 1.732, 1.822, 1.224, 1.807, 1.542, 2.125, 1.365],
        [1.930, 1.840, 1.798, 1.392, 1.101, 1.872, 2.089, 2.206, 2.145, 1.809],
        [1.343, 1.623, 2.032, 1.479, 1.942, 1.546, 2.040, 1.635, 1.863, 1.234],
        [1.237, 1.782, 1.528, 1.688, 0.164, 1.691, 1.098, 1.426, 1.092, 1.826],
        [2.150, 1.521, 1.247, 0.441, 2.077, 1.225, 1.454, 1.549, 1.620, 2.158],
        [2.443, 1.777, 1.872, 1.239, 1.053, 2.033, 1.320, 1.911, 1.729, 1.415],
        [1.754, 1.991, 1.577, 1.552, 1.769, 1.132, 2.000, 2.009, 1.884, 2.054],
        [1.947, 1.720, 1.680, 1.798, 1.689, 1.368, 1.920, 1.849, 1.167, 1.991],
        [2.030, 1.750, 1.940, 1.569, 2.183, 1.669, 2.113, 2.260, 1.612, 1.505],
        [1.695, 1.202, 1.432, 1.092, 1.860, 2.035, 2.152, 2.011, 0.933, 1.742],
        [2.227, 1.832, 1.491, 1.843, 1.245, 1.883, 2.116, 1.780, 1.440, 1.471],
        [1.491, 1.963, 2.022, 1.346, 1.700, 1.635, 2.000, 1.432, 1.657, 0.649],
        [2.044, 0.941, 1.786, 1.309, 1.508, 1.899, 1.776, 1.978, 2.020, 1.834]],
       device='cuda:0')
b after update for 1 param tensor([[69.155, 60.311, 61.075, 41.987, 62.570, 62.610, 62.282, 60.867, 49.571,
         65.579],
        [66.411, 56.825, 62.743, 49.503, 63.742, 67.749, 63.134, 64.395, 52.677,
         57.689],
        [64.169, 63.502, 57.131, 49.214, 65.529, 55.349, 53.603, 54.844, 40.855,
         62.547],
        [65.657, 61.910, 64.196, 54.705, 65.519, 64.829, 69.013, 66.013, 49.084,
         60.931],
        [67.428, 62.208, 56.463, 49.858, 60.614, 52.559, 52.445, 55.042, 49.816,
         36.561],
        [66.508, 63.173, 56.652, 55.546, 54.178, 64.675, 61.754, 61.011, 55.256,
         57.421],
        [70.469, 58.005, 60.496, 39.144, 62.194, 61.628, 62.658, 67.051, 46.229,
         60.597],
        [63.178, 52.420, 52.760, 55.247, 59.341, 49.836, 53.921, 59.361, 49.323,
         47.000],
        [63.039, 47.623, 53.332, 60.031, 59.167, 52.725, 54.438, 52.111, 50.874,
         42.842],
        [66.069, 63.211, 65.711, 47.798, 53.044, 61.219, 66.406, 60.426, 62.749,
         59.655],
        [66.315, 51.288, 55.310, 58.602, 59.593, 43.258, 58.827, 62.809, 48.545,
         61.599],
        [54.809, 61.002, 49.759, 68.257, 59.206, 54.979, 59.286, 61.985, 55.764,
         36.756],
        [56.902, 49.262, 53.621, 13.294, 51.780, 52.755, 53.344, 40.243, 49.454,
         41.608],
        [61.976, 58.716, 55.771, 57.528, 63.242, 54.858, 56.224, 60.352, 51.829,
         46.718],
        [57.289, 57.929, 56.485, 53.198, 57.518, 61.750, 58.781, 45.978, 52.196,
         57.631],
        [58.958, 59.152, 51.385, 47.453, 55.736, 52.947, 53.757, 50.400, 57.728,
         62.648],
        [62.322, 52.840, 57.700, 50.880, 55.976, 55.367, 52.942, 59.085, 46.599,
         45.645],
        [60.785, 57.808, 54.200, 50.003, 63.770, 60.666, 60.852, 60.851, 32.875,
         51.731],
        [58.674, 62.374, 63.055, 20.701, 61.988, 37.854, 60.533, 49.123, 52.332,
         60.226],
        [62.248, 63.140, 59.578, 59.570, 56.596, 54.589, 53.748, 52.706, 55.120,
         55.018],
        [65.925, 49.445, 53.281, 41.550, 49.534, 58.032, 58.640, 57.086, 52.536,
         55.298],
        [66.326, 42.224, 65.296, 44.394, 63.000, 45.032, 60.667, 55.237, 56.011,
         56.572],
        [57.613, 58.509, 61.390, 50.448, 60.928, 54.326, 57.921, 57.233, 47.272,
         45.227],
        [62.968, 63.419, 66.775, 62.096, 57.638, 59.112, 61.032, 51.345, 41.568,
         46.300],
        [61.836, 62.251, 66.715, 54.279, 51.973, 44.115, 45.375, 52.746, 43.972,
         57.490],
        [60.772, 55.860, 51.706, 65.443, 57.962, 62.115, 62.655, 55.584, 48.686,
         59.126],
        [61.003, 52.283, 60.606, 56.860, 57.405, 55.684, 60.692, 63.201, 51.944,
         58.463],
        [65.301, 55.107, 68.057, 30.941, 56.554, 51.903, 59.464, 59.470, 58.480,
         55.791],
        [62.816, 33.946, 55.192, 54.820, 62.343, 64.025, 64.131, 53.158, 43.150,
         62.003],
        [56.905, 50.295, 61.300, 52.926, 62.421, 51.219, 64.156, 50.737, 45.318,
         58.818],
        [55.451, 52.811, 54.873, 65.601, 60.199, 43.733, 50.324, 58.028, 49.878,
         51.050],
        [58.686, 46.417, 60.168, 54.742, 60.357, 51.298, 70.374, 53.228, 55.650,
         57.684],
        [51.819, 64.718, 43.825, 48.521, 48.473, 55.776, 62.812, 58.760, 55.838,
         56.661],
        [60.660, 53.454, 47.966, 62.963, 44.510, 53.620, 62.207, 56.668, 51.397,
         61.767],
        [53.533, 51.390, 64.124, 44.747, 57.110, 56.257, 54.855, 53.861, 65.178,
         55.663],
        [53.084, 59.038, 43.378, 54.254, 60.847, 42.117, 44.594, 50.783, 46.930,
         65.708],
        [57.735, 48.427, 64.763, 59.718, 59.587, 62.878, 63.425, 60.547, 59.467,
         63.598],
        [66.797, 61.444, 48.161, 49.475, 59.291, 49.409, 61.772, 63.371, 60.864,
         59.692],
        [58.179, 60.274, 57.752, 66.914, 64.223, 57.415, 64.592, 51.484, 56.839,
         52.193],
        [61.192, 63.741, 62.943, 53.973, 54.877, 49.135, 49.409, 57.594, 52.990,
         63.430],
        [56.382, 54.311, 55.707, 33.393, 62.953, 55.707, 53.791, 45.856, 53.278,
         61.743],
        [58.106, 56.548, 52.208, 57.665, 67.878, 63.625, 64.380, 59.080, 55.998,
         49.569],
        [59.896, 62.363, 55.172, 52.318, 58.891, 61.667, 46.875, 54.228, 53.263,
         63.353],
        [54.497, 60.736, 58.477, 59.244, 60.693, 59.266, 63.792, 60.118, 51.360,
         55.247],
        [51.756, 48.846, 57.841, 56.379, 56.357, 50.705, 64.960, 46.911, 53.045,
         46.394],
        [56.248, 59.982, 51.615, 56.761, 54.953, 41.159, 61.461, 61.175, 59.048,
         47.979],
        [54.996, 49.508, 53.864, 49.831, 61.195, 62.587, 54.400, 41.333, 52.909,
         63.730],
        [65.814, 52.931, 54.603, 53.332, 60.662, 54.882, 51.759, 64.741, 43.230,
         61.707],
        [68.852, 57.276, 67.982, 54.552, 64.240, 51.558, 65.838, 59.848, 45.892,
         58.710],
        [59.539, 39.175, 52.358, 37.955, 62.882, 50.576, 60.236, 46.855, 52.784,
         56.327],
        [51.909, 43.903, 49.887, 64.113, 64.046, 60.446, 57.496, 53.598, 44.487,
         39.057],
        [63.538, 49.167, 65.235, 52.831, 58.725, 50.516, 55.207, 51.827, 25.889,
         66.298],
        [62.080, 58.562, 56.868, 57.245, 51.734, 52.676, 52.443, 52.336, 60.109,
         51.979],
        [53.620, 61.024, 57.608, 53.900, 58.494, 61.204, 57.350, 53.681, 56.133,
         54.073],
        [48.954, 54.439, 51.917, 48.958, 57.432, 64.387, 54.709, 31.642, 27.635,
         47.133],
        [53.207, 51.958, 64.624, 54.628, 54.654, 55.089, 56.283, 57.071, 39.466,
         52.365],
        [54.101, 52.250, 64.459, 45.350, 40.632, 55.551, 59.290, 53.809, 40.812,
         52.723],
        [59.178, 48.162, 64.441, 61.399, 58.036, 60.754, 62.572, 49.499, 45.535,
         48.455],
        [54.211, 64.315, 56.780, 53.802, 65.513, 57.470, 58.113, 61.198, 62.828,
         53.925],
        [52.276, 52.877, 35.965, 52.105, 64.293, 58.148, 37.533, 55.971, 61.623,
         58.179],
        [64.330, 61.310, 62.731, 58.458, 66.184, 67.671, 68.213, 64.917, 60.440,
         59.566],
        [65.005, 64.380, 60.310, 57.489, 61.859, 64.952, 67.645, 66.119, 59.120,
         63.738],
        [67.712, 61.344, 63.450, 39.616, 67.225, 61.414, 67.361, 62.424, 59.823,
         61.644],
        [68.793, 66.652, 65.514, 34.517, 57.632, 56.956, 62.804, 66.150, 61.949,
         65.077],
        [64.312, 60.939, 51.373, 48.231, 56.540, 51.145, 65.397, 61.696, 58.012,
         60.166],
        [68.514, 56.634, 62.862, 33.771, 68.158, 60.045, 70.689, 65.557, 46.672,
         57.292],
        [63.298, 63.957, 66.969, 52.993, 52.745, 62.287, 69.618, 62.543, 53.194,
         62.397],
        [66.300, 65.572, 64.944, 56.406, 57.659, 59.685, 69.444, 68.789, 60.901,
         62.948],
        [58.203, 56.149, 61.927, 54.521, 55.069, 60.510, 65.198, 57.406, 51.623,
         45.618],
        [68.117, 65.982, 68.432, 51.413, 63.224, 67.010, 67.230, 64.545, 62.857,
         60.947],
        [58.769, 62.254, 51.339, 49.199, 26.935, 63.456, 46.402, 61.842, 51.176,
         57.061],
        [51.703, 51.579, 54.129, 55.887, 56.043, 40.432, 59.333, 59.321, 56.558,
         54.060],
        [51.264, 52.274, 54.272, 57.774, 56.635, 49.829, 56.700, 54.256, 60.461,
         46.256],
        [61.981, 50.853, 57.559, 49.149, 41.521, 58.233, 60.167, 67.621, 59.689,
         54.523],
        [51.769, 61.194, 54.761, 54.051, 57.121, 36.600, 53.400, 62.595, 61.193,
         58.109],
        [57.662, 36.619, 64.295, 53.986, 57.870, 59.775, 59.840, 64.730, 60.642,
         49.621],
        [47.932, 49.798, 40.107, 43.124, 62.775, 63.006, 39.606, 42.243, 53.762,
         62.568],
        [54.288, 59.234, 59.079, 53.019, 60.813, 52.121, 64.124, 58.647, 38.922,
         48.364],
        [65.810, 58.020, 57.221, 52.182, 55.174, 57.180, 52.183, 53.521, 60.388,
         48.888],
        [59.455, 46.554, 58.865, 59.876, 36.005, 47.297, 57.530, 69.775, 48.681,
         58.446],
        [62.686, 51.683, 51.332, 59.091, 53.096, 37.635, 49.350, 35.701, 58.090,
         61.419],
        [59.634, 50.798, 63.091, 53.420, 61.153, 54.083, 56.406, 46.513, 61.792,
         60.337],
        [69.872, 57.105, 59.982, 51.949, 62.571, 55.284, 66.415, 62.227, 58.446,
         44.275],
        [64.942, 59.092, 64.372, 62.207, 64.112, 56.855, 57.298, 60.002, 62.075,
         60.947],
        [65.079, 43.593, 58.688, 53.919, 57.784, 53.986, 53.682, 61.165, 62.076,
         59.065],
        [63.392, 63.448, 61.498, 53.156, 61.149, 52.121, 56.624, 61.522, 66.371,
         62.737],
        [62.781, 59.565, 64.012, 46.022, 65.262, 55.683, 60.516, 63.112, 64.893,
         58.772],
        [66.239, 59.922, 63.025, 58.261, 59.752, 48.984, 59.501, 54.968, 64.530,
         51.721],
        [61.493, 60.050, 59.357, 52.234, 46.461, 60.566, 63.985, 65.747, 64.837,
         59.547],
        [51.309, 56.397, 63.111, 53.830, 61.696, 55.038, 63.224, 56.597, 60.415,
         49.182],
        [49.240, 59.094, 54.729, 57.515, 17.906, 57.569, 46.387, 52.863, 46.266,
         59.820],
        [64.907, 54.602, 49.439, 29.390, 63.795, 48.996, 53.387, 55.088, 56.352,
         65.025],
        [69.192, 59.014, 60.566, 49.277, 45.420, 63.123, 50.856, 61.201, 58.216,
         52.651],
        [58.626, 62.471, 55.591, 55.149, 58.872, 47.093, 62.612, 62.744, 60.759,
         63.451],
        [61.768, 58.065, 57.386, 59.362, 57.538, 51.776, 61.340, 60.191, 47.816,
         62.467],
        [63.067, 58.564, 61.655, 55.456, 65.408, 57.198, 64.348, 66.552, 56.197,
         54.312],
        [57.630, 48.542, 52.981, 46.268, 60.370, 63.158, 64.934, 62.775, 42.760,
         58.425],
        [66.068, 59.912, 54.057, 60.094, 49.404, 60.745, 64.389, 59.064, 53.115,
         53.699],
        [54.058, 62.020, 62.953, 51.353, 57.719, 56.597, 62.609, 52.972, 56.989,
         35.652],
        [63.287, 42.941, 59.157, 50.645, 54.366, 61.008, 59.003, 62.254, 62.922,
         59.948]], device='cuda:0')
clipping threshold 1.1096225036931595
a after update for 1 param tensor([ 0.005,  0.003,  0.020,  0.011,  0.021, -0.010,  0.017, -0.019,  0.027,
        -0.011, -0.011, -0.015,  0.025, -0.045, -0.024, -0.003, -0.010,  0.013,
        -0.000, -0.009,  0.012, -0.002, -0.020,  0.045,  0.032,  0.015, -0.010,
         0.016,  0.032, -0.031, -0.038, -0.023, -0.007,  0.014, -0.023, -0.001,
         0.034, -0.009, -0.011,  0.002, -0.041,  0.007, -0.001,  0.005,  0.024,
        -0.005,  0.005,  0.006, -0.017, -0.009,  0.006, -0.003,  0.008, -0.012,
        -0.020, -0.013,  0.040,  0.035, -0.027, -0.016, -0.012,  0.012, -0.006,
         0.001, -0.004, -0.035, -0.003,  0.020,  0.020, -0.023,  0.035, -0.025,
         0.002, -0.003, -0.005, -0.018, -0.019,  0.001, -0.036,  0.004,  0.012,
         0.005,  0.007,  0.010, -0.009, -0.014,  0.002,  0.055,  0.011, -0.011,
        -0.031,  0.004, -0.009,  0.001, -0.035,  0.005, -0.007,  0.007,  0.009,
        -0.025], device='cuda:0')
s after update for 1 param tensor([1.732, 1.122, 1.674, 0.990, 1.459, 1.089, 1.297, 0.965, 1.846, 1.707,
        1.615, 1.897, 1.563, 1.988, 1.773, 1.819, 0.843, 1.351, 1.423, 1.099,
        1.458, 1.304, 0.972, 2.025, 1.699, 1.200, 0.933, 1.038, 1.266, 1.467,
        1.757, 1.480, 1.464, 1.572, 2.343, 0.782, 1.776, 1.781, 1.341, 1.447,
        1.424, 0.989, 0.185, 1.568, 1.701, 2.022, 1.102, 0.586, 1.193, 1.510,
        1.136, 1.059, 1.838, 0.646, 1.496, 1.328, 1.172, 1.909, 1.700, 1.121,
        1.495, 1.026, 1.575, 1.780, 2.115, 2.057, 0.696, 1.332, 1.039, 1.350,
        1.373, 1.158, 0.035, 1.689, 1.132, 1.444, 1.016, 1.705, 1.974, 1.021,
        1.828, 1.070, 0.640, 1.501, 0.454, 1.167, 0.342, 1.518, 1.052, 2.052,
        1.967, 0.918, 1.962, 1.596, 1.699, 1.143, 1.422, 1.484, 1.421, 1.476],
       device='cuda:0')
b after update for 1 param tensor([58.264, 46.889, 57.277, 44.038, 53.467, 46.194, 50.409, 43.487, 60.151,
        57.830, 56.250, 60.964, 55.346, 62.423, 58.948, 59.698, 40.656, 51.455,
        52.813, 46.410, 53.446, 50.555, 43.649, 62.991, 57.700, 48.502, 42.770,
        45.109, 49.807, 53.617, 58.687, 53.849, 53.568, 55.499, 67.762, 39.150,
        59.003, 59.085, 51.258, 53.260, 52.827, 44.032, 19.043, 55.427, 57.742,
        62.951, 46.478, 33.876, 48.344, 54.396, 47.180, 45.548, 60.013, 35.585,
        54.148, 51.017, 47.927, 61.164, 57.727, 46.862, 54.130, 44.845, 55.564,
        59.055, 64.374, 63.484, 36.940, 51.094, 45.128, 51.440, 51.874, 47.639,
         8.280, 57.531, 47.095, 53.203, 44.612, 57.810, 62.202, 44.723, 59.855,
        45.787, 35.401, 54.229, 29.818, 47.823, 25.905, 54.533, 45.406, 63.409,
        62.085, 42.420, 62.015, 55.927, 57.707, 47.330, 52.789, 53.929, 52.775,
        53.787], device='cuda:0')
clipping threshold 1.1096225036931595
a after update for 1 param tensor([[[-0.033],
         [ 0.002],
         [ 0.014],
         [ 0.009],
         [-0.036],
         [ 0.002],
         [ 0.006],
         [-0.016],
         [ 0.026],
         [ 0.012]],

        [[ 0.004],
         [ 0.012],
         [ 0.005],
         [-0.004],
         [-0.019],
         [-0.016],
         [-0.006],
         [ 0.002],
         [ 0.010],
         [-0.008]],

        [[-0.013],
         [-0.002],
         [-0.015],
         [-0.040],
         [-0.010],
         [ 0.003],
         [-0.007],
         [-0.003],
         [-0.005],
         [-0.025]],

        [[ 0.033],
         [ 0.023],
         [-0.009],
         [-0.025],
         [-0.005],
         [-0.012],
         [-0.029],
         [-0.000],
         [ 0.004],
         [ 0.002]],

        [[ 0.031],
         [ 0.008],
         [-0.026],
         [-0.020],
         [ 0.024],
         [ 0.048],
         [ 0.010],
         [-0.015],
         [-0.026],
         [ 0.011]],

        [[-0.007],
         [-0.005],
         [ 0.021],
         [-0.002],
         [-0.006],
         [ 0.028],
         [-0.012],
         [ 0.033],
         [-0.008],
         [-0.021]],

        [[ 0.006],
         [ 0.019],
         [ 0.044],
         [ 0.031],
         [-0.001],
         [ 0.002],
         [ 0.012],
         [ 0.018],
         [-0.010],
         [-0.005]],

        [[ 0.009],
         [ 0.001],
         [-0.010],
         [ 0.023],
         [-0.003],
         [ 0.000],
         [ 0.078],
         [ 0.010],
         [ 0.013],
         [-0.005]],

        [[ 0.004],
         [ 0.000],
         [ 0.013],
         [ 0.003],
         [ 0.021],
         [ 0.034],
         [-0.004],
         [ 0.038],
         [ 0.007],
         [-0.049]],

        [[ 0.014],
         [-0.007],
         [-0.012],
         [ 0.000],
         [-0.031],
         [ 0.035],
         [-0.016],
         [ 0.012],
         [-0.013],
         [-0.007]]], device='cuda:0')
s after update for 1 param tensor([[[1.865],
         [2.003],
         [2.011],
         [1.481],
         [1.668],
         [1.338],
         [1.753],
         [1.397],
         [1.661],
         [1.726]],

        [[1.602],
         [1.694],
         [1.772],
         [1.160],
         [1.048],
         [1.964],
         [2.032],
         [1.307],
         [1.627],
         [1.614]],

        [[1.296],
         [0.693],
         [1.922],
         [1.950],
         [1.775],
         [1.726],
         [0.908],
         [1.345],
         [1.165],
         [2.020]],

        [[1.733],
         [1.741],
         [1.386],
         [1.648],
         [0.217],
         [1.183],
         [1.833],
         [1.433],
         [1.335],
         [1.435]],

        [[1.300],
         [1.583],
         [1.705],
         [1.808],
         [1.425],
         [1.561],
         [1.144],
         [1.768],
         [1.573],
         [1.126]],

        [[1.427],
         [0.972],
         [1.081],
         [0.889],
         [1.966],
         [1.442],
         [1.201],
         [2.089],
         [0.997],
         [2.305]],

        [[1.367],
         [1.674],
         [1.659],
         [1.624],
         [1.369],
         [1.755],
         [2.097],
         [0.853],
         [1.174],
         [1.513]],

        [[1.538],
         [1.939],
         [1.826],
         [1.543],
         [1.727],
         [1.561],
         [2.014],
         [1.572],
         [1.100],
         [1.801]],

        [[1.144],
         [0.891],
         [1.658],
         [1.685],
         [1.650],
         [1.394],
         [0.795],
         [1.287],
         [0.999],
         [2.277]],

        [[1.565],
         [1.160],
         [0.941],
         [1.636],
         [2.136],
         [1.754],
         [0.661],
         [1.612],
         [1.694],
         [1.321]]], device='cuda:0')
b after update for 1 param tensor([[[60.449],
         [62.657],
         [62.779],
         [53.868],
         [57.180],
         [51.206],
         [58.612],
         [52.331],
         [57.052],
         [58.152]],

        [[56.036],
         [57.615],
         [58.923],
         [47.683],
         [45.322],
         [62.039],
         [63.107],
         [50.608],
         [56.466],
         [56.248]],

        [[50.398],
         [36.857],
         [61.374],
         [61.821],
         [58.973],
         [58.156],
         [42.183],
         [51.347],
         [47.781],
         [62.912]],

        [[58.282],
         [58.418],
         [52.108],
         [56.831],
         [20.645],
         [48.152],
         [59.931],
         [53.001],
         [51.149],
         [53.022]],

        [[50.482],
         [55.700],
         [57.801],
         [59.518],
         [52.843],
         [55.317],
         [47.350],
         [58.867],
         [55.523],
         [46.975]],

        [[52.877],
         [43.637],
         [46.031],
         [41.748],
         [62.064],
         [53.159],
         [48.521],
         [63.990],
         [44.191],
         [67.213]],

        [[51.756],
         [57.282],
         [57.023],
         [56.421],
         [51.799],
         [58.646],
         [64.104],
         [40.893],
         [47.965],
         [54.455]],

        [[54.893],
         [61.643],
         [59.814],
         [54.988],
         [58.181],
         [55.311],
         [62.831],
         [55.499],
         [46.433],
         [59.412]],

        [[47.352],
         [41.795],
         [57.010],
         [57.465],
         [56.858],
         [52.273],
         [39.483],
         [50.229],
         [44.254],
         [66.800]],

        [[55.377],
         [47.670],
         [42.953],
         [56.624],
         [64.695],
         [58.623],
         [35.989],
         [56.212],
         [57.626],
         [50.877]]], device='cuda:0')
clipping threshold 1.1096225036931595
a after update for 1 param tensor([[ 0.024],
        [-0.008],
        [ 0.001],
        [-0.008],
        [-0.027],
        [-0.002],
        [ 0.030],
        [ 0.022],
        [-0.015],
        [ 0.016]], device='cuda:0')
s after update for 1 param tensor([[1.942],
        [1.562],
        [0.955],
        [1.561],
        [1.525],
        [1.389],
        [2.137],
        [1.102],
        [1.578],
        [1.861]], device='cuda:0')
b after update for 1 param tensor([[61.686],
        [55.330],
        [43.269],
        [55.306],
        [54.674],
        [52.177],
        [64.710],
        [46.470],
        [55.617],
        [60.393]], device='cuda:0')
clipping threshold 1.1096225036931595
||w||^2 1.1152100093539408
exp ma of ||w||^2 1.7900760209022333
||w|| 1.0560350417263344
exp ma of ||w|| 1.2608437571638975
||w||^2 3.664262736566931
exp ma of ||w||^2 1.8281267570494484
||w|| 1.91422640681998
exp ma of ||w|| 1.2762581332821512
cuda
Objective function 12.20 = squared loss an data 10.24 + 0.5*rho*h**2 0.250065 + alpha*h 0.948247 + L2reg 0.71 + L1reg 0.06 ; SHD = 18 ; DAG True
Proportion of microbatches that were clipped  0.7705958971019212
iteration 1 in inner loop, alpha 13.408484983051135 rho 100.0 h 0.07071990294303632
1210
cuda
Objective function 14.45 = squared loss an data 10.24 + 0.5*rho*h**2 2.500652 + alpha*h 0.948247 + L2reg 0.71 + L1reg 0.06 ; SHD = 18 ; DAG True
||w||^2 42530710630.85194
exp ma of ||w||^2 61999682915.50742
||w|| 206229.75205059996
exp ma of ||w|| 223024.6533803896
||w||^2 95670.58351892538
exp ma of ||w||^2 3785124.560845051
||w|| 309.3066173215914
exp ma of ||w|| 846.3440686812772
||w||^2 1030.0306377341415
exp ma of ||w||^2 167819.54949088788
||w|| 32.094090386458085
exp ma of ||w|| 107.88391609919155
||w||^2 2.7350218771306527
exp ma of ||w||^2 1.6819569966119867
||w|| 1.6537901551075496
exp ma of ||w|| 1.2277004421193336
cuda
Objective function 11.70 = squared loss an data 10.19 + 0.5*rho*h**2 0.325985 + alpha*h 0.342368 + L2reg 0.78 + L1reg 0.06 ; SHD = 18 ; DAG True
Proportion of microbatches that were clipped  0.7694515306122449
iteration 2 in inner loop, alpha 13.408484983051135 rho 1000.0 h 0.025533710494018536
iteration 3 in outer loop, alpha = 38.942195477069674, rho = 1000.0, h = 0.025533710494018536
cuda
1210
cuda
Objective function 12.35 = squared loss an data 10.19 + 0.5*rho*h**2 0.325985 + alpha*h 0.994339 + L2reg 0.78 + L1reg 0.06 ; SHD = 18 ; DAG True
||w||^2 5316680796.428483
exp ma of ||w||^2 24867475285.718052
||w|| 72915.5730720707
exp ma of ||w|| 128283.65143694957
||w||^2 521546731.23202264
exp ma of ||w||^2 3977992259.6132817
||w|| 22837.397645791927
exp ma of ||w|| 50002.759777788444
||w||^2 0.3515756898825316
exp ma of ||w||^2 2.9057937636485347
||w|| 0.5929381838628135
exp ma of ||w|| 1.3647627212959161
||w||^2 1.1158280995538545
exp ma of ||w||^2 1.8426266286966653
||w|| 1.0563276478223291
exp ma of ||w|| 1.2833979640691027
||w||^2 0.9612153757839529
exp ma of ||w||^2 1.5854896677427226
||w|| 0.9804159197932033
exp ma of ||w|| 1.2058981195355962
cuda
Objective function 11.57 = squared loss an data 10.05 + 0.5*rho*h**2 0.092847 + alpha*h 0.530663 + L2reg 0.83 + L1reg 0.07 ; SHD = 16 ; DAG True
Proportion of microbatches that were clipped  0.7685230024213076
iteration 1 in inner loop, alpha 38.942195477069674 rho 1000.0 h 0.01362694774619655
1210
cuda
Objective function 12.41 = squared loss an data 10.05 + 0.5*rho*h**2 0.928469 + alpha*h 0.530663 + L2reg 0.83 + L1reg 0.07 ; SHD = 16 ; DAG True
||w||^2 1090006157272.2605
exp ma of ||w||^2 495568361816.23254
||w|| 1044033.5996854989
exp ma of ||w|| 571821.2399932012
||w||^2 33468220.42000058
exp ma of ||w||^2 86376565.99696514
||w|| 5785.172462425004
exp ma of ||w|| 6296.649982598368
||w||^2 745944.710551181
exp ma of ||w||^2 10924135.512801077
||w|| 863.680907830653
exp ma of ||w|| 2113.396731468894
||w||^2 94440.94162278059
exp ma of ||w||^2 3172255.187800487
||w|| 307.3124495082823
exp ma of ||w|| 1023.3504991698616
||w||^2 39937.67989319495
exp ma of ||w||^2 500105.93712956633
||w|| 199.84413900136013
exp ma of ||w|| 319.5303806260057
||w||^2 3162.5151296069644
exp ma of ||w||^2 204927.21649263398
||w|| 56.23624391446289
exp ma of ||w|| 175.18467998337434
||w||^2 1.003235507747076
exp ma of ||w||^2 1.7271299076985434
||w|| 1.0016164474224034
exp ma of ||w|| 1.2462612992695188
||w||^2 1.0539907989118245
exp ma of ||w||^2 1.4588741600395727
||w|| 1.0266405402631558
exp ma of ||w|| 1.1538523252874189
||w||^2 0.7892944645032627
exp ma of ||w||^2 1.4431272687490888
||w|| 0.8884224583514662
exp ma of ||w|| 1.1565381845491716
cuda
Objective function 10.95 = squared loss an data 9.63 + 0.5*rho*h**2 0.166531 + alpha*h 0.224742 + L2reg 0.87 + L1reg 0.07 ; SHD = 15 ; DAG True
Proportion of microbatches that were clipped  0.7701240852688515
iteration 2 in inner loop, alpha 38.942195477069674 rho 10000.0 h 0.005771160729270974
iteration 4 in outer loop, alpha = 96.65380276977942, rho = 10000.0, h = 0.005771160729270974
cuda
1210
cuda
Objective function 11.29 = squared loss an data 9.63 + 0.5*rho*h**2 0.166531 + alpha*h 0.557805 + L2reg 0.87 + L1reg 0.07 ; SHD = 15 ; DAG True
||w||^2 424513.56316797284
exp ma of ||w||^2 16594666.991666902
||w|| 651.5470536868177
exp ma of ||w|| 1962.5964364232227
||w||^2 105777.09157093601
exp ma of ||w||^2 8476360.008956008
||w|| 325.233902862134
exp ma of ||w|| 1321.2600570997774
||w||^2 11.809380877439947
exp ma of ||w||^2 3917.3313896050904
||w|| 3.4364779756954573
exp ma of ||w|| 6.567994708399144
||w||^2 3.8873474809240487
exp ma of ||w||^2 207.68041205517383
||w|| 1.9716357373825544
exp ma of ||w|| 2.111422669035328
||w||^2 0.687586012191578
exp ma of ||w||^2 1.5058646220363257
||w|| 0.829208063269755
exp ma of ||w|| 1.1671775212999123
||w||^2 0.35418703500877496
exp ma of ||w||^2 1.5296245718176267
||w|| 0.5951361482961482
exp ma of ||w|| 1.1915033317501358
||w||^2 0.8831749115159228
exp ma of ||w||^2 1.3633738233211166
||w|| 0.9397738619029169
exp ma of ||w|| 1.1226763218075155
cuda
Objective function 10.83 = squared loss an data 9.42 + 0.5*rho*h**2 0.068348 + alpha*h 0.357353 + L2reg 0.91 + L1reg 0.07 ; SHD = 14 ; DAG True
Proportion of microbatches that were clipped  0.7645623169541165
iteration 1 in inner loop, alpha 96.65380276977942 rho 10000.0 h 0.003697243959818408
1210
cuda
Objective function 11.45 = squared loss an data 9.42 + 0.5*rho*h**2 0.683481 + alpha*h 0.357353 + L2reg 0.91 + L1reg 0.07 ; SHD = 14 ; DAG True
||w||^2 11356771358.300488
exp ma of ||w||^2 6667080063468.31
||w|| 106568.15358398815
exp ma of ||w|| 871702.0393331544
||w||^2 1090.550521072312
exp ma of ||w||^2 30528762.871375322
||w|| 33.02348438721014
exp ma of ||w|| 116.45464530248861
||w||^2 1.567572971728171
exp ma of ||w||^2 1.46676653686241
||w|| 1.2520275443168856
exp ma of ||w|| 1.170418683279282
cuda
Objective function 10.64 = squared loss an data 9.32 + 0.5*rho*h**2 0.154836 + alpha*h 0.170086 + L2reg 0.93 + L1reg 0.07 ; SHD = 14 ; DAG True
Proportion of microbatches that were clipped  0.7655072928353903
iteration 2 in inner loop, alpha 96.65380276977942 rho 100000.0 h 0.0017597485884426334
iteration 5 in outer loop, alpha = 1856.4023912124126, rho = 1000000.0, h = 0.0017597485884426334
Threshold 0.3
[[0.009 0.006 0.057 0.002 0.183 0.009 0.731 0.004 0.006 0.02 ]
 [0.816 0.006 0.732 0.033 0.402 0.064 0.656 0.425 0.201 0.975]
 [0.082 0.005 0.006 0.003 0.046 0.017 0.697 0.01  0.006 0.02 ]
 [0.795 0.18  0.601 0.004 0.682 0.304 0.586 0.236 2.013 2.258]
 [0.034 0.008 0.121 0.003 0.005 0.005 0.089 0.025 0.006 0.007]
 [0.534 0.084 0.235 0.013 0.51  0.004 0.426 0.077 0.069 1.155]
 [0.01  0.005 0.009 0.002 0.118 0.006 0.009 0.008 0.004 0.008]
 [0.724 0.013 0.673 0.022 0.261 0.06  0.299 0.005 0.21  0.119]
 [1.27  0.019 1.129 0.003 0.747 0.056 0.782 0.03  0.006 0.273]
 [0.304 0.005 0.381 0.002 0.655 0.004 1.157 0.062 0.02  0.004]]
[[0.    0.    0.    0.    0.    0.    0.731 0.    0.    0.   ]
 [0.816 0.    0.732 0.    0.402 0.    0.656 0.425 0.    0.975]
 [0.    0.    0.    0.    0.    0.    0.697 0.    0.    0.   ]
 [0.795 0.    0.601 0.    0.682 0.304 0.586 0.    2.013 2.258]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.534 0.    0.    0.    0.51  0.    0.426 0.    0.    1.155]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.724 0.    0.673 0.    0.    0.    0.    0.    0.    0.   ]
 [1.27  0.    1.129 0.    0.747 0.    0.782 0.    0.    0.   ]
 [0.304 0.    0.381 0.    0.655 0.    1.157 0.    0.    0.   ]]
{'fdr': 0.2413793103448276, 'tpr': 0.7333333333333333, 'fpr': 0.4666666666666667, 'f1': 0.7457627118644068, 'shd': 14, 'npred': 29, 'ntrue': 30}
[6.226e-03 5.737e-02 2.295e-03 1.830e-01 9.175e-03 7.314e-01 3.854e-03
 5.625e-03 1.994e-02 8.162e-01 7.325e-01 3.280e-02 4.015e-01 6.379e-02
 6.564e-01 4.252e-01 2.014e-01 9.746e-01 8.164e-02 5.241e-03 3.109e-03
 4.646e-02 1.688e-02 6.965e-01 9.570e-03 5.798e-03 2.026e-02 7.947e-01
 1.796e-01 6.007e-01 6.824e-01 3.037e-01 5.857e-01 2.364e-01 2.013e+00
 2.258e+00 3.352e-02 7.988e-03 1.212e-01 2.560e-03 5.400e-03 8.895e-02
 2.531e-02 5.763e-03 7.134e-03 5.345e-01 8.353e-02 2.347e-01 1.261e-02
 5.099e-01 4.261e-01 7.733e-02 6.886e-02 1.155e+00 1.039e-02 4.855e-03
 8.679e-03 2.007e-03 1.180e-01 6.050e-03 8.317e-03 3.596e-03 7.881e-03
 7.243e-01 1.311e-02 6.730e-01 2.196e-02 2.614e-01 6.016e-02 2.992e-01
 2.097e-01 1.188e-01 1.270e+00 1.883e-02 1.129e+00 2.874e-03 7.472e-01
 5.644e-02 7.822e-01 2.983e-02 2.726e-01 3.043e-01 4.826e-03 3.807e-01
 1.882e-03 6.554e-01 3.843e-03 1.157e+00 6.248e-02 2.015e-02]
[[0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [1. 0. 1. 0. 1. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [1. 1. 1. 0. 1. 1. 0. 0. 0. 0.]
 [1. 0. 1. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 1. 0. 1. 0. 0. 0.]]
[0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0.
 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.]
aucroc, aucpr (0.9083333333333333, 0.8521433528266594)
Iterations 630
Achieves (14.15454886112812, 1e-05)-DP
