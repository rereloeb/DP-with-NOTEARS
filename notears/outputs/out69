samples  5000  graph  15 30 ER mlp  minibatch size  75  noise  0.5  minibatches per NN training  111 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.3401316691164595
iteration 1 in outer loop, alpha = 1.3401316691164595, rho = 1.0, h = 1.3401316691164595
cuda
iteration 1 in inner loop,alpha 1.3401316691164595 rho 1.0 h 0.8741315174292428
iteration 2 in inner loop,alpha 1.3401316691164595 rho 10.0 h 0.38347274229216843
iteration 3 in inner loop,alpha 1.3401316691164595 rho 100.0 h 0.13357487921889089
iteration 2 in outer loop, alpha = 14.697619591005548, rho = 100.0, h = 0.13357487921889089
cuda
iteration 1 in inner loop,alpha 14.697619591005548 rho 100.0 h 0.06991993740608571
iteration 2 in inner loop,alpha 14.697619591005548 rho 1000.0 h 0.02592698775515956
iteration 3 in outer loop, alpha = 40.62460734616511, rho = 1000.0, h = 0.02592698775515956
cuda
iteration 1 in inner loop,alpha 40.62460734616511 rho 1000.0 h 0.016465661543334065
iteration 2 in inner loop,alpha 40.62460734616511 rho 10000.0 h 0.006583550827196305
iteration 3 in inner loop,alpha 40.62460734616511 rho 100000.0 h 0.0011537970975332712
iteration 4 in outer loop, alpha = 156.00431709949223, rho = 100000.0, h = 0.0011537970975332712
cuda
iteration 1 in inner loop,alpha 156.00431709949223 rho 100000.0 h 0.00033575511004180214
iteration 5 in outer loop, alpha = 491.7594271412944, rho = 1000000.0, h = 0.00033575511004180214
Threshold 0.3
[[0.002 0.    0.    0.005 0.194 0.    0.    0.    0.    2.734 0.179 0.001
  0.001 0.    0.006]
 [2.52  0.001 0.002 0.262 0.215 0.01  0.01  0.001 0.002 2.189 0.199 1.342
  0.001 0.001 0.098]
 [0.027 0.068 0.001 0.147 0.166 0.035 0.137 0.001 0.067 0.125 0.135 0.162
  0.001 0.001 0.006]
 [0.153 0.    0.001 0.001 0.204 0.    0.    0.    0.    0.214 0.335 0.001
  0.    0.    1.022]
 [0.    0.    0.    0.    0.004 0.    0.    0.    0.    0.    0.002 0.
  0.    0.    0.001]
 [2.646 0.03  0.001 0.968 0.376 0.001 1.377 0.    0.055 1.746 0.956 1.472
  0.012 0.002 1.923]
 [0.414 0.044 0.    0.336 0.408 0.    0.001 0.    0.059 0.139 1.162 0.096
  0.001 0.    0.163]
 [2.69  0.002 0.    2.092 0.137 0.612 0.046 0.    0.003 0.313 0.139 0.061
  0.014 0.022 0.118]
 [0.103 0.383 0.002 0.638 0.415 0.002 0.001 0.001 0.003 2.308 1.722 1.03
  0.    0.    0.367]
 [0.    0.    0.    0.    2.722 0.    0.001 0.    0.    0.002 0.402 0.001
  0.    0.    0.002]
 [0.001 0.    0.    0.001 3.057 0.    0.001 0.    0.001 0.001 0.015 0.
  0.    0.    0.005]
 [0.37  0.    0.    0.18  0.153 0.    0.004 0.    0.002 0.427 0.58  0.001
  0.    0.001 0.032]
 [0.041 0.078 0.    0.112 3.047 0.017 0.008 0.    1.212 0.107 1.585 0.031
  0.001 0.016 0.021]
 [0.126 1.398 0.    1.127 1.231 0.003 0.006 0.    3.368 0.386 0.434 0.158
  0.011 0.002 0.562]
 [0.089 0.    0.    0.    0.111 0.    0.    0.    0.    0.106 0.081 0.002
  0.004 0.    0.001]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    2.734 0.    0.
  0.    0.    0.   ]
 [2.52  0.    0.    0.    0.    0.    0.    0.    0.    2.189 0.    1.342
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.335 0.
  0.    0.    1.022]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [2.646 0.    0.    0.968 0.376 0.    1.377 0.    0.    1.746 0.956 1.472
  0.    0.    1.923]
 [0.414 0.    0.    0.336 0.408 0.    0.    0.    0.    0.    1.162 0.
  0.    0.    0.   ]
 [2.69  0.    0.    2.092 0.    0.612 0.    0.    0.    0.313 0.    0.
  0.    0.    0.   ]
 [0.    0.383 0.    0.638 0.415 0.    0.    0.    0.    2.308 1.722 1.03
  0.    0.    0.367]
 [0.    0.    0.    0.    2.722 0.    0.    0.    0.    0.    0.402 0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    3.057 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.37  0.    0.    0.    0.    0.    0.    0.    0.    0.427 0.58  0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    3.047 0.    0.    0.    1.212 0.    1.585 0.
  0.    0.    0.   ]
 [0.    1.398 0.    1.127 1.231 0.    0.    0.    3.368 0.386 0.434 0.
  0.    0.    0.562]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]]
{'fdr': 0.35555555555555557, 'tpr': 0.9666666666666667, 'fpr': 0.21333333333333335, 'f1': 0.7733333333333333, 'shd': 17, 'npred': 45, 'ntrue': 30}
[7.166e-05 3.031e-04 4.737e-03 1.942e-01 6.655e-05 2.207e-04 4.993e-05
 2.937e-04 2.734e+00 1.793e-01 5.105e-04 1.050e-03 1.242e-04 5.740e-03
 2.520e+00 1.954e-03 2.620e-01 2.147e-01 9.724e-03 9.801e-03 9.328e-04
 1.620e-03 2.189e+00 1.994e-01 1.342e+00 5.488e-04 9.886e-04 9.781e-02
 2.679e-02 6.849e-02 1.472e-01 1.660e-01 3.508e-02 1.368e-01 5.716e-04
 6.687e-02 1.254e-01 1.352e-01 1.619e-01 8.477e-04 1.272e-03 6.092e-03
 1.532e-01 1.509e-04 9.882e-04 2.036e-01 4.044e-05 3.897e-04 2.489e-04
 6.858e-05 2.135e-01 3.353e-01 1.155e-03 4.106e-04 1.293e-04 1.022e+00
 6.064e-05 4.791e-06 5.172e-05 2.471e-04 1.136e-05 1.928e-04 4.191e-06
 2.163e-04 3.383e-04 1.833e-03 1.007e-04 2.631e-05 7.614e-05 1.086e-03
 2.646e+00 3.009e-02 1.478e-03 9.684e-01 3.765e-01 1.377e+00 1.229e-04
 5.513e-02 1.746e+00 9.560e-01 1.472e+00 1.180e-02 1.838e-03 1.923e+00
 4.141e-01 4.437e-02 3.959e-04 3.360e-01 4.079e-01 4.254e-04 5.935e-05
 5.872e-02 1.392e-01 1.162e+00 9.588e-02 6.731e-04 4.063e-04 1.632e-01
 2.690e+00 2.126e-03 4.852e-04 2.092e+00 1.369e-01 6.121e-01 4.646e-02
 3.330e-03 3.125e-01 1.385e-01 6.062e-02 1.448e-02 2.181e-02 1.178e-01
 1.034e-01 3.829e-01 2.017e-03 6.383e-01 4.147e-01 2.074e-03 1.394e-03
 1.328e-03 2.308e+00 1.722e+00 1.030e+00 5.492e-05 3.972e-04 3.674e-01
 1.834e-04 4.607e-06 8.949e-05 4.394e-04 2.722e+00 6.113e-06 8.992e-04
 1.147e-05 4.538e-04 4.020e-01 1.020e-03 1.265e-04 1.194e-04 2.179e-03
 6.634e-04 5.288e-05 3.430e-04 1.176e-03 3.057e+00 1.252e-04 7.885e-04
 1.415e-04 9.900e-04 8.589e-04 1.728e-04 2.153e-04 3.103e-04 5.194e-03
 3.696e-01 4.210e-04 8.175e-05 1.805e-01 1.529e-01 2.371e-04 3.593e-03
 6.136e-05 1.729e-03 4.267e-01 5.799e-01 2.072e-04 6.430e-04 3.169e-02
 4.077e-02 7.764e-02 2.020e-04 1.125e-01 3.047e+00 1.651e-02 8.033e-03
 3.454e-04 1.212e+00 1.069e-01 1.585e+00 3.144e-02 1.628e-02 2.119e-02
 1.264e-01 1.398e+00 2.136e-04 1.127e+00 1.231e+00 3.196e-03 6.293e-03
 3.254e-04 3.368e+00 3.864e-01 4.339e-01 1.576e-01 1.130e-02 5.624e-01
 8.923e-02 3.157e-04 3.306e-04 7.760e-05 1.109e-01 7.500e-05 1.536e-04
 2.248e-04 2.530e-04 1.060e-01 8.126e-02 2.152e-03 4.216e-03 1.418e-04]
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.]
 [0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.9805555555555556, 0.9709424613206593)
cuda
2565
cuda
Objective function 454.76 = squared loss an data 233.99 + 0.5*rho*h**2 220.188202 + alpha*h 0.000000 + L2reg 0.28 + L1reg 0.30 ; SHD = 120 ; DAG False
||w||^2 0.20759553424887284
exp ma of ||w||^2 9189.029683773799
||w|| 0.45562652935147757
exp ma of ||w|| 0.47879541692164834
||w||^2 0.23704184024707786
exp ma of ||w||^2 4829.823407440734
||w|| 0.48686942833482355
exp ma of ||w|| 0.467662424038217
||w||^2 0.14477091613916776
exp ma of ||w||^2 45.76368509090847
||w|| 0.38048773454497553
exp ma of ||w|| 0.43523678032377805
||w||^2 0.1024042681735714
exp ma of ||w||^2 0.2629021517382386
||w|| 0.32000666895171326
exp ma of ||w|| 0.4836690831148732
||w||^2 0.3300695292377338
exp ma of ||w||^2 0.24921965393940507
||w|| 0.574516778900089
exp ma of ||w|| 0.47693225877079826
||w||^2 0.1386721257391031
exp ma of ||w||^2 0.2944576462120529
||w|| 0.3723870644089334
exp ma of ||w|| 0.49784798499016847
||w||^2 0.2902817730357466
exp ma of ||w||^2 0.34382791235256815
||w|| 0.5387780368906537
exp ma of ||w|| 0.5426668790236735
||w||^2 0.2038326440449182
exp ma of ||w||^2 0.5673847461337586
||w|| 0.4514782874567925
exp ma of ||w|| 0.6890991139751312
||w||^2 0.12568122425912306
exp ma of ||w||^2 0.553181703967429
||w|| 0.3545154781657961
exp ma of ||w|| 0.6983931396316183
cuda
Objective function 21.89 = squared loss an data 19.97 + 0.5*rho*h**2 1.328404 + alpha*h 0.000000 + L2reg 0.44 + L1reg 0.15 ; SHD = 50 ; DAG False
Proportion of microbatches that were clipped  0.7554009520322227
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 1.6299716741383001
iteration 1 in outer loop, alpha = 1.6299716741383001, rho = 1.0, h = 1.6299716741383001
cuda
2565
cuda
Objective function 24.54 = squared loss an data 19.97 + 0.5*rho*h**2 1.328404 + alpha*h 2.656808 + L2reg 0.44 + L1reg 0.15 ; SHD = 50 ; DAG False
||w||^2 7312082912.334855
exp ma of ||w||^2 29281038473.821354
||w|| 85510.71811378299
exp ma of ||w|| 150242.49267112507
||w||^2 104743411787.94818
exp ma of ||w||^2 20136803010.720623
||w|| 323640.86853787204
exp ma of ||w|| 121932.6525945027
||w||^2 5297491563.432652
exp ma of ||w||^2 16777314579.296412
||w|| 72783.8688407854
exp ma of ||w|| 112748.19541047899
||w||^2 11849.9765356139
exp ma of ||w||^2 2396761.331061702
||w|| 108.85759750983806
exp ma of ||w|| 536.3811992270076
||w||^2 1.2238877545430182
exp ma of ||w||^2 0.5400883768591582
||w|| 1.1062946056738314
exp ma of ||w|| 0.6898249642529602
||w||^2 0.178019233590411
exp ma of ||w||^2 0.570218193143122
||w|| 0.4219232555695538
exp ma of ||w|| 0.7045352692658872
||w||^2 0.1417693495213762
exp ma of ||w||^2 0.548238387977984
||w|| 0.376522707842935
exp ma of ||w|| 0.6986177761217526
||w||^2 2.007751151874544
exp ma of ||w||^2 0.6490338660237974
||w|| 1.416951358330463
exp ma of ||w|| 0.7453955177794065
||w||^2 2.496883848733824
exp ma of ||w||^2 0.6890664060437767
||w|| 1.5801531092694228
exp ma of ||w|| 0.7820409659781437
||w||^2 0.23002091175176972
exp ma of ||w||^2 0.5893637833957485
||w|| 0.4796049538440671
exp ma of ||w|| 0.7171145779702779
cuda
Objective function 14.16 = squared loss an data 11.40 + 0.5*rho*h**2 0.411265 + alpha*h 1.478278 + L2reg 0.74 + L1reg 0.13 ; SHD = 40 ; DAG False
Proportion of microbatches that were clipped  0.7584431137724551
iteration 1 in inner loop, alpha 1.6299716741383001 rho 1.0 h 0.9069347246652768
2565
cuda
Objective function 17.86 = squared loss an data 11.40 + 0.5*rho*h**2 4.112653 + alpha*h 1.478278 + L2reg 0.74 + L1reg 0.13 ; SHD = 40 ; DAG False
||w||^2 69687146558.6826
exp ma of ||w||^2 71448719487.36853
||w|| 263983.23158617975
exp ma of ||w|| 210313.29007466728
||w||^2 58.6767188416275
exp ma of ||w||^2 218811.27583492047
||w|| 7.660073031089684
exp ma of ||w|| 73.98058940253733
||w||^2 0.2402905132150558
exp ma of ||w||^2 18.376018259973115
||w|| 0.49019436269204053
exp ma of ||w|| 0.7096629372362583
||w||^2 0.4855103292305876
exp ma of ||w||^2 6.317124673937022
||w|| 0.6967857125620385
exp ma of ||w|| 0.7179892659410811
||w||^2 0.27666623114295463
exp ma of ||w||^2 0.7073409734981009
||w|| 0.5259907139322467
exp ma of ||w|| 0.7690882198895189
||w||^2 0.9401799448697429
exp ma of ||w||^2 0.7264449115492911
||w|| 0.9696287665234272
exp ma of ||w|| 0.805847909078503
||w||^2 0.5444283811089148
exp ma of ||w||^2 0.7569351766072585
||w|| 0.737853902279384
exp ma of ||w|| 0.8097999636816475
||w||^2 0.32766020558732245
exp ma of ||w||^2 0.772936106703064
||w|| 0.5724161122708921
exp ma of ||w|| 0.8154095759751578
||w||^2 0.35628274991699543
exp ma of ||w||^2 0.6997475917914903
||w|| 0.5968942535466357
exp ma of ||w|| 0.7751204715284449
cuda
Objective function 14.31 = squared loss an data 11.72 + 0.5*rho*h**2 0.862395 + alpha*h 0.676937 + L2reg 0.92 + L1reg 0.13 ; SHD = 32 ; DAG True
Proportion of microbatches that were clipped  0.7553256988055658
iteration 2 in inner loop, alpha 1.6299716741383001 rho 10.0 h 0.4153059726385955
2565
cuda
Objective function 22.07 = squared loss an data 11.72 + 0.5*rho*h**2 8.623953 + alpha*h 0.676937 + L2reg 0.92 + L1reg 0.13 ; SHD = 32 ; DAG True
||w||^2 107573181858.21724
exp ma of ||w||^2 101610275704.65373
||w|| 327983.50851562223
exp ma of ||w|| 272423.4058938416
||w||^2 284725216.1607645
exp ma of ||w||^2 1177032444.8659716
||w|| 16873.80265858187
exp ma of ||w|| 25399.59633834803
||w||^2 107667.6072710074
exp ma of ||w||^2 10575843.56744472
||w|| 328.127425356381
exp ma of ||w|| 1270.7220558542986
||w||^2 0.32213940679341607
exp ma of ||w||^2 0.8976482804990857
||w|| 0.5675732611684734
exp ma of ||w|| 0.8642479897648718
||w||^2 2.464015238362153
exp ma of ||w||^2 0.9763360698909507
||w|| 1.569718203488178
exp ma of ||w|| 0.907295089438185
||w||^2 0.6732870895472464
exp ma of ||w||^2 0.9785869930753356
||w|| 0.8205407299745981
exp ma of ||w|| 0.9184479454368675
||w||^2 0.3409773750284153
exp ma of ||w||^2 0.9126314887339143
||w|| 0.583932680219574
exp ma of ||w|| 0.8808847111126924
||w||^2 0.7265798245220558
exp ma of ||w||^2 0.8136924508311147
||w|| 0.852396518365752
exp ma of ||w|| 0.8435551041335032
||w||^2 0.6443558018764904
exp ma of ||w||^2 0.8605980903823326
||w|| 0.8027177597863961
exp ma of ||w|| 0.8622518489764536
||w||^2 1.041161238619156
exp ma of ||w||^2 0.9941408384923549
||w|| 1.0203730879532036
exp ma of ||w|| 0.8998133887530747
||w||^2 0.3573284207069155
exp ma of ||w||^2 0.8450520174036746
||w|| 0.597769538122273
exp ma of ||w|| 0.8581277822806834
cuda
Objective function 15.53 = squared loss an data 13.18 + 0.5*rho*h**2 0.960715 + alpha*h 0.225940 + L2reg 1.04 + L1reg 0.12 ; SHD = 26 ; DAG True
Proportion of microbatches that were clipped  0.7620598166907863
iteration 3 in inner loop, alpha 1.6299716741383001 rho 100.0 h 0.1386156612509346
iteration 2 in outer loop, alpha = 15.49153779923176, rho = 100.0, h = 0.1386156612509346
cuda
2565
cuda
Objective function 17.45 = squared loss an data 13.18 + 0.5*rho*h**2 0.960715 + alpha*h 2.147370 + L2reg 1.04 + L1reg 0.12 ; SHD = 26 ; DAG True
||w||^2 0.6704922612424549
exp ma of ||w||^2 18.72539859013598
||w|| 0.8188359183880827
exp ma of ||w|| 0.925586713491881
||w||^2 0.8044510481501507
exp ma of ||w||^2 5.8511673584864425
||w|| 0.8969119511692052
exp ma of ||w|| 0.9261098431954429
||w||^2 0.8177272452182388
exp ma of ||w||^2 1.0064757687573413
||w|| 0.9042827241622162
exp ma of ||w|| 0.9331071733231612
||w||^2 1.310408039913219
exp ma of ||w||^2 1.0760091190962324
||w|| 1.1447305534112466
exp ma of ||w|| 0.9455525637991234
||w||^2 0.3182825247041772
exp ma of ||w||^2 1.099499748644879
||w|| 0.5641653345466887
exp ma of ||w|| 0.9530641699638529
||w||^2 1.1122790761669048
exp ma of ||w||^2 1.1371177892066404
||w|| 1.0546464223458518
exp ma of ||w|| 0.9607628314786741
||w||^2 0.6073008985284816
exp ma of ||w||^2 1.205730070658358
||w|| 0.7792951292857422
exp ma of ||w|| 0.9760263035324475
||w||^2 0.6527973169625634
exp ma of ||w||^2 1.155341746301802
||w|| 0.8079587346904317
exp ma of ||w|| 0.976144795923614
||w||^2 0.443337799032944
exp ma of ||w||^2 1.1014428123500417
||w|| 0.6658361653086621
exp ma of ||w|| 0.9691453355187805
cuda
Objective function 16.10 = squared loss an data 13.21 + 0.5*rho*h**2 0.345718 + alpha*h 1.288161 + L2reg 1.14 + L1reg 0.12 ; SHD = 31 ; DAG True
Proportion of microbatches that were clipped  0.7594859241126071
iteration 1 in inner loop, alpha 15.49153779923176 rho 100.0 h 0.08315258273805703
2565
cuda
Objective function 19.22 = squared loss an data 13.21 + 0.5*rho*h**2 3.457176 + alpha*h 1.288161 + L2reg 1.14 + L1reg 0.12 ; SHD = 31 ; DAG True
||w||^2 141191397702.91672
exp ma of ||w||^2 153105451186.4043
||w|| 375754.438034891
exp ma of ||w|| 344503.254590443
||w||^2 11390564465.699493
exp ma of ||w||^2 82510298642.3361
||w|| 106726.58743583763
exp ma of ||w|| 245428.89990700985
||w||^2 7170075506.099367
exp ma of ||w||^2 64818030376.65878
||w|| 84676.2983726814
exp ma of ||w|| 218050.83955469125
||w||^2 2229718420.012384
exp ma of ||w||^2 12713446971.811085
||w|| 47219.89432445168
exp ma of ||w|| 86726.45820964556
||w||^2 59.851969276147265
exp ma of ||w||^2 325842.9644288089
||w|| 7.736405449312184
exp ma of ||w|| 55.07868015295605
||w||^2 8.877709490674823
exp ma of ||w||^2 106818.35227070152
||w|| 2.9795485380632454
exp ma of ||w|| 22.099955082566154
||w||^2 0.866009658918195
exp ma of ||w||^2 16.495723676049153
||w|| 0.9305963995837266
exp ma of ||w|| 1.0902974355702237
||w||^2 0.6495646989939549
exp ma of ||w||^2 0.9389589952604876
||w|| 0.8059557673929475
exp ma of ||w|| 0.9001947050264899
||w||^2 0.19086594310363808
exp ma of ||w||^2 1.0357446835770452
||w|| 0.4368820700184869
exp ma of ||w|| 0.9383682087797529
||w||^2 0.9890258769147785
exp ma of ||w||^2 0.9238733165301335
||w|| 0.9944978013624658
exp ma of ||w|| 0.8974155588196131
||w||^2 0.48083005546516366
exp ma of ||w||^2 1.1662560147981451
||w|| 0.6934191052063418
exp ma of ||w|| 0.9721178001014613
||w||^2 0.49785451288136345
exp ma of ||w||^2 1.1046141616106548
||w|| 0.7055880617480453
exp ma of ||w|| 0.9761671347046883
||w||^2 0.5826491762931281
exp ma of ||w||^2 1.1405681336646576
||w|| 0.7633145985064926
exp ma of ||w|| 0.9592701770357216
cuda
Objective function 16.00 = squared loss an data 13.66 + 0.5*rho*h**2 0.493513 + alpha*h 0.486697 + L2reg 1.23 + L1reg 0.12 ; SHD = 32 ; DAG True
Proportion of microbatches that were clipped  0.7659574468085106
iteration 2 in inner loop, alpha 15.49153779923176 rho 1000.0 h 0.03141697579031444
iteration 3 in outer loop, alpha = 46.9085135895462, rho = 1000.0, h = 0.03141697579031444
cuda
2565
cuda
Objective function 16.99 = squared loss an data 13.66 + 0.5*rho*h**2 0.493513 + alpha*h 1.473724 + L2reg 1.23 + L1reg 0.12 ; SHD = 32 ; DAG True
||w||^2 3.2991860628768106
exp ma of ||w||^2 1.0488710467405276
||w|| 1.816366169822817
exp ma of ||w|| 0.9330407565566404
||w||^2 1.2519707883001328
exp ma of ||w||^2 1.0688602195904633
||w|| 1.1189150049490502
exp ma of ||w|| 0.945163615808421
||w||^2 1.4222893388939442
exp ma of ||w||^2 0.9560947353092816
||w|| 1.1925977271879835
exp ma of ||w|| 0.9253481430620776
||w||^2 0.368958446219048
exp ma of ||w||^2 1.0269066295592584
||w|| 0.6074194977271046
exp ma of ||w|| 0.9379015679520675
||w||^2 0.19232555540343163
exp ma of ||w||^2 0.9615083569913838
||w|| 0.43854937624335033
exp ma of ||w|| 0.9216466167677652
||w||^2 0.7370113970781472
exp ma of ||w||^2 1.106212288369721
||w|| 0.8584936791136829
exp ma of ||w|| 0.9736675782139697
||w||^2 1.6902141990521244
exp ma of ||w||^2 1.007376017607557
||w|| 1.3000823816405345
exp ma of ||w|| 0.9302952378926008
||w||^2 1.4452653019066726
exp ma of ||w||^2 1.0328661594185475
||w|| 1.2021918739979374
exp ma of ||w|| 0.9522863493211531
||w||^2 0.5500428806490766
exp ma of ||w||^2 0.9779514950512496
||w|| 0.7416487582738048
exp ma of ||w|| 0.9255139087521262
||w||^2 1.1842631084930153
exp ma of ||w||^2 0.9783016646905828
||w|| 1.0882385347399786
exp ma of ||w|| 0.9235235354537961
cuda
Objective function 16.26 = squared loss an data 13.72 + 0.5*rho*h**2 0.181284 + alpha*h 0.893196 + L2reg 1.33 + L1reg 0.13 ; SHD = 32 ; DAG True
Proportion of microbatches that were clipped  0.7623438068664321
iteration 1 in inner loop, alpha 46.9085135895462 rho 1000.0 h 0.019041233433943816
2565
cuda
Objective function 17.89 = squared loss an data 13.72 + 0.5*rho*h**2 1.812843 + alpha*h 0.893196 + L2reg 1.33 + L1reg 0.13 ; SHD = 32 ; DAG True
||w||^2 70951488028.01971
exp ma of ||w||^2 194964144149.13086
||w|| 266367.2052412228
exp ma of ||w|| 285594.4088525334
||w||^2 0.9190313566691397
exp ma of ||w||^2 1.016841250354933
||w|| 0.9586612314416076
exp ma of ||w|| 0.9480362075882214
||w||^2 0.9709697889211841
exp ma of ||w||^2 0.9206885165089931
||w|| 0.9853779929149951
exp ma of ||w|| 0.9065148653240305
||w||^2 0.6560169424915585
exp ma of ||w||^2 1.0978500243763076
||w|| 0.8099487283103532
exp ma of ||w|| 0.9824422402849242
||w||^2 1.3082538691011216
exp ma of ||w||^2 0.9582661179015884
||w|| 1.1437892590425571
exp ma of ||w|| 0.9378281094519137
||w||^2 0.5080758888643598
exp ma of ||w||^2 1.0206830592432041
||w|| 0.7127944225822477
exp ma of ||w|| 0.9536269049704637
||w||^2 0.29536800973864247
exp ma of ||w||^2 1.0711858117340574
||w|| 0.5434776993940437
exp ma of ||w|| 0.9721096512114055
||w||^2 1.13940652886139
exp ma of ||w||^2 1.0073506984865601
||w|| 1.0674298706994245
exp ma of ||w|| 0.9483086688526968
||w||^2 1.6012932391793464
exp ma of ||w||^2 1.0103239452028796
||w|| 1.2654221584828307
exp ma of ||w|| 0.9334231259719734
||w||^2 1.5199726100210544
exp ma of ||w||^2 1.0585184926687217
||w|| 1.2328716924404803
exp ma of ||w|| 0.9507164449058129
||w||^2 1.2155737654700378
exp ma of ||w||^2 1.002716925110667
||w|| 1.102530618835612
exp ma of ||w|| 0.9388375866167372
cuda
Objective function 15.70 = squared loss an data 13.39 + 0.5*rho*h**2 0.381131 + alpha*h 0.409547 + L2reg 1.39 + L1reg 0.13 ; SHD = 33 ; DAG True
Proportion of microbatches that were clipped  0.7607391996083711
iteration 2 in inner loop, alpha 46.9085135895462 rho 10000.0 h 0.008730761622459227
2565
cuda
Objective function 19.13 = squared loss an data 13.39 + 0.5*rho*h**2 3.811310 + alpha*h 0.409547 + L2reg 1.39 + L1reg 0.13 ; SHD = 33 ; DAG True
||w||^2 788306174699.0184
exp ma of ||w||^2 467679124863.21985
||w|| 887866.0792591518
exp ma of ||w|| 472738.7225025282
||w||^2 13943647.929193098
exp ma of ||w||^2 199098120317.88724
||w|| 3734.1194315652383
exp ma of ||w|| 19307.294060461707
||w||^2 0.8195671267378561
exp ma of ||w||^2 0.9970843149713228
||w|| 0.9052994679871718
exp ma of ||w|| 0.9270190442827889
||w||^2 1.3710042763604782
exp ma of ||w||^2 1.041006312175641
||w|| 1.1708989180798137
exp ma of ||w|| 0.9379666565656197
||w||^2 0.5798392320003843
exp ma of ||w||^2 1.1908103834402173
||w|| 0.7614717539084325
exp ma of ||w|| 0.9825416990306485
||w||^2 0.570650662465114
exp ma of ||w||^2 1.139236554441894
||w|| 0.7554142323686481
exp ma of ||w|| 0.9717188847799844
cuda
Objective function 15.68 = squared loss an data 13.57 + 0.5*rho*h**2 0.430830 + alpha*h 0.137695 + L2reg 1.42 + L1reg 0.12 ; SHD = 33 ; DAG True
Proportion of microbatches that were clipped  0.76778166888057
iteration 3 in inner loop, alpha 46.9085135895462 rho 100000.0 h 0.0029354047545915307
iteration 4 in outer loop, alpha = 340.4489890486993, rho = 100000.0, h = 0.0029354047545915307
cuda
2565
cuda
Objective function 16.54 = squared loss an data 13.57 + 0.5*rho*h**2 0.430830 + alpha*h 0.999356 + L2reg 1.42 + L1reg 0.12 ; SHD = 33 ; DAG True
||w||^2 4127777815234.316
exp ma of ||w||^2 405236253477635.1
||w|| 2031693.336907496
exp ma of ||w|| 11745367.15531478
||w||^2 14318.548556672562
exp ma of ||w||^2 107140103006.97859
||w|| 119.6601377095671
exp ma of ||w|| 4933.792607895902
||w||^2 1.698358380444974
exp ma of ||w||^2 2489.820730745699
||w|| 1.303210796626921
exp ma of ||w|| 1.1848677472976301
||w||^2 0.5797943549005516
exp ma of ||w||^2 1.086311130161712
||w|| 0.7614422859945142
exp ma of ||w|| 0.9547006408529203
cuda
Objective function 15.92 = squared loss an data 13.53 + 0.5*rho*h**2 0.178056 + alpha*h 0.642459 + L2reg 1.46 + L1reg 0.12 ; SHD = 32 ; DAG True
Proportion of microbatches that were clipped  0.7640161231220227
iteration 1 in inner loop, alpha 340.4489890486993 rho 100000.0 h 0.0018870931758208087
iteration 5 in outer loop, alpha = 2227.542164869508, rho = 1000000.0, h = 0.0018870931758208087
Threshold 0.3
[[0.002 0.017 0.06  0.105 0.409 0.009 0.018 0.003 0.024 0.96  0.109 0.11
  0.008 0.008 0.051]
 [0.24  0.003 0.045 0.386 0.391 0.119 0.05  0.045 0.014 0.863 0.225 0.877
  0.039 0.004 0.167]
 [0.057 0.105 0.004 0.042 0.231 0.085 0.026 0.018 0.038 0.139 0.088 0.299
  0.024 0.009 0.042]
 [0.053 0.011 0.096 0.003 0.325 0.03  0.01  0.007 0.019 0.158 0.076 0.052
  0.014 0.006 0.16 ]
 [0.003 0.002 0.012 0.009 0.004 0.005 0.001 0.002 0.001 0.001 0.002 0.012
  0.001 0.    0.009]
 [0.571 0.03  0.053 0.177 0.428 0.002 0.006 0.029 0.06  0.429 0.221 0.787
  0.044 0.016 0.106]
 [0.301 0.109 0.147 0.479 0.38  0.378 0.004 0.151 0.097 0.329 1.265 0.243
  0.1   0.027 0.381]
 [1.161 0.094 0.209 0.757 0.64  0.193 0.03  0.004 0.169 0.551 0.23  0.597
  0.028 0.016 0.293]
 [0.144 0.289 0.083 0.271 0.418 0.062 0.052 0.024 0.004 1.161 1.069 0.749
  0.03  0.001 0.188]
 [0.003 0.005 0.02  0.023 1.918 0.004 0.011 0.004 0.008 0.004 0.085 0.115
  0.009 0.001 0.044]
 [0.032 0.018 0.028 0.065 2.309 0.014 0.005 0.017 0.003 0.044 0.005 0.019
  0.002 0.002 0.023]
 [0.029 0.003 0.015 0.061 0.241 0.004 0.018 0.006 0.005 0.035 0.174 0.003
  0.011 0.001 0.044]
 [0.377 0.115 0.145 0.272 1.444 0.106 0.031 0.079 0.167 0.274 1.395 0.346
  0.002 0.037 0.244]
 [0.437 0.761 0.344 0.767 0.622 0.25  0.184 0.301 2.43  0.976 0.479 0.681
  0.106 0.003 0.503]
 [0.049 0.026 0.083 0.031 0.33  0.048 0.011 0.018 0.025 0.08  0.148 0.054
  0.013 0.006 0.003]]
[[0.    0.    0.    0.    0.409 0.    0.    0.    0.    0.96  0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.386 0.391 0.    0.    0.    0.    0.863 0.    0.877
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.325 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.571 0.    0.    0.    0.428 0.    0.    0.    0.    0.429 0.    0.787
  0.    0.    0.   ]
 [0.301 0.    0.    0.479 0.38  0.378 0.    0.    0.    0.329 1.265 0.
  0.    0.    0.381]
 [1.161 0.    0.    0.757 0.64  0.    0.    0.    0.    0.551 0.    0.597
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.418 0.    0.    0.    0.    1.161 1.069 0.749
  0.    0.    0.   ]
 [0.    0.    0.    0.    1.918 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    2.309 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.377 0.    0.    0.    1.444 0.    0.    0.    0.    0.    1.395 0.346
  0.    0.    0.   ]
 [0.437 0.761 0.344 0.767 0.622 0.    0.    0.301 2.43  0.976 0.479 0.681
  0.    0.    0.503]
 [0.    0.    0.    0.    0.33  0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]]
{'fdr': 0.5333333333333333, 'tpr': 0.7, 'fpr': 0.32, 'f1': 0.56, 'shd': 32, 'npred': 45, 'ntrue': 30}
[1.738e-02 6.048e-02 1.053e-01 4.090e-01 8.799e-03 1.759e-02 2.776e-03
 2.351e-02 9.601e-01 1.089e-01 1.099e-01 8.162e-03 7.782e-03 5.074e-02
 2.399e-01 4.525e-02 3.858e-01 3.906e-01 1.195e-01 4.963e-02 4.526e-02
 1.381e-02 8.628e-01 2.249e-01 8.771e-01 3.939e-02 3.935e-03 1.674e-01
 5.662e-02 1.051e-01 4.181e-02 2.313e-01 8.543e-02 2.623e-02 1.761e-02
 3.807e-02 1.389e-01 8.766e-02 2.991e-01 2.412e-02 9.463e-03 4.210e-02
 5.269e-02 1.070e-02 9.584e-02 3.253e-01 3.049e-02 1.014e-02 6.530e-03
 1.888e-02 1.581e-01 7.615e-02 5.217e-02 1.379e-02 5.630e-03 1.603e-01
 2.969e-03 1.647e-03 1.229e-02 8.507e-03 5.165e-03 1.009e-03 1.578e-03
 1.208e-03 1.388e-03 2.017e-03 1.177e-02 6.558e-04 4.518e-04 9.351e-03
 5.711e-01 3.031e-02 5.323e-02 1.766e-01 4.278e-01 6.120e-03 2.939e-02
 5.972e-02 4.290e-01 2.212e-01 7.873e-01 4.363e-02 1.578e-02 1.056e-01
 3.008e-01 1.095e-01 1.474e-01 4.789e-01 3.804e-01 3.781e-01 1.512e-01
 9.656e-02 3.294e-01 1.265e+00 2.428e-01 9.976e-02 2.665e-02 3.806e-01
 1.161e+00 9.401e-02 2.090e-01 7.569e-01 6.395e-01 1.926e-01 2.967e-02
 1.689e-01 5.510e-01 2.300e-01 5.966e-01 2.838e-02 1.584e-02 2.930e-01
 1.436e-01 2.891e-01 8.315e-02 2.715e-01 4.183e-01 6.200e-02 5.195e-02
 2.448e-02 1.161e+00 1.069e+00 7.488e-01 2.958e-02 8.466e-04 1.881e-01
 3.143e-03 4.708e-03 1.955e-02 2.323e-02 1.918e+00 4.207e-03 1.075e-02
 3.882e-03 7.555e-03 8.545e-02 1.154e-01 8.607e-03 1.368e-03 4.360e-02
 3.228e-02 1.807e-02 2.849e-02 6.485e-02 2.309e+00 1.428e-02 4.568e-03
 1.747e-02 2.977e-03 4.392e-02 1.887e-02 2.188e-03 1.942e-03 2.277e-02
 2.935e-02 3.248e-03 1.482e-02 6.079e-02 2.407e-01 4.172e-03 1.785e-02
 5.692e-03 4.908e-03 3.537e-02 1.739e-01 1.107e-02 1.421e-03 4.351e-02
 3.770e-01 1.149e-01 1.446e-01 2.718e-01 1.444e+00 1.056e-01 3.058e-02
 7.876e-02 1.667e-01 2.739e-01 1.395e+00 3.464e-01 3.724e-02 2.442e-01
 4.372e-01 7.610e-01 3.443e-01 7.668e-01 6.222e-01 2.503e-01 1.844e-01
 3.007e-01 2.430e+00 9.761e-01 4.791e-01 6.811e-01 1.057e-01 5.031e-01
 4.864e-02 2.628e-02 8.317e-02 3.138e-02 3.305e-01 4.807e-02 1.131e-02
 1.830e-02 2.527e-02 8.009e-02 1.485e-01 5.440e-02 1.290e-02 5.863e-03]
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.]
 [0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.9011111111111111, 0.7587221668590453)
Iterations 1110
Achieves (23.82233853610087, 1e-05)-DP
