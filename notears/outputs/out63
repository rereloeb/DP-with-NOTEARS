samples  5000  graph  13 26 ER mlp  minibatch size  135  noise  0.5  minibatches per NN training  40 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.3261408551088962
iteration 1 in outer loop, alpha = 1.3261408551088962, rho = 1.0, h = 1.3261408551088962
cuda
iteration 1 in inner loop,alpha 1.3261408551088962 rho 1.0 h 0.8833022561168153
iteration 2 in inner loop,alpha 1.3261408551088962 rho 10.0 h 0.3976662043074768
iteration 3 in inner loop,alpha 1.3261408551088962 rho 100.0 h 0.14473978390051023
iteration 2 in outer loop, alpha = 15.80011924515992, rho = 100.0, h = 0.14473978390051023
cuda
iteration 1 in inner loop,alpha 15.80011924515992 rho 100.0 h 0.09206134723974557
iteration 2 in inner loop,alpha 15.80011924515992 rho 1000.0 h 0.03605103482185257
iteration 3 in outer loop, alpha = 51.85115406701249, rho = 1000.0, h = 0.03605103482185257
cuda
iteration 1 in inner loop,alpha 51.85115406701249 rho 1000.0 h 0.022520091840645406
iteration 2 in inner loop,alpha 51.85115406701249 rho 10000.0 h 0.007430766451431481
iteration 4 in outer loop, alpha = 126.1588185813273, rho = 10000.0, h = 0.007430766451431481
cuda
iteration 1 in inner loop,alpha 126.1588185813273 rho 10000.0 h 0.003895360748593646
iteration 2 in inner loop,alpha 126.1588185813273 rho 100000.0 h 0.0014426436570769141
iteration 5 in outer loop, alpha = 270.4231842890187, rho = 100000.0, h = 0.0014426436570769141
cuda
iteration 1 in inner loop,alpha 270.4231842890187 rho 100000.0 h 0.0007517413688127306
iteration 6 in outer loop, alpha = 1022.1645531017493, rho = 1000000.0, h = 0.0007517413688127306
Threshold 0.3
[[0.001 0.    0.182 2.554 0.627 0.004 0.017 0.    0.    0.42  0.    1.889
  0.   ]
 [0.631 0.001 0.321 0.047 0.17  0.003 0.04  0.    0.    2.069 0.001 0.202
  0.   ]
 [0.    0.    0.002 0.    0.    0.    0.001 0.    0.    0.    0.    0.
  0.   ]
 [0.    0.    2.684 0.001 0.105 0.001 0.09  0.    0.    1.533 0.    0.271
  0.   ]
 [0.    0.    0.258 0.    0.001 0.    0.001 0.    0.    0.    0.    0.
  0.   ]
 [0.081 0.032 0.334 0.067 0.601 0.001 0.013 0.    0.109 2.269 0.039 0.128
  0.007]
 [0.007 0.013 1.088 0.023 0.086 0.042 0.027 0.001 0.002 1.038 0.001 0.292
  0.004]
 [0.015 0.015 0.016 0.013 1.502 3.719 0.081 0.001 0.644 0.429 0.021 0.061
  0.023]
 [0.024 1.535 2.236 0.024 0.092 0.007 0.353 0.    0.    1.236 0.01  0.191
  0.011]
 [0.    0.    1.119 0.    0.247 0.    0.001 0.    0.    0.004 0.    2.344
  0.   ]
 [1.745 0.01  2.557 0.073 0.535 0.001 0.013 0.001 0.003 0.923 0.    0.091
  0.003]
 [0.    0.    0.943 0.    0.964 0.    0.001 0.    0.    0.    0.    0.001
  0.   ]
 [0.012 1.015 2.327 0.018 0.267 0.007 0.089 0.002 0.008 2.256 0.012 0.414
  0.   ]]
[[0.    0.    0.    2.554 0.627 0.    0.    0.    0.    0.42  0.    1.889
  0.   ]
 [0.631 0.    0.321 0.    0.    0.    0.    0.    0.    2.069 0.    0.
  0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.   ]
 [0.    0.    2.684 0.    0.    0.    0.    0.    0.    1.533 0.    0.
  0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.   ]
 [0.    0.    0.334 0.    0.601 0.    0.    0.    0.    2.269 0.    0.
  0.   ]
 [0.    0.    1.088 0.    0.    0.    0.    0.    0.    1.038 0.    0.
  0.   ]
 [0.    0.    0.    0.    1.502 3.719 0.    0.    0.644 0.429 0.    0.
  0.   ]
 [0.    1.535 2.236 0.    0.    0.    0.353 0.    0.    1.236 0.    0.
  0.   ]
 [0.    0.    1.119 0.    0.    0.    0.    0.    0.    0.    0.    2.344
  0.   ]
 [1.745 0.    2.557 0.    0.535 0.    0.    0.    0.    0.923 0.    0.
  0.   ]
 [0.    0.    0.943 0.    0.964 0.    0.    0.    0.    0.    0.    0.
  0.   ]
 [0.    1.015 2.327 0.    0.    0.    0.    0.    0.    2.256 0.    0.414
  0.   ]]
{'fdr': 0.4117647058823529, 'tpr': 0.7692307692307693, 'fpr': 0.2692307692307692, 'f1': 0.6666666666666667, 'shd': 16, 'npred': 34, 'ntrue': 26}
[2.612e-04 1.823e-01 2.554e+00 6.267e-01 4.178e-03 1.674e-02 1.431e-04
 1.087e-04 4.202e-01 2.580e-05 1.889e+00 1.419e-04 6.311e-01 3.207e-01
 4.685e-02 1.701e-01 3.202e-03 4.008e-02 3.474e-04 1.414e-04 2.069e+00
 1.106e-03 2.019e-01 1.166e-04 3.581e-05 1.505e-05 1.052e-04 2.101e-04
 3.524e-05 9.402e-04 5.824e-06 2.289e-05 1.969e-04 1.100e-05 1.926e-05
 1.605e-05 1.250e-04 6.256e-05 2.684e+00 1.053e-01 6.435e-04 8.972e-02
 1.858e-04 6.235e-05 1.533e+00 1.017e-05 2.707e-01 1.772e-04 3.405e-05
 4.132e-05 2.581e-01 1.605e-04 5.503e-05 1.470e-03 8.341e-06 3.488e-05
 2.259e-04 2.862e-05 3.030e-04 3.542e-05 8.051e-02 3.228e-02 3.338e-01
 6.715e-02 6.014e-01 1.289e-02 1.215e-04 1.092e-01 2.269e+00 3.906e-02
 1.279e-01 6.809e-03 7.346e-03 1.259e-02 1.088e+00 2.335e-02 8.627e-02
 4.178e-02 1.094e-03 2.454e-03 1.038e+00 6.815e-04 2.924e-01 4.152e-03
 1.548e-02 1.487e-02 1.583e-02 1.270e-02 1.502e+00 3.719e+00 8.144e-02
 6.436e-01 4.291e-01 2.099e-02 6.079e-02 2.307e-02 2.414e-02 1.535e+00
 2.236e+00 2.404e-02 9.160e-02 7.164e-03 3.531e-01 3.828e-04 1.236e+00
 1.015e-02 1.910e-01 1.101e-02 4.425e-05 1.122e-04 1.119e+00 1.254e-04
 2.466e-01 2.105e-04 9.388e-04 4.670e-05 3.317e-05 3.411e-05 2.344e+00
 3.333e-05 1.745e+00 9.961e-03 2.557e+00 7.250e-02 5.347e-01 8.176e-04
 1.315e-02 9.256e-04 2.938e-03 9.225e-01 9.095e-02 3.048e-03 1.786e-06
 5.745e-06 9.434e-01 3.976e-05 9.642e-01 8.964e-06 9.225e-04 1.627e-05
 4.578e-06 7.095e-05 3.375e-07 8.929e-07 1.153e-02 1.015e+00 2.327e+00
 1.764e-02 2.670e-01 6.502e-03 8.859e-02 1.641e-03 8.110e-03 2.256e+00
 1.183e-02 4.140e-01]
[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]
 [1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0.]
aucroc, aucpr (0.8642011834319527, 0.762143321258095)
cuda
1963
cuda
Objective function 480.43 = squared loss an data 285.64 + 0.5*rho*h**2 194.315677 + alpha*h 0.000000 + L2reg 0.24 + L1reg 0.24 ; SHD = 91 ; DAG False
||w||^2 1211762.0109011636
exp ma of ||w||^2 7188023933.7834835
||w|| 1100.8006226838554
exp ma of ||w|| 7514.879453262541
||w||^2 1769.5375317894436
exp ma of ||w||^2 644271949.1090165
||w|| 42.0658713423298
exp ma of ||w|| 764.1705561442326
||w||^2 0.8268244230282793
exp ma of ||w||^2 39940.46845358449
||w|| 0.9092988634262551
exp ma of ||w|| 1.201300437905471
||w||^2 0.6273161491333319
exp ma of ||w||^2 0.5034268445669525
||w|| 0.7920329217484157
exp ma of ||w|| 0.7028128321380416
||w||^2 0.38939708954967067
exp ma of ||w||^2 0.44647155900450747
||w|| 0.6240168984488086
exp ma of ||w|| 0.6621170763633641
||w||^2 0.3671251324877948
exp ma of ||w||^2 0.40329735174027376
||w|| 0.6059085182499044
exp ma of ||w|| 0.6288226981190127
cuda
Objective function 148.55 = squared loss an data 147.35 + 0.5*rho*h**2 0.971293 + alpha*h 0.000000 + L2reg 0.13 + L1reg 0.10 ; SHD = 36 ; DAG False
Proportion of microbatches that were clipped  0.7397845468053492
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 1.393766998937176
iteration 1 in outer loop, alpha = 1.393766998937176, rho = 1.0, h = 1.393766998937176
cuda
1963
cuda
Objective function 150.49 = squared loss an data 147.35 + 0.5*rho*h**2 0.971293 + alpha*h 1.942586 + L2reg 0.13 + L1reg 0.10 ; SHD = 36 ; DAG False
||w||^2 448638711.7942106
exp ma of ||w||^2 1996707562.1708765
||w|| 21181.093262487906
exp ma of ||w|| 35893.17277277521
||w||^2 3905228.641441516
exp ma of ||w||^2 10695200.470830694
||w|| 1976.1651351649527
exp ma of ||w|| 2529.4670667262744
||w||^2 21946.360960629394
exp ma of ||w||^2 576530.5990662234
||w|| 148.14304222821062
exp ma of ||w|| 517.0886294034686
||w||^2 0.41035760808959115
exp ma of ||w||^2 0.5726031731642396
||w|| 0.6405916078825816
exp ma of ||w|| 0.7429110327152406
||w||^2 0.6700581186187896
exp ma of ||w||^2 0.5725655183076045
||w|| 0.8185707780142103
exp ma of ||w|| 0.7404342367844591
||w||^2 0.4860903013368061
exp ma of ||w||^2 0.5539276357922402
||w|| 0.6972017651561175
exp ma of ||w|| 0.7257801092429129
||w||^2 0.43009322735824673
exp ma of ||w||^2 0.6330198622513263
||w|| 0.6558149337719039
exp ma of ||w|| 0.771213208119358
||w||^2 0.2727519214608524
exp ma of ||w||^2 0.626098254879955
||w|| 0.5222565666995987
exp ma of ||w|| 0.7664909350699585
cuda
Objective function 64.83 = squared loss an data 62.71 + 0.5*rho*h**2 0.447141 + alpha*h 1.318036 + L2reg 0.24 + L1reg 0.10 ; SHD = 32 ; DAG False
Proportion of microbatches that were clipped  0.7438185536345046
iteration 1 in inner loop, alpha 1.393766998937176 rho 1.0 h 0.945664413182481
1963
cuda
Objective function 68.85 = squared loss an data 62.71 + 0.5*rho*h**2 4.471406 + alpha*h 1.318036 + L2reg 0.24 + L1reg 0.10 ; SHD = 32 ; DAG False
||w||^2 150804790.45708874
exp ma of ||w||^2 1354524350.9781523
||w|| 12280.260195007626
exp ma of ||w|| 33013.4569613536
||w||^2 355609789.59527683
exp ma of ||w||^2 1105072565.5975683
||w|| 18857.618873953223
exp ma of ||w|| 29654.37578150186
||w||^2 257913.6272669208
exp ma of ||w||^2 1122682.3326089415
||w|| 507.8519737747613
exp ma of ||w|| 771.0102931516432
||w||^2 84406.71386333808
exp ma of ||w||^2 1017497.3765536639
||w|| 290.5283357322278
exp ma of ||w|| 723.7511213830039
||w||^2 3.9485353055626224
exp ma of ||w||^2 14.501407967566196
||w|| 1.9870921733937312
exp ma of ||w|| 2.122785972340779
||w||^2 2.1510498502587385
exp ma of ||w||^2 4.2722704800553295
||w|| 1.4666457821364838
exp ma of ||w|| 1.4241624413294667
||w||^2 2.5538640735814724
exp ma of ||w||^2 3.6258378988123168
||w|| 1.5980813726407903
exp ma of ||w|| 1.3901932069840799
||w||^2 0.9067071592234427
exp ma of ||w||^2 0.8720218646872036
||w|| 0.9522117197469493
exp ma of ||w|| 0.894228349549388
cuda
Objective function 28.31 = squared loss an data 26.23 + 0.5*rho*h**2 0.971031 + alpha*h 0.614217 + L2reg 0.40 + L1reg 0.10 ; SHD = 29 ; DAG False
Proportion of microbatches that were clipped  0.7447249434815373
iteration 2 in inner loop, alpha 1.393766998937176 rho 10.0 h 0.44068843797909274
1963
cuda
Objective function 37.05 = squared loss an data 26.23 + 0.5*rho*h**2 9.710315 + alpha*h 0.614217 + L2reg 0.40 + L1reg 0.10 ; SHD = 29 ; DAG False
||w||^2 1458598526.274657
exp ma of ||w||^2 1882983330.9956398
||w|| 38191.60282411118
exp ma of ||w|| 37974.85981956365
||w||^2 57996550.583565265
exp ma of ||w||^2 385305377.2553113
||w|| 7615.546637212937
exp ma of ||w|| 16261.766111111345
||w||^2 110218818.84007795
exp ma of ||w||^2 315688273.8762756
||w|| 10498.515077861151
exp ma of ||w|| 14810.25562682232
||w||^2 1039.8337676928168
exp ma of ||w||^2 13869.191437588783
||w|| 32.246453567684256
exp ma of ||w|| 63.70166826270979
cuda
Objective function 18.73 = squared loss an data 17.05 + 0.5*rho*h**2 0.879003 + alpha*h 0.184799 + L2reg 0.53 + L1reg 0.09 ; SHD = 24 ; DAG True
Proportion of microbatches that were clipped  0.7519162460272948
iteration 3 in inner loop, alpha 1.393766998937176 rho 100.0 h 0.13258983047754036
iteration 2 in outer loop, alpha = 14.652750046691212, rho = 100.0, h = 0.13258983047754036
cuda
1963
cuda
Objective function 20.48 = squared loss an data 17.05 + 0.5*rho*h**2 0.879003 + alpha*h 1.942806 + L2reg 0.53 + L1reg 0.09 ; SHD = 24 ; DAG True
||w||^2 403764205.4024161
exp ma of ||w||^2 859894676.4602982
||w|| 20093.884776279974
exp ma of ||w|| 26335.592693923834
||w||^2 932353.058016812
exp ma of ||w||^2 7119225.432387304
||w|| 965.5843091189977
exp ma of ||w|| 2013.384397482712
||w||^2 1.6144508910449848
exp ma of ||w||^2 7.86908145818765
||w|| 1.270610440317954
exp ma of ||w|| 1.7773279563526148
||w||^2 2.630958659636504
exp ma of ||w||^2 1.0594276190009042
||w|| 1.6220230145212196
exp ma of ||w|| 0.973154842134538
||w||^2 1.1502183133047124
exp ma of ||w||^2 1.138044168454525
||w|| 1.0724823137491417
exp ma of ||w|| 1.0080804403045358
cuda
Objective function 18.29 = squared loss an data 16.11 + 0.5*rho*h**2 0.312115 + alpha*h 1.157689 + L2reg 0.61 + L1reg 0.10 ; SHD = 24 ; DAG True
Proportion of microbatches that were clipped  0.7662103746397695
iteration 1 in inner loop, alpha 14.652750046691212 rho 100.0 h 0.07900828541417582
1963
cuda
Objective function 21.09 = squared loss an data 16.11 + 0.5*rho*h**2 3.121155 + alpha*h 1.157689 + L2reg 0.61 + L1reg 0.10 ; SHD = 24 ; DAG True
||w||^2 1830784407.1946378
exp ma of ||w||^2 8957603031.82119
||w|| 42787.666531310606
exp ma of ||w|| 87518.15862434346
||w||^2 428597531.0388934
exp ma of ||w||^2 621406661.4075533
||w|| 20702.59720515504
exp ma of ||w|| 21425.498846253086
||w||^2 90493928.33674212
exp ma of ||w||^2 238448825.77651364
||w|| 9512.829670331648
exp ma of ||w|| 13158.633684276323
||w||^2 220039.66716700082
exp ma of ||w||^2 3283345.898001966
||w|| 469.08385941854874
exp ma of ||w|| 1176.230296189182
||w||^2 14718.207884661277
exp ma of ||w||^2 688491.1263502956
||w|| 121.31862134339178
exp ma of ||w|| 527.4564002605022
||w||^2 2.2779674941712718
exp ma of ||w||^2 6.34712574279062
||w|| 1.5092937070601176
exp ma of ||w|| 1.7905082628719735
||w||^2 0.7009646930798986
exp ma of ||w||^2 1.2468043658696855
||w|| 0.8372363424266165
exp ma of ||w|| 1.0495342459500154
||w||^2 0.6695115090648814
exp ma of ||w||^2 1.248735828402427
||w|| 0.818236829447857
exp ma of ||w|| 1.0617238907041135
cuda
Objective function 17.77 = squared loss an data 16.19 + 0.5*rho*h**2 0.402237 + alpha*h 0.415600 + L2reg 0.67 + L1reg 0.09 ; SHD = 26 ; DAG True
Proportion of microbatches that were clipped  0.7617216117216117
iteration 2 in inner loop, alpha 14.652750046691212 rho 1000.0 h 0.028363243355659762
iteration 3 in outer loop, alpha = 43.01599340235097, rho = 1000.0, h = 0.028363243355659762
cuda
1963
cuda
Objective function 18.57 = squared loss an data 16.19 + 0.5*rho*h**2 0.402237 + alpha*h 1.220073 + L2reg 0.67 + L1reg 0.09 ; SHD = 26 ; DAG True
||w||^2 294184509993.8795
exp ma of ||w||^2 331982750813.9475
||w|| 542387.785623791
exp ma of ||w|| 486481.335280102
||w||^2 1421829081.5316796
exp ma of ||w||^2 11158680398.060663
||w|| 37707.14894461897
exp ma of ||w|| 92087.10410576029
||w||^2 4256815789.000924
exp ma of ||w||^2 5338858767.62428
||w|| 65244.277825729085
exp ma of ||w|| 64337.457025248776
||w||^2 383344693.0569864
exp ma of ||w||^2 1879419633.4136362
||w|| 19579.19030647045
exp ma of ||w|| 39280.21998820487
||w||^2 0.825104586115003
exp ma of ||w||^2 1.5233312028904211
||w|| 0.9083526771662002
exp ma of ||w|| 1.1765234306561216
||w||^2 3.584502426189744
exp ma of ||w||^2 1.2787251315911732
||w|| 1.8932782220766562
exp ma of ||w|| 1.0596703904286688
||w||^2 0.5581517458991009
exp ma of ||w||^2 1.1680580849982545
||w|| 0.7470955400075019
exp ma of ||w|| 1.0258560300544095
||w||^2 1.0592677227999394
exp ma of ||w||^2 1.2550781940145517
||w|| 1.029207327412674
exp ma of ||w|| 1.0598842816474654
cuda
Objective function 17.77 = squared loss an data 16.00 + 0.5*rho*h**2 0.167392 + alpha*h 0.787068 + L2reg 0.72 + L1reg 0.09 ; SHD = 27 ; DAG True
Proportion of microbatches that were clipped  0.7526541255354815
iteration 1 in inner loop, alpha 43.01599340235097 rho 1000.0 h 0.01829709158180215
1963
cuda
Objective function 19.28 = squared loss an data 16.00 + 0.5*rho*h**2 1.673918 + alpha*h 0.787068 + L2reg 0.72 + L1reg 0.09 ; SHD = 27 ; DAG True
||w||^2 2319785.696842686
exp ma of ||w||^2 12029186.647531955
||w|| 1523.084271090305
exp ma of ||w|| 2831.7482419181483
||w||^2 1.9992647273169761
exp ma of ||w||^2 2.565057066627368
||w|| 1.4139535803260928
exp ma of ||w|| 1.4071896670183353
||w||^2 0.7531577171440405
exp ma of ||w||^2 1.4055024266485536
||w|| 0.8678465977026357
exp ma of ||w|| 1.1285998850818924
||w||^2 2.460003881084597
exp ma of ||w||^2 1.2164235240777366
||w|| 1.5684399513799046
exp ma of ||w|| 1.04425714134899
cuda
Objective function 17.34 = squared loss an data 15.83 + 0.5*rho*h**2 0.317976 + alpha*h 0.343038 + L2reg 0.75 + L1reg 0.09 ; SHD = 25 ; DAG True
Proportion of microbatches that were clipped  0.7497147204260175
iteration 2 in inner loop, alpha 43.01599340235097 rho 10000.0 h 0.007974661518575843
1963
cuda
Objective function 20.20 = squared loss an data 15.83 + 0.5*rho*h**2 3.179761 + alpha*h 0.343038 + L2reg 0.75 + L1reg 0.09 ; SHD = 25 ; DAG True
||w||^2 15089279047445.605
exp ma of ||w||^2 9908972838885.2
||w|| 3884492.122201512
exp ma of ||w|| 2743575.9244264322
||w||^2 95979094234.52235
exp ma of ||w||^2 11751109148003.023
||w|| 309804.92932573287
exp ma of ||w|| 3144753.4553059833
||w||^2 888412315.8846983
exp ma of ||w||^2 29990990544.806957
||w|| 29806.24625619097
exp ma of ||w|| 44368.45502261985
||w||^2 95836578.95199083
exp ma of ||w||^2 618868519.5140132
||w|| 9789.615873566789
exp ma of ||w|| 8018.150101790183
v before min max tensor([[ 4.141e+02,  4.832e+01,  9.476e+01,  ..., -1.834e+01, -2.241e+01,
         -6.854e-01],
        [ 4.419e+02,  2.769e+01,  8.950e+03,  ...,  3.059e+02,  5.425e+02,
          1.072e+01],
        [ 6.024e+01,  3.416e+01,  6.420e+03,  ...,  1.887e+00, -2.658e+01,
         -1.494e+01],
        ...,
        [-2.732e-01,  6.761e-02,  8.457e+02,  ..., -1.563e+01,  2.385e+00,
          1.734e+03],
        [-6.144e+00,  9.697e+00,  1.388e+03,  ...,  9.138e+01, -3.237e+00,
          1.101e+03],
        [-2.062e+01,  8.194e-01,  2.076e+02,  ...,  7.344e+00, -1.110e+01,
         -2.690e+01]], device='cuda:0')
v tensor([[1.000e+01, 1.000e+01, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e+01,  ..., 1.000e+01, 1.000e+01,
         1.000e+01],
        [1.000e+01, 1.000e+01, 1.000e+01,  ..., 1.887e+00, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e-12, 6.761e-02, 1.000e+01,  ..., 1.000e-12, 2.385e+00,
         1.000e+01],
        [1.000e-12, 9.697e+00, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.000e+01],
        [1.000e-12, 8.194e-01, 1.000e+01,  ..., 7.344e+00, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([ 8.647e+00,  1.286e+02, -1.545e+01,  4.094e+01, -3.766e-01,  1.614e+00,
        -4.397e+00,  9.636e+00,  9.852e+01, -1.174e-01, -1.849e+01, -2.132e-01,
        -6.756e+00,  9.415e+00,  1.269e+02, -5.674e-01, -1.151e+01, -5.483e+00,
        -1.379e+01, -8.303e+00, -1.106e+01,  1.066e+01,  2.294e+01, -5.920e+00,
         1.119e+02, -1.308e+01, -2.146e-01, -1.380e+01, -1.034e+01, -1.255e+01,
        -2.707e+00, -1.295e+01,  5.046e+00, -1.103e+01, -1.742e+01,  5.705e-01,
         1.063e+02,  1.111e+02,  1.561e+01, -1.995e-01, -6.921e+00, -8.510e+00,
         6.451e+01,  4.863e+01, -3.484e+00,  2.619e+01, -4.778e+00,  1.580e+01,
        -6.277e+00,  1.733e+00, -4.511e+00, -1.634e+01, -8.724e+00,  3.370e+01,
         1.581e+02, -1.769e+01,  3.892e+01,  1.242e+00, -1.822e+00, -1.296e+01,
        -4.865e+00,  2.785e+01, -1.567e+01, -7.736e+00, -7.939e+00, -4.162e+00,
        -1.501e+01, -1.175e+01, -6.301e+00, -2.957e+00, -2.440e+00,  5.174e-01,
        -1.126e+01, -2.028e+00, -9.730e+00, -6.290e+00, -2.429e+01,  4.344e+01,
        -2.701e+00, -1.076e+00, -1.907e-02,  1.246e+01,  7.408e+01, -4.451e-01,
         1.001e+01,  1.537e+01,  2.727e+01, -1.972e+01, -8.672e+00, -3.823e+00,
        -2.598e+00, -7.372e-01, -1.222e+01, -5.719e+00,  8.271e-01, -1.621e+01,
         2.293e+01, -8.946e-01,  1.117e+02,  4.248e+01,  1.102e+01,  3.707e+01,
        -1.170e+01,  8.401e+00,  8.298e+01, -1.235e+00, -9.912e+00, -1.104e+00,
         1.655e+01, -2.038e+01,  5.667e+00, -1.951e+00, -1.211e+01,  1.049e+00,
         1.659e+00,  4.141e-02,  1.702e+01, -8.082e-01,  7.837e-01, -1.339e+01,
        -1.660e+00,  2.698e-02, -1.554e+01, -1.028e+00,  5.354e-01,  7.458e-01,
         1.098e+01, -2.115e+01,  3.742e+01, -1.260e+01], device='cuda:0')
v tensor([8.647e+00, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.614e+00,
        1.000e-12, 9.636e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 9.415e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 5.046e+00, 1.000e-12, 1.000e-12, 5.705e-01,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.733e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.242e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.174e-01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 8.271e-01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 8.401e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 5.667e+00, 1.000e-12, 1.000e-12, 1.049e+00,
        1.659e+00, 4.141e-02, 1.000e+01, 1.000e-12, 7.837e-01, 1.000e-12,
        1.000e-12, 2.698e-02, 1.000e-12, 1.000e-12, 5.354e-01, 7.458e-01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12], device='cuda:0')
v before min max tensor([[[-1.196e+01],
         [-2.074e+01],
         [-2.778e+00],
         [ 4.921e+00],
         [ 8.456e+00],
         [-2.747e+01],
         [-2.109e+01],
         [-1.914e+01],
         [ 1.951e+00],
         [ 1.252e+02]],

        [[-1.834e+01],
         [ 5.057e+00],
         [-1.400e+01],
         [ 8.080e+01],
         [ 1.732e+00],
         [-7.797e-01],
         [-1.534e+01],
         [-1.009e+01],
         [ 2.212e+01],
         [-1.099e+01]],

        [[-1.704e+01],
         [ 8.042e+00],
         [-7.207e-01],
         [-2.164e-01],
         [ 3.181e+01],
         [ 1.753e+00],
         [ 4.660e+00],
         [ 2.741e+01],
         [ 2.394e+00],
         [-1.278e+01]],

        [[-1.032e+01],
         [-1.405e+01],
         [-1.544e+00],
         [-1.128e+01],
         [ 3.702e+00],
         [ 1.446e+01],
         [-9.571e+00],
         [-1.117e+01],
         [-2.344e+01],
         [ 9.177e+00]],

        [[-5.983e+00],
         [ 2.816e+01],
         [ 2.361e+01],
         [ 2.889e+01],
         [-5.036e+00],
         [ 1.429e+01],
         [ 1.103e+02],
         [ 9.047e+01],
         [-6.721e+00],
         [ 1.091e+01]],

        [[-6.837e+00],
         [-2.217e+01],
         [-1.072e+01],
         [-1.549e+01],
         [-2.202e+01],
         [-1.086e+01],
         [-9.701e+00],
         [-5.142e+00],
         [-2.067e+01],
         [ 9.880e+00]],

        [[ 1.804e+00],
         [-2.308e+01],
         [-1.777e+01],
         [ 7.201e+01],
         [ 3.013e+01],
         [ 5.959e+00],
         [ 8.978e+01],
         [-4.340e+00],
         [-1.362e+01],
         [-2.365e+01]],

        [[-1.183e+00],
         [-2.636e+00],
         [ 4.629e+01],
         [-1.364e+01],
         [ 1.730e+01],
         [-9.041e+00],
         [ 1.843e+01],
         [-4.032e+00],
         [ 1.724e+01],
         [-1.051e+00]],

        [[-4.483e+00],
         [ 7.895e-01],
         [ 4.501e+00],
         [ 2.969e+01],
         [-1.114e+00],
         [-2.312e+01],
         [ 1.154e+02],
         [ 2.301e+01],
         [ 1.209e+01],
         [ 4.235e+00]],

        [[-2.677e+01],
         [ 1.881e+01],
         [ 1.415e+01],
         [ 1.412e+00],
         [-1.614e+01],
         [ 2.455e+01],
         [-7.451e+00],
         [-7.202e-01],
         [-1.221e+01],
         [-1.358e+01]],

        [[-2.702e+00],
         [ 5.469e+00],
         [-1.006e+00],
         [ 7.553e+01],
         [-1.008e+01],
         [-1.714e+01],
         [-1.549e+01],
         [ 2.687e+01],
         [-2.262e+01],
         [ 2.626e+01]],

        [[-9.856e+00],
         [ 2.966e+01],
         [-5.305e+00],
         [-9.917e-01],
         [-1.027e+01],
         [-1.065e+01],
         [ 4.029e+01],
         [ 1.163e+02],
         [ 5.932e-01],
         [ 1.007e+01]],

        [[ 7.690e+01],
         [ 3.562e+02],
         [-3.815e+00],
         [-1.523e+01],
         [-1.927e+01],
         [ 2.512e-01],
         [ 3.266e-02],
         [-6.330e+00],
         [ 1.335e+02],
         [-7.920e+00]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.921e+00],
         [8.456e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.951e+00],
         [1.000e+01]],

        [[1.000e-12],
         [5.057e+00],
         [1.000e-12],
         [1.000e+01],
         [1.732e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [8.042e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.753e+00],
         [4.660e+00],
         [1.000e+01],
         [2.394e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.702e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [9.177e+00]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [9.880e+00]],

        [[1.804e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [5.959e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [7.895e-01],
         [4.501e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [4.235e+00]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.412e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [5.469e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [5.932e-01],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.512e-01],
         [3.266e-02],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[-20.608],
        [ -9.421],
        [ 54.316],
        [  0.837],
        [ 33.406],
        [ 26.461],
        [  2.104],
        [ 11.747],
        [-18.849],
        [ 26.931],
        [  3.329],
        [175.086],
        [  7.389]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [8.373e-01],
        [1.000e+01],
        [1.000e+01],
        [2.104e+00],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [3.329e+00],
        [1.000e+01],
        [7.389e+00]], device='cuda:0')
a after update for 1 param tensor([[-0.009,  0.005,  0.037,  ..., -0.010,  0.012, -0.001],
        [-0.009, -0.004,  0.026,  ..., -0.001,  0.030,  0.017],
        [ 0.007,  0.014,  0.037,  ...,  0.005,  0.002,  0.008],
        ...,
        [-0.001,  0.000,  0.004,  ..., -0.009,  0.014, -0.057],
        [ 0.012,  0.009, -0.099,  ..., -0.007, -0.002,  0.015],
        [-0.006, -0.001,  0.023,  ...,  0.001,  0.001,  0.005]],
       device='cuda:0')
s after update for 1 param tensor([[2.129, 1.298, 2.413,  ..., 1.223, 1.451, 0.050],
        [2.003, 1.110, 2.375,  ..., 2.184, 2.161, 1.660],
        [2.168, 1.317, 2.153,  ..., 1.648, 1.873, 0.964],
        ...,
        [1.376, 0.153, 1.994,  ..., 0.970, 1.361, 2.348],
        [1.287, 1.431, 2.233,  ..., 1.651, 0.653, 2.387],
        [1.329, 0.288, 2.303,  ..., 1.713, 0.999, 1.865]], device='cuda:0')
b after update for 1 param tensor([[74.682, 58.310, 79.512,  ..., 56.610, 61.654, 11.410],
        [72.436, 53.933, 78.877,  ..., 75.650, 75.255, 65.948],
        [75.364, 58.735, 75.104,  ..., 65.716, 70.047, 50.245],
        ...,
        [60.046, 20.001, 72.279,  ..., 50.412, 59.712, 78.432],
        [58.061, 61.226, 76.488,  ..., 65.781, 41.348, 79.080],
        [59.001, 27.452, 77.688,  ..., 67.003, 51.158, 69.913]],
       device='cuda:0')
clipping threshold 1.8576392053710808
a after update for 1 param tensor([-7.700e-03, -1.649e-02,  1.066e-02,  8.377e-03, -2.727e-04,  3.060e-03,
        -7.843e-04, -4.073e-03, -1.255e-02,  1.947e-04, -6.876e-03, -5.844e-03,
         1.539e-02,  1.506e-03,  7.579e-03,  1.833e-04,  5.482e-04, -5.514e-03,
        -9.672e-03,  1.616e-05,  5.270e-04,  1.648e-03,  1.174e-02, -1.445e-02,
         1.302e-02, -4.965e-03, -3.524e-04, -3.256e-03, -4.137e-03,  1.308e-02,
        -1.201e-03,  2.133e-03, -2.846e-03,  1.599e-06, -1.965e-02, -1.155e-02,
         4.852e-03, -4.111e-03, -7.385e-03,  6.736e-04, -5.211e-03,  7.070e-03,
         5.644e-03, -6.151e-03,  2.654e-03,  1.129e-03, -1.955e-03,  2.339e-03,
        -4.838e-03,  1.867e-03,  2.833e-04,  4.828e-03,  2.608e-03, -2.992e-03,
        -2.530e-02,  1.938e-02, -4.494e-04,  4.283e-04,  9.436e-03,  3.323e-03,
         1.872e-02, -1.531e-02,  6.569e-03, -4.876e-03,  6.232e-04, -2.457e-03,
         1.756e-02,  5.242e-03, -1.599e-03, -5.348e-03, -1.074e-03,  9.585e-04,
         8.184e-03, -4.720e-03, -2.135e-03,  1.353e-03, -5.929e-03, -1.742e-03,
        -3.210e-03,  7.949e-04, -1.366e-04, -8.406e-03,  1.973e-02,  3.837e-04,
        -1.421e-02, -9.751e-03, -1.906e-03, -6.166e-03, -1.001e-02,  1.341e-02,
        -6.014e-03,  1.424e-03,  1.237e-03,  4.758e-03,  3.353e-03,  4.019e-03,
         1.536e-02, -3.653e-03, -6.622e-03,  3.953e-03, -5.759e-03,  2.141e-02,
         3.128e-03, -7.274e-03,  1.665e-03,  3.278e-03,  4.306e-03, -1.577e-04,
         9.103e-03, -1.174e-02, -2.761e-04,  4.321e-04,  3.054e-03, -2.626e-03,
        -5.661e-03, -6.331e-04, -2.280e-03,  2.246e-03, -9.507e-04, -1.708e-03,
        -1.952e-04, -1.901e-04, -1.931e-03,  5.662e-04,  8.713e-04,  5.467e-03,
        -7.541e-03,  9.469e-03,  2.499e-04, -3.199e-03], device='cuda:0')
s after update for 1 param tensor([1.282e+00, 1.623e+00, 1.175e+00, 1.600e+00, 1.123e-01, 4.124e-01,
        5.864e-01, 1.468e+00, 1.858e+00, 8.638e-03, 1.186e+00, 5.694e-01,
        1.545e+00, 1.003e+00, 1.911e+00, 5.242e-02, 7.604e-01, 8.329e-01,
        8.602e-01, 9.141e-01, 1.207e+00, 1.380e+00, 1.662e+00, 1.297e+00,
        1.346e+00, 8.639e-01, 2.338e-02, 1.071e+00, 7.245e-01, 1.268e+00,
        1.086e+00, 8.148e-01, 1.444e+00, 7.519e-01, 1.179e+00, 1.342e+00,
        1.672e+00, 1.730e+00, 1.041e+00, 2.006e-02, 4.943e-01, 6.639e-01,
        1.355e+00, 1.066e+00, 2.181e-01, 1.414e+00, 4.831e-01, 1.203e+00,
        9.551e-01, 5.527e-01, 3.170e-01, 1.176e+00, 9.565e-01, 1.053e+00,
        1.880e+00, 1.482e+00, 1.392e+00, 3.638e-01, 1.233e+00, 9.282e-01,
        1.104e+00, 1.428e+00, 9.733e-01, 9.872e-01, 6.192e-01, 3.598e-01,
        1.149e+00, 1.146e+00, 6.283e-01, 5.050e-01, 1.987e-01, 2.280e-01,
        1.311e+00, 1.014e+00, 6.308e-01, 1.062e+00, 1.542e+00, 1.413e+00,
        3.736e-01, 7.926e-02, 1.188e-03, 1.192e+00, 1.689e+00, 3.673e-02,
        1.860e+00, 1.370e+00, 1.656e+00, 1.298e+00, 8.781e-01, 1.111e+00,
        1.527e+00, 4.603e-02, 1.349e+00, 4.519e-01, 5.316e-01, 1.575e+00,
        1.325e+00, 8.596e-01, 1.855e+00, 1.243e+00, 1.647e+00, 1.711e+00,
        8.797e-01, 1.553e+00, 1.647e+00, 1.331e-01, 1.064e+00, 1.867e-01,
        1.394e+00, 1.278e+00, 8.651e-01, 8.922e-01, 7.526e-01, 3.242e-01,
        4.334e-01, 6.450e-02, 1.417e+00, 2.041e-01, 2.810e-01, 8.565e-01,
        1.030e-01, 5.337e-02, 1.038e+00, 8.554e-02, 2.371e-01, 3.607e-01,
        1.016e+00, 1.569e+00, 1.604e+00, 8.128e-01], device='cuda:0')
b after update for 1 param tensor([57.961, 65.208, 55.495, 64.739, 17.153, 32.871, 39.196, 62.017, 69.775,
         4.757, 55.737, 38.626, 63.630, 51.264, 70.762, 11.719, 44.635, 46.715,
        47.474, 48.939, 56.232, 60.122, 65.981, 58.289, 59.386, 47.576,  7.827,
        52.969, 43.570, 57.637, 53.347, 46.205, 61.507, 44.385, 55.591, 59.295,
        66.194, 67.328, 52.227,  7.250, 35.989, 41.707, 59.580, 52.855, 23.903,
        60.873, 35.578, 56.143, 50.025, 38.054, 28.819, 55.521, 50.062, 52.523,
        70.183, 62.312, 60.392, 30.874, 56.837, 49.314, 53.780, 61.177, 50.500,
        50.859, 40.278, 30.703, 54.867, 54.798, 40.575, 36.376, 22.816, 24.440,
        58.606, 51.554, 40.656, 52.740, 63.562, 60.853, 31.285, 14.411,  1.764,
        55.897, 66.530,  9.810, 69.815, 59.905, 65.867, 58.315, 47.967, 53.945,
        63.251, 10.983, 59.458, 34.410, 37.322, 64.246, 58.914, 47.457, 69.715,
        57.077, 65.689, 66.963, 48.009, 63.780, 65.686, 18.678, 52.809, 22.118,
        60.439, 57.866, 47.610, 48.351, 44.406, 29.145, 33.698, 13.000, 60.937,
        23.125, 27.132, 47.371, 16.430, 11.825, 52.152, 14.971, 24.923, 30.740,
        51.591, 64.127, 64.826, 46.149], device='cuda:0')
clipping threshold 1.8576392053710808
a after update for 1 param tensor([[[ 0.006],
         [-0.011],
         [ 0.008],
         [ 0.005],
         [-0.008],
         [-0.022],
         [-0.000],
         [ 0.028],
         [-0.003],
         [ 0.010]],

        [[ 0.003],
         [-0.004],
         [ 0.008],
         [-0.015],
         [ 0.017],
         [-0.001],
         [ 0.006],
         [ 0.000],
         [-0.018],
         [-0.008]],

        [[ 0.014],
         [ 0.014],
         [-0.005],
         [-0.001],
         [-0.002],
         [ 0.013],
         [ 0.001],
         [ 0.009],
         [ 0.002],
         [ 0.003]],

        [[ 0.011],
         [ 0.015],
         [-0.001],
         [ 0.009],
         [ 0.001],
         [ 0.004],
         [ 0.009],
         [-0.004],
         [ 0.002],
         [ 0.014]],

        [[ 0.002],
         [-0.015],
         [-0.007],
         [ 0.015],
         [ 0.008],
         [ 0.014],
         [ 0.003],
         [ 0.013],
         [-0.007],
         [ 0.028]],

        [[ 0.022],
         [ 0.037],
         [-0.009],
         [ 0.007],
         [ 0.002],
         [-0.001],
         [-0.011],
         [-0.005],
         [-0.007],
         [ 0.007]],

        [[ 0.006],
         [-0.019],
         [-0.003],
         [ 0.033],
         [-0.007],
         [ 0.000],
         [ 0.008],
         [-0.005],
         [ 0.023],
         [ 0.012]],

        [[-0.001],
         [ 0.002],
         [-0.009],
         [-0.001],
         [-0.007],
         [-0.004],
         [-0.012],
         [ 0.001],
         [-0.009],
         [-0.001]],

        [[-0.003],
         [-0.002],
         [-0.000],
         [-0.006],
         [-0.001],
         [-0.003],
         [ 0.036],
         [ 0.009],
         [-0.010],
         [ 0.002]],

        [[-0.011],
         [-0.009],
         [-0.005],
         [-0.009],
         [-0.007],
         [-0.010],
         [-0.006],
         [-0.003],
         [-0.007],
         [-0.005]],

        [[ 0.001],
         [-0.002],
         [-0.000],
         [ 0.008],
         [ 0.002],
         [-0.009],
         [-0.001],
         [-0.017],
         [ 0.014],
         [ 0.006]],

        [[ 0.006],
         [ 0.000],
         [ 0.001],
         [ 0.002],
         [ 0.001],
         [-0.012],
         [ 0.003],
         [-0.015],
         [ 0.003],
         [ 0.024]],

        [[-0.014],
         [ 0.006],
         [-0.005],
         [ 0.000],
         [-0.009],
         [-0.001],
         [ 0.002],
         [-0.003],
         [ 0.008],
         [ 0.000]]], device='cuda:0')
s after update for 1 param tensor([[[0.874],
         [1.713],
         [0.564],
         [1.257],
         [1.296],
         [1.765],
         [1.315],
         [1.402],
         [0.967],
         [1.354]],

        [[1.140],
         [0.716],
         [0.871],
         [1.364],
         [1.165],
         [0.084],
         [0.993],
         [0.984],
         [1.677],
         [0.864]],

        [[1.187],
         [1.777],
         [0.425],
         [0.058],
         [1.589],
         [1.421],
         [1.009],
         [1.838],
         [0.504],
         [1.001]],

        [[0.884],
         [0.873],
         [0.915],
         [1.284],
         [0.745],
         [1.011],
         [0.627],
         [1.092],
         [1.514],
         [1.382]],

        [[0.532],
         [1.497],
         [1.057],
         [1.748],
         [1.168],
         [1.697],
         [1.647],
         [1.573],
         [0.431],
         [1.820]],

        [[1.587],
         [1.676],
         [0.880],
         [0.966],
         [1.406],
         [1.209],
         [0.979],
         [0.953],
         [1.440],
         [1.139]],

        [[1.867],
         [1.434],
         [1.538],
         [1.805],
         [1.487],
         [1.179],
         [1.637],
         [0.812],
         [1.760],
         [1.760]],

        [[0.226],
         [0.176],
         [1.394],
         [1.024],
         [1.243],
         [0.577],
         [1.928],
         [0.254],
         [1.417],
         [0.097]],

        [[0.396],
         [0.744],
         [0.740],
         [1.429],
         [0.464],
         [1.568],
         [1.790],
         [1.353],
         [1.248],
         [0.655]],

        [[1.761],
         [1.821],
         [1.060],
         [1.248],
         [1.003],
         [1.439],
         [1.356],
         [0.066],
         [1.010],
         [0.951]],

        [[0.315],
         [0.874],
         [0.074],
         [1.040],
         [0.723],
         [1.482],
         [0.962],
         [1.474],
         [1.460],
         [2.061]],

        [[1.194],
         [1.208],
         [0.864],
         [0.172],
         [1.152],
         [1.313],
         [1.326],
         [1.708],
         [0.409],
         [1.901]],

        [[1.949],
         [1.865],
         [0.476],
         [0.956],
         [1.257],
         [0.159],
         [0.374],
         [1.306],
         [1.526],
         [0.495]]], device='cuda:0')
b after update for 1 param tensor([[[47.862],
         [67.000],
         [38.434],
         [57.397],
         [58.279],
         [67.997],
         [58.699],
         [60.618],
         [50.328],
         [59.564]],

        [[54.645],
         [43.327],
         [47.784],
         [59.792],
         [55.244],
         [14.808],
         [50.999],
         [50.774],
         [66.291],
         [47.579]],

        [[55.769],
         [68.235],
         [33.384],
         [12.339],
         [64.521],
         [61.008],
         [51.426],
         [69.401],
         [36.345],
         [51.208]],

        [[48.119],
         [47.821],
         [48.961],
         [58.013],
         [44.182],
         [51.470],
         [40.522],
         [53.497],
         [62.976],
         [60.165]],

        [[37.333],
         [62.625],
         [52.614],
         [67.684],
         [55.324],
         [66.674],
         [65.701],
         [64.203],
         [33.616],
         [69.053]],

        [[64.481],
         [66.273],
         [48.022],
         [50.300],
         [60.691],
         [56.290],
         [50.636],
         [49.971],
         [61.432],
         [54.638]],

        [[69.937],
         [61.296],
         [63.489],
         [68.774],
         [62.429],
         [55.570],
         [65.482],
         [46.134],
         [67.914],
         [67.902]],

        [[24.350],
         [21.500],
         [60.434],
         [51.806],
         [57.064],
         [38.889],
         [71.072],
         [25.796],
         [60.922],
         [15.937]],

        [[32.225],
         [44.164],
         [44.029],
         [61.197],
         [34.851],
         [64.107],
         [68.480],
         [59.536],
         [57.176],
         [41.441]],

        [[67.921],
         [69.083],
         [52.699],
         [57.194],
         [51.260],
         [61.403],
         [59.616],
         [13.191],
         [51.431],
         [49.916]],

        [[28.712],
         [47.855],
         [13.953],
         [52.205],
         [43.536],
         [62.314],
         [50.195],
         [62.148],
         [61.846],
         [73.484]],

        [[55.925],
         [56.264],
         [47.575],
         [21.243],
         [54.931],
         [58.644],
         [58.936],
         [66.904],
         [32.740],
         [70.568]],

        [[71.459],
         [69.902],
         [35.334],
         [50.051],
         [57.387],
         [20.386],
         [31.305],
         [58.508],
         [63.239],
         [36.010]]], device='cuda:0')
clipping threshold 1.8576392053710808
a after update for 1 param tensor([[-0.011],
        [-0.012],
        [ 0.008],
        [-0.001],
        [-0.002],
        [ 0.020],
        [-0.006],
        [ 0.026],
        [ 0.006],
        [ 0.025],
        [-0.003],
        [-0.029],
        [-0.013]], device='cuda:0')
s after update for 1 param tensor([[1.280],
        [1.141],
        [1.567],
        [1.023],
        [1.295],
        [1.471],
        [1.048],
        [1.690],
        [1.264],
        [1.856],
        [0.588],
        [1.884],
        [0.950]], device='cuda:0')
b after update for 1 param tensor([[57.901],
        [54.688],
        [64.072],
        [51.781],
        [58.241],
        [62.079],
        [52.392],
        [66.545],
        [57.551],
        [69.731],
        [39.235],
        [70.269],
        [49.894]], device='cuda:0')
clipping threshold 1.8576392053710808
||w||^2 1.9265027330760032
exp ma of ||w||^2 1.6084584831105224
||w|| 1.3879851343137661
exp ma of ||w|| 1.218944221789088
||w||^2 1.1560317823122472
exp ma of ||w||^2 1.3558424292575533
||w|| 1.0751891844286043
exp ma of ||w|| 1.0871789940140646
cuda
Objective function 17.09 = squared loss an data 15.76 + 0.5*rho*h**2 0.362065 + alpha*h 0.115755 + L2reg 0.77 + L1reg 0.09 ; SHD = 22 ; DAG True
Proportion of microbatches that were clipped  0.7557237464522233
iteration 3 in inner loop, alpha 43.01599340235097 rho 100000.0 h 0.002690965174691584
iteration 4 in outer loop, alpha = 312.11251087150936, rho = 100000.0, h = 0.002690965174691584
cuda
1963
cuda
Objective function 17.82 = squared loss an data 15.76 + 0.5*rho*h**2 0.362065 + alpha*h 0.839884 + L2reg 0.77 + L1reg 0.09 ; SHD = 22 ; DAG True
||w||^2 19868.297273323315
exp ma of ||w||^2 1151806.9655596989
||w|| 140.95494767237975
exp ma of ||w|| 244.31464800588478
||w||^2 1.8874260122552253
exp ma of ||w||^2 1.4017884895090924
||w|| 1.373836239242227
exp ma of ||w|| 1.1356297072060637
||w||^2 3.0001768429968765
exp ma of ||w||^2 1.0991346794218637
||w|| 1.7321018569925029
exp ma of ||w|| 0.9983143147231854
cuda
Objective function 17.15 = squared loss an data 15.61 + 0.5*rho*h**2 0.143603 + alpha*h 0.528942 + L2reg 0.79 + L1reg 0.08 ; SHD = 19 ; DAG True
Proportion of microbatches that were clipped  0.7575926961058319
iteration 1 in inner loop, alpha 312.11251087150936 rho 100000.0 h 0.001694714802681574
iteration 5 in outer loop, alpha = 2006.8273135530833, rho = 1000000.0, h = 0.001694714802681574
Threshold 0.3
[[0.004 0.104 0.479 1.686 0.469 0.181 0.337 0.054 0.188 0.288 0.651 0.621
  0.086]
 [0.042 0.005 0.307 0.135 0.227 0.136 0.335 0.016 0.728 0.384 0.109 0.369
  0.229]
 [0.004 0.006 0.006 0.003 0.02  0.099 0.406 0.015 0.005 0.266 0.006 0.015
  0.006]
 [0.002 0.035 1.535 0.005 0.038 0.099 0.351 0.025 0.071 0.202 0.063 0.022
  0.04 ]
 [0.006 0.013 0.133 0.126 0.003 0.081 0.214 0.007 0.033 0.043 0.09  0.007
  0.022]
 [0.018 0.026 0.045 0.024 0.044 0.004 0.248 0.002 0.015 0.044 0.028 0.021
  0.018]
 [0.006 0.009 0.008 0.006 0.018 0.017 0.007 0.005 0.004 0.015 0.01  0.013
  0.007]
 [0.046 0.272 0.173 0.126 0.481 2.736 0.441 0.005 0.232 2.096 0.127 0.117
  0.089]
 [0.016 0.004 0.839 0.05  0.108 0.222 0.852 0.016 0.004 0.163 0.096 0.063
  0.039]
 [0.008 0.008 0.015 0.013 0.085 0.195 0.351 0.003 0.016 0.008 0.016 0.016
  0.005]
 [0.004 0.033 0.832 0.085 0.019 0.099 0.228 0.029 0.035 0.289 0.004 0.029
  0.049]
 [0.006 0.014 0.218 0.162 0.738 0.228 0.317 0.029 0.062 0.155 0.09  0.006
  0.07 ]
 [0.052 0.017 0.93  0.12  0.19  0.163 0.368 0.036 0.05  1.233 0.09  0.077
  0.005]]
[[0.    0.    0.479 1.686 0.469 0.    0.337 0.    0.    0.    0.651 0.621
  0.   ]
 [0.    0.    0.307 0.    0.    0.    0.335 0.    0.728 0.384 0.    0.369
  0.   ]
 [0.    0.    0.    0.    0.    0.    0.406 0.    0.    0.    0.    0.
  0.   ]
 [0.    0.    1.535 0.    0.    0.    0.351 0.    0.    0.    0.    0.
  0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.   ]
 [0.    0.    0.    0.    0.481 2.736 0.441 0.    0.    2.096 0.    0.
  0.   ]
 [0.    0.    0.839 0.    0.    0.    0.852 0.    0.    0.    0.    0.
  0.   ]
 [0.    0.    0.    0.    0.    0.    0.351 0.    0.    0.    0.    0.
  0.   ]
 [0.    0.    0.832 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.   ]
 [0.    0.    0.    0.    0.738 0.    0.317 0.    0.    0.    0.    0.
  0.   ]
 [0.    0.    0.93  0.    0.    0.    0.368 0.    0.    1.233 0.    0.
  0.   ]]
{'fdr': 0.4074074074074074, 'tpr': 0.6153846153846154, 'fpr': 0.21153846153846154, 'f1': 0.6037735849056604, 'shd': 19, 'npred': 27, 'ntrue': 26}
[1.035e-01 4.788e-01 1.686e+00 4.691e-01 1.808e-01 3.373e-01 5.403e-02
 1.880e-01 2.879e-01 6.513e-01 6.214e-01 8.575e-02 4.155e-02 3.067e-01
 1.348e-01 2.274e-01 1.361e-01 3.355e-01 1.603e-02 7.285e-01 3.837e-01
 1.090e-01 3.694e-01 2.293e-01 3.575e-03 5.672e-03 3.271e-03 2.014e-02
 9.927e-02 4.061e-01 1.450e-02 4.838e-03 2.661e-01 6.093e-03 1.515e-02
 6.001e-03 2.497e-03 3.453e-02 1.535e+00 3.841e-02 9.914e-02 3.508e-01
 2.464e-02 7.106e-02 2.023e-01 6.286e-02 2.248e-02 4.010e-02 6.192e-03
 1.276e-02 1.333e-01 1.259e-01 8.051e-02 2.140e-01 6.714e-03 3.311e-02
 4.320e-02 9.047e-02 6.515e-03 2.239e-02 1.777e-02 2.647e-02 4.493e-02
 2.361e-02 4.368e-02 2.481e-01 1.960e-03 1.532e-02 4.370e-02 2.774e-02
 2.062e-02 1.766e-02 6.113e-03 9.307e-03 8.351e-03 6.359e-03 1.840e-02
 1.694e-02 4.931e-03 4.352e-03 1.505e-02 9.706e-03 1.336e-02 6.708e-03
 4.582e-02 2.724e-01 1.730e-01 1.261e-01 4.813e-01 2.736e+00 4.409e-01
 2.321e-01 2.096e+00 1.272e-01 1.169e-01 8.890e-02 1.576e-02 4.070e-03
 8.393e-01 5.022e-02 1.084e-01 2.217e-01 8.516e-01 1.569e-02 1.630e-01
 9.560e-02 6.271e-02 3.894e-02 7.608e-03 8.214e-03 1.465e-02 1.337e-02
 8.536e-02 1.946e-01 3.509e-01 2.866e-03 1.584e-02 1.582e-02 1.559e-02
 4.720e-03 4.001e-03 3.324e-02 8.322e-01 8.550e-02 1.877e-02 9.875e-02
 2.278e-01 2.879e-02 3.545e-02 2.893e-01 2.888e-02 4.911e-02 5.975e-03
 1.358e-02 2.175e-01 1.623e-01 7.375e-01 2.284e-01 3.175e-01 2.947e-02
 6.208e-02 1.553e-01 9.009e-02 7.037e-02 5.237e-02 1.697e-02 9.300e-01
 1.202e-01 1.897e-01 1.626e-01 3.681e-01 3.575e-02 4.992e-02 1.233e+00
 8.993e-02 7.664e-02]
[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]
 [1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0.]
aucroc, aucpr (0.7523668639053255, 0.5839185354371612)
Iterations 400
Achieves (24.732993516011284, 1e-05)-DP
