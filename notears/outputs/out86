samples  5000  graph  10 20 ER mim  minibatch size  50  noise  0.6  minibatches per NN training  250 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.2475063433069558
iteration 1 in outer loop, alpha = 1.2475063433069558, rho = 1.0, h = 1.2475063433069558
cuda
iteration 1 in inner loop,alpha 1.2475063433069558 rho 1.0 h 0.8085201416893035
iteration 2 in inner loop,alpha 1.2475063433069558 rho 10.0 h 0.3303172643133756
iteration 3 in inner loop,alpha 1.2475063433069558 rho 100.0 h 0.08921441758860027
iteration 2 in outer loop, alpha = 10.168948102166983, rho = 100.0, h = 0.08921441758860027
cuda
iteration 1 in inner loop,alpha 10.168948102166983 rho 100.0 h 0.04477488600516111
iteration 2 in inner loop,alpha 10.168948102166983 rho 1000.0 h 0.014755927158363491
iteration 3 in outer loop, alpha = 24.924875260530474, rho = 1000.0, h = 0.014755927158363491
cuda
iteration 1 in inner loop,alpha 24.924875260530474 rho 1000.0 h 0.006952256959076308
iteration 2 in inner loop,alpha 24.924875260530474 rho 10000.0 h 0.0010979429815165531
iteration 4 in outer loop, alpha = 35.904305075696, rho = 10000.0, h = 0.0010979429815165531
cuda
iteration 1 in inner loop,alpha 35.904305075696 rho 10000.0 h 0.00060622188658499
iteration 2 in inner loop,alpha 35.904305075696 rho 100000.0 h 0.0002564618237617111
iteration 5 in outer loop, alpha = 61.55048745186711, rho = 100000.0, h = 0.0002564618237617111
cuda
iteration 1 in inner loop,alpha 61.55048745186711 rho 100000.0 h 0.0001572061253760637
iteration 6 in outer loop, alpha = 218.75661282793084, rho = 1000000.0, h = 0.0001572061253760637
Threshold 0.3
[[0.005 0.    0.    0.    0.5   0.    0.082 0.    0.    1.749]
 [3.004 0.004 0.593 0.    0.103 0.002 1.11  0.003 0.    1.057]
 [0.311 0.004 0.005 0.    0.097 0.003 1.212 0.007 0.    0.278]
 [1.888 2.971 1.126 0.    0.042 2.633 0.195 2.696 0.011 0.136]
 [0.    0.    0.001 0.    0.004 0.    0.001 0.    0.    0.001]
 [0.412 0.286 0.74  0.    0.057 0.004 0.97  1.044 0.001 0.14 ]
 [0.005 0.001 0.001 0.    0.992 0.001 0.004 0.001 0.    0.015]
 [0.248 0.278 0.021 0.    0.028 0.001 0.239 0.002 0.    0.024]
 [0.304 2.154 0.015 0.015 1.489 0.074 0.534 0.043 0.    0.101]
 [0.001 0.    0.001 0.    0.894 0.    0.059 0.    0.    0.004]]
[[0.    0.    0.    0.    0.5   0.    0.    0.    0.    1.749]
 [3.004 0.    0.593 0.    0.    0.    1.11  0.    0.    1.057]
 [0.311 0.    0.    0.    0.    0.    1.212 0.    0.    0.   ]
 [1.888 2.971 1.126 0.    0.    2.633 0.    2.696 0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.412 0.    0.74  0.    0.    0.    0.97  1.044 0.    0.   ]
 [0.    0.    0.    0.    0.992 0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.304 2.154 0.    0.    1.489 0.    0.534 0.    0.    0.   ]
 [0.    0.    0.    0.    0.894 0.    0.    0.    0.    0.   ]]
{'fdr': 0.17391304347826086, 'tpr': 0.95, 'fpr': 0.16, 'f1': 0.8837209302325583, 'shd': 4, 'npred': 23, 'ntrue': 20}
[1.469e-04 1.517e-04 6.900e-06 4.997e-01 5.137e-05 8.213e-02 3.744e-04
 4.775e-06 1.749e+00 3.004e+00 5.933e-01 2.337e-06 1.034e-01 2.369e-03
 1.110e+00 2.810e-03 2.898e-05 1.057e+00 3.106e-01 3.683e-03 5.793e-05
 9.713e-02 2.649e-03 1.212e+00 6.918e-03 8.623e-05 2.782e-01 1.888e+00
 2.971e+00 1.126e+00 4.250e-02 2.633e+00 1.955e-01 2.696e+00 1.139e-02
 1.363e-01 1.476e-04 1.069e-04 6.858e-04 3.456e-06 3.307e-04 1.324e-03
 2.548e-04 1.250e-05 1.443e-03 4.122e-01 2.859e-01 7.404e-01 6.985e-06
 5.749e-02 9.697e-01 1.044e+00 7.576e-04 1.404e-01 5.468e-03 8.138e-04
 1.362e-03 6.041e-06 9.916e-01 5.751e-04 7.036e-04 2.892e-05 1.483e-02
 2.482e-01 2.779e-01 2.095e-02 7.403e-06 2.803e-02 9.988e-04 2.390e-01
 4.949e-04 2.404e-02 3.041e-01 2.154e+00 1.491e-02 1.484e-02 1.489e+00
 7.444e-02 5.341e-01 4.265e-02 1.006e-01 7.844e-04 1.160e-04 1.296e-03
 6.004e-06 8.937e-01 2.153e-04 5.906e-02 3.322e-04 5.051e-06]
[[0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 1. 1. 0. 0. 1. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9678571428571429, 0.9463610842098485)
cuda
1210
cuda
Objective function 188.58 = squared loss an data 11.52 + 0.5*rho*h**2 176.710652 + alpha*h 0.000000 + L2reg 0.19 + L1reg 0.16 ; SHD = 55 ; DAG False
||w||^2 0.5990389650124651
exp ma of ||w||^2 0.4997835370789383
||w|| 0.7739760752196835
exp ma of ||w|| 0.6710501139574043
||w||^2 0.2609341606214507
exp ma of ||w||^2 0.5061794731185947
||w|| 0.5108171498897142
exp ma of ||w|| 0.6681372471800053
||w||^2 0.9824909474627778
exp ma of ||w||^2 0.5547556806936672
||w|| 0.9912068136684583
exp ma of ||w|| 0.6962924077839188
||w||^2 0.18932596788262995
exp ma of ||w||^2 0.5247899940257484
||w|| 0.4351160395602878
exp ma of ||w|| 0.6837394095079153
||w||^2 0.6546564208075827
exp ma of ||w||^2 0.500121042693698
||w|| 0.8091084110350001
exp ma of ||w|| 0.6706410357890371
cuda
Objective function 6.39 = squared loss an data 5.47 + 0.5*rho*h**2 0.544186 + alpha*h 0.000000 + L2reg 0.31 + L1reg 0.07 ; SHD = 17 ; DAG False
Proportion of microbatches that were clipped  0.7653085921742638
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 1.043250854397927
iteration 1 in outer loop, alpha = 1.043250854397927, rho = 1.0, h = 1.043250854397927
cuda
1210
cuda
Objective function 7.48 = squared loss an data 5.47 + 0.5*rho*h**2 0.544186 + alpha*h 1.088372 + L2reg 0.31 + L1reg 0.07 ; SHD = 17 ; DAG False
||w||^2 167366469.14592257
exp ma of ||w||^2 1061872179.0220664
||w|| 12937.019330043631
exp ma of ||w|| 26521.035323838405
||w||^2 0.043481743932887104
exp ma of ||w||^2 129.82446741114396
||w|| 0.20852276598224737
exp ma of ||w|| 0.27905887646952043
||w||^2 0.3086224439920688
exp ma of ||w||^2 0.4769299758452026
||w|| 0.5555379770925376
exp ma of ||w|| 0.6295018282348398
||w||^2 0.7452389849839687
exp ma of ||w||^2 0.44966128568301816
||w|| 0.8632722542651123
exp ma of ||w|| 0.6358483604742643
||w||^2 0.6885783162700845
exp ma of ||w||^2 0.47829646365878703
||w|| 0.8298061919930969
exp ma of ||w|| 0.6543569661339328
||w||^2 1.0189369915195774
exp ma of ||w||^2 0.5417584546560291
||w|| 1.0094240890327402
exp ma of ||w|| 0.6838190991091601
||w||^2 0.03654133755187539
exp ma of ||w||^2 0.5179706874179806
||w|| 0.19115788644959275
exp ma of ||w|| 0.6677988311894654
||w||^2 1.6156168984526122
exp ma of ||w||^2 0.5581870312508498
||w|| 1.2710691949900337
exp ma of ||w|| 0.6976400844293216
cuda
Objective function 6.71 = squared loss an data 5.35 + 0.5*rho*h**2 0.193893 + alpha*h 0.649658 + L2reg 0.46 + L1reg 0.06 ; SHD = 16 ; DAG False
Proportion of microbatches that were clipped  0.763592035757822
iteration 1 in inner loop, alpha 1.043250854397927 rho 1.0 h 0.622724200813467
1210
cuda
Objective function 8.46 = squared loss an data 5.35 + 0.5*rho*h**2 1.938927 + alpha*h 0.649658 + L2reg 0.46 + L1reg 0.06 ; SHD = 16 ; DAG False
||w||^2 45062.41166991863
exp ma of ||w||^2 10806808.067825556
||w|| 212.27908910186756
exp ma of ||w|| 1053.131841265341
||w||^2 0.7160736300255987
exp ma of ||w||^2 159042.3473883569
||w|| 0.8462113388661243
exp ma of ||w|| 21.630104194406535
||w||^2 0.1633955138246995
exp ma of ||w||^2 1.6360733350804908
||w|| 0.4042221095198771
exp ma of ||w|| 0.44199245243463453
||w||^2 0.24439247004317063
exp ma of ||w||^2 0.4913388873426719
||w|| 0.49436066797751077
exp ma of ||w|| 0.6449071153471618
||w||^2 0.36298054406705205
exp ma of ||w||^2 0.5795971230775145
||w|| 0.6024786668978844
exp ma of ||w|| 0.7070428366314322
||w||^2 0.12614240869995605
exp ma of ||w||^2 0.5491185718557011
||w|| 0.3551653258694548
exp ma of ||w|| 0.6804024870768032
||w||^2 0.08978455267937016
exp ma of ||w||^2 0.5031448869597087
||w|| 0.2996407059786273
exp ma of ||w|| 0.6597721391712915
||w||^2 0.26624670489910324
exp ma of ||w||^2 0.5381202091999778
||w|| 0.5159909930406763
exp ma of ||w|| 0.6823546461794133
||w||^2 0.7171519737695331
exp ma of ||w||^2 0.4788082588053428
||w|| 0.8468482589989385
exp ma of ||w|| 0.6414856007966776
||w||^2 0.1777322132174609
exp ma of ||w||^2 0.4958706558244965
||w|| 0.4215829849714774
exp ma of ||w|| 0.6466872374931014
||w||^2 0.1777886479877049
exp ma of ||w||^2 0.6480390022907547
||w|| 0.4216499116419982
exp ma of ||w|| 0.7448669286847293
||w||^2 0.4855719345703148
exp ma of ||w||^2 0.544161464546747
||w|| 0.6968299179644304
exp ma of ||w|| 0.6676711320834738
cuda
Objective function 7.25 = squared loss an data 6.03 + 0.5*rho*h**2 0.340464 + alpha*h 0.272232 + L2reg 0.56 + L1reg 0.05 ; SHD = 15 ; DAG True
Proportion of microbatches that were clipped  0.7647484909456741
iteration 2 in inner loop, alpha 1.043250854397927 rho 10.0 h 0.260945835250995
1210
cuda
Objective function 10.32 = squared loss an data 6.03 + 0.5*rho*h**2 3.404636 + alpha*h 0.272232 + L2reg 0.56 + L1reg 0.05 ; SHD = 15 ; DAG True
||w||^2 0.6495106146815556
exp ma of ||w||^2 1.4359505877538103
||w|| 0.8059222137908568
exp ma of ||w|| 0.4606042597434408
||w||^2 0.11127399878159856
exp ma of ||w||^2 0.5326864861762465
||w|| 0.33357757535781474
exp ma of ||w|| 0.6762501145900933
||w||^2 1.8872579421226694
exp ma of ||w||^2 0.493654697168501
||w|| 1.3737750696976085
exp ma of ||w|| 0.6572868531217917
v before min max tensor([[-3.712e-01, -3.422e-01,  1.464e-01, -4.906e-01, -3.673e-01, -3.588e-01,
         -7.447e-01, -5.993e-01, -2.964e-02, -5.107e-01],
        [ 5.990e-01, -2.495e-01, -1.852e-01, -3.756e-01, -9.204e-01,  2.107e-01,
         -2.361e-01,  4.587e-01, -3.144e-01, -1.951e-01],
        [-2.617e-01, -8.115e-01, -3.052e-01, -8.697e-01,  1.109e+00,  2.460e+00,
         -7.548e-01,  6.869e-02, -3.542e-01, -3.557e-01],
        [-2.521e-01, -1.031e+00, -7.638e-02, -9.351e-01,  2.772e-01, -5.144e-03,
          1.045e+00, -5.418e-01,  9.565e-01,  1.046e-01],
        [-1.278e+00,  7.344e-01, -5.341e-01, -5.003e-01,  3.116e-01, -6.917e-01,
         -5.746e-01, -4.276e-01, -3.749e-01,  5.082e+00],
        [-1.069e+00, -4.393e-01, -8.592e-01, -5.234e-01,  6.098e-01, -4.648e-01,
          1.258e+00, -4.304e-01,  4.657e-01, -7.950e-01],
        [-6.630e-01,  5.156e-01, -3.593e-01,  9.051e-01,  9.799e-01, -2.838e-01,
          1.987e+00,  1.572e-01, -2.356e-01, -7.278e-01],
        [-6.827e-01, -5.833e-01, -3.305e-01, -5.983e-01, -9.092e-01, -7.673e-01,
         -6.699e-01,  6.697e-01, -4.693e-01,  6.745e-02],
        [ 6.220e+00,  1.797e+00,  4.247e-02, -2.996e-01,  1.734e-01,  2.231e+00,
         -1.046e+00, -1.385e+00, -4.492e-01, -1.273e-01],
        [-2.941e-01, -2.316e-01, -1.003e+00,  2.347e-01, -3.048e-01,  1.922e+00,
          2.563e+00,  5.746e-01,  1.013e-01, -1.127e+00],
        [ 3.835e+00, -8.658e-01, -6.342e-01, -2.429e-01,  7.184e-01, -8.431e-01,
         -7.126e-01, -1.126e-01, -7.503e-01, -9.495e-01],
        [ 2.291e-02, -7.114e-01,  6.919e-02, -1.437e+00,  1.682e-01, -2.827e-01,
          4.583e+00,  1.874e-01, -1.702e-01, -1.091e-01],
        [-8.169e-01,  4.470e+00, -2.240e-01, -9.730e-01, -5.319e-01,  3.493e-01,
          7.982e-01,  4.245e-02, -1.889e-01, -9.380e-01],
        [ 3.057e+00, -4.789e-01, -5.991e-01, -3.426e-01, -7.428e-01, -4.616e-01,
          2.049e-01,  5.334e-01,  1.390e+00, -6.352e-01],
        [ 7.082e-01, -9.039e-01, -6.154e-01, -6.620e-01, -6.184e-01, -5.071e-01,
         -6.838e-01,  5.768e-02,  1.337e+00, -1.535e-01],
        [-3.648e-01,  7.777e-01, -2.142e-01,  8.207e-01, -3.829e-01, -7.318e-01,
          3.629e-02, -8.811e-01, -3.063e-01, -3.021e-01],
        [-7.791e-01,  7.898e-01,  7.312e-01,  1.800e+00,  2.272e+00, -7.634e-01,
         -6.504e-01, -3.176e-01,  2.112e+00,  1.041e-01],
        [-6.928e-01, -3.071e-01, -6.479e-01, -6.189e-01, -6.185e-01,  5.131e-02,
         -6.096e-01, -4.073e-01, -3.239e-01, -5.003e-01],
        [-4.192e-01, -1.095e+00,  1.100e+00, -5.656e-01, -1.110e+00, -8.086e-02,
         -7.213e-01, -1.685e-01, -5.294e-01,  4.131e-01],
        [-2.198e-01, -5.243e-01, -4.134e-01,  1.389e+00, -4.312e-01, -4.682e-02,
         -7.583e-01,  8.961e-02, -7.997e-01, -5.262e-01],
        [-5.122e-01, -8.078e-01, -3.206e-01,  3.900e-01,  6.026e-01, -6.355e-01,
          3.837e-02, -5.553e-01, -5.198e-01, -8.833e-02],
        [-8.451e-01, -4.393e-01,  8.091e-01, -4.492e-01,  4.048e-02, -1.355e+00,
          7.836e-01, -5.502e-01,  2.598e-01,  1.273e+00],
        [ 1.878e+00, -7.397e-01,  1.021e+00,  3.896e-01,  3.145e-01, -6.422e-01,
         -6.826e-01, -5.703e-01, -3.445e-01,  4.956e+00],
        [-3.309e-01, -2.646e-01, -6.526e-02, -3.695e-01, -3.062e-01, -7.070e-01,
         -4.938e-01,  7.033e-01,  2.507e-03,  4.007e-01],
        [-1.002e+00, -4.641e-01, -7.850e-01,  1.558e-01, -5.139e-01, -3.466e-01,
         -6.022e-03,  1.241e+00, -8.044e-01,  2.887e+00],
        [-2.757e-01, -1.907e-01,  1.329e+00, -7.446e-02,  1.521e+00, -4.525e-01,
         -3.631e-01, -4.819e-01,  6.928e-01, -7.736e-01],
        [ 2.755e+00, -5.995e-01,  7.735e-01,  3.578e-01,  1.936e-01,  1.235e+00,
         -7.967e-02, -7.074e-01, -3.270e-01,  2.813e-01],
        [ 5.716e+00,  3.020e+00, -9.665e-01, -4.259e-01, -6.236e-03,  9.941e-03,
          4.347e+00, -6.516e-01, -7.463e-01,  6.601e-01],
        [-4.634e-01, -5.282e-01, -1.461e+00, -2.452e-01, -6.419e-01, -5.128e-01,
          1.091e+00, -1.710e-01, -6.467e-01,  2.248e-01],
        [-2.551e-01,  1.243e-01, -1.049e+00,  2.230e+00, -4.404e-01, -4.006e-01,
          2.343e-01,  2.388e-01, -3.275e-01, -8.231e-01],
        [ 1.840e-01, -6.276e-01, -7.704e-01, -3.720e-01, -6.359e-01, -8.199e-01,
         -2.446e-01, -1.448e-01,  4.065e-01, -3.234e-01],
        [-4.772e-01, -1.548e-01, -3.517e-01, -6.529e-01,  3.595e-01, -2.121e-02,
          2.585e-01, -1.968e-01, -3.032e-01,  6.008e-02],
        [-5.392e-01, -4.315e-01,  3.681e-01, -6.152e-01, -8.839e-01, -4.787e-01,
         -3.420e-01, -5.563e-01,  2.893e-01, -3.479e-01],
        [-6.560e-01,  1.483e-01, -4.548e-01, -8.849e-01, -9.346e-02, -1.085e+00,
         -6.538e-01,  1.918e+00, -1.905e-01, -8.052e-01],
        [ 8.356e-01,  8.094e-01, -7.203e-01, -1.978e-01, -6.327e-01, -4.087e-01,
         -1.090e+00, -5.323e-01, -7.957e-01, -9.663e-01],
        [-6.320e-01,  2.756e-01, -1.903e-01, -9.410e-01, -6.745e-02,  2.975e-01,
         -2.261e-01, -6.277e-01, -4.447e-01, -5.444e-01],
        [-8.945e-02, -7.257e-01, -8.894e-01,  2.817e+00, -5.556e-01, -8.207e-01,
         -2.804e-01, -7.083e-04, -3.034e-01,  1.142e-01],
        [-1.992e-01,  2.560e+00, -6.633e-01, -3.304e-01, -3.813e-01, -6.255e-01,
         -6.914e-01, -4.773e-01,  2.607e+00,  7.478e-01],
        [ 5.957e-01,  1.967e+00,  3.705e-01, -8.268e-01, -6.368e-01, -3.750e-01,
         -4.485e-01, -3.398e-01, -9.035e-01, -4.054e-01],
        [-8.112e-01, -7.279e-01,  1.944e-01, -1.205e-01,  4.374e-01,  1.848e-01,
          3.467e-01, -6.362e-01,  7.837e-01,  6.249e-01],
        [-2.325e-01,  2.442e-01,  7.773e-01, -7.141e-01, -4.843e-01, -4.120e-01,
         -8.743e-01, -2.039e-01, -3.045e-01, -9.750e-01],
        [ 7.101e+00, -8.069e-01,  7.495e-01, -1.818e-03, -1.283e+00, -1.464e-01,
          3.395e-01,  4.271e-01,  2.391e+00,  5.332e-01],
        [ 2.995e-03, -2.395e-01, -6.121e-01, -5.404e-01,  6.222e-01, -1.221e-01,
         -1.955e-01, -6.652e-01,  1.436e+00, -2.565e-01],
        [-4.653e-01,  7.418e-01,  5.841e-01,  8.023e-02, -4.209e-01,  1.351e-02,
          4.891e-01, -6.888e-01,  8.378e-01, -6.450e-01],
        [ 1.926e-01, -3.759e-01, -2.120e-01, -4.646e-01,  1.005e-01,  9.801e-01,
         -2.351e-01,  3.113e-01, -3.516e-01, -2.232e-01],
        [-2.751e-02, -8.276e-01, -1.961e-01, -3.371e-01, -1.071e+00, -1.021e+00,
          5.622e-01,  1.248e+00, -4.695e-01,  9.410e-02],
        [-7.311e-01,  1.820e+01, -3.273e-01, -3.954e-01, -1.034e+00, -5.253e-01,
         -3.317e-01, -1.025e+00,  4.694e-02,  9.864e-01],
        [ 1.490e-01,  3.676e-01,  6.483e-01, -9.189e-01, -2.690e-01, -3.177e-01,
         -8.278e-03,  8.176e-01, -9.409e-02, -4.234e-01],
        [-1.028e+00,  2.065e+00,  3.781e-01, -4.142e-01, -1.197e+00,  2.415e+00,
         -7.148e-01, -5.449e-01, -3.965e-02,  5.807e-01],
        [-1.451e-01, -1.348e-01, -8.749e-01,  1.179e+00, -1.003e+00,  7.431e-01,
          1.403e+00,  3.359e-01,  5.914e+00,  5.325e-01],
        [-4.651e-01, -7.849e-01, -3.257e-01,  2.188e-01, -1.031e+00,  5.622e+00,
         -7.832e-01, -2.918e-01,  3.354e-01, -7.805e-01],
        [-5.782e-01, -9.365e-01, -4.723e-01, -4.590e-01, -7.151e-01, -5.978e-01,
          9.534e-02,  8.978e-01, -5.536e-01,  1.323e-01],
        [ 4.283e+00,  2.388e-01,  8.456e-01,  1.630e+00, -5.478e-01,  5.869e-01,
         -7.918e-01, -1.027e-01, -3.191e-01,  1.169e+00],
        [-7.257e-01, -7.012e-01, -1.425e+00, -2.993e-01, -2.347e-01, -6.520e-01,
          2.865e+00,  1.022e-01,  2.916e-01, -1.817e-01],
        [-6.471e-01,  2.306e-01, -6.802e-01,  1.970e-01, -3.046e-01, -1.210e+00,
         -9.329e-01,  3.470e-02, -2.602e-01,  2.264e+00],
        [-2.867e-01, -8.916e-01, -6.325e-01, -7.290e-01, -2.785e-01,  3.127e+00,
          6.335e-01, -1.239e-02, -2.258e-03, -6.395e-01],
        [ 2.830e-01, -8.097e-01,  4.256e-02, -7.260e-01,  1.033e+00, -6.517e-01,
         -7.942e-01,  8.766e-01, -5.609e-01, -4.638e-01],
        [-6.126e-01, -6.385e-01, -1.217e+00, -5.593e-01,  2.637e-01, -5.362e-01,
         -5.595e-01,  2.966e-01, -3.569e-01,  2.758e-01],
        [-4.614e-01, -7.241e-01, -6.856e-01,  5.376e-01,  7.479e-02,  7.572e-01,
          1.203e+00, -7.695e-01,  3.446e-01,  8.378e-02],
        [ 2.163e+00, -8.978e-01,  2.573e+00, -1.090e+00, -2.906e-01,  2.416e+00,
         -7.456e-01, -9.337e-02, -7.710e-02, -5.888e-01],
        [ 3.039e-01,  3.815e+00, -5.537e-01, -3.426e-01,  9.341e-01, -2.343e-01,
         -8.691e-01,  2.549e+00, -4.250e-01,  3.695e-02],
        [-1.307e+00, -4.481e-01,  5.183e+00, -3.042e-01,  7.189e-01, -1.543e-01,
         -1.070e+00, -3.638e-01, -1.792e-01, -3.097e-01],
        [ 4.798e-01, -4.411e-01, -4.760e-01, -8.397e-01,  1.728e+00, -8.281e-01,
          1.617e+00,  1.604e-01, -1.805e-01,  3.176e-01],
        [-1.871e-01, -6.686e-01, -2.420e-01, -6.728e-01, -4.049e-01, -4.203e-02,
         -1.022e+00, -6.902e-02, -4.090e-01,  4.028e-01],
        [-1.808e-01, -5.445e-01, -1.154e+00,  3.071e-02, -2.189e-01, -1.054e+00,
          8.549e-01, -7.910e-01, -8.991e-01, -8.732e-02],
        [ 3.315e+00, -7.392e-01, -6.359e-01, -3.265e-01,  8.542e-01, -5.339e-01,
         -7.052e-01,  1.677e-01,  1.747e+00, -8.066e-02],
        [-1.195e+00, -1.139e+00,  1.040e-01,  7.434e-01,  1.823e-01, -3.914e-01,
          5.065e-01,  3.534e+00, -3.850e-01, -7.839e-01],
        [ 5.633e+00,  1.965e+00,  1.075e+00,  2.728e-01,  1.976e+00, -8.058e-01,
         -4.387e-01, -9.374e-01,  5.382e-01, -3.983e-02],
        [ 1.849e+00,  3.569e+00, -6.448e-01, -2.343e-01,  3.864e+00, -6.644e-01,
          1.093e+01,  7.497e-01,  5.209e-01, -1.316e+00],
        [-5.497e-01, -6.362e-01, -1.144e-01,  1.014e+00,  2.542e-01, -4.621e-01,
          6.378e-01, -4.516e-01, -7.394e-01, -4.793e-01],
        [-3.266e-01, -2.563e-02, -3.581e-01,  4.416e-01,  1.420e+00, -3.719e-01,
         -8.067e-01,  5.055e-01, -6.191e-01, -7.244e-01],
        [ 9.342e-01,  5.521e-01, -5.451e-01, -5.972e-01,  2.854e-01, -3.089e-01,
          3.237e-01, -1.280e+00,  1.175e+00, -8.868e-01],
        [-5.783e-01, -2.436e-01, -3.507e-01, -3.450e-01, -5.200e-01,  1.618e+00,
         -5.934e-01, -6.117e-01,  2.975e+00, -2.263e-01],
        [ 2.705e+00,  5.587e-01, -4.338e-01, -2.163e-01,  5.217e-01, -1.018e+00,
         -8.397e-01, -7.977e-01, -5.685e-01, -5.297e-01],
        [-3.328e-01,  7.184e-01,  4.137e+00,  7.425e-01, -6.150e-01, -1.630e+00,
         -1.255e-01, -4.707e-01, -5.908e-01, -5.032e-01],
        [-3.794e-01, -2.378e-01,  3.400e-01, -3.878e-01, -3.287e-01,  1.716e-01,
         -4.023e-01, -7.357e-01,  7.877e-01, -2.894e-01],
        [-6.857e-01,  3.054e-01,  7.130e-01, -3.729e-01,  5.052e-01, -9.925e-01,
         -3.755e-01,  4.241e-01,  1.856e+00,  3.338e-01],
        [-5.828e-01, -4.776e-01,  1.247e+00, -1.579e-01, -6.979e-01, -6.485e-01,
         -1.191e+00,  7.515e-01, -1.187e+00, -2.743e-01],
        [-3.046e-01, -7.310e-01,  2.321e+00, -2.175e-01,  1.207e-03,  9.691e-01,
         -4.860e-01, -3.313e-01,  2.390e+00, -1.105e+00],
        [ 4.838e-01, -8.402e-01, -8.006e-02, -2.412e-01, -7.091e-01, -5.400e-01,
          5.580e-03,  9.180e-01,  2.822e-01, -5.580e-01],
        [ 1.752e+00,  1.317e+00,  9.842e-01, -4.519e-01, -5.110e-01, -4.459e-01,
         -1.083e-01,  4.191e-01, -7.525e-01,  4.082e-01],
        [ 2.357e+00,  1.880e+00,  2.407e+00, -3.183e-01, -1.470e-01,  9.997e-01,
         -1.201e+00,  2.953e-01, -6.544e-01, -1.963e-01],
        [-6.126e-01, -7.761e-01,  1.252e-01,  6.048e-01,  6.934e-03, -7.327e-01,
         -4.289e-01,  8.193e-02, -9.644e-03, -5.452e-01],
        [-2.360e-01,  8.129e-01,  2.166e+00, -1.019e+00,  2.880e+00,  3.499e-01,
         -3.529e-01, -7.681e-01, -2.953e-01,  9.635e-01],
        [-6.311e-01,  4.580e-01, -9.210e-02, -5.911e-01, -1.196e+00,  6.359e+00,
         -5.394e-01, -1.422e-01, -6.563e-01, -4.626e-01],
        [ 9.758e-02, -2.868e-01, -1.373e-01,  9.578e-01,  8.360e-01,  2.495e+00,
         -2.696e-01,  1.389e+00, -6.941e-01,  3.458e-01],
        [-3.749e-02, -2.989e-02,  3.251e-01, -5.705e-01, -9.141e-02, -2.623e-01,
         -5.620e-01, -2.884e-01, -8.540e-01,  3.412e+00],
        [-5.544e-01, -8.449e-01,  1.646e-02,  2.187e+00, -1.477e+00, -1.073e-01,
         -3.311e-01, -3.368e-01, -3.769e-01,  3.966e+00],
        [-4.492e-01,  1.040e-01, -2.682e-01,  1.311e-01, -4.156e-01,  2.094e-01,
         -6.378e-01,  2.613e-01,  7.407e-01, -3.815e-01],
        [-8.977e-01, -7.077e-01,  6.517e-02, -5.780e-01, -1.072e-02, -3.800e-01,
         -3.985e-01, -3.762e-01,  2.091e+00,  1.723e-01],
        [-4.667e-01, -9.423e-01, -2.620e-01, -4.619e-01, -1.508e+00, -7.612e-01,
         -7.008e-01, -9.510e-01, -2.565e-01, -1.442e+00],
        [ 8.272e+00,  2.219e-01,  8.489e-01, -1.036e+00, -4.217e-01, -6.141e-01,
          2.291e-01,  1.794e+00, -5.534e-02,  3.129e+00],
        [-1.489e-01, -7.473e-01, -6.464e-02, -1.869e-01, -3.026e-01, -5.863e-01,
         -5.828e-01,  4.419e-01,  3.794e+00, -2.764e-01],
        [-8.457e-01, -4.607e-02,  1.081e-01,  2.002e-01, -4.236e-01, -7.328e-01,
         -1.671e+00,  8.562e+00, -7.855e-01, -1.135e+00],
        [-7.997e-01, -5.266e-01,  2.220e+00,  1.514e-01,  1.102e+00, -8.090e-01,
          2.533e+00,  2.699e-01,  2.235e+00, -9.570e-01],
        [ 1.031e+00, -7.485e-01, -6.459e-01,  1.611e+00,  6.421e+00, -4.068e-01,
         -6.060e-01, -4.415e-01, -3.957e-01,  2.981e+00],
        [ 6.206e+00, -5.654e-01,  4.335e-01, -7.318e-01, -8.019e-02, -2.586e-01,
         -7.700e-01, -5.200e-01, -2.749e-01,  4.067e-01],
        [ 4.533e-01,  2.052e-01,  3.142e-04, -6.557e-01,  6.447e-01,  2.857e-01,
         -4.682e-01, -3.817e-01, -2.987e-01, -8.476e-01],
        [-5.699e-01,  3.470e-01,  6.237e+00,  3.503e-01, -4.478e-01,  6.544e-01,
         -4.418e-01, -4.956e-01,  1.503e+00, -7.324e-02],
        [-7.834e-01,  2.939e-01,  8.589e-01, -5.288e-01,  8.784e-01,  2.364e+00,
         -2.595e-01,  1.250e+00,  5.789e-01,  4.056e+00]], device='cuda:0')
v tensor([[1.000e-12, 1.000e-12, 1.464e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [5.990e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.107e-01,
         1.000e-12, 4.587e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.109e+00, 2.460e+00,
         1.000e-12, 6.869e-02, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.772e-01, 1.000e-12,
         1.045e+00, 1.000e-12, 9.565e-01, 1.046e-01],
        [1.000e-12, 7.344e-01, 1.000e-12, 1.000e-12, 3.116e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 5.082e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 6.098e-01, 1.000e-12,
         1.258e+00, 1.000e-12, 4.657e-01, 1.000e-12],
        [1.000e-12, 5.156e-01, 1.000e-12, 9.051e-01, 9.799e-01, 1.000e-12,
         1.987e+00, 1.572e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 6.697e-01, 1.000e-12, 6.745e-02],
        [6.220e+00, 1.797e+00, 4.247e-02, 1.000e-12, 1.734e-01, 2.231e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 2.347e-01, 1.000e-12, 1.922e+00,
         2.563e+00, 5.746e-01, 1.013e-01, 1.000e-12],
        [3.835e+00, 1.000e-12, 1.000e-12, 1.000e-12, 7.184e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [2.291e-02, 1.000e-12, 6.919e-02, 1.000e-12, 1.682e-01, 1.000e-12,
         4.583e+00, 1.874e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 4.470e+00, 1.000e-12, 1.000e-12, 1.000e-12, 3.493e-01,
         7.982e-01, 4.245e-02, 1.000e-12, 1.000e-12],
        [3.057e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         2.049e-01, 5.334e-01, 1.390e+00, 1.000e-12],
        [7.082e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 5.768e-02, 1.337e+00, 1.000e-12],
        [1.000e-12, 7.777e-01, 1.000e-12, 8.207e-01, 1.000e-12, 1.000e-12,
         3.629e-02, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 7.898e-01, 7.312e-01, 1.800e+00, 2.272e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 2.112e+00, 1.041e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.131e-02,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.100e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 4.131e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.389e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 8.961e-02, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 3.900e-01, 6.026e-01, 1.000e-12,
         3.837e-02, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 8.091e-01, 1.000e-12, 4.048e-02, 1.000e-12,
         7.836e-01, 1.000e-12, 2.598e-01, 1.273e+00],
        [1.878e+00, 1.000e-12, 1.021e+00, 3.896e-01, 3.145e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 4.956e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 7.033e-01, 2.507e-03, 4.007e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.558e-01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.241e+00, 1.000e-12, 2.887e+00],
        [1.000e-12, 1.000e-12, 1.329e+00, 1.000e-12, 1.521e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 6.928e-01, 1.000e-12],
        [2.755e+00, 1.000e-12, 7.735e-01, 3.578e-01, 1.936e-01, 1.235e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 2.813e-01],
        [5.716e+00, 3.020e+00, 1.000e-12, 1.000e-12, 1.000e-12, 9.941e-03,
         4.347e+00, 1.000e-12, 1.000e-12, 6.601e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.091e+00, 1.000e-12, 1.000e-12, 2.248e-01],
        [1.000e-12, 1.243e-01, 1.000e-12, 2.230e+00, 1.000e-12, 1.000e-12,
         2.343e-01, 2.388e-01, 1.000e-12, 1.000e-12],
        [1.840e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 4.065e-01, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.595e-01, 1.000e-12,
         2.585e-01, 1.000e-12, 1.000e-12, 6.008e-02],
        [1.000e-12, 1.000e-12, 3.681e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 2.893e-01, 1.000e-12],
        [1.000e-12, 1.483e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.918e+00, 1.000e-12, 1.000e-12],
        [8.356e-01, 8.094e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 2.756e-01, 1.000e-12, 1.000e-12, 1.000e-12, 2.975e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 2.817e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.142e-01],
        [1.000e-12, 2.560e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 2.607e+00, 7.478e-01],
        [5.957e-01, 1.967e+00, 3.705e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.944e-01, 1.000e-12, 4.374e-01, 1.848e-01,
         3.467e-01, 1.000e-12, 7.837e-01, 6.249e-01],
        [1.000e-12, 2.442e-01, 7.773e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [7.101e+00, 1.000e-12, 7.495e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         3.395e-01, 4.271e-01, 2.391e+00, 5.332e-01],
        [2.995e-03, 1.000e-12, 1.000e-12, 1.000e-12, 6.222e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.436e+00, 1.000e-12],
        [1.000e-12, 7.418e-01, 5.841e-01, 8.023e-02, 1.000e-12, 1.351e-02,
         4.891e-01, 1.000e-12, 8.378e-01, 1.000e-12],
        [1.926e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.005e-01, 9.801e-01,
         1.000e-12, 3.113e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         5.622e-01, 1.248e+00, 1.000e-12, 9.410e-02],
        [1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 4.694e-02, 9.864e-01],
        [1.490e-01, 3.676e-01, 6.483e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 8.176e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 2.065e+00, 3.781e-01, 1.000e-12, 1.000e-12, 2.415e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 5.807e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.179e+00, 1.000e-12, 7.431e-01,
         1.403e+00, 3.359e-01, 5.914e+00, 5.325e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 2.188e-01, 1.000e-12, 5.622e+00,
         1.000e-12, 1.000e-12, 3.354e-01, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         9.534e-02, 8.978e-01, 1.000e-12, 1.323e-01],
        [4.283e+00, 2.388e-01, 8.456e-01, 1.630e+00, 1.000e-12, 5.869e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.169e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         2.865e+00, 1.022e-01, 2.916e-01, 1.000e-12],
        [1.000e-12, 2.306e-01, 1.000e-12, 1.970e-01, 1.000e-12, 1.000e-12,
         1.000e-12, 3.470e-02, 1.000e-12, 2.264e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.127e+00,
         6.335e-01, 1.000e-12, 1.000e-12, 1.000e-12],
        [2.830e-01, 1.000e-12, 4.256e-02, 1.000e-12, 1.033e+00, 1.000e-12,
         1.000e-12, 8.766e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.637e-01, 1.000e-12,
         1.000e-12, 2.966e-01, 1.000e-12, 2.758e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 5.376e-01, 7.479e-02, 7.572e-01,
         1.203e+00, 1.000e-12, 3.446e-01, 8.378e-02],
        [2.163e+00, 1.000e-12, 2.573e+00, 1.000e-12, 1.000e-12, 2.416e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [3.039e-01, 3.815e+00, 1.000e-12, 1.000e-12, 9.341e-01, 1.000e-12,
         1.000e-12, 2.549e+00, 1.000e-12, 3.695e-02],
        [1.000e-12, 1.000e-12, 5.183e+00, 1.000e-12, 7.189e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [4.798e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.728e+00, 1.000e-12,
         1.617e+00, 1.604e-01, 1.000e-12, 3.176e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 4.028e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 3.071e-02, 1.000e-12, 1.000e-12,
         8.549e-01, 1.000e-12, 1.000e-12, 1.000e-12],
        [3.315e+00, 1.000e-12, 1.000e-12, 1.000e-12, 8.542e-01, 1.000e-12,
         1.000e-12, 1.677e-01, 1.747e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.040e-01, 7.434e-01, 1.823e-01, 1.000e-12,
         5.065e-01, 3.534e+00, 1.000e-12, 1.000e-12],
        [5.633e+00, 1.965e+00, 1.075e+00, 2.728e-01, 1.976e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 5.382e-01, 1.000e-12],
        [1.849e+00, 3.569e+00, 1.000e-12, 1.000e-12, 3.864e+00, 1.000e-12,
         1.000e+01, 7.497e-01, 5.209e-01, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.014e+00, 2.542e-01, 1.000e-12,
         6.378e-01, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 4.416e-01, 1.420e+00, 1.000e-12,
         1.000e-12, 5.055e-01, 1.000e-12, 1.000e-12],
        [9.342e-01, 5.521e-01, 1.000e-12, 1.000e-12, 2.854e-01, 1.000e-12,
         3.237e-01, 1.000e-12, 1.175e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.618e+00,
         1.000e-12, 1.000e-12, 2.975e+00, 1.000e-12],
        [2.705e+00, 5.587e-01, 1.000e-12, 1.000e-12, 5.217e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 7.184e-01, 4.137e+00, 7.425e-01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 3.400e-01, 1.000e-12, 1.000e-12, 1.716e-01,
         1.000e-12, 1.000e-12, 7.877e-01, 1.000e-12],
        [1.000e-12, 3.054e-01, 7.130e-01, 1.000e-12, 5.052e-01, 1.000e-12,
         1.000e-12, 4.241e-01, 1.856e+00, 3.338e-01],
        [1.000e-12, 1.000e-12, 1.247e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 7.515e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 2.321e+00, 1.000e-12, 1.207e-03, 9.691e-01,
         1.000e-12, 1.000e-12, 2.390e+00, 1.000e-12],
        [4.838e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         5.580e-03, 9.180e-01, 2.822e-01, 1.000e-12],
        [1.752e+00, 1.317e+00, 9.842e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 4.191e-01, 1.000e-12, 4.082e-01],
        [2.357e+00, 1.880e+00, 2.407e+00, 1.000e-12, 1.000e-12, 9.997e-01,
         1.000e-12, 2.953e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.252e-01, 6.048e-01, 6.934e-03, 1.000e-12,
         1.000e-12, 8.193e-02, 1.000e-12, 1.000e-12],
        [1.000e-12, 8.129e-01, 2.166e+00, 1.000e-12, 2.880e+00, 3.499e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 9.635e-01],
        [1.000e-12, 4.580e-01, 1.000e-12, 1.000e-12, 1.000e-12, 6.359e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [9.758e-02, 1.000e-12, 1.000e-12, 9.578e-01, 8.360e-01, 2.495e+00,
         1.000e-12, 1.389e+00, 1.000e-12, 3.458e-01],
        [1.000e-12, 1.000e-12, 3.251e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 3.412e+00],
        [1.000e-12, 1.000e-12, 1.646e-02, 2.187e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 3.966e+00],
        [1.000e-12, 1.040e-01, 1.000e-12, 1.311e-01, 1.000e-12, 2.094e-01,
         1.000e-12, 2.613e-01, 7.407e-01, 1.000e-12],
        [1.000e-12, 1.000e-12, 6.517e-02, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 2.091e+00, 1.723e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [8.272e+00, 2.219e-01, 8.489e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         2.291e-01, 1.794e+00, 1.000e-12, 3.129e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 4.419e-01, 3.794e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.081e-01, 2.002e-01, 1.000e-12, 1.000e-12,
         1.000e-12, 8.562e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 2.220e+00, 1.514e-01, 1.102e+00, 1.000e-12,
         2.533e+00, 2.699e-01, 2.235e+00, 1.000e-12],
        [1.031e+00, 1.000e-12, 1.000e-12, 1.611e+00, 6.421e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 2.981e+00],
        [6.206e+00, 1.000e-12, 4.335e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 4.067e-01],
        [4.533e-01, 2.052e-01, 3.142e-04, 1.000e-12, 6.447e-01, 2.857e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 3.470e-01, 6.237e+00, 3.503e-01, 1.000e-12, 6.544e-01,
         1.000e-12, 1.000e-12, 1.503e+00, 1.000e-12],
        [1.000e-12, 2.939e-01, 8.589e-01, 1.000e-12, 8.784e-01, 2.364e+00,
         1.000e-12, 1.250e+00, 5.789e-01, 4.056e+00]], device='cuda:0')
v before min max tensor([-2.665e-01, -3.060e-01, -9.187e-01,  4.153e-01, -8.378e-01,  5.010e-01,
        -1.194e-01, -4.355e-01, -4.574e-01, -4.455e-01, -5.603e-01,  2.952e-01,
         3.967e-01, -5.584e-01, -4.649e-02,  1.485e+00, -1.164e+00, -6.627e-02,
         1.258e+00,  1.317e+00, -4.193e-01,  3.858e-01, -7.357e-01, -3.792e-01,
        -6.252e-01, -3.866e-01, -8.026e-01, -4.371e-01,  5.067e-01, -1.899e-01,
        -1.118e+00, -1.183e+00, -7.299e-01,  1.142e-01, -2.933e-01, -4.964e-01,
        -7.073e-02,  2.647e+00, -4.787e-01, -1.404e+00, -8.201e-01, -4.757e-01,
        -4.628e-01, -7.006e-01, -7.208e-01,  1.184e+00, -8.447e-01, -2.178e-01,
        -7.404e-01,  2.602e+00,  4.209e-03, -4.735e-01, -4.005e-01, -6.065e-01,
        -4.203e-01, -5.414e-01,  6.048e-01, -1.662e-01,  9.428e-01, -8.761e-01,
         2.397e-01, -2.597e-02, -3.761e-01, -5.072e-01, -9.510e-01, -7.356e-01,
         5.912e-01, -8.854e-01,  1.046e+00, -6.713e-01, -3.608e-01, -7.114e-01,
        -3.108e-01, -4.717e-01, -6.648e-01, -3.968e-01, -5.349e-01, -4.666e-01,
        -5.267e-01,  7.031e-01,  3.889e-02, -5.619e-04,  2.325e-01, -5.321e-01,
        -6.867e-01,  6.182e-02,  4.406e-01, -5.313e-01,  1.930e+00, -1.126e+00,
        -9.754e-01, -4.313e-01, -4.222e-01, -4.990e-01, -3.746e-01,  1.464e-02,
        -6.851e-01, -5.429e-01,  2.040e-01, -2.532e-01], device='cuda:0')
v tensor([1.000e-12, 1.000e-12, 1.000e-12, 4.153e-01, 1.000e-12, 5.010e-01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.952e-01,
        3.967e-01, 1.000e-12, 1.000e-12, 1.485e+00, 1.000e-12, 1.000e-12,
        1.258e+00, 1.317e+00, 1.000e-12, 3.858e-01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.067e-01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.142e-01, 1.000e-12, 1.000e-12,
        1.000e-12, 2.647e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.184e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 2.602e+00, 4.209e-03, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 6.048e-01, 1.000e-12, 9.428e-01, 1.000e-12,
        2.397e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        5.912e-01, 1.000e-12, 1.046e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 7.031e-01, 3.889e-02, 1.000e-12, 2.325e-01, 1.000e-12,
        1.000e-12, 6.182e-02, 4.406e-01, 1.000e-12, 1.930e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.464e-02,
        1.000e-12, 1.000e-12, 2.040e-01, 1.000e-12], device='cuda:0')
v before min max tensor([[[ 1.559e-01],
         [-5.960e-01],
         [-3.049e-01],
         [ 7.372e+00],
         [-3.138e-01],
         [ 3.259e-01],
         [ 5.577e-01],
         [-4.089e-01],
         [ 7.645e-02],
         [ 1.247e-01]],

        [[-4.916e-01],
         [-8.941e-02],
         [-1.268e+00],
         [ 5.946e-01],
         [ 6.747e-01],
         [-2.068e-01],
         [-9.696e-01],
         [ 9.018e-01],
         [-1.227e+00],
         [ 3.687e+00]],

        [[-8.066e-01],
         [-7.575e-01],
         [ 4.666e-01],
         [-4.165e-01],
         [-6.663e-01],
         [-4.011e-01],
         [-7.578e-01],
         [-4.567e-01],
         [ 4.481e+00],
         [-8.405e-01]],

        [[ 7.085e-01],
         [ 1.278e+00],
         [ 3.519e-01],
         [-6.265e-01],
         [-7.349e-01],
         [ 1.641e+00],
         [-1.364e+00],
         [-8.248e-01],
         [ 7.349e-01],
         [ 1.620e-01]],

        [[ 5.837e-02],
         [ 1.216e-01],
         [ 8.860e-02],
         [-2.129e-02],
         [ 7.824e-01],
         [-1.003e+00],
         [-5.807e-01],
         [-2.288e-01],
         [-6.227e-01],
         [-4.441e-01]],

        [[-8.239e-01],
         [-4.298e-01],
         [-3.920e-01],
         [ 7.509e-01],
         [-5.097e-01],
         [-5.706e-01],
         [ 6.451e-01],
         [-1.387e+00],
         [-3.375e-01],
         [ 1.798e+00]],

        [[-4.343e-01],
         [-5.716e-01],
         [ 1.805e+00],
         [-1.936e-01],
         [ 4.747e-01],
         [-1.538e-01],
         [ 3.430e-01],
         [-7.854e-01],
         [-3.328e-01],
         [-1.113e+00]],

        [[ 4.891e-01],
         [-1.474e+00],
         [-2.627e-01],
         [-5.927e-01],
         [-8.529e-01],
         [-6.615e-01],
         [ 2.379e-01],
         [-2.676e-01],
         [-6.520e-01],
         [-1.031e-01]],

        [[-4.551e-01],
         [ 1.510e+00],
         [ 9.076e-02],
         [-7.881e-01],
         [-2.839e-01],
         [-6.421e-01],
         [ 1.641e-01],
         [ 4.167e-01],
         [-4.272e-01],
         [-6.708e-01]],

        [[-6.862e-05],
         [-3.803e-01],
         [-7.390e-01],
         [-4.002e-01],
         [ 5.938e-02],
         [-5.790e-01],
         [ 1.273e+00],
         [-5.317e-02],
         [-8.462e-01],
         [-4.553e-01]]], device='cuda:0')
v tensor([[[1.559e-01],
         [1.000e-12],
         [1.000e-12],
         [7.372e+00],
         [1.000e-12],
         [3.259e-01],
         [5.577e-01],
         [1.000e-12],
         [7.645e-02],
         [1.247e-01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.946e-01],
         [6.747e-01],
         [1.000e-12],
         [1.000e-12],
         [9.018e-01],
         [1.000e-12],
         [3.687e+00]],

        [[1.000e-12],
         [1.000e-12],
         [4.666e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.481e+00],
         [1.000e-12]],

        [[7.085e-01],
         [1.278e+00],
         [3.519e-01],
         [1.000e-12],
         [1.000e-12],
         [1.641e+00],
         [1.000e-12],
         [1.000e-12],
         [7.349e-01],
         [1.620e-01]],

        [[5.837e-02],
         [1.216e-01],
         [8.860e-02],
         [1.000e-12],
         [7.824e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.509e-01],
         [1.000e-12],
         [1.000e-12],
         [6.451e-01],
         [1.000e-12],
         [1.000e-12],
         [1.798e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.805e+00],
         [1.000e-12],
         [4.747e-01],
         [1.000e-12],
         [3.430e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[4.891e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.379e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.510e+00],
         [9.076e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.641e-01],
         [4.167e-01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.938e-02],
         [1.000e-12],
         [1.273e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[ 0.223],
        [ 4.622],
        [-0.303],
        [-1.059],
        [ 0.848],
        [ 7.776],
        [10.890],
        [-0.217],
        [-0.516],
        [-1.376]], device='cuda:0')
v tensor([[2.229e-01],
        [4.622e+00],
        [1.000e-12],
        [1.000e-12],
        [8.478e-01],
        [7.776e+00],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 6.931e-03, -1.771e-02,  2.384e-02,  1.099e-02,  3.354e-03,  7.493e-03,
         -5.088e-02,  2.864e-02,  1.420e-03, -3.626e-02],
        [ 1.715e-03,  2.377e-02,  2.185e-02, -8.261e-03,  1.604e-02, -2.595e-02,
          6.481e-03,  1.041e-02, -1.593e-02, -9.798e-03],
        [-1.242e-03, -1.536e-02,  8.429e-03,  4.117e-03, -7.468e-03,  1.479e-02,
          1.645e-02,  4.892e-03, -4.994e-04, -4.460e-04],
        [ 5.212e-04,  6.291e-04, -4.456e-03,  2.413e-03,  4.255e-02,  2.419e-02,
         -9.303e-03, -4.889e-03, -3.221e-02, -3.986e-03],
        [-6.830e-03, -1.683e-02, -8.794e-03, -1.985e-02, -1.560e-02,  1.688e-02,
          9.446e-03, -1.234e-02,  6.396e-03, -1.585e-02],
        [-4.029e-03,  2.635e-02,  9.395e-04,  3.741e-02, -1.498e-02, -1.867e-02,
         -3.333e-03, -8.033e-04, -8.727e-03,  2.280e-03],
        [-2.507e-04,  2.818e-03,  1.087e-02, -1.012e-05,  5.186e-03,  3.095e-02,
          4.436e-04, -6.178e-03,  1.055e-02, -2.993e-04],
        [ 2.660e-03,  2.219e-02,  7.242e-05,  7.364e-03, -6.557e-03,  1.439e-02,
          4.216e-03, -1.814e-02, -1.402e-02,  1.728e-03],
        [ 3.165e-03,  1.451e-03, -1.799e-02,  2.258e-02, -2.390e-02,  1.322e-02,
          3.505e-04, -7.445e-02,  8.852e-05, -1.343e-02],
        [ 7.047e-03, -4.320e-02, -3.383e-02, -1.582e-02, -5.685e-03,  3.897e-03,
         -4.392e-03,  1.265e-02, -2.275e-02, -1.757e-02],
        [ 1.858e-02,  5.419e-04, -1.004e-02,  1.677e-02,  1.393e-03,  6.561e-03,
          8.835e-03,  2.028e-02, -3.486e-03,  2.065e-02],
        [ 1.041e-02, -5.776e-03,  1.268e-02,  3.835e-02,  1.102e-03,  5.150e-04,
         -3.366e-02, -2.730e-02, -1.586e-02, -3.405e-04],
        [-2.519e-02, -5.493e-03, -5.604e-03,  1.047e-02, -3.436e-02, -1.152e-04,
         -7.643e-03,  1.673e-02, -2.403e-02,  1.496e-02],
        [ 2.024e-02, -1.107e-02,  5.295e-03, -7.698e-03,  2.406e-02, -5.111e-04,
         -3.652e-04,  9.893e-03, -2.043e-03, -2.556e-02],
        [ 3.721e-03, -4.393e-03,  4.285e-03,  2.070e-02,  2.544e-02,  1.713e-02,
          2.310e-02,  8.010e-05,  9.435e-03, -1.629e-03],
        [ 2.427e-03,  1.099e-02, -4.987e-03, -2.637e-03, -1.963e-02,  8.125e-03,
          5.607e-03, -3.863e-03,  5.549e-02, -2.045e-02],
        [ 1.344e-03, -5.533e-03, -9.204e-03, -1.314e-02, -2.515e-03,  3.573e-02,
          3.077e-03, -2.516e-02, -2.163e-03,  6.799e-03],
        [ 2.794e-03, -1.045e-03, -4.119e-03, -1.545e-02, -6.853e-03,  1.899e-02,
          1.410e-02,  9.958e-03,  1.096e-02, -1.471e-02],
        [ 1.644e-02,  2.879e-03, -4.823e-03,  5.578e-02, -1.608e-02, -2.696e-02,
         -2.130e-03, -1.506e-02, -3.985e-02, -1.190e-02],
        [ 2.740e-03, -4.158e-03, -2.385e-02, -1.595e-03, -1.001e-02,  2.048e-02,
          8.157e-03, -1.166e-02,  4.946e-02,  3.125e-03],
        [-9.521e-03,  3.456e-03, -6.879e-03,  2.663e-02, -2.223e-03, -3.780e-03,
          6.428e-03, -2.436e-02,  7.530e-04, -9.163e-04],
        [-2.860e-02,  1.134e-02,  1.327e-02, -1.202e-02, -7.516e-03,  5.752e-03,
          2.174e-03, -1.268e-02,  4.040e-03, -3.185e-02],
        [ 2.232e-04,  1.345e-02, -2.124e-03, -3.804e-02,  2.594e-03, -2.808e-02,
         -4.636e-03,  1.270e-02,  3.387e-03,  3.388e-03],
        [ 1.642e-02, -4.283e-02, -2.740e-03,  1.219e-02,  1.330e-03, -4.830e-03,
         -8.637e-03,  1.171e-02,  3.247e-03, -3.343e-03],
        [-2.957e-02, -4.108e-03,  3.080e-03, -7.919e-03, -5.607e-03,  8.994e-03,
         -3.436e-03, -1.275e-02,  1.886e-02, -1.248e-02],
        [ 3.286e-03, -1.531e-03,  1.152e-03, -2.820e-02,  3.755e-03, -3.546e-02,
          1.485e-04,  1.004e-02,  2.532e-02, -1.534e-03],
        [-1.409e-02,  2.254e-02, -9.326e-03,  5.276e-03,  8.188e-03,  1.037e-02,
          1.199e-02,  2.382e-03, -5.565e-03,  1.062e-02],
        [ 4.967e-02, -3.707e-03,  1.362e-02,  1.513e-03, -3.035e-02, -1.884e-02,
          1.185e-02, -1.672e-04, -1.139e-02, -1.456e-02],
        [ 8.157e-04,  1.898e-03, -1.343e-02,  4.838e-03, -2.937e-03,  8.297e-03,
         -7.882e-03,  4.459e-03, -5.004e-03,  1.514e-02],
        [ 3.165e-03,  1.094e-03, -2.400e-03, -3.083e-02, -1.370e-02,  1.390e-02,
          1.283e-02,  1.567e-02, -1.405e-02,  4.384e-02],
        [ 1.746e-03, -7.110e-03, -3.805e-03,  1.302e-03,  1.895e-02,  5.939e-04,
          4.723e-03, -2.666e-03, -2.522e-02, -1.603e-02],
        [-1.769e-03,  5.571e-03,  4.600e-03, -1.376e-03,  7.592e-04,  8.467e-04,
         -5.359e-03, -1.208e-03, -2.107e-02, -5.525e-03],
        [ 4.362e-03, -1.568e-03,  8.613e-04,  3.194e-03,  6.545e-03, -2.932e-03,
         -2.346e-02, -1.763e-03, -6.262e-03,  2.822e-04],
        [ 5.350e-04, -6.166e-03, -4.000e-03,  2.810e-03,  3.157e-03,  1.152e-03,
          1.555e-02, -1.565e-03,  5.990e-03,  2.036e-03],
        [ 5.780e-04, -3.873e-03, -1.768e-03, -5.125e-03,  5.322e-03, -1.559e-02,
          1.693e-02, -3.246e-02, -5.983e-03, -8.048e-03],
        [-3.054e-04, -1.637e-02, -5.563e-03,  2.286e-03,  1.364e-03, -7.873e-03,
          4.817e-04,  1.899e-02, -1.839e-02, -4.010e-03],
        [ 1.113e-02,  2.018e-03,  1.331e-03,  1.399e-02, -1.448e-02, -3.046e-03,
          1.647e-03, -9.572e-04, -9.809e-03, -5.461e-03],
        [ 5.311e-03, -5.503e-03,  7.093e-03,  4.980e-03,  1.778e-03,  2.259e-03,
          1.681e-02,  2.998e-03, -9.027e-03, -1.187e-02],
        [ 2.232e-02, -1.577e-03, -7.982e-03,  1.097e-03,  1.366e-03, -7.780e-04,
         -1.022e-03,  1.533e-03, -9.103e-03,  8.238e-03],
        [-1.472e-02, -9.366e-03, -4.874e-03,  5.666e-03,  2.149e-02,  7.138e-03,
          2.708e-03,  1.616e-02,  3.169e-03,  5.837e-03],
        [ 3.692e-03, -1.496e-02, -2.044e-02,  1.983e-02, -1.429e-03, -3.384e-03,
          5.767e-02, -6.327e-03, -4.390e-02, -2.725e-03],
        [ 5.608e-02, -3.161e-02, -1.583e-02,  5.639e-03, -3.769e-04,  5.728e-03,
         -8.591e-03,  1.491e-02, -4.552e-03,  2.962e-03],
        [ 3.435e-04,  2.596e-02, -1.296e-02, -3.053e-03, -2.091e-03, -1.392e-02,
         -4.853e-03,  1.035e-02, -1.889e-02,  6.537e-03],
        [-1.448e-02, -7.230e-03, -1.772e-02, -4.032e-03, -3.581e-03, -8.552e-04,
         -6.035e-03, -6.750e-03, -5.906e-04,  4.664e-03],
        [ 4.360e-03,  1.693e-02,  1.485e-02,  1.229e-03, -1.238e-02, -1.799e-02,
          7.561e-03, -1.928e-03, -8.647e-03, -3.570e-03],
        [ 1.426e-02,  4.543e-03, -2.928e-02,  5.555e-03,  4.242e-03, -8.084e-03,
          3.369e-02,  2.910e-02,  3.350e-02, -2.159e-02],
        [ 1.709e-02,  7.978e-03,  9.533e-03,  1.700e-02,  3.344e-03,  3.497e-02,
          2.575e-03,  2.102e-02, -1.300e-02,  2.567e-03],
        [ 8.550e-03, -1.620e-03,  6.314e-03, -3.436e-02,  1.840e-03,  4.257e-03,
          9.023e-04,  1.126e-02,  1.409e-02, -3.387e-03],
        [-5.632e-03,  3.901e-02, -1.950e-02, -4.425e-03, -1.403e-02,  6.627e-03,
          5.211e-03,  1.488e-02,  1.837e-02, -8.559e-03],
        [-2.029e-03, -4.430e-02, -1.949e-02,  1.967e-02,  1.205e-03,  7.628e-03,
         -3.945e-03,  1.401e-02, -9.513e-03,  2.079e-03],
        [-1.134e-03, -1.239e-03,  5.504e-03,  2.245e-02, -1.930e-03,  4.443e-03,
          1.351e-02,  2.478e-03,  1.528e-02, -2.297e-02],
        [ 7.923e-03,  1.048e-02, -1.012e-02,  3.144e-02,  1.992e-02, -4.692e-03,
          3.125e-03, -1.216e-02, -2.980e-04,  1.507e-02],
        [-2.552e-02, -3.674e-02, -3.002e-03,  8.644e-04,  1.196e-02, -1.705e-03,
          1.419e-02,  6.018e-04, -1.601e-02,  9.160e-03],
        [ 1.567e-02, -1.119e-03,  5.254e-04,  1.576e-02,  1.076e-02, -4.969e-03,
          1.921e-02, -2.921e-02, -1.352e-02, -1.636e-02],
        [ 3.216e-03,  6.068e-03, -1.581e-02,  2.916e-02,  9.872e-05, -3.363e-03,
          9.176e-02,  1.091e-02, -1.968e-02, -3.725e-03],
        [ 1.945e-02,  1.626e-02, -1.825e-02, -4.642e-03,  7.556e-04, -2.732e-03,
         -1.228e-02, -3.067e-03,  1.071e-02,  2.127e-02],
        [-9.218e-03,  4.212e-03, -3.254e-03, -2.919e-02, -6.162e-03, -2.262e-03,
         -9.254e-02,  4.565e-03, -2.537e-02,  1.637e-02],
        [-1.009e-03,  1.070e-02, -1.486e-03,  8.500e-03, -1.196e-02, -9.858e-04,
          1.286e-02, -1.176e-02,  9.871e-03, -2.085e-02],
        [ 9.631e-03,  6.227e-03, -1.311e-02,  7.935e-03,  2.421e-04,  1.613e-03,
         -1.131e-02, -1.281e-02,  3.024e-03, -4.122e-03],
        [-1.120e-02, -1.149e-02, -5.933e-03, -2.779e-03,  2.572e-02, -6.149e-03,
          7.185e-03,  1.691e-02,  1.215e-02, -2.198e-05],
        [ 1.467e-02, -6.660e-03,  3.549e-03,  7.043e-03, -2.184e-03,  1.201e-03,
         -2.719e-03,  7.964e-03,  2.239e-02, -8.344e-04],
        [ 1.344e-03,  2.974e-04, -8.065e-03,  2.120e-02,  8.942e-04, -1.233e-02,
         -1.570e-02, -1.117e-02, -7.784e-03, -1.287e-02],
        [-6.758e-03,  4.149e-03, -4.709e-03,  1.084e-02,  4.836e-03, -1.980e-02,
         -2.288e-03, -1.497e-02,  1.330e-03,  1.708e-02],
        [ 1.638e-02,  2.011e-03,  1.111e-02,  3.089e-02,  1.812e-02, -2.965e-02,
         -4.720e-03,  2.261e-04,  5.886e-03, -1.223e-02],
        [-7.466e-03, -9.806e-04, -4.831e-03, -6.324e-03,  2.888e-03, -6.608e-04,
         -6.647e-03, -1.338e-02,  1.834e-03,  7.602e-03],
        [ 1.250e-02, -7.619e-03,  2.416e-02,  1.944e-02, -6.833e-04, -8.350e-03,
          2.638e-03,  1.089e-02, -2.776e-03,  6.577e-03],
        [-1.042e-02,  3.471e-03,  3.579e-03, -6.837e-03, -1.072e-02,  1.382e-02,
         -2.409e-03,  1.877e-02, -1.204e-03, -6.175e-03],
        [ 2.531e-02, -1.895e-02, -8.596e-03, -3.303e-02,  1.361e-02,  1.985e-02,
          5.603e-03,  4.901e-03,  4.535e-03, -3.471e-03],
        [ 1.549e-02, -3.416e-03, -1.065e-02, -8.406e-03, -7.196e-03,  6.353e-03,
          3.206e-03,  3.146e-02, -4.757e-03,  5.714e-03],
        [ 4.436e-03,  1.660e-03,  1.632e-03,  3.819e-02, -2.186e-02, -2.296e-04,
         -9.598e-04, -5.937e-03, -2.136e-03, -7.782e-03],
        [ 3.376e-03, -4.986e-03, -1.187e-02, -9.139e-03,  3.139e-05,  1.114e-04,
          2.332e-02, -7.909e-04, -2.485e-04, -1.964e-03],
        [ 4.801e-03, -1.370e-02, -1.138e-02,  7.220e-04,  1.185e-02, -3.979e-03,
          2.429e-02,  2.621e-03,  1.826e-02,  1.833e-02],
        [ 8.057e-03, -6.527e-03, -2.413e-03, -1.037e-02,  5.613e-03, -5.869e-04,
         -3.625e-02,  4.371e-03, -5.728e-04, -1.215e-02],
        [-1.182e-02, -2.173e-02,  4.219e-03, -1.925e-02,  1.554e-03,  1.742e-03,
          2.072e-02,  8.781e-05,  4.579e-02, -3.590e-02],
        [-7.614e-03,  1.050e-02,  2.597e-02, -3.337e-03, -4.603e-04, -1.559e-02,
          7.301e-03, -4.076e-03, -3.821e-03, -1.112e-02],
        [-8.121e-03,  4.104e-03,  1.506e-02,  4.989e-02, -2.408e-02, -7.412e-03,
         -4.382e-03, -7.116e-03, -7.561e-03, -3.533e-03],
        [ 1.908e-02,  1.595e-03, -2.445e-03,  2.232e-03,  3.730e-02,  1.094e-02,
         -8.589e-03, -2.817e-04,  1.152e-02, -2.144e-03],
        [-1.033e-02, -1.766e-03,  1.695e-02,  6.512e-03,  4.242e-03,  2.441e-03,
         -9.567e-05, -2.130e-03, -8.187e-03, -1.774e-02],
        [ 2.249e-03, -2.132e-02,  4.975e-03,  9.698e-03, -8.177e-03,  2.820e-02,
          2.150e-02, -3.627e-03, -1.283e-02, -1.749e-02],
        [-6.958e-05, -2.943e-02, -2.232e-02,  5.018e-04, -9.141e-03, -7.509e-04,
         -3.296e-03, -2.720e-03, -8.064e-03, -1.436e-02],
        [ 5.920e-03, -4.413e-03,  1.251e-02, -1.401e-03, -7.355e-03,  1.778e-03,
          2.483e-03,  7.762e-03, -8.689e-03,  7.822e-03],
        [-2.170e-03, -2.707e-03,  1.082e-02, -1.944e-02,  2.595e-02, -9.020e-03,
          1.165e-02, -3.608e-02, -2.031e-03, -2.609e-02],
        [ 7.058e-03,  1.136e-03, -3.744e-03,  2.875e-03, -3.524e-03, -1.608e-02,
         -1.064e-02, -1.414e-02,  1.060e-02, -2.061e-04],
        [-1.397e-02,  3.626e-03,  8.653e-03,  8.641e-03,  9.161e-03, -1.237e-03,
          1.151e-02, -1.257e-02,  7.854e-03,  2.251e-03],
        [ 1.371e-02, -4.797e-03, -6.106e-03,  1.525e-02,  3.493e-03, -6.999e-03,
         -1.763e-03,  6.337e-03,  2.731e-03, -2.892e-04],
        [-1.107e-02,  2.634e-03,  3.400e-03,  2.493e-02, -4.429e-03,  5.834e-03,
          1.089e-02, -1.103e-02,  3.946e-03,  6.573e-03],
        [-1.452e-02,  2.637e-03, -1.284e-02, -6.989e-03, -4.918e-04,  2.916e-03,
         -2.713e-02, -1.997e-02, -3.717e-03, -9.609e-03],
        [ 2.358e-03,  1.389e-02, -2.783e-03,  9.559e-03, -1.276e-02,  5.866e-04,
         -1.276e-02,  1.221e-02,  1.238e-03, -1.315e-02],
        [-4.425e-03, -4.008e-03, -1.130e-03,  9.050e-03,  7.293e-04, -3.499e-04,
         -2.512e-03,  4.197e-04,  5.813e-04,  2.192e-03],
        [-3.298e-04,  1.552e-03, -1.963e-02, -6.474e-03,  1.127e-02,  2.983e-03,
          2.832e-03,  1.782e-02,  2.128e-02, -6.254e-04],
        [ 1.948e-02,  3.741e-03, -2.168e-02, -4.709e-03,  4.053e-03, -1.684e-02,
         -9.955e-03,  4.170e-02,  2.100e-02,  1.944e-02],
        [ 2.248e-02,  2.609e-03,  2.121e-03, -9.621e-03,  1.977e-03,  6.708e-03,
          4.888e-03, -6.673e-03, -2.996e-02,  1.273e-02],
        [ 9.401e-04, -3.966e-03, -1.074e-02, -8.451e-03,  1.148e-02, -1.299e-02,
          1.029e-02,  2.084e-02,  4.276e-03,  2.885e-03],
        [-2.762e-02,  2.117e-03, -2.562e-03,  7.080e-03,  4.349e-04,  1.112e-02,
          2.446e-02,  7.539e-03, -6.420e-03, -2.670e-03],
        [ 4.019e-02,  2.068e-03, -2.412e-02, -6.071e-03, -4.234e-03,  4.386e-04,
         -2.491e-03,  6.247e-03,  6.202e-03,  2.963e-03],
        [-1.545e-02,  3.448e-02, -2.545e-04, -2.288e-02,  4.188e-03, -1.941e-02,
          8.097e-03, -4.147e-03,  2.832e-02,  3.206e-03],
        [ 1.360e-02, -1.283e-02, -8.931e-04,  1.402e-03, -5.659e-03,  2.164e-02,
         -1.860e-02,  1.597e-02, -9.840e-03, -2.136e-04],
        [ 1.565e-02, -6.473e-03, -1.417e-02,  1.066e-03, -4.267e-02,  5.986e-04,
          8.587e-03,  1.317e-02, -1.042e-02, -6.716e-04],
        [ 1.143e-02,  3.659e-02, -5.708e-03, -9.553e-04, -1.283e-02,  2.819e-02,
          9.975e-03, -2.259e-02, -2.007e-02,  2.947e-03],
        [ 2.252e-02, -1.360e-02, -1.685e-02, -4.557e-04,  2.937e-03, -2.013e-02,
         -5.497e-02,  6.842e-03, -7.722e-03,  4.843e-03]], device='cuda:0')
s after update for 1 param tensor([[0.613, 0.590, 0.736, 0.487, 0.532, 0.559, 0.636, 0.488, 1.041, 0.422],
        [0.465, 0.479, 0.523, 0.419, 0.848, 0.507, 0.515, 0.857, 0.454, 0.490],
        [0.647, 0.797, 0.634, 0.703, 0.685, 1.134, 0.692, 0.962, 0.663, 0.784],
        [0.431, 0.901, 1.224, 0.809, 0.484, 0.169, 0.590, 0.438, 0.448, 0.805],
        [1.353, 0.519, 0.532, 0.523, 0.395, 0.625, 0.772, 0.463, 0.604, 0.987],
        [0.883, 0.466, 0.779, 0.514, 0.512, 0.477, 0.483, 0.478, 0.575, 0.758],
        [0.600, 0.449, 1.030, 0.567, 0.476, 0.403, 0.571, 0.420, 0.225, 0.623],
        [0.557, 0.857, 0.315, 0.486, 0.772, 0.804, 0.570, 0.510, 0.387, 1.006],
        [1.149, 0.671, 0.827, 0.474, 0.776, 0.943, 0.882, 1.115, 0.529, 0.704],
        [1.211, 0.653, 0.837, 0.731, 0.731, 0.789, 0.606, 0.857, 0.585, 0.981],
        [0.904, 0.772, 0.564, 0.363, 0.810, 0.959, 0.623, 0.414, 0.609, 0.776],
        [0.307, 0.821, 0.393, 1.204, 0.587, 0.270, 1.002, 0.751, 0.254, 0.422],
        [0.843, 0.981, 1.046, 0.920, 0.526, 0.662, 1.513, 0.473, 0.318, 0.804],
        [1.315, 0.473, 0.585, 0.294, 0.692, 0.484, 0.329, 0.680, 0.553, 0.516],
        [0.748, 0.891, 0.827, 0.789, 0.505, 0.491, 0.739, 0.592, 0.570, 0.477],
        [0.318, 0.858, 0.568, 0.668, 0.376, 0.799, 0.666, 0.726, 0.248, 0.415],
        [0.630, 0.701, 0.760, 0.644, 0.985, 0.625, 0.524, 0.357, 0.684, 0.484],
        [0.696, 0.641, 0.544, 0.635, 0.537, 0.805, 0.595, 0.733, 0.277, 0.403],
        [0.365, 0.886, 0.590, 0.459, 0.894, 0.743, 0.614, 0.583, 0.433, 0.553],
        [0.661, 0.442, 1.121, 0.507, 0.493, 0.315, 0.611, 0.576, 0.755, 0.427],
        [0.498, 0.675, 1.062, 0.435, 0.561, 0.661, 0.737, 0.447, 0.609, 0.606],
        [0.785, 0.688, 0.965, 0.362, 0.567, 1.099, 0.581, 0.455, 0.648, 0.725],
        [0.645, 0.621, 0.529, 0.730, 0.742, 0.526, 0.550, 0.727, 0.654, 0.858],
        [0.505, 0.219, 0.618, 0.360, 0.269, 0.590, 0.424, 0.475, 0.183, 0.880],
        [0.807, 0.549, 0.672, 0.686, 0.425, 0.358, 0.598, 0.663, 0.680, 0.810],
        [0.409, 0.544, 0.595, 0.489, 0.449, 0.403, 0.305, 0.459, 0.545, 0.662],
        [0.832, 0.546, 1.025, 0.485, 0.778, 0.934, 0.567, 0.600, 0.263, 0.849],
        [1.071, 0.866, 1.005, 0.545, 0.548, 0.643, 1.050, 0.597, 0.602, 0.662],
        [0.576, 0.509, 1.184, 0.308, 0.566, 0.557, 0.688, 0.327, 0.529, 0.345],
        [0.293, 0.211, 0.845, 0.557, 0.589, 0.710, 0.371, 0.431, 0.360, 0.675],
        [0.453, 0.609, 0.620, 0.303, 0.533, 0.726, 0.615, 0.366, 0.611, 0.656],
        [0.410, 0.358, 0.284, 0.799, 0.464, 0.631, 0.593, 0.492, 0.392, 0.709],
        [0.633, 0.427, 0.468, 0.690, 0.718, 0.386, 0.547, 0.962, 0.380, 0.320],
        [0.529, 0.466, 0.476, 0.745, 0.653, 0.897, 0.739, 0.769, 0.259, 0.760],
        [0.626, 0.895, 0.581, 0.526, 0.650, 0.605, 0.877, 0.494, 0.658, 0.795],
        [0.738, 0.596, 0.303, 0.768, 0.536, 0.720, 0.189, 0.555, 0.494, 0.564],
        [0.594, 0.602, 0.826, 1.124, 0.963, 0.735, 0.556, 1.115, 0.428, 0.486],
        [0.380, 0.769, 0.535, 0.894, 0.315, 0.806, 0.559, 0.474, 0.695, 0.636],
        [0.752, 1.008, 0.525, 0.696, 0.564, 0.575, 0.430, 0.760, 0.834, 0.429],
        [0.721, 0.586, 0.471, 0.652, 0.731, 0.552, 0.463, 0.519, 0.711, 0.523],
        [0.562, 0.543, 0.436, 0.679, 0.535, 0.423, 0.985, 0.291, 0.502, 0.848],
        [1.122, 0.658, 0.716, 0.897, 1.034, 0.654, 0.404, 0.561, 0.778, 0.425],
        [0.617, 0.843, 0.511, 0.665, 1.021, 0.688, 0.302, 0.554, 0.475, 0.545],
        [0.383, 0.486, 0.591, 0.673, 0.762, 0.474, 0.698, 0.567, 0.512, 0.537],
        [0.278, 0.526, 0.445, 0.445, 0.707, 0.698, 0.657, 0.454, 0.504, 0.619],
        [0.379, 0.685, 0.434, 0.299, 0.907, 0.823, 0.546, 0.548, 0.862, 0.549],
        [0.614, 1.543, 0.377, 1.142, 1.023, 0.791, 0.695, 0.858, 0.516, 1.034],
        [0.581, 0.404, 0.460, 0.965, 0.545, 0.332, 0.692, 1.242, 0.823, 0.350],
        [0.979, 0.697, 0.648, 0.436, 1.469, 0.883, 0.809, 0.879, 0.450, 0.896],
        [0.397, 0.718, 0.778, 0.571, 0.838, 0.995, 0.969, 0.340, 1.165, 0.508],
        [0.479, 0.698, 0.417, 0.417, 1.152, 1.097, 0.633, 0.680, 0.520, 0.629],
        [0.478, 0.854, 0.464, 0.405, 0.581, 0.704, 0.511, 0.505, 0.811, 0.641],
        [0.918, 0.821, 0.494, 0.556, 0.643, 0.580, 0.804, 0.459, 0.304, 0.867],
        [0.630, 0.653, 1.169, 0.405, 0.854, 0.546, 0.959, 0.529, 0.446, 0.274],
        [0.535, 0.649, 0.548, 0.443, 0.377, 0.992, 0.771, 0.861, 0.360, 0.691],
        [0.260, 0.770, 0.509, 0.732, 0.591, 0.866, 0.924, 0.748, 0.583, 0.947],
        [0.396, 0.656, 0.434, 0.673, 0.704, 0.861, 0.832, 0.621, 0.452, 1.172],
        [0.565, 0.569, 1.010, 0.483, 0.580, 0.520, 0.563, 0.319, 0.294, 0.747],
        [0.382, 0.651, 0.582, 0.510, 0.548, 0.585, 0.579, 0.745, 0.412, 0.315],
        [0.835, 0.809, 0.935, 0.978, 0.911, 0.829, 0.606, 0.720, 0.310, 0.584],
        [0.302, 0.886, 0.532, 0.440, 0.792, 0.802, 0.961, 1.067, 0.436, 0.754],
        [1.161, 1.184, 1.172, 0.313, 0.740, 0.614, 0.868, 0.546, 0.541, 0.386],
        [0.787, 0.760, 0.530, 0.677, 1.208, 0.956, 0.991, 0.907, 0.576, 0.773],
        [0.290, 0.605, 0.786, 0.566, 0.328, 0.315, 0.965, 0.312, 0.403, 0.740],
        [0.880, 0.755, 0.968, 0.501, 1.133, 0.866, 1.215, 0.693, 0.822, 0.351],
        [0.830, 0.620, 0.568, 0.263, 0.530, 0.618, 0.819, 0.681, 0.926, 0.573],
        [1.004, 1.134, 0.382, 0.454, 1.037, 0.336, 0.509, 1.037, 0.521, 0.674],
        [1.052, 0.769, 0.647, 0.877, 0.909, 0.713, 0.404, 1.352, 0.657, 0.988],
        [0.945, 0.901, 0.607, 0.499, 0.977, 0.556, 1.454, 0.857, 0.483, 1.201],
        [0.452, 0.512, 0.267, 0.539, 0.436, 0.375, 0.458, 0.415, 0.753, 0.508],
        [0.350, 0.533, 0.334, 0.498, 0.727, 0.634, 0.663, 0.751, 0.609, 0.693],
        [0.508, 0.381, 0.684, 0.544, 0.983, 0.251, 0.345, 1.070, 0.554, 0.797],
        [0.905, 0.279, 0.532, 0.618, 0.434, 0.580, 0.540, 0.643, 0.793, 0.428],
        [0.785, 0.967, 0.406, 0.190, 0.410, 0.895, 0.783, 0.731, 0.602, 0.675],
        [0.268, 0.563, 1.052, 0.479, 0.506, 1.335, 0.415, 0.700, 0.565, 0.576],
        [0.313, 0.391, 0.998, 0.588, 0.280, 0.278, 0.359, 0.658, 0.523, 0.315],
        [0.576, 0.697, 0.691, 0.314, 0.676, 0.883, 0.994, 0.728, 0.659, 1.060],
        [0.486, 0.429, 0.629, 0.186, 0.695, 0.575, 1.126, 0.694, 0.992, 0.607],
        [0.257, 0.596, 0.760, 0.422, 0.403, 0.753, 0.707, 0.626, 0.809, 0.890],
        [0.389, 0.677, 0.370, 0.220, 0.654, 0.541, 0.507, 0.952, 0.446, 0.451],
        [0.555, 0.918, 0.402, 0.389, 0.413, 0.372, 0.473, 0.336, 0.606, 0.744],
        [0.644, 0.604, 0.869, 0.269, 0.480, 0.777, 1.035, 0.570, 0.528, 0.471],
        [0.504, 0.633, 0.323, 0.401, 0.433, 0.847, 0.354, 0.447, 0.600, 0.602],
        [0.298, 0.752, 0.538, 0.823, 0.780, 0.444, 0.718, 0.618, 0.646, 0.646],
        [0.508, 0.643, 0.321, 0.496, 0.969, 1.102, 0.434, 0.386, 0.785, 0.581],
        [0.533, 0.370, 0.183, 0.637, 0.510, 0.884, 0.382, 0.691, 0.601, 0.454],
        [0.498, 0.631, 0.448, 0.683, 0.595, 0.449, 0.506, 0.479, 0.921, 1.023],
        [0.452, 0.717, 0.310, 0.610, 1.189, 0.262, 0.299, 0.519, 0.468, 1.087],
        [0.504, 0.469, 0.340, 0.299, 0.538, 0.445, 0.568, 0.353, 0.734, 0.358],
        [0.804, 0.916, 0.532, 0.465, 0.744, 0.480, 0.340, 0.710, 0.756, 0.418],
        [0.541, 0.799, 0.394, 0.482, 1.222, 0.765, 0.953, 0.766, 0.821, 1.259],
        [1.262, 0.660, 0.815, 1.020, 0.478, 0.620, 0.725, 0.748, 0.302, 1.518],
        [0.280, 0.612, 0.614, 0.266, 0.475, 0.497, 0.742, 0.316, 0.778, 0.813],
        [1.053, 0.722, 0.714, 0.751, 0.843, 0.603, 1.476, 1.328, 0.752, 1.385],
        [0.672, 0.692, 0.898, 0.371, 0.485, 0.666, 0.745, 0.268, 0.956, 1.051],
        [0.953, 0.841, 0.552, 0.573, 1.043, 0.533, 0.563, 0.381, 0.497, 1.732],
        [1.366, 0.488, 0.666, 0.702, 0.569, 0.775, 0.767, 0.566, 0.375, 0.946],
        [0.674, 0.416, 0.537, 0.990, 0.457, 0.514, 0.449, 0.581, 0.268, 0.694],
        [0.604, 0.674, 1.099, 0.558, 0.372, 0.516, 0.530, 0.470, 0.583, 0.610],
        [0.635, 0.636, 0.701, 0.568, 0.655, 0.758, 0.720, 0.813, 0.633, 0.883]],
       device='cuda:0')
b after update for 1 param tensor([[21.891, 21.473, 23.985, 19.514, 20.387, 20.904, 22.292, 19.533, 28.530,
         18.153],
        [19.065, 19.355, 20.212, 18.101, 25.742, 19.906, 20.058, 25.880, 18.838,
         19.582],
        [22.498, 24.967, 22.266, 23.445, 23.139, 29.778, 23.261, 27.426, 22.762,
         24.762],
        [18.362, 26.543, 30.935, 25.153, 19.449, 11.487, 21.483, 18.500, 18.723,
         25.092],
        [32.521, 20.145, 20.395, 20.218, 17.571, 22.101, 24.565, 19.028, 21.738,
         27.771],
        [26.268, 19.086, 24.672, 20.053, 20.009, 19.314, 19.426, 19.337, 21.199,
         24.344],
        [21.654, 18.737, 28.372, 21.045, 19.284, 17.741, 21.130, 18.115, 13.263,
         22.065],
        [20.868, 25.880, 15.701, 19.485, 24.569, 25.071, 21.107, 19.971, 17.385,
         28.040],
        [29.966, 22.907, 25.428, 19.248, 24.624, 27.148, 26.253, 29.522, 20.332,
         23.452],
        [30.770, 22.589, 25.577, 23.910, 23.901, 24.842, 21.772, 25.888, 21.393,
         27.694],
        [26.581, 24.568, 21.002, 16.857, 25.164, 27.374, 22.071, 17.996, 21.815,
         24.627],
        [15.494, 25.336, 17.525, 30.676, 21.422, 14.542, 27.992, 24.235, 14.097,
         18.163],
        [25.678, 27.693, 28.598, 26.815, 20.276, 22.744, 34.396, 19.240, 15.756,
         25.069],
        [32.067, 19.234, 21.384, 15.172, 23.265, 19.452, 16.035, 23.053, 20.801,
         20.082],
        [24.175, 26.390, 25.422, 24.841, 19.876, 19.589, 24.044, 21.509, 21.105,
         19.302],
        [15.759, 25.905, 21.072, 22.861, 17.152, 24.994, 22.826, 23.830, 13.938,
         18.002],
        [22.187, 23.404, 24.379, 22.443, 27.743, 22.107, 20.231, 16.702, 23.130,
         19.447],
        [23.324, 22.380, 20.619, 22.278, 20.487, 25.085, 21.569, 23.932, 14.720,
         17.750],
        [16.893, 26.315, 21.477, 18.946, 26.438, 24.103, 21.911, 21.348, 18.394,
         20.797],
        [22.734, 18.579, 29.600, 19.913, 19.640, 15.701, 21.850, 21.212, 24.301,
         18.260],
        [19.724, 22.980, 28.820, 18.433, 20.949, 22.728, 24.000, 18.693, 21.815,
         21.768],
        [24.774, 23.188, 27.467, 16.830, 21.058, 29.310, 21.317, 18.852, 22.502,
         23.810],
        [22.463, 22.030, 20.333, 23.887, 24.092, 20.276, 20.735, 23.836, 22.612,
         25.895],
        [19.861, 13.082, 21.987, 16.770, 14.505, 21.474, 18.210, 19.267, 11.954,
         26.232],
        [25.113, 20.718, 22.914, 23.157, 18.226, 16.721, 21.629, 22.760, 23.058,
         25.167],
        [17.883, 20.631, 21.561, 19.544, 18.730, 17.746, 15.449, 18.942, 20.633,
         22.756],
        [25.502, 20.653, 28.314, 19.472, 24.654, 27.025, 21.054, 21.659, 14.352,
         25.759],
        [28.943, 26.015, 28.035, 20.647, 20.704, 22.423, 28.647, 21.609, 21.693,
         22.745],
        [21.220, 19.957, 30.421, 15.505, 21.040, 20.876, 23.189, 15.989, 20.334,
         16.428],
        [15.134, 12.829, 25.698, 20.861, 21.453, 23.563, 17.027, 18.360, 16.776,
         22.964],
        [18.809, 21.826, 22.021, 15.381, 20.416, 23.822, 21.931, 16.920, 21.857,
         22.642],
        [17.901, 16.725, 14.897, 24.987, 19.047, 22.219, 21.540, 19.615, 17.510,
         23.537],
        [22.253, 18.263, 19.133, 23.231, 23.690, 17.365, 20.682, 27.428, 17.239,
         15.819],
        [20.331, 19.083, 19.300, 24.140, 22.589, 26.485, 24.036, 24.515, 14.216,
         24.371],
        [22.120, 26.448, 21.313, 20.283, 22.542, 21.744, 26.191, 19.653, 22.682,
         24.938],
        [24.027, 21.593, 15.403, 24.499, 20.475, 23.720, 12.141, 20.832, 19.660,
         20.991],
        [21.548, 21.700, 25.412, 29.646, 27.443, 23.966, 20.846, 29.519, 18.286,
         19.494],
        [17.231, 24.524, 20.453, 26.444, 15.693, 25.096, 20.900, 19.253, 23.307,
         22.295],
        [24.253, 28.077, 20.266, 23.328, 20.996, 21.207, 18.329, 24.374, 25.534,
         18.315],
        [23.747, 21.407, 19.188, 22.583, 23.899, 20.768, 19.018, 20.141, 23.578,
         20.226],
        [20.962, 20.603, 18.459, 23.038, 20.444, 18.183, 27.748, 15.071, 19.812,
         25.748],
        [29.612, 22.682, 23.660, 26.488, 28.427, 22.614, 17.779, 20.944, 24.667,
         18.227],
        [21.966, 25.675, 19.978, 22.793, 28.256, 23.185, 15.355, 20.809, 19.262,
         20.640],
        [17.295, 19.490, 21.496, 22.938, 24.407, 19.257, 23.353, 21.045, 20.011,
         20.497],
        [14.747, 20.285, 18.655, 18.641, 23.507, 23.353, 22.662, 18.847, 19.848,
         22.000],
        [17.215, 23.135, 18.423, 15.286, 26.631, 25.370, 20.669, 20.694, 25.961,
         20.708],
        [21.910, 34.731, 17.162, 29.884, 28.273, 24.865, 23.302, 25.905, 20.080,
         28.436],
        [21.321, 17.764, 18.960, 27.462, 20.649, 16.110, 23.252, 31.156, 25.365,
         16.536],
        [27.663, 23.341, 22.507, 18.466, 33.890, 26.278, 25.144, 26.220, 18.766,
         26.473],
        [17.622, 23.686, 24.667, 21.127, 25.599, 27.884, 27.520, 16.312, 30.179,
         19.921],
        [19.346, 23.362, 18.061, 18.045, 30.005, 29.291, 22.243, 23.054, 20.169,
         22.175],
        [19.336, 25.838, 19.050, 17.783, 21.316, 23.454, 19.993, 19.869, 25.177,
         22.379],
        [26.794, 25.333, 19.659, 20.844, 22.415, 21.300, 25.064, 18.934, 15.425,
         26.031],
        [22.196, 22.598, 30.236, 17.795, 25.844, 20.666, 27.375, 20.330, 18.667,
         14.627],
        [20.443, 22.529, 20.692, 18.614, 17.162, 27.852, 24.548, 25.942, 16.782,
         23.242],
        [14.251, 24.536, 19.955, 23.925, 21.503, 26.018, 26.881, 24.185, 21.349,
         27.206],
        [17.605, 22.647, 18.415, 22.930, 23.454, 25.940, 25.497, 22.035, 18.797,
         30.264],
        [21.017, 21.095, 28.098, 19.433, 21.291, 20.160, 20.973, 15.786, 15.156,
         24.164],
        [17.291, 22.562, 21.337, 19.965, 20.693, 21.378, 21.284, 24.141, 17.943,
         15.701],
        [25.551, 25.152, 27.036, 27.655, 26.690, 25.462, 21.765, 23.722, 15.562,
         21.373],
        [15.356, 26.320, 20.400, 18.553, 24.876, 25.040, 27.416, 28.887, 18.462,
         24.286],
        [30.126, 30.429, 30.266, 15.649, 24.058, 21.908, 26.042, 20.668, 20.565,
         17.381],
        [24.802, 24.375, 20.348, 23.012, 30.729, 27.336, 27.833, 26.629, 21.229,
         24.587],
        [15.070, 21.752, 24.790, 21.040, 16.007, 15.686, 27.463, 15.617, 17.748,
         24.050],
        [26.228, 24.296, 27.509, 19.785, 29.765, 26.015, 30.823, 23.280, 25.347,
         16.559],
        [25.477, 22.023, 21.076, 14.334, 20.360, 21.982, 25.309, 23.067, 26.913,
         21.162],
        [28.019, 29.770, 17.290, 18.839, 28.479, 16.202, 19.954, 28.469, 20.185,
         22.961],
        [28.677, 24.515, 22.484, 26.187, 26.653, 23.603, 17.769, 32.516, 22.664,
         27.793],
        [27.174, 26.533, 21.781, 19.745, 27.639, 20.850, 33.712, 25.888, 19.426,
         30.642],
        [18.808, 20.014, 14.458, 20.523, 18.469, 17.129, 18.920, 18.012, 24.266,
         19.933],
        [16.546, 20.420, 16.155, 19.724, 23.839, 22.264, 22.761, 24.234, 21.823,
         23.272],
        [19.922, 17.259, 23.124, 20.617, 27.717, 14.009, 16.434, 28.929, 20.807,
         24.955],
        [26.593, 14.776, 20.400, 21.980, 18.430, 21.296, 20.553, 22.420, 24.904,
         18.300],
        [24.775, 27.491, 17.812, 12.176, 17.904, 26.459, 24.746, 23.912, 21.701,
         22.971],
        [14.485, 20.980, 28.676, 19.360, 19.897, 32.308, 18.020, 23.400, 21.013,
         21.228],
        [15.635, 17.485, 27.936, 21.436, 14.795, 14.743, 16.762, 22.684, 20.227,
         15.687],
        [21.225, 23.337, 23.237, 15.662, 22.994, 26.276, 27.873, 23.853, 22.693,
         28.793],
        [19.501, 18.306, 22.167, 12.072, 23.318, 21.193, 29.673, 23.293, 27.849,
         21.791],
        [14.184, 21.585, 24.381, 18.164, 17.753, 24.260, 23.505, 22.131, 25.156,
         26.371],
        [17.436, 23.007, 17.004, 13.103, 22.620, 20.568, 19.910, 27.283, 18.664,
         18.780],
        [20.825, 26.790, 17.718, 17.444, 17.972, 17.043, 19.233, 16.206, 21.768,
         24.116],
        [22.443, 21.735, 26.065, 14.494, 19.374, 24.648, 28.452, 21.113, 20.318,
         19.196],
        [19.841, 22.240, 15.897, 17.697, 18.394, 25.733, 16.642, 18.699, 21.650,
         21.695],
        [15.271, 24.245, 20.515, 25.358, 24.701, 18.629, 23.700, 21.985, 22.479,
         22.481],
        [19.927, 22.416, 15.841, 19.691, 27.527, 29.351, 18.426, 17.371, 24.768,
         21.310],
        [20.419, 17.011, 11.959, 22.318, 19.963, 26.282, 17.282, 23.241, 21.678,
         18.830],
        [19.723, 22.202, 18.721, 23.108, 21.571, 18.731, 19.892, 19.350, 26.835,
         28.275],
        [18.802, 23.669, 15.563, 21.835, 30.490, 14.322, 15.299, 20.136, 19.132,
         29.150],
        [19.846, 19.147, 16.303, 15.300, 20.505, 18.649, 21.077, 16.606, 23.957,
         16.719],
        [25.073, 26.767, 20.394, 19.071, 24.117, 19.367, 16.299, 23.552, 24.310,
         18.088],
        [20.568, 24.989, 17.551, 19.410, 30.904, 24.449, 27.301, 24.468, 25.335,
         31.374],
        [31.413, 22.722, 25.240, 28.242, 19.334, 22.014, 23.808, 24.180, 15.361,
         34.447],
        [14.794, 21.882, 21.911, 14.420, 19.274, 19.709, 24.078, 15.721, 24.667,
         25.214],
        [28.690, 23.760, 23.621, 24.228, 25.668, 21.717, 33.973, 32.224, 24.242,
         32.909],
        [22.922, 23.255, 26.500, 17.034, 19.462, 22.813, 24.136, 14.475, 27.337,
         28.666],
        [27.289, 25.645, 20.764, 21.173, 28.557, 20.408, 20.974, 17.263, 19.713,
         36.801],
        [32.681, 19.525, 22.813, 23.432, 21.095, 24.609, 24.481, 21.028, 17.116,
         27.189],
        [22.948, 18.039, 20.492, 27.823, 18.898, 20.040, 18.728, 21.305, 14.474,
         23.297],
        [21.730, 22.947, 29.314, 20.881, 17.042, 20.081, 20.352, 19.160, 21.346,
         21.844],
        [22.284, 22.305, 23.418, 21.070, 22.628, 24.338, 23.718, 25.205, 22.243,
         26.277]], device='cuda:0')
clipping threshold 0.4531958058606569
a after update for 1 param tensor([ 0.063,  0.001, -0.006,  0.005,  0.027, -0.035, -0.023,  0.015,  0.030,
         0.048,  0.014, -0.006, -0.054, -0.056,  0.003,  0.012, -0.014,  0.018,
        -0.000, -0.009, -0.005, -0.046,  0.054,  0.018, -0.016, -0.022,  0.013,
         0.010,  0.018, -0.016,  0.041,  0.023, -0.028, -0.008, -0.008,  0.010,
        -0.059, -0.035,  0.003, -0.057, -0.036, -0.034,  0.004,  0.005, -0.060,
        -0.040,  0.016, -0.023,  0.033,  0.013, -0.032,  0.043,  0.007,  0.006,
        -0.029, -0.003, -0.041,  0.040, -0.039, -0.021, -0.014,  0.007, -0.030,
        -0.034,  0.015, -0.014,  0.018, -0.048,  0.024, -0.005,  0.003, -0.017,
         0.021,  0.045,  0.020, -0.048,  0.004,  0.009, -0.024,  0.009, -0.032,
         0.017,  0.028, -0.020,  0.023, -0.002, -0.001, -0.009,  0.019, -0.038,
        -0.016,  0.016, -0.024, -0.044, -0.002,  0.049,  0.026,  0.019, -0.026,
        -0.014], device='cuda:0')
s after update for 1 param tensor([0.782, 0.381, 0.789, 0.492, 0.692, 0.621, 0.628, 0.357, 0.372, 0.462,
        0.593, 0.384, 0.541, 0.539, 0.372, 0.514, 0.986, 0.163, 0.973, 0.528,
        0.692, 0.550, 0.662, 0.392, 0.515, 0.336, 0.647, 0.894, 0.503, 0.323,
        0.936, 0.952, 0.747, 0.367, 0.440, 0.449, 0.266, 0.897, 0.600, 1.131,
        0.738, 0.407, 0.385, 0.577, 0.581, 0.581, 0.681, 0.292, 0.599, 1.015,
        0.494, 0.595, 0.587, 0.681, 0.533, 0.758, 0.815, 0.348, 0.782, 0.707,
        0.594, 0.391, 0.560, 0.416, 0.768, 0.603, 1.250, 0.715, 0.579, 0.661,
        0.318, 0.603, 0.256, 0.469, 0.879, 0.538, 0.442, 0.390, 0.509, 0.484,
        0.471, 0.607, 0.364, 0.439, 0.578, 0.502, 0.658, 0.500, 0.829, 0.939,
        1.143, 0.701, 0.364, 0.481, 0.459, 0.533, 0.555, 0.451, 0.501, 0.444],
       device='cuda:0')
b after update for 1 param tensor([24.728, 17.253, 24.829, 19.610, 23.252, 22.040, 22.166, 16.704, 17.065,
        19.002, 21.525, 17.327, 20.556, 20.520, 17.055, 20.054, 27.768, 11.296,
        27.582, 20.320, 23.263, 20.739, 22.744, 17.513, 20.074, 16.196, 22.489,
        26.431, 19.836, 15.898, 27.053, 27.287, 24.166, 16.945, 18.550, 18.730,
        14.419, 26.487, 21.661, 29.741, 24.014, 17.829, 17.357, 21.238, 21.305,
        21.306, 23.081, 15.115, 21.641, 28.168, 19.647, 21.559, 21.431, 23.068,
        20.411, 24.339, 25.243, 16.493, 24.722, 23.511, 21.551, 17.474, 20.931,
        18.027, 24.498, 21.707, 31.266, 23.647, 21.273, 22.732, 15.776, 21.708,
        14.142, 19.157, 26.214, 20.503, 18.580, 17.456, 19.956, 19.458, 19.195,
        21.788, 16.875, 18.518, 21.258, 19.811, 22.687, 19.768, 25.453, 27.091,
        29.899, 23.412, 16.879, 19.388, 18.933, 20.408, 20.829, 18.771, 19.796,
        18.637], device='cuda:0')
clipping threshold 0.4531958058606569
a after update for 1 param tensor([[[ 0.004],
         [-0.026],
         [ 0.036],
         [-0.012],
         [ 0.003],
         [-0.019],
         [-0.011],
         [ 0.035],
         [ 0.028],
         [ 0.030]],

        [[ 0.084],
         [ 0.008],
         [-0.013],
         [ 0.001],
         [-0.001],
         [ 0.016],
         [-0.025],
         [ 0.030],
         [ 0.020],
         [-0.014]],

        [[ 0.014],
         [-0.052],
         [ 0.011],
         [ 0.004],
         [ 0.003],
         [ 0.030],
         [ 0.026],
         [ 0.008],
         [-0.003],
         [-0.004]],

        [[-0.003],
         [-0.017],
         [ 0.006],
         [-0.002],
         [-0.043],
         [-0.004],
         [-0.022],
         [ 0.006],
         [-0.041],
         [ 0.015]],

        [[-0.005],
         [-0.040],
         [ 0.001],
         [-0.056],
         [ 0.007],
         [ 0.047],
         [ 0.020],
         [ 0.026],
         [-0.001],
         [ 0.012]],

        [[ 0.055],
         [-0.029],
         [-0.009],
         [ 0.011],
         [-0.006],
         [ 0.000],
         [-0.035],
         [ 0.020],
         [ 0.011],
         [-0.005]],

        [[-0.003],
         [-0.016],
         [ 0.013],
         [ 0.004],
         [-0.027],
         [-0.014],
         [ 0.004],
         [ 0.014],
         [ 0.028],
         [-0.038]],

        [[-0.013],
         [-0.014],
         [-0.039],
         [ 0.009],
         [ 0.003],
         [-0.016],
         [ 0.022],
         [-0.051],
         [-0.040],
         [ 0.021]],

        [[ 0.016],
         [-0.020],
         [ 0.028],
         [ 0.046],
         [-0.005],
         [ 0.016],
         [ 0.011],
         [ 0.013],
         [-0.008],
         [-0.034]],

        [[ 0.014],
         [-0.001],
         [ 0.023],
         [ 0.003],
         [-0.022],
         [-0.008],
         [-0.005],
         [-0.026],
         [ 0.029],
         [ 0.016]]], device='cuda:0')
s after update for 1 param tensor([[[0.404],
         [0.481],
         [0.390],
         [1.208],
         [0.487],
         [0.889],
         [0.832],
         [0.810],
         [0.751],
         [0.333]],

        [[0.905],
         [0.658],
         [1.020],
         [0.480],
         [0.477],
         [0.586],
         [0.892],
         [0.568],
         [1.031],
         [1.051]],

        [[0.655],
         [0.614],
         [0.662],
         [0.382],
         [0.791],
         [0.401],
         [1.022],
         [0.602],
         [1.050],
         [0.709]],

        [[0.759],
         [1.033],
         [0.664],
         [0.581],
         [0.753],
         [1.049],
         [1.165],
         [0.676],
         [1.265],
         [0.488]],

        [[0.328],
         [0.955],
         [0.519],
         [0.827],
         [0.615],
         [0.914],
         [0.840],
         [0.932],
         [0.645],
         [0.358]],

        [[0.808],
         [0.670],
         [0.634],
         [0.862],
         [0.416],
         [0.739],
         [0.480],
         [1.128],
         [0.648],
         [0.954]],

        [[0.380],
         [0.532],
         [0.960],
         [0.480],
         [1.088],
         [0.524],
         [0.639],
         [0.661],
         [0.406],
         [0.896]],

        [[0.944],
         [1.256],
         [0.600],
         [0.671],
         [0.761],
         [0.596],
         [0.712],
         [0.455],
         [0.955],
         [0.476]],

        [[0.528],
         [0.585],
         [0.511],
         [0.750],
         [0.316],
         [0.532],
         [0.569],
         [0.483],
         [0.345],
         [0.590]],

        [[0.437],
         [0.658],
         [0.746],
         [0.406],
         [0.410],
         [0.493],
         [0.568],
         [0.825],
         [0.811],
         [1.080]]], device='cuda:0')
b after update for 1 param tensor([[[17.780],
         [19.391],
         [17.450],
         [30.733],
         [19.520],
         [26.356],
         [25.511],
         [25.158],
         [24.235],
         [16.132]],

        [[26.604],
         [22.672],
         [28.244],
         [19.374],
         [19.304],
         [21.401],
         [26.401],
         [21.078],
         [28.393],
         [28.660]],

        [[22.635],
         [21.909],
         [22.746],
         [17.288],
         [24.875],
         [17.714],
         [28.272],
         [21.685],
         [28.657],
         [23.549]],

        [[24.366],
         [28.415],
         [22.782],
         [21.318],
         [24.268],
         [28.631],
         [30.174],
         [22.994],
         [31.450],
         [19.526]],

        [[16.015],
         [27.321],
         [20.139],
         [25.420],
         [21.934],
         [26.727],
         [25.625],
         [26.995],
         [22.449],
         [16.732]],

        [[25.137],
         [22.891],
         [22.258],
         [25.954],
         [18.040],
         [24.042],
         [19.368],
         [29.692],
         [22.513],
         [27.303]],

        [[17.240],
         [20.396],
         [27.396],
         [19.379],
         [29.162],
         [20.246],
         [22.345],
         [22.725],
         [17.811],
         [26.470]],

        [[27.168],
         [31.336],
         [21.651],
         [22.908],
         [24.386],
         [21.585],
         [23.596],
         [18.853],
         [27.327],
         [19.286]],

        [[20.326],
         [21.392],
         [19.989],
         [24.213],
         [15.714],
         [20.397],
         [21.097],
         [19.431],
         [16.435],
         [21.483]],

        [[18.483],
         [22.676],
         [24.154],
         [17.808],
         [17.894],
         [19.637],
         [21.075],
         [25.396],
         [25.183],
         [29.061]]], device='cuda:0')
clipping threshold 0.4531958058606569
a after update for 1 param tensor([[-0.013],
        [-0.044],
        [ 0.007],
        [ 0.021],
        [-0.002],
        [ 0.004],
        [-0.014],
        [ 0.017],
        [-0.014],
        [-0.018]], device='cuda:0')
s after update for 1 param tensor([[0.857],
        [1.129],
        [1.353],
        [0.867],
        [1.579],
        [1.323],
        [1.666],
        [1.330],
        [0.845],
        [1.192]], device='cuda:0')
b after update for 1 param tensor([[25.881],
        [29.707],
        [32.520],
        [26.037],
        [35.135],
        [32.158],
        [36.094],
        [32.242],
        [25.708],
        [30.526]], device='cuda:0')
clipping threshold 0.4531958058606569
||w||^2 0.3080415627267875
exp ma of ||w||^2 0.5769800652768658
||w|| 0.5550149211749064
exp ma of ||w|| 0.7010140725728061
v before min max tensor([[-9.383e-01,  5.808e-01, -3.274e-01,  2.939e-01, -4.229e-02,  2.227e-01,
          1.223e+00, -2.743e-02, -1.398e+00, -9.284e-02],
        [ 1.700e+00, -6.596e-01,  7.918e+00, -5.955e-01, -1.944e-01, -6.222e-02,
          7.132e-01, -4.190e-01, -9.414e-01, -1.179e-02],
        [ 1.102e+00,  1.256e+00,  3.273e+00,  3.056e-02, -1.318e+00, -8.695e-01,
         -1.238e+00,  7.488e-01, -8.431e-01, -1.118e-01],
        [ 1.591e+00, -9.049e-01, -7.280e-01, -8.312e-01, -1.069e+00,  1.138e-01,
         -8.912e-01, -2.919e-01, -9.844e-01, -5.145e-01],
        [-5.423e-01, -1.858e+00,  3.032e-01, -1.566e+00, -6.605e-01, -7.920e-01,
         -9.718e-01,  7.356e-01, -4.716e-01,  4.422e-02],
        [-1.284e+00, -1.771e+00, -6.770e-01, -5.088e-01, -6.139e-01, -7.312e-01,
         -6.567e-01,  6.730e-01, -5.116e-01, -3.030e-01],
        [ 5.971e-01,  1.164e+00, -1.319e-01, -3.767e-01, -3.978e-01, -9.045e-01,
          1.389e+00, -4.454e-01, -1.900e-03, -2.146e-01],
        [-1.514e-02, -6.734e-01,  1.164e+00,  3.411e-01,  7.836e-01, -1.064e+00,
         -2.744e-01, -2.547e-01, -2.680e-01, -1.003e-01],
        [ 4.413e-01, -8.062e-01,  4.756e-01, -5.559e-01, -6.433e-01, -3.028e-01,
         -1.233e+00, -1.122e+00,  4.999e-01, -1.186e-01],
        [ 2.730e+00,  5.556e+00, -5.761e-01,  1.218e+00,  5.768e-01, -5.088e-01,
         -7.461e-01,  1.204e+00,  9.521e-01, -1.352e+00],
        [ 1.386e+00, -4.296e-01, -5.328e-01,  3.365e-01, -3.909e-01,  3.557e+00,
          3.353e+00,  3.348e-01, -4.238e-01, -5.832e-01],
        [-9.170e-01, -1.117e+00, -2.725e-01, -7.431e-01, -3.894e-01, -6.623e-01,
         -9.401e-01, -4.754e-01, -1.266e-01,  9.366e-01],
        [-5.936e-01, -1.793e-01, -7.211e-01, -6.536e-01,  1.265e+00, -1.228e+00,
         -7.016e-01, -6.788e-01, -4.544e-01, -7.108e-01],
        [-1.351e+00, -5.538e-01, -5.996e-01, -4.228e-01, -1.486e+00, -6.588e-01,
         -2.012e-01, -1.068e+00,  3.329e-01, -7.446e-01],
        [-1.413e+00,  2.427e-01,  4.749e+00, -7.671e-01,  2.091e+00, -7.212e-01,
         -1.015e+00, -5.681e-01, -2.926e-01,  7.710e-01],
        [ 7.535e-01, -3.144e-03, -3.469e-01,  4.299e-01, -3.687e-01, -2.741e-02,
         -4.397e-01, -9.704e-01, -5.753e-02, -6.696e-01],
        [-6.177e-01, -5.488e-01, -3.251e-01, -2.104e-01,  1.042e+00,  1.257e-01,
         -5.194e-02,  2.113e-01, -2.165e-01, -6.350e-01],
        [-3.196e-01, -1.396e+00, -6.671e-01, -7.310e-01,  7.359e-01, -6.493e-01,
         -7.637e-01,  8.138e-01, -8.967e-01,  8.687e-01],
        [-9.280e-01, -9.766e-01, -3.931e-01, -1.592e-01, -3.844e-01, -3.847e-01,
         -2.551e-01, -4.951e-02, -7.506e-01, -7.934e-01],
        [-9.391e-01, -1.361e+00, -9.045e-01, -4.442e-03,  6.009e-02, -5.967e-01,
         -3.184e-01, -8.028e-01,  1.555e+00, -7.662e-01],
        [-5.211e-01, -1.173e+00, -1.505e+00,  6.421e-02, -9.031e-01, -1.234e+00,
         -7.449e-01,  1.451e+00, -2.615e-02,  3.666e+00],
        [-1.469e+00,  3.116e+00,  9.919e-01, -8.604e-01,  1.252e+01, -1.112e+00,
         -3.869e-01,  4.902e-01,  9.788e-01,  1.847e+00],
        [-2.690e-01, -4.904e-01,  1.181e+00,  9.154e-03,  1.917e-01,  2.155e-01,
         -6.765e-01, -6.707e-01, -4.970e-01,  9.076e-01],
        [-4.101e-01,  2.473e+00, -1.392e+00, -2.208e-01,  6.628e-02, -1.140e+00,
         -7.216e-01, -6.558e-01, -7.854e-01, -4.602e-01],
        [-1.070e+00,  3.491e+00,  1.896e+00, -3.691e-01, -1.073e+00,  1.939e+00,
          1.147e-01, -6.563e-01, -3.954e-01,  7.416e+00],
        [-3.195e-01, -9.343e-02, -8.043e-01,  9.861e-01, -2.029e-01, -4.842e-01,
         -9.018e-01,  1.306e+00, -6.215e-01, -4.928e-01],
        [ 1.953e-01, -4.744e-01, -5.550e-01,  4.604e-01, -1.134e+00, -5.638e-01,
         -1.503e+00, -2.977e-01, -4.672e-01, -1.160e+00],
        [-5.180e-01, -3.097e-01, -5.965e-01, -1.021e+00, -5.371e-01,  8.713e+00,
         -1.094e+00,  1.112e+00, -4.497e-01, -1.380e+00],
        [ 9.820e-01, -4.741e-01, -1.541e+00, -5.559e-01, -6.082e-01,  4.580e-01,
          1.287e+00,  1.259e+00,  2.363e+00, -4.903e-01],
        [-3.145e-01,  5.601e-01,  4.901e-01, -1.911e-01, -8.637e-01, -1.708e-01,
         -7.412e-01, -9.084e-01, -8.321e-01, -6.368e-01],
        [ 9.367e-01, -2.416e-01, -7.017e-01,  9.894e-01, -3.278e-01, -1.093e+00,
          8.223e-02, -8.319e-01, -6.725e-01, -4.304e-01],
        [-4.016e-01, -4.143e-01,  1.245e-01, -6.050e-01, -4.548e-01, -5.787e-01,
         -5.288e-01, -2.490e-01, -2.695e-01, -2.893e-01],
        [-4.649e-01, -5.927e-01,  8.198e-01, -8.487e-01,  9.951e-02,  4.374e+00,
         -4.498e-01, -9.224e-01,  3.154e-02, -7.402e-01],
        [-3.380e-01, -3.832e-01, -4.519e-01, -9.235e-01, -8.146e-01, -8.086e-01,
         -6.427e-01, -8.166e-01,  1.372e+00, -6.305e-01],
        [ 2.043e-01, -2.708e-01,  6.167e-01, -1.496e+00,  1.740e-01,  5.047e-01,
         -1.936e-01, -1.323e+00, -4.873e-01, -1.247e+00],
        [-9.578e-01,  5.789e-01, -4.808e-01, -7.033e-01,  1.422e-01, -5.491e-01,
          5.982e-01, -4.379e-01, -5.777e-01,  8.724e-02],
        [-6.571e-01, -1.404e+00, -5.568e-01, -6.806e-01, -1.567e+00, -4.308e-01,
         -4.886e-01,  1.460e+00,  2.577e+00,  1.966e-01],
        [-2.679e-01, -9.245e-01, -6.019e-01, -2.566e-01, -7.129e-01, -6.236e-01,
         -4.654e-01, -7.209e-01,  1.058e+00,  2.517e+00],
        [-9.269e-01, -7.742e-01, -2.329e-01, -4.412e-01, -7.571e-01, -1.254e-01,
         -3.738e-01, -5.542e-01,  1.074e+00, -4.703e-02],
        [-7.557e-01,  3.619e-01, -3.880e-01, -1.184e+00, -1.130e+00, -9.184e-01,
         -5.987e-01, -2.930e-01,  5.075e-01, -4.970e-01],
        [ 4.479e-01,  4.427e-01,  1.581e-01, -9.224e-01,  7.092e-01,  3.640e-01,
         -9.194e-01, -5.738e-01,  2.333e+00,  6.065e-01],
        [-9.166e-01, -5.640e-01, -6.714e-01, -1.788e-02, -1.295e+00,  1.044e+00,
         -7.574e-01, -4.907e-01, -6.559e-01, -4.385e-01],
        [-5.015e-01, -1.023e+00, -5.033e-01, -6.323e-01, -6.969e-01, -1.027e+00,
         -6.284e-01, -7.782e-01, -9.027e-01,  3.945e+00],
        [ 1.297e+00, -6.248e-01, -2.163e-01, -7.149e-01, -1.844e+00, -1.514e-01,
          3.711e-01,  2.913e+00,  1.191e+00,  1.822e-01],
        [-5.693e-01, -4.580e-01, -8.289e-01,  2.760e-01,  9.116e-01, -9.044e-01,
          9.620e-01, -2.109e-01, -8.106e-01,  2.183e+00],
        [ 4.073e-01, -9.972e-01, -8.303e-01, -4.150e-01, -5.127e-01,  9.243e-01,
         -2.641e-01,  1.255e-01, -6.017e-01,  1.121e+00],
        [-5.687e-01, -8.381e-01, -9.727e-01,  7.959e-01, -1.164e+00, -1.028e+00,
         -1.173e+00, -5.324e-01,  6.179e-01, -5.312e-01],
        [-5.703e-01,  1.780e+00, -3.389e-01,  2.318e+00,  2.911e+00, -1.535e+00,
         -1.464e-01, -7.405e-01, -1.398e-01, -8.695e-01],
        [ 1.983e+00, -9.481e-01,  2.431e+00, -8.920e-01, -1.232e+00,  1.930e-01,
         -1.329e+00, -5.800e-01, -4.042e-01, -7.396e-01],
        [-1.050e+00, -8.049e-01, -7.857e-01,  3.283e-01, -1.144e+00,  6.947e-01,
         -1.281e+00, -9.846e-01, -4.552e-01,  7.282e+00],
        [-5.343e-01,  4.680e-01, -7.033e-01, -1.158e+00,  8.180e-02, -1.414e+00,
          1.282e+00,  1.686e+00, -8.790e-01,  5.142e+00],
        [-2.412e-01,  7.175e-01,  2.257e-01,  1.151e-01, -8.195e-01, -6.333e-01,
          1.748e-02, -6.749e-01,  3.615e-01, -3.945e-01],
        [-8.414e-01, -1.048e-01, -2.167e-01, -5.553e-01, -1.801e-01, -5.361e-01,
         -4.950e-01, -3.704e-01, -7.709e-01, -3.609e-01],
        [-8.065e-01,  9.509e-01, -6.971e-01, -2.345e-03, -2.315e-01, -1.416e+00,
          1.497e+00, -1.256e-01, -5.867e-01, -3.961e-01],
        [-3.140e-01, -4.413e-01, -6.930e-01, -7.885e-02, -2.553e-01, -6.149e-01,
         -1.052e+00, -3.917e-01, -3.302e-01, -6.309e-01],
        [ 1.509e+00, -6.811e-01, -7.231e-01, -1.554e-01,  3.046e+00,  2.630e+00,
         -1.107e+00, -1.387e+00, -4.051e-01, -2.110e-02],
        [-1.321e+00, -2.650e-01, -6.464e-01, -8.046e-01, -9.682e-01,  8.225e-01,
         -4.074e-01, -6.135e-01, -1.635e-01, -6.170e-01],
        [-3.167e-01, -4.598e-01, -1.080e+00, -3.452e-01, -6.376e-01,  6.927e-01,
          4.845e-01, -4.811e-01,  1.182e+00,  1.535e+00],
        [-2.811e-01, -1.464e+00,  2.590e+00, -6.405e-01,  7.047e-01, -5.029e-01,
          1.773e+00, -2.172e-01, -2.851e-01, -3.072e-01],
        [-2.242e-01, -9.130e-01, -7.222e-01,  1.306e+00,  7.665e-03, -6.993e-01,
         -7.262e-01, -7.142e-01, -7.005e-01, -7.215e-01],
        [-5.938e-01, -1.054e+00, -4.568e-01, -1.870e-01, -4.394e-01, -8.858e-01,
         -7.721e-01,  3.401e-01,  8.462e-01, -8.199e-01],
        [ 7.174e-01, -4.097e-01, -2.470e-01, -2.189e-01,  4.345e-01,  5.212e-01,
         -1.223e+00, -3.853e-01, -5.355e-01, -1.835e-01],
        [-9.987e-01, -9.355e-01, -8.057e-01, -4.687e-01, -5.200e-01,  5.635e-01,
          1.670e+00, -6.983e-01, -1.501e+00,  1.245e+00],
        [-7.375e-01, -7.624e-01, -6.622e-01, -3.730e-01, -2.978e-01, -2.879e-01,
         -1.209e+00, -7.093e-01, -5.330e-01, -7.455e-01],
        [-3.889e-01, -1.056e+00,  2.465e-01,  4.489e-01, -3.553e-01,  2.515e-02,
         -6.184e-01,  3.182e-01,  1.132e+00,  2.164e+00],
        [ 5.315e-01, -5.371e-01, -6.477e-01, -4.791e-01,  1.853e+00, -6.536e-01,
         -7.646e-01, -3.649e-01, -4.294e-01, -2.366e-02],
        [ 2.995e-02, -5.188e-01, -5.219e-01,  1.981e+00, -5.536e-01, -1.990e+00,
         -9.831e-01,  6.683e-01, -1.415e+00, -1.224e+00],
        [-2.821e-02,  2.113e+00,  1.428e+00, -4.698e-01, -8.778e-01, -8.499e-01,
          3.958e+00, -1.013e+00, -6.072e-01, -1.251e+00],
        [-7.344e-01, -1.190e+00, -6.062e-01,  1.257e+00,  1.653e+00, -1.678e-02,
         -1.481e+00,  1.227e+00,  4.791e-01, -4.507e-01],
        [ 4.772e-01, -5.723e-01, -1.538e-01,  8.591e-01,  8.145e-01, -4.907e-01,
         -1.445e+00, -1.181e-01, -1.551e+00, -3.323e-01],
        [-5.193e-01,  1.664e+00,  8.012e-01, -6.872e-01, -6.985e-01,  4.689e+00,
          1.040e+00,  3.906e+00,  4.076e-02, -6.385e-01],
        [-3.264e-01, -2.996e-01, -2.148e-01, -3.754e-02,  7.760e-01, -5.522e-01,
         -9.331e-01,  5.921e-01,  9.883e-01, -4.574e-01],
        [-1.263e+00,  4.225e-01, -1.910e-01,  1.863e+00,  6.228e-01, -2.080e-01,
         -8.804e-01, -4.111e-01, -2.273e-02,  7.017e-01],
        [-7.469e-01, -6.691e-01, -5.768e-01, -1.582e-01, -7.197e-01, -4.146e-01,
         -5.397e-01,  2.456e-01, -2.352e-01, -4.050e-01],
        [-8.591e-01, -8.836e-01, -5.403e-01, -2.753e-01, -1.185e+00, -7.395e-01,
         -7.915e-01, -1.088e+00, -4.974e-01, -3.805e-01],
        [ 7.770e-01,  1.947e-01,  3.289e-01, -4.798e-01, -1.682e-02, -8.262e-01,
          2.798e+00,  2.804e-01, -2.876e-01,  1.135e+00],
        [-6.419e-01, -1.185e+00, -1.776e-01, -8.107e-01, -7.344e-01, -1.256e+00,
          7.157e+00, -8.907e-01, -6.541e-01,  5.039e-01],
        [-5.081e-01,  3.633e+00, -2.938e-01, -5.302e-01, -7.676e-01, -9.010e-01,
         -8.156e-02, -1.043e+00, -1.080e+00, -4.913e-01],
        [-2.863e-01, -7.050e-01,  1.378e-01, -5.557e-01,  2.802e-02, -3.248e-01,
          1.152e+00, -5.911e-01,  6.008e-01, -6.585e-01],
        [-8.075e-01, -1.109e+00, -3.361e-01, -1.071e+00,  3.794e-01, -6.874e-01,
         -2.151e-01, -5.426e-01,  9.603e-01, -1.148e+00],
        [ 6.798e-01, -1.200e+00, -5.273e-01, -8.117e-01, -2.269e-01, -3.960e-01,
         -1.209e+00, -1.199e-01,  5.146e+00,  7.934e-01],
        [-9.527e-01, -9.585e-01, -4.256e-01,  2.154e-01, -7.495e-01, -1.244e+00,
         -1.352e+00, -1.974e-01, -8.199e-01, -6.085e-01],
        [-1.214e+00, -6.737e-01, -9.588e-01, -6.009e-01, -8.470e-01, -3.264e-01,
         -3.202e-02,  1.145e+00, -3.751e-01, -8.693e-01],
        [-8.079e-01, -8.847e-01, -5.390e-01, -3.519e-01, -1.188e+00, -9.178e-01,
         -7.443e-01,  4.983e+00,  1.268e+00, -9.303e-01],
        [-2.614e-01, -7.179e-01, -8.599e-01, -3.972e-01, -1.562e+00, -8.303e-01,
          1.116e+00, -3.032e-01,  2.918e-01, -3.421e-01],
        [ 1.913e+00, -6.502e-01, -6.942e-01,  1.065e-01, -6.091e-01, -5.253e-01,
          1.084e+00, -9.707e-02, -5.618e-01, -3.324e-01],
        [-4.043e-01,  7.249e-01, -1.002e+00, -9.051e-02,  1.105e+00,  1.311e+00,
         -1.074e+00, -9.961e-01, -7.141e-01, -1.727e-01],
        [ 9.560e-01, -1.005e+00, -4.977e-01, -2.075e-01, -5.316e-01, -1.015e+00,
          2.135e+00, -2.816e-01, -7.956e-01, -9.567e-01],
        [-8.568e-01,  8.669e-01, -7.986e-01,  1.237e-01, -6.114e-01,  7.320e-02,
         -8.264e-01, -2.360e-02, -7.199e-01, -2.617e-01],
        [ 2.671e+00, -4.520e-01,  3.604e+00,  3.158e-01, -9.451e-01,  9.098e-02,
         -7.369e-01, -4.070e-01, -9.731e-01, -4.618e-02],
        [ 4.882e-01,  1.616e-01,  2.484e-01, -4.749e-01,  1.347e+00,  3.564e+00,
         -5.736e-01,  6.007e-01,  1.155e+00,  1.085e+00],
        [-7.764e-01,  3.661e-02,  7.160e-01, -6.688e-01, -6.405e-01, -5.218e-01,
          7.482e-01, -4.652e-01, -7.153e-01,  1.692e+00],
        [-4.639e-01, -4.731e-01,  2.337e+00, -2.333e-01,  1.246e+00, -7.823e-01,
         -5.491e-01,  5.952e-03, -5.211e-01, -5.660e-01],
        [-1.013e+00, -3.989e-01, -1.298e+00, -1.487e+00,  1.247e+00, -1.361e+00,
         -1.028e+00,  6.766e+00, -8.615e-01,  2.684e+00],
        [ 1.102e+00, -3.801e-02, -1.702e-01, -3.366e-01, -4.254e-01,  5.726e-01,
         -1.098e+00,  1.158e+00,  5.164e-01, -1.457e+00],
        [-1.262e+00,  9.221e-01,  3.955e-01, -6.913e-01, -5.610e-01, -5.750e-01,
         -5.834e-01, -8.655e-01,  3.624e+00, -6.748e-01],
        [-9.339e-01, -1.283e+00, -3.495e-01,  1.446e+00, -7.177e-01, -2.036e+00,
          2.423e+00,  1.226e+00, -6.572e-01, -1.831e+00],
        [-3.115e-01, -6.964e-01, -2.685e-01, -4.076e-01, -6.790e-01, -3.557e-01,
         -1.250e+00, -9.426e-01, -7.696e-01, -5.632e-01],
        [ 3.534e+00, -4.918e-01, -7.254e-01, -8.720e-01, -6.497e-01,  5.895e-01,
         -7.253e-01, -5.443e-01, -3.645e-01, -2.446e-01],
        [-9.098e-01,  1.492e+00, -1.216e+00, -6.660e-01, -7.945e-01, -4.744e-01,
         -1.174e+00,  1.358e+00, -5.532e-01, -1.124e+00]], device='cuda:0')
v tensor([[1.000e-12, 5.808e-01, 1.000e-12, 2.939e-01, 1.000e-12, 2.227e-01,
         1.223e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.700e+00, 1.000e-12, 7.918e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         7.132e-01, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.102e+00, 1.256e+00, 3.273e+00, 3.056e-02, 1.000e-12, 1.000e-12,
         1.000e-12, 7.488e-01, 1.000e-12, 1.000e-12],
        [1.591e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.138e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 3.032e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 7.356e-01, 1.000e-12, 4.422e-02],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 6.730e-01, 1.000e-12, 1.000e-12],
        [5.971e-01, 1.164e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.389e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.164e+00, 3.411e-01, 7.836e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [4.413e-01, 1.000e-12, 4.756e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 4.999e-01, 1.000e-12],
        [2.730e+00, 5.556e+00, 1.000e-12, 1.218e+00, 5.768e-01, 1.000e-12,
         1.000e-12, 1.204e+00, 9.521e-01, 1.000e-12],
        [1.386e+00, 1.000e-12, 1.000e-12, 3.365e-01, 1.000e-12, 3.557e+00,
         3.353e+00, 3.348e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 9.366e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.265e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 3.329e-01, 1.000e-12],
        [1.000e-12, 2.427e-01, 4.749e+00, 1.000e-12, 2.091e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 7.710e-01],
        [7.535e-01, 1.000e-12, 1.000e-12, 4.299e-01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.042e+00, 1.257e-01,
         1.000e-12, 2.113e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 7.359e-01, 1.000e-12,
         1.000e-12, 8.138e-01, 1.000e-12, 8.687e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 6.009e-02, 1.000e-12,
         1.000e-12, 1.000e-12, 1.555e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 6.421e-02, 1.000e-12, 1.000e-12,
         1.000e-12, 1.451e+00, 1.000e-12, 3.666e+00],
        [1.000e-12, 3.116e+00, 9.919e-01, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 4.902e-01, 9.788e-01, 1.847e+00],
        [1.000e-12, 1.000e-12, 1.181e+00, 9.154e-03, 1.917e-01, 2.155e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 9.076e-01],
        [1.000e-12, 2.473e+00, 1.000e-12, 1.000e-12, 6.628e-02, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 3.491e+00, 1.896e+00, 1.000e-12, 1.000e-12, 1.939e+00,
         1.147e-01, 1.000e-12, 1.000e-12, 7.416e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 9.861e-01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.306e+00, 1.000e-12, 1.000e-12],
        [1.953e-01, 1.000e-12, 1.000e-12, 4.604e-01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 8.713e+00,
         1.000e-12, 1.112e+00, 1.000e-12, 1.000e-12],
        [9.820e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 4.580e-01,
         1.287e+00, 1.259e+00, 2.363e+00, 1.000e-12],
        [1.000e-12, 5.601e-01, 4.901e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [9.367e-01, 1.000e-12, 1.000e-12, 9.894e-01, 1.000e-12, 1.000e-12,
         8.223e-02, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.245e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 8.198e-01, 1.000e-12, 9.951e-02, 4.374e+00,
         1.000e-12, 1.000e-12, 3.154e-02, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.372e+00, 1.000e-12],
        [2.043e-01, 1.000e-12, 6.167e-01, 1.000e-12, 1.740e-01, 5.047e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 5.789e-01, 1.000e-12, 1.000e-12, 1.422e-01, 1.000e-12,
         5.982e-01, 1.000e-12, 1.000e-12, 8.724e-02],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.460e+00, 2.577e+00, 1.966e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.058e+00, 2.517e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.074e+00, 1.000e-12],
        [1.000e-12, 3.619e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 5.075e-01, 1.000e-12],
        [4.479e-01, 4.427e-01, 1.581e-01, 1.000e-12, 7.092e-01, 3.640e-01,
         1.000e-12, 1.000e-12, 2.333e+00, 6.065e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.044e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 3.945e+00],
        [1.297e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         3.711e-01, 2.913e+00, 1.191e+00, 1.822e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 2.760e-01, 9.116e-01, 1.000e-12,
         9.620e-01, 1.000e-12, 1.000e-12, 2.183e+00],
        [4.073e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 9.243e-01,
         1.000e-12, 1.255e-01, 1.000e-12, 1.121e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 7.959e-01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 6.179e-01, 1.000e-12],
        [1.000e-12, 1.780e+00, 1.000e-12, 2.318e+00, 2.911e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.983e+00, 1.000e-12, 2.431e+00, 1.000e-12, 1.000e-12, 1.930e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 3.283e-01, 1.000e-12, 6.947e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 7.282e+00],
        [1.000e-12, 4.680e-01, 1.000e-12, 1.000e-12, 8.180e-02, 1.000e-12,
         1.282e+00, 1.686e+00, 1.000e-12, 5.142e+00],
        [1.000e-12, 7.175e-01, 2.257e-01, 1.151e-01, 1.000e-12, 1.000e-12,
         1.748e-02, 1.000e-12, 3.615e-01, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 9.509e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.497e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.509e+00, 1.000e-12, 1.000e-12, 1.000e-12, 3.046e+00, 2.630e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 8.225e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 6.927e-01,
         4.845e-01, 1.000e-12, 1.182e+00, 1.535e+00],
        [1.000e-12, 1.000e-12, 2.590e+00, 1.000e-12, 7.047e-01, 1.000e-12,
         1.773e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.306e+00, 7.665e-03, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 3.401e-01, 8.462e-01, 1.000e-12],
        [7.174e-01, 1.000e-12, 1.000e-12, 1.000e-12, 4.345e-01, 5.212e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.635e-01,
         1.670e+00, 1.000e-12, 1.000e-12, 1.245e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 2.465e-01, 4.489e-01, 1.000e-12, 2.515e-02,
         1.000e-12, 3.182e-01, 1.132e+00, 2.164e+00],
        [5.315e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.853e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [2.995e-02, 1.000e-12, 1.000e-12, 1.981e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 6.683e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 2.113e+00, 1.428e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         3.958e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.257e+00, 1.653e+00, 1.000e-12,
         1.000e-12, 1.227e+00, 4.791e-01, 1.000e-12],
        [4.772e-01, 1.000e-12, 1.000e-12, 8.591e-01, 8.145e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.664e+00, 8.012e-01, 1.000e-12, 1.000e-12, 4.689e+00,
         1.040e+00, 3.906e+00, 4.076e-02, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 7.760e-01, 1.000e-12,
         1.000e-12, 5.921e-01, 9.883e-01, 1.000e-12],
        [1.000e-12, 4.225e-01, 1.000e-12, 1.863e+00, 6.228e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 7.017e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 2.456e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [7.770e-01, 1.947e-01, 3.289e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         2.798e+00, 2.804e-01, 1.000e-12, 1.135e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         7.157e+00, 1.000e-12, 1.000e-12, 5.039e-01],
        [1.000e-12, 3.633e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.378e-01, 1.000e-12, 2.802e-02, 1.000e-12,
         1.152e+00, 1.000e-12, 6.008e-01, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.794e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 9.603e-01, 1.000e-12],
        [6.798e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 5.146e+00, 7.934e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 2.154e-01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.145e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 4.983e+00, 1.268e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.116e+00, 1.000e-12, 2.918e-01, 1.000e-12],
        [1.913e+00, 1.000e-12, 1.000e-12, 1.065e-01, 1.000e-12, 1.000e-12,
         1.084e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 7.249e-01, 1.000e-12, 1.000e-12, 1.105e+00, 1.311e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [9.560e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         2.135e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 8.669e-01, 1.000e-12, 1.237e-01, 1.000e-12, 7.320e-02,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [2.671e+00, 1.000e-12, 3.604e+00, 3.158e-01, 1.000e-12, 9.098e-02,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [4.882e-01, 1.616e-01, 2.484e-01, 1.000e-12, 1.347e+00, 3.564e+00,
         1.000e-12, 6.007e-01, 1.155e+00, 1.085e+00],
        [1.000e-12, 3.661e-02, 7.160e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         7.482e-01, 1.000e-12, 1.000e-12, 1.692e+00],
        [1.000e-12, 1.000e-12, 2.337e+00, 1.000e-12, 1.246e+00, 1.000e-12,
         1.000e-12, 5.952e-03, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.247e+00, 1.000e-12,
         1.000e-12, 6.766e+00, 1.000e-12, 2.684e+00],
        [1.102e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.726e-01,
         1.000e-12, 1.158e+00, 5.164e-01, 1.000e-12],
        [1.000e-12, 9.221e-01, 3.955e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 3.624e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.446e+00, 1.000e-12, 1.000e-12,
         2.423e+00, 1.226e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [3.534e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.895e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.492e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.358e+00, 1.000e-12, 1.000e-12]], device='cuda:0')
v before min max tensor([ 3.729e-01, -6.311e-01, -5.091e-01, -3.414e-01, -5.817e-01,  1.769e+00,
        -6.297e-01, -4.012e-01,  4.407e-01, -4.000e-01, -7.404e-01, -2.664e-01,
         3.560e-01,  3.438e+00, -8.777e-01, -2.086e-01,  5.251e-01, -4.088e-01,
         1.271e+00, -1.004e-02, -6.144e-01,  3.711e-01,  1.381e-01, -6.060e-01,
        -7.173e-01, -2.961e-03, -4.615e-01,  3.472e+00, -1.234e-01, -5.202e-01,
        -5.639e-01, -5.087e-01,  2.903e-01, -1.280e-01, -2.840e-01, -2.420e-01,
        -6.238e-01, -7.186e-01, -2.928e-02, -7.273e-02,  3.462e-01, -6.939e-01,
        -3.390e-01,  1.623e+00,  7.055e-01,  4.350e-01, -1.000e+00, -8.862e-01,
        -6.550e-01,  8.462e-01,  3.715e+00, -4.941e-01, -6.064e-01,  3.003e+00,
        -6.779e-01,  1.521e+00, -2.773e-01, -4.733e-01,  4.893e-01, -3.323e-01,
         1.566e+00, -2.180e-01, -1.311e+00,  1.268e+00, -9.836e-01, -8.810e-01,
         2.153e+00,  1.398e+00,  2.808e+00, -3.837e-01,  3.443e+00, -9.433e-01,
        -2.996e-01,  1.049e-02,  1.589e+00,  1.374e+00, -7.480e-01, -7.446e-01,
        -1.329e+00, -7.489e-01,  1.298e+00, -2.770e-01,  1.149e+00, -4.362e-01,
        -3.907e-01, -7.896e-01, -1.938e-01, -8.343e-01, -6.479e-01, -6.324e-01,
        -6.518e-01,  1.171e+00,  2.378e+00, -1.318e+00,  1.823e+00,  2.016e+00,
         1.728e+00, -8.966e-03,  1.332e+00, -2.450e-01], device='cuda:0')
v tensor([3.729e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.769e+00,
        1.000e-12, 1.000e-12, 4.407e-01, 1.000e-12, 1.000e-12, 1.000e-12,
        3.560e-01, 3.438e+00, 1.000e-12, 1.000e-12, 5.251e-01, 1.000e-12,
        1.271e+00, 1.000e-12, 1.000e-12, 3.711e-01, 1.381e-01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 3.472e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 2.903e-01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.462e-01, 1.000e-12,
        1.000e-12, 1.623e+00, 7.055e-01, 4.350e-01, 1.000e-12, 1.000e-12,
        1.000e-12, 8.462e-01, 3.715e+00, 1.000e-12, 1.000e-12, 3.003e+00,
        1.000e-12, 1.521e+00, 1.000e-12, 1.000e-12, 4.893e-01, 1.000e-12,
        1.566e+00, 1.000e-12, 1.000e-12, 1.268e+00, 1.000e-12, 1.000e-12,
        2.153e+00, 1.398e+00, 2.808e+00, 1.000e-12, 3.443e+00, 1.000e-12,
        1.000e-12, 1.049e-02, 1.589e+00, 1.374e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.298e+00, 1.000e-12, 1.149e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.171e+00, 2.378e+00, 1.000e-12, 1.823e+00, 2.016e+00,
        1.728e+00, 1.000e-12, 1.332e+00, 1.000e-12], device='cuda:0')
v before min max tensor([[[-0.716],
         [12.703],
         [ 2.660],
         [-0.791],
         [ 4.490],
         [-1.344],
         [ 3.526],
         [-1.134],
         [-0.517],
         [ 0.764]],

        [[-0.908],
         [ 0.183],
         [ 1.760],
         [-1.159],
         [ 2.278],
         [-0.416],
         [-0.263],
         [ 0.399],
         [ 0.022],
         [-0.096]],

        [[-1.612],
         [-1.010],
         [ 1.288],
         [-0.337],
         [ 0.985],
         [-0.979],
         [-1.105],
         [-0.312],
         [-0.827],
         [ 0.766]],

        [[-0.659],
         [-0.188],
         [-0.685],
         [ 1.181],
         [ 0.534],
         [-0.350],
         [-1.023],
         [-0.091],
         [-1.141],
         [-0.204]],

        [[-0.745],
         [ 2.217],
         [ 0.829],
         [ 0.374],
         [ 1.322],
         [-0.490],
         [-1.397],
         [-0.861],
         [-0.752],
         [ 0.646]],

        [[-0.987],
         [-1.494],
         [-0.521],
         [ 0.352],
         [-1.169],
         [-0.856],
         [-1.539],
         [ 4.311],
         [-0.640],
         [-0.773]],

        [[-1.037],
         [-1.322],
         [-1.086],
         [-1.572],
         [-0.143],
         [ 0.924],
         [-0.551],
         [ 4.415],
         [ 4.214],
         [-0.728]],

        [[-0.599],
         [-0.421],
         [-0.156],
         [-0.584],
         [-0.114],
         [-1.285],
         [ 4.643],
         [-0.051],
         [ 4.529],
         [ 3.158]],

        [[-0.696],
         [-0.646],
         [-0.717],
         [ 1.269],
         [-0.463],
         [-0.949],
         [-0.084],
         [-0.258],
         [-0.860],
         [-1.462]],

        [[-0.270],
         [-0.834],
         [-0.625],
         [-0.489],
         [-0.680],
         [-0.044],
         [-0.231],
         [-0.799],
         [-0.541],
         [ 3.071]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e+01],
         [2.660e+00],
         [1.000e-12],
         [4.490e+00],
         [1.000e-12],
         [3.526e+00],
         [1.000e-12],
         [1.000e-12],
         [7.637e-01]],

        [[1.000e-12],
         [1.829e-01],
         [1.760e+00],
         [1.000e-12],
         [2.278e+00],
         [1.000e-12],
         [1.000e-12],
         [3.988e-01],
         [2.168e-02],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.288e+00],
         [1.000e-12],
         [9.846e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.657e-01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.181e+00],
         [5.343e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [2.217e+00],
         [8.294e-01],
         [3.743e-01],
         [1.322e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.460e-01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.523e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.311e+00],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [9.238e-01],
         [1.000e-12],
         [4.415e+00],
         [4.214e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.643e+00],
         [1.000e-12],
         [4.529e+00],
         [3.158e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.269e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.071e+00]]], device='cuda:0')
v before min max tensor([[13.372],
        [-0.614],
        [ 2.450],
        [ 1.614],
        [-0.848],
        [-0.075],
        [ 0.948],
        [ 2.076],
        [-1.197],
        [ 2.504]], device='cuda:0')
v tensor([[1.000e+01],
        [1.000e-12],
        [2.450e+00],
        [1.614e+00],
        [1.000e-12],
        [1.000e-12],
        [9.476e-01],
        [2.076e+00],
        [1.000e-12],
        [2.504e+00]], device='cuda:0')
a after update for 1 param tensor([[ 2.740e-03, -1.371e-02,  2.194e-02,  1.323e-02,  6.272e-03,  1.232e-02,
         -2.679e-02,  6.284e-03,  4.257e-03, -2.425e-02],
        [ 4.394e-03,  2.291e-03,  1.748e-02,  3.098e-03,  7.586e-03, -2.647e-02,
         -2.441e-03,  1.773e-03, -2.117e-02, -4.678e-03],
        [ 7.987e-03, -2.206e-03,  5.778e-03,  8.633e-03, -3.715e-03,  1.317e-02,
          3.585e-04,  4.179e-03,  5.044e-03,  4.016e-03],
        [ 2.222e-03,  2.384e-03, -1.385e-02,  1.058e-02,  1.867e-02,  1.917e-02,
          1.198e-02,  7.677e-04, -2.766e-02,  3.756e-03],
        [ 2.262e-03, -1.317e-03, -1.628e-02, -3.370e-03, -4.900e-03,  2.611e-02,
          1.062e-02, -5.339e-03,  1.243e-02, -1.655e-02],
        [-2.388e-03,  1.751e-02,  5.462e-03,  2.778e-02, -1.305e-02, -1.533e-02,
         -8.108e-04,  6.241e-03, -6.273e-03,  5.929e-03],
        [-3.651e-03, -7.065e-03,  6.329e-03,  8.546e-03,  3.903e-03,  1.112e-02,
         -4.399e-03, -4.533e-03,  8.619e-03, -4.524e-04],
        [ 5.105e-04,  1.055e-02, -6.125e-04,  9.044e-03,  2.729e-03,  1.243e-02,
          2.152e-03, -1.215e-02, -6.140e-03, -5.064e-03],
        [-9.025e-04,  7.042e-03, -1.206e-02,  1.786e-02, -1.501e-02,  2.490e-02,
          1.551e-02, -5.820e-02, -5.347e-03, -1.506e-03],
        [ 9.670e-03, -2.261e-02, -2.777e-02, -2.223e-02, -3.262e-03, -1.302e-03,
         -3.544e-03,  1.022e-02, -1.642e-02, -5.112e-03],
        [ 7.940e-03, -1.360e-04, -1.359e-02,  1.492e-02,  3.957e-03,  9.584e-03,
         -1.618e-03,  5.782e-03, -3.443e-03,  1.780e-02],
        [ 5.367e-03, -1.392e-03,  1.044e-02,  1.810e-02,  5.978e-03,  6.778e-03,
         -1.804e-02, -1.715e-02, -7.250e-03, -4.333e-03],
        [-8.830e-03, -5.544e-03, -1.588e-03,  1.083e-02, -2.960e-02, -5.836e-03,
          1.296e-02,  1.853e-02, -1.967e-02,  1.300e-02],
        [ 7.851e-03, -5.242e-03,  3.792e-03, -1.240e-02,  2.040e-02, -8.887e-03,
         -4.621e-04,  2.852e-03, -2.114e-03, -1.483e-02],
        [ 7.208e-03, -8.656e-03,  6.112e-03,  9.330e-03,  1.145e-02,  1.010e-02,
          1.382e-02, -1.317e-02,  1.271e-03,  1.125e-02],
        [-1.463e-02,  1.169e-02, -1.109e-02,  3.783e-03, -1.736e-02,  1.053e-04,
          4.884e-04, -6.884e-04,  4.274e-02, -1.286e-02],
        [-5.416e-03, -1.065e-02, -6.954e-03,  5.963e-03, -4.514e-03,  2.735e-02,
          8.983e-03, -2.249e-02, -6.593e-03,  3.143e-03],
        [ 9.796e-03, -2.244e-03, -8.600e-03, -2.469e-03, -2.302e-03,  7.351e-03,
          8.111e-04,  6.306e-03, -3.756e-03, -1.042e-04],
        [ 1.757e-03, -7.255e-03,  1.089e-02,  3.816e-02, -6.817e-03, -2.350e-02,
          1.154e-02, -2.040e-02, -3.464e-02, -7.455e-03],
        [ 3.961e-03, -2.325e-03, -1.700e-02,  9.644e-04, -5.044e-03,  1.592e-02,
          4.287e-03, -2.877e-02,  4.220e-02, -4.069e-03],
        [-6.724e-03, -7.660e-04, -4.613e-03,  1.426e-02, -5.177e-03,  2.948e-03,
          7.898e-03, -1.582e-02, -1.046e-02,  7.314e-03],
        [-2.021e-02,  8.771e-03,  4.023e-03, -1.881e-02,  2.145e-03, -1.359e-03,
          1.010e-03, -9.454e-03, -3.794e-05, -2.915e-02],
        [ 5.318e-03,  1.423e-02,  7.673e-04, -1.639e-02,  1.738e-03, -1.998e-02,
          1.334e-02, -3.174e-03,  3.887e-03,  6.222e-03],
        [ 1.380e-02, -2.178e-02,  4.107e-03,  2.163e-03,  3.052e-03, -7.855e-03,
         -4.245e-03,  1.596e-02,  3.247e-03,  1.328e-02],
        [-1.690e-02, -1.056e-02,  4.386e-03, -1.325e-02,  4.526e-03, -1.437e-03,
         -5.789e-03, -1.525e-02,  9.198e-03, -2.015e-02],
        [ 5.738e-03,  6.295e-03,  4.167e-03, -2.744e-02,  8.517e-03, -1.174e-02,
          1.265e-03,  2.465e-03,  2.874e-02, -3.217e-03],
        [-1.867e-03,  1.350e-02, -5.802e-03,  2.037e-03,  4.008e-03,  2.070e-02,
          2.799e-03,  5.098e-03, -9.637e-03, -5.327e-03],
        [ 3.356e-02,  1.562e-04,  6.164e-04, -3.341e-04, -2.377e-02, -1.187e-02,
         -8.029e-04, -1.482e-03, -6.426e-03, -9.316e-03],
        [ 1.670e-03,  6.020e-03, -4.711e-04, -2.604e-03,  3.454e-03,  1.153e-02,
         -1.779e-02, -2.110e-03,  2.094e-03,  1.468e-02],
        [-1.711e-03, -2.906e-03, -5.890e-04, -2.466e-02, -2.347e-03,  1.150e-02,
          4.888e-03,  1.704e-02,  1.206e-03,  3.384e-02],
        [ 1.366e-03, -2.582e-03,  1.302e-03, -1.358e-03,  1.687e-02, -2.301e-03,
         -3.343e-03, -1.898e-03, -2.225e-02, -1.988e-02],
        [-1.804e-03,  8.028e-03, -2.564e-03, -2.972e-03,  9.103e-03, -3.472e-03,
          3.161e-03,  2.870e-03, -2.497e-02, -1.304e-02],
        [ 3.501e-03, -1.660e-03, -1.460e-03, -3.434e-03,  3.323e-03, -9.471e-04,
         -1.897e-02,  8.030e-03, -1.233e-02, -4.080e-03],
        [-8.019e-03, -3.136e-03,  6.581e-03, -2.750e-03,  1.307e-02, -7.466e-03,
          1.778e-02,  6.170e-03, -2.265e-05,  1.759e-03],
        [ 2.245e-03,  3.037e-04, -9.866e-03, -7.373e-03,  2.478e-03,  3.584e-03,
          1.017e-02, -8.689e-03, -1.765e-02,  1.250e-02],
        [ 1.990e-03, -8.524e-03,  3.917e-04,  2.008e-03, -2.919e-04, -8.340e-03,
          5.196e-03,  1.028e-02, -1.709e-02,  8.788e-04],
        [ 8.376e-03,  1.069e-02, -1.577e-03, -9.436e-04, -6.053e-03, -3.606e-03,
         -1.559e-03, -1.117e-02, -6.099e-03, -3.933e-03],
        [-4.276e-03, -5.557e-03, -1.815e-03,  7.668e-03, -2.896e-03,  3.616e-03,
          1.064e-02, -1.151e-03,  6.353e-03, -9.178e-03],
        [ 1.093e-02,  1.212e-03, -7.102e-03, -1.766e-03,  2.570e-03, -4.358e-03,
          3.985e-03,  3.612e-03, -9.455e-03,  9.922e-03],
        [-2.001e-03, -5.106e-03, -3.453e-03,  7.183e-03,  2.181e-02,  6.713e-03,
         -7.886e-04,  5.003e-03,  1.368e-03,  5.431e-03],
        [ 3.355e-03, -4.542e-04, -2.389e-02,  2.081e-02,  1.443e-03,  1.866e-03,
          4.228e-02,  1.765e-03, -4.188e-02, -1.031e-03],
        [ 4.041e-02, -1.058e-02, -1.487e-02, -8.402e-05, -9.404e-04,  6.589e-03,
          2.290e-03,  1.143e-02, -6.336e-03,  4.285e-03],
        [ 6.070e-03,  2.947e-02, -1.833e-02,  3.577e-04,  4.716e-03, -6.731e-03,
         -7.451e-03,  7.582e-03, -2.415e-02,  3.103e-03],
        [-9.285e-03,  1.065e-03, -1.799e-02, -3.965e-03, -1.024e-02, -3.713e-03,
         -7.414e-03,  2.244e-03, -3.097e-03,  1.229e-02],
        [-1.092e-02,  5.566e-03,  4.651e-03,  3.505e-04, -1.368e-02, -1.605e-02,
          8.381e-03, -1.328e-03, -1.258e-02,  3.518e-03],
        [ 7.974e-03,  7.740e-03, -7.007e-03,  9.545e-04, -1.086e-03,  5.705e-03,
          3.499e-02,  2.371e-02,  2.305e-02, -6.595e-03],
        [-4.303e-03,  2.867e-03,  4.027e-03,  1.569e-02,  3.525e-04,  1.169e-02,
          7.403e-03,  1.932e-02, -1.132e-02, -4.823e-03],
        [-5.193e-03, -1.624e-03,  2.574e-03, -2.202e-02,  2.099e-03,  5.987e-03,
          1.789e-03, -6.143e-05,  1.275e-02, -2.643e-03],
        [ 1.107e-02,  2.906e-02, -1.898e-02, -6.127e-03,  1.766e-03,  3.166e-03,
         -4.699e-03,  1.013e-02,  2.288e-02,  2.591e-04],
        [ 1.778e-03, -2.945e-02, -2.813e-02,  1.161e-02, -5.111e-03, -5.329e-03,
          2.080e-03,  8.745e-03, -6.795e-03,  2.094e-03],
        [ 4.216e-03, -2.049e-04, -7.252e-03,  1.583e-02, -7.231e-03,  5.773e-03,
         -4.893e-03, -4.480e-03,  1.083e-02, -1.588e-02],
        [ 3.767e-03,  6.055e-03, -1.383e-03,  2.642e-02,  1.244e-02,  1.550e-03,
          4.866e-03, -1.535e-02, -5.267e-03, -5.411e-04],
        [-1.494e-02, -2.069e-02, -4.394e-03,  3.802e-03, -2.798e-03, -2.958e-03,
          7.290e-03,  1.545e-03, -2.079e-02,  7.220e-03],
        [ 2.424e-02, -4.501e-03,  6.044e-03,  8.750e-03,  3.373e-03, -6.160e-03,
          8.325e-03, -3.271e-02, -4.929e-03, -2.491e-02],
        [ 4.572e-03, -4.424e-03, -8.713e-03,  1.824e-02, -6.692e-03,  3.465e-04,
          6.561e-02,  1.030e-02, -7.736e-03, -4.294e-03],
        [ 1.853e-02,  6.413e-03, -2.330e-02, -1.650e-02,  1.372e-02,  4.167e-03,
          2.004e-03, -1.332e-03,  7.022e-03,  1.528e-02],
        [-4.870e-03,  1.105e-02,  4.958e-03, -2.936e-02, -6.451e-04,  1.879e-03,
         -5.941e-02, -9.773e-03, -1.061e-02,  1.734e-02],
        [ 9.599e-04,  9.300e-03, -6.446e-03,  8.592e-03,  1.147e-03,  2.970e-04,
          6.833e-03, -5.217e-03,  5.481e-03, -1.830e-02],
        [ 1.113e-03,  1.717e-03,  4.091e-03,  1.306e-02,  1.038e-02, -8.102e-03,
         -1.311e-02, -9.492e-03,  3.669e-03, -8.010e-03],
        [ 1.118e-04,  2.259e-03, -1.235e-02,  1.012e-02,  2.273e-02, -8.004e-04,
          1.021e-02,  8.883e-03,  4.923e-03,  4.504e-03],
        [ 1.197e-02, -6.830e-03, -9.521e-04,  8.817e-03,  3.698e-03, -7.794e-03,
          1.360e-03,  2.073e-03,  1.769e-02, -9.669e-03],
        [ 3.086e-03,  5.332e-03,  1.563e-03,  1.206e-02, -4.884e-03, -6.477e-03,
         -1.065e-02, -1.448e-02, -1.642e-02, -7.643e-04],
        [-2.017e-03,  1.344e-02,  2.809e-03, -8.488e-04,  1.494e-03, -6.185e-04,
         -1.564e-05, -1.283e-02, -1.513e-03,  1.353e-02],
        [ 1.004e-02,  2.592e-03, -2.564e-03,  2.061e-02,  7.737e-03, -1.581e-02,
         -5.422e-03, -8.414e-03,  2.018e-03, -1.276e-02],
        [-3.553e-04, -4.063e-03, -4.490e-03, -9.446e-03,  7.750e-03, -1.221e-03,
          1.250e-03,  2.038e-03,  3.494e-03,  1.938e-04],
        [-3.080e-03, -2.720e-03,  1.504e-02, -2.488e-03, -4.712e-04, -2.307e-03,
         -2.993e-03,  9.882e-03,  1.199e-03,  1.191e-03],
        [ 5.921e-03, -7.023e-03, -5.034e-03,  2.695e-03, -6.579e-04, -6.239e-03,
         -1.768e-03, -4.817e-04, -7.745e-03, -1.525e-03],
        [ 6.473e-03, -3.212e-03, -1.221e-03, -2.900e-02,  1.360e-02,  9.542e-03,
          4.788e-03,  1.125e-02,  7.716e-04,  9.005e-03],
        [ 7.768e-03, -6.334e-03, -1.286e-02, -7.170e-03,  1.494e-02,  2.541e-03,
          4.692e-03,  3.016e-02,  2.182e-04,  2.412e-03],
        [-1.319e-03,  7.004e-03,  7.339e-03,  2.519e-02, -8.411e-03, -5.016e-03,
         -3.117e-03, -2.572e-03,  5.308e-03, -3.282e-03],
        [ 1.189e-02,  4.147e-03, -5.956e-03, -8.813e-03, -5.894e-03,  7.418e-03,
          2.836e-03, -1.670e-03, -2.508e-03, -1.410e-02],
        [ 4.182e-03, -6.325e-03, -2.239e-02, -5.746e-03,  5.645e-03,  2.839e-03,
          2.225e-02, -1.029e-03,  1.021e-02,  6.569e-03],
        [ 3.324e-03, -5.785e-03,  4.324e-04, -1.263e-02, -3.285e-03, -3.917e-03,
         -2.538e-02, -6.551e-03, -2.202e-03, -9.503e-03],
        [ 4.229e-03, -1.653e-02,  2.035e-03, -1.158e-02, -7.035e-04,  6.604e-03,
          2.637e-02,  9.910e-04,  1.233e-02, -1.200e-02],
        [ 7.502e-03,  1.177e-02,  2.231e-02,  6.482e-03,  2.905e-03,  3.947e-03,
         -7.183e-04, -9.002e-03,  3.988e-03, -4.186e-03],
        [ 2.133e-03, -1.420e-03, -5.322e-03,  2.952e-02, -1.378e-02, -5.448e-03,
         -8.636e-03,  3.539e-03,  5.165e-04,  1.080e-03],
        [ 1.528e-02, -7.860e-03,  5.070e-03, -1.522e-02,  2.291e-02,  5.246e-03,
         -1.185e-02,  5.971e-03,  7.828e-03, -6.714e-03],
        [ 8.976e-04,  6.961e-03,  5.557e-03,  1.059e-04,  5.769e-04,  6.158e-03,
         -5.663e-03,  1.766e-03, -2.811e-03, -1.399e-02],
        [ 1.410e-03, -9.641e-03,  8.105e-03, -3.103e-03, -7.676e-04,  2.338e-02,
          1.537e-02, -5.387e-03, -1.329e-02,  3.219e-03],
        [ 9.922e-03, -2.704e-02, -1.407e-02, -1.170e-03, -4.095e-03,  8.239e-03,
         -6.024e-03, -3.281e-04, -6.108e-03, -1.741e-02],
        [-1.376e-03, -2.651e-03,  1.562e-02, -3.301e-03, -2.000e-03,  9.943e-04,
          3.256e-03,  9.981e-03, -6.889e-03,  3.035e-03],
        [-6.731e-03, -3.487e-03,  5.582e-03, -1.362e-02,  1.325e-02, -3.797e-03,
          7.198e-03, -1.394e-02,  1.262e-03, -2.058e-02],
        [ 4.311e-03,  1.881e-03, -3.648e-03, -5.100e-03,  3.534e-03,  8.274e-03,
         -6.843e-03, -1.637e-03,  2.861e-03,  1.649e-03],
        [-3.556e-03, -3.777e-03,  9.679e-03, -9.732e-04,  1.632e-02,  2.849e-03,
         -1.622e-03, -6.407e-03,  2.328e-03, -2.044e-03],
        [ 6.206e-03, -6.018e-03, -6.987e-03,  1.506e-02, -2.458e-03, -3.161e-03,
         -3.067e-03,  8.339e-03,  1.371e-03, -6.893e-03],
        [-3.750e-04,  2.587e-03,  5.100e-03,  4.857e-03,  1.467e-04,  2.467e-03,
          6.243e-03,  1.121e-03,  2.647e-03, -9.385e-03],
        [-8.613e-03, -6.228e-04, -1.281e-03, -1.231e-02, -1.006e-02,  7.395e-03,
         -7.974e-03, -7.480e-03, -2.782e-03,  1.903e-03],
        [ 5.717e-03,  6.752e-03,  2.993e-03,  8.775e-03, -4.059e-03,  6.691e-04,
         -1.134e-02,  5.041e-03,  1.050e-03, -2.076e-03],
        [ 2.244e-03, -4.860e-04,  3.825e-03,  7.841e-03,  2.170e-03, -1.647e-03,
         -7.504e-03, -2.855e-03,  1.593e-04, -4.118e-03],
        [-3.984e-03,  4.949e-04, -1.062e-03, -3.201e-03,  5.590e-03,  1.284e-02,
          4.427e-03,  1.715e-02,  6.533e-03,  2.067e-04],
        [ 1.726e-02,  1.267e-02, -1.437e-02, -1.536e-03, -1.682e-03, -5.970e-03,
         -1.469e-02,  3.473e-02,  1.557e-02,  6.484e-03],
        [ 2.515e-03,  1.884e-02,  8.497e-03, -1.250e-02,  5.455e-03,  1.179e-02,
          5.731e-03, -1.334e-02, -2.721e-02,  1.121e-02],
        [ 3.912e-03,  4.978e-03, -1.566e-02, -5.664e-03,  3.347e-03,  2.849e-03,
          1.681e-02,  1.482e-02,  3.451e-03, -6.615e-05],
        [-1.666e-02,  1.191e-03, -6.225e-04,  1.770e-02, -1.062e-02,  1.077e-02,
          3.113e-02, -3.924e-03,  4.861e-03, -4.550e-03],
        [ 2.214e-02,  1.464e-02, -2.417e-02, -5.225e-03, -1.681e-03, -1.935e-03,
          1.897e-03, -8.970e-04,  1.747e-03,  1.612e-03],
        [-6.674e-03,  3.971e-02, -3.738e-04, -1.765e-02,  9.863e-03, -1.668e-02,
         -1.992e-03, -7.433e-03,  2.050e-02,  3.766e-03],
        [ 1.205e-02, -1.843e-02, -7.029e-03,  5.451e-03,  7.245e-03,  8.004e-03,
         -7.522e-03,  1.386e-02,  7.188e-03,  2.717e-03],
        [ 1.448e-02,  4.020e-04, -1.947e-02,  2.709e-06, -2.725e-02, -4.810e-04,
          8.299e-03,  1.026e-02, -1.912e-03,  2.243e-03],
        [ 5.377e-05,  2.206e-02,  8.543e-03,  2.859e-03, -1.790e-02,  2.483e-02,
          8.942e-03, -2.450e-02, -1.832e-02,  2.030e-04],
        [ 1.104e-02, -1.383e-02, -1.520e-02,  8.092e-03, -4.480e-03, -1.856e-02,
         -2.645e-02,  4.943e-03, -1.706e-02,  9.188e-03]], device='cuda:0')
s after update for 1 param tensor([[0.692, 0.701, 0.344, 0.658, 0.380, 0.733, 0.944, 0.556, 1.231, 1.023],
        [0.892, 0.566, 1.130, 0.677, 0.306, 0.623, 0.434, 0.392, 0.748, 0.548],
        [0.951, 0.801, 0.920, 0.262, 0.910, 0.659, 0.855, 0.984, 0.613, 0.664],
        [0.823, 0.664, 0.497, 0.808, 0.790, 0.291, 0.903, 0.530, 0.673, 0.462],
        [0.713, 1.265, 0.725, 1.099, 0.607, 0.625, 0.661, 0.721, 0.377, 0.818],
        [1.077, 1.219, 0.531, 0.725, 0.452, 0.521, 0.550, 0.561, 0.587, 0.434],
        [0.589, 0.450, 0.615, 0.418, 0.417, 0.634, 0.470, 0.308, 0.871, 0.510],
        [0.777, 0.458, 0.570, 0.571, 0.519, 0.802, 0.522, 0.409, 0.423, 0.783],
        [0.874, 0.596, 0.669, 0.577, 0.971, 0.662, 1.112, 0.780, 1.028, 0.668],
        [0.787, 1.122, 0.620, 0.657, 0.667, 0.412, 0.519, 0.596, 0.605, 1.151],
        [0.913, 0.907, 0.434, 0.556, 0.582, 0.762, 0.805, 0.348, 0.343, 0.507],
        [0.625, 0.804, 0.190, 0.774, 0.385, 0.454, 0.663, 0.324, 0.482, 0.404],
        [0.406, 0.346, 0.748, 0.445, 0.684, 0.936, 0.830, 0.657, 0.339, 0.558],
        [1.051, 0.382, 0.518, 0.457, 1.011, 0.450, 0.340, 0.734, 0.474, 0.535],
        [0.962, 0.672, 1.036, 0.768, 0.862, 0.533, 0.783, 0.605, 0.647, 0.716],
        [0.998, 0.476, 0.694, 0.344, 0.343, 0.337, 0.368, 0.694, 0.378, 0.472],
        [0.442, 0.461, 0.771, 0.350, 0.529, 0.428, 0.318, 0.325, 0.348, 0.715],
        [0.431, 0.995, 0.458, 0.563, 0.376, 0.633, 0.548, 0.654, 0.634, 0.601],
        [0.890, 1.180, 0.529, 0.486, 0.374, 0.523, 0.460, 0.738, 0.549, 0.640],
        [0.646, 1.166, 0.626, 0.298, 0.600, 0.409, 0.405, 0.912, 0.517, 0.563],
        [0.366, 0.798, 1.080, 0.416, 0.999, 0.842, 0.554, 1.186, 0.500, 1.220],
        [1.149, 0.751, 0.984, 0.591, 1.342, 0.824, 0.517, 0.415, 0.747, 1.121],
        [0.492, 0.341, 0.820, 0.857, 0.727, 0.640, 0.542, 0.489, 0.343, 0.511],
        [0.424, 0.928, 1.352, 0.398, 0.188, 0.780, 0.508, 0.446, 0.629, 0.500],
        [0.729, 1.087, 1.572, 0.601, 0.756, 0.732, 0.607, 1.409, 0.536, 1.283],
        [0.225, 0.424, 0.808, 0.514, 0.327, 0.579, 0.806, 0.999, 0.436, 0.337],
        [1.039, 0.491, 0.828, 0.349, 1.240, 0.770, 1.222, 1.126, 0.732, 0.905],
        [0.741, 0.548, 0.623, 0.738, 0.366, 1.224, 0.997, 0.560, 0.461, 0.941],
        [0.506, 0.536, 1.104, 0.447, 0.439, 0.320, 0.949, 0.672, 0.757, 0.439],
        [0.217, 0.452, 1.017, 0.493, 0.796, 0.173, 0.535, 0.812, 0.566, 0.517],
        [0.732, 0.361, 0.632, 0.640, 0.526, 0.816, 0.643, 0.581, 0.510, 0.446],
        [0.273, 0.390, 0.420, 0.454, 0.379, 0.526, 0.434, 0.323, 0.581, 0.263],
        [0.385, 0.644, 0.630, 0.687, 0.816, 1.242, 0.342, 0.697, 0.402, 0.505],
        [0.771, 0.381, 0.552, 0.630, 0.600, 0.678, 0.721, 0.691, 0.405, 0.439],
        [0.445, 0.945, 0.762, 1.056, 0.416, 0.925, 0.595, 0.988, 0.333, 1.040],
        [0.701, 1.019, 0.373, 0.724, 0.714, 0.379, 0.709, 0.581, 0.419, 0.604],
        [0.459, 1.050, 0.691, 0.608, 1.267, 0.402, 0.338, 1.172, 0.737, 0.391],
        [0.552, 0.680, 0.410, 0.429, 0.707, 0.682, 0.429, 0.493, 0.533, 1.162],
        [0.727, 0.539, 0.603, 0.442, 0.519, 0.259, 0.583, 0.377, 0.485, 0.311],
        [0.519, 0.388, 0.282, 0.854, 0.830, 0.870, 0.516, 0.400, 0.620, 0.528],
        [0.545, 0.575, 0.547, 0.771, 0.486, 0.374, 1.074, 0.555, 0.704, 0.441],
        [0.702, 0.936, 0.457, 0.294, 0.886, 0.674, 0.515, 0.368, 0.548, 0.365],
        [0.354, 0.832, 0.364, 0.662, 0.475, 0.715, 0.500, 0.588, 0.734, 0.694],
        [0.689, 0.774, 0.502, 0.569, 1.256, 0.572, 0.402, 0.749, 0.812, 0.810],
        [0.601, 0.433, 0.564, 0.191, 0.664, 0.634, 0.825, 0.351, 0.591, 0.740],
        [0.996, 0.717, 0.905, 0.314, 0.895, 0.796, 0.618, 0.443, 0.467, 0.515],
        [0.542, 0.623, 0.787, 0.906, 0.965, 0.763, 0.819, 0.400, 0.401, 0.703],
        [0.842, 0.785, 0.267, 0.766, 1.088, 1.106, 0.957, 0.526, 0.363, 0.597],
        [0.990, 0.645, 0.914, 0.642, 0.842, 0.847, 0.907, 0.395, 0.341, 0.981],
        [0.965, 1.028, 0.630, 0.703, 0.833, 0.790, 0.878, 0.675, 0.667, 1.129],
        [0.368, 0.709, 0.794, 0.894, 0.312, 1.044, 0.756, 0.641, 0.862, 0.975],
        [0.185, 0.547, 0.387, 0.427, 0.561, 0.513, 0.236, 0.520, 0.336, 0.704],
        [0.677, 0.586, 0.435, 0.387, 0.591, 0.374, 0.337, 0.275, 0.823, 0.249],
        [0.549, 0.693, 0.491, 0.576, 0.556, 1.093, 0.542, 0.401, 0.545, 0.674],
        [0.302, 0.345, 0.499, 0.379, 0.264, 0.435, 0.730, 0.271, 0.239, 0.459],
        [0.474, 0.463, 0.549, 0.932, 0.886, 0.858, 0.761, 0.973, 0.508, 0.662],
        [0.971, 0.394, 0.747, 0.555, 0.696, 1.050, 0.818, 0.487, 0.584, 0.431],
        [0.401, 0.394, 0.749, 0.520, 0.445, 0.702, 0.451, 0.563, 0.532, 0.732],
        [0.398, 1.302, 1.119, 0.660, 0.582, 0.896, 0.494, 0.340, 0.437, 0.209],
        [0.847, 0.670, 0.510, 1.030, 0.447, 0.955, 0.843, 0.507, 0.503, 0.753],
        [0.699, 0.772, 0.604, 0.186, 0.494, 0.709, 1.164, 0.443, 0.439, 0.569],
        [0.947, 0.429, 0.731, 0.340, 0.588, 0.508, 0.965, 0.617, 0.454, 0.642],
        [0.840, 0.637, 0.559, 0.548, 0.557, 0.948, 0.883, 0.482, 1.104, 0.826],
        [0.503, 0.711, 0.630, 0.311, 0.312, 0.361, 0.839, 0.534, 0.402, 0.507],
        [0.302, 0.718, 0.541, 0.544, 0.649, 0.500, 0.814, 0.725, 0.997, 1.292],
        [0.688, 0.376, 0.441, 0.472, 0.537, 0.577, 0.525, 0.362, 0.666, 0.919],
        [1.065, 0.541, 0.388, 0.982, 0.399, 1.381, 0.676, 0.833, 1.233, 0.839],
        [0.859, 0.928, 0.781, 0.437, 0.809, 0.601, 0.799, 0.822, 0.479, 0.889],
        [0.731, 0.995, 0.682, 0.480, 1.484, 0.303, 1.016, 0.616, 0.481, 0.450],
        [0.713, 0.412, 0.521, 0.461, 0.526, 0.567, 1.017, 0.465, 1.170, 0.614],
        [0.497, 0.656, 0.614, 0.595, 0.557, 0.949, 0.514, 1.170, 0.209, 0.624],
        [0.305, 0.215, 0.515, 0.446, 0.914, 0.379, 0.643, 0.636, 0.418, 0.314],
        [0.860, 0.832, 0.262, 0.806, 0.520, 0.464, 0.652, 1.062, 0.412, 0.461],
        [0.521, 0.478, 0.440, 0.379, 0.520, 0.491, 0.480, 0.422, 0.784, 0.339],
        [0.587, 0.853, 0.599, 0.294, 0.813, 0.550, 0.671, 0.851, 0.549, 0.296],
        [0.602, 0.659, 0.846, 0.609, 0.592, 0.595, 0.670, 1.039, 0.254, 0.583],
        [0.465, 0.983, 0.561, 0.608, 0.548, 0.857, 1.114, 0.617, 0.495, 0.769],
        [0.346, 0.797, 0.655, 0.568, 0.622, 0.628, 0.539, 0.826, 1.107, 0.376],
        [0.203, 0.587, 0.782, 0.469, 0.433, 0.612, 0.549, 0.607, 0.433, 0.520],
        [0.632, 0.798, 0.326, 0.830, 0.852, 0.721, 0.162, 0.766, 0.538, 0.781],
        [0.623, 0.830, 0.470, 0.850, 0.338, 0.273, 0.823, 0.307, 0.950, 0.708],
        [0.666, 0.655, 0.423, 0.229, 0.512, 1.015, 0.928, 0.448, 1.100, 0.556],
        [0.903, 0.503, 0.848, 0.746, 0.583, 0.475, 0.756, 0.861, 0.523, 0.946],
        [0.556, 0.606, 0.625, 0.254, 0.913, 0.648, 0.597, 1.145, 0.750, 0.899],
        [0.370, 0.842, 0.894, 0.457, 1.096, 0.959, 0.436, 0.588, 0.567, 0.438],
        [0.773, 0.596, 0.534, 0.682, 0.511, 0.452, 0.558, 0.589, 0.384, 0.484],
        [0.504, 0.579, 0.682, 0.463, 0.556, 0.715, 0.971, 0.710, 0.520, 0.500],
        [0.668, 0.723, 0.468, 0.269, 0.687, 0.702, 0.562, 0.352, 0.548, 0.842],
        [0.653, 0.769, 0.710, 0.338, 0.452, 0.317, 0.620, 0.163, 0.567, 0.286],
        [0.628, 1.153, 0.696, 0.603, 0.684, 0.252, 0.502, 0.487, 0.810, 0.492],
        [0.683, 1.233, 0.870, 0.325, 0.873, 1.306, 0.673, 0.846, 0.807, 1.265],
        [0.867, 0.656, 0.812, 0.514, 0.447, 0.833, 0.771, 0.459, 0.656, 1.049],
        [0.316, 0.428, 0.795, 0.288, 0.403, 0.570, 0.381, 0.557, 0.360, 0.970],
        [0.721, 0.888, 0.920, 1.162, 0.755, 0.976, 0.865, 1.332, 0.886, 1.397],
        [0.837, 0.877, 0.453, 0.532, 0.915, 0.518, 0.808, 0.725, 1.065, 1.017],
        [0.859, 0.867, 0.506, 0.471, 0.386, 0.656, 0.495, 0.833, 0.883, 1.437],
        [0.971, 1.058, 0.353, 0.518, 0.780, 1.385, 0.607, 1.041, 0.624, 1.298],
        [0.627, 0.517, 0.359, 0.315, 0.711, 0.529, 0.908, 0.728, 0.651, 0.886],
        [0.782, 0.740, 0.712, 0.598, 0.526, 0.527, 0.500, 0.371, 0.322, 0.564],
        [0.941, 0.506, 0.829, 0.735, 0.720, 0.422, 0.806, 0.916, 0.648, 0.765]],
       device='cuda:0')
b after update for 1 param tensor([[23.430, 23.592, 16.529, 22.853, 17.373, 24.112, 27.377, 21.012, 31.252,
         28.497],
        [26.602, 21.184, 29.939, 23.175, 15.575, 22.242, 18.554, 17.648, 24.369,
         20.858],
        [27.475, 25.217, 27.016, 14.411, 26.877, 22.868, 26.052, 27.950, 22.053,
         22.958],
        [25.556, 22.955, 19.851, 25.319, 25.030, 15.201, 26.771, 20.499, 23.117,
         19.140],
        [23.779, 31.683, 23.982, 29.537, 21.946, 22.262, 22.904, 23.922, 17.301,
         25.483],
        [29.228, 31.103, 20.524, 23.980, 18.935, 20.327, 20.884, 21.099, 21.583,
         18.561],
        [21.629, 18.893, 22.097, 18.220, 18.183, 22.438, 19.306, 15.623, 26.297,
         20.116],
        [24.839, 19.069, 21.264, 21.285, 20.288, 25.231, 20.354, 18.010, 18.318,
         24.922],
        [26.338, 21.741, 23.039, 21.400, 27.764, 22.923, 29.702, 24.885, 28.558,
         23.020],
        [24.994, 29.839, 22.185, 22.832, 23.004, 18.082, 20.301, 21.756, 21.908,
         30.219],
        [26.921, 26.826, 18.566, 21.013, 21.497, 24.583, 25.273, 16.619, 16.498,
         20.065],
        [22.267, 25.258, 12.273, 24.783, 17.476, 18.976, 22.941, 16.031, 19.554,
         17.910],
        [17.948, 16.569, 24.361, 18.791, 23.293, 27.248, 25.659, 22.842, 16.401,
         21.034],
        [28.877, 17.406, 20.279, 19.040, 28.322, 18.900, 16.421, 24.132, 19.390,
         20.609],
        [27.626, 23.096, 28.671, 24.687, 26.157, 20.559, 24.933, 21.915, 22.662,
         23.838],
        [28.138, 19.427, 23.465, 16.525, 16.497, 16.356, 17.079, 23.470, 17.310,
         19.348],
        [18.727, 19.135, 24.728, 16.674, 20.494, 18.435, 15.893, 16.050, 16.629,
         23.822],
        [18.489, 28.094, 19.059, 21.135, 17.270, 22.411, 20.851, 22.786, 22.424,
         21.837],
        [26.570, 30.606, 20.493, 19.647, 17.232, 20.380, 19.097, 24.204, 20.874,
         22.535],
        [22.635, 30.418, 22.291, 15.368, 21.825, 18.005, 17.923, 26.898, 20.259,
         21.141],
        [17.052, 25.162, 29.278, 18.159, 28.156, 25.855, 20.974, 30.677, 19.915,
         31.109],
        [30.199, 24.411, 27.951, 21.653, 32.629, 25.568, 20.255, 18.142, 24.351,
         29.832],
        [19.755, 16.458, 25.516, 26.079, 24.020, 22.529, 20.730, 19.698, 16.491,
         20.145],
        [18.341, 27.143, 32.754, 17.761, 12.226, 24.877, 20.077, 18.818, 22.343,
         19.921],
        [24.052, 29.371, 35.315, 21.836, 24.492, 24.107, 21.948, 33.435, 20.627,
         31.908],
        [13.355, 18.349, 25.326, 20.200, 16.117, 21.438, 25.284, 28.155, 18.607,
         16.356],
        [28.718, 19.746, 25.629, 16.643, 31.372, 24.716, 31.145, 29.896, 24.106,
         26.798],
        [24.257, 20.856, 22.232, 24.203, 17.031, 31.172, 28.130, 21.082, 19.124,
         27.326],
        [20.044, 20.631, 29.598, 18.824, 18.669, 15.944, 27.444, 23.091, 24.502,
         18.671],
        [13.111, 18.932, 28.412, 19.787, 25.139, 11.731, 20.602, 25.385, 21.195,
         20.247],
        [24.106, 16.917, 22.388, 22.542, 20.440, 25.446, 22.591, 21.481, 20.121,
         18.812],
        [14.729, 17.598, 18.264, 18.983, 17.340, 20.423, 18.566, 16.008, 21.479,
         14.455],
        [17.472, 22.608, 22.361, 23.357, 25.444, 31.399, 16.467, 23.521, 17.860,
         20.013],
        [24.743, 17.395, 20.931, 22.354, 21.819, 23.198, 23.916, 23.414, 17.921,
         18.674],
        [18.786, 27.380, 24.586, 28.946, 18.166, 27.100, 21.738, 28.004, 16.258,
         28.724],
        [23.582, 28.436, 17.200, 23.972, 23.797, 17.332, 23.727, 21.473, 18.224,
         21.902],
        [19.092, 28.868, 23.423, 21.957, 31.712, 17.863, 16.379, 30.498, 24.190,
         17.614],
        [20.925, 23.224, 18.039, 18.460, 23.682, 23.268, 18.445, 19.770, 20.574,
         30.360],
        [24.014, 20.682, 21.877, 18.726, 20.295, 14.339, 21.501, 17.300, 19.608,
         15.721],
        [20.301, 17.549, 14.958, 26.026, 25.664, 26.273, 20.245, 17.816, 22.176,
         20.462],
        [20.806, 21.363, 20.832, 24.737, 19.633, 17.232, 29.193, 20.995, 23.628,
         18.704],
        [23.608, 27.255, 19.044, 15.266, 26.513, 23.122, 20.221, 17.080, 20.858,
         17.017],
        [16.756, 25.699, 16.998, 22.923, 19.422, 23.813, 19.923, 21.604, 24.142,
         23.472],
        [23.386, 24.776, 19.959, 21.252, 31.571, 21.297, 17.863, 24.373, 25.385,
         25.347],
        [21.845, 18.534, 21.153, 12.297, 22.951, 22.432, 25.581, 16.686, 21.662,
         24.233],
        [28.111, 23.854, 26.804, 15.795, 26.647, 25.131, 22.140, 18.740, 19.257,
         20.221],
        [20.742, 22.243, 24.996, 26.812, 27.670, 24.605, 25.500, 17.814, 17.835,
         23.620],
        [25.856, 24.965, 14.544, 24.649, 29.389, 29.619, 27.564, 20.433, 16.969,
         21.766],
        [28.032, 22.630, 26.932, 22.563, 25.845, 25.924, 26.832, 17.708, 16.452,
         27.901],
        [27.671, 28.566, 22.361, 23.623, 25.713, 25.039, 26.403, 23.152, 23.006,
         29.925],
        [17.077, 23.723, 25.109, 26.631, 15.724, 28.782, 24.493, 22.562, 26.159,
         27.816],
        [12.111, 20.837, 17.535, 18.397, 21.106, 20.171, 13.675, 20.312, 16.333,
         23.644],
        [23.182, 21.572, 18.578, 17.520, 21.654, 17.231, 16.360, 14.771, 25.550,
         14.069],
        [20.882, 23.455, 19.748, 21.375, 20.998, 29.455, 20.748, 17.832, 20.802,
         23.119],
        [15.475, 16.557, 19.905, 17.335, 14.471, 18.586, 24.074, 14.664, 13.761,
         19.089],
        [19.399, 19.175, 20.865, 27.195, 26.517, 26.096, 24.574, 27.784, 20.079,
         22.926],
        [27.764, 17.690, 24.347, 20.985, 23.502, 28.861, 25.475, 19.655, 21.528,
         18.499],
        [17.835, 17.680, 24.373, 20.318, 18.787, 23.610, 18.914, 21.134, 20.552,
         24.108],
        [17.765, 32.147, 29.802, 22.885, 21.499, 26.663, 19.795, 16.414, 18.620,
         12.879],
        [25.931, 23.060, 20.122, 28.591, 18.841, 27.531, 25.860, 20.060, 19.971,
         24.437],
        [23.559, 24.757, 21.901, 12.146, 19.795, 23.726, 30.393, 18.755, 18.659,
         21.240],
        [27.409, 18.453, 24.092, 16.435, 21.610, 20.074, 27.678, 22.134, 18.985,
         22.570],
        [25.825, 22.482, 21.060, 20.860, 21.017, 27.425, 26.471, 19.557, 29.599,
         25.610],
        [19.973, 23.758, 22.358, 15.721, 15.723, 16.927, 25.803, 20.593, 17.853,
         20.062],
        [15.473, 23.876, 20.729, 20.777, 22.695, 19.919, 25.418, 23.983, 28.121,
         32.023],
        [23.369, 17.282, 18.701, 19.349, 20.644, 21.394, 20.408, 16.951, 22.987,
         27.000],
        [29.067, 20.725, 17.552, 27.918, 17.796, 33.109, 23.163, 25.706, 31.279,
         25.806],
        [26.113, 27.144, 24.895, 18.617, 25.339, 21.837, 25.179, 25.542, 19.488,
         26.556],
        [24.090, 28.105, 23.266, 19.517, 34.317, 15.513, 28.398, 22.104, 19.533,
         18.888],
        [23.779, 18.088, 20.341, 19.124, 20.435, 21.208, 28.407, 19.218, 30.469,
         22.072],
        [19.864, 22.808, 22.075, 21.734, 21.019, 27.435, 20.200, 30.469, 12.883,
         22.244],
        [15.553, 13.064, 20.220, 18.815, 26.927, 17.351, 22.585, 22.469, 18.220,
         15.793],
        [26.121, 25.691, 14.408, 25.291, 20.317, 19.190, 22.746, 29.035, 18.084,
         19.128],
        [20.343, 19.474, 18.679, 17.353, 20.311, 19.730, 19.519, 18.308, 24.938,
         16.410],
        [21.589, 26.017, 21.808, 15.262, 25.399, 20.885, 23.082, 25.982, 20.873,
         15.318],
        [21.860, 22.871, 25.906, 21.991, 21.668, 21.733, 23.064, 28.717, 14.192,
         21.501],
        [19.209, 27.934, 21.093, 21.966, 20.845, 26.076, 29.733, 22.125, 19.813,
         24.698],
        [16.562, 25.145, 22.791, 21.228, 22.214, 22.318, 20.691, 25.601, 29.636,
         17.275],
        [12.680, 21.590, 24.919, 19.296, 18.529, 22.030, 20.882, 21.942, 18.547,
         20.305],
        [22.401, 25.163, 16.093, 25.664, 26.004, 23.922, 11.348, 24.653, 20.661,
         24.895],
        [22.232, 25.663, 19.307, 25.969, 16.389, 14.720, 25.552, 15.598, 27.450,
         23.711],
        [22.988, 22.794, 18.313, 13.491, 20.152, 28.376, 27.139, 18.851, 29.551,
         20.999],
        [26.763, 19.983, 25.941, 24.335, 21.512, 19.406, 24.489, 26.143, 20.379,
         27.397],
        [21.004, 21.932, 22.271, 14.193, 26.913, 22.683, 21.774, 30.145, 24.401,
         26.704],
        [17.126, 25.842, 26.634, 19.035, 29.494, 27.593, 18.609, 21.595, 21.212,
         18.645],
        [24.774, 21.755, 20.591, 23.258, 20.131, 18.946, 21.039, 21.622, 17.466,
         19.595],
        [20.000, 21.435, 23.259, 19.173, 21.010, 23.814, 27.762, 23.743, 20.323,
         19.927],
        [23.020, 23.947, 19.277, 14.606, 23.347, 23.605, 21.114, 16.702, 20.848,
         25.850],
        [22.765, 24.695, 23.734, 16.386, 18.943, 15.852, 22.186, 11.360, 21.217,
         15.059],
        [22.317, 30.247, 23.509, 21.871, 23.303, 14.146, 19.955, 19.665, 25.353,
         19.758],
        [23.276, 31.279, 26.281, 16.059, 26.320, 32.187, 23.111, 25.909, 25.299,
         31.687],
        [26.228, 22.813, 25.380, 20.205, 18.834, 25.710, 24.735, 19.083, 22.811,
         28.853],
        [15.824, 18.427, 25.118, 15.113, 17.894, 21.276, 17.385, 21.023, 16.898,
         27.739],
        [23.928, 26.549, 27.022, 30.370, 24.474, 27.837, 26.202, 32.511, 26.510,
         33.293],
        [25.765, 26.374, 18.952, 20.543, 26.940, 20.276, 25.315, 23.983, 29.065,
         28.403],
        [26.104, 26.228, 20.031, 19.335, 17.501, 22.814, 19.813, 25.718, 26.467,
         33.765],
        [27.754, 28.970, 16.745, 20.276, 24.876, 33.155, 21.948, 28.748, 22.251,
         32.098],
        [22.311, 20.264, 16.882, 15.821, 23.751, 20.487, 26.842, 24.039, 22.721,
         26.512],
        [24.918, 24.238, 23.776, 21.792, 20.437, 20.458, 19.921, 17.148, 15.981,
         21.148],
        [27.328, 20.033, 25.643, 24.149, 23.898, 18.296, 25.298, 26.968, 22.684,
         24.646]], device='cuda:0')
clipping threshold 0.48901445361078894
a after update for 1 param tensor([ 4.898e-02, -2.327e-04, -1.640e-02,  2.832e-03,  2.336e-02, -1.479e-02,
        -2.387e-02,  1.077e-02,  1.904e-02,  2.539e-02,  8.754e-03, -4.168e-03,
        -4.222e-02, -3.764e-02,  3.305e-03,  2.119e-02, -6.662e-03,  1.273e-02,
        -3.304e-03, -1.740e-02, -1.382e-02, -3.301e-02,  4.398e-02,  1.224e-02,
        -9.672e-03, -2.011e-02,  1.260e-02,  1.568e-02,  1.320e-02, -5.851e-03,
         4.105e-02,  1.950e-02, -2.682e-02, -6.576e-03,  4.879e-05,  8.665e-03,
        -4.388e-02, -1.797e-02,  7.098e-03, -3.604e-02, -2.863e-02, -2.776e-02,
        -2.529e-04,  8.337e-03, -4.813e-02, -3.149e-02,  7.170e-04, -1.188e-02,
         2.032e-02,  5.982e-03, -2.426e-02,  3.431e-02,  1.344e-02,  4.810e-03,
        -1.352e-02, -1.366e-02, -3.796e-02,  3.025e-02, -3.915e-02, -1.640e-02,
        -2.723e-02, -1.670e-04, -9.460e-03, -2.855e-02,  4.245e-03,  3.180e-03,
         1.305e-02, -3.038e-02,  2.056e-02, -1.257e-02, -7.072e-04, -1.701e-02,
         1.213e-02,  3.160e-02,  1.483e-02, -4.264e-02,  8.732e-03,  9.608e-03,
        -1.584e-02,  6.957e-03, -3.194e-02,  8.808e-03,  1.023e-02, -1.952e-02,
         2.461e-02, -1.313e-02, -1.022e-02, -1.300e-02,  1.462e-02, -2.082e-02,
        -2.000e-02,  1.419e-02, -1.290e-02, -1.914e-02,  4.179e-03,  2.767e-02,
         2.124e-02,  1.637e-02, -7.933e-03, -3.891e-03], device='cuda:0')
s after update for 1 param tensor([0.669, 0.605, 0.529, 0.503, 0.401, 0.587, 0.457, 0.330, 0.486, 0.748,
        0.740, 0.435, 0.822, 0.841, 0.720, 0.504, 0.625, 0.395, 0.529, 0.360,
        0.420, 0.441, 0.737, 0.437, 0.611, 0.309, 0.628, 0.751, 0.338, 0.366,
        0.392, 0.350, 0.300, 0.336, 0.199, 0.482, 0.473, 0.681, 0.480, 0.568,
        0.458, 0.719, 0.403, 0.569, 0.658, 0.418, 1.023, 0.656, 0.620, 0.660,
        1.052, 0.723, 0.788, 0.976, 0.477, 0.877, 0.688, 0.402, 0.808, 0.504,
        0.711, 0.527, 0.907, 0.839, 0.775, 1.067, 1.054, 0.652, 0.794, 0.355,
        0.996, 0.651, 0.431, 0.293, 0.728, 0.577, 0.510, 0.537, 0.916, 0.551,
        0.666, 0.476, 0.795, 0.315, 0.671, 0.827, 0.835, 0.638, 0.446, 0.481,
        0.487, 1.101, 0.789, 1.191, 1.046, 1.151, 0.879, 0.511, 0.787, 0.429],
       device='cuda:0')
b after update for 1 param tensor([23.043, 21.904, 20.487, 19.976, 17.848, 21.582, 19.045, 16.193, 19.635,
        24.371, 24.225, 18.572, 25.545, 25.827, 23.898, 19.993, 22.268, 17.695,
        20.487, 16.894, 18.267, 18.700, 24.188, 18.613, 22.015, 15.666, 22.324,
        24.416, 16.378, 17.043, 17.641, 16.663, 15.435, 16.320, 12.558, 19.552,
        19.377, 23.246, 19.523, 21.238, 19.070, 23.891, 17.885, 21.256, 22.859,
        18.217, 28.493, 22.815, 22.179, 22.877, 28.895, 23.948, 25.012, 27.829,
        19.446, 26.375, 23.370, 17.855, 25.329, 19.998, 23.747, 20.446, 26.832,
        25.809, 24.796, 29.105, 28.926, 22.741, 25.102, 16.778, 28.117, 22.729,
        18.486, 15.253, 24.029, 21.399, 20.109, 20.638, 26.957, 20.910, 22.989,
        19.438, 25.112, 15.810, 23.080, 25.616, 25.735, 22.501, 18.808, 19.528,
        19.652, 29.563, 25.025, 30.748, 28.809, 30.223, 26.409, 20.141, 24.985,
        18.454], device='cuda:0')
clipping threshold 0.48901445361078894
a after update for 1 param tensor([[[ 0.003],
         [-0.016],
         [ 0.038],
         [-0.009],
         [ 0.003],
         [-0.006],
         [ 0.008],
         [ 0.013],
         [ 0.024],
         [ 0.026]],

        [[ 0.053],
         [ 0.006],
         [-0.005],
         [ 0.002],
         [ 0.004],
         [ 0.015],
         [-0.019],
         [ 0.025],
         [ 0.009],
         [-0.013]],

        [[ 0.007],
         [-0.023],
         [ 0.010],
         [ 0.010],
         [ 0.017],
         [ 0.022],
         [ 0.017],
         [ 0.006],
         [-0.010],
         [ 0.004]],

        [[ 0.000],
         [-0.012],
         [ 0.015],
         [ 0.003],
         [-0.022],
         [ 0.003],
         [-0.015],
         [ 0.001],
         [-0.035],
         [ 0.011]],

        [[-0.016],
         [-0.036],
         [ 0.005],
         [-0.051],
         [ 0.000],
         [ 0.033],
         [ 0.010],
         [ 0.016],
         [-0.011],
         [ 0.001]],

        [[ 0.057],
         [-0.020],
         [-0.015],
         [ 0.005],
         [-0.004],
         [-0.001],
         [-0.020],
         [ 0.015],
         [ 0.004],
         [ 0.001]],

        [[-0.008],
         [-0.010],
         [ 0.026],
         [ 0.000],
         [-0.031],
         [-0.016],
         [ 0.007],
         [ 0.007],
         [ 0.016],
         [-0.035]],

        [[-0.011],
         [ 0.003],
         [-0.032],
         [ 0.010],
         [ 0.003],
         [-0.004],
         [ 0.013],
         [-0.031],
         [-0.043],
         [ 0.022]],

        [[-0.002],
         [-0.011],
         [ 0.012],
         [ 0.034],
         [-0.011],
         [ 0.015],
         [ 0.013],
         [ 0.012],
         [-0.001],
         [-0.030]],

        [[ 0.023],
         [-0.011],
         [ 0.019],
         [ 0.004],
         [-0.011],
         [-0.010],
         [ 0.003],
         [-0.012],
         [ 0.020],
         [ 0.030]]], device='cuda:0')
s after update for 1 param tensor([[[0.864],
         [1.286],
         [0.762],
         [0.672],
         [0.806],
         [0.914],
         [1.282],
         [1.100],
         [0.516],
         [0.588]],

        [[0.620],
         [0.334],
         [0.704],
         [0.846],
         [0.723],
         [0.287],
         [0.524],
         [0.739],
         [0.606],
         [1.126]],

        [[1.383],
         [0.723],
         [1.203],
         [0.478],
         [0.711],
         [0.842],
         [0.809],
         [0.525],
         [0.592],
         [0.631]],

        [[0.971],
         [1.133],
         [0.564],
         [0.621],
         [0.494],
         [0.708],
         [0.733],
         [0.489],
         [0.791],
         [0.423]],

        [[0.738],
         [0.688],
         [0.951],
         [0.427],
         [0.690],
         [0.509],
         [0.978],
         [0.612],
         [0.697],
         [1.239]],

        [[0.679],
         [1.051],
         [0.464],
         [0.678],
         [0.796],
         [0.705],
         [1.094],
         [1.107],
         [0.444],
         [0.533]],

        [[0.756],
         [0.910],
         [0.741],
         [1.096],
         [0.411],
         [0.793],
         [0.375],
         [1.085],
         [1.398],
         [0.670]],

        [[0.687],
         [0.308],
         [0.468],
         [0.448],
         [0.491],
         [1.104],
         [0.801],
         [0.659],
         [1.103],
         [0.785]],

        [[0.506],
         [0.498],
         [0.550],
         [0.989],
         [0.683],
         [0.653],
         [0.477],
         [0.871],
         [0.714],
         [1.182]],

        [[0.804],
         [0.791],
         [0.726],
         [0.492],
         [0.523],
         [0.635],
         [0.904],
         [0.850],
         [0.383],
         [1.100]]], device='cuda:0')
b after update for 1 param tensor([[[26.179],
         [31.950],
         [24.594],
         [23.100],
         [25.285],
         [26.935],
         [31.896],
         [29.540],
         [20.227],
         [21.602]],

        [[22.175],
         [16.275],
         [23.634],
         [25.907],
         [23.948],
         [15.090],
         [20.382],
         [24.213],
         [21.934],
         [29.896]],

        [[33.127],
         [23.961],
         [30.904],
         [19.470],
         [23.748],
         [25.851],
         [25.334],
         [20.406],
         [21.682],
         [22.384]],

        [[27.756],
         [29.982],
         [21.158],
         [22.192],
         [19.791],
         [23.704],
         [24.114],
         [19.689],
         [25.047],
         [18.324]],

        [[24.200],
         [23.374],
         [27.464],
         [18.400],
         [23.408],
         [20.098],
         [27.863],
         [22.038],
         [23.510],
         [31.351]],

        [[23.206],
         [28.879],
         [19.198],
         [23.204],
         [25.129],
         [23.656],
         [29.459],
         [29.643],
         [18.761],
         [20.562]],

        [[24.486],
         [26.873],
         [24.245],
         [29.496],
         [18.059],
         [25.089],
         [17.256],
         [29.346],
         [33.311],
         [23.054]],

        [[23.350],
         [15.642],
         [19.265],
         [18.852],
         [19.748],
         [29.604],
         [25.214],
         [22.861],
         [29.586],
         [24.961]],

        [[20.033],
         [19.888],
         [20.888],
         [28.010],
         [23.277],
         [22.768],
         [19.454],
         [26.283],
         [23.810],
         [30.626]],

        [[25.265],
         [25.050],
         [24.009],
         [19.768],
         [20.378],
         [22.443],
         [26.787],
         [25.965],
         [17.423],
         [29.551]]], device='cuda:0')
clipping threshold 0.48901445361078894
a after update for 1 param tensor([[-0.000],
        [-0.034],
        [ 0.005],
        [ 0.043],
        [-0.011],
        [ 0.020],
        [-0.016],
        [ 0.011],
        [-0.004],
        [-0.004]], device='cuda:0')
s after update for 1 param tensor([[1.246],
        [0.490],
        [0.664],
        [0.879],
        [0.886],
        [0.783],
        [1.306],
        [1.380],
        [0.828],
        [1.115]], device='cuda:0')
b after update for 1 param tensor([[31.445],
        [19.718],
        [22.952],
        [26.414],
        [26.520],
        [24.926],
        [32.191],
        [33.087],
        [25.632],
        [29.743]], device='cuda:0')
clipping threshold 0.48901445361078894
||w||^2 0.9840584827011911
exp ma of ||w||^2 0.6277402634097282
||w|| 0.9919972190995251
exp ma of ||w|| 0.7361651982119681
||w||^2 0.7691757341547587
exp ma of ||w||^2 0.5241796869932906
||w|| 0.8770266439252338
exp ma of ||w|| 0.6719479920785711
||w||^2 0.31820081709256
exp ma of ||w||^2 0.5779338641100195
||w|| 0.564092915300804
exp ma of ||w|| 0.7047061781916127
||w||^2 0.3523608795677358
exp ma of ||w||^2 0.6135270464899852
||w|| 0.5935999322504475
exp ma of ||w|| 0.7186488494667873
||w||^2 0.6836219661557891
exp ma of ||w||^2 0.5954926935597431
||w|| 0.8268143480587339
exp ma of ||w|| 0.7115829182417851
cuda
Objective function 8.05 = squared loss an data 6.99 + 0.5*rho*h**2 0.322003 + alpha*h 0.083721 + L2reg 0.60 + L1reg 0.05 ; SHD = 14 ; DAG True
Proportion of microbatches that were clipped  0.764825345247766
iteration 3 in inner loop, alpha 1.043250854397927 rho 100.0 h 0.08024994952793207
iteration 2 in outer loop, alpha = 9.068245807191134, rho = 100.0, h = 0.08024994952793207
cuda
1210
cuda
Objective function 8.69 = squared loss an data 6.99 + 0.5*rho*h**2 0.322003 + alpha*h 0.727726 + L2reg 0.60 + L1reg 0.05 ; SHD = 14 ; DAG True
||w||^2 9582.671476636466
exp ma of ||w||^2 9713270.41930058
||w|| 97.89112051987384
exp ma of ||w|| 725.0227302940272
||w||^2 0.2004519597766926
exp ma of ||w||^2 54364.0057602088
||w|| 0.44771861674124364
exp ma of ||w|| 5.450089086905649
||w||^2 0.09466191354564703
exp ma of ||w||^2 211.97128188506716
||w|| 0.30767176267192126
exp ma of ||w|| 0.4004708121999842
||w||^2 0.322655486742066
exp ma of ||w||^2 0.5963679923994147
||w|| 0.5680277165262854
exp ma of ||w|| 0.7051610624402164
||w||^2 0.46573940291849997
exp ma of ||w||^2 0.5968223679837411
||w|| 0.6824510260220142
exp ma of ||w|| 0.7122398725039533
||w||^2 0.5760504920454586
exp ma of ||w||^2 0.5097086942696915
||w|| 0.758979902267154
exp ma of ||w|| 0.6707788142650645
cuda
Objective function 8.51 = squared loss an data 7.38 + 0.5*rho*h**2 0.092712 + alpha*h 0.390487 + L2reg 0.61 + L1reg 0.04 ; SHD = 15 ; DAG True
Proportion of microbatches that were clipped  0.7658852061438965
iteration 1 in inner loop, alpha 9.068245807191134 rho 100.0 h 0.043060897817692734
1210
cuda
Objective function 9.35 = squared loss an data 7.38 + 0.5*rho*h**2 0.927120 + alpha*h 0.390487 + L2reg 0.61 + L1reg 0.04 ; SHD = 15 ; DAG True
||w||^2 6010457.926887967
exp ma of ||w||^2 218593674.85241684
||w|| 2451.623528784133
exp ma of ||w|| 8326.3444573918
||w||^2 26.575079009201712
exp ma of ||w||^2 2650804.915538556
||w|| 5.155102230722656
exp ma of ||w|| 182.79539752020892
||w||^2 2.5130276624829317
exp ma of ||w||^2 587041.7652633939
||w|| 1.5852531856088263
exp ma of ||w|| 43.03325687038488
||w||^2 0.45792408583560246
exp ma of ||w||^2 0.39720455463647675
||w|| 0.6767008835782634
exp ma of ||w|| 0.5808316480370899
||w||^2 0.2933734432394987
exp ma of ||w||^2 0.45503672848558474
||w|| 0.5416395879544799
exp ma of ||w|| 0.6249723771132831
||w||^2 0.2339651436322301
exp ma of ||w||^2 0.5135555635795629
||w|| 0.4836994352200859
exp ma of ||w|| 0.6678137856021317
||w||^2 0.3686061223236613
exp ma of ||w||^2 0.4726978725698713
||w|| 0.6071294115126208
exp ma of ||w|| 0.6476773851741089
||w||^2 0.15833199236726025
exp ma of ||w||^2 0.4788799817856272
||w|| 0.39790952786690126
exp ma of ||w|| 0.6405281505744118
||w||^2 0.6503144528301807
exp ma of ||w||^2 0.5626174500599479
||w|| 0.806420766616399
exp ma of ||w|| 0.6918472406505282
||w||^2 0.39061643305295635
exp ma of ||w||^2 0.5301642635452878
||w|| 0.6249931464047876
exp ma of ||w|| 0.6789692821015104
||w||^2 0.8488948186605574
exp ma of ||w||^2 0.4560402054268824
||w|| 0.9213548820408765
exp ma of ||w|| 0.637040497017131
||w||^2 0.964404711659328
exp ma of ||w||^2 0.4654130690815751
||w|| 0.9820410946896917
exp ma of ||w|| 0.642774478131086
||w||^2 1.2958792855506451
exp ma of ||w||^2 0.5393469540721803
||w|| 1.138366938008411
exp ma of ||w|| 0.6768088954459284
cuda
Objective function 8.73 = squared loss an data 7.83 + 0.5*rho*h**2 0.122569 + alpha*h 0.141981 + L2reg 0.59 + L1reg 0.04 ; SHD = 11 ; DAG True
Proportion of microbatches that were clipped  0.7700119000396668
iteration 2 in inner loop, alpha 9.068245807191134 rho 1000.0 h 0.0156569058398226
iteration 3 in outer loop, alpha = 24.725151647013732, rho = 1000.0, h = 0.0156569058398226
cuda
1210
cuda
Objective function 8.98 = squared loss an data 7.83 + 0.5*rho*h**2 0.122569 + alpha*h 0.387119 + L2reg 0.59 + L1reg 0.04 ; SHD = 11 ; DAG True
||w||^2 0.49804117530496617
exp ma of ||w||^2 83019.70893945478
||w|| 0.7057203237153981
exp ma of ||w|| 7.153528482686611
||w||^2 0.1023372909911983
exp ma of ||w||^2 0.4014719536530747
||w|| 0.31990200216816134
exp ma of ||w|| 0.5835586231057482
||w||^2 0.6525809587143984
exp ma of ||w||^2 0.547609608829241
||w|| 0.8078248317020209
exp ma of ||w|| 0.6846612726774653
||w||^2 0.37235281653793073
exp ma of ||w||^2 0.4597946873597124
||w|| 0.610207191483295
exp ma of ||w|| 0.6376821798766082
||w||^2 0.36845936665391077
exp ma of ||w||^2 0.5318227583803353
||w|| 0.6070085391935691
exp ma of ||w|| 0.6703349900722798
||w||^2 0.2593267373521075
exp ma of ||w||^2 0.5053882005685121
||w|| 0.5092413350780821
exp ma of ||w|| 0.6472726504565891
||w||^2 0.14035009196515644
exp ma of ||w||^2 0.5237742235203611
||w|| 0.37463327663884377
exp ma of ||w|| 0.6655299856050724
||w||^2 0.29818702107310674
exp ma of ||w||^2 0.5626862139997637
||w|| 0.5460650337396699
exp ma of ||w|| 0.6973519199148274
||w||^2 0.5948684345858084
exp ma of ||w||^2 0.4888545362904094
||w|| 0.7712771451208758
exp ma of ||w|| 0.6542092651427642
||w||^2 0.3195271154787325
exp ma of ||w||^2 0.46686378401868917
||w|| 0.5652672956033566
exp ma of ||w|| 0.633934221720527
cuda
Objective function 8.97 = squared loss an data 8.05 + 0.5*rho*h**2 0.050124 + alpha*h 0.247558 + L2reg 0.58 + L1reg 0.04 ; SHD = 11 ; DAG True
Proportion of microbatches that were clipped  0.7683975788467665
iteration 1 in inner loop, alpha 24.725151647013732 rho 1000.0 h 0.010012378678510458
1210
cuda
Objective function 9.43 = squared loss an data 8.05 + 0.5*rho*h**2 0.501239 + alpha*h 0.247558 + L2reg 0.58 + L1reg 0.04 ; SHD = 11 ; DAG True
||w||^2 6995549838.867668
exp ma of ||w||^2 11535448682.423975
||w|| 83639.40362572935
exp ma of ||w|| 86387.52466044623
||w||^2 8114552.00564696
exp ma of ||w||^2 606334356.404814
||w|| 2848.605273751869
exp ma of ||w|| 14457.920974272207
||w||^2 0.2396196899759404
exp ma of ||w||^2 0.32815589629377184
||w|| 0.4895096423727937
exp ma of ||w|| 0.47686244742268347
||w||^2 0.39377451994134977
exp ma of ||w||^2 0.37739033938769595
||w|| 0.6275145575533286
exp ma of ||w|| 0.5691764196010901
||w||^2 0.23459484324537153
exp ma of ||w||^2 0.40214730861669984
||w|| 0.484349918184541
exp ma of ||w|| 0.5896778641082908
||w||^2 0.27090658030383996
exp ma of ||w||^2 0.4164282257316621
||w|| 0.5204868685220022
exp ma of ||w|| 0.6008103611625847
||w||^2 1.5326045352578856
exp ma of ||w||^2 0.40647023786507375
||w|| 1.2379840609870087
exp ma of ||w|| 0.5907074862327826
||w||^2 0.2657506561893017
exp ma of ||w||^2 0.5222255598855847
||w|| 0.5155100931982823
exp ma of ||w|| 0.6780259752000021
||w||^2 0.20247384030086046
exp ma of ||w||^2 0.46765272072498576
||w|| 0.44997093272883804
exp ma of ||w|| 0.6354324425731865
||w||^2 0.2598623353623168
exp ma of ||w||^2 0.47549912928107596
||w|| 0.5097669422023331
exp ma of ||w|| 0.6379471675423398
||w||^2 0.5822948977382572
exp ma of ||w||^2 0.5398084510372866
||w|| 0.7630824973345
exp ma of ||w|| 0.6807133724697139
||w||^2 0.20363865418585897
exp ma of ||w||^2 0.43839195777613454
||w|| 0.45126339779097857
exp ma of ||w|| 0.620322513879495
||w||^2 0.081502127756569
exp ma of ||w||^2 0.4428922498377173
||w|| 0.28548577505117306
exp ma of ||w|| 0.6110550315577187
cuda
Objective function 9.05 = squared loss an data 8.26 + 0.5*rho*h**2 0.079917 + alpha*h 0.098849 + L2reg 0.57 + L1reg 0.04 ; SHD = 11 ; DAG True
Proportion of microbatches that were clipped  0.764645017510347
iteration 2 in inner loop, alpha 24.725151647013732 rho 10000.0 h 0.003997926315548739
1210
cuda
Objective function 9.77 = squared loss an data 8.26 + 0.5*rho*h**2 0.799171 + alpha*h 0.098849 + L2reg 0.57 + L1reg 0.04 ; SHD = 11 ; DAG True
||w||^2 79578765.11879417
exp ma of ||w||^2 30310098134.724148
||w|| 8920.693085113633
exp ma of ||w|| 52658.61267447301
||w||^2 36463171.59046663
exp ma of ||w||^2 9378446186.585688
||w|| 6038.474276708202
exp ma of ||w|| 20134.205999625345
||w||^2 12.089526965929561
exp ma of ||w||^2 31463152.731154468
||w|| 3.4769997074963297
exp ma of ||w|| 109.40339332249086
||w||^2 0.5417029248056209
exp ma of ||w||^2 293879.0014762532
||w|| 0.7360047043366101
exp ma of ||w|| 1.7192478344356699
||w||^2 0.14159008237045165
exp ma of ||w||^2 3159.8541426209836
||w|| 0.3762845763121997
exp ma of ||w|| 0.43842078341862883
||w||^2 0.09266510385825029
exp ma of ||w||^2 64.17394206311315
||w|| 0.30440943457496566
exp ma of ||w|| 0.4085661810345745
||w||^2 0.12155517564325931
exp ma of ||w||^2 14.213688430664728
||w|| 0.34864763822985995
exp ma of ||w|| 0.41012200762942497
||w||^2 0.10509350242681482
exp ma of ||w||^2 0.30743808546647156
||w|| 0.3241812801918316
exp ma of ||w|| 0.5119835759414234
||w||^2 0.18317342375357876
exp ma of ||w||^2 0.3240416628267933
||w|| 0.4279876443935955
exp ma of ||w|| 0.5346708901738737
||w||^2 0.31875991727258135
exp ma of ||w||^2 0.34984129263689945
||w|| 0.5645882723477184
exp ma of ||w|| 0.5477831740396232
||w||^2 0.14100519388671723
exp ma of ||w||^2 0.44193781973958646
||w|| 0.3755065830138231
exp ma of ||w|| 0.6222481733791017
||w||^2 0.6538523756540191
exp ma of ||w||^2 0.42733142773122046
||w|| 0.8086113872893573
exp ma of ||w|| 0.6122732021414424
||w||^2 0.16821605677654183
exp ma of ||w||^2 0.4842275933982646
||w|| 0.4101415082340994
exp ma of ||w|| 0.6454685441891631
||w||^2 0.7243630492181817
exp ma of ||w||^2 0.48591319766182084
||w|| 0.8510952057309346
exp ma of ||w|| 0.6406010691789753
||w||^2 0.6957073664840214
exp ma of ||w||^2 0.46422973943900697
||w|| 0.834090742356023
exp ma of ||w|| 0.6334444652073158
||w||^2 0.8935367056503202
exp ma of ||w||^2 0.48498336244158907
||w|| 0.9452707049572203
exp ma of ||w|| 0.643454808196741
||w||^2 0.5234385242438331
exp ma of ||w||^2 0.4174886547955407
||w|| 0.7234905142735688
exp ma of ||w|| 0.6072125232746244
||w||^2 0.44204911577282474
exp ma of ||w||^2 0.387506392974069
||w|| 0.6648677430683675
exp ma of ||w|| 0.5844740513555126
cuda
Objective function 9.09 = squared loss an data 8.36 + 0.5*rho*h**2 0.090975 + alpha*h 0.033351 + L2reg 0.55 + L1reg 0.04 ; SHD = 8 ; DAG True
Proportion of microbatches that were clipped  0.7648048721852713
iteration 3 in inner loop, alpha 24.725151647013732 rho 100000.0 h 0.0013488855963696977
iteration 4 in outer loop, alpha = 159.6137112839835, rho = 100000.0, h = 0.0013488855963696977
cuda
1210
cuda
Objective function 9.27 = squared loss an data 8.36 + 0.5*rho*h**2 0.090975 + alpha*h 0.215301 + L2reg 0.55 + L1reg 0.04 ; SHD = 8 ; DAG True
||w||^2 7877528657014.742
exp ma of ||w||^2 2295130960031.063
||w|| 2806693.5452618874
exp ma of ||w|| 861667.0700858227
||w||^2 2825144.465415864
exp ma of ||w||^2 45527378364.94879
||w|| 1680.8166067170635
exp ma of ||w|| 27892.086629127272
||w||^2 135.88614985598588
exp ma of ||w||^2 710054551.095019
||w|| 11.657021483036988
exp ma of ||w|| 548.4563318314887
||w||^2 0.19732688463546114
exp ma of ||w||^2 0.33091425379211975
||w|| 0.4442149081643491
exp ma of ||w|| 0.5429521397756806
||w||^2 0.621373688080965
exp ma of ||w||^2 0.3419805295939063
||w|| 0.7882725975707674
exp ma of ||w|| 0.5499207912729345
||w||^2 0.19277084500114655
exp ma of ||w||^2 0.3316357324893231
||w|| 0.43905676740160443
exp ma of ||w|| 0.5471719131937649
||w||^2 0.9628885624985705
exp ma of ||w||^2 0.34582571788822547
||w|| 0.9812688533213364
exp ma of ||w|| 0.5500733064837802
||w||^2 0.10727475660091403
exp ma of ||w||^2 0.32575076953630955
||w|| 0.32752825313385414
exp ma of ||w|| 0.5387108687995464
||w||^2 0.3425131140811296
exp ma of ||w||^2 0.33977900186718335
||w|| 0.585246199544371
exp ma of ||w|| 0.5497067746002522
||w||^2 0.12511870300081823
exp ma of ||w||^2 0.38482611402569344
||w|| 0.35372122215216073
exp ma of ||w|| 0.5921161196902318
||w||^2 0.08417098466754787
exp ma of ||w||^2 0.3382054466044279
||w|| 0.2901223615434492
exp ma of ||w|| 0.5466565138427899
||w||^2 0.11536461736631387
exp ma of ||w||^2 0.37235752236571956
||w|| 0.3396536726819156
exp ma of ||w|| 0.5732486075937698
||w||^2 0.36328476465181886
exp ma of ||w||^2 0.3539879279881181
||w|| 0.6027310881743357
exp ma of ||w|| 0.560186555308572
||w||^2 0.37901578886199583
exp ma of ||w||^2 0.33112069809175004
||w|| 0.6156425820733942
exp ma of ||w|| 0.5460253358229314
||w||^2 0.11717623310986283
exp ma of ||w||^2 0.3364895454961474
||w|| 0.342310141698815
exp ma of ||w|| 0.5507519460313691
cuda
Objective function 9.16 = squared loss an data 8.40 + 0.5*rho*h**2 0.041415 + alpha*h 0.145266 + L2reg 0.52 + L1reg 0.05 ; SHD = 12 ; DAG True
Proportion of microbatches that were clipped  0.7653249779063228
iteration 1 in inner loop, alpha 159.6137112839835 rho 100000.0 h 0.0009101069294104036
iteration 5 in outer loop, alpha = 1069.7206406943872, rho = 1000000.0, h = 0.0009101069294104036
Threshold 0.3
[[0.002 0.013 0.194 0.003 0.182 0.043 0.131 0.018 0.013 0.762]
 [0.376 0.005 0.385 0.007 0.142 0.255 0.477 0.017 0.003 0.265]
 [0.027 0.009 0.004 0.004 0.044 0.007 0.446 0.01  0.007 0.129]
 [0.943 0.548 0.702 0.003 0.268 1.566 0.45  0.844 0.116 0.494]
 [0.014 0.023 0.061 0.013 0.004 0.04  0.425 0.03  0.003 0.394]
 [0.082 0.022 0.516 0.003 0.094 0.005 0.443 0.006 0.009 0.113]
 [0.027 0.01  0.013 0.007 0.008 0.007 0.005 0.012 0.01  0.054]
 [0.175 0.224 0.302 0.004 0.12  0.78  0.354 0.003 0.022 0.469]
 [0.183 1.172 0.38  0.033 0.636 0.378 0.391 0.186 0.002 0.38 ]
 [0.007 0.027 0.033 0.006 0.011 0.036 0.068 0.009 0.009 0.003]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.762]
 [0.376 0.    0.385 0.    0.    0.    0.477 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.446 0.    0.    0.   ]
 [0.943 0.548 0.702 0.    0.    1.566 0.45  0.844 0.    0.494]
 [0.    0.    0.    0.    0.    0.    0.425 0.    0.    0.394]
 [0.    0.    0.516 0.    0.    0.    0.443 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.302 0.    0.    0.78  0.354 0.    0.    0.469]
 [0.    1.172 0.38  0.    0.636 0.378 0.391 0.    0.    0.38 ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]]
{'fdr': 0.38461538461538464, 'tpr': 0.8, 'fpr': 0.4, 'f1': 0.6956521739130435, 'shd': 12, 'npred': 26, 'ntrue': 20}
[0.013 0.194 0.003 0.182 0.043 0.131 0.018 0.013 0.762 0.376 0.385 0.007
 0.142 0.255 0.477 0.017 0.003 0.265 0.027 0.009 0.004 0.044 0.007 0.446
 0.01  0.007 0.129 0.943 0.548 0.702 0.268 1.566 0.45  0.844 0.116 0.494
 0.014 0.023 0.061 0.013 0.04  0.425 0.03  0.003 0.394 0.082 0.022 0.516
 0.003 0.094 0.443 0.006 0.009 0.113 0.027 0.01  0.013 0.007 0.008 0.007
 0.012 0.01  0.054 0.175 0.224 0.302 0.004 0.12  0.78  0.354 0.022 0.469
 0.183 1.172 0.38  0.033 0.636 0.378 0.391 0.186 0.38  0.007 0.027 0.033
 0.006 0.011 0.036 0.068 0.009 0.009]
[[0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 1. 1. 0. 0. 1. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.8878571428571428, 0.818089985994398)
Iterations 2500
Achieves (13.610683049707138, 1e-05)-DP
