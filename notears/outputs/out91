samples  5000  graph  10 30 ER mlp  minibatch size  50  noise  0.6  minibatches per NN training  250 quantile adaptive clipping
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.1229782946562032
iteration 1 in outer loop, alpha = 1.1229782946562032, rho = 1.0, h = 1.1229782946562032
cuda
iteration 1 in inner loop,alpha 1.1229782946562032 rho 1.0 h 0.7586153562268656
iteration 2 in inner loop,alpha 1.1229782946562032 rho 10.0 h 0.35052850700977345
iteration 3 in inner loop,alpha 1.1229782946562032 rho 100.0 h 0.11468940960946838
iteration 2 in outer loop, alpha = 12.591919255603042, rho = 100.0, h = 0.11468940960946838
cuda
iteration 1 in inner loop,alpha 12.591919255603042 rho 100.0 h 0.05177271318199317
iteration 2 in inner loop,alpha 12.591919255603042 rho 1000.0 h 0.015651355822457802
iteration 3 in outer loop, alpha = 28.243275078060844, rho = 1000.0, h = 0.015651355822457802
cuda
iteration 1 in inner loop,alpha 28.243275078060844 rho 1000.0 h 0.0076855114245848455
iteration 2 in inner loop,alpha 28.243275078060844 rho 10000.0 h 0.0014289170876846669
iteration 4 in outer loop, alpha = 42.532445954907516, rho = 10000.0, h = 0.0014289170876846669
cuda
iteration 1 in inner loop,alpha 42.532445954907516 rho 10000.0 h 0.0007810909223238127
iteration 2 in inner loop,alpha 42.532445954907516 rho 100000.0 h 0.0003151968036405606
iteration 5 in outer loop, alpha = 74.05212631896357, rho = 100000.0, h = 0.0003151968036405606
cuda
iteration 1 in inner loop,alpha 74.05212631896357 rho 100000.0 h 0.00017956972001975657
iteration 6 in outer loop, alpha = 253.62184633872016, rho = 1000000.0, h = 0.00017956972001975657
Threshold 0.3
[[0.004 0.    0.368 0.    1.15  0.001 1.809 0.    0.001 0.006]
 [2.231 0.002 1.466 0.    0.876 0.016 0.115 0.106 0.005 2.624]
 [0.003 0.    0.007 0.    2.007 0.    1.925 0.    0.001 0.   ]
 [1.277 0.407 1.441 0.    0.834 0.432 1.183 0.248 2.714 2.813]
 [0.    0.    0.    0.    0.004 0.    0.    0.    0.    0.   ]
 [0.186 0.007 0.189 0.    0.256 0.001 0.317 0.005 0.008 2.979]
 [0.    0.    0.001 0.    1.626 0.    0.004 0.    0.    0.   ]
 [1.802 0.006 1.35  0.    1.751 0.109 0.28  0.002 0.003 0.102]
 [2.328 0.039 2.294 0.    0.915 0.063 0.591 0.205 0.004 0.314]
 [0.183 0.    2.462 0.    1.744 0.    2.586 0.003 0.004 0.006]]
[[0.    0.    0.368 0.    1.15  0.    1.809 0.    0.    0.   ]
 [2.231 0.    1.466 0.    0.876 0.    0.    0.    0.    2.624]
 [0.    0.    0.    0.    2.007 0.    1.925 0.    0.    0.   ]
 [1.277 0.407 1.441 0.    0.834 0.432 1.183 0.    2.714 2.813]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.317 0.    0.    2.979]
 [0.    0.    0.    0.    1.626 0.    0.    0.    0.    0.   ]
 [1.802 0.    1.35  0.    1.751 0.    0.    0.    0.    0.   ]
 [2.328 0.    2.294 0.    0.915 0.    0.591 0.    0.    0.314]
 [0.    0.    2.462 0.    1.744 0.    2.586 0.    0.    0.   ]]
{'fdr': 0.12903225806451613, 'tpr': 0.9, 'fpr': 0.26666666666666666, 'f1': 0.8852459016393444, 'shd': 7, 'npred': 31, 'ntrue': 30}
[1.803e-04 3.685e-01 4.657e-05 1.150e+00 7.759e-04 1.809e+00 3.113e-04
 6.473e-04 6.239e-03 2.231e+00 1.466e+00 3.026e-04 8.756e-01 1.629e-02
 1.147e-01 1.060e-01 4.843e-03 2.624e+00 3.457e-03 4.974e-05 6.914e-06
 2.007e+00 1.628e-05 1.925e+00 4.218e-04 9.659e-04 3.474e-04 1.277e+00
 4.067e-01 1.441e+00 8.338e-01 4.317e-01 1.183e+00 2.478e-01 2.714e+00
 2.813e+00 9.493e-05 5.335e-06 1.069e-04 8.132e-06 1.721e-06 4.393e-04
 2.501e-05 7.378e-05 1.776e-05 1.861e-01 6.534e-03 1.893e-01 3.123e-04
 2.558e-01 3.172e-01 5.060e-03 8.206e-03 2.979e+00 2.337e-04 3.950e-05
 6.329e-04 1.201e-05 1.626e+00 2.851e-05 8.471e-05 1.369e-05 3.371e-04
 1.802e+00 5.666e-03 1.350e+00 3.756e-04 1.751e+00 1.090e-01 2.798e-01
 2.746e-03 1.020e-01 2.328e+00 3.940e-02 2.294e+00 1.263e-04 9.154e-01
 6.258e-02 5.911e-01 2.047e-01 3.136e-01 1.828e-01 2.226e-04 2.462e+00
 1.237e-04 1.744e+00 1.853e-04 2.586e+00 2.559e-03 4.399e-03]
[[0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [1. 0. 1. 0. 1. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [1. 1. 1. 0. 1. 1. 0. 0. 0. 0.]
 [1. 0. 1. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 1. 0. 1. 0. 0. 0.]]
[0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0.
 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.]
aucroc, aucpr (0.9788888888888889, 0.969600766232419)
cuda
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cuda
Objective function 461.65 = squared loss an data 284.59 + 0.5*rho*h**2 176.710652 + alpha*h 0.000000 + L2reg 0.19 + L1reg 0.16 ; SHD = 55 ; DAG False
total norm for a microbatch 27.77419000425405 clip 25.00335662397432
total norm for a microbatch 48.47687948584544 clip 29.956400112934162
total norm for a microbatch 57.49674571704751 clip 32.77005670205696
total norm for a microbatch 36.399428134232565 clip 32.13271456104715
total norm for a microbatch 32.68528650466224 clip 34.77561442346309
cuda
Objective function 9.74 = squared loss an data 8.03 + 0.5*rho*h**2 1.056953 + alpha*h 0.000000 + L2reg 0.56 + L1reg 0.08 ; SHD = 35 ; DAG False
Proportion of microbatches that were clipped  0.8081484469544171
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 1.4539279781618575
iteration 1 in outer loop, alpha = 1.4539279781618575, rho = 1.0, h = 1.4539279781618575
cuda
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cuda
Objective function 11.85 = squared loss an data 8.03 + 0.5*rho*h**2 1.056953 + alpha*h 2.113907 + L2reg 0.56 + L1reg 0.08 ; SHD = 35 ; DAG False
total norm for a microbatch 72.18857412641735 clip 2.7688643253295933
total norm for a microbatch 55.68762575145783 clip 42.98034683737883
total norm for a microbatch 77.32211730415511 clip 44.795181460657695
total norm for a microbatch 72.67870454901548 clip 45.17557038818687
total norm for a microbatch 26.518469947640696 clip 45.17557038818687
total norm for a microbatch 52.138962092631814 clip 43.620573431070824
total norm for a microbatch 44.59178766357685 clip 45.8281117160273
total norm for a microbatch 42.327520938438845 clip 44.863547022200734
cuda
Objective function 9.16 = squared loss an data 6.09 + 0.5*rho*h**2 0.584451 + alpha*h 1.571925 + L2reg 0.84 + L1reg 0.08 ; SHD = 27 ; DAG False
Proportion of microbatches that were clipped  0.81007720438846
iteration 1 in inner loop, alpha 1.4539279781618575 rho 1.0 h 1.0811577472366878
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cuda
Objective function 14.42 = squared loss an data 6.09 + 0.5*rho*h**2 5.844510 + alpha*h 1.571925 + L2reg 0.84 + L1reg 0.08 ; SHD = 27 ; DAG False
total norm for a microbatch 115.58773624558005 clip 5.9199640572575865
total norm for a microbatch 54.58679096185441 clip 12.421035186619871
total norm for a microbatch 102.00294398713744 clip 61.390582449195556
total norm for a microbatch 70.4071596892458 clip 61.02912599969783
total norm for a microbatch 68.85042279388858 clip 64.31626212888955
total norm for a microbatch 93.18681103194113 clip 58.85101444418557
total norm for a microbatch 102.51922307181647 clip 57.32209903173742
total norm for a microbatch 85.53502737370451 clip 58.04595685964004
total norm for a microbatch 52.00353211450867 clip 60.8819426016909
total norm for a microbatch 64.45158097163072 clip 59.38587463154343
total norm for a microbatch 47.76750911461356 clip 56.21687371790852
total norm for a microbatch 70.6595674739968 clip 57.34416174591542
cuda
Objective function 9.60 = squared loss an data 6.96 + 0.5*rho*h**2 0.942334 + alpha*h 0.631190 + L2reg 1.00 + L1reg 0.07 ; SHD = 18 ; DAG True
Proportion of microbatches that were clipped  0.8141649899396378
iteration 2 in inner loop, alpha 1.4539279781618575 rho 10.0 h 0.4341277321599737
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cuda
Objective function 18.08 = squared loss an data 6.96 + 0.5*rho*h**2 9.423344 + alpha*h 0.631190 + L2reg 1.00 + L1reg 0.07 ; SHD = 18 ; DAG True
total norm for a microbatch 78.81238429393808 clip 73.30195967681482
total norm for a microbatch 96.34539916853895 clip 69.49260211675843
total norm for a microbatch 41.28716938031153 clip 71.38079748290728
total norm for a microbatch 52.04402265758092 clip 67.13852863128028
total norm for a microbatch 128.34125100931172 clip 67.30705487903926
total norm for a microbatch 77.53795228015095 clip 70.50440176144794
total norm for a microbatch 70.31116116617059 clip 67.30958893068605
total norm for a microbatch 120.80564436215376 clip 67.4795265322537
total norm for a microbatch 77.02436262135396 clip 67.90521106790025
cuda
Objective function 11.25 = squared loss an data 8.92 + 0.5*rho*h**2 0.992256 + alpha*h 0.204819 + L2reg 1.07 + L1reg 0.07 ; SHD = 21 ; DAG True
Proportion of microbatches that were clipped  0.8135662063363119
iteration 3 in inner loop, alpha 1.4539279781618575 rho 100.0 h 0.14087268218704807
iteration 2 in outer loop, alpha = 15.541196196866665, rho = 100.0, h = 0.14087268218704807
cuda
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cuda
Objective function 13.23 = squared loss an data 8.92 + 0.5*rho*h**2 0.992256 + alpha*h 2.189330 + L2reg 1.07 + L1reg 0.07 ; SHD = 21 ; DAG True
total norm for a microbatch 137.73246985328765 clip 6.564687627580317
total norm for a microbatch 83.782921532137 clip 18.164255132124815
total norm for a microbatch 99.19473130313307 clip 49.82458694189299
total norm for a microbatch 70.92402504660801 clip 69.96764263116046
total norm for a microbatch 74.11362427949301 clip 69.96764263116046
total norm for a microbatch 97.05169706677104 clip 66.50520220748005
cuda
Objective function 11.32 = squared loss an data 8.55 + 0.5*rho*h**2 0.305792 + alpha*h 1.215382 + L2reg 1.19 + L1reg 0.07 ; SHD = 14 ; DAG True
Proportion of microbatches that were clipped  0.8141471301535974
iteration 1 in inner loop, alpha 15.541196196866665 rho 100.0 h 0.07820387666466289
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cuda
Objective function 14.08 = squared loss an data 8.55 + 0.5*rho*h**2 3.057923 + alpha*h 1.215382 + L2reg 1.19 + L1reg 0.07 ; SHD = 14 ; DAG True
total norm for a microbatch 90.62504280079409 clip 3.6321249744684736
total norm for a microbatch 97.59220897573432 clip 8.373833671890935
total norm for a microbatch 86.53757956868513 clip 10.839386798130443
total norm for a microbatch 97.36062047675891 clip 78.25140779571463
total norm for a microbatch 122.74215631876936 clip 67.76529060994135
total norm for a microbatch 81.31062601561237 clip 74.0926804389712
total norm for a microbatch 117.66182120449011 clip 74.4201140252366
total norm for a microbatch 64.46971490928627 clip 72.04815079440354
total norm for a microbatch 118.70327177474205 clip 67.54700277331702
total norm for a microbatch 138.37917141193844 clip 74.97174877425196
total norm for a microbatch 102.02022889627588 clip 68.09921295265526
total norm for a microbatch 80.89231518022878 clip 68.09921295265526
total norm for a microbatch 76.03394767339073 clip 70.90958636831402
cuda
Objective function 11.11 = squared loss an data 8.77 + 0.5*rho*h**2 0.507100 + alpha*h 0.494933 + L2reg 1.26 + L1reg 0.08 ; SHD = 13 ; DAG True
Proportion of microbatches that were clipped  0.8171360571201904
iteration 2 in inner loop, alpha 15.541196196866665 rho 1000.0 h 0.03184650079225371
iteration 3 in outer loop, alpha = 47.38769698912037, rho = 1000.0, h = 0.03184650079225371
cuda
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cuda
Objective function 12.13 = squared loss an data 8.77 + 0.5*rho*h**2 0.507100 + alpha*h 1.509132 + L2reg 1.26 + L1reg 0.08 ; SHD = 13 ; DAG True
total norm for a microbatch 53.40248886853678 clip 16.07818570165579
total norm for a microbatch 80.28667210989857 clip 78.09303294264524
total norm for a microbatch 102.84530758520876 clip 71.36432189502302
total norm for a microbatch 85.05019099340099 clip 69.73172101417937
total norm for a microbatch 95.57897463850998 clip 71.52126132430227
total norm for a microbatch 76.1253278780192 clip 67.97807703631264
total norm for a microbatch 115.1146690323518 clip 71.24369191555608
total norm for a microbatch 117.3337364336444 clip 73.02260309044816
total norm for a microbatch 167.4039340299436 clip 69.84909529536067
total norm for a microbatch 49.32775756462312 clip 71.12577673864365
cuda
Objective function 11.31 = squared loss an data 8.82 + 0.5*rho*h**2 0.192226 + alpha*h 0.929151 + L2reg 1.27 + L1reg 0.09 ; SHD = 15 ; DAG True
Proportion of microbatches that were clipped  0.8185727938834023
iteration 1 in inner loop, alpha 47.38769698912037 rho 1000.0 h 0.019607423670493063
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cuda
Objective function 13.04 = squared loss an data 8.82 + 0.5*rho*h**2 1.922255 + alpha*h 0.929151 + L2reg 1.27 + L1reg 0.09 ; SHD = 15 ; DAG True
total norm for a microbatch 142.19218836602818 clip 1.4171834245493617
total norm for a microbatch 107.48530516175379 clip 2.6989633271281956
total norm for a microbatch 99.0221567306693 clip 76.99975483210294
total norm for a microbatch 93.12706852074338 clip 76.05800400348535
total norm for a microbatch 91.6258921552787 clip 73.24834091789005
total norm for a microbatch 108.67210855302824 clip 76.16008253712403
total norm for a microbatch 112.68233032943456 clip 72.44990036467206
total norm for a microbatch 77.23761060674227 clip 70.39988384544522
total norm for a microbatch 135.09750174612927 clip 72.08702703181294
total norm for a microbatch 123.65758832999869 clip 71.37666525575922
total norm for a microbatch 136.89247371447084 clip 71.19800573870164
total norm for a microbatch 68.60506364324344 clip 71.00703172016661
total norm for a microbatch 86.94150244400599 clip 71.75697865874979
cuda
Objective function 11.36 = squared loss an data 8.83 + 0.5*rho*h**2 0.618796 + alpha*h 0.527174 + L2reg 1.29 + L1reg 0.09 ; SHD = 14 ; DAG True
Proportion of microbatches that were clipped  0.8182903533906399
iteration 2 in inner loop, alpha 47.38769698912037 rho 10000.0 h 0.011124710302752305
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cuda
Objective function 16.93 = squared loss an data 8.83 + 0.5*rho*h**2 6.187959 + alpha*h 0.527174 + L2reg 1.29 + L1reg 0.09 ; SHD = 14 ; DAG True
total norm for a microbatch 361.8947103189027 clip 1.840249113357779
total norm for a microbatch 180.22676938149263 clip 2.38210984317952
total norm for a microbatch 142.61259493040853 clip 6.834490206932316
total norm for a microbatch 145.06702229746463 clip 15.686513421710213
total norm for a microbatch 156.06325790936265 clip 31.729833131831846
total norm for a microbatch 162.31079205948484 clip 65.55900525022999
total norm for a microbatch 126.08344185154394 clip 85.77688303304292
total norm for a microbatch 145.0914138859014 clip 113.54134056717069
total norm for a microbatch 151.5974897225989 clip 123.01819391320034
total norm for a microbatch 117.3552384488811 clip 108.57959909758733
total norm for a microbatch 92.47424688281225 clip 83.6622752277132
total norm for a microbatch 120.06234452886329 clip 80.39076634765365
total norm for a microbatch 88.92673090276425 clip 85.74691541525853
total norm for a microbatch 91.56375861501667 clip 83.80742156922575
total norm for a microbatch 152.64755703713348 clip 84.35502526295568
total norm for a microbatch 91.41919294157925 clip 67.05492322646617
total norm for a microbatch 153.41434184494395 clip 68.7374178103852
total norm for a microbatch 87.62476302075217 clip 79.37538493081692
cuda
Objective function 10.74 = squared loss an data 8.68 + 0.5*rho*h**2 0.493738 + alpha*h 0.148912 + L2reg 1.33 + L1reg 0.10 ; SHD = 12 ; DAG True
Proportion of microbatches that were clipped  0.8200977642439298
iteration 3 in inner loop, alpha 47.38769698912037 rho 100000.0 h 0.0031424136663353863
iteration 4 in outer loop, alpha = 361.62906362265903, rho = 100000.0, h = 0.0031424136663353863
cuda
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cuda
Objective function 11.73 = squared loss an data 8.68 + 0.5*rho*h**2 0.493738 + alpha*h 1.136388 + L2reg 1.33 + L1reg 0.10 ; SHD = 12 ; DAG True
total norm for a microbatch 8412.24308647475 clip 1.10161882550675
total norm for a microbatch 480.3946319336891 clip 2.4612922984782855
total norm for a microbatch 189.77539240862365 clip 4.925544827453087
total norm for a microbatch 145.5079813235634 clip 145.20544924969883
total norm for a microbatch 101.6931629064085 clip 87.99610825022442
total norm for a microbatch 82.10839991966769 clip 76.50252507444564
total norm for a microbatch 128.89897657603072 clip 83.94314569123166
total norm for a microbatch 72.04905657254913 clip 78.25217180598911
total norm for a microbatch 77.99002538094093 clip 70.90262141460968
total norm for a microbatch 150.30543720143766 clip 67.82420924171173
total norm for a microbatch 69.38394852049743 clip 76.9091695056265
total norm for a microbatch 80.49050271167782 clip 83.06636229500573
total norm for a microbatch 76.38274527942127 clip 84.54487748893024
total norm for a microbatch 66.32751463113759 clip 85.30483850127474
total norm for a microbatch 131.276858697907 clip 81.68210809099426
cuda
Objective function 10.97 = squared loss an data 8.51 + 0.5*rho*h**2 0.214601 + alpha*h 0.749195 + L2reg 1.39 + L1reg 0.10 ; SHD = 13 ; DAG True
Proportion of microbatches that were clipped  0.8201172973407247
iteration 1 in inner loop, alpha 361.62906362265903 rho 100000.0 h 0.0020717213393997014
iteration 5 in outer loop, alpha = 2433.3504030223603, rho = 1000000.0, h = 0.0020717213393997014
Threshold 0.3
[[0.003 0.004 0.02  0.002 0.369 0.006 0.948 0.009 0.003 0.021]
 [1.023 0.003 0.452 0.013 0.962 0.055 0.569 0.787 0.097 1.064]
 [0.425 0.011 0.005 0.002 0.531 0.011 1.594 0.021 0.004 0.022]
 [1.683 0.391 1.268 0.004 1.504 0.376 1.564 0.851 2.15  2.063]
 [0.026 0.004 0.011 0.003 0.007 0.003 0.307 0.008 0.003 0.006]
 [0.565 0.176 0.502 0.013 1.214 0.006 0.772 0.4   0.258 1.033]
 [0.004 0.003 0.003 0.001 0.019 0.003 0.004 0.009 0.002 0.002]
 [0.937 0.01  0.324 0.009 0.488 0.018 0.549 0.007 0.047 0.153]
 [2.273 0.053 1.428 0.005 1.174 0.037 0.857 0.131 0.008 0.405]
 [0.363 0.006 0.352 0.003 1.273 0.006 1.852 0.026 0.019 0.005]]
[[0.    0.    0.    0.    0.369 0.    0.948 0.    0.    0.   ]
 [1.023 0.    0.452 0.    0.962 0.    0.569 0.787 0.    1.064]
 [0.425 0.    0.    0.    0.531 0.    1.594 0.    0.    0.   ]
 [1.683 0.391 1.268 0.    1.504 0.376 1.564 0.851 2.15  2.063]
 [0.    0.    0.    0.    0.    0.    0.307 0.    0.    0.   ]
 [0.565 0.    0.502 0.    1.214 0.    0.772 0.4   0.    1.033]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.937 0.    0.324 0.    0.488 0.    0.549 0.    0.    0.   ]
 [2.273 0.    1.428 0.    1.174 0.    0.857 0.    0.    0.405]
 [0.363 0.    0.352 0.    1.273 0.    1.852 0.    0.    0.   ]]
{'fdr': 0.325, 'tpr': 0.9, 'fpr': 0.8666666666666667, 'f1': 0.7714285714285714, 'shd': 13, 'npred': 40, 'ntrue': 30}
[4.444e-03 2.009e-02 1.715e-03 3.690e-01 6.305e-03 9.477e-01 8.914e-03
 3.057e-03 2.100e-02 1.023e+00 4.520e-01 1.312e-02 9.620e-01 5.512e-02
 5.694e-01 7.869e-01 9.739e-02 1.064e+00 4.249e-01 1.090e-02 2.415e-03
 5.306e-01 1.093e-02 1.594e+00 2.145e-02 3.562e-03 2.159e-02 1.683e+00
 3.908e-01 1.268e+00 1.504e+00 3.762e-01 1.564e+00 8.507e-01 2.150e+00
 2.063e+00 2.566e-02 3.960e-03 1.125e-02 3.226e-03 2.868e-03 3.073e-01
 8.267e-03 3.272e-03 5.605e-03 5.646e-01 1.760e-01 5.016e-01 1.261e-02
 1.214e+00 7.725e-01 3.996e-01 2.579e-01 1.033e+00 4.239e-03 2.516e-03
 2.947e-03 9.931e-04 1.942e-02 2.950e-03 8.836e-03 2.456e-03 2.366e-03
 9.365e-01 1.009e-02 3.237e-01 8.770e-03 4.884e-01 1.758e-02 5.495e-01
 4.672e-02 1.529e-01 2.273e+00 5.325e-02 1.428e+00 4.836e-03 1.174e+00
 3.683e-02 8.573e-01 1.312e-01 4.054e-01 3.626e-01 5.971e-03 3.518e-01
 3.219e-03 1.273e+00 5.880e-03 1.852e+00 2.583e-02 1.914e-02]
[[0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [1. 0. 1. 0. 1. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [1. 1. 1. 0. 1. 1. 0. 0. 0. 0.]
 [1. 0. 1. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 1. 0. 1. 0. 0. 0.]]
[0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0.
 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.]
aucroc, aucpr (0.9, 0.8520114155984988)
Iterations 2500
Achieves (13.610683049707138, 1e-05)-DP
