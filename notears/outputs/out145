samples  5000  graph  30 120 ER mlp  minibatch size  50  noise  0.6  minibatches per NN training  250 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 2.407192360868244
iteration 1 in outer loop, alpha = 2.407192360868244, rho = 1.0, h = 2.407192360868244
cuda
iteration 1 in inner loop,alpha 2.407192360868244 rho 1.0 h 1.519847643277938
iteration 2 in inner loop,alpha 2.407192360868244 rho 10.0 h 0.6681085661998409
iteration 3 in inner loop,alpha 2.407192360868244 rho 100.0 h 0.2142382096787543
iteration 2 in outer loop, alpha = 23.831013328743673, rho = 100.0, h = 0.2142382096787543
cuda
iteration 1 in inner loop,alpha 23.831013328743673 rho 100.0 h 0.12078187772351612
iteration 2 in inner loop,alpha 23.831013328743673 rho 1000.0 h 0.04372606397762979
iteration 3 in outer loop, alpha = 67.55707730637346, rho = 1000.0, h = 0.04372606397762979
cuda
iteration 1 in inner loop,alpha 67.55707730637346 rho 1000.0 h 0.023239082362103147
iteration 2 in inner loop,alpha 67.55707730637346 rho 10000.0 h 0.007686345269199535
iteration 4 in outer loop, alpha = 144.4205299983688, rho = 10000.0, h = 0.007686345269199535
cuda
iteration 1 in inner loop,alpha 144.4205299983688 rho 10000.0 h 0.004012326571370295
iteration 2 in inner loop,alpha 144.4205299983688 rho 100000.0 h 0.0013267240677272696
iteration 5 in outer loop, alpha = 277.09293677109576, rho = 100000.0, h = 0.0013267240677272696
cuda
iteration 1 in inner loop,alpha 277.09293677109576 rho 100000.0 h 0.0006434116048055216
iteration 6 in outer loop, alpha = 920.5045415766174, rho = 1000000.0, h = 0.0006434116048055216
Threshold 0.3
[[0.001 0.    0.001 1.875 0.005 0.158 0.154 0.    0.    0.    0.    0.091
  0.    0.    0.    0.91  0.    0.    0.643 0.153 0.    0.    0.161 0.
  0.    0.    0.16  0.    0.193 0.   ]
 [0.391 0.002 0.022 0.091 0.201 1.534 0.183 0.    0.995 0.    0.    0.122
  0.    0.    0.    0.827 0.    1.186 0.332 0.577 0.    0.003 0.986 0.001
  0.    0.    0.164 0.    0.206 0.147]
 [0.167 0.036 0.001 0.451 0.01  0.442 0.216 0.002 0.125 0.    0.    0.153
  0.    0.    0.    0.731 0.    0.251 0.053 0.076 0.    0.    0.191 0.
  0.    0.002 0.176 0.    0.221 0.004]
 [0.    0.    0.    0.002 0.001 0.002 0.135 0.    0.    0.    0.    0.
  0.    0.    0.    0.794 0.    0.    0.19  0.535 0.    0.    0.167 0.
  0.    0.    0.    0.    0.162 0.   ]
 [0.079 0.006 0.068 0.209 0.003 0.075 0.332 0.    0.206 0.    0.    0.185
  0.    0.    0.    0.174 0.    0.001 0.646 0.146 0.    0.001 1.409 0.
  0.    0.003 0.081 0.    0.147 0.005]
 [0.001 0.    0.    0.18  0.009 0.002 1.6   0.001 0.001 0.    0.    0.
  0.    0.    0.    0.18  0.    0.    0.137 0.102 0.    0.    0.273 0.
  0.    0.    0.    0.    0.745 0.   ]
 [0.001 0.    0.    0.002 0.    0.    0.003 0.    0.001 0.    0.    0.
  0.    0.    0.    0.953 0.    0.    0.006 0.003 0.    0.    0.    0.
  0.    0.    0.    0.    0.063 0.   ]
 [0.42  0.757 0.109 0.138 2.113 0.175 0.194 0.002 1.37  0.    0.    0.13
  0.    0.    0.    0.506 0.    0.3   0.165 0.675 0.    0.006 0.258 0.001
  0.    0.006 0.141 0.    0.319 0.274]
 [1.205 0.    0.002 0.25  0.002 0.11  0.099 0.    0.003 0.    0.    0.275
  0.    0.    0.    0.072 0.    0.    0.248 0.823 0.    0.    0.116 0.
  0.    0.    0.108 0.    0.107 0.   ]
 [0.311 0.953 0.166 0.229 0.273 0.352 0.211 0.32  1.044 0.001 0.    0.214
  2.237 0.087 0.007 0.29  0.001 0.391 0.23  0.09  0.002 0.476 0.452 0.083
  0.    0.163 0.237 0.001 0.309 1.843]
 [1.648 1.786 0.316 0.164 0.182 0.326 0.303 1.953 0.276 1.269 0.002 0.063
  0.169 0.275 0.004 1.064 0.001 0.28  0.225 0.168 0.017 0.09  0.264 0.02
  0.    0.207 0.092 0.015 0.978 0.421]
 [0.012 0.001 0.003 0.132 0.005 0.133 0.88  0.001 0.004 0.    0.    0.001
  0.    0.    0.    0.31  0.    0.001 0.184 0.118 0.    0.    0.155 0.
  0.    0.    0.885 0.    0.133 0.   ]
 [0.156 1.634 0.104 0.175 2.282 0.358 0.346 1.355 0.853 0.    0.    1.729
  0.001 0.    0.    0.225 0.    0.185 0.64  0.09  0.    2.498 0.541 0.003
  0.    0.03  1.041 0.001 0.34  0.263]
 [0.223 0.185 2.751 1.111 0.125 1.679 0.351 0.125 0.41  0.005 0.002 0.488
  0.298 0.001 0.    0.488 0.    1.738 0.401 0.217 0.    0.126 0.315 2.611
  0.    0.52  0.362 0.007 0.214 2.42 ]
 [0.229 0.83  0.07  0.249 0.251 0.236 0.421 0.281 0.259 0.029 0.019 0.675
  2.492 0.083 0.001 0.252 0.    0.176 0.186 0.166 0.357 0.619 1.018 3.564
  0.007 0.103 0.449 0.002 0.43  0.272]
 [0.    0.    0.    0.    0.001 0.    0.001 0.    0.    0.    0.    0.
  0.    0.    0.    0.004 0.    0.    0.006 0.002 0.    0.    0.    0.
  0.    0.    0.    0.    0.099 0.   ]
 [0.207 0.226 0.146 0.066 0.347 1.06  0.543 0.271 0.544 0.128 0.079 0.129
  1.09  0.108 2.998 0.451 0.001 0.025 0.199 0.068 0.704 1.322 0.197 0.333
  0.001 0.053 0.136 0.004 0.265 0.141]
 [0.169 0.    0.001 0.223 0.14  0.239 0.19  0.    1.085 0.    0.    0.212
  0.    0.    0.    0.184 0.    0.001 0.668 0.231 0.    0.    0.336 0.
  0.    0.    0.672 0.    0.171 0.001]
 [0.001 0.001 0.002 0.002 0.    0.002 0.248 0.    0.001 0.    0.    0.001
  0.    0.    0.    0.164 0.    0.    0.012 0.001 0.    0.    0.013 0.
  0.    0.001 0.002 0.    0.008 0.   ]
 [0.    0.    0.001 0.005 0.001 0.004 0.25  0.001 0.001 0.    0.    0.001
  0.    0.    0.    0.231 0.    0.    0.676 0.003 0.    0.    0.209 0.
  0.    0.    0.    0.    0.371 0.   ]
 [0.191 0.538 0.214 0.392 1.815 1.002 0.266 1.101 0.183 0.082 0.028 0.204
  0.223 3.74  0.001 0.133 0.001 0.215 0.218 0.061 0.001 1.691 0.632 0.075
  0.001 2.437 0.219 0.001 0.213 0.158]
 [0.084 0.175 2.454 1.056 1.49  0.214 0.583 0.225 0.446 0.    0.    0.363
  0.    0.    0.    0.258 0.    2.279 0.279 0.221 0.    0.001 0.505 0.
  0.    0.004 0.28  0.    0.493 2.092]
 [0.001 0.001 0.001 0.002 0.    0.001 1.039 0.    0.002 0.    0.    0.
  0.    0.    0.    0.189 0.    0.    0.485 0.004 0.    0.    0.004 0.
  0.    0.    0.    0.    0.085 0.   ]
 [2.089 0.276 0.127 0.189 0.218 0.148 0.98  0.132 0.512 0.003 0.    2.151
  0.247 0.    0.    0.752 0.    0.087 0.764 0.758 0.    0.257 0.446 0.001
  0.    0.014 1.513 0.005 0.117 0.126]
 [0.229 0.447 0.694 0.128 0.166 0.522 0.573 0.282 0.115 1.142 4.363 0.15
  0.192 2.137 0.04  0.147 0.011 0.392 0.161 0.062 0.033 0.099 0.875 0.108
  0.001 2.779 0.113 0.001 0.264 0.898]
 [0.227 1.707 0.18  0.072 0.186 0.245 0.185 0.116 0.191 0.003 0.004 0.103
  0.018 0.    0.    0.119 0.    0.116 0.333 0.159 0.    0.125 1.325 0.038
  0.    0.003 0.065 0.    0.088 0.143]
 [0.002 0.001 0.001 1.513 0.011 1.762 0.358 0.    0.001 0.    0.    0.001
  0.    0.    0.    0.729 0.    0.    0.766 0.173 0.    0.    1.283 0.
  0.    0.    0.003 0.    0.703 0.   ]
 [2.064 0.356 0.187 0.266 0.121 0.222 0.088 0.1   0.247 0.013 0.006 0.977
  0.005 0.017 0.021 0.188 0.018 0.121 0.164 0.072 0.001 0.052 0.888 0.033
  0.003 2.992 0.137 0.    0.12  0.088]
 [0.004 0.001 0.002 0.013 0.007 0.001 0.036 0.002 0.003 0.    0.    0.001
  0.    0.    0.    0.078 0.    0.    0.124 0.019 0.    0.    0.008 0.
  0.    0.    0.002 0.    0.011 0.001]
 [0.267 0.004 0.234 0.378 0.145 0.242 0.224 0.002 0.553 0.    0.    1.959
  0.    0.    0.    0.189 0.    0.311 0.593 0.196 0.    0.    0.161 0.001
  0.    0.001 0.675 0.    0.106 0.002]]
[[0.    0.    0.    1.875 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.91  0.    0.    0.643 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.391 0.    0.    0.    0.    1.534 0.    0.    0.995 0.    0.    0.
  0.    0.    0.    0.827 0.    1.186 0.332 0.577 0.    0.    0.986 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.451 0.    0.442 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.731 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.794 0.    0.    0.    0.535 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.332 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.646 0.    0.    0.    1.409 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    1.6   0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.745 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.953 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.42  0.757 0.    0.    2.113 0.    0.    0.    1.37  0.    0.    0.
  0.    0.    0.    0.506 0.    0.3   0.    0.675 0.    0.    0.    0.
  0.    0.    0.    0.    0.319 0.   ]
 [1.205 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.823 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.311 0.953 0.    0.    0.    0.352 0.    0.32  1.044 0.    0.    0.
  2.237 0.    0.    0.    0.    0.391 0.    0.    0.    0.476 0.452 0.
  0.    0.    0.    0.    0.309 1.843]
 [1.648 1.786 0.316 0.    0.    0.326 0.303 1.953 0.    1.269 0.    0.
  0.    0.    0.    1.064 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.978 0.421]
 [0.    0.    0.    0.    0.    0.    0.88  0.    0.    0.    0.    0.
  0.    0.    0.    0.31  0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.885 0.    0.    0.   ]
 [0.    1.634 0.    0.    2.282 0.358 0.346 1.355 0.853 0.    0.    1.729
  0.    0.    0.    0.    0.    0.    0.64  0.    0.    2.498 0.541 0.
  0.    0.    1.041 0.    0.34  0.   ]
 [0.    0.    2.751 1.111 0.    1.679 0.351 0.    0.41  0.    0.    0.488
  0.    0.    0.    0.488 0.    1.738 0.401 0.    0.    0.    0.315 2.611
  0.    0.52  0.362 0.    0.    2.42 ]
 [0.    0.83  0.    0.    0.    0.    0.421 0.    0.    0.    0.    0.675
  2.492 0.    0.    0.    0.    0.    0.    0.    0.357 0.619 1.018 3.564
  0.    0.    0.449 0.    0.43  0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.347 1.06  0.543 0.    0.544 0.    0.    0.
  1.09  0.    2.998 0.451 0.    0.    0.    0.    0.704 1.322 0.    0.333
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    1.085 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.668 0.    0.    0.    0.336 0.
  0.    0.    0.672 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.676 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.371 0.   ]
 [0.    0.538 0.    0.392 1.815 1.002 0.    1.101 0.    0.    0.    0.
  0.    3.74  0.    0.    0.    0.    0.    0.    0.    1.691 0.632 0.
  0.    2.437 0.    0.    0.    0.   ]
 [0.    0.    2.454 1.056 1.49  0.    0.583 0.    0.446 0.    0.    0.363
  0.    0.    0.    0.    0.    2.279 0.    0.    0.    0.    0.505 0.
  0.    0.    0.    0.    0.493 2.092]
 [0.    0.    0.    0.    0.    0.    1.039 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.485 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [2.089 0.    0.    0.    0.    0.    0.98  0.    0.512 0.    0.    2.151
  0.    0.    0.    0.752 0.    0.    0.764 0.758 0.    0.    0.446 0.
  0.    0.    1.513 0.    0.    0.   ]
 [0.    0.447 0.694 0.    0.    0.522 0.573 0.    0.    1.142 4.363 0.
  0.    2.137 0.    0.    0.    0.392 0.    0.    0.    0.    0.875 0.
  0.    2.779 0.    0.    0.    0.898]
 [0.    1.707 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.333 0.    0.    0.    1.325 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    1.513 0.    1.762 0.358 0.    0.    0.    0.    0.
  0.    0.    0.    0.729 0.    0.    0.766 0.    0.    0.    1.283 0.
  0.    0.    0.    0.    0.703 0.   ]
 [2.064 0.356 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.977
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.888 0.
  0.    2.992 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.378 0.    0.    0.    0.    0.553 0.    0.    1.959
  0.    0.    0.    0.    0.    0.311 0.593 0.    0.    0.    0.    0.
  0.    0.    0.675 0.    0.    0.   ]]
{'fdr': 0.3235294117647059, 'tpr': 0.9583333333333334, 'fpr': 0.1746031746031746, 'f1': 0.7931034482758621, 'shd': 60, 'npred': 170, 'ntrue': 120}
[2.786e-04 7.501e-04 1.875e+00 4.516e-03 1.583e-01 1.545e-01 2.576e-05
 4.301e-04 2.457e-05 1.546e-05 9.097e-02 1.534e-05 1.437e-04 3.727e-05
 9.098e-01 2.295e-05 1.065e-04 6.429e-01 1.525e-01 7.164e-07 8.594e-05
 1.611e-01 1.831e-04 2.248e-06 8.431e-05 1.598e-01 2.553e-05 1.928e-01
 1.174e-04 3.909e-01 2.214e-02 9.079e-02 2.007e-01 1.534e+00 1.829e-01
 1.852e-04 9.954e-01 8.822e-05 4.917e-05 1.223e-01 2.148e-04 1.655e-04
 9.758e-05 8.270e-01 5.731e-05 1.186e+00 3.320e-01 5.767e-01 1.372e-05
 2.917e-03 9.861e-01 6.722e-04 7.609e-07 4.346e-04 1.640e-01 3.690e-05
 2.062e-01 1.475e-01 1.671e-01 3.597e-02 4.511e-01 1.036e-02 4.421e-01
 2.158e-01 2.412e-03 1.246e-01 3.105e-06 1.861e-05 1.530e-01 2.323e-05
 1.961e-04 4.619e-06 7.315e-01 5.757e-06 2.513e-01 5.341e-02 7.567e-02
 1.744e-05 1.369e-04 1.908e-01 3.876e-04 1.777e-05 2.039e-03 1.764e-01
 8.896e-05 2.214e-01 3.602e-03 1.222e-04 8.790e-05 1.787e-04 1.224e-03
 1.735e-03 1.354e-01 6.648e-05 1.867e-04 9.009e-05 1.551e-05 9.196e-05
 2.991e-05 2.028e-05 2.167e-06 7.944e-01 1.285e-05 3.654e-05 1.902e-01
 5.352e-01 6.559e-06 2.153e-05 1.666e-01 1.826e-05 1.153e-05 2.902e-05
 3.545e-05 1.256e-05 1.621e-01 2.445e-04 7.889e-02 5.502e-03 6.797e-02
 2.092e-01 7.517e-02 3.321e-01 3.121e-04 2.057e-01 2.947e-05 7.729e-05
 1.852e-01 8.995e-05 1.450e-05 1.689e-05 1.738e-01 1.631e-06 1.176e-03
 6.461e-01 1.462e-01 3.536e-05 8.411e-04 1.409e+00 3.153e-04 8.050e-07
 2.506e-03 8.124e-02 1.765e-04 1.474e-01 4.786e-03 7.553e-04 4.058e-04
 7.109e-05 1.797e-01 8.510e-03 1.600e+00 5.029e-04 1.215e-03 9.594e-05
 2.019e-05 5.374e-05 3.044e-05 2.942e-05 7.275e-06 1.803e-01 3.315e-06
 2.136e-04 1.366e-01 1.017e-01 2.818e-06 3.871e-05 2.726e-01 2.682e-05
 1.830e-06 8.092e-05 3.926e-05 5.230e-06 7.454e-01 2.291e-04 5.790e-04
 1.712e-04 2.682e-04 1.739e-03 2.789e-04 3.493e-04 1.289e-04 7.864e-04
 1.784e-05 4.561e-05 6.951e-05 4.878e-05 7.977e-06 1.526e-05 9.530e-01
 1.185e-05 8.863e-05 5.711e-03 3.443e-03 2.006e-06 3.270e-05 4.849e-04
 9.429e-05 4.250e-06 4.812e-05 7.257e-05 4.106e-06 6.281e-02 1.159e-05
 4.198e-01 7.571e-01 1.089e-01 1.385e-01 2.113e+00 1.749e-01 1.941e-01
 1.370e+00 3.537e-05 7.572e-05 1.301e-01 3.267e-04 1.312e-04 1.732e-05
 5.059e-01 1.266e-04 3.003e-01 1.649e-01 6.748e-01 1.444e-05 6.327e-03
 2.577e-01 1.380e-03 6.070e-06 6.347e-03 1.408e-01 4.672e-05 3.188e-01
 2.737e-01 1.205e+00 1.634e-04 1.662e-03 2.496e-01 1.847e-03 1.097e-01
 9.950e-02 8.607e-05 4.782e-05 1.269e-05 2.749e-01 2.011e-05 2.260e-05
 1.047e-05 7.223e-02 1.191e-05 1.557e-04 2.476e-01 8.226e-01 3.435e-06
 5.765e-05 1.156e-01 2.045e-04 2.042e-07 2.810e-04 1.079e-01 1.557e-05
 1.069e-01 1.902e-04 3.110e-01 9.533e-01 1.658e-01 2.290e-01 2.725e-01
 3.520e-01 2.110e-01 3.201e-01 1.044e+00 5.967e-05 2.138e-01 2.237e+00
 8.748e-02 6.556e-03 2.899e-01 9.171e-04 3.912e-01 2.296e-01 9.050e-02
 1.771e-03 4.758e-01 4.519e-01 8.313e-02 3.034e-05 1.628e-01 2.373e-01
 1.115e-03 3.086e-01 1.843e+00 1.648e+00 1.786e+00 3.160e-01 1.636e-01
 1.821e-01 3.256e-01 3.034e-01 1.953e+00 2.758e-01 1.269e+00 6.258e-02
 1.688e-01 2.745e-01 4.476e-03 1.064e+00 9.337e-04 2.797e-01 2.252e-01
 1.676e-01 1.669e-02 9.017e-02 2.641e-01 2.011e-02 3.087e-04 2.074e-01
 9.245e-02 1.504e-02 9.781e-01 4.209e-01 1.230e-02 1.413e-03 3.402e-03
 1.320e-01 5.404e-03 1.332e-01 8.804e-01 6.519e-04 4.093e-03 2.863e-05
 2.081e-05 5.322e-05 9.621e-06 3.767e-06 3.103e-01 1.312e-05 8.532e-04
 1.838e-01 1.178e-01 1.121e-05 3.050e-05 1.548e-01 5.049e-05 4.753e-06
 3.053e-04 8.851e-01 5.979e-05 1.331e-01 2.127e-04 1.562e-01 1.634e+00
 1.037e-01 1.749e-01 2.282e+00 3.582e-01 3.459e-01 1.355e+00 8.533e-01
 1.674e-04 3.389e-05 1.729e+00 1.596e-04 7.504e-05 2.251e-01 2.339e-05
 1.847e-01 6.398e-01 8.969e-02 3.256e-05 2.498e+00 5.408e-01 2.995e-03
 8.006e-06 3.032e-02 1.041e+00 1.063e-03 3.402e-01 2.633e-01 2.229e-01
 1.855e-01 2.751e+00 1.111e+00 1.255e-01 1.679e+00 3.513e-01 1.247e-01
 4.101e-01 5.162e-03 2.076e-03 4.884e-01 2.978e-01 7.937e-05 4.881e-01
 1.668e-04 1.738e+00 4.006e-01 2.167e-01 7.844e-05 1.259e-01 3.150e-01
 2.611e+00 2.603e-04 5.204e-01 3.619e-01 6.691e-03 2.142e-01 2.420e+00
 2.288e-01 8.304e-01 6.986e-02 2.491e-01 2.506e-01 2.359e-01 4.210e-01
 2.807e-01 2.595e-01 2.858e-02 1.924e-02 6.748e-01 2.492e+00 8.251e-02
 2.520e-01 2.552e-04 1.759e-01 1.857e-01 1.659e-01 3.569e-01 6.191e-01
 1.018e+00 3.564e+00 6.529e-03 1.027e-01 4.487e-01 2.406e-03 4.304e-01
 2.723e-01 9.380e-05 4.584e-04 4.321e-04 2.993e-04 5.478e-04 1.923e-04
 1.438e-03 7.667e-05 2.044e-04 9.163e-05 4.158e-05 9.645e-05 1.928e-05
 4.401e-05 5.626e-06 9.530e-06 1.479e-04 6.169e-03 1.520e-03 3.497e-06
 2.916e-05 2.759e-04 3.749e-05 3.003e-06 1.580e-04 4.404e-05 1.348e-05
 9.893e-02 3.744e-05 2.070e-01 2.264e-01 1.464e-01 6.646e-02 3.466e-01
 1.060e+00 5.435e-01 2.713e-01 5.436e-01 1.277e-01 7.853e-02 1.286e-01
 1.090e+00 1.084e-01 2.998e+00 4.509e-01 2.536e-02 1.987e-01 6.837e-02
 7.040e-01 1.322e+00 1.968e-01 3.331e-01 6.456e-04 5.284e-02 1.356e-01
 3.977e-03 2.647e-01 1.410e-01 1.693e-01 4.472e-04 6.506e-04 2.229e-01
 1.403e-01 2.386e-01 1.896e-01 6.395e-05 1.085e+00 5.608e-06 1.544e-05
 2.123e-01 8.094e-06 1.146e-04 4.997e-06 1.842e-01 3.635e-07 6.684e-01
 2.306e-01 2.022e-05 1.226e-04 3.358e-01 1.036e-04 6.963e-06 2.734e-04
 6.719e-01 9.946e-06 1.708e-01 1.289e-03 1.369e-03 7.715e-04 2.164e-03
 1.995e-03 3.046e-04 2.436e-03 2.482e-01 1.562e-04 5.218e-04 3.793e-05
 2.329e-05 5.476e-04 6.652e-05 7.770e-05 7.924e-05 1.641e-01 6.209e-05
 3.961e-04 9.641e-04 5.470e-06 8.878e-05 1.344e-02 3.695e-04 1.199e-06
 6.107e-04 1.805e-03 2.194e-05 8.269e-03 1.538e-04 4.193e-04 1.911e-04
 9.684e-04 4.605e-03 1.355e-03 4.076e-03 2.497e-01 6.186e-04 6.857e-04
 1.395e-05 1.723e-05 7.502e-04 3.665e-05 7.217e-05 7.740e-05 2.313e-01
 3.837e-05 2.415e-04 6.756e-01 1.529e-05 1.842e-05 2.092e-01 2.636e-04
 2.123e-05 1.278e-04 2.811e-04 2.869e-05 3.713e-01 2.042e-04 1.910e-01
 5.375e-01 2.139e-01 3.923e-01 1.815e+00 1.002e+00 2.658e-01 1.101e+00
 1.833e-01 8.162e-02 2.772e-02 2.038e-01 2.226e-01 3.740e+00 9.191e-04
 1.332e-01 6.602e-04 2.154e-01 2.180e-01 6.112e-02 1.691e+00 6.324e-01
 7.502e-02 1.272e-03 2.437e+00 2.191e-01 1.130e-03 2.125e-01 1.579e-01
 8.408e-02 1.753e-01 2.454e+00 1.056e+00 1.490e+00 2.145e-01 5.833e-01
 2.246e-01 4.455e-01 1.406e-05 7.775e-05 3.627e-01 9.352e-05 2.146e-05
 1.069e-04 2.582e-01 6.215e-06 2.279e+00 2.788e-01 2.207e-01 6.298e-05
 5.046e-01 2.715e-04 1.456e-06 4.047e-03 2.800e-01 1.529e-04 4.934e-01
 2.092e+00 1.145e-03 1.200e-03 9.259e-04 2.357e-03 3.765e-04 9.432e-04
 1.039e+00 5.762e-05 1.982e-03 1.631e-05 2.635e-05 3.411e-04 2.680e-05
 1.163e-04 4.207e-06 1.890e-01 2.961e-06 2.419e-04 4.846e-01 4.253e-03
 3.059e-06 4.622e-05 1.892e-05 8.130e-06 1.977e-04 4.669e-04 1.740e-05
 8.543e-02 2.139e-04 2.089e+00 2.764e-01 1.274e-01 1.890e-01 2.180e-01
 1.485e-01 9.802e-01 1.320e-01 5.124e-01 3.231e-03 6.039e-05 2.151e+00
 2.473e-01 8.272e-05 2.164e-04 7.516e-01 6.223e-05 8.734e-02 7.635e-01
 7.583e-01 5.849e-06 2.572e-01 4.457e-01 1.976e-05 1.406e-02 1.513e+00
 4.770e-03 1.175e-01 1.257e-01 2.288e-01 4.465e-01 6.942e-01 1.282e-01
 1.657e-01 5.223e-01 5.730e-01 2.820e-01 1.148e-01 1.142e+00 4.363e+00
 1.497e-01 1.918e-01 2.137e+00 3.995e-02 1.469e-01 1.066e-02 3.917e-01
 1.614e-01 6.161e-02 3.341e-02 9.855e-02 8.749e-01 1.084e-01 2.779e+00
 1.125e-01 5.611e-04 2.636e-01 8.980e-01 2.270e-01 1.707e+00 1.801e-01
 7.188e-02 1.857e-01 2.451e-01 1.855e-01 1.158e-01 1.911e-01 3.444e-03
 4.240e-03 1.034e-01 1.773e-02 3.488e-04 8.439e-05 1.191e-01 7.709e-05
 1.160e-01 3.333e-01 1.594e-01 3.732e-05 1.255e-01 1.325e+00 3.753e-02
 3.955e-04 6.487e-02 8.608e-05 8.779e-02 1.426e-01 1.777e-03 5.774e-04
 8.646e-04 1.513e+00 1.089e-02 1.762e+00 3.577e-01 4.549e-04 9.862e-04
 2.254e-05 2.408e-04 5.427e-04 4.834e-05 2.045e-05 5.774e-06 7.292e-01
 7.102e-06 1.062e-04 7.658e-01 1.728e-01 3.763e-06 5.692e-05 1.283e+00
 4.760e-05 1.949e-06 2.932e-04 1.223e-05 7.030e-01 1.408e-04 2.064e+00
 3.560e-01 1.873e-01 2.660e-01 1.214e-01 2.218e-01 8.768e-02 9.962e-02
 2.469e-01 1.294e-02 6.369e-03 9.770e-01 5.097e-03 1.670e-02 2.120e-02
 1.879e-01 1.826e-02 1.213e-01 1.639e-01 7.207e-02 5.078e-04 5.165e-02
 8.877e-01 3.303e-02 3.343e-03 2.992e+00 1.365e-01 1.198e-01 8.824e-02
 4.142e-03 9.984e-04 1.918e-03 1.296e-02 6.749e-03 1.456e-03 3.569e-02
 2.198e-03 3.107e-03 2.413e-05 2.062e-04 8.865e-04 7.693e-05 5.257e-05
 1.330e-04 7.812e-02 6.432e-05 4.469e-04 1.242e-01 1.902e-02 1.907e-05
 1.939e-04 8.436e-03 9.588e-05 9.252e-05 1.770e-04 1.678e-03 2.040e-05
 7.864e-04 2.671e-01 4.319e-03 2.338e-01 3.781e-01 1.446e-01 2.415e-01
 2.244e-01 1.963e-03 5.530e-01 3.140e-05 2.810e-05 1.959e+00 8.699e-06
 1.078e-04 1.817e-06 1.889e-01 5.894e-06 3.112e-01 5.932e-01 1.961e-01
 1.996e-05 1.082e-04 1.615e-01 7.017e-04 2.401e-05 7.815e-04 6.752e-01
 5.579e-05 1.061e-01]
[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 1.]
 [1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 0. 1.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.
  0. 1. 1. 0. 0. 0.]
 [0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
  0. 1. 0. 0. 0. 1.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1.
 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0.]
aucroc, aucpr (0.9848222222222223, 0.9556282359883823)
cuda
9630
cuda
Objective function 1220.30 = squared loss an data 964.29 + 0.5*rho*h**2 254.631624 + alpha*h 0.000000 + L2reg 0.55 + L1reg 0.82 ; SHD = 397 ; DAG False
||w||^2 114074607.82529438
exp ma of ||w||^2 44226178872.47624
||w|| 10680.571512109938
exp ma of ||w|| 78408.9104042805
||w||^2 0.2283752695334763
exp ma of ||w||^2 0.2165401581298796
||w|| 0.4778862516681939
exp ma of ||w|| 0.4517486362153652
||w||^2 0.4659858675607844
exp ma of ||w||^2 0.34662450693312835
||w|| 0.6826315752737961
exp ma of ||w|| 0.5660485541783562
||w||^2 1.0169924605062477
exp ma of ||w||^2 0.42973604043980357
||w|| 1.0084604407244975
exp ma of ||w|| 0.6315831307025048
||w||^2 0.1806925129325856
exp ma of ||w||^2 0.4379574668082226
||w|| 0.42507941955896383
exp ma of ||w|| 0.6386146351401344
||w||^2 0.7640916578261737
exp ma of ||w||^2 0.48582988755156525
||w|| 0.8741233653359083
exp ma of ||w|| 0.6710054098326141
||w||^2 1.245087769255182
exp ma of ||w||^2 0.5110326418143668
||w|| 1.1158350098716128
exp ma of ||w|| 0.688689433512254
||w||^2 0.5035838998262383
exp ma of ||w||^2 0.6199117843049802
||w|| 0.7096364561000501
exp ma of ||w|| 0.7540246693787687
||w||^2 1.3440475430845282
exp ma of ||w||^2 0.914822827451448
||w|| 1.1593306444170828
exp ma of ||w|| 0.9228958732496241
||w||^2 0.7697546733305667
exp ma of ||w||^2 0.9836227113058509
||w|| 0.8773566397597767
exp ma of ||w|| 0.9434637461261735
||w||^2 2.102277107137168
exp ma of ||w||^2 1.1380583777069493
||w|| 1.4499231383549847
exp ma of ||w|| 1.028978702714892
||w||^2 1.011496673025399
exp ma of ||w||^2 1.1109793059287898
||w|| 1.0057319091216104
exp ma of ||w|| 1.0173059072583805
cuda
Objective function 95.89 = squared loss an data 76.44 + 0.5*rho*h**2 17.055674 + alpha*h 0.000000 + L2reg 1.79 + L1reg 0.61 ; SHD = 233 ; DAG False
Proportion of microbatches that were clipped  0.7721621185209107
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 5.840492041132492
iteration 1 in outer loop, alpha = 5.840492041132492, rho = 1.0, h = 5.840492041132492
cuda
9630
cuda
Objective function 130.00 = squared loss an data 76.44 + 0.5*rho*h**2 17.055674 + alpha*h 34.111347 + L2reg 1.79 + L1reg 0.61 ; SHD = 233 ; DAG False
||w||^2 11823503.445729109
exp ma of ||w||^2 3083249144.820116
||w|| 3438.5321644168325
exp ma of ||w|| 20516.17027130461
||w||^2 4.411744520901462
exp ma of ||w||^2 5724490.044836155
||w|| 2.100415321049973
exp ma of ||w|| 56.731822410645606
||w||^2 0.9891606260557493
exp ma of ||w||^2 1933474.9282042638
||w|| 0.9945655463848269
exp ma of ||w|| 20.537667185932477
||w||^2 1.0918059800677642
exp ma of ||w||^2 2.1951338170108046
||w|| 1.0448952005190588
exp ma of ||w|| 1.4257628066213655
||w||^2 0.8128133097359265
exp ma of ||w||^2 1.8855510912412323
||w|| 0.9015615950870615
exp ma of ||w|| 1.3209884208977982
||w||^2 0.9381873301180781
exp ma of ||w||^2 1.799397245683432
||w|| 0.9686007072669719
exp ma of ||w|| 1.2884010261599164
||w||^2 2.5981298146434764
exp ma of ||w||^2 1.7819549580308198
||w|| 1.6118715254769769
exp ma of ||w|| 1.2906288098377983
||w||^2 1.1412671121453128
exp ma of ||w||^2 2.022483654969381
||w|| 1.0683010400375508
exp ma of ||w|| 1.368585810067875
cuda
Objective function 90.76 = squared loss an data 59.83 + 0.5*rho*h**2 6.670495 + alpha*h 21.332584 + L2reg 2.36 + L1reg 0.56 ; SHD = 187 ; DAG False
Proportion of microbatches that were clipped  0.773145509323345
iteration 1 in inner loop, alpha 5.840492041132492 rho 1.0 h 3.6525320517929245
9630
cuda
Objective function 150.79 = squared loss an data 59.83 + 0.5*rho*h**2 66.704952 + alpha*h 21.332584 + L2reg 2.36 + L1reg 0.56 ; SHD = 187 ; DAG False
||w||^2 1935969.251533358
exp ma of ||w||^2 3297650159.382212
||w|| 1391.3911209769012
exp ma of ||w|| 17316.999546771247
||w||^2 2.0384424062437385
exp ma of ||w||^2 3.8389927569675715
||w|| 1.4277403147084342
exp ma of ||w|| 1.8661919800017075
||w||^2 4.479648631096841
exp ma of ||w||^2 3.6773308025757774
||w|| 2.1165180441226674
exp ma of ||w|| 1.8606501980104215
||w||^2 2.9267365270135803
exp ma of ||w||^2 3.5455599880238537
||w|| 1.7107707406352204
exp ma of ||w|| 1.8289510000080036
||w||^2 1.2755785995938782
exp ma of ||w||^2 3.6480046676303814
||w|| 1.1294151582097163
exp ma of ||w|| 1.8440749918498236
||w||^2 3.372497586649768
exp ma of ||w||^2 3.4797673542054732
||w|| 1.8364361101464346
exp ma of ||w|| 1.7771975548368466
||w||^2 4.119548892377501
exp ma of ||w||^2 3.4556578252586307
||w|| 2.0296671875895074
exp ma of ||w|| 1.797552800388525
||w||^2 4.088836994037844
exp ma of ||w||^2 3.5682060789473597
||w|| 2.0220872864537385
exp ma of ||w|| 1.8346650607800545
||w||^2 1.8965946671537812
exp ma of ||w||^2 3.652246560184634
||w|| 1.3771690771847083
exp ma of ||w|| 1.8545303707760799
||w||^2 12.395558709145936
exp ma of ||w||^2 3.881855463578849
||w|| 3.5207326949295563
exp ma of ||w|| 1.8933905928076082
||w||^2 4.0156240171376565
exp ma of ||w||^2 4.077892314472274
||w|| 2.0039021974980855
exp ma of ||w|| 1.959949484603611
||w||^2 2.898619082625161
exp ma of ||w||^2 4.0277478824074535
||w|| 1.702533137012364
exp ma of ||w|| 1.939369420364394
||w||^2 9.098699282213255
exp ma of ||w||^2 3.758502269837423
||w|| 3.0164050262213222
exp ma of ||w|| 1.8668133647961622
cuda
Objective function 92.89 = squared loss an data 63.74 + 0.5*rho*h**2 15.662743 + alpha*h 10.337091 + L2reg 2.65 + L1reg 0.50 ; SHD = 161 ; DAG False
Proportion of microbatches that were clipped  0.7785817655571635
iteration 2 in inner loop, alpha 5.840492041132492 rho 10.0 h 1.769900726139376
9630
cuda
Objective function 233.85 = squared loss an data 63.74 + 0.5*rho*h**2 156.627429 + alpha*h 10.337091 + L2reg 2.65 + L1reg 0.50 ; SHD = 161 ; DAG False
||w||^2 1648279941113.4333
exp ma of ||w||^2 600935085222.1869
||w|| 1283853.551271886
exp ma of ||w|| 407378.3800356994
||w||^2 280.1729996882434
exp ma of ||w||^2 94484439.98288532
||w|| 16.73836908686875
exp ma of ||w|| 392.3596009492708
||w||^2 253.51229606830725
exp ma of ||w||^2 92604203.30750878
||w|| 15.922069465628745
exp ma of ||w|| 384.8173413250166
||w||^2 25.581436075489684
exp ma of ||w||^2 360801.85670657473
||w|| 5.057809414706102
exp ma of ||w|| 4.278520186939151
||w||^2 4.160591914740366
exp ma of ||w||^2 18059.464690258377
||w|| 2.039752905314849
exp ma of ||w|| 2.565250434528658
||w||^2 6.211778326624538
exp ma of ||w||^2 14.22758406065145
||w|| 2.492343942280948
exp ma of ||w|| 2.3490158286265412
||w||^2 8.083499242500285
exp ma of ||w||^2 5.366625944995017
||w|| 2.8431495286917787
exp ma of ||w|| 2.2360015552488086
||w||^2 5.914556761147939
exp ma of ||w||^2 5.572957986955467
||w|| 2.431986176183561
exp ma of ||w|| 2.283151782231991
||w||^2 2.092872836978596
exp ma of ||w||^2 5.223218809193282
||w|| 1.446676479721225
exp ma of ||w|| 2.2145232746056247
||w||^2 4.990368341026594
exp ma of ||w||^2 5.497668106234632
||w|| 2.2339132348922135
exp ma of ||w|| 2.269030949954677
||w||^2 5.5746179934507
exp ma of ||w||^2 5.435656293903113
||w|| 2.3610628948528034
exp ma of ||w|| 2.258831628917485
||w||^2 6.307170107981071
exp ma of ||w||^2 4.731560645607278
||w|| 2.5114079931347417
exp ma of ||w|| 2.1166225830090926
||w||^2 2.6736316375963574
exp ma of ||w||^2 4.687933897137411
||w|| 1.6351243492763348
exp ma of ||w|| 2.097381751760758
||w||^2 11.231061323687518
exp ma of ||w||^2 5.130636680045723
||w|| 3.351277565897447
exp ma of ||w|| 2.1971193402300835
||w||^2 1.881020285382
exp ma of ||w||^2 4.958558673443096
||w|| 1.371502929410652
exp ma of ||w|| 2.139971116289863
||w||^2 3.483062389848748
exp ma of ||w||^2 4.881896045783021
||w|| 1.8662964367561623
exp ma of ||w|| 2.147832705978786
||w||^2 1.7422935494373362
exp ma of ||w||^2 5.157599424587983
||w|| 1.319959677201291
exp ma of ||w|| 2.1837014895608338
cuda
Objective function 97.53 = squared loss an data 67.65 + 0.5*rho*h**2 22.668970 + alpha*h 3.932605 + L2reg 2.84 + L1reg 0.44 ; SHD = 150 ; DAG True
Proportion of microbatches that were clipped  0.7786172719148591
iteration 3 in inner loop, alpha 5.840492041132492 rho 100.0 h 0.6733345376925826
iteration 2 in outer loop, alpha = 73.17394581039075, rho = 100.0, h = 0.6733345376925826
cuda
9630
cuda
Objective function 142.86 = squared loss an data 67.65 + 0.5*rho*h**2 22.668970 + alpha*h 49.270545 + L2reg 2.84 + L1reg 0.44 ; SHD = 150 ; DAG True
||w||^2 95521225914.9396
exp ma of ||w||^2 559603200453.9604
||w|| 309065.083623077
exp ma of ||w|| 624955.8141809127
||w||^2 2068929832.1121035
exp ma of ||w||^2 36146762515.91106
||w|| 45485.49034705577
exp ma of ||w|| 95849.52098320883
||w||^2 7695162.034681262
exp ma of ||w||^2 7225133258.727651
||w|| 2774.015507289255
exp ma of ||w|| 24534.38641693702
||w||^2 17.862607419227068
exp ma of ||w||^2 13122540.023063844
||w|| 4.2264177998900045
exp ma of ||w|| 64.2912450476232
||w||^2 2.766088176226889
exp ma of ||w||^2 1420.7028898584047
||w|| 1.6631560889546384
exp ma of ||w|| 2.529216927336178
v before min max tensor([[-1004.828,  -241.817,    70.063,  ...,  -133.570,  -502.273,
          -188.000],
        [ -743.119, -1167.488,  1110.540,  ...,  -484.686,  -916.168,
          -383.568],
        [  -49.789,  -574.909,  -759.693,  ...,  -847.875,  -517.054,
          -406.094],
        ...,
        [ -635.580,   524.510,  -973.666,  ...,  -489.391,  -594.819,
         -1032.728],
        [ -225.532,  -755.533,  -246.813,  ...,  -678.522,  -693.656,
            25.167],
        [ -335.241, -1038.674,  -994.476,  ...,  -338.701,  1424.246,
          -437.270]], device='cuda:0')
v tensor([[1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         1.000e-12]], device='cuda:0')
v before min max tensor([ 6.926e+02, -9.158e+02, -4.601e+02, -5.899e+02,  1.010e+02, -1.212e+01,
        -8.619e+02,  3.925e+01,  5.728e+02, -1.191e+03, -8.099e+02, -8.645e+02,
        -8.418e+02,  1.974e+02,  7.368e+02, -8.796e+02,  7.651e+02, -6.665e+02,
        -6.807e+02, -7.699e+02,  1.336e+02, -8.266e+02,  1.111e+03,  6.188e+02,
        -7.145e+02, -2.998e+02,  1.010e+03, -4.443e+02,  2.092e+03, -7.250e+01,
        -5.342e+02,  3.338e+03,  1.107e+03, -6.251e+02, -5.642e+02, -9.975e+02,
         8.908e+02, -4.692e+02, -3.391e+02, -8.230e+02, -4.587e+02,  4.646e+02,
        -2.337e+02, -3.514e+02, -3.319e+02, -6.925e+02, -6.328e+02, -2.392e+02,
        -5.663e+02, -6.333e+02,  7.930e+02,  3.524e+03, -6.293e+02, -5.991e+02,
        -4.382e+02, -6.110e+02, -9.940e+02,  2.001e+02,  2.909e+03, -2.733e+02,
        -5.912e+02,  1.853e+02, -7.117e+02, -9.762e+02, -1.699e+02, -2.124e+02,
        -5.639e+02,  2.817e+03, -4.951e+00, -5.195e+02, -4.377e+02, -1.139e+02,
        -6.605e+02, -3.165e+02,  5.057e+02, -6.560e+02, -8.387e+01, -1.042e+03,
        -1.592e+02,  1.790e+03, -4.883e+02, -7.672e+02, -5.138e+02, -6.240e+02,
        -7.914e+02, -7.888e+02,  2.854e+02,  1.045e+03,  1.252e+03, -7.075e+02,
        -8.042e+02, -7.146e+02, -8.521e+02, -7.573e+02,  8.802e+02, -7.160e+02,
        -6.391e+02, -5.198e+02, -4.944e+01, -8.134e+02, -2.008e+02, -8.212e+02,
         1.715e+03, -8.465e+02, -1.106e+03, -8.137e+02, -6.735e+02, -2.969e+02,
        -8.367e+02, -6.222e+02, -8.414e+02, -2.632e+02,  2.920e+02, -8.245e+02,
        -6.875e+02,  4.956e+02, -8.204e+02,  3.459e+03, -6.942e+02, -9.657e+02,
        -5.272e+02, -4.246e+02, -2.459e+02, -6.897e+01, -8.197e+02, -7.152e+02,
        -4.987e+02, -5.217e+02, -7.414e+02, -1.915e+02,  1.726e+03, -2.109e+02,
         2.288e+02, -5.466e+01,  6.756e+02, -6.626e+02, -9.704e+02,  4.467e+01,
         3.678e+02,  1.462e+03, -7.569e+02, -5.650e+02,  2.469e+03,  2.366e+03,
         4.258e+02, -5.475e+01, -7.957e+02,  6.675e+02, -5.740e+02, -7.952e+02,
        -2.729e+02, -5.892e+02, -8.345e+02, -5.409e+02,  8.817e+01,  2.224e+02,
        -4.502e+02, -6.682e+02,  1.318e+03,  6.733e+02, -4.785e+02, -7.966e+02,
        -1.107e+02, -3.839e+02, -6.439e+02, -8.735e+02, -8.744e+02, -1.132e+03,
        -4.442e+02,  1.673e+03, -7.092e+02,  4.176e+02,  2.559e+03, -1.012e+03,
        -5.524e+02, -8.411e+02,  1.897e+02, -3.155e+02, -7.182e+02, -5.752e+02,
        -6.226e+02,  4.911e+02, -4.879e+02, -4.012e+02, -2.767e+02,  8.176e+02,
        -4.904e+02,  7.411e+02, -8.522e+02, -7.628e+02,  4.260e+02,  6.499e+02,
         2.625e+03, -6.481e+02, -6.958e+02, -3.663e+02, -1.104e+03,  3.534e+02,
        -9.995e+02, -5.827e+02, -6.302e+02,  9.143e+02, -1.100e+03, -6.030e+02,
        -4.913e+02, -8.056e+02, -1.935e+02,  1.656e+02, -8.810e+02, -7.430e+02,
         3.331e+01, -2.565e+02, -9.564e+02, -6.150e+02, -6.578e+02, -7.160e+02,
        -5.674e+02, -1.906e+02, -8.084e+02,  1.326e+02, -9.433e+01, -8.185e+02,
        -9.425e+02,  4.707e+02, -9.483e+02, -6.543e+02,  3.881e+02, -7.160e+02,
        -5.023e+01, -3.607e+02,  1.325e+03, -6.984e+02, -5.320e+02,  7.966e+01,
        -1.970e+02,  2.681e+02, -5.448e+02, -7.770e+02,  2.327e+03, -1.112e+02,
        -8.824e+02,  9.180e+02, -9.277e+02, -4.209e+02, -5.996e+02, -5.737e+02,
        -8.957e+02, -5.323e+01, -4.221e+02, -4.859e+02, -4.632e+02, -6.845e+02,
        -4.560e+02,  2.601e+03,  2.302e+02,  9.725e+01, -9.643e+02, -6.909e+02,
         6.033e+01, -7.193e+02, -8.503e+02, -6.909e+02, -1.120e+03, -9.378e+02,
        -8.962e+02, -7.145e+02,  3.338e+02, -5.170e+02, -7.126e+02, -8.695e+02,
        -4.218e+02, -8.212e+02,  3.332e+03, -6.356e+02, -8.187e+02, -6.450e+02,
        -8.881e+02, -7.284e+02,  4.395e+02,  7.688e+02,  8.781e+02, -8.664e+02,
        -7.928e+02, -3.312e+02, -5.199e+02, -9.417e+02, -4.473e+02,  5.408e+03,
         3.117e+02, -5.843e+02,  9.642e+02, -5.891e+02, -9.095e+01, -5.391e+02,
        -8.994e+02,  4.808e+02, -5.709e+02, -8.331e+02, -2.362e+02, -6.750e+02],
       device='cuda:0')
v tensor([1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-4.149e+02],
         [-8.703e+02],
         [ 8.699e+02],
         [-8.546e+02],
         [-8.169e+02],
         [-3.881e+02],
         [ 3.649e+02],
         [ 9.536e+02],
         [-6.280e+02],
         [-2.119e+02]],

        [[ 1.924e+03],
         [-5.688e+02],
         [ 2.020e+02],
         [-1.050e+03],
         [ 4.552e+01],
         [-6.396e+02],
         [ 8.932e+02],
         [-1.019e+03],
         [-1.499e+02],
         [-8.878e+00]],

        [[ 4.981e+02],
         [-4.049e+01],
         [-1.029e+03],
         [-3.840e+02],
         [ 1.525e+03],
         [ 9.780e+02],
         [-7.041e+02],
         [-8.317e+02],
         [-3.940e+02],
         [ 1.922e+03]],

        [[-4.278e+02],
         [-2.758e+02],
         [ 3.681e+02],
         [-7.062e+02],
         [-1.206e+02],
         [-6.732e+02],
         [-3.377e+02],
         [ 1.142e+03],
         [-7.164e+02],
         [-6.287e+02]],

        [[-1.544e+02],
         [-1.899e+02],
         [ 1.717e+03],
         [-7.296e+02],
         [ 4.487e+03],
         [-6.240e+02],
         [-8.322e+02],
         [ 2.770e+03],
         [ 2.559e+01],
         [ 3.630e+03]],

        [[-4.241e+02],
         [ 1.396e+03],
         [-7.129e+02],
         [-5.215e+02],
         [-3.303e+02],
         [ 4.421e+02],
         [-8.772e+02],
         [-1.013e+03],
         [ 1.742e+02],
         [-6.114e+02]],

        [[-9.561e+02],
         [-4.895e+02],
         [-4.749e+02],
         [-6.755e+02],
         [-6.662e+02],
         [ 4.361e+00],
         [-9.842e+02],
         [-7.149e+02],
         [-4.069e+02],
         [-2.261e+02]],

        [[-8.992e+02],
         [-8.032e+02],
         [-9.319e+02],
         [-1.140e+03],
         [ 2.288e+03],
         [-9.802e+02],
         [-8.847e+02],
         [ 1.765e+02],
         [-9.459e+02],
         [-1.026e+03]],

        [[-8.191e+02],
         [ 3.085e+02],
         [ 4.358e+02],
         [-9.814e+02],
         [ 1.368e+03],
         [ 1.071e+03],
         [-6.049e+02],
         [-5.667e+02],
         [-8.260e+02],
         [-3.742e+02]],

        [[-7.812e+02],
         [-5.706e+02],
         [-6.621e+02],
         [-4.276e+02],
         [-7.598e+02],
         [ 4.038e+02],
         [-9.259e+02],
         [-1.340e+02],
         [-4.917e+02],
         [-9.206e+02]],

        [[-8.828e+02],
         [-1.774e+02],
         [-6.955e+02],
         [-4.917e+02],
         [-7.885e+02],
         [ 7.832e+02],
         [-9.044e+02],
         [-6.889e+02],
         [-9.207e+02],
         [ 1.259e+03]],

        [[-3.124e+00],
         [-3.701e+02],
         [-9.724e+02],
         [ 2.543e+02],
         [ 5.060e+03],
         [ 2.916e+03],
         [-5.468e+02],
         [ 1.317e+02],
         [-8.489e+02],
         [ 7.066e+03]],

        [[-5.526e+02],
         [ 1.922e+02],
         [-5.743e+02],
         [-4.041e+01],
         [-6.901e+02],
         [ 1.244e+03],
         [-9.425e+02],
         [-3.596e+02],
         [ 1.658e+02],
         [-9.461e+02]],

        [[ 2.339e+02],
         [ 3.415e+03],
         [ 6.745e+02],
         [-8.987e+02],
         [-8.843e+02],
         [-1.283e+02],
         [-9.433e+02],
         [-5.448e+02],
         [-6.771e+02],
         [-3.879e+02]],

        [[-5.209e+02],
         [-6.657e+02],
         [-9.816e+02],
         [-3.925e+02],
         [ 3.106e+02],
         [ 2.613e+03],
         [-6.361e+02],
         [-7.638e+02],
         [-9.288e+02],
         [ 4.370e+01]],

        [[-4.672e+02],
         [-5.067e+02],
         [ 2.988e+02],
         [ 1.986e+03],
         [-5.841e+02],
         [-5.754e+02],
         [-8.763e+02],
         [-7.115e+02],
         [-9.451e+02],
         [ 3.108e+02]],

        [[-7.873e+02],
         [-8.100e+02],
         [-5.503e+02],
         [-5.545e+02],
         [-1.759e+02],
         [ 6.723e+02],
         [-8.859e+02],
         [-2.174e+02],
         [-5.429e+02],
         [ 7.393e+02]],

        [[-5.566e+02],
         [ 1.818e+03],
         [ 1.040e+03],
         [-9.507e+02],
         [-8.897e+02],
         [-8.305e+02],
         [ 4.162e+02],
         [-8.939e+02],
         [ 1.669e+03],
         [-8.301e+02]],

        [[-6.962e+02],
         [ 4.600e+02],
         [-7.422e+02],
         [ 7.933e+02],
         [-7.293e+02],
         [-2.100e+02],
         [-5.786e+02],
         [-5.408e+02],
         [ 1.642e+01],
         [ 5.000e+02]],

        [[-9.716e+02],
         [-5.285e+02],
         [-6.658e+02],
         [-4.275e+02],
         [-5.861e+02],
         [ 3.487e+02],
         [-9.101e+02],
         [ 1.952e+03],
         [ 2.156e+02],
         [-8.996e+02]],

        [[ 3.470e+02],
         [-7.320e+02],
         [-5.989e+02],
         [-1.679e+02],
         [-3.006e+02],
         [-8.495e+02],
         [-3.414e+02],
         [-7.917e+02],
         [ 8.909e+02],
         [ 1.948e+01]],

        [[-8.810e+01],
         [-4.945e+02],
         [-9.688e+02],
         [-8.074e+02],
         [ 9.497e+02],
         [ 2.318e+02],
         [ 8.250e+01],
         [-7.905e+02],
         [-2.246e+02],
         [-2.291e+02]],

        [[-7.658e+02],
         [ 7.621e+02],
         [-1.035e+03],
         [ 2.889e+03],
         [-6.256e+02],
         [ 1.449e+03],
         [ 1.275e+03],
         [-8.442e+02],
         [-2.609e+01],
         [-8.530e+02]],

        [[-7.998e+02],
         [-6.991e+02],
         [-5.642e+02],
         [-8.066e+02],
         [ 2.354e+03],
         [-9.295e+02],
         [ 2.703e+03],
         [-6.260e+02],
         [ 7.404e+01],
         [-7.414e+02]],

        [[-3.686e+02],
         [-6.179e+02],
         [ 4.461e+03],
         [-7.264e+02],
         [ 9.616e+02],
         [-5.810e+01],
         [-7.474e+02],
         [ 3.562e+03],
         [-5.929e+02],
         [ 2.345e+03]],

        [[-1.013e+03],
         [-9.506e+02],
         [-1.286e+02],
         [-6.009e+02],
         [-4.518e+02],
         [-6.462e+02],
         [-7.217e+02],
         [-1.081e+03],
         [-8.752e+01],
         [-5.247e+02]],

        [[-6.148e+02],
         [-2.868e+02],
         [-8.331e+02],
         [-6.649e+02],
         [ 8.253e+03],
         [-2.134e+01],
         [ 6.170e+03],
         [ 1.896e+01],
         [-6.695e+02],
         [-1.302e+02]],

        [[ 8.653e+01],
         [-5.998e+02],
         [-2.909e+02],
         [-8.967e+02],
         [ 4.178e+03],
         [-9.754e+02],
         [-2.987e+02],
         [-9.666e+02],
         [-3.491e+02],
         [ 5.002e+02]],

        [[ 2.965e+02],
         [-9.865e+01],
         [ 1.100e+03],
         [ 2.403e+03],
         [ 8.733e+02],
         [-5.311e+02],
         [ 3.712e+03],
         [ 1.734e+03],
         [ 1.332e+03],
         [-5.737e+02]],

        [[-7.610e+02],
         [-7.930e+01],
         [ 3.524e+03],
         [-6.697e+02],
         [-9.104e+02],
         [-7.618e+02],
         [-6.409e+02],
         [-4.665e+02],
         [ 8.671e+02],
         [-3.652e+02]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.361e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[ -976.351],
        [  891.916],
        [ -998.144],
        [ -808.103],
        [  379.305],
        [ -706.788],
        [  -41.539],
        [ -138.067],
        [  943.877],
        [-1010.871],
        [ -719.028],
        [  882.509],
        [ -416.514],
        [-1068.216],
        [ -805.443],
        [ -861.232],
        [ -923.975],
        [ -600.902],
        [  675.166],
        [ -780.925],
        [ -142.164],
        [  982.055],
        [  119.404],
        [ -213.157],
        [ -578.697],
        [ -920.484],
        [ -270.534],
        [  589.815],
        [ -697.334],
        [ -740.288]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 0.030,  0.046,  0.052,  ..., -0.238, -0.062,  0.327],
        [ 0.018,  0.125,  0.411,  ...,  0.105, -0.040, -0.319],
        [ 0.047, -0.144, -0.206,  ...,  0.020, -0.204, -0.264],
        ...,
        [-0.200,  0.238, -0.552,  ...,  0.099,  0.016,  0.124],
        [-0.325,  0.047, -0.188,  ..., -0.014,  0.766, -0.082],
        [-0.055,  0.051, -0.216,  ...,  0.008, -0.348,  0.158]],
       device='cuda:0')
s after update for 1 param tensor([[1.966, 1.741, 2.130,  ..., 1.680, 1.927, 1.396],
        [1.439, 2.214, 1.852,  ..., 1.804, 1.915, 1.744],
        [1.299, 1.558, 1.492,  ..., 1.792, 1.034, 1.213],
        ...,
        [1.375, 2.165, 1.933,  ..., 1.141, 1.137, 2.112],
        [1.126, 1.426, 1.282,  ..., 1.289, 1.406, 1.868],
        [1.446, 2.010, 1.919,  ..., 2.016, 1.569, 2.398]], device='cuda:0')
b after update for 1 param tensor([[181.855, 171.126, 189.271,  ..., 168.107, 180.035, 153.219],
        [155.591, 192.978, 176.515,  ..., 174.182, 179.470, 171.261],
        [147.834, 161.877, 158.410,  ..., 173.605, 131.894, 142.844],
        ...,
        [152.077, 190.811, 180.316,  ..., 138.543, 138.306, 188.455],
        [137.622, 154.887, 146.832,  ..., 147.220, 153.791, 177.257],
        [155.926, 183.852, 179.673,  ..., 184.141, 162.459, 200.829]],
       device='cuda:0')
clipping threshold 2.018500398535765
a after update for 1 param tensor([ 0.104, -0.171, -0.216,  0.028,  0.313,  0.083, -0.334, -0.332, -0.023,
         0.577, -0.191,  0.069, -0.180,  0.067,  0.194,  0.373,  0.363,  0.117,
        -0.346, -0.021,  0.186,  0.184, -0.563, -0.185, -0.091, -0.406,  0.072,
        -0.041,  0.102,  0.280, -0.054,  0.141,  0.130, -0.069, -0.375, -0.136,
         0.201,  0.191, -0.125,  0.090,  0.021, -0.385,  0.394,  0.044,  0.170,
        -0.096, -0.127,  0.130,  0.149,  0.412, -0.395,  0.316,  0.219, -0.206,
        -0.280,  0.193, -0.186,  0.025,  0.272, -0.181, -0.393, -0.565, -0.193,
        -0.090,  0.010, -0.050,  0.412,  0.058, -0.219,  0.110,  0.242, -0.024,
        -0.072,  0.023, -0.247,  0.104, -0.064,  0.258, -0.752,  0.088, -0.351,
        -0.584, -0.052, -0.179, -0.008,  0.055, -0.050,  0.044,  0.377, -0.374,
         0.188,  0.114, -0.252,  0.178,  0.072,  0.163,  0.078, -0.344,  0.061,
        -0.144,  0.068, -0.039, -0.204, -0.224,  0.208, -0.431, -0.374,  0.003,
         0.177,  0.202,  0.057,  0.060,  0.149,  0.179, -0.232,  0.377,  0.100,
        -0.084,  0.030,  0.001,  0.037, -0.107,  0.019,  0.134,  0.022,  0.816,
         0.071,  0.004, -0.546, -0.086, -0.120,  0.183, -0.369, -0.074, -0.268,
        -0.233,  0.105,  0.085,  0.346,  0.194, -0.095,  0.159, -0.065, -0.049,
         0.052, -0.073, -0.343,  0.418,  0.024,  0.069, -0.040, -0.058,  0.635,
         0.068,  0.580,  0.122,  0.508, -0.059,  0.059, -0.231, -0.113, -0.262,
         0.287,  0.510, -0.016, -0.015, -0.082,  0.238,  0.353, -0.008,  0.082,
         0.233,  0.353, -0.317, -0.145, -0.010,  0.138, -0.365, -0.032, -0.042,
        -0.510,  0.005,  0.039,  0.142, -0.014,  0.085,  0.140,  0.325, -0.206,
         0.008, -0.558,  0.019,  0.330,  0.278,  0.125, -0.106,  0.398, -0.169,
         0.228, -0.726, -0.215,  0.156, -0.381, -0.323,  0.233,  0.193, -0.110,
        -0.089,  0.214, -0.090, -0.114, -0.202,  0.278, -0.165,  0.174, -0.410,
         0.211, -0.474, -0.211, -0.406, -0.049, -0.035,  0.392, -0.530,  0.642,
        -0.228, -0.269,  0.255,  0.130, -0.171,  0.262,  0.278, -0.127,  0.112,
        -0.167, -0.026,  0.050, -0.085, -0.239,  0.283,  0.444, -0.049,  0.129,
        -0.402, -0.466, -0.084, -0.424,  0.091, -0.063, -0.049, -0.126, -0.176,
         0.114,  0.179,  0.184, -0.143, -0.037, -0.368, -0.055, -0.205, -0.081,
         0.044,  0.151, -0.267,  0.205,  0.101, -0.209, -0.054, -0.293,  0.092,
         0.003, -0.220,  0.653, -0.246, -0.038,  0.492,  0.010, -0.043, -0.646,
         0.350, -0.262, -0.187, -0.218,  0.234, -0.186, -0.692, -0.143,  0.901,
        -0.389,  0.417,  0.248, -0.109,  0.205,  0.053,  0.014, -0.528,  0.568,
        -0.511, -0.203, -0.268], device='cuda:0')
s after update for 1 param tensor([1.747, 1.829, 1.751, 1.161, 1.122, 1.771, 1.848, 1.946, 1.965, 2.249,
        1.553, 1.800, 1.616, 1.550, 2.158, 1.696, 1.606, 1.812, 1.559, 1.493,
        2.076, 1.734, 1.691, 2.079, 1.867, 2.082, 2.129, 1.474, 1.901, 1.827,
        1.578, 2.222, 1.479, 1.393, 1.621, 2.042, 1.854, 1.400, 1.818, 1.899,
        1.183, 1.655, 1.840, 1.720, 1.476, 2.147, 1.195, 1.395, 1.282, 1.802,
        1.819, 1.818, 1.924, 1.771, 1.859, 1.484, 1.885, 2.267, 2.133, 1.855,
        1.911, 1.729, 1.870, 1.893, 1.115, 1.635, 1.625, 2.191, 1.869, 1.563,
        1.786, 1.592, 1.456, 1.896, 2.188, 1.517, 1.456, 1.966, 1.536, 1.370,
        2.342, 1.452, 1.954, 1.188, 1.564, 1.575, 1.336, 1.741, 1.850, 1.441,
        1.517, 1.683, 1.626, 1.510, 1.883, 1.440, 1.891, 1.212, 1.834, 1.589,
        0.750, 1.942, 1.973, 1.677, 2.101, 1.762, 1.271, 1.492, 1.590, 1.372,
        2.075, 2.199, 1.904, 1.636, 1.417, 1.705, 1.708, 1.777, 1.331, 1.891,
        1.798, 1.855, 1.894, 1.175, 1.569, 1.706, 1.255, 1.949, 1.772, 1.518,
        2.498, 1.796, 2.079, 1.637, 1.753, 1.409, 2.079, 1.765, 2.087, 1.659,
        1.468, 1.469, 1.899, 1.634, 2.143, 1.375, 1.833, 1.921, 1.090, 1.507,
        1.807, 1.655, 2.252, 1.034, 1.504, 1.990, 1.206, 1.694, 1.772, 2.294,
        1.191, 1.584, 1.659, 2.019, 1.411, 1.820, 1.656, 2.174, 1.400, 1.686,
        1.340, 1.565, 1.690, 1.912, 1.786, 1.598, 2.145, 1.819, 1.679, 1.101,
        1.857, 1.392, 1.047, 1.554, 1.888, 1.997, 1.967, 1.832, 1.829, 1.643,
        2.215, 1.772, 2.245, 1.380, 1.500, 1.549, 2.194, 2.090, 1.892, 1.840,
        1.675, 1.972, 2.076, 1.675, 1.413, 1.591, 1.038, 1.938, 1.717, 1.446,
        1.595, 1.390, 1.835, 1.164, 1.722, 1.609, 2.174, 1.636, 1.579, 1.581,
        2.139, 1.621, 1.931, 2.045, 2.096, 1.475, 1.956, 1.431, 1.269, 1.310,
        1.939, 1.412, 1.714, 1.802, 1.279, 1.857, 1.824, 1.828, 1.855, 1.783,
        2.063, 1.993, 1.768, 1.107, 1.568, 1.560, 2.029, 1.360, 0.824, 1.444,
        1.462, 1.295, 1.564, 1.745, 1.603, 1.812, 1.964, 2.053, 1.832, 1.472,
        1.610, 1.370, 2.197, 1.770, 1.711, 1.410, 1.761, 1.700, 1.346, 1.685,
        1.385, 1.782, 1.779, 1.299, 1.705, 1.375, 1.832, 1.375, 1.878, 2.027,
        1.665, 1.723, 1.880, 0.847, 1.401, 1.793, 1.414, 1.885, 1.773, 1.404,
        1.743, 1.579, 1.488, 1.584, 1.837, 2.198, 1.498, 1.847, 0.946, 2.028],
       device='cuda:0')
b after update for 1 param tensor([171.416, 175.406, 171.612, 139.729, 137.382, 172.603, 176.298, 180.925,
        181.776, 194.478, 161.605, 173.989, 164.843, 161.483, 190.518, 168.913,
        164.366, 174.587, 161.908, 158.478, 186.857, 170.786, 168.669, 186.991,
        177.199, 187.135, 189.229, 157.478, 178.799, 175.298, 162.897, 193.305,
        157.701, 153.068, 165.107, 185.325, 176.592, 153.425, 174.873, 178.698,
        141.054, 166.829, 175.945, 170.084, 157.551, 190.045, 141.752, 153.180,
        146.842, 174.074, 174.904, 174.888, 179.878, 172.594, 176.832, 157.977,
        178.063, 195.283, 189.412, 176.639, 179.302, 170.543, 177.355, 178.457,
        136.972, 165.848, 165.305, 191.950, 177.301, 162.133, 173.308, 163.643,
        156.470, 178.558, 191.826, 159.747, 156.478, 181.833, 160.729, 151.772,
        198.478, 156.258, 181.269, 141.350, 162.200, 162.753, 149.892, 171.144,
        176.414, 155.697, 159.757, 168.231, 165.352, 159.364, 177.974, 155.612,
        178.324, 142.806, 175.638, 163.483, 112.304, 180.727, 182.170, 167.932,
        187.974, 172.131, 146.197, 158.427, 163.548, 151.894, 186.831, 192.308,
        178.977, 165.874, 154.392, 169.343, 169.486, 172.868, 149.613, 178.338,
        173.922, 176.625, 178.502, 140.580, 162.465, 169.406, 145.276, 181.057,
        172.633, 159.779, 204.970, 173.788, 186.997, 165.925, 171.691, 153.968,
        187.011, 172.310, 187.375, 167.044, 157.156, 157.164, 178.708, 165.764,
        189.848, 152.092, 175.595, 179.733, 135.407, 159.218, 174.331, 166.841,
        194.629, 131.861, 159.062, 182.929, 142.450, 168.803, 172.645, 196.426,
        141.536, 163.206, 167.063, 184.289, 154.079, 174.968, 166.875, 191.243,
        153.439, 168.391, 150.129, 162.251, 168.612, 179.320, 173.327, 163.960,
        189.964, 174.898, 168.057, 136.058, 176.742, 153.037, 132.726, 161.692,
        178.209, 183.263, 181.890, 175.550, 175.386, 166.215, 193.008, 172.657,
        194.299, 152.359, 158.848, 161.429, 192.105, 187.486, 178.411, 175.944,
        167.871, 182.122, 186.872, 167.867, 154.178, 163.569, 132.130, 180.560,
        169.943, 155.932, 163.765, 152.893, 175.662, 139.895, 170.182, 164.532,
        191.221, 165.894, 162.955, 163.045, 189.677, 165.142, 180.213, 185.466,
        187.757, 157.508, 181.390, 155.117, 146.122, 148.453, 180.577, 154.130,
        169.803, 174.094, 146.664, 176.746, 175.168, 175.358, 176.639, 173.169,
        186.298, 183.075, 172.436, 136.434, 162.374, 162.009, 184.732, 151.240,
        117.720, 155.867, 156.808, 147.603, 162.198, 171.336, 164.182, 174.588,
        181.733, 185.839, 175.546, 157.353, 164.568, 151.789, 192.218, 172.528,
        169.644, 153.981, 172.097, 169.080, 150.467, 168.345, 152.628, 173.125,
        172.992, 147.788, 169.354, 152.082, 175.529, 152.075, 177.750, 184.644,
        167.367, 170.235, 177.811, 119.371, 153.524, 173.675, 154.197, 178.045,
        172.692, 153.694, 171.244, 162.989, 158.175, 163.213, 175.781, 192.290,
        158.738, 176.237, 126.124, 184.691], device='cuda:0')
clipping threshold 2.018500398535765
a after update for 1 param tensor([[[ 2.101e-01],
         [-2.795e-01],
         [-2.352e-01],
         [-2.065e-01],
         [-2.947e-01],
         [ 3.285e-01],
         [-2.475e-01],
         [ 7.136e-02],
         [-2.553e-02],
         [ 2.123e-01]],

        [[-2.230e-01],
         [ 3.612e-01],
         [-1.893e-01],
         [-8.534e-02],
         [ 1.856e-01],
         [ 4.388e-01],
         [ 3.899e-01],
         [-1.575e-01],
         [-1.749e-01],
         [-3.097e-02]],

        [[-2.164e-01],
         [-3.097e-01],
         [ 5.199e-02],
         [-4.889e-01],
         [ 2.995e-01],
         [ 8.847e-02],
         [-3.118e-01],
         [-4.152e-01],
         [ 4.087e-01],
         [-3.254e-01]],

        [[ 3.240e-01],
         [-3.628e-03],
         [ 1.595e-01],
         [ 3.180e-02],
         [ 4.012e-01],
         [ 2.391e-01],
         [-1.618e-02],
         [ 7.870e-02],
         [ 8.696e-02],
         [-1.649e-01]],

        [[ 2.258e-01],
         [ 1.357e-01],
         [ 3.416e-02],
         [ 1.350e-02],
         [ 4.612e-02],
         [-4.399e-01],
         [ 7.897e-02],
         [-5.885e-02],
         [-9.201e-02],
         [ 3.443e-01]],

        [[ 3.593e-01],
         [-5.610e-02],
         [-1.177e-01],
         [-3.308e-01],
         [-6.022e-02],
         [-4.275e-01],
         [-1.238e-01],
         [ 4.760e-01],
         [-1.671e-01],
         [ 5.907e-01]],

        [[ 1.664e-01],
         [ 1.582e-01],
         [-3.386e-01],
         [-7.770e-02],
         [-4.946e-01],
         [ 2.424e-01],
         [ 7.028e-02],
         [ 4.303e-01],
         [-3.546e-01],
         [-1.049e-02]],

        [[-3.509e-02],
         [ 8.856e-02],
         [ 2.686e-01],
         [ 3.359e-01],
         [-2.462e-01],
         [ 2.765e-01],
         [-4.353e-01],
         [-3.212e-01],
         [-2.135e-01],
         [ 1.394e-01]],

        [[-1.961e-01],
         [ 6.781e-02],
         [-3.053e-01],
         [ 1.130e-01],
         [ 1.463e-01],
         [ 1.407e-01],
         [-1.113e-01],
         [ 6.089e-01],
         [ 3.311e-01],
         [ 3.615e-01]],

        [[-2.785e-01],
         [-1.655e-01],
         [ 9.484e-02],
         [ 1.743e-01],
         [ 1.031e-01],
         [-4.794e-02],
         [ 2.077e-01],
         [ 6.259e-02],
         [-1.298e-02],
         [-1.158e-01]],

        [[ 3.963e-01],
         [-7.103e-03],
         [ 1.181e-01],
         [ 1.528e-01],
         [-1.487e-01],
         [-2.320e-01],
         [ 1.146e-01],
         [-3.308e-01],
         [-3.485e-01],
         [-2.853e-01]],

        [[ 5.901e-01],
         [ 4.450e-01],
         [ 2.727e-01],
         [ 3.783e-01],
         [-6.321e-02],
         [ 4.026e-01],
         [ 1.576e-01],
         [ 3.058e-03],
         [ 2.454e-01],
         [ 4.077e-02]],

        [[ 1.573e-01],
         [ 3.105e-01],
         [ 1.364e-01],
         [ 2.360e-01],
         [ 2.985e-02],
         [-1.906e-01],
         [-8.791e-02],
         [ 9.953e-02],
         [-1.061e-01],
         [ 7.086e-02]],

        [[-1.055e-01],
         [ 3.294e-01],
         [ 2.991e-01],
         [ 6.765e-02],
         [-2.950e-01],
         [-3.606e-01],
         [ 4.687e-01],
         [ 3.912e-02],
         [-6.168e-04],
         [-8.903e-02]],

        [[ 4.102e-01],
         [ 2.830e-02],
         [ 1.615e-01],
         [ 2.776e-03],
         [ 1.807e-01],
         [ 3.218e-01],
         [-5.629e-02],
         [-3.151e-02],
         [ 1.186e-01],
         [ 4.642e-03]],

        [[ 8.054e-03],
         [-3.994e-01],
         [ 4.051e-01],
         [ 4.435e-01],
         [-9.999e-02],
         [ 1.658e-01],
         [-3.568e-01],
         [ 2.439e-01],
         [ 2.306e-01],
         [ 6.460e-02]],

        [[-7.615e-01],
         [ 2.044e-01],
         [-3.360e-01],
         [ 6.297e-03],
         [ 2.301e-01],
         [ 1.065e-01],
         [ 4.820e-01],
         [-2.980e-02],
         [ 1.721e-02],
         [ 4.580e-01]],

        [[-1.567e-02],
         [ 1.478e-01],
         [-9.024e-02],
         [-2.600e-01],
         [ 1.898e-01],
         [ 4.285e-01],
         [ 3.860e-01],
         [ 7.732e-02],
         [ 1.987e-02],
         [-1.527e-01]],

        [[ 6.997e-02],
         [-6.202e-01],
         [ 2.202e-01],
         [ 3.977e-01],
         [ 1.011e-01],
         [-5.714e-01],
         [ 3.531e-01],
         [-3.736e-01],
         [ 1.853e-01],
         [ 4.172e-01]],

        [[ 8.365e-01],
         [ 2.051e-01],
         [-1.544e-01],
         [-3.401e-01],
         [-1.922e-01],
         [-3.052e-01],
         [ 1.373e-02],
         [ 3.299e-02],
         [-2.543e-02],
         [ 2.230e-01]],

        [[-4.273e-01],
         [-2.623e-01],
         [ 9.090e-02],
         [-3.158e-02],
         [ 5.234e-02],
         [-1.728e-01],
         [-2.128e-01],
         [-6.659e-01],
         [-1.533e-01],
         [-1.400e-01]],

        [[-5.500e-02],
         [-1.743e-01],
         [ 3.387e-02],
         [ 8.030e-02],
         [-4.237e-01],
         [-5.786e-01],
         [ 6.548e-02],
         [-3.913e-01],
         [ 9.889e-02],
         [-1.010e-01]],

        [[ 1.737e-01],
         [ 3.923e-01],
         [ 4.163e-01],
         [ 3.294e-01],
         [ 1.885e-01],
         [ 9.464e-02],
         [ 4.590e-02],
         [ 2.235e-01],
         [-4.731e-01],
         [-1.442e-01]],

        [[-1.109e-01],
         [-2.040e-01],
         [-6.853e-02],
         [-6.374e-02],
         [ 1.451e-02],
         [-6.091e-02],
         [ 4.491e-01],
         [-6.528e-02],
         [-2.309e-01],
         [ 2.949e-01]],

        [[-2.610e-01],
         [ 6.777e-02],
         [ 7.590e-02],
         [-1.267e-01],
         [ 8.285e-02],
         [-2.827e-01],
         [ 2.151e-01],
         [ 6.684e-02],
         [ 9.794e-02],
         [ 1.732e-01]],

        [[-1.518e-01],
         [-3.612e-01],
         [-4.661e-02],
         [ 4.377e-01],
         [-2.953e-01],
         [ 2.327e-01],
         [-1.129e-01],
         [-4.530e-01],
         [ 4.873e-02],
         [ 2.953e-01]],

        [[ 1.336e-01],
         [ 2.872e-01],
         [ 9.709e-02],
         [ 2.212e-01],
         [-3.246e-01],
         [-7.858e-01],
         [ 3.480e-01],
         [-3.509e-02],
         [-2.309e-01],
         [-6.956e-02]],

        [[ 1.469e-01],
         [ 3.945e-01],
         [-6.510e-02],
         [ 1.257e-02],
         [ 2.830e-01],
         [-1.012e-01],
         [ 1.452e-01],
         [ 1.764e-01],
         [-1.584e-01],
         [ 1.042e-01]],

        [[ 1.274e-01],
         [ 3.847e-01],
         [-5.732e-02],
         [-1.134e-01],
         [-1.673e-01],
         [ 3.027e-02],
         [-1.695e-01],
         [ 1.690e-01],
         [-2.475e-01],
         [ 1.709e-01]],

        [[-2.043e-02],
         [-3.341e-01],
         [-1.330e-01],
         [-5.717e-02],
         [ 3.329e-01],
         [ 2.145e-01],
         [-4.696e-02],
         [ 3.688e-01],
         [ 4.966e-01],
         [-3.552e-01]]], device='cuda:0')
s after update for 1 param tensor([[[1.335],
         [1.709],
         [2.120],
         [1.635],
         [1.544],
         [1.605],
         [2.360],
         [1.251],
         [1.307],
         [1.261]],

        [[2.361],
         [1.375],
         [1.660],
         [1.987],
         [1.410],
         [1.600],
         [2.243],
         [1.960],
         [1.377],
         [1.572]],

        [[1.892],
         [1.630],
         [1.949],
         [0.733],
         [1.453],
         [1.980],
         [1.356],
         [1.597],
         [1.416],
         [2.295]],

        [[1.370],
         [1.630],
         [2.253],
         [1.380],
         [1.520],
         [1.538],
         [0.858],
         [2.381],
         [1.674],
         [1.209]],

        [[1.770],
         [1.496],
         [2.047],
         [1.501],
         [1.685],
         [1.177],
         [1.570],
         [1.653],
         [1.953],
         [2.139]],

        [[1.621],
         [1.894],
         [1.366],
         [2.021],
         [1.581],
         [1.365],
         [1.792],
         [1.963],
         [1.956],
         [1.718]],

        [[1.822],
         [1.302],
         [1.293],
         [1.663],
         [1.257],
         [1.360],
         [1.977],
         [1.630],
         [1.041],
         [1.727]],

        [[1.719],
         [1.657],
         [1.966],
         [2.159],
         [2.128],
         [1.862],
         [1.858],
         [2.123],
         [1.828],
         [2.070]],

        [[1.706],
         [1.493],
         [2.032],
         [1.929],
         [2.186],
         [1.682],
         [1.441],
         [1.098],
         [1.722],
         [1.618]],

        [[1.497],
         [2.079],
         [1.657],
         [1.443],
         [1.677],
         [2.266],
         [2.182],
         [1.858],
         [1.638],
         [1.737]],

        [[1.666],
         [1.636],
         [1.655],
         [1.363],
         [1.695],
         [2.364],
         [1.810],
         [1.673],
         [1.737],
         [2.055]],

        [[1.708],
         [1.746],
         [2.239],
         [1.756],
         [2.020],
         [1.625],
         [1.577],
         [2.250],
         [1.614],
         [1.695]],

        [[1.364],
         [2.054],
         [2.035],
         [1.917],
         [1.306],
         [1.631],
         [1.781],
         [1.362],
         [1.895],
         [1.829]],

        [[1.465],
         [1.778],
         [1.903],
         [1.800],
         [1.716],
         [1.474],
         [1.850],
         [1.482],
         [1.645],
         [1.439]],

        [[1.295],
         [1.757],
         [1.870],
         [1.470],
         [1.809],
         [1.823],
         [1.861],
         [1.509],
         [1.759],
         [2.086]],

        [[1.830],
         [1.223],
         [1.826],
         [2.115],
         [1.619],
         [1.662],
         [1.668],
         [1.636],
         [1.812],
         [1.705]],

        [[1.734],
         [1.535],
         [1.784],
         [1.471],
         [1.719],
         [1.922],
         [1.672],
         [1.494],
         [1.824],
         [1.738]],

        [[1.556],
         [2.141],
         [1.844],
         [1.823],
         [1.811],
         [1.690],
         [1.601],
         [1.693],
         [2.356],
         [1.773]],

        [[1.351],
         [2.162],
         [1.670],
         [1.653],
         [1.955],
         [2.235],
         [1.549],
         [1.251],
         [2.266],
         [2.029]],

        [[2.147],
         [1.560],
         [1.472],
         [1.682],
         [1.277],
         [1.860],
         [1.718],
         [1.641],
         [1.678],
         [1.698]],

        [[2.085],
         [2.110],
         [1.583],
         [1.529],
         [1.812],
         [1.624],
         [1.682],
         [1.769],
         [1.565],
         [2.247]],

        [[1.753],
         [2.073],
         [1.886],
         [1.556],
         [2.161],
         [2.105],
         [2.513],
         [1.734],
         [0.805],
         [2.204]],

        [[1.839],
         [2.071],
         [2.054],
         [2.112],
         [1.634],
         [2.156],
         [1.879],
         [1.753],
         [1.332],
         [1.951]],

        [[1.523],
         [1.376],
         [1.867],
         [1.906],
         [1.469],
         [1.755],
         [2.024],
         [1.186],
         [1.943],
         [1.455]],

        [[1.166],
         [1.175],
         [1.965],
         [1.570],
         [1.698],
         [1.713],
         [1.410],
         [2.383],
         [1.513],
         [2.159]],

        [[1.977],
         [1.802],
         [0.940],
         [1.560],
         [1.207],
         [1.881],
         [1.406],
         [2.164],
         [1.397],
         [1.744]],

        [[1.660],
         [1.136],
         [1.754],
         [1.588],
         [2.243],
         [1.286],
         [2.348],
         [1.993],
         [1.522],
         [1.632]],

        [[1.705],
         [1.634],
         [1.133],
         [1.692],
         [2.263],
         [1.845],
         [1.835],
         [1.836],
         [1.216],
         [1.473]],

        [[1.474],
         [1.279],
         [1.897],
         [1.893],
         [2.032],
         [1.806],
         [1.669],
         [1.802],
         [1.769],
         [1.229]],

        [[1.445],
         [1.536],
         [2.284],
         [1.390],
         [1.876],
         [1.486],
         [1.833],
         [2.021],
         [1.661],
         [2.082]]], device='cuda:0')
b after update for 1 param tensor([[[149.855],
         [169.563],
         [188.830],
         [165.849],
         [161.176],
         [164.295],
         [199.234],
         [145.030],
         [148.257],
         [145.644]],

        [[199.269],
         [152.079],
         [167.076],
         [182.803],
         [154.000],
         [164.040],
         [194.250],
         [181.570],
         [152.182],
         [162.593]],

        [[178.405],
         [165.591],
         [181.056],
         [111.011],
         [156.309],
         [182.495],
         [151.024],
         [163.890],
         [154.318],
         [196.476]],

        [[151.774],
         [165.581],
         [194.653],
         [152.376],
         [159.906],
         [160.856],
         [120.131],
         [200.107],
         [167.811],
         [142.630]],

        [[172.530],
         [158.601],
         [185.542],
         [158.917],
         [168.367],
         [140.720],
         [162.522],
         [166.754],
         [181.230],
         [189.691]],

        [[165.137],
         [178.480],
         [151.551],
         [184.379],
         [163.094],
         [151.531],
         [173.602],
         [181.687],
         [181.364],
         [170.010]],

        [[175.064],
         [147.967],
         [147.451],
         [167.222],
         [145.423],
         [151.218],
         [182.342],
         [165.578],
         [132.318],
         [170.422]],

        [[170.014],
         [166.926],
         [181.847],
         [190.560],
         [189.180],
         [176.958],
         [176.757],
         [188.953],
         [175.349],
         [186.611]],

        [[169.400],
         [158.460],
         [184.889],
         [180.122],
         [191.761],
         [168.185],
         [155.667],
         [135.916],
         [170.170],
         [164.991]],

        [[158.703],
         [186.990],
         [166.930],
         [155.785],
         [167.962],
         [195.208],
         [191.571],
         [176.793],
         [166.008],
         [170.931]],

        [[167.399],
         [165.888],
         [166.828],
         [151.422],
         [168.824],
         [199.417],
         [174.481],
         [167.764],
         [170.931],
         [185.894]],

        [[169.488],
         [171.349],
         [194.070],
         [171.858],
         [184.309],
         [165.324],
         [162.885],
         [194.536],
         [164.777],
         [168.853]],

        [[151.462],
         [185.882],
         [185.000],
         [179.561],
         [148.226],
         [165.612],
         [173.062],
         [151.369],
         [178.546],
         [175.384]],

        [[156.981],
         [172.930],
         [178.928],
         [174.003],
         [169.914],
         [157.459],
         [176.398],
         [157.861],
         [166.350],
         [155.551]],

        [[147.604],
         [171.889],
         [177.371],
         [157.219],
         [174.436],
         [175.085],
         [176.917],
         [159.314],
         [172.016],
         [187.308]],

        [[175.450],
         [143.439],
         [175.234],
         [188.601],
         [165.019],
         [167.199],
         [167.499],
         [165.889],
         [174.564],
         [169.362]],

        [[170.783],
         [160.686],
         [173.245],
         [157.286],
         [170.039],
         [179.788],
         [167.691],
         [158.540],
         [175.159],
         [170.984]],

        [[161.785],
         [189.745],
         [176.124],
         [175.129],
         [174.528],
         [168.574],
         [164.077],
         [168.730],
         [199.050],
         [172.675]],

        [[150.734],
         [190.696],
         [167.602],
         [166.764],
         [181.323],
         [193.882],
         [161.396],
         [145.070],
         [195.220],
         [184.738]],

        [[190.010],
         [161.979],
         [157.366],
         [168.197],
         [146.536],
         [176.888],
         [169.977],
         [166.149],
         [168.012],
         [168.971]],

        [[187.260],
         [188.385],
         [163.187],
         [160.376],
         [174.556],
         [165.284],
         [168.193],
         [172.473],
         [162.250],
         [194.409]],

        [[171.691],
         [186.715],
         [178.110],
         [161.756],
         [190.646],
         [188.152],
         [205.583],
         [170.758],
         [116.391],
         [192.536]],

        [[175.868],
         [186.660],
         [185.888],
         [188.496],
         [165.765],
         [190.441],
         [177.757],
         [171.722],
         [149.687],
         [181.153]],

        [[160.043],
         [152.106],
         [177.216],
         [179.041],
         [157.170],
         [171.809],
         [184.512],
         [141.219],
         [180.770],
         [156.457]],

        [[140.067],
         [140.584],
         [181.798],
         [162.520],
         [168.998],
         [169.749],
         [154.012],
         [200.209],
         [159.514],
         [190.565]],

        [[182.336],
         [174.105],
         [125.738],
         [161.994],
         [142.504],
         [177.881],
         [153.758],
         [190.782],
         [153.280],
         [171.282]],

        [[167.093],
         [138.207],
         [171.758],
         [163.428],
         [194.213],
         [147.096],
         [198.746],
         [183.103],
         [159.991],
         [165.672]],

        [[169.352],
         [165.768],
         [138.021],
         [168.692],
         [195.089],
         [176.182],
         [175.662],
         [175.727],
         [142.987],
         [157.384]],

        [[157.452],
         [146.646],
         [178.607],
         [178.450],
         [184.872],
         [174.269],
         [167.528],
         [174.110],
         [172.470],
         [143.768]],

        [[155.915],
         [160.714],
         [196.002],
         [152.896],
         [177.627],
         [158.082],
         [175.605],
         [184.381],
         [167.134],
         [187.142]]], device='cuda:0')
clipping threshold 2.018500398535765
a after update for 1 param tensor([[ 0.262],
        [-0.460],
        [ 0.063],
        [ 0.362],
        [ 0.090],
        [-0.200],
        [-0.222],
        [ 0.013],
        [ 0.176],
        [-0.573],
        [ 0.009],
        [ 0.519],
        [ 0.077],
        [-0.142],
        [-0.034],
        [ 0.173],
        [-0.024],
        [ 0.209],
        [ 0.042],
        [-0.201],
        [ 0.651],
        [ 0.260],
        [-0.034],
        [-0.288],
        [ 0.120],
        [-0.064],
        [-0.259],
        [ 0.217],
        [-0.065],
        [ 0.320]], device='cuda:0')
s after update for 1 param tensor([[1.867],
        [1.997],
        [1.885],
        [1.532],
        [1.327],
        [1.949],
        [1.664],
        [1.431],
        [1.743],
        [1.920],
        [1.952],
        [2.118],
        [1.575],
        [2.082],
        [1.680],
        [1.761],
        [1.984],
        [1.583],
        [1.917],
        [1.836],
        [1.320],
        [1.742],
        [2.209],
        [1.737],
        [1.593],
        [2.047],
        [1.675],
        [1.852],
        [1.348],
        [1.555]], device='cuda:0')
b after update for 1 param tensor([[177.202],
        [183.292],
        [178.040],
        [160.524],
        [149.371],
        [181.056],
        [167.320],
        [155.126],
        [171.231],
        [179.721],
        [181.183],
        [188.755],
        [162.736],
        [187.149],
        [168.104],
        [172.086],
        [182.691],
        [163.186],
        [179.580],
        [175.709],
        [148.985],
        [171.178],
        [192.739],
        [170.928],
        [163.710],
        [185.560],
        [167.847],
        [176.488],
        [150.590],
        [161.703]], device='cuda:0')
clipping threshold 2.018500398535765
||w||^2 3.2947477569202093
exp ma of ||w||^2 6.1996596931504
||w|| 1.8151440044581062
exp ma of ||w|| 2.4168215577167578
||w||^2 5.0259505355820275
exp ma of ||w||^2 6.175936273353384
||w|| 2.241863183957047
exp ma of ||w|| 2.4052658383648526
||w||^2 2.7719010837120805
exp ma of ||w||^2 6.347354368095246
||w|| 1.6649027249998964
exp ma of ||w|| 2.4417169207230414
||w||^2 5.305056935947108
exp ma of ||w||^2 5.749421719192228
||w|| 2.3032709210918085
exp ma of ||w|| 2.3279683259915434
||w||^2 9.612126813313422
exp ma of ||w||^2 5.788454171676744
||w|| 3.1003430154280385
exp ma of ||w|| 2.336798956622016
||w||^2 4.0064838420025355
exp ma of ||w||^2 6.084686018843401
||w|| 2.0016203041542457
exp ma of ||w|| 2.389161694503504
||w||^2 9.171387300180823
exp ma of ||w||^2 5.951472125631847
||w|| 3.0284298407228825
exp ma of ||w|| 2.377768243825394
||w||^2 5.176432382817076
exp ma of ||w||^2 6.0674318483981295
||w|| 2.275177439853225
exp ma of ||w|| 2.3821863057888093
||w||^2 16.151780444242345
exp ma of ||w||^2 6.190160628497509
||w|| 4.018927772956656
exp ma of ||w|| 2.40452751577632
||w||^2 4.704248311547551
exp ma of ||w||^2 5.6823340796083235
||w|| 2.1689279175545577
exp ma of ||w|| 2.298443843837128
cuda
Objective function 115.89 = squared loss an data 69.91 + 0.5*rho*h**2 9.937233 + alpha*h 32.621522 + L2reg 3.01 + L1reg 0.42 ; SHD = 162 ; DAG True
Proportion of microbatches that were clipped  0.7786673136018114
iteration 1 in inner loop, alpha 73.17394581039075 rho 100.0 h 0.4458078781082335
9630
cuda
Objective function 205.33 = squared loss an data 69.91 + 0.5*rho*h**2 99.372332 + alpha*h 32.621522 + L2reg 3.01 + L1reg 0.42 ; SHD = 162 ; DAG True
||w||^2 8007588652.430682
exp ma of ||w||^2 233150771859.96246
||w|| 89485.13090134406
exp ma of ||w|| 344574.557478338
||w||^2 153758.00480001594
exp ma of ||w||^2 1993161326.9686122
||w|| 392.11988574926414
exp ma of ||w|| 6195.534663662531
||w||^2 3.537574966023086
exp ma of ||w||^2 6.496134680100117
||w|| 1.8808442163090187
exp ma of ||w|| 2.473254126093261
||w||^2 6.610559761169246
exp ma of ||w||^2 6.488019735048742
||w|| 2.5711008850625148
exp ma of ||w|| 2.4742631382753912
||w||^2 5.2091697805006305
exp ma of ||w||^2 7.053023793679213
||w|| 2.282360571973813
exp ma of ||w|| 2.5710937290586746
||w||^2 3.363748958218501
exp ma of ||w||^2 6.660483972091313
||w|| 1.8340526050848436
exp ma of ||w|| 2.4893121608562967
||w||^2 7.525088028583588
exp ma of ||w||^2 6.871996181888163
||w|| 2.7431893898496305
exp ma of ||w|| 2.532815611618402
||w||^2 7.837610166445606
exp ma of ||w||^2 6.883101384308247
||w|| 2.799573211481637
exp ma of ||w|| 2.534854170864041
||w||^2 13.018540407662277
exp ma of ||w||^2 6.144486573676807
||w|| 3.608121451345877
exp ma of ||w|| 2.394142473941303
||w||^2 6.781398596966896
exp ma of ||w||^2 6.06042472609371
||w|| 2.6041118633743245
exp ma of ||w|| 2.3995084542693883
||w||^2 3.1998516267245116
exp ma of ||w||^2 6.287056175807891
||w|| 1.7888129099278414
exp ma of ||w|| 2.437060943753123
||w||^2 7.537031610131328
exp ma of ||w||^2 6.596678067610214
||w|| 2.7453654784256556
exp ma of ||w|| 2.492424451055323
||w||^2 6.451043643116547
exp ma of ||w||^2 6.760751935186861
||w|| 2.5398904785672447
exp ma of ||w|| 2.5204508117864783
||w||^2 4.793072555122245
exp ma of ||w||^2 6.549734617864883
||w|| 2.189308693428646
exp ma of ||w|| 2.490866743462502
cuda
Objective function 110.38 = squared loss an data 71.86 + 0.5*rho*h**2 20.215229 + alpha*h 14.713324 + L2reg 3.19 + L1reg 0.39 ; SHD = 164 ; DAG True
Proportion of microbatches that were clipped  0.7825567502986858
iteration 2 in inner loop, alpha 73.17394581039075 rho 1000.0 h 0.2010732632914518
9630
cuda
Objective function 292.31 = squared loss an data 71.86 + 0.5*rho*h**2 202.152286 + alpha*h 14.713324 + L2reg 3.19 + L1reg 0.39 ; SHD = 164 ; DAG True
||w||^2 204018963105.58987
exp ma of ||w||^2 1742416225514.504
||w|| 451684.5836483573
exp ma of ||w|| 969132.7276375253
||w||^2 177796390.1877072
exp ma of ||w||^2 63206606254.22377
||w|| 13334.031280438305
exp ma of ||w|| 86381.89783738137
||w||^2 8.547532535008239
exp ma of ||w||^2 235.8638299633872
||w|| 2.9236163453860082
exp ma of ||w|| 2.904335923736392
||w||^2 16.315970364845857
exp ma of ||w||^2 83.24773802036819
||w|| 4.039303202886094
exp ma of ||w|| 3.0071257398766718
||w||^2 7.344969467225484
exp ma of ||w||^2 45.20370720089232
||w|| 2.7101604135595894
exp ma of ||w|| 2.9315437036914913
||w||^2 8.873776978063288
exp ma of ||w||^2 7.77586631285211
||w|| 2.9788885474390088
exp ma of ||w|| 2.7251551465397608
||w||^2 4.8002701789807
exp ma of ||w||^2 7.886140456351675
||w|| 2.190951888787314
exp ma of ||w|| 2.7414916734453265
||w||^2 8.215210746890856
exp ma of ||w||^2 8.041572078537985
||w|| 2.866218893750241
exp ma of ||w|| 2.770372296289189
||w||^2 14.015899482134751
exp ma of ||w||^2 7.7035344945691335
||w|| 3.7437814415554165
exp ma of ||w|| 2.714881459129513
||w||^2 14.723117724850887
exp ma of ||w||^2 8.346200536682892
||w|| 3.837071503744866
exp ma of ||w|| 2.826316268289944
||w||^2 6.088874119028735
exp ma of ||w||^2 8.34521572558624
||w|| 2.46756441031004
exp ma of ||w|| 2.824438653071106
||w||^2 5.385742502080761
exp ma of ||w||^2 8.06989613131886
||w|| 2.320720255024453
exp ma of ||w|| 2.7778274182851734
v before min max tensor([[ 1727.429,  -863.478,   853.782,  ...,  -406.026,  -566.802,
          -505.151],
        [ -589.271,  1463.217,    23.517,  ...,  -565.483, -1258.586,
          -694.643],
        [-1097.724,  1044.365,  -554.272,  ..., 11232.502, -1055.754,
          -859.416],
        ...,
        [ 2159.963,  -959.531,  -957.020,  ...,  -977.184,  -766.607,
          -907.741],
        [-1007.350,  3522.193, -1253.587,  ...,  1532.988, -1062.207,
          1242.417],
        [  362.613,  2871.315, -1095.588,  ...,  -460.693,   -86.489,
          2113.031]], device='cuda:0')
v tensor([[1.000e+01, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e+01, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e+01, 1.000e-12,
         1.000e+01],
        [1.000e+01, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e+01]], device='cuda:0')
v before min max tensor([   83.656,   419.654, -1141.364,  -997.894,  -121.406,   -20.694,
          496.310, -1024.245,  -965.077,  1339.312,  1067.758,   642.439,
         -385.472,  -657.892, -1067.729,  2110.688,  -880.504,  -600.975,
          426.505,  2450.375,   557.293,  -660.727,  -222.556, -1103.074,
          981.297,   872.977,  -987.597,  -178.722,   319.986,  -986.235,
          987.077,  -344.270,  -399.679,  -829.813,  1108.965,  -188.048,
         -651.237,  -802.086,  -743.348,  1434.266,  -371.345,   162.219,
         -516.483,  -562.193,  1222.658,   843.265,  5541.758,  -618.278,
         6275.840,  -286.238,  -335.222,   609.350,  -595.167, -1017.118,
          515.192,  -600.621,   744.818, -1097.597, -1023.606, -1062.588,
         -788.362, -1015.432,  -259.880,  -159.613,  -733.773,  -834.226,
          276.426,  -785.398,  1918.526,  -500.947,  2487.818, -1055.999,
         -590.232,  -664.817,  -602.800,  -703.377,  1142.411,  -782.499,
        -1072.560,  -779.893,  -957.636,  -986.425,  -989.161,  1309.814,
         -818.121,  -687.853,  -390.031,   667.437,  -719.629,  -293.827,
         -194.399,   558.085,  -115.505,  -402.408,   135.072,  -913.407,
         -719.134,  -896.324,  -534.466,  -468.070,  -100.619,  4090.258,
         -747.052,   151.109,  -556.009,  -915.154, -1103.386,  -467.227,
        -1062.965,   574.569,  -746.449,  -379.228,   -91.348,   870.892,
         -282.576,  1615.333,  1193.680,   739.528,  -836.719,  -772.377,
         -689.751,  1048.990,  -972.640, -1071.889,  -893.900,  -258.286,
         -541.877,  -524.395,  2584.372,  -499.329,   511.823,  1479.422,
         -941.902,  -377.873,   743.280,  -766.859, -1010.089,  -398.590,
         -554.185,  -980.982,  -661.742,  -391.107,  -636.078,   681.096,
         -254.596,  -671.650,  -494.251, -1144.730,  -482.358, -1037.410,
         -725.262,  -399.874,  4824.961,  -820.893,  -870.869,    37.227,
         1141.388, -1180.646,   290.928,  -990.804,   -38.753,  -797.916,
         -257.722,  -664.285,  -560.551,  -665.200,  -335.606, -1016.837,
        -1017.476,  -720.421,  5401.926, -1032.553,  1657.775,  -792.114,
         -646.404,  -586.703,  -464.426,  -738.666,   321.995,  -671.249,
        -1011.524,   193.405,  -891.504,  -794.010,  -763.469,  -594.538,
         -412.213,  -596.378,  -795.020,  -898.331,  2296.321,  -496.095,
         2832.688,  -938.948,   166.321,    47.049,  -977.826,  1107.547,
         -419.849,  -616.809,  -748.412,    98.841, -1051.364,    33.044,
          407.157,  -375.929,  -676.093,  3181.471,   698.699,  -721.213,
         -880.428,  -722.054,  -595.635,   121.588,    55.597,  -289.904,
         -860.853,  -218.312,  -698.997,   532.867,  2051.195,  -754.090,
         -838.043,  -259.746,  2975.643,   895.919,  -970.447,  -450.315,
         -959.495,  -681.960,  -965.334,  -791.586,  -594.128,  1783.459,
          462.063,  -615.235,  2172.226,  -862.803,  -931.583,  3109.584,
         2762.969,  1397.196,  -829.269, -1112.971,  -237.018,   106.764,
        -1298.435,  -412.575, -1040.056, -1143.695,   446.138,  -892.259,
          -95.456,  -835.659, -1002.399,  -964.316,  -935.905,   926.632,
         -867.191,  -634.583,   232.317,  -765.233,  1552.405,  -339.895,
         -789.102,  -748.858,   119.674,  -411.954,   431.841,  -814.253,
         -878.045,  -557.469,  -501.569,  1643.062,  -835.887,   739.080,
         -900.475,  -484.977,  -336.243,  -930.848,   386.213,  -686.286,
        -1000.109,  -873.926,    92.951,   660.731,    87.986,  -491.429,
         -557.747,  1441.879, -1022.448,  -880.122,    33.824,  2472.481,
         -871.140,  -454.466,  -575.651,   -46.881,  1403.353,  -291.532],
       device='cuda:0')
v tensor([1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[ -770.330],
         [ -901.431],
         [ -753.591],
         [ -332.874],
         [  621.668],
         [ 1362.186],
         [ -762.692],
         [ -734.278],
         [ -899.009],
         [ 1317.845]],

        [[ -894.138],
         [ -339.663],
         [ 1205.026],
         [ -812.149],
         [ -303.462],
         [ 1355.370],
         [ 4883.266],
         [-1137.622],
         [-1085.993],
         [ -727.403]],

        [[  114.399],
         [ -866.100],
         [ -706.350],
         [ -893.859],
         [ -841.882],
         [ 4736.901],
         [ -628.334],
         [ -216.080],
         [ -355.153],
         [ 1877.975]],

        [[  -64.328],
         [ -792.414],
         [ -509.798],
         [ -671.063],
         [  881.266],
         [ -581.364],
         [ 2481.750],
         [  715.486],
         [ -974.651],
         [ -641.442]],

        [[ -473.819],
         [ -646.645],
         [  606.410],
         [ -920.547],
         [ -418.066],
         [ -860.570],
         [ -987.135],
         [  524.410],
         [ -833.925],
         [ -286.516]],

        [[ 9710.812],
         [ -582.447],
         [ 3453.986],
         [ -816.855],
         [-1086.309],
         [ 3614.893],
         [ -824.684],
         [ -153.722],
         [ 1751.273],
         [ -481.692]],

        [[  455.479],
         [ -888.620],
         [  258.601],
         [ 7830.437],
         [ 1646.227],
         [ -527.220],
         [ -792.280],
         [ -320.060],
         [  805.124],
         [ -396.006]],

        [[ -283.506],
         [ -573.645],
         [ -763.423],
         [ -861.438],
         [ -394.244],
         [  424.229],
         [ -970.813],
         [  390.303],
         [ -854.481],
         [  821.417]],

        [[ 2646.795],
         [  150.705],
         [ -744.324],
         [-1095.220],
         [  225.749],
         [-1200.439],
         [ -964.966],
         [ -808.090],
         [ -694.667],
         [ 2001.907]],

        [[  543.389],
         [   81.639],
         [ -807.147],
         [ -320.946],
         [ -844.749],
         [ -315.728],
         [ -771.971],
         [ -738.512],
         [ -714.533],
         [ 9858.717]],

        [[-1085.387],
         [ -791.321],
         [ -894.275],
         [ -188.857],
         [ -892.187],
         [ -958.560],
         [  629.172],
         [ -392.736],
         [  609.864],
         [ 1598.103]],

        [[ 4216.224],
         [ -855.698],
         [ -729.949],
         [ -682.950],
         [ -529.673],
         [-1106.936],
         [ 3306.946],
         [ -843.100],
         [ 2992.251],
         [  550.684]],

        [[ -694.626],
         [ -160.055],
         [  783.024],
         [ -567.323],
         [ -524.061],
         [ -273.518],
         [ -619.118],
         [ 2185.384],
         [ -555.742],
         [  659.364]],

        [[ -965.950],
         [ -442.522],
         [ -793.359],
         [-1036.527],
         [ -811.677],
         [  665.704],
         [ 1694.328],
         [ -730.885],
         [ -284.657],
         [ -682.218]],

        [[ -147.548],
         [ -827.842],
         [  739.338],
         [  310.383],
         [  362.561],
         [-1134.283],
         [ -584.634],
         [  385.513],
         [ -910.203],
         [ 2982.537]],

        [[ -903.201],
         [ 2265.964],
         [ -185.289],
         [ -720.607],
         [ -164.232],
         [ -715.585],
         [ -849.989],
         [ -634.126],
         [ 3043.537],
         [   85.655]],

        [[ -670.272],
         [ -692.704],
         [ -710.599],
         [ -658.301],
         [-1041.123],
         [ -800.588],
         [  355.392],
         [-1016.191],
         [ 1178.768],
         [ 5239.768]],

        [[ -586.161],
         [ -126.819],
         [ 1009.094],
         [ -149.430],
         [ -551.008],
         [-1063.857],
         [-1240.795],
         [ -582.572],
         [ 1563.984],
         [  435.647]],

        [[ -703.405],
         [ -797.145],
         [ -846.150],
         [  775.655],
         [  194.960],
         [  267.982],
         [-1004.480],
         [  -76.394],
         [ -921.445],
         [ -937.572]],

        [[ -633.706],
         [  814.727],
         [ -830.903],
         [-1156.124],
         [ -426.759],
         [ -670.380],
         [ -357.718],
         [ -285.576],
         [ -426.623],
         [ -322.292]],

        [[  240.017],
         [ -582.403],
         [  634.205],
         [ 5362.859],
         [  759.880],
         [ -884.043],
         [ 2835.012],
         [ -585.403],
         [ -131.185],
         [ 1267.233]],

        [[ -843.601],
         [ 1167.071],
         [ -940.860],
         [ -698.694],
         [-1178.107],
         [ 1175.494],
         [  323.445],
         [ -505.417],
         [ 5056.457],
         [ -585.992]],

        [[  692.685],
         [ -315.171],
         [ -732.185],
         [ -396.234],
         [ -649.097],
         [ -878.319],
         [ -973.220],
         [ -501.089],
         [ 1135.019],
         [  236.188]],

        [[ -766.939],
         [ -354.712],
         [ -859.989],
         [ 2378.263],
         [ 2309.390],
         [ -688.374],
         [ -751.393],
         [-1023.638],
         [ -494.212],
         [  920.508]],

        [[ -183.432],
         [ -960.317],
         [ -482.266],
         [ 3403.237],
         [  398.156],
         [ -606.729],
         [-1154.206],
         [ -633.700],
         [ 3017.813],
         [   86.281]],

        [[ -838.438],
         [-1115.546],
         [ -127.890],
         [ -347.897],
         [-1036.256],
         [ -747.924],
         [ -804.487],
         [ 8177.058],
         [  -39.026],
         [ 2630.353]],

        [[-1095.750],
         [ -800.394],
         [ 3667.083],
         [ 1449.932],
         [ -963.168],
         [-1010.974],
         [ -651.273],
         [ -568.962],
         [-1027.947],
         [  948.157]],

        [[  284.148],
         [  -83.249],
         [ -566.942],
         [ -192.248],
         [ 3720.984],
         [ 3328.232],
         [ -512.593],
         [  236.069],
         [  105.981],
         [  -50.230]],

        [[-1090.014],
         [ -429.224],
         [  910.319],
         [  624.177],
         [ 4954.820],
         [-1105.108],
         [ 1545.129],
         [ 1286.295],
         [ -732.574],
         [  -96.519]],

        [[ 3883.840],
         [ 3214.615],
         [ -348.002],
         [ -935.810],
         [ -513.790],
         [  715.482],
         [ 4651.104],
         [ -860.077],
         [ -350.466],
         [ -233.672]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[ 7.672e+02],
        [ 6.172e+02],
        [-9.076e+01],
        [ 1.151e+03],
        [ 8.401e+03],
        [-4.588e+02],
        [-8.414e+02],
        [-8.433e+02],
        [-1.002e+03],
        [ 3.750e+02],
        [-3.717e+02],
        [ 9.310e+02],
        [-3.484e+02],
        [-5.827e+02],
        [-1.015e+03],
        [ 3.695e+02],
        [-7.288e+02],
        [-5.375e+02],
        [-9.766e+02],
        [-2.477e+02],
        [-1.983e+02],
        [-5.778e+02],
        [-9.800e+02],
        [-1.008e+03],
        [ 9.131e+02],
        [-6.203e+02],
        [-1.013e+03],
        [ 2.596e+02],
        [-3.692e+02],
        [-5.472e+00]], device='cuda:0')
v tensor([[1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-0.071, -0.084,  0.236,  ..., -0.348,  0.280, -0.086],
        [ 0.076,  0.433,  0.287,  ..., -0.468,  0.088,  0.079],
        [ 0.134, -0.304,  0.274,  ..., -0.323, -0.120,  0.247],
        ...,
        [ 0.007, -0.162, -0.158,  ...,  0.551,  0.003,  0.016],
        [ 0.121,  0.384,  0.149,  ..., -0.101,  0.055, -0.050],
        [-0.069,  0.020,  0.113,  ...,  0.632,  0.109, -0.168]],
       device='cuda:0')
s after update for 1 param tensor([[1.899, 1.560, 2.051,  ..., 1.828, 1.645, 1.848],
        [2.324, 2.175, 1.785,  ..., 1.518, 2.347, 1.540],
        [2.042, 1.649, 1.540,  ..., 2.464, 1.873, 1.636],
        ...,
        [1.826, 1.774, 1.721,  ..., 1.961, 1.570, 1.729],
        [1.794, 1.833, 2.228,  ..., 1.641, 1.926, 2.112],
        [2.240, 1.848, 1.963,  ..., 1.772, 1.394, 2.488]], device='cuda:0')
b after update for 1 param tensor([[183.643, 166.451, 190.848,  ..., 180.184, 170.928, 181.186],
        [203.157, 196.554, 178.027,  ..., 164.194, 204.151, 165.394],
        [190.430, 171.129, 165.362,  ..., 209.169, 182.361, 170.480],
        ...,
        [180.063, 177.512, 174.837,  ..., 186.603, 166.975, 175.242],
        [178.479, 180.428, 198.922,  ..., 170.701, 184.946, 193.656],
        [199.454, 181.172, 186.698,  ..., 177.394, 157.339, 210.197]],
       device='cuda:0')
clipping threshold 2.030823203077907
a after update for 1 param tensor([-0.243,  0.392, -0.272, -0.157, -0.335,  0.113, -0.174,  0.548,  0.246,
        -0.093,  0.128,  0.218, -0.674,  0.658,  0.348,  0.138,  0.081,  0.043,
         0.485,  0.036, -0.258,  0.104,  0.852,  0.694,  0.530,  0.007, -0.457,
        -0.111,  0.159,  0.373, -0.547,  0.646, -0.342,  0.028,  0.375, -0.108,
         0.252, -0.725, -0.496,  0.264, -0.153, -0.218, -0.369, -0.450,  0.107,
         0.323,  0.490, -0.014, -0.538,  0.067,  0.029,  0.607, -0.123,  0.097,
        -0.501,  0.354, -0.321,  0.312,  0.082,  0.280, -0.404, -0.016, -0.393,
        -0.417, -0.925,  0.903,  0.019, -0.173,  0.510, -0.019, -0.104, -0.539,
         0.336,  0.228,  0.145,  0.495, -0.124,  0.406, -0.244, -0.070, -0.081,
         0.216, -0.054,  0.533, -0.361, -0.576,  0.121, -0.219, -0.379, -0.808,
         0.145,  0.297,  0.003,  0.088, -0.177, -0.186,  0.067, -0.299, -0.101,
         0.512, -0.016,  1.024, -0.035, -0.420,  0.161, -0.016, -0.280,  0.300,
         0.272, -0.482,  0.224,  0.215, -0.600, -0.284, -0.317,  0.219,  0.437,
        -0.198,  0.246, -0.150, -0.408, -0.038, -0.172,  0.054,  0.005,  0.885,
         0.096,  0.048,  0.006, -0.120, -0.086, -0.006,  0.038,  0.423,  0.061,
        -0.407, -0.063,  0.592,  0.023, -0.134, -0.287, -0.144, -0.409,  0.389,
         0.011, -0.151,  0.440, -0.078,  0.002,  0.425,  0.143, -0.033,  0.513,
        -0.130,  0.164, -0.054,  0.129, -0.143, -0.573, -0.483,  0.043,  0.076,
         0.184,  0.116,  0.020,  0.042, -0.320, -0.174, -0.034,  0.233, -0.079,
        -0.094, -0.097, -0.615, -0.038,  0.503,  0.164, -0.076,  0.183,  0.279,
        -0.063, -0.065,  0.252,  0.195, -0.243, -0.272, -0.271,  0.618, -0.276,
         0.428,  0.074,  0.363,  0.111, -0.251, -0.297,  0.459,  0.505,  0.472,
         0.160,  0.436,  0.401, -0.299,  0.486, -0.118,  0.796,  0.614,  0.282,
        -0.191, -0.032,  0.171,  0.144,  0.792,  0.436, -0.258,  0.203,  0.116,
        -0.354, -0.303,  0.333, -0.256, -0.349, -0.166,  0.454, -0.112,  0.105,
         0.287,  0.331,  0.161,  0.113,  0.422,  0.042, -0.251, -0.315,  0.114,
        -0.199, -0.540,  0.140, -0.269, -0.055,  0.247,  0.582,  0.352,  0.189,
         0.317, -0.500,  0.284,  0.309,  0.370, -0.870,  0.033, -0.567, -0.142,
         0.822,  0.161, -0.120,  0.377, -0.013,  0.694,  0.434, -0.273,  0.062,
        -0.164,  0.068, -0.027, -0.548, -0.805, -0.495,  0.181,  0.064, -0.359,
         0.226,  0.016, -0.707, -0.181,  0.049, -0.514,  0.225, -0.039, -0.072,
        -0.762,  0.174, -0.365, -0.129, -0.022,  0.147, -0.528,  0.153,  0.420,
         0.175, -0.633,  0.042, -0.703, -0.899, -0.064, -0.107,  0.337, -0.566,
         0.208,  0.777,  0.478], device='cuda:0')
s after update for 1 param tensor([1.883, 2.060, 2.029, 1.795, 1.388, 1.525, 2.302, 1.824, 1.767, 2.167,
        2.281, 1.620, 1.402, 1.377, 2.087, 1.641, 1.564, 1.958, 1.842, 1.770,
        2.110, 1.244, 1.755, 1.986, 1.949, 2.190, 2.056, 1.855, 1.765, 1.995,
        2.003, 1.521, 0.831, 1.498, 2.037, 2.185, 1.283, 1.823, 1.399, 2.063,
        1.642, 1.851, 1.820, 1.323, 2.365, 1.665, 1.870, 2.286, 2.095, 1.523,
        1.937, 1.797, 1.684, 2.121, 2.033, 2.169, 2.000, 1.984, 2.039, 1.901,
        1.745, 1.960, 1.193, 1.828, 1.530, 1.681, 1.965, 1.417, 1.771, 1.653,
        1.909, 1.875, 1.295, 1.758, 1.575, 1.565, 2.249, 1.440, 1.920, 2.062,
        1.739, 1.849, 1.827, 2.079, 1.833, 1.531, 1.718, 2.042, 1.319, 1.551,
        1.614, 2.071, 1.242, 1.185, 1.499, 1.623, 1.498, 1.775, 1.770, 1.601,
        2.178, 2.070, 1.414, 1.771, 1.157, 1.865, 1.968, 1.866, 1.930, 2.579,
        1.957, 1.378, 1.316, 2.291, 1.199, 2.242, 2.304, 1.604, 1.745, 1.596,
        1.693, 2.059, 1.755, 1.902, 1.585, 1.647, 1.431, 1.784, 1.988, 1.324,
        1.779, 2.187, 1.720, 1.900, 1.822, 1.566, 1.917, 1.419, 0.984, 1.740,
        2.112, 1.538, 1.721, 1.723, 2.122, 2.195, 1.311, 2.043, 1.413, 1.873,
        1.868, 1.563, 2.171, 1.667, 1.568, 1.864, 2.187, 2.183, 1.600, 1.758,
        1.435, 1.523, 1.230, 1.526, 0.994, 1.687, 1.501, 1.837, 1.872, 1.607,
        1.939, 1.940, 1.797, 1.423, 1.275, 1.855, 1.491, 1.471, 1.697, 1.355,
        1.830, 1.828, 2.242, 1.408, 1.723, 1.111, 1.366, 1.214, 1.909, 1.754,
        1.933, 1.675, 2.481, 2.028, 1.983, 2.322, 1.747, 1.507, 1.580, 1.681,
        1.793, 2.157, 1.997, 1.834, 2.011, 1.663, 1.784, 1.673, 1.933, 1.279,
        1.757, 2.035, 1.733, 2.040, 1.300, 1.324, 1.621, 0.764, 1.446, 2.230,
        2.064, 2.341, 2.082, 1.514, 1.980, 2.064, 1.865, 1.677, 1.763, 1.580,
        1.949, 1.678, 1.341, 1.608, 1.965, 1.246, 2.094, 1.691, 2.014, 2.061,
        2.162, 2.124, 1.471, 1.976, 1.976, 1.903, 2.303, 1.517, 1.858, 2.115,
        1.789, 1.768, 1.668, 1.775, 1.787, 2.014, 1.833, 1.715, 1.545, 1.508,
        1.789, 1.358, 2.010, 1.736, 1.656, 1.525, 1.987, 1.046, 2.341, 1.684,
        1.730, 2.010, 1.191, 2.095, 1.656, 1.653, 1.755, 1.133, 1.395, 1.904,
        1.697, 1.389, 1.915, 1.550, 2.452, 1.434, 1.801, 1.674, 1.498, 2.136,
        1.891, 1.564, 1.880, 2.031, 1.556, 1.195, 1.713, 1.606, 1.856, 1.396],
       device='cuda:0')
b after update for 1 param tensor([182.852, 191.250, 189.839, 178.561, 157.006, 164.563, 202.201, 180.003,
        177.163, 196.164, 201.249, 169.614, 157.785, 156.359, 192.527, 170.719,
        166.642, 186.462, 180.862, 177.280, 193.581, 148.645, 176.564, 187.798,
        186.025, 197.237, 191.084, 181.485, 177.054, 188.214, 188.623, 164.377,
        121.470, 163.095, 190.203, 196.980, 150.970, 179.917, 157.649, 191.399,
        170.786, 181.298, 179.762, 153.293, 204.959, 171.950, 182.253, 201.488,
        192.902, 164.487, 185.467, 178.667, 172.938, 194.065, 189.996, 196.247,
        188.459, 187.709, 190.299, 183.763, 176.044, 186.567, 145.537, 180.160,
        164.839, 172.785, 186.819, 158.634, 177.343, 171.338, 184.135, 182.492,
        151.633, 176.695, 167.239, 166.695, 199.838, 159.928, 184.641, 191.360,
        175.726, 181.225, 180.109, 192.152, 180.435, 164.918, 174.694, 190.426,
        153.026, 165.942, 169.321, 191.793, 148.495, 145.082, 163.134, 169.769,
        163.091, 177.555, 177.276, 168.630, 196.664, 191.716, 158.465, 177.363,
        143.330, 181.989, 186.952, 182.045, 185.118, 214.017, 186.419, 156.447,
        152.855, 201.719, 145.922, 199.520, 202.266, 168.769, 176.033, 168.338,
        173.419, 191.232, 176.526, 183.803, 167.787, 171.030, 159.441, 178.003,
        187.880, 153.333, 177.765, 197.073, 174.794, 183.674, 179.883, 166.751,
        184.500, 158.745, 132.194, 175.769, 193.664, 165.267, 174.851, 174.922,
        194.113, 197.422, 152.616, 190.490, 158.408, 182.373, 182.124, 166.589,
        196.346, 172.062, 166.871, 181.965, 197.090, 196.914, 168.549, 176.673,
        159.663, 164.441, 147.790, 164.637, 132.869, 173.067, 163.250, 180.607,
        182.349, 168.945, 185.565, 185.641, 178.620, 158.954, 150.486, 181.505,
        162.706, 161.643, 173.621, 155.103, 180.277, 180.198, 199.562, 158.151,
        174.912, 140.452, 155.734, 146.820, 184.108, 176.503, 185.267, 172.468,
        209.906, 189.782, 187.651, 203.061, 176.134, 163.604, 167.494, 172.793,
        178.451, 195.727, 188.335, 180.498, 188.964, 171.834, 177.996, 172.353,
        185.266, 150.743, 176.628, 190.094, 175.437, 190.349, 151.954, 153.318,
        169.672, 116.455, 160.251, 198.993, 191.468, 203.900, 192.289, 163.988,
        187.527, 191.463, 181.993, 172.579, 176.970, 167.510, 186.052, 172.616,
        154.328, 169.006, 186.791, 148.779, 192.824, 173.299, 189.135, 191.308,
        195.931, 194.236, 161.606, 187.329, 187.315, 183.856, 202.235, 164.152,
        181.652, 193.788, 178.222, 177.190, 172.097, 177.545, 178.140, 189.106,
        180.443, 174.529, 165.652, 163.656, 178.268, 155.315, 188.950, 175.564,
        171.517, 164.585, 187.845, 136.324, 203.916, 172.960, 175.302, 188.941,
        145.446, 192.900, 171.504, 171.320, 176.528, 141.857, 157.420, 183.881,
        173.586, 157.041, 184.423, 165.905, 208.683, 159.570, 178.826, 172.418,
        163.133, 194.774, 183.275, 166.640, 182.739, 189.922, 166.252, 145.703,
        174.399, 168.878, 181.537, 157.450], device='cuda:0')
clipping threshold 2.030823203077907
a after update for 1 param tensor([[[-0.033],
         [ 0.560],
         [-0.076],
         [ 0.184],
         [ 0.103],
         [-0.118],
         [-0.482],
         [ 0.062],
         [ 0.118],
         [ 0.526]],

        [[ 0.112],
         [-0.515],
         [ 1.019],
         [-0.461],
         [ 0.263],
         [-0.091],
         [ 0.077],
         [-0.181],
         [-0.478],
         [ 0.389]],

        [[-0.351],
         [ 0.135],
         [ 0.520],
         [ 0.622],
         [ 0.158],
         [ 0.231],
         [ 0.121],
         [ 0.084],
         [-0.392],
         [-0.290]],

        [[-0.012],
         [-0.630],
         [-0.584],
         [ 0.596],
         [-0.139],
         [ 0.564],
         [ 0.030],
         [ 0.191],
         [ 0.333],
         [ 0.086]],

        [[ 0.332],
         [-0.688],
         [ 0.188],
         [ 0.163],
         [ 0.234],
         [ 0.454],
         [-0.155],
         [-0.021],
         [ 0.080],
         [ 0.389]],

        [[-0.064],
         [-0.448],
         [ 0.008],
         [-0.069],
         [-0.309],
         [-0.541],
         [-0.312],
         [-0.379],
         [-0.027],
         [-0.376]],

        [[-0.321],
         [ 0.196],
         [-0.259],
         [-0.309],
         [ 0.542],
         [ 0.243],
         [ 0.395],
         [-0.137],
         [-0.254],
         [ 0.139]],

        [[-0.091],
         [ 0.358],
         [ 0.107],
         [-0.474],
         [ 0.077],
         [-0.479],
         [-0.313],
         [ 0.319],
         [-0.581],
         [ 0.197]],

        [[-0.075],
         [ 0.177],
         [-0.498],
         [-0.118],
         [ 0.286],
         [ 0.995],
         [ 0.136],
         [ 0.358],
         [-0.116],
         [-0.126]],

        [[ 0.146],
         [ 0.353],
         [ 0.121],
         [ 0.575],
         [ 0.571],
         [ 0.153],
         [ 0.182],
         [-0.007],
         [ 0.272],
         [ 0.768]],

        [[ 0.572],
         [-0.446],
         [ 0.654],
         [-0.275],
         [-0.103],
         [ 0.306],
         [ 0.097],
         [-0.172],
         [ 0.248],
         [ 0.574]],

        [[-0.430],
         [-0.243],
         [ 0.219],
         [ 0.350],
         [-0.330],
         [-0.045],
         [ 0.012],
         [ 0.849],
         [ 0.692],
         [-0.417]],

        [[-0.077],
         [ 0.644],
         [-0.284],
         [ 0.548],
         [ 0.311],
         [-0.342],
         [-0.221],
         [ 0.558],
         [ 0.400],
         [-0.303]],

        [[ 0.453],
         [ 0.382],
         [-0.099],
         [-0.092],
         [ 0.346],
         [ 0.245],
         [ 0.550],
         [ 0.171],
         [-0.272],
         [-0.391]],

        [[-0.392],
         [ 0.111],
         [-0.287],
         [-0.434],
         [-0.069],
         [-0.131],
         [ 0.480],
         [ 0.741],
         [ 0.131],
         [-0.116]],

        [[ 0.672],
         [-0.087],
         [-0.050],
         [ 0.240],
         [-0.513],
         [ 0.279],
         [-0.312],
         [ 0.369],
         [ 0.033],
         [ 0.034]],

        [[ 1.275],
         [-0.174],
         [-0.359],
         [ 0.136],
         [ 0.605],
         [ 0.472],
         [ 0.196],
         [-0.005],
         [-0.495],
         [ 0.086]],

        [[-0.177],
         [-0.015],
         [ 0.022],
         [-0.286],
         [-0.161],
         [ 0.356],
         [ 0.650],
         [-0.477],
         [ 0.351],
         [-0.629]],

        [[-0.254],
         [ 0.179],
         [-0.182],
         [-0.154],
         [ 0.125],
         [ 0.393],
         [ 0.810],
         [ 0.030],
         [-0.002],
         [ 0.733]],

        [[ 0.155],
         [ 0.152],
         [-0.012],
         [ 0.464],
         [-0.075],
         [ 0.138],
         [ 0.152],
         [-0.162],
         [-0.370],
         [ 0.350]],

        [[-0.141],
         [ 0.276],
         [ 0.505],
         [-0.133],
         [ 0.193],
         [ 0.282],
         [-0.207],
         [ 0.111],
         [-0.063],
         [ 0.493]],

        [[-0.831],
         [ 0.162],
         [ 0.233],
         [-0.358],
         [ 0.060],
         [-0.334],
         [-0.209],
         [-0.200],
         [ 0.023],
         [-0.534]],

        [[-0.088],
         [ 0.495],
         [ 0.100],
         [ 0.128],
         [ 0.030],
         [-0.324],
         [-0.090],
         [-0.245],
         [ 0.598],
         [ 0.015]],

        [[ 0.810],
         [ 0.208],
         [-0.256],
         [ 0.449],
         [-0.244],
         [-0.259],
         [-0.345],
         [-0.483],
         [-0.645],
         [ 0.633]],

        [[-0.271],
         [ 0.170],
         [ 0.343],
         [ 0.318],
         [ 0.236],
         [ 0.051],
         [-0.284],
         [-0.390],
         [ 0.114],
         [-0.192]],

        [[-0.258],
         [ 0.113],
         [-0.663],
         [-0.340],
         [ 0.151],
         [-0.447],
         [ 0.074],
         [-0.315],
         [ 0.005],
         [ 0.500]],

        [[ 0.022],
         [ 0.196],
         [-0.063],
         [-0.322],
         [ 0.116],
         [-0.307],
         [ 0.103],
         [-0.536],
         [-0.532],
         [ 0.578]],

        [[-0.326],
         [ 0.054],
         [-1.025],
         [ 0.656],
         [-0.095],
         [-0.542],
         [-0.463],
         [ 0.082],
         [-0.486],
         [ 0.874]],

        [[-0.482],
         [ 0.062],
         [-0.159],
         [-0.083],
         [ 0.172],
         [-0.163],
         [-0.578],
         [ 0.319],
         [ 0.072],
         [ 0.265]],

        [[-0.180],
         [-0.236],
         [-0.051],
         [ 0.194],
         [ 0.508],
         [-0.296],
         [ 0.762],
         [ 0.133],
         [ 0.043],
         [ 0.134]]], device='cuda:0')
s after update for 1 param tensor([[[1.714],
         [1.662],
         [1.524],
         [1.930],
         [1.893],
         [2.130],
         [1.453],
         [1.470],
         [1.694],
         [1.772]],

        [[1.664],
         [1.777],
         [1.993],
         [1.512],
         [1.465],
         [2.192],
         [2.276],
         [2.018],
         [1.958],
         [1.540]],

        [[1.527],
         [1.541],
         [1.968],
         [1.706],
         [1.777],
         [2.023],
         [1.435],
         [2.001],
         [0.695],
         [1.772]],

        [[2.014],
         [1.588],
         [1.172],
         [1.191],
         [1.980],
         [1.183],
         [1.722],
         [2.069],
         [1.824],
         [1.313]],

        [[1.568],
         [1.463],
         [1.770],
         [1.812],
         [1.287],
         [1.683],
         [1.753],
         [1.847],
         [1.682],
         [1.414]],

        [[2.118],
         [1.098],
         [2.035],
         [1.508],
         [1.985],
         [2.111],
         [1.978],
         [1.666],
         [1.886],
         [2.013]],

        [[1.859],
         [1.635],
         [2.051],
         [2.419],
         [1.884],
         [1.284],
         [1.817],
         [1.224],
         [1.813],
         [0.857]],

        [[1.126],
         [1.540],
         [1.502],
         [1.699],
         [1.522],
         [1.802],
         [1.834],
         [1.850],
         [1.516],
         [1.720]],

        [[2.100],
         [1.666],
         [1.605],
         [2.243],
         [1.978],
         [2.192],
         [1.780],
         [1.860],
         [1.515],
         [1.787]],

        [[1.728],
         [1.836],
         [1.634],
         [0.929],
         [1.651],
         [1.503],
         [1.728],
         [1.874],
         [2.029],
         [2.166]],

        [[2.231],
         [1.450],
         [1.892],
         [1.186],
         [1.616],
         [1.732],
         [2.215],
         [2.130],
         [2.404],
         [1.765]],

        [[2.427],
         [1.549],
         [1.571],
         [1.248],
         [1.560],
         [2.211],
         [1.763],
         [1.730],
         [1.972],
         [1.623]],

        [[1.500],
         [1.445],
         [2.088],
         [1.553],
         [1.694],
         [1.162],
         [1.281],
         [1.923],
         [2.162],
         [2.012]],

        [[1.736],
         [1.332],
         [1.521],
         [1.854],
         [1.977],
         [2.370],
         [1.895],
         [1.496],
         [2.029],
         [1.615]],

        [[1.981],
         [1.568],
         [2.227],
         [2.049],
         [1.342],
         [2.198],
         [1.274],
         [1.654],
         [1.943],
         [1.919]],

        [[1.683],
         [2.032],
         [1.773],
         [1.936],
         [1.417],
         [1.457],
         [1.622],
         [1.255],
         [2.036],
         [1.703]],

        [[1.194],
         [1.773],
         [1.680],
         [1.395],
         [2.166],
         [1.999],
         [1.619],
         [1.866],
         [2.581],
         [2.219]],

        [[1.418],
         [1.592],
         [1.660],
         [2.051],
         [1.341],
         [1.889],
         [2.246],
         [1.528],
         [2.088],
         [1.923]],

        [[1.294],
         [2.181],
         [1.607],
         [2.184],
         [2.050],
         [1.680],
         [1.782],
         [0.965],
         [1.643],
         [1.812]],

        [[1.365],
         [1.863],
         [1.711],
         [2.074],
         [1.992],
         [1.677],
         [1.980],
         [1.081],
         [0.806],
         [1.055]],

        [[1.979],
         [1.758],
         [1.946],
         [2.032],
         [2.257],
         [1.644],
         [1.888],
         [1.277],
         [1.735],
         [2.099]],

        [[1.616],
         [1.749],
         [2.124],
         [1.704],
         [2.090],
         [2.064],
         [1.691],
         [1.267],
         [1.772],
         [1.778]],

        [[1.609],
         [1.800],
         [1.415],
         [1.403],
         [1.176],
         [1.720],
         [1.767],
         [1.185],
         [2.137],
         [1.866]],

        [[1.518],
         [2.228],
         [1.541],
         [2.259],
         [2.244],
         [2.202],
         [1.388],
         [2.017],
         [1.321],
         [1.712]],

        [[1.865],
         [1.821],
         [0.945],
         [1.557],
         [2.006],
         [1.077],
         [2.048],
         [1.598],
         [1.769],
         [1.916]],

        [[1.532],
         [2.248],
         [1.532],
         [1.339],
         [1.871],
         [1.647],
         [1.427],
         [2.075],
         [1.053],
         [2.110]],

        [[2.068],
         [1.433],
         [2.190],
         [2.445],
         [1.718],
         [1.944],
         [1.651],
         [1.591],
         [2.135],
         [1.983]],

        [[1.689],
         [1.692],
         [1.976],
         [1.951],
         [1.769],
         [2.299],
         [1.871],
         [2.042],
         [1.670],
         [1.872]],

        [[1.980],
         [1.350],
         [1.913],
         [2.161],
         [2.376],
         [1.969],
         [1.869],
         [1.681],
         [1.754],
         [1.379]],

        [[2.226],
         [2.352],
         [2.029],
         [1.662],
         [1.505],
         [1.519],
         [1.745],
         [2.026],
         [1.585],
         [1.308]]], device='cuda:0')
b after update for 1 param tensor([[[174.446],
         [171.818],
         [164.536],
         [185.155],
         [183.346],
         [194.485],
         [160.657],
         [161.575],
         [173.456],
         [177.388]],

        [[171.920],
         [177.659],
         [188.148],
         [163.872],
         [161.290],
         [197.298],
         [201.057],
         [189.293],
         [186.454],
         [165.363]],

        [[164.659],
         [165.440],
         [186.965],
         [174.085],
         [177.669],
         [189.556],
         [159.622],
         [188.516],
         [111.094],
         [177.394]],

        [[189.112],
         [167.926],
         [144.291],
         [145.423],
         [187.537],
         [144.974],
         [174.900],
         [191.680],
         [179.989],
         [152.730]],

        [[166.881],
         [161.181],
         [177.277],
         [179.403],
         [151.203],
         [172.911],
         [176.454],
         [181.109],
         [172.809],
         [158.488]],

        [[193.940],
         [139.633],
         [190.094],
         [163.639],
         [187.766],
         [193.628],
         [187.424],
         [172.026],
         [183.000],
         [189.059]],

        [[181.719],
         [170.384],
         [190.861],
         [207.259],
         [182.931],
         [150.984],
         [179.623],
         [147.429],
         [179.427],
         [123.387]],

        [[141.410],
         [165.397],
         [163.347],
         [173.728],
         [164.402],
         [178.897],
         [180.464],
         [181.252],
         [164.090],
         [174.793]],

        [[193.134],
         [172.027],
         [168.854],
         [199.596],
         [187.427],
         [197.311],
         [177.814],
         [181.761],
         [164.020],
         [178.143]],

        [[175.190],
         [180.590],
         [170.331],
         [128.430],
         [171.211],
         [163.371],
         [175.203],
         [182.449],
         [189.832],
         [196.153]],

        [[199.049],
         [160.486],
         [183.317],
         [145.100],
         [169.402],
         [175.363],
         [198.315],
         [194.503],
         [206.617],
         [177.054]],

        [[207.602],
         [165.876],
         [167.056],
         [148.847],
         [166.473],
         [198.154],
         [176.955],
         [175.289],
         [187.125],
         [169.758]],

        [[163.201],
         [160.213],
         [192.564],
         [166.074],
         [173.467],
         [143.651],
         [150.811],
         [184.812],
         [195.971],
         [189.013]],

        [[175.589],
         [153.788],
         [164.344],
         [181.436],
         [187.359],
         [205.173],
         [183.431],
         [162.989],
         [189.814],
         [169.382]],

        [[187.567],
         [166.888],
         [198.887],
         [190.783],
         [154.360],
         [197.581],
         [150.395],
         [171.375],
         [185.739],
         [184.596]],

        [[172.862],
         [189.974],
         [177.437],
         [185.425],
         [158.649],
         [160.849],
         [169.706],
         [149.307],
         [190.144],
         [173.895]],

        [[145.613],
         [177.441],
         [172.742],
         [157.422],
         [196.132],
         [188.429],
         [169.558],
         [182.044],
         [214.079],
         [198.498]],

        [[158.680],
         [168.164],
         [171.701],
         [190.851],
         [154.343],
         [183.173],
         [199.708],
         [164.727],
         [192.577],
         [184.808]],

        [[151.603],
         [196.828],
         [168.956],
         [196.923],
         [190.796],
         [172.747],
         [177.908],
         [130.885],
         [170.819],
         [179.409]],

        [[155.719],
         [181.873],
         [174.337],
         [191.913],
         [188.091],
         [172.561],
         [187.504],
         [138.526],
         [119.627],
         [136.851]],

        [[187.452],
         [176.710],
         [185.917],
         [189.945],
         [200.191],
         [170.856],
         [183.129],
         [150.579],
         [175.537],
         [193.069]],

        [[169.423],
         [176.263],
         [194.206],
         [173.944],
         [192.669],
         [191.462],
         [173.320],
         [150.029],
         [177.404],
         [177.721]],

        [[169.063],
         [178.793],
         [158.505],
         [157.856],
         [144.492],
         [174.796],
         [177.153],
         [145.098],
         [194.799],
         [182.038]],

        [[164.193],
         [198.907],
         [165.424],
         [200.318],
         [199.623],
         [197.766],
         [157.021],
         [189.256],
         [153.141],
         [174.389]],

        [[181.991],
         [179.846],
         [129.519],
         [166.275],
         [188.764],
         [138.273],
         [190.705],
         [168.475],
         [177.254],
         [184.485]],

        [[164.935],
         [199.794],
         [164.943],
         [154.198],
         [182.308],
         [171.022],
         [159.196],
         [191.953],
         [136.757],
         [193.578]],

        [[191.655],
         [159.547],
         [197.234],
         [208.377],
         [174.682],
         [185.794],
         [171.212],
         [168.071],
         [194.706],
         [187.686]],

        [[173.171],
         [173.333],
         [187.321],
         [186.148],
         [177.249],
         [202.042],
         [182.289],
         [190.415],
         [172.200],
         [182.338]],

        [[187.539],
         [154.832],
         [184.310],
         [195.892],
         [205.421],
         [186.989],
         [182.192],
         [172.766],
         [176.502],
         [156.496]],

        [[198.840],
         [204.368],
         [189.813],
         [171.803],
         [163.498],
         [164.254],
         [176.059],
         [189.671],
         [167.760],
         [152.396]]], device='cuda:0')
clipping threshold 2.030823203077907
a after update for 1 param tensor([[-0.222],
        [-0.329],
        [-0.425],
        [-0.158],
        [-0.090],
        [ 0.165],
        [ 0.279],
        [-0.069],
        [ 0.032],
        [ 0.249],
        [-0.216],
        [ 0.463],
        [-0.290],
        [-0.145],
        [-0.052],
        [-0.156],
        [-0.540],
        [-0.144],
        [ 0.158],
        [ 0.363],
        [ 0.264],
        [ 0.457],
        [ 0.448],
        [-0.272],
        [-0.002],
        [ 0.333],
        [-0.124],
        [-0.436],
        [ 0.682],
        [-0.088]], device='cuda:0')
s after update for 1 param tensor([[2.100],
        [2.050],
        [1.547],
        [2.269],
        [2.361],
        [1.843],
        [1.503],
        [1.495],
        [1.812],
        [1.711],
        [1.184],
        [1.739],
        [1.652],
        [1.745],
        [1.808],
        [1.998],
        [1.330],
        [1.685],
        [1.804],
        [1.884],
        [1.834],
        [1.617],
        [1.777],
        [1.788],
        [2.435],
        [1.180],
        [1.921],
        [1.763],
        [1.484],
        [2.034]], device='cuda:0')
b after update for 1 param tensor([[193.110],
        [190.791],
        [165.772],
        [200.756],
        [204.751],
        [180.901],
        [163.386],
        [162.964],
        [179.381],
        [174.336],
        [144.988],
        [175.723],
        [171.292],
        [176.023],
        [179.180],
        [188.382],
        [153.686],
        [172.982],
        [179.002],
        [182.911],
        [180.456],
        [169.487],
        [177.654],
        [178.177],
        [207.938],
        [144.765],
        [184.700],
        [176.934],
        [162.316],
        [190.074]], device='cuda:0')
clipping threshold 2.030823203077907
cuda
Objective function 108.15 = squared loss an data 73.66 + 0.5*rho*h**2 25.508651 + alpha*h 5.226551 + L2reg 3.38 + L1reg 0.38 ; SHD = 172 ; DAG True
Proportion of microbatches that were clipped  0.7840682561199266
iteration 3 in inner loop, alpha 73.17394581039075 rho 10000.0 h 0.07142639703737785
iteration 3 in outer loop, alpha = 787.4379161841692, rho = 10000.0, h = 0.07142639703737785
cuda
9630
cuda
Objective function 159.17 = squared loss an data 73.66 + 0.5*rho*h**2 25.508651 + alpha*h 56.243853 + L2reg 3.38 + L1reg 0.38 ; SHD = 172 ; DAG True
||w||^2 2580562783490.449
exp ma of ||w||^2 799972397693.1721
||w|| 1606413.017716941
exp ma of ||w|| 432250.0822869153
||w||^2 6.1224481204452195
exp ma of ||w||^2 927.1898054062947
||w|| 2.4743581229169758
exp ma of ||w|| 3.098439519264543
||w||^2 5.949523056633192
exp ma of ||w||^2 7.581190739015298
||w|| 2.4391644177121785
exp ma of ||w|| 2.6909462220780895
||w||^2 5.5574497976326835
exp ma of ||w||^2 7.333182683402576
||w|| 2.3574243991340813
exp ma of ||w|| 2.6615766036483532
||w||^2 7.5313590778542165
exp ma of ||w||^2 7.824858071783027
||w|| 2.744332173381024
exp ma of ||w|| 2.7455785567340527
||w||^2 8.195835394812308
exp ma of ||w||^2 8.549217757652615
||w|| 2.862836948694827
exp ma of ||w|| 2.867089563309869
||w||^2 7.1868448442357185
exp ma of ||w||^2 8.513984712643234
||w|| 2.6808291337263026
exp ma of ||w|| 2.850218195206148
||w||^2 5.581210188984859
exp ma of ||w||^2 8.047537250965956
||w|| 2.362458505240856
exp ma of ||w|| 2.7834318559967874
||w||^2 8.434185175497186
exp ma of ||w||^2 7.9164696164686115
||w|| 2.9041668642654104
exp ma of ||w|| 2.7588399045706478
||w||^2 4.612640880573727
exp ma of ||w||^2 7.54713760346281
||w|| 2.147705957661273
exp ma of ||w|| 2.6947642111619072
||w||^2 5.664069000055945
exp ma of ||w||^2 8.633017292935282
||w|| 2.379930461180735
exp ma of ||w|| 2.8865918901301604
cuda
Objective function 126.10 = squared loss an data 73.71 + 0.5*rho*h**2 11.236525 + alpha*h 37.329084 + L2reg 3.45 + L1reg 0.37 ; SHD = 167 ; DAG True
Proportion of microbatches that were clipped  0.786049098275999
iteration 1 in inner loop, alpha 787.4379161841692 rho 10000.0 h 0.047405748955696936
9630
cuda
Objective function 227.23 = squared loss an data 73.71 + 0.5*rho*h**2 112.365252 + alpha*h 37.329084 + L2reg 3.45 + L1reg 0.37 ; SHD = 167 ; DAG True
||w||^2 24.942320848797827
exp ma of ||w||^2 83463.00273799912
||w|| 4.994228754151919
exp ma of ||w|| 4.6521969952839175
||w||^2 13.5231113243744
exp ma of ||w||^2 88.48313822734266
||w|| 3.677378322171163
exp ma of ||w|| 3.430048318409306
||w||^2 10.79551779583546
exp ma of ||w||^2 9.357536133043304
||w|| 3.285653328614487
exp ma of ||w|| 3.0103819448667184
||w||^2 10.565285969405426
exp ma of ||w||^2 9.611930555950991
||w|| 3.2504285824188517
exp ma of ||w|| 3.049563276947821
||w||^2 16.986880471238088
exp ma of ||w||^2 9.699281926820188
||w|| 4.1215143419910705
exp ma of ||w|| 3.0638377560403907
v before min max tensor([[ 4924.078,  3952.606, -1467.195,  ..., -1566.334,   187.007,
          -719.296],
        [14976.425, -1743.938,  4702.706,  ..., -1502.732,  -913.061,
          2605.844],
        [  368.298,  -709.443,  -439.612,  ...,  -677.795,   989.812,
          -859.193],
        ...,
        [  814.394,  5822.955,   614.689,  ..., -1125.557,  -935.792,
          -836.546],
        [-1318.095, -1713.349,   -44.728,  ...,  -958.977,  3983.394,
           514.343],
        [ 7216.985, -1407.140,  9112.045,  ...,  4309.443, -1162.564,
          -936.854]], device='cuda:0')
v tensor([[1.000e+01, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e+01],
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         1.000e-12],
        ...,
        [1.000e+01, 1.000e+01, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         1.000e+01],
        [1.000e+01, 1.000e-12, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([ 2.064e+03, -1.205e+03,  8.843e+02, -8.201e+02,  9.360e+02, -1.370e+03,
        -1.033e+03, -7.580e+02, -1.345e+03,  3.598e+03,  9.987e+02, -9.088e+02,
         2.519e+03, -1.220e+03,  2.714e+03,  1.097e+03, -9.459e+02, -8.363e+02,
         5.075e+03, -3.254e+02, -5.741e+02, -1.346e+02, -5.603e+01, -9.808e+02,
        -6.044e+02, -1.070e+03, -5.871e+02,  1.203e+03, -9.062e+00,  6.796e+02,
         1.954e+04, -6.506e+02, -1.194e+02,  1.993e+03, -7.480e+02, -6.963e+02,
         8.908e+03, -1.845e+03, -8.259e+02,  1.462e+04,  3.246e+02,  7.728e+03,
        -1.715e+03, -1.215e+03,  1.273e+02, -1.018e+03,  3.978e+03,  1.892e+02,
        -1.664e+01, -7.877e+02, -6.288e+01, -1.407e+03, -1.795e+03, -1.887e+03,
        -1.535e+03, -9.935e+02,  4.912e+02,  5.585e+03,  4.453e+03, -1.474e+03,
        -4.359e+02,  5.547e+03,  3.356e+03, -1.067e+03, -1.528e+03, -1.510e+03,
         7.707e+02, -1.202e+03, -1.033e+03, -1.360e+03, -3.977e+02, -1.018e+03,
         8.978e+00, -1.345e+03,  7.714e+03, -1.290e+03,  2.752e+03, -1.087e+03,
        -1.088e+03, -6.365e+02, -9.293e+02, -1.275e+03, -4.997e+02,  3.622e+02,
         1.200e+04,  6.418e+02,  1.475e+04,  9.286e+02, -1.087e+03, -2.960e+02,
        -1.560e+03, -1.335e+03, -1.018e+03, -9.290e+02, -8.443e+02, -1.231e+03,
         3.554e+03, -1.358e+03,  2.421e+04, -1.378e+03, -1.380e+03, -1.330e+03,
         5.521e+03,  1.031e+03,  9.792e+02,  1.893e+02,  2.357e+02, -1.431e+03,
         2.535e+03, -6.282e+02, -4.224e+02,  5.852e+03, -1.125e+03,  7.426e+02,
        -3.531e+02, -1.279e+03, -3.212e+02, -1.223e+03, -1.059e+03, -1.090e+03,
         1.387e+04, -3.772e+02,  2.415e+03,  4.841e+03, -1.072e+03, -1.232e+03,
        -1.173e+03, -3.220e+02, -1.261e+03, -1.515e+03,  4.975e+02,  1.100e+03,
        -1.736e+03, -1.218e+03,  9.017e+03,  5.813e+02, -1.685e+03, -1.267e+03,
        -1.313e+03, -4.792e+02,  2.251e+03, -1.065e+03, -1.176e+03, -1.313e+03,
         2.430e+03, -1.447e+03,  2.232e+03, -1.165e+03, -5.760e+02, -1.396e+03,
        -8.847e+02, -1.050e+03, -1.322e+03,  3.152e+03, -1.684e+02, -7.418e+02,
         4.232e+02, -1.435e+03, -8.643e+02, -1.534e+03, -1.352e+03, -6.282e+02,
         2.150e+03, -6.810e+02,  1.739e+03, -1.257e+03, -1.274e+03,  7.509e+02,
         8.115e+02, -6.294e+02,  5.823e+02, -1.236e+03,  2.520e+03, -1.191e+03,
        -1.495e+03,  2.272e+02, -1.269e+03,  1.540e+03, -1.278e+03, -7.939e+02,
        -1.024e+03,  8.534e+02, -1.354e+02, -9.904e+02, -1.230e+03,  3.743e+03,
        -7.704e+02, -7.492e+02,  1.205e+03,  5.603e+03, -6.734e+02, -1.338e+03,
        -9.335e+02, -1.232e+03, -1.260e+03,  1.312e+04, -1.155e+03, -6.295e+02,
        -4.645e+02,  4.353e+03,  7.338e+02, -4.872e+02,  1.457e+03,  1.376e+03,
         6.336e+03, -1.480e+03,  3.360e+03, -1.129e+03,  1.414e+01,  4.128e+03,
         6.815e+02, -2.533e+02,  7.248e+03,  3.240e+03, -1.053e+03,  6.439e+03,
        -1.674e+03, -1.439e+03, -4.717e+02,  4.823e+03,  2.406e+03, -4.239e+01,
        -1.478e+03, -5.731e+02,  7.966e+03,  8.395e+03, -1.324e+03, -1.447e+03,
         3.605e+03, -1.280e+03,  5.592e+03, -6.750e+02, -6.617e+02, -1.036e+03,
        -2.113e+02,  2.923e+03,  2.022e+02,  1.084e+03,  1.799e+03,  5.788e+02,
        -1.672e+03, -1.024e+03, -4.125e+02,  1.442e+04,  2.705e+03,  5.995e+02,
        -4.810e+02,  4.138e+02, -5.475e+02,  1.647e+02, -8.121e+02,  2.245e+03,
        -9.502e+02, -1.081e+03,  8.049e+02,  2.791e+03, -1.305e+03,  1.076e+02,
        -8.762e+02, -1.700e+03,  1.701e+03,  1.478e+02,  1.398e+03, -1.142e+03,
         3.578e+03, -8.941e+02,  3.701e+03, -1.687e+03,  7.261e+02,  1.717e+03,
        -1.196e+03, -1.069e+03,  4.787e+03,  4.634e+02,  2.032e+02,  2.745e+03,
        -1.322e+03,  2.125e+03, -1.596e+02, -1.195e+03, -5.360e+02,  1.285e+03,
         3.403e+03,  6.926e+03, -2.773e+02, -1.598e+03,  2.993e+03, -9.741e+02,
        -6.020e+02, -1.230e+03, -1.023e+03, -1.581e+03, -1.204e+03, -1.189e+03,
        -1.205e+03,  6.593e+02, -6.265e+02, -1.576e+03,  1.199e+03, -1.274e+03],
       device='cuda:0')
v tensor([1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        8.978e+00, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-1.423e+03],
         [ 2.684e+03],
         [ 5.383e+03],
         [ 2.418e+02],
         [-1.585e+03],
         [-1.071e+03],
         [-6.938e+02],
         [ 3.014e+02],
         [ 2.657e+02],
         [-4.701e+02]],

        [[ 3.892e+02],
         [ 7.970e+02],
         [-1.045e+03],
         [-1.108e+02],
         [-3.229e+02],
         [ 7.577e+01],
         [ 2.188e+03],
         [ 9.214e+03],
         [ 4.257e+03],
         [-4.671e+02]],

        [[ 6.757e+02],
         [-1.093e+03],
         [-1.072e+03],
         [ 3.561e+03],
         [ 2.733e+03],
         [ 2.591e+03],
         [-1.644e+03],
         [-7.309e+02],
         [-3.327e+02],
         [ 2.034e+03]],

        [[-1.279e+03],
         [-1.323e+03],
         [ 5.333e+03],
         [ 4.077e+03],
         [-8.789e+02],
         [-9.719e+02],
         [-1.551e+03],
         [ 8.964e+02],
         [-1.005e+03],
         [-8.211e+02]],

        [[ 5.042e+03],
         [-1.262e+03],
         [-3.322e+02],
         [-1.537e+03],
         [-1.746e+03],
         [-1.004e+03],
         [-9.218e+02],
         [-1.242e+03],
         [-1.475e+03],
         [-5.558e+02]],

        [[ 1.435e+04],
         [ 2.991e+03],
         [ 1.002e+02],
         [ 2.747e+03],
         [-7.996e+02],
         [ 4.269e+03],
         [ 9.356e+02],
         [ 6.267e+00],
         [ 2.605e+03],
         [ 5.036e+03]],

        [[-1.027e+03],
         [-1.667e+03],
         [-7.990e+02],
         [-1.256e+03],
         [ 3.230e+03],
         [ 2.391e+02],
         [-7.870e+02],
         [ 2.513e+03],
         [ 3.227e+03],
         [-7.271e+02]],

        [[ 1.981e+03],
         [ 3.207e+03],
         [-1.230e+03],
         [ 4.394e+03],
         [-4.014e+01],
         [-7.947e+02],
         [-1.145e+03],
         [-4.895e+02],
         [-1.164e+03],
         [ 1.088e+03]],

        [[-1.059e+03],
         [-1.368e+03],
         [-1.141e+03],
         [ 1.145e+03],
         [ 1.161e+03],
         [-9.454e+02],
         [-1.339e+03],
         [ 1.688e+01],
         [-1.012e+03],
         [-2.992e+02]],

        [[-8.205e+02],
         [-1.262e+03],
         [ 6.695e+03],
         [ 4.452e+03],
         [ 5.037e+02],
         [ 1.146e+04],
         [-9.983e+01],
         [ 1.146e+04],
         [-7.322e+02],
         [ 6.404e+03]],

        [[ 2.790e+03],
         [ 1.705e+03],
         [-1.350e+03],
         [ 2.621e+03],
         [-1.650e+03],
         [-1.170e+03],
         [ 2.750e+03],
         [ 3.317e+01],
         [-7.232e+02],
         [-1.124e+03]],

        [[-1.111e+03],
         [-7.010e+02],
         [-1.468e+03],
         [ 2.694e+03],
         [ 2.184e+02],
         [-6.422e+02],
         [-6.258e+02],
         [-1.227e+03],
         [ 1.839e+03],
         [-7.311e+02]],

        [[ 6.000e+03],
         [ 3.027e+02],
         [ 2.091e+03],
         [-1.424e+03],
         [ 4.891e+02],
         [ 6.483e+02],
         [-1.235e+03],
         [-1.035e+03],
         [ 1.518e+03],
         [-1.329e+02]],

        [[-2.327e+02],
         [ 3.395e+03],
         [ 7.351e+02],
         [-9.723e+02],
         [-1.213e+03],
         [-2.537e+02],
         [-4.584e+02],
         [ 1.655e+03],
         [ 4.262e+03],
         [ 1.774e+03]],

        [[-1.239e+03],
         [-1.289e+03],
         [-1.433e+03],
         [-3.370e+02],
         [ 7.644e+03],
         [ 8.733e+03],
         [-1.189e+03],
         [-9.068e+02],
         [ 3.694e+03],
         [ 3.614e+03]],

        [[-1.536e+03],
         [ 1.844e+03],
         [ 2.701e+03],
         [-2.711e+02],
         [ 1.825e+03],
         [-1.229e+03],
         [ 4.892e+03],
         [-1.450e+03],
         [-8.119e+02],
         [ 5.623e+03]],

        [[ 2.261e+03],
         [ 6.858e+02],
         [-8.062e+02],
         [-1.646e+03],
         [-1.407e+03],
         [ 5.397e+03],
         [-1.415e+03],
         [-4.073e+01],
         [-3.113e+02],
         [-4.177e+02]],

        [[ 1.637e+03],
         [ 4.527e+03],
         [ 6.783e+02],
         [-1.729e+02],
         [-4.306e+02],
         [-9.647e+02],
         [ 4.198e+02],
         [ 8.815e+02],
         [ 1.249e+03],
         [-1.434e+03]],

        [[-7.454e+02],
         [-7.741e+02],
         [-9.465e+02],
         [ 9.290e+03],
         [-1.147e+03],
         [ 2.274e+03],
         [-2.100e+02],
         [ 3.994e+03],
         [-7.331e+02],
         [-1.398e+03]],

        [[ 1.077e+03],
         [-5.263e+02],
         [-3.385e+02],
         [-1.347e+03],
         [-9.023e+02],
         [ 9.485e+02],
         [-8.051e+02],
         [-1.271e+03],
         [ 3.408e+02],
         [ 4.091e+03]],

        [[-1.664e+03],
         [-5.067e+02],
         [-1.403e+03],
         [-1.457e+03],
         [-1.370e+03],
         [-9.331e+02],
         [-7.554e+02],
         [-1.431e+03],
         [ 1.313e+01],
         [ 3.617e+03]],

        [[-3.698e+02],
         [-1.561e+03],
         [ 1.707e+03],
         [-1.552e+03],
         [-8.429e+01],
         [ 1.031e+03],
         [ 3.062e+03],
         [-1.279e+03],
         [-9.012e+02],
         [ 4.010e+03]],

        [[-6.382e+02],
         [-1.201e+03],
         [-1.203e+03],
         [-1.204e+03],
         [-6.610e+02],
         [-7.312e+02],
         [ 4.105e+03],
         [ 2.064e+02],
         [-1.875e+03],
         [-1.091e+02]],

        [[-1.159e+03],
         [ 2.136e+03],
         [-7.873e+02],
         [-8.514e+02],
         [-1.445e+03],
         [-3.675e+02],
         [-3.295e+02],
         [ 1.300e+03],
         [ 1.746e+02],
         [ 3.546e+03]],

        [[-8.620e+02],
         [-9.914e+02],
         [-8.157e+02],
         [-1.036e+03],
         [-6.118e+02],
         [ 1.090e+03],
         [ 6.090e+02],
         [-1.334e+03],
         [-1.245e+03],
         [ 1.220e+03]],

        [[-1.347e+03],
         [-1.473e+03],
         [-1.453e+03],
         [ 1.526e+03],
         [-1.415e+03],
         [-1.228e+03],
         [-8.121e+02],
         [ 2.066e+03],
         [-3.045e+02],
         [ 2.013e+03]],

        [[-7.723e+02],
         [-9.664e+02],
         [ 3.016e+02],
         [ 4.208e+03],
         [-1.626e+02],
         [ 6.907e+01],
         [ 9.798e+03],
         [-1.628e+03],
         [ 4.016e+03],
         [-8.435e+01]],

        [[-6.470e+02],
         [-1.125e+03],
         [-1.297e+03],
         [-1.459e+03],
         [-1.424e+03],
         [ 8.472e+03],
         [ 1.147e+03],
         [-1.053e+03],
         [ 5.170e+02],
         [ 1.475e+03]],

        [[ 3.069e+03],
         [-1.179e+03],
         [-1.489e+03],
         [ 3.196e+02],
         [-1.624e+03],
         [-1.821e+03],
         [-1.014e+03],
         [-1.671e+03],
         [ 7.704e+02],
         [ 1.595e+03]],

        [[ 1.585e+03],
         [ 1.197e+02],
         [-3.099e+02],
         [ 1.088e+02],
         [ 2.938e+03],
         [-4.217e+02],
         [-1.320e+03],
         [ 4.337e+03],
         [-1.604e+03],
         [-9.659e+02]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [6.267e+00],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[ -497.894],
        [ -150.776],
        [ -450.040],
        [ 1160.297],
        [ 3036.337],
        [-1033.198],
        [-1283.745],
        [ 1589.201],
        [ -802.694],
        [ -407.422],
        [ -612.614],
        [ 1685.670],
        [-1082.388],
        [-1281.428],
        [-1135.341],
        [ 1717.060],
        [-1323.474],
        [ -628.206],
        [ 3609.515],
        [-1041.440],
        [ 4808.099],
        [  255.473],
        [  537.082],
        [ 4308.069],
        [ 2144.405],
        [ -408.228],
        [  699.930],
        [ -771.306],
        [ -185.170],
        [-1652.075]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e+01],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-0.229,  0.900,  0.466,  ..., -0.848,  0.013, -0.303],
        [-0.123,  0.046,  0.007,  ..., -0.023,  0.185,  0.069],
        [-0.221, -0.049,  0.317,  ..., -0.462, -0.021,  0.446],
        ...,
        [-0.311, -0.249,  0.525,  ...,  0.578,  0.107,  0.059],
        [-0.181,  0.109,  0.396,  ..., -1.017,  0.180,  0.039],
        [-0.081, -0.080,  0.190,  ..., -0.571,  0.201,  0.009]],
       device='cuda:0')
s after update for 1 param tensor([[2.703, 2.000, 2.172,  ..., 1.960, 1.704, 1.394],
        [2.095, 2.296, 1.832,  ..., 1.867, 1.166, 1.799],
        [2.656, 1.469, 1.565,  ..., 1.316, 1.386, 1.589],
        ...,
        [2.051, 1.850, 1.737,  ..., 1.610, 1.950, 2.288],
        [1.784, 2.116, 1.188,  ..., 1.698, 2.232, 1.876],
        [2.143, 1.796, 1.846,  ..., 1.670, 1.483, 2.056]], device='cuda:0')
b after update for 1 param tensor([[220.744, 189.882, 197.887,  ..., 187.953, 175.290, 158.541],
        [194.350, 203.430, 181.730,  ..., 183.474, 144.967, 180.098],
        [218.803, 162.747, 167.991,  ..., 154.013, 158.082, 169.228],
        ...,
        [192.279, 182.641, 176.979,  ..., 170.372, 187.512, 203.110],
        [179.315, 195.330, 146.341,  ..., 174.971, 200.573, 183.922],
        [196.536, 179.921, 182.435,  ..., 173.505, 163.506, 192.503]],
       device='cuda:0')
clipping threshold 2.4378934769769356
a after update for 1 param tensor([ 0.151,  0.145,  0.833, -0.456, -0.198, -0.078,  0.069,  0.115, -0.110,
         0.077, -1.118, -0.148,  0.481,  0.015,  0.086,  0.261, -0.914,  0.205,
         0.413,  0.448,  1.208,  0.214,  0.172,  0.323, -0.236, -0.145, -0.408,
         0.418, -0.230,  0.599, -0.263,  0.824, -0.086, -0.065, -0.366, -0.741,
        -0.355,  0.095,  0.320,  0.074, -0.301, -0.325,  0.582,  0.792,  0.284,
        -0.368,  0.847,  1.239, -0.583, -0.495, -0.006, -0.376, -0.071, -0.279,
         0.106,  0.344, -0.450, -0.023,  0.201, -0.041,  0.003, -0.362,  0.613,
         0.348,  0.517, -0.125,  0.113,  0.064,  0.479,  0.039, -0.118,  0.065,
         0.814,  0.169, -0.022,  0.181, -0.120,  0.632, -0.341,  0.662,  0.603,
        -0.255, -0.170, -0.965, -0.891,  0.715, -0.069, -0.228,  0.223,  0.854,
         0.061, -0.591,  0.134, -0.571,  0.562, -0.678,  0.108,  0.410, -0.724,
         0.471,  0.131, -0.009, -0.184,  0.205, -0.647, -0.093, -0.058, -0.425,
         0.170, -0.777, -0.089,  0.059,  0.536, -0.237,  0.327,  0.442, -0.299,
         0.113,  0.353,  0.131,  0.264, -0.546,  0.791,  0.197,  0.637,  0.091,
         0.046,  0.680,  0.013, -0.341, -1.945,  0.073, -0.542,  0.175, -0.107,
        -0.444,  0.376, -0.789,  0.227,  0.582, -0.358,  0.192, -0.045, -0.315,
         0.308, -0.260,  0.511, -0.082,  0.599,  0.923, -0.224, -0.057, -0.217,
        -0.374, -0.318, -0.327, -0.185, -0.469, -0.156,  0.445, -0.059, -0.060,
         0.288,  0.308, -0.113,  0.268,  0.762,  0.050,  0.118, -0.273,  0.103,
         0.269,  0.360, -0.040, -0.283, -0.454, -0.031,  0.862, -0.776,  0.322,
         0.543,  0.738, -0.072,  0.032, -0.140, -0.486, -0.362, -0.016,  0.449,
        -0.245, -0.375,  0.625, -0.137, -0.796,  0.401,  0.027, -0.188,  0.228,
         0.395, -0.263, -0.232,  0.320, -0.570, -0.606,  0.124, -0.649,  0.805,
         0.298, -0.280,  0.061, -0.194,  0.090,  0.283, -0.388, -0.558,  0.323,
         0.089,  0.449,  0.202, -0.186, -0.473, -0.316,  0.379, -0.266,  0.793,
         0.693,  0.313,  0.109,  0.550, -0.874, -0.399,  0.168, -0.857, -0.092,
        -0.567,  0.691, -0.018,  0.675,  0.557, -0.067, -0.218, -0.419, -0.146,
        -0.244, -0.274,  0.046,  0.048, -0.038, -0.269, -0.654, -0.186,  0.210,
         0.632, -0.300, -0.886,  0.362, -0.724, -0.559, -0.838,  0.214,  0.881,
        -0.353, -0.157,  0.100,  0.362, -0.034, -0.425,  0.562, -0.649, -0.491,
         0.936, -0.052,  0.157,  0.030, -0.148,  0.297,  0.753, -0.367, -0.105,
        -0.268,  0.192, -0.788, -0.602, -0.196,  0.348,  0.170,  0.453, -0.664,
         0.631,  0.240, -0.405, -0.588,  0.475, -0.157,  0.195,  0.518, -0.161,
         0.291,  0.376,  0.457], device='cuda:0')
s after update for 1 param tensor([1.928, 1.806, 2.141, 1.894, 1.857, 1.843, 1.510, 1.947, 2.331, 1.989,
        1.551, 1.141, 1.571, 1.754, 1.800, 2.133, 1.307, 1.533, 1.816, 1.088,
        1.634, 1.730, 1.941, 1.467, 1.542, 1.522, 1.162, 1.603, 1.828, 2.066,
        2.285, 1.498, 1.522, 1.734, 1.671, 1.688, 1.811, 2.276, 1.535, 2.028,
        1.801, 1.878, 2.181, 1.989, 1.843, 1.307, 1.976, 1.493, 1.706, 1.656,
        2.026, 1.829, 2.250, 2.323, 1.973, 1.749, 1.642, 2.207, 1.943, 1.828,
        1.187, 1.953, 1.624, 1.523, 1.998, 1.858, 1.744, 2.006, 1.287, 1.821,
        0.991, 2.028, 1.793, 1.686, 2.031, 1.590, 2.306, 1.718, 1.631, 0.817,
        1.618, 1.939, 1.743, 1.733, 2.217, 1.619, 2.542, 2.075, 1.553, 1.124,
        1.932, 1.823, 1.822, 1.548, 1.204, 1.552, 2.022, 1.689, 2.601, 1.778,
        1.696, 1.699, 1.952, 1.696, 2.196, 1.899, 1.786, 1.788, 2.622, 1.530,
        1.286, 1.627, 1.398, 1.998, 1.784, 1.609, 1.152, 1.562, 1.339, 1.393,
        2.275, 1.329, 1.911, 1.635, 1.648, 1.548, 1.595, 1.391, 1.853, 1.926,
        2.429, 1.949, 2.193, 1.620, 1.925, 2.200, 2.075, 1.744, 1.801, 1.604,
        1.741, 1.444, 1.521, 1.694, 2.191, 1.795, 2.206, 1.438, 1.803, 1.715,
        1.577, 1.789, 1.624, 2.229, 1.467, 1.797, 2.086, 1.870, 1.789, 1.890,
        1.706, 1.480, 1.837, 1.558, 1.520, 1.739, 1.809, 2.340, 1.133, 1.952,
        2.216, 1.756, 1.239, 1.568, 1.842, 1.637, 1.560, 2.165, 1.591, 1.696,
        1.258, 2.144, 1.682, 1.217, 1.563, 1.941, 1.859, 2.094, 2.294, 1.846,
        1.531, 1.933, 1.624, 1.791, 1.644, 1.587, 1.459, 1.208, 1.444, 1.867,
        2.072, 1.510, 1.881, 2.022, 1.833, 1.877, 1.679, 1.633, 1.994, 1.921,
        1.514, 1.835, 2.116, 1.862, 1.604, 1.882, 2.142, 1.872, 2.066, 1.800,
        2.050, 2.009, 1.818, 1.838, 1.837, 2.165, 1.638, 1.777, 1.666, 1.576,
        1.997, 1.265, 1.835, 1.534, 1.390, 2.341, 1.637, 2.171, 1.863, 2.037,
        2.093, 1.792, 1.094, 1.978, 1.971, 2.245, 2.132, 1.756, 1.315, 1.834,
        1.364, 2.063, 1.362, 1.355, 1.741, 2.275, 1.630, 2.226, 1.346, 2.109,
        1.719, 1.842, 2.621, 2.284, 1.780, 1.099, 2.164, 2.186, 1.855, 1.913,
        1.469, 1.506, 1.890, 1.715, 2.168, 2.174, 1.637, 2.053, 0.696, 1.524,
        1.888, 1.977, 1.664, 2.090, 1.462, 1.968, 2.267, 1.965, 1.193, 1.569,
        1.291, 1.977, 1.640, 1.803, 1.691, 1.599, 1.651, 2.102, 2.098, 2.069],
       device='cuda:0')
b after update for 1 param tensor([186.444, 180.417, 196.444, 184.781, 182.959, 182.255, 165.014, 187.356,
        204.993, 189.341, 167.198, 143.411, 168.261, 177.797, 180.136, 196.095,
        153.518, 166.258, 180.940, 140.077, 171.616, 176.621, 187.039, 162.599,
        166.737, 165.653, 144.704, 170.015, 181.553, 193.000, 202.974, 164.313,
        165.665, 176.821, 173.549, 174.453, 180.693, 202.565, 166.363, 191.213,
        180.199, 183.996, 198.276, 189.362, 182.264, 153.495, 188.720, 164.075,
        175.357, 172.801, 191.101, 181.570, 201.394, 204.628, 188.572, 177.574,
        172.045, 199.473, 187.159, 181.519, 146.258, 187.656, 171.117, 165.719,
        189.761, 183.038, 177.318, 190.171, 152.344, 181.198, 133.637, 191.197,
        179.797, 174.338, 191.336, 169.320, 203.904, 176.001, 171.496, 121.381,
        170.761, 186.984, 177.242, 176.775, 199.906, 170.856, 214.084, 193.425,
        167.338, 142.373, 186.632, 181.276, 181.230, 167.036, 147.344, 167.248,
        190.916, 174.489, 216.530, 179.025, 174.832, 174.989, 187.602, 174.836,
        198.946, 185.033, 179.409, 179.544, 217.422, 166.085, 152.284, 171.265,
        158.738, 189.787, 179.349, 170.331, 144.133, 167.817, 155.383, 158.478,
        202.535, 154.802, 185.610, 171.656, 172.339, 167.024, 169.554, 158.377,
        182.753, 186.312, 209.241, 187.464, 198.834, 170.871, 186.288, 199.143,
        193.397, 177.301, 180.194, 170.070, 177.138, 161.346, 165.594, 174.753,
        198.752, 179.908, 199.414, 161.031, 180.271, 175.817, 168.598, 179.590,
        171.108, 200.475, 162.638, 179.977, 193.931, 183.626, 179.596, 184.607,
        175.376, 163.356, 181.979, 167.616, 165.547, 177.081, 180.593, 205.368,
        142.885, 187.597, 199.847, 177.921, 149.464, 168.139, 182.211, 171.772,
        167.697, 197.572, 169.353, 174.855, 150.603, 196.596, 174.147, 148.117,
        167.864, 187.042, 183.082, 194.309, 203.349, 182.402, 166.109, 186.666,
        171.078, 179.667, 172.167, 169.126, 162.175, 147.589, 161.358, 183.454,
        193.276, 164.965, 184.141, 190.909, 181.782, 183.934, 173.953, 171.583,
        189.594, 186.102, 165.218, 181.863, 195.317, 183.207, 170.069, 184.195,
        196.513, 183.720, 193.010, 180.147, 192.255, 190.321, 181.031, 182.024,
        181.990, 197.553, 171.819, 178.986, 173.293, 168.558, 189.741, 151.035,
        181.884, 166.267, 158.291, 205.412, 171.790, 197.829, 183.276, 191.607,
        194.241, 179.716, 140.449, 188.816, 188.487, 201.174, 196.030, 177.944,
        153.992, 181.848, 156.791, 192.859, 156.686, 156.280, 177.155, 202.510,
        171.396, 200.302, 155.755, 194.965, 176.026, 182.210, 217.353, 202.932,
        179.135, 140.783, 197.524, 198.526, 182.873, 185.680, 162.726, 164.779,
        184.583, 175.841, 197.692, 197.982, 171.776, 192.373, 112.019, 165.755,
        184.507, 188.777, 173.202, 194.108, 162.344, 188.344, 202.153, 188.219,
        146.649, 168.194, 152.564, 188.783, 171.957, 180.291, 174.597, 169.773,
        172.493, 194.647, 194.477, 193.114], device='cuda:0')
clipping threshold 2.4378934769769356
a after update for 1 param tensor([[[ 3.151e-01],
         [ 4.347e-01],
         [-2.962e-01],
         [ 2.382e-01],
         [-2.791e-01],
         [ 7.466e-02],
         [ 6.737e-02],
         [ 2.491e-01],
         [ 6.736e-01],
         [-9.817e-04]],

        [[-2.129e-01],
         [ 7.172e-02],
         [ 5.328e-01],
         [-3.882e-01],
         [ 5.434e-01],
         [ 4.099e-01],
         [ 2.333e-01],
         [ 4.289e-01],
         [-6.859e-01],
         [ 3.677e-01]],

        [[-8.095e-02],
         [ 1.223e-01],
         [-8.606e-01],
         [ 6.265e-01],
         [ 5.766e-02],
         [ 3.633e-01],
         [ 8.572e-02],
         [ 4.014e-01],
         [ 1.708e-01],
         [-2.511e-01]],

        [[-4.675e-01],
         [-1.988e-01],
         [ 1.404e-01],
         [ 6.621e-01],
         [-5.779e-01],
         [-3.880e-02],
         [ 1.808e-01],
         [-7.089e-01],
         [-1.102e-03],
         [ 2.150e-01]],

        [[-5.736e-01],
         [-2.183e-01],
         [ 5.066e-01],
         [ 2.289e-02],
         [ 3.271e-01],
         [ 6.324e-03],
         [-3.544e-01],
         [ 7.047e-01],
         [-2.381e-01],
         [ 7.256e-01]],

        [[-8.734e-01],
         [-1.110e+00],
         [-6.605e-02],
         [ 4.091e-01],
         [-6.041e-02],
         [ 9.519e-02],
         [-2.577e-01],
         [-1.479e-01],
         [-6.925e-02],
         [-2.057e-01]],

        [[ 2.507e-01],
         [ 6.605e-01],
         [-1.416e-01],
         [-8.160e-02],
         [-1.236e-01],
         [ 5.338e-01],
         [ 1.396e-01],
         [-1.109e+00],
         [-2.705e-02],
         [ 4.816e-01]],

        [[-3.672e-02],
         [ 6.686e-01],
         [ 4.785e-01],
         [-3.943e-01],
         [-2.076e-01],
         [-5.018e-02],
         [-5.052e-01],
         [ 6.671e-01],
         [ 2.752e-02],
         [ 2.848e-01]],

        [[-6.850e-01],
         [-1.160e-01],
         [ 7.553e-02],
         [ 1.252e-01],
         [-1.705e-01],
         [ 1.427e-01],
         [ 3.391e-01],
         [ 1.127e-01],
         [-6.841e-01],
         [ 4.303e-02]],

        [[-2.105e-01],
         [-1.949e-02],
         [-2.118e-01],
         [ 3.948e-01],
         [ 1.205e-01],
         [ 1.009e-01],
         [ 2.906e-01],
         [-6.790e-01],
         [-3.368e-01],
         [ 7.556e-02]],

        [[ 2.473e-01],
         [ 7.677e-01],
         [ 9.775e-02],
         [-3.356e-01],
         [ 8.051e-02],
         [ 6.922e-02],
         [ 8.900e-02],
         [-4.946e-02],
         [-4.913e-01],
         [-9.124e-02]],

        [[-7.011e-01],
         [-4.661e-01],
         [ 8.119e-01],
         [ 7.550e-01],
         [-2.724e-01],
         [-1.514e-01],
         [ 2.733e-01],
         [ 3.653e-01],
         [-3.023e-01],
         [ 3.235e-03]],

        [[ 4.180e-01],
         [-2.999e-01],
         [-6.463e-01],
         [ 5.385e-01],
         [ 1.227e-01],
         [-5.978e-01],
         [-1.710e-01],
         [ 8.483e-01],
         [-2.940e-01],
         [ 3.065e-01]],

        [[-8.421e-01],
         [ 5.652e-01],
         [ 2.247e-01],
         [-6.255e-01],
         [ 6.287e-01],
         [-1.934e-01],
         [ 2.277e-01],
         [-7.090e-01],
         [-6.071e-01],
         [-1.267e-01]],

        [[-5.974e-01],
         [-2.789e-03],
         [ 8.144e-01],
         [ 6.999e-02],
         [ 2.168e-01],
         [ 9.415e-01],
         [ 1.387e-01],
         [ 1.957e-01],
         [ 7.939e-01],
         [ 1.498e-02]],

        [[ 3.131e-01],
         [ 1.293e-01],
         [-5.463e-01],
         [-3.740e-01],
         [ 7.587e-01],
         [-5.290e-01],
         [-1.736e-01],
         [-4.363e-01],
         [-4.741e-02],
         [-5.000e-01]],

        [[ 7.921e-01],
         [ 5.752e-02],
         [-2.277e-02],
         [-2.066e-01],
         [ 3.291e-01],
         [ 1.803e-01],
         [ 2.206e-01],
         [ 6.075e-01],
         [ 4.344e-02],
         [ 3.168e-01]],

        [[ 1.929e-01],
         [-6.130e-01],
         [ 3.123e-01],
         [ 7.534e-02],
         [-5.279e-01],
         [ 2.832e-01],
         [-2.496e-01],
         [ 6.590e-01],
         [-7.094e-02],
         [ 2.300e-02]],

        [[-3.803e-02],
         [-4.885e-01],
         [ 6.354e-01],
         [ 5.937e-03],
         [ 1.747e-01],
         [ 2.026e-01],
         [ 4.576e-01],
         [ 2.368e-01],
         [-4.643e-01],
         [-6.511e-01]],

        [[-3.276e-01],
         [ 3.839e-02],
         [-3.971e-02],
         [-7.639e-01],
         [-1.926e-01],
         [-2.097e-02],
         [-1.673e-01],
         [-4.167e-01],
         [ 4.716e-01],
         [-9.538e-01]],

        [[ 1.139e+00],
         [-1.628e-01],
         [ 2.270e-01],
         [-4.783e-01],
         [ 4.506e-02],
         [-1.517e-01],
         [-6.672e-01],
         [-2.974e-02],
         [ 4.890e-01],
         [-8.027e-02]],

        [[ 3.436e-01],
         [ 5.368e-01],
         [ 5.630e-01],
         [ 3.616e-01],
         [-1.814e-01],
         [ 1.685e-01],
         [-2.587e-01],
         [-6.020e-01],
         [-2.203e-01],
         [-9.733e-01]],

        [[-4.647e-01],
         [-3.620e-01],
         [-7.822e-01],
         [-9.557e-01],
         [-7.603e-02],
         [-6.156e-02],
         [ 5.626e-01],
         [ 2.155e-01],
         [ 4.269e-01],
         [ 2.267e-01]],

        [[-1.983e-01],
         [-5.717e-01],
         [-1.769e-01],
         [ 7.789e-02],
         [-1.879e-01],
         [-7.253e-01],
         [ 1.313e-01],
         [-7.306e-02],
         [-2.816e-01],
         [ 1.078e+00]],

        [[ 4.242e-01],
         [-1.449e-01],
         [-2.419e-01],
         [ 6.849e-01],
         [ 2.851e-01],
         [ 8.392e-02],
         [-1.536e-01],
         [ 3.548e-01],
         [ 1.434e-01],
         [-3.907e-02]],

        [[ 6.475e-01],
         [ 1.151e-01],
         [-7.231e-01],
         [ 3.837e-01],
         [-4.114e-01],
         [-1.879e-01],
         [-1.272e-01],
         [-1.179e-01],
         [ 3.025e-01],
         [ 2.276e-01]],

        [[-3.431e-01],
         [ 1.499e-01],
         [-1.533e-01],
         [ 6.006e-02],
         [-2.679e-01],
         [ 3.201e-01],
         [ 2.720e-01],
         [-6.836e-02],
         [-2.886e-01],
         [ 1.157e-01]],

        [[-3.734e-01],
         [-1.098e-01],
         [-2.015e+00],
         [ 2.037e-01],
         [-2.095e-01],
         [ 4.629e-01],
         [ 1.488e-01],
         [ 2.050e-01],
         [ 2.630e-01],
         [ 1.078e-03]],

        [[-4.153e-01],
         [ 1.212e-01],
         [-7.256e-01],
         [ 3.273e-01],
         [ 7.714e-01],
         [-2.776e-01],
         [-3.584e-02],
         [-2.430e-01],
         [-3.396e-01],
         [ 6.065e-02]],

        [[ 3.311e-01],
         [-1.938e-01],
         [ 4.577e-01],
         [ 1.731e-01],
         [-7.618e-01],
         [-2.494e-01],
         [-1.833e-01],
         [-1.775e-03],
         [ 1.207e-01],
         [ 7.836e-01]]], device='cuda:0')
s after update for 1 param tensor([[[1.848],
         [1.777],
         [2.001],
         [2.012],
         [1.978],
         [1.786],
         [1.483],
         [1.691],
         [1.673],
         [1.484]],

        [[2.144],
         [2.083],
         [1.513],
         [1.637],
         [1.553],
         [1.727],
         [1.994],
         [1.899],
         [2.115],
         [2.184]],

        [[1.534],
         [1.755],
         [1.522],
         [2.311],
         [2.036],
         [1.641],
         [2.034],
         [1.029],
         [0.917],
         [2.188]],

        [[1.696],
         [1.625],
         [1.963],
         [2.064],
         [1.895],
         [1.759],
         [2.044],
         [1.654],
         [1.663],
         [1.324]],

        [[2.229],
         [1.573],
         [1.858],
         [1.975],
         [2.145],
         [1.612],
         [1.409],
         [1.837],
         [1.828],
         [1.484]],

        [[2.168],
         [1.589],
         [1.872],
         [1.601],
         [1.748],
         [1.631],
         [1.819],
         [1.961],
         [2.417],
         [2.182]],

        [[1.871],
         [2.064],
         [1.108],
         [1.684],
         [1.962],
         [2.234],
         [1.180],
         [1.258],
         [1.923],
         [1.914]],

        [[2.269],
         [2.225],
         [1.666],
         [1.924],
         [1.210],
         [1.792],
         [1.640],
         [0.990],
         [1.511],
         [2.082]],

        [[1.675],
         [1.682],
         [1.532],
         [1.904],
         [2.005],
         [1.482],
         [1.714],
         [1.925],
         [1.280],
         [1.876]],

        [[1.853],
         [1.602],
         [1.629],
         [1.905],
         [2.195],
         [1.920],
         [1.597],
         [1.860],
         [1.963],
         [1.551]],

        [[2.062],
         [2.066],
         [1.659],
         [2.094],
         [2.027],
         [1.868],
         [1.732],
         [1.567],
         [1.614],
         [1.632]],

        [[2.073],
         [1.642],
         [1.812],
         [1.965],
         [1.887],
         [1.498],
         [1.975],
         [1.763],
         [2.110],
         [1.665]],

        [[2.128],
         [1.187],
         [2.322],
         [1.756],
         [1.919],
         [1.922],
         [1.545],
         [1.421],
         [2.572],
         [1.730]],

        [[1.358],
         [2.145],
         [1.693],
         [1.808],
         [1.641],
         [1.442],
         [2.078],
         [1.867],
         [2.303],
         [2.113]],

        [[1.594],
         [1.587],
         [1.851],
         [1.518],
         [2.135],
         [2.150],
         [1.677],
         [1.597],
         [1.835],
         [2.108]],

        [[1.917],
         [2.427],
         [2.032],
         [1.728],
         [1.896],
         [1.523],
         [1.830],
         [1.824],
         [2.039],
         [1.834]],

        [[2.306],
         [2.074],
         [1.160],
         [2.144],
         [1.907],
         [2.270],
         [1.743],
         [2.003],
         [1.373],
         [1.591]],

        [[2.291],
         [2.253],
         [1.601],
         [1.112],
         [1.727],
         [1.362],
         [1.716],
         [1.596],
         [1.806],
         [1.881]],

        [[1.174],
         [1.304],
         [2.162],
         [2.067],
         [1.934],
         [2.463],
         [1.498],
         [1.970],
         [1.157],
         [1.774]],

        [[2.094],
         [1.730],
         [2.189],
         [1.935],
         [1.737],
         [2.240],
         [1.904],
         [1.618],
         [1.634],
         [2.286]],

        [[2.045],
         [1.822],
         [1.726],
         [1.922],
         [1.969],
         [1.546],
         [1.487],
         [1.768],
         [2.019],
         [1.933]],

        [[1.860],
         [1.918],
         [2.047],
         [1.944],
         [1.661],
         [2.069],
         [1.894],
         [1.574],
         [1.600],
         [2.076]],

        [[0.971],
         [1.577],
         [1.812],
         [1.500],
         [1.376],
         [1.630],
         [1.584],
         [1.441],
         [2.336],
         [1.697]],

        [[1.449],
         [2.144],
         [1.059],
         [1.894],
         [1.786],
         [1.159],
         [1.619],
         [2.174],
         [1.516],
         [1.929]],

        [[1.611],
         [1.389],
         [1.802],
         [1.349],
         [1.793],
         [2.124],
         [2.210],
         [1.665],
         [1.581],
         [1.656]],

        [[1.829],
         [2.042],
         [1.944],
         [1.881],
         [1.842],
         [1.636],
         [1.001],
         [2.064],
         [1.090],
         [1.766]],

        [[1.583],
         [1.330],
         [2.064],
         [2.286],
         [1.583],
         [1.738],
         [2.177],
         [2.004],
         [1.708],
         [1.606]],

        [[1.799],
         [1.877],
         [1.606],
         [1.795],
         [1.825],
         [2.092],
         [1.824],
         [1.590],
         [2.103],
         [1.388]],

        [[1.588],
         [1.787],
         [1.873],
         [1.725],
         [2.005],
         [2.238],
         [1.842],
         [2.083],
         [2.260],
         [1.598]],

        [[1.942],
         [2.058],
         [1.128],
         [2.085],
         [2.057],
         [1.477],
         [1.629],
         [2.419],
         [2.067],
         [1.198]]], device='cuda:0')
b after update for 1 param tensor([[[182.499],
         [178.999],
         [189.945],
         [190.458],
         [188.838],
         [179.437],
         [163.495],
         [174.616],
         [173.656],
         [163.538]],

        [[196.613],
         [193.763],
         [165.156],
         [171.777],
         [167.339],
         [176.426],
         [189.603],
         [185.008],
         [195.276],
         [198.443]],

        [[166.315],
         [177.874],
         [165.660],
         [204.091],
         [191.600],
         [171.994],
         [191.477],
         [136.210],
         [128.563],
         [198.621]],

        [[174.852],
         [171.148],
         [188.106],
         [192.893],
         [184.805],
         [178.089],
         [191.944],
         [172.686],
         [173.146],
         [154.488]],

        [[200.461],
         [168.393],
         [183.010],
         [188.686],
         [196.649],
         [170.457],
         [159.401],
         [181.964],
         [181.551],
         [163.588]],

        [[197.685],
         [169.262],
         [183.690],
         [169.894],
         [177.535],
         [171.464],
         [181.069],
         [188.017],
         [208.731],
         [198.322]],

        [[183.669],
         [192.871],
         [141.304],
         [174.254],
         [188.073],
         [200.683],
         [145.828],
         [150.615],
         [186.166],
         [185.766]],

        [[202.242],
         [200.267],
         [173.313],
         [186.218],
         [147.676],
         [179.717],
         [171.969],
         [133.617],
         [165.068],
         [193.743]],

        [[173.778],
         [174.141],
         [166.192],
         [185.284],
         [190.139],
         [163.434],
         [175.762],
         [186.282],
         [151.883],
         [183.896]],

        [[182.771],
         [169.949],
         [171.340],
         [185.328],
         [198.908],
         [186.024],
         [169.700],
         [183.115],
         [188.111],
         [167.197]],

        [[192.804],
         [192.974],
         [172.960],
         [194.272],
         [191.147],
         [183.499],
         [176.705],
         [168.072],
         [170.593],
         [171.529]],

        [[193.299],
         [172.043],
         [180.740],
         [188.200],
         [184.425],
         [164.335],
         [188.707],
         [178.279],
         [195.018],
         [173.223]],

        [[195.864],
         [146.280],
         [204.598],
         [177.930],
         [186.017],
         [186.146],
         [166.880],
         [160.030],
         [215.323],
         [176.622]],

        [[156.456],
         [196.650],
         [174.682],
         [180.516],
         [172.017],
         [161.210],
         [193.539],
         [183.458],
         [203.735],
         [195.163]],

        [[169.514],
         [169.129],
         [182.684],
         [165.446],
         [196.163],
         [196.863],
         [173.859],
         [169.664],
         [181.884],
         [194.944]],

        [[185.885],
         [209.167],
         [191.384],
         [176.484],
         [184.873],
         [165.718],
         [181.637],
         [181.342],
         [191.715],
         [181.847]],

        [[203.901],
         [193.351],
         [144.596],
         [196.580],
         [185.392],
         [202.286],
         [177.267],
         [190.042],
         [157.351],
         [169.378]],

        [[203.203],
         [201.532],
         [169.878],
         [141.572],
         [176.450],
         [156.688],
         [175.861],
         [169.621],
         [180.443],
         [184.134]],

        [[145.467],
         [153.326],
         [197.399],
         [193.019],
         [186.721],
         [210.695],
         [164.314],
         [188.464],
         [144.439],
         [178.824]],

        [[194.268],
         [176.622],
         [198.628],
         [186.772],
         [176.964],
         [200.930],
         [185.257],
         [170.805],
         [171.607],
         [202.993]],

        [[191.991],
         [181.252],
         [176.414],
         [186.127],
         [188.407],
         [166.937],
         [163.705],
         [178.502],
         [190.796],
         [186.655]],

        [[183.090],
         [185.950],
         [192.090],
         [187.207],
         [173.063],
         [193.128],
         [184.761],
         [168.461],
         [169.849],
         [193.454]],

        [[132.294],
         [168.599],
         [180.750],
         [164.466],
         [157.512],
         [171.424],
         [168.966],
         [161.168],
         [205.201],
         [174.900]],

        [[161.615],
         [196.588],
         [138.188],
         [184.757],
         [179.441],
         [144.553],
         [170.823],
         [197.946],
         [165.333],
         [186.469]],

        [[170.433],
         [158.246],
         [180.259],
         [155.918],
         [179.777],
         [195.674],
         [199.598],
         [173.270],
         [168.834],
         [172.772]],

        [[181.605],
         [191.844],
         [187.213],
         [184.122],
         [182.219],
         [171.719],
         [134.306],
         [192.895],
         [140.205],
         [178.406]],

        [[168.947],
         [154.844],
         [192.885],
         [202.982],
         [168.936],
         [176.993],
         [198.083],
         [190.051],
         [175.458],
         [170.174]],

        [[180.106],
         [183.939],
         [170.138],
         [179.878],
         [181.374],
         [194.198],
         [181.320],
         [169.327],
         [194.691],
         [158.208]],

        [[169.217],
         [179.474],
         [183.737],
         [176.334],
         [190.102],
         [200.871],
         [182.249],
         [193.800],
         [201.824],
         [169.739]],

        [[187.119],
         [192.609],
         [142.606],
         [193.867],
         [192.557],
         [163.174],
         [171.364],
         [208.811],
         [193.018],
         [146.933]]], device='cuda:0')
clipping threshold 2.4378934769769356
a after update for 1 param tensor([[-0.188],
        [-0.485],
        [-0.077],
        [-0.430],
        [ 0.181],
        [-0.724],
        [ 0.178],
        [-0.680],
        [-0.092],
        [ 0.346],
        [-0.293],
        [-0.187],
        [ 0.517],
        [ 0.288],
        [-0.904],
        [ 0.243],
        [-0.282],
        [-0.373],
        [-0.214],
        [-0.379],
        [-0.991],
        [-0.213],
        [ 0.126],
        [ 0.015],
        [ 0.924],
        [-0.239],
        [ 0.584],
        [-0.820],
        [-0.055],
        [-0.129]], device='cuda:0')
s after update for 1 param tensor([[1.817],
        [1.849],
        [1.376],
        [2.294],
        [2.028],
        [1.723],
        [2.124],
        [2.043],
        [1.954],
        [1.379],
        [1.913],
        [1.607],
        [1.370],
        [1.676],
        [1.565],
        [1.947],
        [1.995],
        [1.035],
        [1.749],
        [1.343],
        [2.507],
        [1.708],
        [1.360],
        [2.418],
        [1.717],
        [1.407],
        [1.813],
        [1.311],
        [1.373],
        [2.227]], device='cuda:0')
b after update for 1 param tensor([[180.968],
        [182.586],
        [157.519],
        [203.351],
        [191.210],
        [176.262],
        [195.656],
        [191.913],
        [187.660],
        [157.651],
        [185.709],
        [170.205],
        [157.172],
        [173.834],
        [167.986],
        [187.353],
        [189.619],
        [136.570],
        [177.561],
        [155.603],
        [212.581],
        [175.471],
        [156.601],
        [208.780],
        [175.941],
        [159.242],
        [180.768],
        [153.751],
        [157.340],
        [200.374]], device='cuda:0')
clipping threshold 2.4378934769769356
||w||^2 19.441874055626478
exp ma of ||w||^2 9.741529720362923
||w|| 4.409294054111891
exp ma of ||w|| 3.077182851612515
||w||^2 10.997596877897418
exp ma of ||w||^2 9.624958914530904
||w|| 3.3162624862784034
exp ma of ||w|| 3.0565269373198083
||w||^2 7.803028352218066
exp ma of ||w||^2 10.492910513874953
||w|| 2.7933901181571588
exp ma of ||w|| 3.1990630845270385
||w||^2 9.385362926647092
exp ma of ||w||^2 10.313517486949218
||w|| 3.0635539699256307
exp ma of ||w|| 3.172856707632876
||w||^2 8.923627901803767
exp ma of ||w||^2 10.165504021807905
||w|| 2.9872441985555462
exp ma of ||w|| 3.1457414313740815
||w||^2 14.514450935832622
exp ma of ||w||^2 10.256455896170802
||w|| 3.8097835812330105
exp ma of ||w|| 3.1466152280577613
||w||^2 9.23367289145117
exp ma of ||w||^2 10.6332880792534
||w|| 3.03869591954364
exp ma of ||w|| 3.219129749652489
||w||^2 10.068133458232968
exp ma of ||w||^2 11.700079421315765
||w|| 3.1730322182784354
exp ma of ||w|| 3.381999243262651
cuda
Objective function 114.07 = squared loss an data 71.72 + 0.5*rho*h**2 21.890836 + alpha*h 16.476406 + L2reg 3.61 + L1reg 0.37 ; SHD = 169 ; DAG True
Proportion of microbatches that were clipped  0.7824657094730088
iteration 2 in inner loop, alpha 787.4379161841692 rho 100000.0 h 0.020924070235885495
iteration 4 in outer loop, alpha = 21711.508152069662, rho = 1000000.0, h = 0.020924070235885495
Threshold 0.3
[[0.006 0.085 0.119 0.041 0.131 0.009 0.082 0.058 0.061 0.061 0.116 0.072
  0.028 0.012 0.01  0.06  0.072 0.073 0.341 0.019 0.039 0.011 0.104 0.015
  0.012 0.051 0.048 0.011 0.143 0.066]
 [0.045 0.005 0.146 0.093 0.144 0.015 0.125 0.074 0.103 0.041 0.256 0.244
  0.024 0.01  0.008 0.135 0.33  0.081 0.17  0.05  0.044 0.011 0.151 0.05
  0.013 0.131 0.213 0.009 0.351 0.114]
 [0.039 0.05  0.009 0.026 0.263 0.016 0.069 0.014 0.028 0.016 0.102 0.068
  0.028 0.005 0.008 0.068 0.046 0.034 0.058 0.026 0.05  0.006 0.065 0.028
  0.005 0.037 0.038 0.008 0.094 0.067]
 [0.172 0.056 0.179 0.004 0.273 0.02  0.115 0.024 0.172 0.031 0.183 0.107
  0.045 0.009 0.007 0.138 0.169 0.05  0.264 0.036 0.03  0.02  0.162 0.097
  0.011 0.084 0.094 0.011 0.24  0.04 ]
 [0.037 0.043 0.033 0.022 0.009 0.007 0.04  0.006 0.024 0.015 0.059 0.078
  0.005 0.013 0.008 0.059 0.044 0.019 0.188 0.028 0.031 0.007 0.041 0.035
  0.01  0.046 0.016 0.009 0.148 0.021]
 [0.403 0.367 0.403 0.342 0.666 0.007 0.733 0.144 0.2   0.133 0.332 0.582
  0.083 0.132 0.054 0.516 0.473 0.227 0.538 0.224 0.254 0.093 0.562 0.19
  0.106 0.267 0.292 0.034 0.797 0.522]
 [0.097 0.068 0.133 0.067 0.12  0.006 0.004 0.04  0.039 0.029 0.152 0.207
  0.028 0.013 0.01  0.162 0.147 0.03  0.16  0.035 0.033 0.01  0.076 0.021
  0.021 0.031 0.063 0.022 0.277 0.044]
 [0.148 0.111 0.47  0.271 1.141 0.033 0.243 0.004 0.154 0.092 0.177 0.173
  0.131 0.056 0.021 0.34  0.36  0.192 0.196 0.109 0.13  0.017 0.211 0.234
  0.033 0.14  0.088 0.018 0.379 0.296]
 [0.172 0.045 0.134 0.055 0.259 0.033 0.167 0.035 0.004 0.032 0.108 0.073
  0.023 0.009 0.01  0.134 0.147 0.019 0.202 0.041 0.016 0.008 0.187 0.063
  0.005 0.029 0.066 0.016 0.112 0.083]
 [0.126 0.175 0.283 0.133 0.47  0.075 0.141 0.068 0.232 0.006 0.235 0.221
  0.185 0.021 0.034 0.226 0.335 0.1   0.434 0.098 0.148 0.042 0.401 0.137
  0.03  0.128 0.126 0.022 0.225 0.227]
 [0.035 0.021 0.072 0.041 0.129 0.01  0.049 0.027 0.05  0.034 0.008 0.114
  0.018 0.014 0.013 0.197 0.067 0.021 0.135 0.05  0.035 0.015 0.141 0.036
  0.003 0.009 0.034 0.008 0.337 0.062]
 [0.113 0.026 0.069 0.07  0.086 0.014 0.045 0.024 0.064 0.027 0.054 0.005
  0.012 0.011 0.004 0.035 0.136 0.029 0.127 0.009 0.03  0.012 0.037 0.031
  0.006 0.046 0.046 0.004 0.04  0.063]
 [0.249 0.309 0.181 0.205 1.035 0.088 0.238 0.046 0.274 0.036 0.202 0.402
  0.006 0.03  0.012 0.79  0.159 0.091 0.525 0.11  0.256 0.016 0.199 0.19
  0.022 0.173 0.252 0.033 0.3   0.228]
 [0.422 0.448 1.297 0.583 0.345 0.049 0.392 0.117 0.31  0.266 0.402 0.448
  0.184 0.005 0.031 0.377 0.383 0.279 0.668 0.168 0.206 0.038 0.502 0.155
  0.114 0.274 0.185 0.058 0.345 0.797]
 [0.531 0.706 0.579 0.887 0.252 0.165 0.522 0.273 0.522 0.167 0.452 0.869
  0.484 0.219 0.005 0.735 0.748 0.451 1.118 0.64  0.573 0.153 0.347 1.429
  0.107 0.55  0.389 0.142 0.65  0.361]
 [0.145 0.036 0.109 0.05  0.112 0.01  0.034 0.027 0.033 0.038 0.04  0.127
  0.008 0.012 0.006 0.004 0.11  0.017 0.114 0.012 0.038 0.012 0.053 0.029
  0.012 0.037 0.029 0.008 0.122 0.028]
 [0.088 0.017 0.133 0.027 0.138 0.013 0.043 0.018 0.039 0.021 0.074 0.046
  0.025 0.007 0.005 0.055 0.006 0.029 0.271 0.018 0.026 0.007 0.096 0.022
  0.008 0.043 0.055 0.013 0.186 0.052]
 [0.092 0.145 0.112 0.143 0.242 0.042 0.203 0.035 0.349 0.079 0.307 0.196
  0.048 0.031 0.008 0.321 0.178 0.006 0.412 0.068 0.065 0.023 0.105 0.125
  0.027 0.144 0.215 0.014 0.392 0.089]
 [0.02  0.037 0.111 0.025 0.032 0.007 0.038 0.02  0.03  0.019 0.038 0.053
  0.008 0.007 0.005 0.053 0.027 0.01  0.005 0.012 0.021 0.007 0.013 0.005
  0.009 0.038 0.017 0.005 0.121 0.052]
 [0.235 0.205 0.257 0.181 0.212 0.027 0.249 0.06  0.211 0.095 0.135 0.501
  0.061 0.031 0.011 0.47  0.429 0.081 0.474 0.008 0.19  0.023 0.164 0.527
  0.021 0.263 0.149 0.009 0.771 0.216]
 [0.201 0.174 0.185 0.131 0.132 0.021 0.227 0.042 0.352 0.041 0.172 0.198
  0.029 0.023 0.011 0.144 0.29  0.102 0.323 0.038 0.004 0.022 0.062 0.061
  0.019 0.059 0.257 0.036 0.383 0.094]
 [0.592 0.404 0.847 0.347 1.254 0.067 0.478 0.359 0.622 0.194 0.38  0.533
  0.354 0.13  0.045 0.482 0.752 0.197 0.752 0.258 0.259 0.006 0.583 0.491
  0.044 0.285 0.269 0.036 0.675 0.263]
 [0.046 0.043 0.105 0.058 0.097 0.014 0.059 0.02  0.052 0.016 0.056 0.182
  0.025 0.012 0.013 0.12  0.059 0.038 0.491 0.034 0.06  0.012 0.005 0.031
  0.017 0.029 0.043 0.013 0.126 0.042]
 [0.435 0.165 0.227 0.071 0.245 0.018 0.373 0.022 0.136 0.06  0.143 0.29
  0.056 0.032 0.004 0.287 0.16  0.074 0.834 0.01  0.112 0.011 0.137 0.005
  0.045 0.2   0.109 0.023 0.367 0.103]
 [0.538 0.349 0.779 0.41  0.252 0.08  0.372 0.22  0.673 0.193 1.372 0.723
  0.311 0.068 0.046 0.659 0.545 0.252 0.613 0.26  0.265 0.171 0.381 0.131
  0.005 1.583 0.255 0.057 1.099 0.406]
 [0.147 0.051 0.134 0.1   0.098 0.023 0.131 0.037 0.231 0.028 0.587 0.139
  0.041 0.031 0.012 0.133 0.245 0.046 0.158 0.02  0.122 0.022 0.261 0.027
  0.004 0.004 0.117 0.006 0.443 0.143]
 [0.149 0.032 0.195 0.085 0.39  0.019 0.11  0.048 0.102 0.038 0.199 0.172
  0.02  0.029 0.013 0.196 0.141 0.027 0.261 0.049 0.022 0.03  0.175 0.072
  0.019 0.06  0.007 0.007 0.454 0.073]
 [0.524 0.512 0.325 0.63  0.397 0.13  0.209 0.236 0.416 0.245 0.806 0.868
  0.156 0.101 0.061 0.542 0.479 0.393 0.569 0.423 0.243 0.226 0.581 0.324
  0.11  0.711 0.696 0.004 0.534 0.487]
 [0.041 0.013 0.069 0.026 0.062 0.006 0.02  0.016 0.044 0.023 0.022 0.129
  0.021 0.008 0.004 0.055 0.049 0.018 0.073 0.009 0.021 0.009 0.055 0.017
  0.003 0.016 0.01  0.013 0.004 0.034]
 [0.057 0.064 0.08  0.184 0.207 0.012 0.243 0.031 0.072 0.03  0.153 0.139
  0.019 0.006 0.015 0.226 0.136 0.092 0.13  0.03  0.058 0.02  0.188 0.07
  0.011 0.039 0.09  0.011 0.232 0.005]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.341 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.33  0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.351 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.403 0.367 0.403 0.342 0.666 0.    0.733 0.    0.    0.    0.332 0.582
  0.    0.    0.    0.516 0.473 0.    0.538 0.    0.    0.    0.562 0.
  0.    0.    0.    0.    0.797 0.522]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.47  0.    1.141 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.34  0.36  0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.379 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.47  0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.335 0.    0.434 0.    0.    0.    0.401 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.337 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.309 0.    0.    1.035 0.    0.    0.    0.    0.    0.    0.402
  0.    0.    0.    0.79  0.    0.    0.525 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.422 0.448 1.297 0.583 0.345 0.    0.392 0.    0.31  0.    0.402 0.448
  0.    0.    0.    0.377 0.383 0.    0.668 0.    0.    0.    0.502 0.
  0.    0.    0.    0.    0.345 0.797]
 [0.531 0.706 0.579 0.887 0.    0.    0.522 0.    0.522 0.    0.452 0.869
  0.484 0.    0.    0.735 0.748 0.451 1.118 0.64  0.573 0.    0.347 1.429
  0.    0.55  0.389 0.    0.65  0.361]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.349 0.    0.307 0.
  0.    0.    0.    0.321 0.    0.    0.412 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.392 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.501
  0.    0.    0.    0.47  0.429 0.    0.474 0.    0.    0.    0.    0.527
  0.    0.    0.    0.    0.771 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.352 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.323 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.383 0.   ]
 [0.592 0.404 0.847 0.347 1.254 0.    0.478 0.359 0.622 0.    0.38  0.533
  0.354 0.    0.    0.482 0.752 0.    0.752 0.    0.    0.    0.583 0.491
  0.    0.    0.    0.    0.675 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.491 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.435 0.    0.    0.    0.    0.    0.373 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.834 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.367 0.   ]
 [0.538 0.349 0.779 0.41  0.    0.    0.372 0.    0.673 0.    1.372 0.723
  0.311 0.    0.    0.659 0.545 0.    0.613 0.    0.    0.    0.381 0.
  0.    1.583 0.    0.    1.099 0.406]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.587 0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.443 0.   ]
 [0.    0.    0.    0.    0.39  0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.454 0.   ]
 [0.524 0.512 0.325 0.63  0.397 0.    0.    0.    0.416 0.    0.806 0.868
  0.    0.    0.    0.542 0.479 0.393 0.569 0.423 0.    0.    0.581 0.324
  0.    0.711 0.696 0.    0.534 0.487]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]]
{'fdr': 0.6923076923076923, 'tpr': 0.36666666666666664, 'fpr': 0.3142857142857143, 'f1': 0.33460076045627374, 'shd': 169, 'npred': 143, 'ntrue': 120}
[0.085 0.119 0.041 0.131 0.009 0.082 0.058 0.061 0.061 0.116 0.072 0.028
 0.012 0.01  0.06  0.072 0.073 0.341 0.019 0.039 0.011 0.104 0.015 0.012
 0.051 0.048 0.011 0.143 0.066 0.045 0.146 0.093 0.144 0.015 0.125 0.074
 0.103 0.041 0.256 0.244 0.024 0.01  0.008 0.135 0.33  0.081 0.17  0.05
 0.044 0.011 0.151 0.05  0.013 0.131 0.213 0.009 0.351 0.114 0.039 0.05
 0.026 0.263 0.016 0.069 0.014 0.028 0.016 0.102 0.068 0.028 0.005 0.008
 0.068 0.046 0.034 0.058 0.026 0.05  0.006 0.065 0.028 0.005 0.037 0.038
 0.008 0.094 0.067 0.172 0.056 0.179 0.273 0.02  0.115 0.024 0.172 0.031
 0.183 0.107 0.045 0.009 0.007 0.138 0.169 0.05  0.264 0.036 0.03  0.02
 0.162 0.097 0.011 0.084 0.094 0.011 0.24  0.04  0.037 0.043 0.033 0.022
 0.007 0.04  0.006 0.024 0.015 0.059 0.078 0.005 0.013 0.008 0.059 0.044
 0.019 0.188 0.028 0.031 0.007 0.041 0.035 0.01  0.046 0.016 0.009 0.148
 0.021 0.403 0.367 0.403 0.342 0.666 0.733 0.144 0.2   0.133 0.332 0.582
 0.083 0.132 0.054 0.516 0.473 0.227 0.538 0.224 0.254 0.093 0.562 0.19
 0.106 0.267 0.292 0.034 0.797 0.522 0.097 0.068 0.133 0.067 0.12  0.006
 0.04  0.039 0.029 0.152 0.207 0.028 0.013 0.01  0.162 0.147 0.03  0.16
 0.035 0.033 0.01  0.076 0.021 0.021 0.031 0.063 0.022 0.277 0.044 0.148
 0.111 0.47  0.271 1.141 0.033 0.243 0.154 0.092 0.177 0.173 0.131 0.056
 0.021 0.34  0.36  0.192 0.196 0.109 0.13  0.017 0.211 0.234 0.033 0.14
 0.088 0.018 0.379 0.296 0.172 0.045 0.134 0.055 0.259 0.033 0.167 0.035
 0.032 0.108 0.073 0.023 0.009 0.01  0.134 0.147 0.019 0.202 0.041 0.016
 0.008 0.187 0.063 0.005 0.029 0.066 0.016 0.112 0.083 0.126 0.175 0.283
 0.133 0.47  0.075 0.141 0.068 0.232 0.235 0.221 0.185 0.021 0.034 0.226
 0.335 0.1   0.434 0.098 0.148 0.042 0.401 0.137 0.03  0.128 0.126 0.022
 0.225 0.227 0.035 0.021 0.072 0.041 0.129 0.01  0.049 0.027 0.05  0.034
 0.114 0.018 0.014 0.013 0.197 0.067 0.021 0.135 0.05  0.035 0.015 0.141
 0.036 0.003 0.009 0.034 0.008 0.337 0.062 0.113 0.026 0.069 0.07  0.086
 0.014 0.045 0.024 0.064 0.027 0.054 0.012 0.011 0.004 0.035 0.136 0.029
 0.127 0.009 0.03  0.012 0.037 0.031 0.006 0.046 0.046 0.004 0.04  0.063
 0.249 0.309 0.181 0.205 1.035 0.088 0.238 0.046 0.274 0.036 0.202 0.402
 0.03  0.012 0.79  0.159 0.091 0.525 0.11  0.256 0.016 0.199 0.19  0.022
 0.173 0.252 0.033 0.3   0.228 0.422 0.448 1.297 0.583 0.345 0.049 0.392
 0.117 0.31  0.266 0.402 0.448 0.184 0.031 0.377 0.383 0.279 0.668 0.168
 0.206 0.038 0.502 0.155 0.114 0.274 0.185 0.058 0.345 0.797 0.531 0.706
 0.579 0.887 0.252 0.165 0.522 0.273 0.522 0.167 0.452 0.869 0.484 0.219
 0.735 0.748 0.451 1.118 0.64  0.573 0.153 0.347 1.429 0.107 0.55  0.389
 0.142 0.65  0.361 0.145 0.036 0.109 0.05  0.112 0.01  0.034 0.027 0.033
 0.038 0.04  0.127 0.008 0.012 0.006 0.11  0.017 0.114 0.012 0.038 0.012
 0.053 0.029 0.012 0.037 0.029 0.008 0.122 0.028 0.088 0.017 0.133 0.027
 0.138 0.013 0.043 0.018 0.039 0.021 0.074 0.046 0.025 0.007 0.005 0.055
 0.029 0.271 0.018 0.026 0.007 0.096 0.022 0.008 0.043 0.055 0.013 0.186
 0.052 0.092 0.145 0.112 0.143 0.242 0.042 0.203 0.035 0.349 0.079 0.307
 0.196 0.048 0.031 0.008 0.321 0.178 0.412 0.068 0.065 0.023 0.105 0.125
 0.027 0.144 0.215 0.014 0.392 0.089 0.02  0.037 0.111 0.025 0.032 0.007
 0.038 0.02  0.03  0.019 0.038 0.053 0.008 0.007 0.005 0.053 0.027 0.01
 0.012 0.021 0.007 0.013 0.005 0.009 0.038 0.017 0.005 0.121 0.052 0.235
 0.205 0.257 0.181 0.212 0.027 0.249 0.06  0.211 0.095 0.135 0.501 0.061
 0.031 0.011 0.47  0.429 0.081 0.474 0.19  0.023 0.164 0.527 0.021 0.263
 0.149 0.009 0.771 0.216 0.201 0.174 0.185 0.131 0.132 0.021 0.227 0.042
 0.352 0.041 0.172 0.198 0.029 0.023 0.011 0.144 0.29  0.102 0.323 0.038
 0.022 0.062 0.061 0.019 0.059 0.257 0.036 0.383 0.094 0.592 0.404 0.847
 0.347 1.254 0.067 0.478 0.359 0.622 0.194 0.38  0.533 0.354 0.13  0.045
 0.482 0.752 0.197 0.752 0.258 0.259 0.583 0.491 0.044 0.285 0.269 0.036
 0.675 0.263 0.046 0.043 0.105 0.058 0.097 0.014 0.059 0.02  0.052 0.016
 0.056 0.182 0.025 0.012 0.013 0.12  0.059 0.038 0.491 0.034 0.06  0.012
 0.031 0.017 0.029 0.043 0.013 0.126 0.042 0.435 0.165 0.227 0.071 0.245
 0.018 0.373 0.022 0.136 0.06  0.143 0.29  0.056 0.032 0.004 0.287 0.16
 0.074 0.834 0.01  0.112 0.011 0.137 0.045 0.2   0.109 0.023 0.367 0.103
 0.538 0.349 0.779 0.41  0.252 0.08  0.372 0.22  0.673 0.193 1.372 0.723
 0.311 0.068 0.046 0.659 0.545 0.252 0.613 0.26  0.265 0.171 0.381 0.131
 1.583 0.255 0.057 1.099 0.406 0.147 0.051 0.134 0.1   0.098 0.023 0.131
 0.037 0.231 0.028 0.587 0.139 0.041 0.031 0.012 0.133 0.245 0.046 0.158
 0.02  0.122 0.022 0.261 0.027 0.004 0.117 0.006 0.443 0.143 0.149 0.032
 0.195 0.085 0.39  0.019 0.11  0.048 0.102 0.038 0.199 0.172 0.02  0.029
 0.013 0.196 0.141 0.027 0.261 0.049 0.022 0.03  0.175 0.072 0.019 0.06
 0.007 0.454 0.073 0.524 0.512 0.325 0.63  0.397 0.13  0.209 0.236 0.416
 0.245 0.806 0.868 0.156 0.101 0.061 0.542 0.479 0.393 0.569 0.423 0.243
 0.226 0.581 0.324 0.11  0.711 0.696 0.534 0.487 0.041 0.013 0.069 0.026
 0.062 0.006 0.02  0.016 0.044 0.023 0.022 0.129 0.021 0.008 0.004 0.055
 0.049 0.018 0.073 0.009 0.021 0.009 0.055 0.017 0.003 0.016 0.01  0.013
 0.034 0.057 0.064 0.08  0.184 0.207 0.012 0.243 0.031 0.072 0.03  0.153
 0.139 0.019 0.006 0.015 0.226 0.136 0.092 0.13  0.03  0.058 0.02  0.188
 0.07  0.011 0.039 0.09  0.011 0.232]
[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 1.]
 [1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 0. 1.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.
  0. 1. 1. 0. 0. 0.]
 [0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
  0. 1. 0. 0. 0. 1.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1.
 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0.]
aucroc, aucpr (0.682288888888889, 0.33054044377832337)
Iterations 2250
Achieves (13.034436291409676, 1e-05)-DP
