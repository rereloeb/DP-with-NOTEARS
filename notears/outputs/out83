samples  5000  graph  15 30 ER mlp  minibatch size  100  noise  0.75  minibatches per NN training  63 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.3401316691164595
iteration 1 in outer loop, alpha = 1.3401316691164595, rho = 1.0, h = 1.3401316691164595
cuda
iteration 1 in inner loop,alpha 1.3401316691164595 rho 1.0 h 0.8741315174292428
iteration 2 in inner loop,alpha 1.3401316691164595 rho 10.0 h 0.38347274229216843
iteration 3 in inner loop,alpha 1.3401316691164595 rho 100.0 h 0.13357487921889089
iteration 2 in outer loop, alpha = 14.697619591005548, rho = 100.0, h = 0.13357487921889089
cuda
iteration 1 in inner loop,alpha 14.697619591005548 rho 100.0 h 0.06991993740608571
iteration 2 in inner loop,alpha 14.697619591005548 rho 1000.0 h 0.02592698775515956
iteration 3 in outer loop, alpha = 40.62460734616511, rho = 1000.0, h = 0.02592698775515956
cuda
iteration 1 in inner loop,alpha 40.62460734616511 rho 1000.0 h 0.016465661543334065
iteration 2 in inner loop,alpha 40.62460734616511 rho 10000.0 h 0.006583550827196305
iteration 3 in inner loop,alpha 40.62460734616511 rho 100000.0 h 0.0011537970975332712
iteration 4 in outer loop, alpha = 156.00431709949223, rho = 100000.0, h = 0.0011537970975332712
cuda
iteration 1 in inner loop,alpha 156.00431709949223 rho 100000.0 h 0.00033575511004180214
iteration 5 in outer loop, alpha = 491.7594271412944, rho = 1000000.0, h = 0.00033575511004180214
Threshold 0.3
[[0.002 0.    0.    0.005 0.194 0.    0.    0.    0.    2.734 0.179 0.001
  0.001 0.    0.006]
 [2.52  0.001 0.002 0.262 0.215 0.01  0.01  0.001 0.002 2.189 0.199 1.342
  0.001 0.001 0.098]
 [0.027 0.068 0.001 0.147 0.166 0.035 0.137 0.001 0.067 0.125 0.135 0.162
  0.001 0.001 0.006]
 [0.153 0.    0.001 0.001 0.204 0.    0.    0.    0.    0.214 0.335 0.001
  0.    0.    1.022]
 [0.    0.    0.    0.    0.004 0.    0.    0.    0.    0.    0.002 0.
  0.    0.    0.001]
 [2.646 0.03  0.001 0.968 0.376 0.001 1.377 0.    0.055 1.746 0.956 1.472
  0.012 0.002 1.923]
 [0.414 0.044 0.    0.336 0.408 0.    0.001 0.    0.059 0.139 1.162 0.096
  0.001 0.    0.163]
 [2.69  0.002 0.    2.092 0.137 0.612 0.046 0.    0.003 0.313 0.139 0.061
  0.014 0.022 0.118]
 [0.103 0.383 0.002 0.638 0.415 0.002 0.001 0.001 0.003 2.308 1.722 1.03
  0.    0.    0.367]
 [0.    0.    0.    0.    2.722 0.    0.001 0.    0.    0.002 0.402 0.001
  0.    0.    0.002]
 [0.001 0.    0.    0.001 3.057 0.    0.001 0.    0.001 0.001 0.015 0.
  0.    0.    0.005]
 [0.37  0.    0.    0.18  0.153 0.    0.004 0.    0.002 0.427 0.58  0.001
  0.    0.001 0.032]
 [0.041 0.078 0.    0.112 3.047 0.017 0.008 0.    1.212 0.107 1.585 0.031
  0.001 0.016 0.021]
 [0.126 1.398 0.    1.127 1.231 0.003 0.006 0.    3.368 0.386 0.434 0.158
  0.011 0.002 0.562]
 [0.089 0.    0.    0.    0.111 0.    0.    0.    0.    0.106 0.081 0.002
  0.004 0.    0.001]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    2.734 0.    0.
  0.    0.    0.   ]
 [2.52  0.    0.    0.    0.    0.    0.    0.    0.    2.189 0.    1.342
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.335 0.
  0.    0.    1.022]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [2.646 0.    0.    0.968 0.376 0.    1.377 0.    0.    1.746 0.956 1.472
  0.    0.    1.923]
 [0.414 0.    0.    0.336 0.408 0.    0.    0.    0.    0.    1.162 0.
  0.    0.    0.   ]
 [2.69  0.    0.    2.092 0.    0.612 0.    0.    0.    0.313 0.    0.
  0.    0.    0.   ]
 [0.    0.383 0.    0.638 0.415 0.    0.    0.    0.    2.308 1.722 1.03
  0.    0.    0.367]
 [0.    0.    0.    0.    2.722 0.    0.    0.    0.    0.    0.402 0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    3.057 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.37  0.    0.    0.    0.    0.    0.    0.    0.    0.427 0.58  0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    3.047 0.    0.    0.    1.212 0.    1.585 0.
  0.    0.    0.   ]
 [0.    1.398 0.    1.127 1.231 0.    0.    0.    3.368 0.386 0.434 0.
  0.    0.    0.562]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]]
{'fdr': 0.35555555555555557, 'tpr': 0.9666666666666667, 'fpr': 0.21333333333333335, 'f1': 0.7733333333333333, 'shd': 17, 'npred': 45, 'ntrue': 30}
[7.166e-05 3.031e-04 4.737e-03 1.942e-01 6.655e-05 2.207e-04 4.993e-05
 2.937e-04 2.734e+00 1.793e-01 5.105e-04 1.050e-03 1.242e-04 5.740e-03
 2.520e+00 1.954e-03 2.620e-01 2.147e-01 9.724e-03 9.801e-03 9.328e-04
 1.620e-03 2.189e+00 1.994e-01 1.342e+00 5.488e-04 9.886e-04 9.781e-02
 2.679e-02 6.849e-02 1.472e-01 1.660e-01 3.508e-02 1.368e-01 5.716e-04
 6.687e-02 1.254e-01 1.352e-01 1.619e-01 8.477e-04 1.272e-03 6.092e-03
 1.532e-01 1.509e-04 9.882e-04 2.036e-01 4.044e-05 3.897e-04 2.489e-04
 6.858e-05 2.135e-01 3.353e-01 1.155e-03 4.106e-04 1.293e-04 1.022e+00
 6.064e-05 4.791e-06 5.172e-05 2.471e-04 1.136e-05 1.928e-04 4.191e-06
 2.163e-04 3.383e-04 1.833e-03 1.007e-04 2.631e-05 7.614e-05 1.086e-03
 2.646e+00 3.009e-02 1.478e-03 9.684e-01 3.765e-01 1.377e+00 1.229e-04
 5.513e-02 1.746e+00 9.560e-01 1.472e+00 1.180e-02 1.838e-03 1.923e+00
 4.141e-01 4.437e-02 3.959e-04 3.360e-01 4.079e-01 4.254e-04 5.935e-05
 5.872e-02 1.392e-01 1.162e+00 9.588e-02 6.731e-04 4.063e-04 1.632e-01
 2.690e+00 2.126e-03 4.852e-04 2.092e+00 1.369e-01 6.121e-01 4.646e-02
 3.330e-03 3.125e-01 1.385e-01 6.062e-02 1.448e-02 2.181e-02 1.178e-01
 1.034e-01 3.829e-01 2.017e-03 6.383e-01 4.147e-01 2.074e-03 1.394e-03
 1.328e-03 2.308e+00 1.722e+00 1.030e+00 5.492e-05 3.972e-04 3.674e-01
 1.834e-04 4.607e-06 8.949e-05 4.394e-04 2.722e+00 6.113e-06 8.992e-04
 1.147e-05 4.538e-04 4.020e-01 1.020e-03 1.265e-04 1.194e-04 2.179e-03
 6.634e-04 5.288e-05 3.430e-04 1.176e-03 3.057e+00 1.252e-04 7.885e-04
 1.415e-04 9.900e-04 8.589e-04 1.728e-04 2.153e-04 3.103e-04 5.194e-03
 3.696e-01 4.210e-04 8.175e-05 1.805e-01 1.529e-01 2.371e-04 3.593e-03
 6.136e-05 1.729e-03 4.267e-01 5.799e-01 2.072e-04 6.430e-04 3.169e-02
 4.077e-02 7.764e-02 2.020e-04 1.125e-01 3.047e+00 1.651e-02 8.033e-03
 3.454e-04 1.212e+00 1.069e-01 1.585e+00 3.144e-02 1.628e-02 2.119e-02
 1.264e-01 1.398e+00 2.136e-04 1.127e+00 1.231e+00 3.196e-03 6.293e-03
 3.254e-04 3.368e+00 3.864e-01 4.339e-01 1.576e-01 1.130e-02 5.624e-01
 8.923e-02 3.157e-04 3.306e-04 7.760e-05 1.109e-01 7.500e-05 1.536e-04
 2.248e-04 2.530e-04 1.060e-01 8.126e-02 2.152e-03 4.216e-03 1.418e-04]
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.]
 [0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.9805555555555556, 0.9709424613206593)
cuda
2565
cuda
Objective function 454.76 = squared loss an data 233.99 + 0.5*rho*h**2 220.188202 + alpha*h 0.000000 + L2reg 0.28 + L1reg 0.30 ; SHD = 120 ; DAG False
||w||^2 20582.119893884323
exp ma of ||w||^2 1135195542.888187
||w|| 143.46469912101836
exp ma of ||w|| 1478.0784913015088
||w||^2 11.361599960968176
exp ma of ||w||^2 9784206.357169056
||w|| 3.3706972514552795
exp ma of ||w|| 19.71405745659794
||w||^2 0.11189873541944484
exp ma of ||w||^2 0.15996112178835983
||w|| 0.33451268349562596
exp ma of ||w|| 0.3916214032905698
||w||^2 0.1428001403664483
exp ma of ||w||^2 0.15553039790267556
||w|| 0.377889058278284
exp ma of ||w|| 0.3855732162914537
||w||^2 0.15935696501670596
exp ma of ||w||^2 0.16317352921891787
||w|| 0.39919539703847534
exp ma of ||w|| 0.3940112369285254
||w||^2 0.1032843707871022
exp ma of ||w||^2 0.1917961074085696
||w|| 0.32137885864988414
exp ma of ||w|| 0.41559655487255226
cuda
Objective function 51.22 = squared loss an data 49.35 + 0.5*rho*h**2 1.460204 + alpha*h 0.000000 + L2reg 0.26 + L1reg 0.15 ; SHD = 56 ; DAG False
Proportion of microbatches that were clipped  0.7274178104053622
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 1.7089198649903352
iteration 1 in outer loop, alpha = 1.7089198649903352, rho = 1.0, h = 1.7089198649903352
cuda
2565
cuda
Objective function 54.14 = squared loss an data 49.35 + 0.5*rho*h**2 1.460204 + alpha*h 2.920407 + L2reg 0.26 + L1reg 0.15 ; SHD = 56 ; DAG False
||w||^2 22417.43450990573
exp ma of ||w||^2 347799.04927093984
||w|| 149.7245287516569
exp ma of ||w|| 306.03016380327006
||w||^2 1870.8125971186537
exp ma of ||w||^2 43422.25540195918
||w|| 43.25289119953317
exp ma of ||w|| 77.47909028091084
||w||^2 10273.378016762628
exp ma of ||w||^2 29930.186813280063
||w|| 101.35767369450933
exp ma of ||w|| 61.106728540611975
||w||^2 10.027353966081556
exp ma of ||w||^2 2647.2579740823767
||w|| 3.166599748323358
exp ma of ||w|| 12.682151340008069
||w||^2 0.3062482173780283
exp ma of ||w||^2 0.2553761619627974
||w|| 0.5533969799140833
exp ma of ||w|| 0.43444083684398854
||w||^2 0.08717078226710787
exp ma of ||w||^2 0.31044442336711464
||w|| 0.2952469851956288
exp ma of ||w|| 0.5125573452037137
||w||^2 0.12233088662804449
exp ma of ||w||^2 0.3394994337722569
||w|| 0.34975832603105317
exp ma of ||w|| 0.529787596881544
cuda
Objective function 23.27 = squared loss an data 20.22 + 0.5*rho*h**2 0.582350 + alpha*h 1.844287 + L2reg 0.48 + L1reg 0.14 ; SHD = 46 ; DAG False
Proportion of microbatches that were clipped  0.7348066298342542
iteration 1 in inner loop, alpha 1.7089198649903352 rho 1.0 h 1.079212309432073
2565
cuda
Objective function 28.51 = squared loss an data 20.22 + 0.5*rho*h**2 5.823496 + alpha*h 1.844287 + L2reg 0.48 + L1reg 0.14 ; SHD = 46 ; DAG False
||w||^2 2944118047.5089808
exp ma of ||w||^2 12555133991.632694
||w|| 54259.72767632529
exp ma of ||w|| 95587.55778576784
||w||^2 303625.0750210592
exp ma of ||w||^2 10891050.010842055
||w|| 551.021846228495
exp ma of ||w|| 2088.760354350053
||w||^2 0.49969195203580097
exp ma of ||w||^2 1.8454819738425972
||w|| 0.706888924821857
exp ma of ||w|| 0.6839659513133921
||w||^2 0.8715683483231639
exp ma of ||w||^2 0.4708672685926511
||w|| 0.9335782497054887
exp ma of ||w|| 0.6306617156691704
||w||^2 0.09836538688870491
exp ma of ||w||^2 0.5222329759683315
||w|| 0.3136325666902353
exp ma of ||w|| 0.6616472815691132
||w||^2 0.16996894508886867
exp ma of ||w||^2 0.5145349846418423
||w|| 0.41227290123032423
exp ma of ||w|| 0.6614820289039228
cuda
Objective function 18.70 = squared loss an data 15.95 + 0.5*rho*h**2 1.165209 + alpha*h 0.824971 + L2reg 0.63 + L1reg 0.13 ; SHD = 35 ; DAG False
Proportion of microbatches that were clipped  0.743613853627958
iteration 2 in inner loop, alpha 1.7089198649903352 rho 10.0 h 0.48274405831542744
2565
cuda
Objective function 29.18 = squared loss an data 15.95 + 0.5*rho*h**2 11.652091 + alpha*h 0.824971 + L2reg 0.63 + L1reg 0.13 ; SHD = 35 ; DAG False
||w||^2 1.5072606861555533
exp ma of ||w||^2 8.772872205012984
||w|| 1.2277054557814562
exp ma of ||w|| 0.9744251075625278
||w||^2 0.11114469083962866
exp ma of ||w||^2 0.7312368660198125
||w|| 0.3333836991210408
exp ma of ||w|| 0.7810353741863318
||w||^2 1.327407012588118
exp ma of ||w||^2 0.7827810151161867
||w|| 1.152131508373987
exp ma of ||w|| 0.7857228913025588
cuda
Objective function 18.81 = squared loss an data 16.69 + 0.5*rho*h**2 1.033644 + alpha*h 0.245710 + L2reg 0.73 + L1reg 0.11 ; SHD = 31 ; DAG True
Proportion of microbatches that were clipped  0.7505480739116818
iteration 3 in inner loop, alpha 1.7089198649903352 rho 100.0 h 0.14378067900594793
iteration 2 in outer loop, alpha = 16.08698776558513, rho = 100.0, h = 0.14378067900594793
cuda
2565
cuda
Objective function 20.88 = squared loss an data 16.69 + 0.5*rho*h**2 1.033644 + alpha*h 2.312998 + L2reg 0.73 + L1reg 0.11 ; SHD = 31 ; DAG True
||w||^2 111030966.50301108
exp ma of ||w||^2 698186992.8863189
||w|| 10537.123255567009
exp ma of ||w|| 20472.365714308675
||w||^2 350159.02110983717
exp ma of ||w||^2 5258272.022262129
||w|| 591.7423604152716
exp ma of ||w|| 1300.0368335201701
||w||^2 13.0718508884402
exp ma of ||w||^2 714.196571250646
||w|| 3.6155014712263913
exp ma of ||w|| 4.39205745912708
||w||^2 0.9397179231593821
exp ma of ||w||^2 22.256972925001666
||w|| 0.969390490545158
exp ma of ||w|| 1.2946846764013846
||w||^2 0.4270130468135736
exp ma of ||w||^2 1.3145537042914466
||w|| 0.6534623530193409
exp ma of ||w|| 0.8988485826953666
||w||^2 0.4105910077924796
exp ma of ||w||^2 1.132315316469896
||w|| 0.6407737571034566
exp ma of ||w|| 0.9481647300665093
cuda
Objective function 19.00 = squared loss an data 16.04 + 0.5*rho*h**2 0.465035 + alpha*h 1.551432 + L2reg 0.83 + L1reg 0.10 ; SHD = 28 ; DAG True
Proportion of microbatches that were clipped  0.743739837398374
iteration 1 in inner loop, alpha 16.08698776558513 rho 100.0 h 0.09644016301422909
2565
cuda
Objective function 23.18 = squared loss an data 16.04 + 0.5*rho*h**2 4.650353 + alpha*h 1.551432 + L2reg 0.83 + L1reg 0.10 ; SHD = 28 ; DAG True
||w||^2 183022434393.0641
exp ma of ||w||^2 170823730817.721
||w|| 427811.2134961683
exp ma of ||w|| 265435.7948128941
||w||^2 7104029131.179642
exp ma of ||w||^2 39671017509.1552
||w|| 84285.40283572026
exp ma of ||w|| 174421.48339266714
||w||^2 30396358.133278966
exp ma of ||w||^2 132901923.2151977
||w|| 5513.289229967802
exp ma of ||w|| 7783.683315266478
||w||^2 21.79267287171437
exp ma of ||w||^2 6749.38666492169
||w|| 4.6682622967989245
exp ma of ||w|| 13.949977262868288
||w||^2 6.366207344818996
exp ma of ||w||^2 978.0549175709896
||w|| 2.52313442860641
exp ma of ||w|| 4.312279592445304
cuda
Objective function 18.71 = squared loss an data 16.36 + 0.5*rho*h**2 0.732129 + alpha*h 0.615579 + L2reg 0.90 + L1reg 0.10 ; SHD = 30 ; DAG True
Proportion of microbatches that were clipped  0.7566533864541832
iteration 2 in inner loop, alpha 16.08698776558513 rho 1000.0 h 0.03826562327405547
2565
cuda
Objective function 25.30 = squared loss an data 16.36 + 0.5*rho*h**2 7.321290 + alpha*h 0.615579 + L2reg 0.90 + L1reg 0.10 ; SHD = 30 ; DAG True
||w||^2 1855323360.5820482
exp ma of ||w||^2 8815790782.909847
||w|| 43073.46469210537
exp ma of ||w|| 74774.35159254944
||w||^2 3211005.957266394
exp ma of ||w||^2 98124000.42431217
||w|| 1791.9280000229903
exp ma of ||w|| 6482.987516571571
||w||^2 9588718.625330392
exp ma of ||w||^2 94497105.1724797
||w|| 3096.565617798272
exp ma of ||w|| 6322.529474036585
||w||^2 0.5070648263376926
exp ma of ||w||^2 1.1409721645193835
||w|| 0.712084844901008
exp ma of ||w|| 0.9984274917713882
||w||^2 1.7411767994955314
exp ma of ||w||^2 0.9925695068519493
||w|| 1.3195365851296172
exp ma of ||w|| 0.935658389094789
cuda
Objective function 18.77 = squared loss an data 16.74 + 0.5*rho*h**2 0.755568 + alpha*h 0.197755 + L2reg 0.98 + L1reg 0.10 ; SHD = 32 ; DAG True
Proportion of microbatches that were clipped  0.7535904469904793
iteration 3 in inner loop, alpha 16.08698776558513 rho 10000.0 h 0.012292826258505585
iteration 3 in outer loop, alpha = 139.01525035064097, rho = 10000.0, h = 0.012292826258505585
cuda
2565
cuda
Objective function 20.28 = squared loss an data 16.74 + 0.5*rho*h**2 0.755568 + alpha*h 1.708890 + L2reg 0.98 + L1reg 0.10 ; SHD = 32 ; DAG True
||w||^2 63287401790.70763
exp ma of ||w||^2 213864700584.02295
||w|| 251569.8745690899
exp ma of ||w|| 386744.99098955037
||w||^2 39449487051.799866
exp ma of ||w||^2 67312617601.91684
||w|| 198618.9493774445
exp ma of ||w|| 210732.06976130634
||w||^2 745.236072205035
exp ma of ||w||^2 247173.70712639837
||w|| 27.299012293580056
exp ma of ||w|| 146.26653007767592
||w||^2 2.6671305061888027
exp ma of ||w||^2 61.58872660918297
||w|| 1.6331351769491718
exp ma of ||w|| 1.8317926022024742
||w||^2 1.038742784002929
exp ma of ||w||^2 15.684030578610507
||w|| 1.019187315464105
exp ma of ||w|| 1.4830992889292451
||w||^2 0.3646724696435714
exp ma of ||w||^2 1.00376970480397
||w|| 0.6038811717909174
exp ma of ||w|| 0.9422816950458791
||w||^2 0.6054998096471194
exp ma of ||w||^2 0.8572716105107199
||w|| 0.7781386827854784
exp ma of ||w|| 0.8733267272639419
||w||^2 0.6228395881372482
exp ma of ||w||^2 1.0172578898981768
||w|| 0.7892018677988846
exp ma of ||w|| 0.9363570932189266
||w||^2 0.8087882612802393
exp ma of ||w||^2 1.067475542329651
||w|| 0.8993265598659028
exp ma of ||w|| 0.9306339515648857
||w||^2 2.0786990340085336
exp ma of ||w||^2 0.9230943763886087
||w|| 1.4417694108311958
exp ma of ||w|| 0.907000681398175
||w||^2 0.5535147392658929
exp ma of ||w||^2 0.887991548789707
||w|| 0.7439857117350392
exp ma of ||w|| 0.8927950418103903
cuda
Objective function 18.76 = squared loss an data 16.40 + 0.5*rho*h**2 0.251270 + alpha*h 0.985480 + L2reg 1.02 + L1reg 0.10 ; SHD = 28 ; DAG True
Proportion of microbatches that were clipped  0.7565726955970858
iteration 1 in inner loop, alpha 139.01525035064097 rho 10000.0 h 0.007089002918524656
2565
cuda
Objective function 21.02 = squared loss an data 16.40 + 0.5*rho*h**2 2.512698 + alpha*h 0.985480 + L2reg 1.02 + L1reg 0.10 ; SHD = 28 ; DAG True
||w||^2 24024.629724072052
exp ma of ||w||^2 22420204.41272485
||w|| 154.9988055569205
exp ma of ||w|| 547.3334666219284
||w||^2 3.065877338036914
exp ma of ||w||^2 227.64793392177359
||w|| 1.750964687832657
exp ma of ||w|| 1.8500793661493666
||w||^2 0.839790237033989
exp ma of ||w||^2 1.060798551708612
||w|| 0.9164006967664249
exp ma of ||w|| 0.9718466883643042
||w||^2 1.4987537195728757
exp ma of ||w||^2 1.0133048028175768
||w|| 1.2242359738109625
exp ma of ||w|| 0.9449955780554933
cuda
Objective function 18.30 = squared loss an data 16.08 + 0.5*rho*h**2 0.559913 + alpha*h 0.465198 + L2reg 1.10 + L1reg 0.10 ; SHD = 28 ; DAG True
Proportion of microbatches that were clipped  0.7512583211560319
iteration 2 in inner loop, alpha 139.01525035064097 rho 100000.0 h 0.0033463812012985983
iteration 4 in outer loop, alpha = 3485.396451649239, rho = 1000000.0, h = 0.0033463812012985983
Threshold 0.3
[[0.004 0.049 0.047 0.255 0.214 0.075 0.028 0.005 0.028 0.925 0.04  0.065
  0.049 0.012 0.063]
 [0.104 0.007 0.397 0.389 0.266 0.24  0.072 0.077 0.32  0.221 0.229 0.963
  0.098 0.009 0.131]
 [0.09  0.014 0.004 0.094 0.32  0.022 0.063 0.033 0.056 0.115 0.101 0.06
  0.039 0.015 0.138]
 [0.04  0.013 0.045 0.006 0.152 0.019 0.013 0.008 0.031 0.15  0.085 0.061
  0.032 0.014 0.206]
 [0.005 0.009 0.014 0.028 0.007 0.004 0.004 0.006 0.005 0.001 0.003 0.017
  0.002 0.002 0.015]
 [0.06  0.028 0.094 0.162 0.434 0.002 0.029 0.043 0.133 0.304 0.296 0.361
  0.024 0.012 0.118]
 [0.147 0.077 0.074 0.344 0.469 0.17  0.004 0.041 0.271 0.153 0.898 0.316
  0.028 0.049 0.069]
 [0.769 0.067 0.144 0.515 0.484 0.093 0.143 0.005 0.163 0.375 0.152 0.177
  0.097 0.02  0.106]
 [0.177 0.015 0.078 0.139 0.363 0.011 0.02  0.037 0.006 0.76  0.789 0.013
  0.031 0.002 0.059]
 [0.007 0.022 0.048 0.042 1.712 0.013 0.019 0.007 0.006 0.006 0.025 0.031
  0.022 0.004 0.03 ]
 [0.103 0.026 0.045 0.08  1.666 0.01  0.005 0.022 0.006 0.275 0.007 0.03
  0.005 0.004 0.044]
 [0.085 0.006 0.059 0.105 0.216 0.018 0.016 0.027 0.432 0.179 0.207 0.004
  0.028 0.005 0.044]
 [0.123 0.049 0.155 0.11  0.536 0.131 0.127 0.069 0.103 0.214 1.124 0.198
  0.004 0.064 0.209]
 [0.239 0.66  0.265 0.335 0.412 0.427 0.1   0.177 1.548 0.79  0.751 0.897
  0.089 0.005 0.129]
 [0.048 0.032 0.043 0.027 0.296 0.038 0.058 0.037 0.084 0.167 0.128 0.082
  0.021 0.033 0.005]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.925 0.    0.
  0.    0.    0.   ]
 [0.    0.    0.397 0.389 0.    0.    0.    0.    0.32  0.    0.    0.963
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.32  0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.434 0.    0.    0.    0.    0.304 0.    0.361
  0.    0.    0.   ]
 [0.    0.    0.    0.344 0.469 0.    0.    0.    0.    0.    0.898 0.316
  0.    0.    0.   ]
 [0.769 0.    0.    0.515 0.484 0.    0.    0.    0.    0.375 0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.363 0.    0.    0.    0.    0.76  0.789 0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    1.712 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    1.666 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.432 0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.536 0.    0.    0.    0.    0.    1.124 0.
  0.    0.    0.   ]
 [0.    0.66  0.    0.335 0.412 0.427 0.    0.    1.548 0.79  0.751 0.897
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]]
{'fdr': 0.48484848484848486, 'tpr': 0.5666666666666667, 'fpr': 0.21333333333333335, 'f1': 0.5396825396825397, 'shd': 28, 'npred': 33, 'ntrue': 30}
[4.921e-02 4.721e-02 2.550e-01 2.140e-01 7.473e-02 2.850e-02 5.078e-03
 2.782e-02 9.251e-01 3.985e-02 6.506e-02 4.937e-02 1.250e-02 6.286e-02
 1.037e-01 3.966e-01 3.885e-01 2.660e-01 2.403e-01 7.220e-02 7.705e-02
 3.197e-01 2.210e-01 2.288e-01 9.630e-01 9.753e-02 8.780e-03 1.306e-01
 9.014e-02 1.413e-02 9.408e-02 3.195e-01 2.239e-02 6.312e-02 3.347e-02
 5.606e-02 1.149e-01 1.012e-01 5.957e-02 3.871e-02 1.511e-02 1.378e-01
 4.026e-02 1.283e-02 4.516e-02 1.516e-01 1.881e-02 1.273e-02 8.316e-03
 3.123e-02 1.503e-01 8.487e-02 6.123e-02 3.157e-02 1.442e-02 2.055e-01
 4.671e-03 8.992e-03 1.402e-02 2.781e-02 3.853e-03 4.110e-03 5.803e-03
 5.205e-03 1.154e-03 2.651e-03 1.708e-02 2.231e-03 2.209e-03 1.488e-02
 6.018e-02 2.770e-02 9.395e-02 1.624e-01 4.337e-01 2.942e-02 4.259e-02
 1.326e-01 3.044e-01 2.962e-01 3.607e-01 2.437e-02 1.205e-02 1.175e-01
 1.471e-01 7.721e-02 7.445e-02 3.438e-01 4.694e-01 1.701e-01 4.129e-02
 2.712e-01 1.534e-01 8.983e-01 3.163e-01 2.838e-02 4.937e-02 6.873e-02
 7.688e-01 6.729e-02 1.442e-01 5.155e-01 4.839e-01 9.270e-02 1.434e-01
 1.629e-01 3.746e-01 1.517e-01 1.766e-01 9.658e-02 1.992e-02 1.062e-01
 1.768e-01 1.538e-02 7.755e-02 1.395e-01 3.633e-01 1.111e-02 2.040e-02
 3.658e-02 7.597e-01 7.891e-01 1.273e-02 3.118e-02 2.467e-03 5.884e-02
 6.812e-03 2.207e-02 4.787e-02 4.234e-02 1.712e+00 1.276e-02 1.920e-02
 7.078e-03 6.470e-03 2.523e-02 3.149e-02 2.174e-02 3.698e-03 2.996e-02
 1.026e-01 2.618e-02 4.519e-02 8.014e-02 1.666e+00 1.009e-02 5.384e-03
 2.172e-02 6.397e-03 2.755e-01 2.983e-02 4.523e-03 4.179e-03 4.381e-02
 8.500e-02 6.284e-03 5.922e-02 1.047e-01 2.161e-01 1.795e-02 1.620e-02
 2.656e-02 4.322e-01 1.789e-01 2.071e-01 2.806e-02 4.938e-03 4.432e-02
 1.233e-01 4.864e-02 1.546e-01 1.097e-01 5.356e-01 1.314e-01 1.272e-01
 6.932e-02 1.031e-01 2.144e-01 1.124e+00 1.978e-01 6.372e-02 2.090e-01
 2.395e-01 6.598e-01 2.653e-01 3.353e-01 4.123e-01 4.273e-01 1.002e-01
 1.765e-01 1.548e+00 7.902e-01 7.511e-01 8.969e-01 8.923e-02 1.294e-01
 4.759e-02 3.199e-02 4.306e-02 2.680e-02 2.962e-01 3.781e-02 5.807e-02
 3.673e-02 8.429e-02 1.672e-01 1.275e-01 8.176e-02 2.084e-02 3.291e-02]
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.]
 [0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.8301851851851852, 0.6036370035540393)
Iterations 567
Achieves (7.541179662743805, 1e-05)-DP
