samples  5000  graph  20 80 ER mlp  minibatch size  50  noise  0.8  minibatches per NN training  250 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.7622777646747636
iteration 1 in outer loop, alpha = 1.7622777646747636, rho = 1.0, h = 1.7622777646747636
cuda
iteration 1 in inner loop,alpha 1.7622777646747636 rho 1.0 h 1.1769941079911774
iteration 2 in inner loop,alpha 1.7622777646747636 rho 10.0 h 0.546699080645368
iteration 3 in inner loop,alpha 1.7622777646747636 rho 100.0 h 0.18621708103119516
iteration 2 in outer loop, alpha = 20.38398586779428, rho = 100.0, h = 0.18621708103119516
cuda
iteration 1 in inner loop,alpha 20.38398586779428 rho 100.0 h 0.10940001097876006
iteration 2 in inner loop,alpha 20.38398586779428 rho 1000.0 h 0.04301154858590195
iteration 3 in outer loop, alpha = 63.39553445369623, rho = 1000.0, h = 0.04301154858590195
cuda
iteration 1 in inner loop,alpha 63.39553445369623 rho 1000.0 h 0.023128187443614223
iteration 2 in inner loop,alpha 63.39553445369623 rho 10000.0 h 0.007902794642451028
iteration 4 in outer loop, alpha = 142.4234808782065, rho = 10000.0, h = 0.007902794642451028
cuda
iteration 1 in inner loop,alpha 142.4234808782065 rho 10000.0 h 0.004070041409214298
iteration 2 in inner loop,alpha 142.4234808782065 rho 100000.0 h 0.0013553723134869244
iteration 5 in outer loop, alpha = 277.960712226899, rho = 100000.0, h = 0.0013553723134869244
cuda
iteration 1 in inner loop,alpha 277.960712226899 rho 100000.0 h 0.0006781233923440766
iteration 6 in outer loop, alpha = 956.0841045709756, rho = 1000000.0, h = 0.0006781233923440766
Threshold 0.3
[[0.001 3.157 0.076 0.244 0.906 1.124 0.317 0.    1.976 1.125 0.121 1.159
  0.262 0.001 0.362 0.487 0.304 1.229 1.315 0.47 ]
 [0.    0.001 0.022 0.496 0.486 1.674 1.783 0.    0.547 0.453 0.087 0.673
  0.311 0.001 1.221 0.307 0.36  0.864 0.486 1.91 ]
 [0.003 0.01  0.    0.056 0.458 0.558 1.535 0.    0.204 0.576 0.096 0.184
  1.318 0.001 1.511 0.347 0.634 0.001 1.21  0.337]
 [0.    0.    0.    0.021 0.001 0.003 0.001 0.    0.    0.002 0.    0.
  0.    0.    0.219 0.19  0.214 0.    0.001 0.728]
 [0.    0.    0.    0.568 0.004 0.324 0.227 0.    0.    0.425 0.001 0.001
  0.002 0.    0.228 0.316 1.249 0.    0.338 1.082]
 [0.    0.    0.    0.496 0.002 0.003 0.001 0.    0.    0.    0.    0.
  0.    0.    0.359 1.744 1.851 0.    0.292 0.284]
 [0.    0.    0.    0.207 0.001 0.228 0.002 0.    0.    0.009 0.    0.
  0.    0.    0.363 0.292 0.279 0.    0.171 0.205]
 [2.566 0.134 0.001 0.101 0.717 0.22  0.742 0.001 0.311 0.488 0.132 0.396
  1.989 0.708 0.225 0.199 0.191 1.143 0.495 0.462]
 [0.    0.    0.002 0.326 1.623 0.951 1.309 0.    0.001 0.813 0.462 0.29
  1.791 0.    1.25  1.268 0.859 0.    1.353 0.716]
 [0.    0.    0.    0.104 0.015 2.219 0.13  0.    0.    0.007 0.001 0.001
  0.    0.    1.202 1.381 1.775 0.    0.827 0.228]
 [0.    0.    0.    0.923 0.115 0.589 2.336 0.    0.    0.255 0.001 0.
  0.    0.    1.532 0.518 1.043 0.    0.283 1.339]
 [0.    0.    0.    0.144 0.445 0.25  1.683 0.    0.    0.326 0.126 0.001
  0.113 0.    0.179 0.918 0.305 0.    0.121 0.235]
 [0.    0.    0.    0.111 0.145 1.41  1.072 0.    0.    0.196 2.165 0.002
  0.001 0.    0.311 0.387 0.311 0.    0.488 1.121]
 [0.151 0.036 0.03  0.718 0.346 1.66  0.334 0.001 0.295 0.354 1.727 0.532
  2.081 0.001 0.436 0.423 1.056 0.351 0.741 2.008]
 [0.    0.    0.    0.003 0.001 0.001 0.    0.    0.    0.    0.    0.
  0.    0.    0.002 0.288 0.002 0.    0.001 0.002]
 [0.    0.    0.    0.003 0.001 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.001 0.006 0.001 0.    0.001 0.   ]
 [0.    0.    0.    0.002 0.001 0.001 0.001 0.    0.    0.    0.    0.
  0.    0.    1.149 1.278 0.004 0.    0.001 0.001]
 [0.    0.    0.031 0.045 0.475 0.296 1.414 0.    3.193 0.59  0.094 0.735
  0.077 0.    0.351 0.188 0.206 0.001 0.423 0.261]
 [0.    0.    0.    0.752 0.001 0.001 0.001 0.    0.    0.001 0.    0.
  0.    0.    0.338 1.164 0.385 0.    0.001 0.243]
 [0.    0.    0.    0.003 0.    0.    0.001 0.    0.    0.001 0.    0.
  0.    0.    0.118 1.844 0.301 0.    0.001 0.002]]
[[0.    3.157 0.    0.    0.906 1.124 0.317 0.    1.976 1.125 0.    1.159
  0.    0.    0.362 0.487 0.304 1.229 1.315 0.47 ]
 [0.    0.    0.    0.496 0.486 1.674 1.783 0.    0.547 0.453 0.    0.673
  0.311 0.    1.221 0.307 0.36  0.864 0.486 1.91 ]
 [0.    0.    0.    0.    0.458 0.558 1.535 0.    0.    0.576 0.    0.
  1.318 0.    1.511 0.347 0.634 0.    1.21  0.337]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.728]
 [0.    0.    0.    0.568 0.    0.324 0.    0.    0.    0.425 0.    0.
  0.    0.    0.    0.316 1.249 0.    0.338 1.082]
 [0.    0.    0.    0.496 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.359 1.744 1.851 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.363 0.    0.    0.    0.    0.   ]
 [2.566 0.    0.    0.    0.717 0.    0.742 0.    0.311 0.488 0.    0.396
  1.989 0.708 0.    0.    0.    1.143 0.495 0.462]
 [0.    0.    0.    0.326 1.623 0.951 1.309 0.    0.    0.813 0.462 0.
  1.791 0.    1.25  1.268 0.859 0.    1.353 0.716]
 [0.    0.    0.    0.    0.    2.219 0.    0.    0.    0.    0.    0.
  0.    0.    1.202 1.381 1.775 0.    0.827 0.   ]
 [0.    0.    0.    0.923 0.    0.589 2.336 0.    0.    0.    0.    0.
  0.    0.    1.532 0.518 1.043 0.    0.    1.339]
 [0.    0.    0.    0.    0.445 0.    1.683 0.    0.    0.326 0.    0.
  0.    0.    0.    0.918 0.305 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    1.41  1.072 0.    0.    0.    2.165 0.
  0.    0.    0.311 0.387 0.311 0.    0.488 1.121]
 [0.    0.    0.    0.718 0.346 1.66  0.334 0.    0.    0.354 1.727 0.532
  2.081 0.    0.436 0.423 1.056 0.351 0.741 2.008]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    1.149 1.278 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.475 0.    1.414 0.    3.193 0.59  0.    0.735
  0.    0.    0.351 0.    0.    0.    0.423 0.   ]
 [0.    0.    0.    0.752 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.338 1.164 0.385 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    1.844 0.301 0.    0.    0.   ]]
{'fdr': 0.44881889763779526, 'tpr': 0.875, 'fpr': 0.5181818181818182, 'f1': 0.676328502415459, 'shd': 62, 'npred': 127, 'ntrue': 80}
[3.157e+00 7.582e-02 2.437e-01 9.063e-01 1.124e+00 3.169e-01 2.342e-04
 1.976e+00 1.125e+00 1.214e-01 1.159e+00 2.622e-01 1.380e-03 3.620e-01
 4.875e-01 3.036e-01 1.229e+00 1.315e+00 4.698e-01 4.008e-04 2.225e-02
 4.956e-01 4.860e-01 1.674e+00 1.783e+00 1.670e-04 5.466e-01 4.535e-01
 8.660e-02 6.726e-01 3.110e-01 1.171e-03 1.221e+00 3.066e-01 3.595e-01
 8.640e-01 4.857e-01 1.910e+00 2.583e-03 1.016e-02 5.552e-02 4.582e-01
 5.582e-01 1.535e+00 7.199e-05 2.039e-01 5.758e-01 9.583e-02 1.840e-01
 1.318e+00 6.724e-04 1.511e+00 3.467e-01 6.339e-01 7.014e-04 1.210e+00
 3.367e-01 7.771e-05 1.375e-05 8.293e-05 6.855e-04 2.659e-03 1.150e-03
 7.765e-05 9.243e-05 2.020e-03 4.242e-04 2.218e-04 8.570e-05 7.131e-06
 2.186e-01 1.898e-01 2.139e-01 1.949e-05 1.250e-03 7.278e-01 5.770e-06
 3.187e-06 3.090e-04 5.676e-01 3.235e-01 2.269e-01 1.710e-05 1.356e-04
 4.247e-01 1.450e-03 1.108e-03 2.376e-03 7.225e-05 2.277e-01 3.164e-01
 1.249e+00 1.607e-05 3.380e-01 1.082e+00 8.128e-05 1.889e-04 6.577e-05
 4.960e-01 1.999e-03 1.436e-03 4.693e-05 7.570e-05 4.296e-04 5.281e-05
 2.439e-04 2.570e-04 6.664e-06 3.585e-01 1.744e+00 1.851e+00 1.293e-05
 2.919e-01 2.842e-01 5.558e-05 8.610e-05 5.032e-06 2.073e-01 1.104e-03
 2.284e-01 2.593e-05 1.010e-05 8.597e-03 1.272e-04 1.849e-04 7.417e-05
 3.727e-05 3.626e-01 2.916e-01 2.792e-01 1.833e-06 1.707e-01 2.049e-01
 2.566e+00 1.339e-01 5.798e-04 1.011e-01 7.168e-01 2.202e-01 7.422e-01
 3.105e-01 4.883e-01 1.324e-01 3.965e-01 1.989e+00 7.085e-01 2.249e-01
 1.989e-01 1.910e-01 1.143e+00 4.954e-01 4.616e-01 1.014e-05 5.007e-06
 1.557e-03 3.257e-01 1.623e+00 9.509e-01 1.309e+00 1.025e-05 8.128e-01
 4.623e-01 2.902e-01 1.791e+00 2.800e-05 1.250e+00 1.268e+00 8.593e-01
 4.937e-05 1.353e+00 7.156e-01 3.031e-05 3.063e-05 9.380e-05 1.043e-01
 1.483e-02 2.219e+00 1.304e-01 5.682e-05 1.621e-04 5.808e-04 7.252e-04
 2.659e-04 1.184e-04 1.202e+00 1.381e+00 1.775e+00 3.329e-05 8.265e-01
 2.277e-01 6.667e-06 8.859e-06 6.319e-05 9.235e-01 1.149e-01 5.888e-01
 2.336e+00 2.078e-05 6.795e-05 2.549e-01 4.403e-04 2.334e-04 4.332e-05
 1.532e+00 5.180e-01 1.043e+00 1.673e-05 2.827e-01 1.339e+00 2.685e-05
 5.167e-05 2.870e-04 1.443e-01 4.453e-01 2.496e-01 1.683e+00 1.612e-05
 2.317e-04 3.264e-01 1.259e-01 1.125e-01 5.767e-05 1.793e-01 9.182e-01
 3.054e-01 1.718e-04 1.213e-01 2.355e-01 5.155e-06 3.968e-06 1.746e-04
 1.110e-01 1.448e-01 1.410e+00 1.072e+00 2.961e-05 2.215e-04 1.963e-01
 2.165e+00 1.600e-03 8.038e-05 3.110e-01 3.871e-01 3.108e-01 8.230e-06
 4.877e-01 1.121e+00 1.508e-01 3.609e-02 3.007e-02 7.181e-01 3.459e-01
 1.660e+00 3.336e-01 6.435e-04 2.955e-01 3.537e-01 1.727e+00 5.320e-01
 2.081e+00 4.361e-01 4.228e-01 1.056e+00 3.511e-01 7.411e-01 2.008e+00
 4.031e-05 7.041e-05 2.897e-05 3.045e-03 1.029e-03 6.781e-04 3.321e-04
 2.679e-05 3.732e-06 4.603e-05 8.701e-05 1.753e-04 5.444e-05 2.733e-05
 2.885e-01 2.222e-03 2.030e-06 5.933e-04 1.700e-03 2.408e-05 1.978e-05
 2.609e-05 2.521e-03 5.104e-04 1.006e-04 3.631e-04 1.868e-05 2.508e-05
 2.160e-04 8.025e-05 5.483e-05 2.124e-05 1.164e-05 8.800e-04 9.155e-04
 4.831e-06 5.010e-04 2.305e-04 4.787e-05 8.907e-05 2.512e-05 1.985e-03
 8.244e-04 5.845e-04 8.747e-04 3.856e-05 4.159e-05 5.826e-05 7.145e-05
 7.236e-05 2.319e-05 1.131e-05 1.149e+00 1.278e+00 4.995e-06 6.509e-04
 1.426e-03 8.998e-05 5.141e-06 3.090e-02 4.481e-02 4.749e-01 2.961e-01
 1.414e+00 9.435e-05 3.193e+00 5.896e-01 9.440e-02 7.354e-01 7.672e-02
 1.302e-04 3.514e-01 1.884e-01 2.065e-01 4.229e-01 2.611e-01 5.486e-05
 1.571e-05 1.423e-04 7.522e-01 9.997e-04 7.802e-04 9.280e-04 4.402e-05
 1.451e-04 5.737e-04 1.565e-04 2.592e-04 1.437e-04 2.067e-05 3.379e-01
 1.164e+00 3.846e-01 1.443e-05 2.434e-01 3.605e-05 7.557e-05 6.269e-05
 2.835e-03 2.486e-04 4.332e-04 5.080e-04 1.793e-05 6.728e-05 9.808e-04
 3.239e-04 1.181e-04 2.179e-04 5.097e-05 1.180e-01 1.844e+00 3.012e-01
 1.491e-05 6.060e-04]
[[0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0.]
 [0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1.]
 [0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0.]
 [0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.]
 [0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.]
 [0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]
 [0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]
[1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1.
 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.
 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.
 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1.
 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
aucroc, aucpr (0.9382916666666667, 0.8927524502943456)
cuda
4420
cuda
Objective function 730.81 = squared loss an data 514.80 + 0.5*rho*h**2 215.201283 + alpha*h 0.000000 + L2reg 0.37 + L1reg 0.45 ; SHD = 206 ; DAG False
v before min max tensor([[-5.098e-03,  5.077e-05, -1.476e-03,  ..., -5.048e-05,  4.404e-03,
         -1.739e-04],
        [-7.380e-03, -1.735e-03, -1.397e-02,  ..., -2.389e-03,  9.430e-07,
         -6.090e-04],
        [-3.184e-03,  5.430e-04, -4.609e-03,  ..., -6.013e-04, -1.964e-04,
         -3.276e-04],
        ...,
        [ 7.370e-02, -1.805e-02, -1.003e-03,  ..., -1.109e-05,  1.586e-04,
         -3.948e-03],
        [-1.411e-03, -4.006e-03, -3.441e-04,  ...,  3.570e-04, -1.134e-04,
         -7.051e-04],
        [ 7.174e-03, -8.979e-05, -1.174e-03,  ..., -8.492e-05,  2.210e-03,
         -6.013e-03]], device='cuda:0')
v tensor([[1.000e-12, 5.077e-05, 1.000e-12,  ..., 1.000e-12, 4.404e-03,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 9.430e-07,
         1.000e-12],
        [1.000e-12, 5.430e-04, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        ...,
        [7.370e-02, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.586e-04,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 3.570e-04, 1.000e-12,
         1.000e-12],
        [7.174e-03, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 2.210e-03,
         1.000e-12]], device='cuda:0')
v before min max tensor([-1.241e-04,  4.055e-03, -1.574e-05, -1.240e-03, -5.950e-05, -3.460e-02,
        -3.253e-04, -8.387e-04, -1.080e-03, -9.039e-04, -1.176e-03, -3.709e-04,
         1.277e-05, -5.248e-03, -6.670e-04, -4.965e-03, -1.224e-05, -3.991e-04,
         1.819e-04,  6.192e-06, -1.809e-04, -3.750e-03,  8.697e-05,  1.106e-05,
         5.165e-02,  1.109e-04, -3.550e-03,  5.052e-06,  1.184e-03, -3.157e-06,
        -3.504e-03, -7.403e-03, -1.043e-02, -3.152e-06,  1.605e-04, -2.671e-03,
        -9.773e-05, -1.150e-02, -1.147e-03, -2.298e-04, -8.273e-05, -5.240e-03,
        -3.658e-04, -3.937e-03, -3.117e-06,  7.843e-05,  9.020e-05, -3.147e-04,
        -3.132e-04,  7.992e-03, -7.129e-03,  3.509e-04, -3.582e-05, -2.663e-05,
        -4.636e-03,  1.142e-03, -6.516e-04, -3.519e-04, -8.827e-04, -4.014e-03,
         2.019e-05, -5.867e-03,  1.057e-03, -2.728e-04, -2.951e-03, -7.254e-06,
         2.253e-04, -2.020e-02, -1.086e-02,  3.857e-05, -1.035e-03, -2.694e-03,
        -2.304e-06, -7.237e-05,  4.928e-04, -1.021e-04,  3.107e-04, -6.677e-05,
        -1.111e-03, -1.428e-05,  1.389e-04,  3.609e-03, -3.234e-04, -9.677e-04,
        -4.146e-02, -5.487e-04, -6.459e-05, -3.919e-05,  1.263e-05, -1.270e-03,
         1.328e-02,  3.448e-03, -8.385e-04,  1.159e-02, -5.208e-05, -1.622e-04,
        -1.635e-04, -1.601e-04, -7.253e-04,  7.488e-05,  1.798e-05,  5.053e-05,
        -4.424e-03, -5.237e-04, -4.446e-03, -5.275e-04,  4.173e-02, -4.984e-04,
        -9.422e-05, -2.253e-03, -6.448e-04,  3.119e-05,  1.559e-04, -2.801e-03,
        -2.632e-03, -4.412e-04, -1.173e-04,  1.295e-04, -1.543e-02,  5.719e-04,
        -1.444e-05,  7.706e-05, -4.798e-04,  9.929e-04, -2.613e-04, -1.704e-04,
         8.914e-04,  2.907e-03, -1.434e-03, -1.044e-02,  1.309e-02,  2.166e-02,
         2.991e-04, -5.382e-04,  1.774e-04, -1.179e-03, -9.438e-06,  3.930e-06,
         4.481e-04, -2.534e-04, -3.479e-05, -1.426e-06, -7.170e-06, -4.296e-04,
        -7.988e-04,  7.065e-05,  5.232e-06,  5.217e-02, -1.568e-02, -1.501e-04,
        -1.142e-03, -1.590e-03,  2.440e-04, -4.524e-02, -1.029e-02,  3.420e-04,
        -6.556e-03,  2.056e-04, -2.902e-04, -1.499e-05, -5.830e-03, -5.423e-05,
        -4.412e-03, -4.770e-05, -5.777e-03,  7.187e-04,  8.544e-03, -5.643e-05,
         7.215e-03,  1.235e-05, -3.096e-04, -3.769e-02, -3.972e-05, -3.349e-04,
        -3.032e-05,  2.433e-03, -4.189e-04, -4.407e-04, -2.323e-05,  3.440e-04,
        -2.630e-04, -2.505e-05, -3.472e-04, -3.013e-05, -1.065e-03,  3.006e-02,
        -8.268e-04,  1.256e-02,  3.339e-04, -1.006e-04, -3.270e-03, -2.739e-05,
        -2.683e-03, -5.097e-04, -7.444e-04, -1.615e-03,  1.835e-03, -1.985e-07,
         1.071e-03, -2.117e-03], device='cuda:0')
v tensor([1.000e-12, 4.055e-03, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.277e-05, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.819e-04, 6.192e-06, 1.000e-12, 1.000e-12, 8.697e-05, 1.106e-05,
        5.165e-02, 1.109e-04, 1.000e-12, 5.052e-06, 1.184e-03, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.605e-04, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 7.843e-05, 9.020e-05, 1.000e-12,
        1.000e-12, 7.992e-03, 1.000e-12, 3.509e-04, 1.000e-12, 1.000e-12,
        1.000e-12, 1.142e-03, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        2.019e-05, 1.000e-12, 1.057e-03, 1.000e-12, 1.000e-12, 1.000e-12,
        2.253e-04, 1.000e-12, 1.000e-12, 3.857e-05, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 4.928e-04, 1.000e-12, 3.107e-04, 1.000e-12,
        1.000e-12, 1.000e-12, 1.389e-04, 3.609e-03, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.263e-05, 1.000e-12,
        1.328e-02, 3.448e-03, 1.000e-12, 1.159e-02, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 7.488e-05, 1.798e-05, 5.053e-05,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 4.173e-02, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 3.119e-05, 1.559e-04, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.295e-04, 1.000e-12, 5.719e-04,
        1.000e-12, 7.706e-05, 1.000e-12, 9.929e-04, 1.000e-12, 1.000e-12,
        8.914e-04, 2.907e-03, 1.000e-12, 1.000e-12, 1.309e-02, 2.166e-02,
        2.991e-04, 1.000e-12, 1.774e-04, 1.000e-12, 1.000e-12, 3.930e-06,
        4.481e-04, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 7.065e-05, 5.232e-06, 5.217e-02, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 2.440e-04, 1.000e-12, 1.000e-12, 3.420e-04,
        1.000e-12, 2.056e-04, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 7.187e-04, 8.544e-03, 1.000e-12,
        7.215e-03, 1.235e-05, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 2.433e-03, 1.000e-12, 1.000e-12, 1.000e-12, 3.440e-04,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.006e-02,
        1.000e-12, 1.256e-02, 3.339e-04, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.835e-03, 1.000e-12,
        1.071e-03, 1.000e-12], device='cuda:0')
v before min max tensor([[[ 4.629e-03],
         [-2.556e-03],
         [-1.294e-03],
         [-3.944e-03],
         [-2.093e-02],
         [-3.004e-03],
         [-2.106e-03],
         [-6.135e-04],
         [-2.459e-05],
         [-9.362e-04]],

        [[-4.110e-02],
         [-5.959e-03],
         [-4.906e-02],
         [-3.777e-02],
         [-1.195e-02],
         [ 1.132e-02],
         [-6.762e-04],
         [ 1.374e-04],
         [ 1.659e-02],
         [-7.001e-02]],

        [[ 7.298e-04],
         [ 4.201e-02],
         [-1.182e-03],
         [-6.307e-02],
         [ 1.151e-02],
         [-2.391e-02],
         [ 2.723e-03],
         [-5.674e-03],
         [-5.993e-03],
         [-8.742e-05]],

        [[-1.143e-02],
         [-4.485e-03],
         [ 2.525e-03],
         [ 1.034e-03],
         [-3.691e-05],
         [-2.039e-03],
         [-1.551e-03],
         [ 3.390e-03],
         [ 4.387e-04],
         [-4.946e-03]],

        [[ 4.653e-02],
         [ 2.672e-01],
         [-2.522e-02],
         [-2.648e-02],
         [ 3.187e-03],
         [-1.585e-04],
         [ 3.012e-02],
         [ 2.920e-01],
         [ 2.553e-03],
         [-4.587e-03]],

        [[ 7.407e-04],
         [-9.681e-04],
         [-1.440e-03],
         [-8.216e-03],
         [ 4.232e-05],
         [-3.083e-04],
         [-1.123e-03],
         [-2.568e-03],
         [-2.865e-03],
         [-2.761e-03]],

        [[ 6.254e-02],
         [-5.270e-03],
         [ 9.551e-03],
         [ 3.789e-03],
         [-1.646e-02],
         [-3.766e-02],
         [-3.564e-02],
         [ 1.918e-03],
         [ 8.800e-03],
         [-9.038e-03]],

        [[-1.295e-05],
         [ 2.454e-03],
         [-4.945e-05],
         [-1.152e-02],
         [-2.685e-03],
         [-5.316e-04],
         [ 5.658e-03],
         [ 5.787e-03],
         [-8.300e-04],
         [ 2.478e-04]],

        [[-3.006e-03],
         [-1.767e-02],
         [ 1.893e-04],
         [ 6.520e-02],
         [ 2.225e-02],
         [ 9.255e-04],
         [ 1.068e-01],
         [-1.226e-03],
         [-1.858e-02],
         [-9.523e-03]],

        [[ 4.544e-02],
         [ 4.945e-02],
         [ 9.243e-02],
         [-4.379e-03],
         [ 3.665e-02],
         [ 1.344e-01],
         [ 7.847e-05],
         [-1.323e-01],
         [-7.699e-03],
         [-2.594e-02]],

        [[-6.225e-03],
         [ 2.162e-03],
         [-6.922e-03],
         [-2.154e-02],
         [-4.471e-02],
         [ 1.344e-04],
         [-3.469e-04],
         [-3.635e-04],
         [ 6.541e-03],
         [ 9.142e-02]],

        [[ 8.457e-04],
         [ 1.258e-03],
         [-7.504e-04],
         [ 1.440e-02],
         [ 5.359e-04],
         [ 5.688e-02],
         [ 2.740e-02],
         [-6.706e-02],
         [ 7.442e-04],
         [-1.625e-04]],

        [[ 1.177e-02],
         [-6.853e-03],
         [ 9.627e-02],
         [-2.643e-02],
         [-4.220e-03],
         [ 2.088e-01],
         [ 4.711e-03],
         [-4.192e-02],
         [-3.471e-02],
         [ 4.487e-03]],

        [[-2.637e-03],
         [ 2.300e-03],
         [-5.800e-02],
         [-8.273e-04],
         [ 1.328e-04],
         [ 8.566e-03],
         [ 9.794e-03],
         [ 2.586e-03],
         [ 6.010e-03],
         [-6.135e-02]],

        [[-5.454e-03],
         [-2.246e-03],
         [-4.715e-03],
         [ 1.577e-02],
         [ 3.689e-03],
         [ 7.418e-03],
         [-2.474e-02],
         [ 9.547e-02],
         [-1.105e-05],
         [-9.536e-07]],

        [[ 1.169e-02],
         [-1.436e-02],
         [ 1.927e-03],
         [ 4.429e-02],
         [-5.771e-03],
         [ 8.237e-02],
         [-3.037e-04],
         [-1.789e-03],
         [-9.401e-03],
         [-6.950e-03]],

        [[ 2.277e-02],
         [-3.513e-03],
         [-1.613e-03],
         [-8.193e-05],
         [-4.213e-03],
         [-1.565e-04],
         [-1.117e-02],
         [-7.333e-03],
         [-2.666e-02],
         [-5.588e-02]],

        [[-3.822e-03],
         [-7.042e-02],
         [-3.207e-02],
         [ 1.790e-02],
         [-9.647e-02],
         [-2.580e-02],
         [-3.396e-03],
         [-1.469e-03],
         [ 6.727e-03],
         [-1.588e-02]],

        [[-1.788e-03],
         [ 2.622e-03],
         [-1.673e-03],
         [ 1.578e-03],
         [-9.345e-05],
         [-4.121e-03],
         [-7.342e-04],
         [-6.314e-04],
         [ 1.080e-06],
         [ 9.021e-03]],

        [[ 3.607e-04],
         [-5.247e-03],
         [-1.726e-04],
         [-7.894e-04],
         [-4.971e-04],
         [-3.484e-05],
         [ 2.800e-03],
         [-4.134e-03],
         [ 1.521e-03],
         [ 1.264e-04]]], device='cuda:0')
v tensor([[[4.629e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.132e-02],
         [1.000e-12],
         [1.374e-04],
         [1.659e-02],
         [1.000e-12]],

        [[7.298e-04],
         [4.201e-02],
         [1.000e-12],
         [1.000e-12],
         [1.151e-02],
         [1.000e-12],
         [2.723e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [2.525e-03],
         [1.034e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.390e-03],
         [4.387e-04],
         [1.000e-12]],

        [[4.653e-02],
         [2.672e-01],
         [1.000e-12],
         [1.000e-12],
         [3.187e-03],
         [1.000e-12],
         [3.012e-02],
         [2.920e-01],
         [2.553e-03],
         [1.000e-12]],

        [[7.407e-04],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.232e-05],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[6.254e-02],
         [1.000e-12],
         [9.551e-03],
         [3.789e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.918e-03],
         [8.800e-03],
         [1.000e-12]],

        [[1.000e-12],
         [2.454e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.658e-03],
         [5.787e-03],
         [1.000e-12],
         [2.478e-04]],

        [[1.000e-12],
         [1.000e-12],
         [1.893e-04],
         [6.520e-02],
         [2.225e-02],
         [9.255e-04],
         [1.068e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[4.544e-02],
         [4.945e-02],
         [9.243e-02],
         [1.000e-12],
         [3.665e-02],
         [1.344e-01],
         [7.847e-05],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [2.162e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.344e-04],
         [1.000e-12],
         [1.000e-12],
         [6.541e-03],
         [9.142e-02]],

        [[8.457e-04],
         [1.258e-03],
         [1.000e-12],
         [1.440e-02],
         [5.359e-04],
         [5.688e-02],
         [2.740e-02],
         [1.000e-12],
         [7.442e-04],
         [1.000e-12]],

        [[1.177e-02],
         [1.000e-12],
         [9.627e-02],
         [1.000e-12],
         [1.000e-12],
         [2.088e-01],
         [4.711e-03],
         [1.000e-12],
         [1.000e-12],
         [4.487e-03]],

        [[1.000e-12],
         [2.300e-03],
         [1.000e-12],
         [1.000e-12],
         [1.328e-04],
         [8.566e-03],
         [9.794e-03],
         [2.586e-03],
         [6.010e-03],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.577e-02],
         [3.689e-03],
         [7.418e-03],
         [1.000e-12],
         [9.547e-02],
         [1.000e-12],
         [1.000e-12]],

        [[1.169e-02],
         [1.000e-12],
         [1.927e-03],
         [4.429e-02],
         [1.000e-12],
         [8.237e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[2.277e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.790e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.727e-03],
         [1.000e-12]],

        [[1.000e-12],
         [2.622e-03],
         [1.000e-12],
         [1.578e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.080e-06],
         [9.021e-03]],

        [[3.607e-04],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.800e-03],
         [1.000e-12],
         [1.521e-03],
         [1.264e-04]]], device='cuda:0')
v before min max tensor([[ 0.002],
        [ 0.120],
        [-0.032],
        [-0.002],
        [ 0.259],
        [ 0.001],
        [ 0.002],
        [-0.005],
        [ 0.043],
        [ 0.251],
        [ 0.079],
        [ 0.039],
        [ 0.035],
        [ 0.006],
        [-0.032],
        [-0.010],
        [ 0.013],
        [ 0.027],
        [-0.015],
        [ 0.017]], device='cuda:0')
v tensor([[2.425e-03],
        [1.202e-01],
        [1.000e-12],
        [1.000e-12],
        [2.585e-01],
        [6.753e-04],
        [2.406e-03],
        [1.000e-12],
        [4.250e-02],
        [2.507e-01],
        [7.936e-02],
        [3.854e-02],
        [3.456e-02],
        [6.325e-03],
        [1.000e-12],
        [1.000e-12],
        [1.256e-02],
        [2.704e-02],
        [1.000e-12],
        [1.699e-02]], device='cuda:0')
a after update for 1 param tensor([[-4.160e-06, -1.131e-05, -2.228e-05,  ...,  3.355e-05,  5.273e-05,
         -5.098e-05],
        [-3.658e-05,  2.735e-06,  5.148e-05,  ..., -4.908e-05, -4.524e-06,
         -2.623e-05],
        [ 6.758e-05, -1.514e-05, -2.714e-05,  ...,  8.420e-06, -1.259e-04,
          1.114e-06],
        ...,
        [ 7.078e-04, -8.927e-07, -1.048e-04,  ..., -4.442e-06,  2.319e-05,
          1.099e-04],
        [-1.830e-05,  3.316e-08, -1.680e-05,  ..., -8.754e-05,  5.556e-05,
         -7.558e-05],
        [ 8.451e-05,  1.058e-05,  1.836e-06,  ..., -1.313e-05,  1.313e-04,
         -3.216e-04]], device='cuda:0')
s after update for 1 param tensor([[3.554e-03, 2.254e-03, 9.317e-04,  ..., 6.094e-05, 2.100e-02,
         6.426e-04],
        [4.324e-03, 1.017e-03, 1.287e-02,  ..., 2.026e-03, 3.071e-04,
         3.568e-04],
        [2.293e-03, 7.376e-03, 3.181e-03,  ..., 3.558e-04, 4.586e-03,
         2.232e-04],
        ...,
        [9.449e-02, 1.221e-02, 1.748e-03,  ..., 4.227e-05, 3.982e-03,
         2.798e-03],
        [1.429e-03, 2.347e-03, 2.548e-04,  ..., 6.158e-03, 5.174e-04,
         4.146e-03],
        [2.700e-02, 1.145e-04, 9.013e-04,  ..., 6.078e-05, 1.516e-02,
         1.890e-02]], device='cuda:0')
b after update for 1 param tensor([[0.361, 0.288, 0.185,  ..., 0.047, 0.878, 0.154],
        [0.398, 0.193, 0.688,  ..., 0.273, 0.106, 0.114],
        [0.290, 0.520, 0.342,  ..., 0.114, 0.410, 0.091],
        ...,
        [1.863, 0.670, 0.253,  ..., 0.039, 0.382, 0.321],
        [0.229, 0.294, 0.097,  ..., 0.476, 0.138, 0.390],
        [0.996, 0.065, 0.182,  ..., 0.047, 0.746, 0.833]], device='cuda:0')
clipping threshold 2.782537623814828
a after update for 1 param tensor([ 1.726e-05,  2.135e-04, -9.210e-06,  1.371e-05,  2.175e-06, -3.881e-05,
         4.061e-05,  4.683e-05, -1.815e-05,  1.345e-05, -3.744e-05, -1.531e-05,
         1.107e-05, -4.401e-05, -6.793e-05, -3.751e-05, -2.572e-07, -2.687e-05,
         6.350e-05, -6.756e-06, -1.507e-05, -2.596e-05, -4.505e-05, -7.788e-06,
        -5.225e-04, -4.410e-05,  2.014e-05, -5.703e-06, -9.867e-05, -5.796e-07,
         4.656e-05, -9.514e-05,  1.821e-04,  3.286e-07,  3.980e-05,  2.430e-06,
         8.142e-06,  3.892e-05, -6.093e-07,  1.939e-05, -2.907e-05,  1.332e-05,
         7.209e-06, -8.114e-05,  2.936e-07,  2.095e-05, -1.058e-05,  9.708e-06,
         1.202e-05,  1.727e-04, -1.993e-04,  1.042e-04,  2.273e-06, -7.426e-06,
         8.470e-06,  6.298e-05, -3.768e-05,  3.109e-05, -2.134e-05, -9.307e-05,
        -1.385e-05,  3.455e-05, -3.300e-04, -1.667e-05, -8.638e-05, -3.934e-06,
         3.376e-05,  3.328e-05, -1.653e-04,  1.968e-05, -4.180e-06,  8.048e-05,
         2.512e-06, -4.470e-06,  3.252e-05,  5.580e-06,  5.203e-05, -5.930e-06,
        -1.713e-06,  3.366e-06,  1.629e-05,  2.042e-04, -4.672e-07, -1.375e-06,
        -2.401e-04,  2.556e-05, -1.720e-06,  4.949e-06,  6.596e-06,  3.018e-05,
        -1.799e-04, -1.078e-04, -7.199e-05, -1.763e-04,  5.289e-06, -1.212e-05,
         1.827e-06, -6.112e-06, -1.762e-05, -1.420e-05, -1.169e-05, -1.948e-05,
        -3.027e-05,  5.170e-06,  5.624e-05,  3.083e-05,  4.226e-04,  3.305e-05,
         8.610e-06,  1.327e-04,  8.528e-07, -7.606e-06, -4.423e-05,  2.885e-05,
        -3.360e-05,  1.412e-05,  1.114e-05, -4.346e-05, -4.921e-05, -3.984e-05,
        -4.045e-07,  1.416e-05, -1.743e-05,  5.933e-05,  6.915e-06, -1.556e-05,
         9.577e-05, -5.488e-05,  9.109e-05, -1.923e-05, -2.040e-04,  2.506e-04,
        -3.736e-05, -3.437e-05,  2.970e-05, -2.009e-05,  1.788e-05,  5.182e-06,
        -8.645e-05, -8.951e-05,  3.166e-06,  6.339e-06,  3.666e-06, -2.416e-05,
         4.732e-05, -1.971e-05, -9.936e-06, -5.031e-04,  2.716e-06, -1.535e-05,
        -2.640e-05, -1.174e-05,  7.741e-05,  2.790e-04, -1.698e-04, -3.359e-05,
        -2.628e-04,  6.728e-06, -1.156e-05,  1.462e-05,  2.270e-05, -7.646e-06,
         1.046e-04,  6.264e-06, -1.444e-05,  4.205e-05,  1.660e-04,  1.011e-05,
        -1.487e-04,  7.996e-06,  2.129e-05, -1.378e-04, -2.149e-06,  7.008e-06,
        -3.790e-06,  8.393e-05, -2.426e-05,  9.456e-06, -1.935e-07, -5.231e-05,
         1.694e-05,  5.675e-05,  2.342e-05,  3.823e-06, -7.804e-06,  2.659e-04,
         5.893e-06,  1.410e-04, -2.721e-05, -3.105e-06, -6.376e-05,  5.018e-07,
         1.712e-05,  2.859e-05,  1.293e-04,  1.421e-05, -6.595e-05, -1.996e-05,
        -4.793e-05,  7.650e-06], device='cuda:0')
s after update for 1 param tensor([7.851e-05, 2.061e-02, 4.464e-05, 7.297e-04, 3.487e-05, 2.454e-02,
        2.532e-04, 1.116e-03, 8.401e-04, 5.326e-04, 7.612e-04, 6.233e-04,
        1.130e-03, 3.343e-03, 1.165e-03, 3.069e-03, 8.862e-06, 2.887e-04,
        4.453e-03, 7.873e-04, 3.089e-04, 3.765e-03, 2.998e-03, 1.052e-03,
        7.322e-02, 3.357e-03, 2.683e-03, 7.108e-04, 1.089e-02, 1.882e-06,
        2.154e-03, 5.304e-03, 1.068e-02, 1.882e-06, 4.022e-03, 1.751e-03,
        5.766e-05, 7.055e-03, 7.690e-04, 1.958e-04, 1.141e-04, 3.482e-03,
        2.487e-04, 4.630e-03, 1.882e-06, 2.801e-03, 3.003e-03, 1.947e-04,
        1.882e-04, 2.834e-02, 9.776e-03, 6.060e-03, 2.111e-05, 3.563e-05,
        3.178e-03, 1.069e-02, 8.436e-04, 4.081e-04, 5.415e-04, 3.012e-03,
        1.422e-03, 3.481e-03, 1.507e-02, 2.527e-04, 4.142e-03, 5.474e-06,
        4.747e-03, 1.230e-02, 8.883e-03, 1.977e-03, 7.897e-04, 1.702e-03,
        1.882e-06, 4.415e-05, 7.021e-03, 6.012e-05, 5.578e-03, 4.069e-05,
        7.876e-04, 1.198e-05, 3.729e-03, 1.980e-02, 1.899e-04, 6.074e-04,
        2.446e-02, 3.596e-04, 4.094e-05, 2.331e-05, 1.124e-03, 1.274e-03,
        3.646e-02, 1.860e-02, 7.972e-04, 3.431e-02, 3.606e-05, 9.591e-05,
        1.603e-04, 1.039e-04, 4.754e-04, 2.794e-03, 1.341e-03, 2.248e-03,
        4.130e-03, 3.116e-04, 2.948e-03, 5.496e-04, 6.537e-02, 4.850e-04,
        6.245e-05, 1.775e-03, 3.785e-04, 1.766e-03, 4.017e-03, 2.121e-03,
        1.685e-03, 9.069e-04, 6.910e-05, 3.603e-03, 1.265e-02, 7.564e-03,
        9.079e-06, 2.776e-03, 3.207e-04, 9.991e-03, 1.532e-04, 1.102e-04,
        9.585e-03, 1.723e-02, 1.600e-03, 6.668e-03, 3.677e-02, 4.663e-02,
        5.472e-03, 4.921e-04, 4.213e-03, 6.920e-04, 2.557e-05, 6.269e-04,
        6.712e-03, 1.077e-03, 1.567e-04, 2.366e-05, 5.347e-06, 5.243e-04,
        7.414e-04, 2.681e-03, 7.234e-04, 7.440e-02, 1.026e-02, 1.112e-04,
        8.288e-04, 1.228e-03, 5.006e-03, 3.192e-02, 9.902e-03, 5.850e-03,
        1.091e-02, 4.538e-03, 3.557e-04, 1.652e-05, 3.422e-03, 3.182e-05,
        4.736e-03, 4.251e-05, 5.303e-03, 8.479e-03, 2.956e-02, 3.702e-05,
        2.688e-02, 1.116e-03, 1.904e-03, 2.212e-02, 2.524e-05, 2.036e-04,
        1.881e-05, 1.562e-02, 2.604e-04, 3.153e-04, 1.368e-05, 5.870e-03,
        1.546e-04, 3.706e-04, 2.054e-04, 1.770e-05, 6.441e-04, 5.810e-02,
        5.084e-04, 4.019e-02, 5.779e-03, 7.018e-05, 5.506e-03, 1.607e-05,
        1.631e-03, 3.066e-04, 6.609e-03, 9.824e-04, 1.355e-02, 1.188e-04,
        1.035e-02, 1.330e-03], device='cuda:0')
b after update for 1 param tensor([0.054, 0.870, 0.040, 0.164, 0.036, 0.949, 0.096, 0.202, 0.176, 0.140,
        0.167, 0.151, 0.204, 0.350, 0.207, 0.336, 0.018, 0.103, 0.404, 0.170,
        0.106, 0.372, 0.332, 0.197, 1.640, 0.351, 0.314, 0.162, 0.632, 0.008,
        0.281, 0.441, 0.626, 0.008, 0.384, 0.254, 0.046, 0.509, 0.168, 0.085,
        0.065, 0.358, 0.096, 0.412, 0.008, 0.321, 0.332, 0.085, 0.083, 1.020,
        0.599, 0.472, 0.028, 0.036, 0.342, 0.627, 0.176, 0.122, 0.141, 0.333,
        0.229, 0.358, 0.744, 0.096, 0.390, 0.014, 0.418, 0.672, 0.571, 0.269,
        0.170, 0.250, 0.008, 0.040, 0.508, 0.047, 0.453, 0.039, 0.170, 0.021,
        0.370, 0.853, 0.084, 0.149, 0.948, 0.115, 0.039, 0.029, 0.203, 0.216,
        1.157, 0.826, 0.171, 1.123, 0.036, 0.059, 0.077, 0.062, 0.132, 0.320,
        0.222, 0.287, 0.389, 0.107, 0.329, 0.142, 1.549, 0.133, 0.048, 0.255,
        0.118, 0.255, 0.384, 0.279, 0.249, 0.182, 0.050, 0.364, 0.681, 0.527,
        0.018, 0.319, 0.109, 0.606, 0.075, 0.064, 0.593, 0.795, 0.242, 0.495,
        1.162, 1.309, 0.448, 0.134, 0.393, 0.159, 0.031, 0.152, 0.496, 0.199,
        0.076, 0.029, 0.014, 0.139, 0.165, 0.314, 0.163, 1.653, 0.614, 0.064,
        0.174, 0.212, 0.429, 1.083, 0.603, 0.463, 0.633, 0.408, 0.114, 0.025,
        0.355, 0.034, 0.417, 0.040, 0.441, 0.558, 1.042, 0.037, 0.993, 0.202,
        0.264, 0.901, 0.030, 0.086, 0.026, 0.757, 0.098, 0.108, 0.022, 0.464,
        0.075, 0.117, 0.087, 0.025, 0.154, 1.461, 0.137, 1.215, 0.461, 0.051,
        0.450, 0.024, 0.245, 0.106, 0.493, 0.190, 0.705, 0.066, 0.617, 0.221],
       device='cuda:0')
clipping threshold 2.782537623814828
a after update for 1 param tensor([[[ 1.455e-04],
         [-2.117e-05],
         [ 9.380e-05],
         [-1.198e-04],
         [-2.319e-04],
         [ 1.720e-04],
         [ 1.886e-04],
         [ 5.603e-05],
         [ 3.390e-06],
         [-6.585e-07]],

        [[-2.518e-04],
         [-6.854e-05],
         [-1.618e-04],
         [-1.684e-04],
         [-3.404e-04],
         [ 1.876e-04],
         [ 1.516e-04],
         [-1.370e-04],
         [-3.620e-04],
         [-3.128e-04]],

        [[ 8.999e-05],
         [-2.239e-04],
         [ 7.588e-05],
         [-1.174e-04],
         [ 1.505e-04],
         [ 6.607e-05],
         [ 1.317e-04],
         [ 2.077e-04],
         [ 1.081e-04],
         [ 8.015e-06]],

        [[ 8.855e-05],
         [ 1.270e-04],
         [ 1.563e-04],
         [ 7.665e-05],
         [ 9.733e-06],
         [ 1.170e-05],
         [ 7.120e-05],
         [ 1.132e-04],
         [ 3.525e-05],
         [ 2.384e-04]],

        [[-6.804e-04],
         [-1.072e-03],
         [-2.323e-04],
         [-5.941e-05],
         [-1.102e-04],
         [-8.320e-07],
         [ 2.613e-04],
         [-1.068e-03],
         [-8.774e-04],
         [ 4.666e-05]],

        [[ 4.831e-05],
         [-2.272e-05],
         [-7.267e-06],
         [ 1.291e-04],
         [ 3.975e-05],
         [ 2.707e-05],
         [ 6.251e-06],
         [ 1.006e-04],
         [ 5.574e-06],
         [ 1.210e-04]],

        [[-5.149e-04],
         [ 1.338e-05],
         [-2.176e-04],
         [-1.597e-04],
         [-7.220e-05],
         [-6.887e-05],
         [-2.279e-04],
         [-2.433e-04],
         [-1.553e-04],
         [ 5.449e-05]],

        [[ 2.314e-06],
         [ 1.159e-04],
         [ 1.580e-05],
         [ 2.322e-05],
         [-1.795e-06],
         [ 3.904e-05],
         [-1.569e-04],
         [ 1.594e-04],
         [ 9.336e-06],
         [ 3.638e-05]],

        [[ 8.647e-05],
         [ 4.365e-05],
         [ 9.068e-05],
         [ 6.415e-04],
         [ 2.902e-04],
         [ 4.806e-05],
         [-3.550e-04],
         [-4.509e-05],
         [ 7.316e-04],
         [ 4.815e-05]],

        [[ 6.594e-04],
         [ 8.889e-04],
         [ 7.105e-04],
         [-2.651e-05],
         [ 6.124e-04],
         [ 7.283e-04],
         [ 1.438e-05],
         [ 5.891e-04],
         [-7.184e-05],
         [-3.685e-05]],

        [[ 2.153e-04],
         [ 1.518e-04],
         [-2.849e-05],
         [ 4.401e-04],
         [ 3.837e-04],
         [ 5.200e-05],
         [ 1.851e-04],
         [ 2.653e-05],
         [ 1.844e-04],
         [ 7.240e-04]],

        [[-8.355e-05],
         [ 9.542e-05],
         [-4.451e-05],
         [ 3.850e-04],
         [ 3.517e-05],
         [ 8.221e-04],
         [ 6.435e-04],
         [ 3.065e-04],
         [ 3.067e-04],
         [ 6.345e-06]],

        [[ 2.610e-04],
         [-1.476e-04],
         [ 5.471e-04],
         [ 8.356e-05],
         [ 8.241e-05],
         [ 7.715e-04],
         [ 1.671e-04],
         [ 4.170e-04],
         [ 5.648e-04],
         [ 1.319e-04]],

        [[ 6.742e-05],
         [ 1.357e-04],
         [ 3.981e-04],
         [ 7.698e-05],
         [-2.689e-05],
         [ 2.412e-04],
         [ 3.227e-04],
         [ 6.959e-05],
         [ 2.362e-04],
         [ 2.274e-04]],

        [[ 2.345e-04],
         [-4.028e-05],
         [ 7.277e-05],
         [ 3.565e-04],
         [ 2.318e-04],
         [ 2.398e-04],
         [ 1.614e-04],
         [ 6.333e-04],
         [ 5.148e-05],
         [ 3.129e-05]],

        [[ 3.717e-04],
         [ 5.031e-04],
         [-1.597e-04],
         [ 5.485e-04],
         [-4.276e-05],
         [ 7.243e-04],
         [ 1.882e-05],
         [ 1.278e-04],
         [ 2.553e-05],
         [ 1.134e-04]],

        [[-3.439e-04],
         [ 2.927e-05],
         [-4.760e-04],
         [ 1.084e-05],
         [-2.117e-05],
         [-1.727e-05],
         [-3.506e-04],
         [ 2.120e-04],
         [-2.315e-04],
         [-7.527e-04]],

        [[-5.705e-04],
         [-4.622e-04],
         [-6.663e-04],
         [-2.945e-04],
         [-5.122e-04],
         [-1.781e-04],
         [ 1.665e-05],
         [-8.859e-05],
         [ 1.175e-04],
         [ 5.397e-05]],

        [[ 5.086e-04],
         [-5.361e-05],
         [ 6.016e-05],
         [ 5.504e-05],
         [-1.209e-06],
         [-1.043e-04],
         [ 1.847e-05],
         [-2.971e-07],
         [-8.665e-06],
         [ 9.610e-05]],

        [[ 5.798e-05],
         [ 1.590e-04],
         [-4.285e-06],
         [ 5.379e-05],
         [-4.541e-05],
         [ 1.015e-05],
         [ 1.181e-04],
         [-3.275e-05],
         [ 8.904e-05],
         [-1.129e-05]]], device='cuda:0')
s after update for 1 param tensor([[[2.157e-02],
         [1.980e-03],
         [1.564e-03],
         [4.877e-03],
         [1.821e-02],
         [4.693e-03],
         [4.386e-03],
         [7.652e-04],
         [1.833e-05],
         [1.738e-03]],

        [[2.680e-02],
         [3.780e-03],
         [2.891e-02],
         [2.564e-02],
         [1.188e-02],
         [3.370e-02],
         [3.445e-03],
         [4.585e-03],
         [4.100e-02],
         [1.000e-01]],

        [[8.998e-03],
         [6.750e-02],
         [1.047e-03],
         [3.696e-02],
         [3.419e-02],
         [1.404e-02],
         [1.653e-02],
         [6.048e-03],
         [3.512e-03],
         [5.137e-05]],

        [[6.829e-03],
         [4.525e-03],
         [1.607e-02],
         [1.017e-02],
         [2.462e-05],
         [1.225e-03],
         [9.260e-04],
         [1.874e-02],
         [6.624e-03],
         [8.413e-03]],

        [[7.069e-02],
         [1.646e-01],
         [1.800e-02],
         [1.653e-02],
         [1.789e-02],
         [1.320e-04],
         [5.678e-02],
         [1.737e-01],
         [5.387e-02],
         [2.696e-03]],

        [[8.610e-03],
         [5.994e-04],
         [8.767e-04],
         [4.813e-03],
         [2.086e-03],
         [1.815e-04],
         [6.629e-04],
         [4.670e-03],
         [1.798e-03],
         [1.770e-03]],

        [[7.923e-02],
         [3.132e-03],
         [3.285e-02],
         [1.951e-02],
         [1.206e-02],
         [2.702e-02],
         [2.400e-02],
         [1.465e-02],
         [2.972e-02],
         [5.484e-03]],

        [[9.838e-06],
         [1.569e-02],
         [2.945e-05],
         [6.847e-03],
         [1.668e-03],
         [5.242e-04],
         [2.382e-02],
         [2.408e-02],
         [5.282e-04],
         [4.978e-03]],

        [[1.879e-03],
         [1.246e-02],
         [4.486e-03],
         [8.340e-02],
         [4.742e-02],
         [9.623e-03],
         [1.072e-01],
         [2.172e-03],
         [3.617e-02],
         [5.897e-03]],

        [[6.964e-02],
         [8.524e-02],
         [1.019e-01],
         [2.786e-03],
         [6.326e-02],
         [1.174e-01],
         [2.801e-03],
         [7.766e-02],
         [1.078e-02],
         [1.531e-02]],

        [[4.599e-03],
         [1.479e-02],
         [4.055e-03],
         [2.241e-02],
         [2.720e-02],
         [3.712e-03],
         [4.186e-03],
         [3.107e-04],
         [2.560e-02],
         [9.677e-02]],

        [[9.318e-03],
         [1.125e-02],
         [4.645e-04],
         [3.895e-02],
         [7.462e-03],
         [7.986e-02],
         [5.547e-02],
         [4.101e-02],
         [1.163e-02],
         [1.057e-04]],

        [[4.447e-02],
         [5.097e-03],
         [9.838e-02],
         [3.403e-02],
         [4.013e-03],
         [1.455e-01],
         [2.183e-02],
         [3.551e-02],
         [3.689e-02],
         [2.120e-02]],

        [[2.054e-03],
         [1.525e-02],
         [3.428e-02],
         [1.234e-03],
         [3.659e-03],
         [2.958e-02],
         [3.178e-02],
         [1.614e-02],
         [2.471e-02],
         [3.832e-02]],

        [[8.815e-03],
         [2.061e-03],
         [2.799e-03],
         [4.140e-02],
         [1.957e-02],
         [2.760e-02],
         [1.454e-02],
         [9.893e-02],
         [2.297e-04],
         [1.700e-04]],

        [[3.690e-02],
         [3.665e-02],
         [1.449e-02],
         [6.781e-02],
         [3.767e-03],
         [9.647e-02],
         [1.784e-04],
         [1.487e-03],
         [1.587e-02],
         [4.134e-03]],

        [[4.776e-02],
         [2.600e-03],
         [2.124e-02],
         [3.508e-04],
         [2.535e-03],
         [9.641e-05],
         [1.021e-02],
         [9.302e-03],
         [1.815e-02],
         [6.114e-02]],

        [[2.183e-02],
         [4.167e-02],
         [3.983e-02],
         [4.292e-02],
         [5.943e-02],
         [1.691e-02],
         [2.808e-03],
         [1.034e-03],
         [2.599e-02],
         [1.160e-02]],

        [[2.881e-02],
         [1.620e-02],
         [1.281e-03],
         [1.257e-02],
         [8.764e-05],
         [2.669e-03],
         [5.467e-04],
         [4.783e-04],
         [3.290e-04],
         [3.037e-02]],

        [[6.022e-03],
         [6.826e-03],
         [1.017e-04],
         [5.142e-04],
         [3.138e-04],
         [8.558e-05],
         [1.674e-02],
         [2.752e-03],
         [1.236e-02],
         [3.557e-03]]], device='cuda:0')
b after update for 1 param tensor([[[0.890],
         [0.270],
         [0.240],
         [0.423],
         [0.818],
         [0.415],
         [0.401],
         [0.168],
         [0.026],
         [0.253]],

        [[0.992],
         [0.373],
         [1.030],
         [0.970],
         [0.661],
         [1.112],
         [0.356],
         [0.410],
         [1.227],
         [1.917]],

        [[0.575],
         [1.574],
         [0.196],
         [1.165],
         [1.120],
         [0.718],
         [0.779],
         [0.471],
         [0.359],
         [0.043]],

        [[0.501],
         [0.408],
         [0.768],
         [0.611],
         [0.030],
         [0.212],
         [0.184],
         [0.829],
         [0.493],
         [0.556]],

        [[1.611],
         [2.459],
         [0.813],
         [0.779],
         [0.811],
         [0.070],
         [1.444],
         [2.526],
         [1.406],
         [0.315]],

        [[0.562],
         [0.148],
         [0.179],
         [0.420],
         [0.277],
         [0.082],
         [0.156],
         [0.414],
         [0.257],
         [0.255]],

        [[1.706],
         [0.339],
         [1.098],
         [0.846],
         [0.665],
         [0.996],
         [0.939],
         [0.734],
         [1.045],
         [0.449]],

        [[0.019],
         [0.759],
         [0.033],
         [0.501],
         [0.247],
         [0.139],
         [0.935],
         [0.940],
         [0.139],
         [0.428]],

        [[0.263],
         [0.676],
         [0.406],
         [1.750],
         [1.320],
         [0.594],
         [1.984],
         [0.282],
         [1.153],
         [0.465]],

        [[1.599],
         [1.769],
         [1.934],
         [0.320],
         [1.524],
         [2.077],
         [0.321],
         [1.689],
         [0.629],
         [0.750]],

        [[0.411],
         [0.737],
         [0.386],
         [0.907],
         [0.999],
         [0.369],
         [0.392],
         [0.107],
         [0.970],
         [1.885]],

        [[0.585],
         [0.643],
         [0.131],
         [1.196],
         [0.523],
         [1.712],
         [1.427],
         [1.227],
         [0.653],
         [0.062]],

        [[1.278],
         [0.433],
         [1.901],
         [1.118],
         [0.384],
         [2.311],
         [0.895],
         [1.142],
         [1.164],
         [0.882]],

        [[0.275],
         [0.748],
         [1.122],
         [0.213],
         [0.367],
         [1.042],
         [1.080],
         [0.770],
         [0.953],
         [1.186]],

        [[0.569],
         [0.275],
         [0.321],
         [1.233],
         [0.848],
         [1.007],
         [0.731],
         [1.906],
         [0.092],
         [0.079]],

        [[1.164],
         [1.160],
         [0.730],
         [1.578],
         [0.372],
         [1.882],
         [0.081],
         [0.234],
         [0.763],
         [0.390]],

        [[1.324],
         [0.309],
         [0.883],
         [0.114],
         [0.305],
         [0.060],
         [0.612],
         [0.584],
         [0.816],
         [1.498]],

        [[0.895],
         [1.237],
         [1.209],
         [1.255],
         [1.477],
         [0.788],
         [0.321],
         [0.195],
         [0.977],
         [0.653]],

        [[1.029],
         [0.771],
         [0.217],
         [0.679],
         [0.057],
         [0.313],
         [0.142],
         [0.133],
         [0.110],
         [1.056]],

        [[0.470],
         [0.501],
         [0.061],
         [0.137],
         [0.107],
         [0.056],
         [0.784],
         [0.318],
         [0.674],
         [0.361]]], device='cuda:0')
clipping threshold 2.782537623814828
a after update for 1 param tensor([[ 9.221e-05],
        [-1.622e-03],
        [ 5.101e-04],
        [-1.397e-04],
        [-1.539e-03],
        [ 1.257e-04],
        [ 1.421e-04],
        [ 6.700e-05],
        [ 4.316e-04],
        [ 1.115e-03],
        [ 5.551e-04],
        [ 4.991e-04],
        [ 5.340e-04],
        [ 2.821e-04],
        [ 8.030e-05],
        [ 1.289e-04],
        [-7.039e-04],
        [-4.119e-04],
        [ 1.064e-04],
        [ 1.648e-04]], device='cuda:0')
s after update for 1 param tensor([[0.016],
        [0.149],
        [0.036],
        [0.004],
        [0.179],
        [0.011],
        [0.021],
        [0.004],
        [0.066],
        [0.160],
        [0.092],
        [0.062],
        [0.059],
        [0.027],
        [0.020],
        [0.006],
        [0.045],
        [0.054],
        [0.009],
        [0.041]], device='cuda:0')
b after update for 1 param tensor([[0.757],
        [2.337],
        [1.150],
        [0.372],
        [2.560],
        [0.621],
        [0.876],
        [0.396],
        [1.555],
        [2.422],
        [1.838],
        [1.511],
        [1.477],
        [0.988],
        [0.854],
        [0.470],
        [1.283],
        [1.405],
        [0.572],
        [1.232]], device='cuda:0')
clipping threshold 2.782537623814828
||w||^2 0.1013355883094239
exp ma of ||w||^2 0.2342213551484777
||w|| 0.3183325121777917
exp ma of ||w|| 0.45233900175589836
||w||^2 0.1169682915834686
exp ma of ||w||^2 0.2396737818775907
||w|| 0.34200627418728535
exp ma of ||w|| 0.4583916003539014
||w||^2 0.18155830777027487
exp ma of ||w||^2 0.19677675806292944
||w|| 0.4260965944129041
exp ma of ||w|| 0.42991161733843014
||w||^2 0.17602551524548707
exp ma of ||w||^2 0.2471371477387002
||w|| 0.4195539479560252
exp ma of ||w|| 0.4623994013846751
||w||^2 0.15268678388540588
exp ma of ||w||^2 0.4363865220971499
||w|| 0.3907515628700746
exp ma of ||w|| 0.6051617362304523
||w||^2 0.23810003944332908
exp ma of ||w||^2 0.45575974045671086
||w|| 0.48795495636721337
exp ma of ||w|| 0.6137319933150402
||w||^2 1.2201607957798564
exp ma of ||w||^2 0.45972189679937
||w|| 1.1046088881499443
exp ma of ||w|| 0.6153018832054955
v before min max tensor([[-24.916,   4.841, -19.807,  ..., -17.447, -13.477,   3.818],
        [-30.761,  15.148,  -2.484,  ...,  -9.138, -19.129, -16.825],
        [-19.654,  18.369, -20.470,  ..., -19.243, -22.898,  -9.600],
        ...,
        [-17.027, -27.887, -18.279,  ..., -15.988, -11.589, -14.496],
        [-24.441,  13.120, -10.444,  ..., -21.021, -22.752,   4.608],
        [-10.951, -21.301,  11.082,  ...,  81.494, -20.526,  -4.188]],
       device='cuda:0')
v tensor([[1.000e-12, 4.841e+00, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         3.818e+00],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         4.608e+00],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([-2.779e+01, -1.463e+01, -2.686e+01, -1.854e+01,  2.449e+01, -2.287e+01,
        -1.898e+01, -1.658e+01, -2.442e+01, -1.226e+01, -9.225e+00, -8.144e-01,
        -2.670e+00, -2.068e+01, -1.382e+01, -2.487e+01, -2.208e+01,  1.548e+01,
        -9.026e+00,  1.001e+01, -1.676e+01,  2.402e+01,  5.461e+01,  5.796e+01,
        -2.505e+01, -2.201e+00, -1.248e+01, -9.365e-01, -2.834e+01, -2.848e+01,
        -7.339e+00, -2.596e+01, -2.476e+01, -2.369e+01, -2.444e+01, -2.178e+01,
        -2.542e+01, -2.293e+01, -1.368e+01, -1.871e+01,  3.805e+01, -9.922e+00,
        -7.783e-01, -2.652e+01,  1.839e+01, -9.841e+00,  1.755e-01, -4.147e+00,
        -1.923e+01, -3.858e+00, -1.923e+01, -1.162e+01, -2.222e+01, -2.492e+01,
        -3.295e+01,  4.136e+01, -7.428e+00, -1.987e+01, -1.157e+01, -2.974e+01,
        -2.782e+01,  1.302e+02,  2.841e+01, -2.230e+01, -2.633e+01, -2.589e+01,
        -2.185e+01,  4.721e+01, -1.869e+01,  7.184e+01,  3.687e+01, -2.717e+01,
         3.915e+00, -1.157e+01, -2.035e+01,  6.479e+01, -1.486e+01, -4.881e+00,
         1.167e+01, -8.184e+00,  1.304e+00, -5.549e+00, -8.246e+00, -1.851e+01,
        -1.720e+01, -1.156e+01,  8.668e+00, -2.876e+01, -2.628e+01, -9.267e+00,
         3.917e+01,  1.954e+01, -2.765e+01, -2.862e+01, -8.873e+00, -2.057e+01,
         1.175e+00, -2.435e+01,  7.613e-01, -1.172e+01,  1.310e+01, -1.700e+01,
        -1.873e+00, -8.606e+00,  5.804e+01,  1.516e+01, -1.259e+01, -2.253e+01,
        -2.091e+01, -1.907e+01, -3.257e+00, -1.909e+01, -2.643e+01, -1.385e+01,
        -2.143e+01, -1.942e+01, -1.341e+01, -5.258e+00,  2.405e+01, -3.204e+01,
         3.951e+01, -5.627e+00, -1.293e+01, -2.635e+01, -2.909e+01, -2.681e+01,
        -2.280e+01, -2.611e+01, -2.323e+01, -2.498e+01, -1.082e+01, -2.388e+01,
         5.273e+01,  2.546e+01, -1.019e+01, -2.391e+01, -2.851e+01, -1.052e+01,
        -8.092e+00,  9.941e+00, -4.063e+00, -4.121e+00, -2.542e+01,  1.280e+01,
        -1.079e+01, -2.163e+01, -2.011e+01, -2.500e+01, -1.733e+01, -2.579e+01,
        -2.890e+01,  1.266e-01, -8.655e+00, -5.779e+00, -8.841e+00,  3.716e+01,
        -1.509e+01, -1.954e+01,  6.648e+01, -1.202e+00, -2.591e+01,  9.906e+00,
         1.145e+00,  5.412e+00,  3.289e+01, -3.270e+00, -1.472e+01, -1.152e+00,
         1.995e+01, -2.113e+01, -2.140e+01, -1.626e+01, -2.090e+01,  1.965e+01,
        -1.918e+01, -2.176e+01, -2.639e+01, -1.332e+01, -7.350e+00, -3.429e+01,
        -1.907e+01, -1.770e+01, -7.249e+00,  1.469e+01, -2.162e+01, -1.647e+01,
        -1.700e+01, -1.291e+01, -1.396e+01,  9.755e+01, -2.653e+01, -2.586e+01,
        -8.156e-01, -2.055e+01, -1.366e+01, -9.029e+00, -2.232e+01,  4.058e+00,
        -1.680e+01, -2.381e+01], device='cuda:0')
v tensor([1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.755e-01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        3.915e+00, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.304e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 8.668e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.175e+00, 1.000e-12, 7.613e-01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 9.941e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.266e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 9.906e+00,
        1.145e+00, 5.412e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 4.058e+00,
        1.000e-12, 1.000e-12], device='cuda:0')
v before min max tensor([[[-1.898e+01],
         [-1.550e+01],
         [-2.268e+01],
         [ 1.253e+01],
         [-1.973e+01],
         [ 7.810e+01],
         [-1.726e+01],
         [-2.516e+01],
         [-1.037e+01],
         [ 2.737e+01]],

        [[-4.547e+00],
         [-3.636e+01],
         [ 8.635e+01],
         [ 9.728e+01],
         [ 2.145e+01],
         [-2.440e+01],
         [-2.614e+01],
         [-1.522e+01],
         [ 1.995e+02],
         [-1.616e+01]],

        [[-1.958e+01],
         [ 1.368e+02],
         [ 2.851e+01],
         [-2.223e+01],
         [-2.599e+01],
         [-1.400e+01],
         [-2.353e+01],
         [-1.342e+01],
         [ 9.344e+00],
         [ 4.662e+01]],

        [[-2.211e+01],
         [-9.591e+00],
         [ 3.208e+01],
         [-2.759e+01],
         [ 1.170e+00],
         [-2.675e+01],
         [-2.182e+01],
         [-2.522e+01],
         [-1.406e+01],
         [-1.509e+01]],

        [[ 1.197e+02],
         [ 7.261e+00],
         [ 3.667e+01],
         [ 5.837e+01],
         [-2.338e+01],
         [ 4.975e+01],
         [ 5.876e+00],
         [-4.262e+00],
         [ 6.092e+00],
         [ 3.196e+02]],

        [[-2.997e+01],
         [ 1.271e+01],
         [ 6.176e+01],
         [-9.605e+00],
         [-1.326e+01],
         [-7.016e-02],
         [-3.829e+00],
         [ 3.561e+01],
         [-1.933e+01],
         [ 2.108e+00]],

        [[-2.072e+01],
         [-1.112e+01],
         [-2.371e+01],
         [-3.153e+01],
         [-4.412e+00],
         [-2.341e+01],
         [-1.488e+01],
         [-3.113e+01],
         [ 6.354e+00],
         [ 4.229e+01]],

        [[ 8.890e+01],
         [ 1.206e+01],
         [-3.098e+01],
         [-4.336e-01],
         [-1.471e+01],
         [ 1.816e+00],
         [ 6.715e+01],
         [ 7.248e+00],
         [-1.737e+01],
         [ 8.603e-01]],

        [[ 8.036e+01],
         [ 1.076e+02],
         [ 4.704e+01],
         [-2.354e+01],
         [-2.493e+01],
         [ 8.968e+00],
         [-3.088e+01],
         [ 1.085e+02],
         [-2.496e+00],
         [-4.343e+00]],

        [[ 9.845e+01],
         [-3.930e+01],
         [ 9.750e+01],
         [-1.987e+01],
         [ 5.130e+01],
         [-2.170e+01],
         [-3.950e+00],
         [ 3.296e+02],
         [ 5.268e+00],
         [-2.139e+01]],

        [[-1.939e+01],
         [ 4.832e+01],
         [-2.275e+00],
         [-1.475e+01],
         [-2.241e+01],
         [-1.206e+01],
         [ 7.020e+00],
         [-1.365e+01],
         [-1.363e+01],
         [-2.310e+01]],

        [[-2.563e+00],
         [-1.322e+01],
         [ 3.178e+00],
         [-1.909e+01],
         [-1.676e+01],
         [ 1.983e+01],
         [-1.382e+01],
         [-1.338e-01],
         [-2.617e+01],
         [-2.461e+01]],

        [[ 1.429e+01],
         [-1.754e+01],
         [ 1.247e+02],
         [-2.323e+01],
         [-3.217e+01],
         [ 1.183e+02],
         [-1.043e+01],
         [ 6.085e+01],
         [-2.785e+01],
         [-2.584e+01]],

        [[-1.723e+01],
         [ 3.650e+00],
         [ 2.203e+01],
         [-1.896e+01],
         [-8.938e+00],
         [ 2.470e+01],
         [-1.260e+01],
         [ 5.097e+01],
         [-6.545e+00],
         [-2.694e+01]],

        [[ 1.488e+00],
         [-1.145e+00],
         [-2.598e+01],
         [-1.138e+01],
         [-2.615e+01],
         [-2.464e+01],
         [ 5.235e-01],
         [-1.510e+01],
         [-7.643e+00],
         [-2.576e+01]],

        [[-1.573e+01],
         [-1.815e+01],
         [ 4.462e+01],
         [-2.503e+01],
         [-9.931e+00],
         [-5.813e+00],
         [-3.145e+00],
         [-1.525e+01],
         [-1.386e+01],
         [-2.909e+01]],

        [[-1.976e+01],
         [-2.169e+01],
         [-2.210e+01],
         [-1.964e+01],
         [ 2.753e+01],
         [ 9.983e+00],
         [ 8.909e+01],
         [-1.316e+01],
         [-2.608e-01],
         [ 1.107e+02]],

        [[-3.165e+01],
         [-2.688e+01],
         [-7.868e+00],
         [-3.737e+01],
         [-3.157e+01],
         [ 6.528e+01],
         [-1.719e+01],
         [-1.160e+01],
         [ 1.476e+01],
         [-3.099e+00]],

        [[-1.464e+01],
         [ 3.363e+01],
         [-2.423e+01],
         [-2.074e+01],
         [-2.166e+01],
         [-1.249e+01],
         [-1.899e+01],
         [-1.604e+01],
         [-1.940e+01],
         [-4.605e+00]],

        [[-1.238e+01],
         [ 1.069e+01],
         [-1.872e+01],
         [-2.303e+01],
         [-1.479e+01],
         [-1.514e+00],
         [-2.456e+01],
         [-1.610e+01],
         [ 1.418e+01],
         [-5.168e+00]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [9.344e+00],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.170e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [7.261e+00],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [5.876e+00],
         [1.000e-12],
         [6.092e+00],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [2.108e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.354e+00],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.816e+00],
         [1.000e+01],
         [7.248e+00],
         [1.000e-12],
         [8.603e-01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [8.968e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [5.268e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.020e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [3.178e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [3.650e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.488e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.235e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [9.983e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[ 57.806],
        [ 64.058],
        [-15.396],
        [-21.873],
        [225.300],
        [-19.972],
        [-24.726],
        [ -8.978],
        [-29.091],
        [ 45.758],
        [ 62.258],
        [-31.947],
        [-19.582],
        [-31.507],
        [-13.096],
        [-15.635],
        [-21.592],
        [ 27.577],
        [ 86.062],
        [ -2.265]], device='cuda:0')
v tensor([[1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-0.012, -0.055, -0.030,  ...,  0.007, -0.006, -0.007],
        [-0.080, -0.014,  0.114,  ...,  0.053, -0.026, -0.032],
        [ 0.046, -0.062, -0.029,  ..., -0.031, -0.132,  0.086],
        ...,
        [-0.048,  0.056, -0.044,  ...,  0.012, -0.051,  0.085],
        [-0.026, -0.012, -0.067,  ...,  0.022, -0.039, -0.013],
        [ 0.027, -0.019,  0.027,  ...,  0.050, -0.055,  0.020]],
       device='cuda:0')
s after update for 1 param tensor([[1.664, 1.655, 1.761,  ..., 1.207, 1.240, 1.051],
        [2.088, 1.913, 1.228,  ..., 0.787, 1.502, 1.196],
        [1.588, 2.001, 1.330,  ..., 1.532, 1.418, 1.654],
        ...,
        [1.157, 1.714, 1.647,  ..., 1.613, 0.982, 1.627],
        [1.595, 1.975, 1.588,  ..., 1.687, 1.724, 1.531],
        [1.188, 1.310, 1.651,  ..., 1.599, 1.309, 1.099]], device='cuda:0')
b after update for 1 param tensor([[107.309, 107.007, 110.376,  ...,  91.384,  92.623,  85.273],
        [120.200, 115.038,  92.165,  ...,  73.785, 101.930,  90.968],
        [104.803, 117.649,  95.940,  ..., 102.948,  99.029, 106.978],
        ...,
        [ 89.451, 108.899, 106.744,  ..., 105.627,  82.416, 106.092],
        [105.047, 116.893, 104.807,  ..., 108.047, 109.204, 102.900],
        [ 90.656,  95.185, 106.885,  ..., 105.173,  95.147,  87.206]],
       device='cuda:0')
clipping threshold 0.4104805946818939
a after update for 1 param tensor([ 5.061e-02, -7.354e-02,  1.392e-02,  3.378e-03, -3.997e-02, -2.943e-03,
         3.137e-02, -6.088e-02,  3.591e-02,  3.567e-03,  7.943e-03,  5.800e-03,
         3.080e-03, -2.385e-02, -4.017e-03,  1.629e-02, -1.509e-02, -5.374e-02,
         3.697e-02,  7.234e-02, -5.125e-02,  2.843e-02, -4.732e-02,  1.035e-01,
        -8.694e-03,  1.012e-01, -8.081e-02,  9.635e-03,  7.866e-02, -1.264e-02,
         4.519e-02, -7.177e-02, -9.041e-02, -5.411e-02, -3.545e-02, -1.822e-02,
         3.776e-02, -8.385e-02, -1.015e-02, -5.001e-02, -8.953e-03, -1.391e-01,
        -3.644e-03, -1.040e-01, -2.070e-02, -6.006e-02,  6.195e-02, -2.161e-02,
        -1.198e-01, -3.989e-02, -6.179e-03, -2.180e-02,  1.607e-02, -3.352e-02,
         8.586e-02,  5.791e-03,  4.360e-02, -1.017e-01,  5.933e-02, -3.309e-02,
         2.985e-03, -1.695e-02,  7.406e-02, -3.521e-02, -1.366e-02, -4.486e-02,
        -4.451e-02,  1.102e-02, -6.386e-02, -7.285e-02, -7.531e-02,  2.472e-02,
         5.682e-02,  6.889e-02, -4.208e-02,  5.254e-02, -8.270e-02,  1.404e-02,
         5.874e-02, -4.362e-02, -3.540e-02, -3.792e-02, -1.792e-02,  8.238e-02,
         3.110e-02, -5.914e-03, -1.889e-02, -2.107e-02,  5.220e-02, -5.089e-03,
         4.749e-02,  6.083e-05, -8.204e-02,  4.435e-02,  4.157e-02, -2.594e-02,
        -6.229e-02,  5.456e-03, -7.640e-03, -2.533e-03, -1.723e-03,  6.638e-03,
         3.554e-02,  4.075e-02, -1.460e-02, -5.806e-02, -3.063e-02, -6.180e-02,
        -2.659e-02, -2.127e-03,  2.603e-02, -2.334e-05,  2.863e-02, -3.288e-03,
         6.302e-02, -4.436e-02, -7.586e-02, -1.964e-02, -3.539e-02, -8.421e-04,
        -8.482e-02,  1.529e-02, -3.515e-02,  7.216e-03, -7.484e-02, -4.821e-02,
        -8.487e-02,  9.133e-02,  5.824e-02, -1.874e-02,  2.324e-02,  3.755e-03,
         1.006e-01,  1.461e-02, -4.291e-02, -9.079e-02,  5.240e-02,  1.919e-02,
        -2.617e-02,  3.684e-02,  4.048e-02,  6.586e-02,  4.394e-03, -4.927e-03,
        -6.524e-02, -4.201e-02, -1.040e-01,  5.800e-03, -1.245e-02,  2.514e-02,
        -2.576e-02,  1.896e-02,  2.672e-02, -3.881e-03, -3.119e-02, -3.249e-02,
        -2.640e-02,  6.413e-02, -3.640e-02,  6.555e-02, -3.906e-02, -5.400e-02,
        -7.332e-02,  5.735e-03,  1.347e-02,  8.491e-02,  2.821e-02, -3.514e-02,
         7.890e-02,  7.513e-03, -5.781e-02, -3.777e-02, -4.926e-02, -2.645e-02,
         7.127e-03,  6.819e-03, -2.631e-02,  4.329e-02, -1.719e-02, -1.460e-02,
         3.493e-02,  7.757e-02, -1.037e-01, -9.200e-03, -3.285e-02, -5.773e-02,
         2.954e-02, -1.480e-02, -4.366e-03, -1.327e-02,  9.175e-03, -1.148e-01,
         9.736e-02, -2.466e-02, -2.461e-04,  5.299e-02,  4.197e-02,  3.749e-02,
        -9.283e-02,  6.108e-02], device='cuda:0')
s after update for 1 param tensor([1.888, 1.561, 1.862, 1.421, 1.690, 1.457, 1.554, 1.364, 1.593, 0.754,
        1.613, 0.870, 1.616, 1.512, 1.226, 1.533, 1.358, 1.868, 1.011, 1.904,
        1.919, 1.533, 2.071, 2.169, 1.554, 1.508, 1.703, 1.290, 1.753, 2.066,
        2.043, 1.732, 1.554, 1.766, 1.788, 1.373, 1.765, 1.491, 1.468, 1.522,
        1.642, 1.610, 1.560, 1.846, 1.681, 1.492, 1.781, 1.333, 1.262, 1.484,
        1.353, 1.005, 1.802, 1.756, 2.038, 1.967, 0.528, 1.231, 1.423, 2.043,
        1.781, 1.723, 2.004, 1.689, 1.851, 1.660, 1.707, 1.404, 1.151, 2.019,
        1.878, 1.729, 1.559, 1.288, 1.257, 1.711, 1.670, 0.360, 2.125, 0.645,
        1.468, 1.774, 1.497, 1.376, 1.342, 1.752, 1.847, 1.787, 1.650, 1.128,
        1.996, 2.303, 1.705, 2.111, 1.856, 1.265, 1.415, 1.518, 1.784, 1.451,
        1.680, 1.257, 1.216, 1.039, 1.601, 2.047, 1.275, 1.633, 1.427, 1.273,
        1.042, 1.256, 1.624, 0.867, 1.686, 1.253, 1.775, 1.324, 1.697, 1.986,
        2.116, 0.956, 1.215, 1.933, 1.935, 1.989, 1.670, 1.612, 1.875, 1.535,
        1.797, 1.565, 1.750, 2.057, 1.358, 1.505, 1.792, 1.006, 1.480, 2.021,
        1.072, 0.956, 1.565, 1.425, 1.680, 1.337, 2.017, 1.576, 1.363, 1.611,
        1.822, 1.068, 0.586, 1.061, 1.241, 2.154, 1.343, 1.377, 1.833, 2.061,
        1.596, 1.795, 1.768, 1.393, 1.957, 1.668, 1.658, 1.671, 1.872, 1.334,
        1.452, 1.082, 1.303, 1.957, 1.841, 1.397, 1.684, 1.455, 2.034, 2.188,
        1.344, 1.131, 1.315, 2.134, 1.723, 1.627, 1.252, 1.132, 1.071, 1.812,
        1.707, 2.018, 1.823, 1.342, 1.469, 0.754, 1.456, 1.524, 1.033, 1.490],
       device='cuda:0')
b after update for 1 param tensor([114.290, 103.929, 113.502,  99.148, 108.117, 100.392, 103.692,  97.138,
        104.991,  72.206, 105.627,  77.575, 105.746, 102.268,  92.096, 102.981,
         96.931, 113.670,  83.623, 114.779, 115.210, 102.982, 119.693, 122.489,
        103.688, 102.151, 108.540,  94.477, 110.140, 119.545, 118.884, 109.468,
        103.691, 110.536, 111.215,  97.455, 110.515, 101.575, 100.760, 102.601,
        106.596, 105.551, 103.886, 113.023, 107.832, 101.608, 110.986,  96.048,
         93.443, 101.316,  96.740,  83.365, 111.648, 110.213, 118.752, 116.646,
         60.466,  92.301,  99.237, 118.872, 111.005, 109.165, 117.753, 108.103,
        113.159, 107.162, 108.663,  98.538,  89.243, 118.197, 113.994, 109.379,
        103.865,  94.406,  93.249, 108.786, 107.497,  49.934, 121.241,  66.805,
        100.781, 110.791, 101.756,  97.576,  96.371, 110.091, 113.039, 111.191,
        106.850,  88.336, 117.524, 126.234, 108.598, 120.842, 113.312,  93.532,
         98.934, 102.476, 111.081, 100.194, 107.803,  93.237,  91.725,  84.764,
        105.228, 118.989,  93.932, 106.300,  99.365,  93.833,  84.920,  93.202,
        106.012,  77.456, 107.996,  93.105, 110.820,  95.711, 108.344, 117.205,
        120.997,  81.336,  91.684, 115.639, 115.696, 117.303, 107.484, 105.600,
        113.899, 103.063, 111.501, 104.041, 110.029, 119.283,  96.925, 102.035,
        111.356,  83.423, 101.190, 118.251,  86.128,  81.315, 104.057,  99.297,
        107.812,  96.162, 118.114, 104.432,  97.113, 105.565, 112.262,  85.944,
         63.660,  85.688,  92.645, 122.081,  96.399,  97.613, 112.617, 119.400,
        105.073, 111.433, 110.581,  98.176, 116.354, 107.417, 107.106, 107.517,
        113.792,  96.078, 100.224,  86.530,  94.951, 116.352, 112.867,  98.296,
        107.927, 100.324, 118.615, 123.043,  96.436,  88.454,  95.365, 121.511,
        109.163, 106.086,  93.055,  88.483,  86.089, 111.951, 108.673, 118.143,
        112.290,  96.371, 100.809,  72.203, 100.376, 102.686,  84.541, 101.542],
       device='cuda:0')
clipping threshold 0.4104805946818939
a after update for 1 param tensor([[[ 2.002e-01],
         [-1.167e-01],
         [ 1.200e-02],
         [ 2.090e-01],
         [-6.446e-02],
         [ 1.463e-01],
         [ 2.257e-01],
         [-1.657e-01],
         [-3.389e-02],
         [ 1.848e-01]],

        [[-2.215e+00],
         [-1.407e+00],
         [-4.103e+00],
         [-4.171e+00],
         [-3.933e+00],
         [ 4.688e-02],
         [-5.199e-01],
         [-3.696e+00],
         [-3.917e+00],
         [-4.105e+00]],

        [[ 1.930e-01],
         [ 1.870e-01],
         [ 2.234e-01],
         [ 1.563e-01],
         [ 5.298e-02],
         [ 2.396e-01],
         [ 1.132e-01],
         [ 2.383e-01],
         [ 2.473e-01],
         [ 6.962e-03]],

        [[ 2.080e-01],
         [ 3.163e-01],
         [ 2.490e-01],
         [ 2.889e-01],
         [ 3.792e-02],
         [ 1.499e-01],
         [ 2.840e-01],
         [ 1.661e-02],
         [-1.104e-01],
         [ 1.549e-02]],

        [[-2.848e+00],
         [-2.871e+00],
         [-6.532e-01],
         [-2.986e+00],
         [-2.441e-02],
         [-4.539e-01],
         [-2.268e+00],
         [-2.018e-01],
         [-2.938e+00],
         [-2.310e+00]],

        [[ 7.784e-02],
         [ 1.093e+00],
         [-7.273e-01],
         [ 1.184e+00],
         [-8.929e-01],
         [ 7.732e-01],
         [-1.329e-01],
         [-5.225e-01],
         [-1.088e+00],
         [-9.452e-02]],

        [[-9.150e-01],
         [ 2.745e-01],
         [-1.382e+00],
         [-1.171e+00],
         [-1.171e+00],
         [-1.170e+00],
         [ 3.073e-01],
         [-1.140e+00],
         [-9.303e-01],
         [ 1.053e-01]],

        [[-4.663e-02],
         [-5.322e-04],
         [ 1.445e-01],
         [ 1.120e-01],
         [ 4.843e-02],
         [-5.553e-04],
         [-6.631e-02],
         [-2.069e-02],
         [-3.164e-02],
         [ 1.260e-01]],

        [[ 2.365e-01],
         [ 3.799e-01],
         [ 2.616e-01],
         [ 3.658e-01],
         [ 4.300e-01],
         [ 2.674e-01],
         [ 3.029e-01],
         [ 1.694e-01],
         [ 5.774e-02],
         [ 4.080e-01]],

        [[ 3.506e+00],
         [ 3.470e+00],
         [ 3.250e+00],
         [ 7.209e-03],
         [ 3.480e+00],
         [ 3.154e+00],
         [ 2.871e+00],
         [ 3.423e+00],
         [-2.380e-03],
         [-4.304e-02]],

        [[ 5.379e-01],
         [ 6.205e-01],
         [-6.443e-02],
         [ 4.699e-01],
         [ 5.283e-01],
         [ 1.458e-01],
         [ 5.118e-01],
         [-4.474e-02],
         [ 5.782e-02],
         [ 4.048e-01]],

        [[ 3.432e-02],
         [-5.157e-02],
         [ 3.909e-02],
         [ 1.283e-01],
         [ 1.215e+00],
         [ 1.259e+00],
         [ 1.330e+00],
         [ 1.145e+00],
         [ 1.166e+00],
         [ 9.387e-01]],

        [[ 1.098e+00],
         [ 1.237e-01],
         [ 9.281e-01],
         [-8.021e-02],
         [ 1.057e+00],
         [ 1.114e+00],
         [ 8.936e-02],
         [ 1.277e+00],
         [ 6.081e-02],
         [ 1.137e+00]],

        [[-6.387e-02],
         [ 6.911e-01],
         [ 7.332e-01],
         [ 6.525e-01],
         [ 2.529e-02],
         [ 8.024e-01],
         [-5.278e-03],
         [-1.019e-01],
         [ 4.136e-01],
         [ 8.058e-01]],

        [[-5.465e-02],
         [-6.036e-02],
         [ 1.120e+00],
         [ 1.295e+00],
         [ 2.255e-03],
         [-5.444e-02],
         [ 1.352e+00],
         [ 1.511e+00],
         [-1.046e-01],
         [ 4.202e-01]],

        [[ 1.272e+00],
         [ 1.314e+00],
         [-5.630e-01],
         [ 1.203e+00],
         [-1.785e-01],
         [-4.012e-01],
         [-1.824e-01],
         [ 1.254e+00],
         [ 6.824e-01],
         [ 8.803e-01]],

        [[-9.778e-01],
         [ 3.101e-01],
         [-1.173e+00],
         [-1.256e+00],
         [-1.170e+00],
         [ 1.353e-01],
         [-1.367e+00],
         [ 3.287e-01],
         [-1.264e+00],
         [-1.163e+00]],

        [[-1.038e+00],
         [-9.322e-01],
         [-9.677e-01],
         [-7.358e-01],
         [-9.204e-01],
         [-7.789e-01],
         [ 1.320e-02],
         [ 2.780e-02],
         [-9.765e-02],
         [-7.465e-02]],

        [[ 4.950e-01],
         [ 3.118e-01],
         [-8.846e-02],
         [ 3.881e-01],
         [-1.429e-01],
         [-1.151e-01],
         [-1.728e-01],
         [-3.030e-02],
         [-1.214e-01],
         [ 3.557e-01]],

        [[-1.146e-01],
         [ 4.440e-01],
         [ 6.010e-02],
         [ 1.161e-01],
         [ 5.486e-02],
         [ 5.676e-02],
         [ 4.574e-01],
         [ 3.124e-01],
         [ 4.621e-01],
         [ 2.107e-01]]], device='cuda:0')
s after update for 1 param tensor([[[1.456],
         [1.321],
         [1.786],
         [1.854],
         [1.327],
         [1.937],
         [1.758],
         [1.727],
         [1.323],
         [1.539]],

        [[2.470],
         [2.237],
         [2.261],
         [2.374],
         [1.925],
         [1.579],
         [2.724],
         [1.902],
         [2.555],
         [1.689]],

        [[1.419],
         [2.099],
         [1.932],
         [1.650],
         [2.090],
         [1.130],
         [1.550],
         [0.854],
         [1.721],
         [1.634]],

        [[1.387],
         [1.570],
         [1.592],
         [2.085],
         [1.479],
         [1.707],
         [1.342],
         [1.861],
         [1.587],
         [1.717]],

        [[2.670],
         [2.821],
         [1.815],
         [2.799],
         [1.437],
         [2.207],
         [2.416],
         [1.615],
         [2.731],
         [2.637]],

        [[1.884],
         [1.488],
         [2.214],
         [1.367],
         [0.952],
         [1.719],
         [1.466],
         [1.980],
         [1.351],
         [1.209]],

        [[1.759],
         [0.709],
         [1.490],
         [1.990],
         [1.810],
         [1.834],
         [1.117],
         [1.974],
         [1.643],
         [2.159]],

        [[2.316],
         [1.567],
         [1.923],
         [2.052],
         [0.904],
         [0.906],
         [2.027],
         [1.464],
         [1.068],
         [1.542]],

        [[2.005],
         [2.413],
         [2.124],
         [1.841],
         [1.687],
         [1.835],
         [1.932],
         [1.681],
         [1.740],
         [1.818]],

        [[2.593],
         [2.611],
         [2.731],
         [1.221],
         [2.622],
         [2.474],
         [2.067],
         [2.449],
         [2.026],
         [1.363]],

        [[1.421],
         [2.220],
         [1.238],
         [1.292],
         [1.684],
         [1.648],
         [1.409],
         [1.096],
         [1.118],
         [1.700]],

        [[1.653],
         [1.508],
         [1.669],
         [1.413],
         [1.843],
         [2.600],
         [2.173],
         [2.248],
         [1.667],
         [2.030]],

        [[2.392],
         [1.080],
         [2.274],
         [1.878],
         [2.228],
         [2.329],
         [1.569],
         [2.129],
         [1.739],
         [2.496]],

        [[1.515],
         [1.396],
         [1.822],
         [1.918],
         [1.338],
         [2.058],
         [0.868],
         [1.886],
         [1.355],
         [1.659]],

        [[1.866],
         [1.695],
         [1.597],
         [2.031],
         [1.678],
         [1.695],
         [1.690],
         [1.515],
         [1.176],
         [1.711]],

        [[0.969],
         [1.692],
         [1.997],
         [2.074],
         [2.051],
         [1.367],
         [1.802],
         [0.940],
         [1.718],
         [1.788]],

        [[1.218],
         [1.335],
         [1.732],
         [1.214],
         [1.915],
         [1.974],
         [1.781],
         [0.905],
         [1.800],
         [2.047]],

        [[2.068],
         [2.019],
         [1.501],
         [2.526],
         [1.943],
         [2.405],
         [1.381],
         [1.145],
         [1.590],
         [1.544]],

        [[1.548],
         [1.688],
         [1.518],
         [1.598],
         [1.350],
         [1.207],
         [1.385],
         [1.125],
         [1.269],
         [1.814]],

        [[0.933],
         [1.722],
         [1.482],
         [1.611],
         [1.693],
         [0.489],
         [1.550],
         [1.884],
         [1.486],
         [1.344]]], device='cuda:0')
b after update for 1 param tensor([[[100.380],
         [ 95.597],
         [111.152],
         [113.240],
         [ 95.818],
         [115.757],
         [110.282],
         [109.314],
         [ 95.671],
         [103.193]],

        [[130.709],
         [124.398],
         [125.078],
         [128.167],
         [115.394],
         [104.514],
         [137.279],
         [114.707],
         [132.959],
         [108.089]],

        [[ 99.086],
         [120.506],
         [115.612],
         [106.837],
         [120.239],
         [ 88.408],
         [103.537],
         [ 76.873],
         [109.120],
         [106.315]],

        [[ 97.953],
         [104.207],
         [104.956],
         [120.094],
         [101.136],
         [108.673],
         [ 96.337],
         [113.480],
         [104.774],
         [108.998]],

        [[135.900],
         [139.699],
         [112.063],
         [139.163],
         [ 99.716],
         [123.561],
         [129.283],
         [105.688],
         [137.464],
         [135.056]],

        [[114.174],
         [101.476],
         [123.757],
         [ 97.256],
         [ 81.146],
         [109.052],
         [100.720],
         [117.042],
         [ 96.664],
         [ 91.459]],

        [[110.303],
         [ 70.032],
         [101.512],
         [117.337],
         [111.889],
         [112.645],
         [ 87.924],
         [116.871],
         [106.630],
         [122.209]],

        [[126.586],
         [104.120],
         [115.346],
         [119.154],
         [ 79.094],
         [ 79.169],
         [118.425],
         [100.654],
         [ 85.945],
         [103.282]],

        [[117.762],
         [129.209],
         [121.207],
         [112.861],
         [108.045],
         [112.683],
         [115.625],
         [107.854],
         [109.702],
         [112.163]],

        [[133.948],
         [134.398],
         [137.446],
         [ 91.911],
         [134.673],
         [130.817],
         [119.581],
         [130.176],
         [118.396],
         [ 97.118]],

        [[ 99.156],
         [123.938],
         [ 92.534],
         [ 94.528],
         [107.923],
         [106.764],
         [ 98.744],
         [ 87.089],
         [ 87.963],
         [108.438]],

        [[106.948],
         [102.146],
         [107.470],
         [ 98.854],
         [112.923],
         [134.119],
         [122.607],
         [124.703],
         [107.387],
         [118.505]],

        [[128.643],
         [ 86.450],
         [125.419],
         [113.976],
         [124.157],
         [126.927],
         [104.192],
         [121.363],
         [109.685],
         [131.420]],

        [[102.381],
         [ 98.261],
         [112.280],
         [115.206],
         [ 96.197],
         [119.334],
         [ 77.495],
         [114.220],
         [ 96.818],
         [107.135]],

        [[113.627],
         [108.287],
         [105.107],
         [118.527],
         [107.758],
         [108.283],
         [108.124],
         [102.370],
         [ 90.202],
         [108.807]],

        [[ 81.882],
         [108.181],
         [117.535],
         [119.787],
         [119.109],
         [ 97.253],
         [111.652],
         [ 80.640],
         [109.030],
         [111.224]],

        [[ 91.786],
         [ 96.102],
         [109.456],
         [ 91.662],
         [115.094],
         [116.863],
         [111.004],
         [ 79.114],
         [111.583],
         [118.996]],

        [[119.612],
         [118.189],
         [101.906],
         [132.198],
         [115.939],
         [129.000],
         [ 97.740],
         [ 89.011],
         [104.870],
         [103.346]],

        [[103.476],
         [108.058],
         [102.494],
         [105.150],
         [ 96.630],
         [ 91.381],
         [ 97.900],
         [ 88.226],
         [ 93.710],
         [112.016]],

        [[ 80.327],
         [109.146],
         [101.240],
         [105.573],
         [108.212],
         [ 58.176],
         [103.546],
         [114.181],
         [101.391],
         [ 96.412]]], device='cuda:0')
clipping threshold 0.4104805946818939
a after update for 1 param tensor([[ 1.007e-01],
        [-4.016e+00],
        [ 2.050e-01],
        [ 1.023e-01],
        [-2.842e+00],
        [-2.535e-03],
        [-1.003e+00],
        [-1.524e-02],
        [ 3.699e-01],
        [ 3.521e+00],
        [ 4.661e-01],
        [ 1.204e+00],
        [ 1.208e+00],
        [ 7.859e-01],
        [ 1.309e+00],
        [ 7.271e-01],
        [-9.249e-01],
        [-7.866e-01],
        [ 3.620e-01],
        [ 9.372e-02]], device='cuda:0')
s after update for 1 param tensor([[1.551],
        [2.109],
        [1.375],
        [1.365],
        [2.881],
        [1.438],
        [1.729],
        [1.266],
        [1.827],
        [2.850],
        [2.045],
        [2.199],
        [1.692],
        [1.947],
        [1.469],
        [2.011],
        [2.204],
        [2.089],
        [2.227],
        [1.659]], device='cuda:0')
b after update for 1 param tensor([[103.577],
        [120.805],
        [ 97.537],
        [ 97.165],
        [141.180],
        [ 99.737],
        [109.368],
        [ 93.603],
        [112.433],
        [140.418],
        [118.941],
        [123.343],
        [108.200],
        [116.050],
        [100.802],
        [117.938],
        [123.484],
        [120.207],
        [124.132],
        [107.142]], device='cuda:0')
clipping threshold 0.4104805946818939
||w||^2 0.17675950908732654
exp ma of ||w||^2 0.6363870396314869
||w|| 0.42042776916769725
exp ma of ||w|| 0.7270818788292199
||w||^2 0.5764852245061356
exp ma of ||w||^2 0.6403050641578143
||w|| 0.7592662408576688
exp ma of ||w|| 0.750116975561722
||w||^2 0.3859004169822814
exp ma of ||w||^2 0.6579687990326043
||w|| 0.6212088352416452
exp ma of ||w|| 0.7661207445914895
||w||^2 0.39880325027744234
exp ma of ||w||^2 0.6522925426629129
||w|| 0.6315087095816195
exp ma of ||w|| 0.7620397591289524
||w||^2 1.9439634652845224
exp ma of ||w||^2 0.8094745160387451
||w|| 1.394260902874538
exp ma of ||w|| 0.8608245935303463
cuda
Objective function 42.31 = squared loss an data 35.04 + 0.5*rho*h**2 5.755893 + alpha*h 0.000000 + L2reg 1.22 + L1reg 0.30 ; SHD = 133 ; DAG False
Proportion of microbatches that were clipped  0.7699079308673882
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 3.3929022201207317
iteration 1 in outer loop, alpha = 3.3929022201207317, rho = 1.0, h = 3.3929022201207317
cuda
4420
cuda
Objective function 53.82 = squared loss an data 35.04 + 0.5*rho*h**2 5.755893 + alpha*h 11.511785 + L2reg 1.22 + L1reg 0.30 ; SHD = 133 ; DAG False
||w||^2 66531134116.93013
exp ma of ||w||^2 107800665614.84293
||w|| 257936.29856406432
exp ma of ||w|| 251207.90014730915
||w||^2 1452.0074995870784
exp ma of ||w||^2 86620766.06436528
||w|| 38.10521617294775
exp ma of ||w|| 1097.3191261616544
||w||^2 1.388014067775139
exp ma of ||w||^2 1863306.273978488
||w|| 1.1781400883490634
exp ma of ||w|| 28.419234042625817
||w||^2 1.030250917015094
exp ma of ||w||^2 1.0124206309425345
||w|| 1.0150127669222166
exp ma of ||w|| 0.968007664229611
||w||^2 0.75185224344928
exp ma of ||w||^2 0.9885449520048255
||w|| 0.8670941375936525
exp ma of ||w|| 0.9455549473895533
||w||^2 1.6777679496429385
exp ma of ||w||^2 1.2381110248213798
||w|| 1.2952868213808626
exp ma of ||w|| 1.0512130119128453
||w||^2 0.6480276012150179
exp ma of ||w||^2 1.131886237535808
||w|| 0.8050016156598805
exp ma of ||w|| 1.0177295616573034
||w||^2 2.77717030196761
exp ma of ||w||^2 1.2384984608956986
||w|| 1.6664844139588015
exp ma of ||w|| 1.0613180852612902
||w||^2 1.8002939853563005
exp ma of ||w||^2 1.1343822909774264
||w|| 1.3417503439001983
exp ma of ||w|| 1.033372376302272
||w||^2 0.6251842696931385
exp ma of ||w||^2 1.1767527953488206
||w|| 0.7906859488400806
exp ma of ||w|| 1.0317275753640838
||w||^2 1.257198934635773
exp ma of ||w||^2 1.1197911569839447
||w|| 1.1212488281535784
exp ma of ||w|| 1.0275511759269402
||w||^2 0.827249188201147
exp ma of ||w||^2 1.2742488906584877
||w|| 0.9095324008528487
exp ma of ||w|| 1.0880411573327078
cuda
Objective function 39.21 = squared loss an data 27.21 + 0.5*rho*h**2 2.517296 + alpha*h 7.612959 + L2reg 1.59 + L1reg 0.27 ; SHD = 108 ; DAG False
Proportion of microbatches that were clipped  0.7679719938125865
iteration 1 in inner loop, alpha 3.3929022201207317 rho 1.0 h 2.2437896394973222
4420
cuda
Objective function 61.87 = squared loss an data 27.21 + 0.5*rho*h**2 25.172960 + alpha*h 7.612959 + L2reg 1.59 + L1reg 0.27 ; SHD = 108 ; DAG False
||w||^2 302.32287262526455
exp ma of ||w||^2 27813317.1354529
||w|| 17.387434331299847
exp ma of ||w|| 293.22544826067855
||w||^2 1.5880751940255362
exp ma of ||w||^2 4.012674984784179
||w|| 1.2601885549494314
exp ma of ||w|| 1.3713322785801405
v before min max tensor([[-171.892, -154.540,  260.700,  ...,   12.759, -192.572,  705.684],
        [ -67.582,  -39.480, 2004.208,  ...,  -25.805,  676.292, -197.688],
        [ 409.826,   55.950,  288.712,  ...,  179.256,  -27.381,   46.261],
        ...,
        [ -71.102,   -5.437,    5.923,  ...,  162.295, -133.803, -115.590],
        [ -55.367,   -6.456, -146.756,  ..., -164.975,  -68.934, -172.017],
        [ -21.903,  -37.590, -119.732,  ...,  -43.986,  -80.538, -157.458]],
       device='cuda:0')
v tensor([[1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e+01,
         1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.000e+01],
        ...,
        [1.000e-12, 1.000e-12, 5.923e+00,  ..., 1.000e+01, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([-9.657e+01,  2.163e+02, -1.874e+01, -1.924e+02, -1.458e+02, -8.063e+01,
         2.785e+02, -1.169e+02,  9.619e+01,  9.395e+00,  1.716e+02, -1.042e+02,
        -1.530e+02, -5.414e+01, -1.260e+02, -1.899e+01,  8.377e+02, -1.650e+02,
         4.904e+02,  6.626e+00, -7.456e+01,  2.087e+02,  9.299e+01, -1.490e+02,
         1.788e+02, -3.131e+01, -1.998e+02, -1.263e+02,  3.006e+02,  1.412e+02,
        -6.128e+01, -1.552e+02,  4.102e+01,  3.006e+01, -1.049e+02, -1.434e+02,
        -1.919e+02,  1.586e+02, -1.119e+02, -1.549e+02,  7.618e+02, -1.307e+02,
        -2.002e+02, -1.516e+02, -1.592e+02, -1.760e+02,  1.196e+00, -7.479e+01,
         4.250e+02, -7.935e+01, -1.529e+02,  9.154e+01,  7.885e+01, -1.448e+02,
        -1.656e+02,  6.048e+01,  4.913e+01, -1.740e+02,  1.646e+02,  1.250e+02,
         9.488e+01, -1.569e+02, -1.457e+02, -1.951e+02, -1.846e+01, -1.369e+02,
        -1.493e+02,  3.047e+02,  8.029e+01,  9.520e+01, -1.955e+02, -9.576e+01,
        -5.085e+01,  2.571e+02, -1.270e+02, -1.085e+02,  3.693e+01, -1.202e+02,
         3.747e+02,  1.629e+02, -1.657e+02, -1.829e+02,  3.320e+02,  1.022e+01,
        -1.331e+02, -7.623e+01, -1.219e+02,  1.526e+02,  4.663e+02,  6.214e+02,
         2.298e+03,  2.368e+02,  1.027e+03, -1.432e+02,  1.232e+02,  3.083e+02,
        -1.707e+02, -9.287e+01,  2.782e+02, -9.583e+01, -1.879e+02, -1.964e+02,
        -9.378e+01,  1.077e+03, -1.259e+02, -1.903e+02,  1.615e+02, -1.973e+01,
        -6.486e+00,  3.112e+02, -1.903e+02, -1.822e+02, -5.719e+01,  3.282e+01,
         1.859e+02, -1.165e+02, -1.085e+02, -1.768e+02, -1.957e+02,  8.883e+02,
        -1.593e+02, -1.212e+02,  9.109e+01,  8.772e+02, -1.729e+02, -1.323e+02,
        -1.623e+02,  3.488e+02, -1.535e+02,  1.096e+02, -2.127e+02, -1.838e+02,
         1.472e+02, -1.475e+02, -1.504e+02,  4.049e+02, -1.668e+02, -1.927e+02,
        -1.165e+02, -1.503e+02, -5.458e+01,  3.135e+02, -1.895e+02, -3.632e+01,
         1.255e+01, -1.362e+02, -1.628e+02,  1.564e+02, -1.060e+02, -1.398e+02,
        -1.155e+02, -1.480e+02, -1.150e+02, -1.557e+02, -1.299e+01,  4.506e+01,
        -1.012e+02, -1.863e+02,  6.315e+02, -1.256e+02, -5.885e+01,  2.327e+02,
        -1.125e+02, -1.478e+02, -1.375e+02, -1.782e+02, -1.356e+02,  1.069e+02,
         2.150e+02, -2.133e+02, -1.746e+02,  2.623e+02, -9.958e+01, -9.801e+00,
        -1.117e+02, -1.183e+02, -7.595e+01, -1.087e+02, -1.965e+02, -1.221e+02,
        -2.103e+02, -1.564e+02, -1.624e+02,  4.404e+02, -1.791e+02, -1.605e+02,
         6.288e+01, -7.329e+01, -1.302e+02, -1.263e+02, -1.699e+02, -1.225e+02,
        -1.304e+02,  1.511e+02, -2.041e+02, -6.575e+01, -2.294e+01, -1.632e+02,
        -1.312e+00, -1.515e+01], device='cuda:0')
v tensor([1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 9.395e+00, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 6.626e+00, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.196e+00, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12], device='cuda:0')
v before min max tensor([[[ 7.681e+01],
         [-4.934e+01],
         [-5.032e+01],
         [-1.398e+02],
         [-1.141e+02],
         [ 1.097e+02],
         [-2.192e+02],
         [ 3.844e+01],
         [ 4.776e+01],
         [-6.548e-01]],

        [[ 3.160e+01],
         [-1.067e+02],
         [-1.882e+02],
         [ 2.628e+02],
         [-4.903e+01],
         [ 5.133e+01],
         [ 5.067e+01],
         [ 5.232e+02],
         [-1.181e+02],
         [ 1.791e+02]],

        [[ 1.467e+01],
         [-1.572e+02],
         [-8.043e+01],
         [ 1.690e+02],
         [-1.123e+02],
         [-3.229e+01],
         [ 5.400e+01],
         [-1.918e+02],
         [ 3.001e+02],
         [-1.675e+02]],

        [[-1.728e+02],
         [-4.618e+00],
         [-1.885e+02],
         [-1.677e+02],
         [-1.386e+02],
         [ 1.396e+03],
         [-1.231e+02],
         [ 7.222e+01],
         [-1.672e+02],
         [-1.500e+02]],

        [[-7.478e+01],
         [-9.101e+01],
         [-1.610e+02],
         [-1.701e+02],
         [ 1.815e+01],
         [ 9.661e+00],
         [ 5.447e+01],
         [-1.171e+02],
         [ 1.809e+03],
         [-3.783e+01]],

        [[-1.502e+02],
         [-1.106e+02],
         [ 1.061e+02],
         [ 5.873e+01],
         [-7.689e+01],
         [-1.538e+02],
         [ 1.333e+02],
         [ 6.204e+02],
         [-1.289e+02],
         [-1.751e+02]],

        [[-2.466e+01],
         [ 1.075e+01],
         [-9.914e+01],
         [-1.333e+02],
         [-5.093e+01],
         [-6.143e+01],
         [-1.932e+02],
         [-1.145e+02],
         [-2.770e+01],
         [-7.911e+01]],

        [[ 8.423e+01],
         [ 1.341e+02],
         [-1.091e+02],
         [-1.269e+02],
         [ 6.694e+01],
         [ 7.038e+02],
         [-7.231e+01],
         [-2.026e+02],
         [-1.779e+02],
         [ 8.723e+02]],

        [[-9.886e+01],
         [-1.279e+02],
         [ 1.974e+02],
         [-1.527e+02],
         [ 6.220e+01],
         [ 8.437e+01],
         [ 4.214e+02],
         [-1.241e+02],
         [-1.245e+02],
         [ 2.007e+02]],

        [[-1.352e+02],
         [-9.159e+01],
         [-1.721e+02],
         [-1.811e+02],
         [ 2.971e+02],
         [ 1.445e+01],
         [ 1.249e+02],
         [-4.009e+01],
         [-1.715e+02],
         [ 1.397e+02]],

        [[-1.324e+02],
         [ 3.560e+02],
         [ 6.373e+02],
         [-1.944e+02],
         [-1.694e+02],
         [-8.310e+00],
         [-1.456e+02],
         [-1.440e+02],
         [-2.022e+02],
         [ 3.334e+02]],

        [[-1.510e+02],
         [ 3.470e+02],
         [-5.368e+01],
         [-1.795e+02],
         [ 3.973e+02],
         [-1.687e+02],
         [ 1.222e+02],
         [-6.187e+01],
         [ 4.850e+01],
         [-1.382e+02]],

        [[-1.363e+02],
         [ 2.586e+01],
         [-1.665e+02],
         [-1.755e+02],
         [-2.176e+02],
         [-7.704e+01],
         [-6.905e+01],
         [-8.878e+01],
         [ 3.833e+01],
         [ 3.065e+02]],

        [[-1.459e+02],
         [-1.376e+02],
         [-5.518e+01],
         [-2.178e+02],
         [ 1.460e+02],
         [-2.397e+00],
         [-1.755e+02],
         [ 4.945e+01],
         [-8.189e+01],
         [-1.696e+02]],

        [[-1.574e+02],
         [ 4.451e+02],
         [-1.601e+02],
         [-1.518e+02],
         [ 2.075e+01],
         [-1.480e+02],
         [-1.181e+02],
         [ 1.953e+03],
         [ 4.216e+02],
         [ 1.093e+02]],

        [[-2.952e+01],
         [-1.898e+02],
         [-1.883e+02],
         [ 3.115e+02],
         [ 6.016e+01],
         [ 4.840e+02],
         [ 6.449e+02],
         [-1.566e+02],
         [-1.384e+02],
         [ 1.424e+02]],

        [[-1.276e+02],
         [-1.754e+02],
         [-1.172e+02],
         [ 1.258e+01],
         [ 9.095e+00],
         [-6.476e+01],
         [-1.640e+02],
         [-1.652e+02],
         [ 9.189e+01],
         [-1.330e+02]],

        [[ 5.453e+01],
         [-1.816e+02],
         [-2.761e+01],
         [ 2.821e+02],
         [-1.888e+02],
         [-1.982e+02],
         [-1.272e+02],
         [-8.905e+01],
         [-1.231e+02],
         [ 9.806e+01]],

        [[-1.214e+02],
         [ 1.131e+02],
         [ 7.138e+01],
         [-1.633e+02],
         [-1.694e+02],
         [-5.363e+01],
         [ 5.686e+01],
         [-5.840e+01],
         [-1.641e+02],
         [-1.081e+02]],

        [[-1.784e+02],
         [ 1.726e+02],
         [-1.705e+02],
         [-1.651e+02],
         [-1.267e+02],
         [-1.138e+02],
         [ 4.275e+02],
         [-1.341e+02],
         [-1.600e+02],
         [-1.727e+02]]], device='cuda:0')
v tensor([[[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [9.661e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [9.095e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[  75.984],
        [-167.626],
        [ -64.465],
        [-105.187],
        [ 316.849],
        [ 254.839],
        [-124.571],
        [-162.371],
        [ 142.599],
        [-186.475],
        [ 272.960],
        [1112.861],
        [ 136.446],
        [-178.807],
        [ 805.694],
        [-191.001],
        [ 725.713],
        [-103.020],
        [ -82.403],
        [ -79.749]], device='cuda:0')
v tensor([[1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 2.820e-02,  2.357e-04, -3.457e-01,  ..., -3.200e-01,  1.028e-01,
         -1.155e-01],
        [-9.576e-02, -3.721e-01,  8.346e-02,  ...,  3.784e-01,  7.033e-02,
          1.182e-01],
        [-3.517e-02, -4.634e-03,  1.025e-01,  ..., -1.359e-01,  1.256e-01,
         -7.290e-02],
        ...,
        [-3.462e-03, -5.527e-02, -9.719e-03,  ...,  5.022e-02,  1.534e-01,
          1.737e-01],
        [ 2.681e-02,  6.928e-02,  1.270e-01,  ...,  6.938e-02,  1.871e-02,
         -1.166e-02],
        [ 6.067e-02, -8.899e-02, -1.865e-01,  ..., -3.572e-02,  1.147e-01,
         -8.973e-03]], device='cuda:0')
s after update for 1 param tensor([[1.631, 1.662, 2.078,  ..., 1.961, 1.806, 1.761],
        [1.554, 1.567, 2.246,  ..., 1.345, 1.946, 2.097],
        [1.715, 1.809, 1.711,  ..., 1.878, 1.044, 1.669],
        ...,
        [1.206, 1.587, 2.283,  ..., 1.638, 1.794, 1.950],
        [1.404, 2.283, 1.835,  ..., 1.621, 1.401, 1.700],
        [2.112, 1.780, 1.156,  ..., 1.178, 1.525, 1.489]], device='cuda:0')
b after update for 1 param tensor([[111.963, 113.023, 126.381,  ..., 122.772, 117.823, 116.358],
        [109.290, 109.767, 131.407,  ..., 101.693, 122.295, 126.962],
        [114.828, 117.916, 114.682,  ..., 120.150,  89.579, 113.249],
        ...,
        [ 96.296, 110.434, 132.465,  ..., 112.213, 117.417, 122.426],
        [103.878, 132.468, 118.753,  ..., 111.636, 103.784, 114.316],
        [127.409, 116.979,  94.263,  ...,  95.155, 108.254, 106.981]],
       device='cuda:0')
clipping threshold 1.006451199552889
a after update for 1 param tensor([-0.112,  0.020,  0.044, -0.060, -0.027, -0.119,  0.213,  0.160,  0.162,
         0.082, -0.086,  0.154,  0.197, -0.124,  0.331,  0.038,  0.189,  0.031,
        -0.067,  0.022,  0.082,  0.219, -0.100,  0.098, -0.032,  0.253, -0.169,
        -0.003,  0.164,  0.199, -0.046, -0.110, -0.113, -0.105,  0.151, -0.229,
        -0.078, -0.023, -0.053, -0.141,  0.345,  0.012, -0.345, -0.032,  0.057,
        -0.184,  0.031, -0.008, -0.194,  0.153,  0.116,  0.338,  0.003, -0.202,
        -0.057,  0.218,  0.215, -0.210,  0.044, -0.174, -0.039,  0.112, -0.218,
        -0.327,  0.290, -0.021,  0.413,  0.041, -0.205,  0.038,  0.008, -0.421,
        -0.081, -0.096,  0.221,  0.142,  0.105,  0.221,  0.123,  0.180,  0.069,
        -0.115, -0.013,  0.358, -0.178,  0.080, -0.058, -0.232,  0.174, -0.055,
        -0.132,  0.084, -0.272,  0.069,  0.178,  0.080, -0.262, -0.296, -0.114,
        -0.133, -0.075,  0.170, -0.026,  0.160, -0.169, -0.020, -0.056, -0.094,
        -0.163,  0.374, -0.272,  0.070, -0.324, -0.021,  0.071, -0.054,  0.403,
        -0.080, -0.047, -0.280,  0.218,  0.103,  0.027, -0.001, -0.067, -0.212,
         0.376,  0.108,  0.106,  0.120,  0.005, -0.040,  0.003,  0.129, -0.079,
        -0.096,  0.067, -0.087,  0.451,  0.249,  0.031,  0.130,  0.210, -0.138,
        -0.202, -0.037, -0.013,  0.113, -0.028,  0.066,  0.140,  0.110, -0.341,
         0.219, -0.038,  0.079,  0.161, -0.129,  0.160,  0.020,  0.163,  0.205,
         0.275, -0.056,  0.099,  0.314,  0.123,  0.255,  0.172,  0.002, -0.325,
         0.146,  0.172, -0.058,  0.244,  0.229, -0.024,  0.286,  0.016,  0.110,
         0.243,  0.016,  0.219,  0.208,  0.109,  0.101, -0.166,  0.119, -0.143,
        -0.130, -0.043,  0.256,  0.025, -0.240, -0.221, -0.065, -0.227,  0.107,
        -0.072,  0.223], device='cuda:0')
s after update for 1 param tensor([1.283, 1.731, 0.864, 1.810, 1.598, 1.534, 1.852, 1.907, 2.035, 1.754,
        1.210, 1.187, 1.816, 1.620, 1.385, 1.788, 1.744, 1.579, 1.620, 1.431,
        1.681, 2.000, 1.984, 1.554, 2.016, 1.752, 1.873, 1.965, 1.695, 1.857,
        1.253, 1.766, 2.116, 2.194, 1.548, 1.343, 1.862, 1.640, 1.530, 1.524,
        1.893, 1.440, 1.898, 1.851, 1.727, 1.650, 2.189, 1.451, 1.928, 2.047,
        1.852, 1.742, 1.747, 1.559, 1.929, 1.253, 1.619, 1.754, 2.033, 2.053,
        2.239, 1.508, 1.445, 1.911, 1.326, 1.432, 1.410, 1.678, 2.278, 1.819,
        1.831, 1.607, 1.548, 2.100, 1.649, 1.924, 2.106, 1.643, 2.267, 2.259,
        1.771, 1.787, 1.956, 1.971, 1.645, 1.255, 1.408, 2.153, 1.978, 2.023,
        2.008, 1.531, 2.247, 1.477, 1.597, 1.920, 1.738, 1.659, 2.121, 1.182,
        1.760, 1.890, 1.385, 1.937, 1.594, 1.901, 1.969, 1.813, 1.727, 2.085,
        1.792, 1.712, 1.865, 1.517, 2.065, 1.116, 1.596, 1.697, 2.290, 2.304,
        1.575, 1.189, 1.955, 2.462, 1.623, 1.437, 1.836, 2.060, 2.029, 2.084,
        2.005, 1.726, 1.967, 1.755, 1.411, 2.210, 1.924, 1.806, 1.105, 2.092,
        1.768, 1.864, 1.776, 1.609, 2.035, 1.277, 1.539, 2.166, 1.029, 1.422,
        1.565, 1.403, 1.285, 1.581, 1.492, 1.811, 1.627, 1.760, 2.051, 1.473,
        1.564, 1.999, 1.837, 1.664, 1.851, 1.891, 1.719, 1.773, 2.147, 2.026,
        1.675, 1.723, 1.081, 1.803, 1.460, 1.780, 1.672, 1.498, 1.863, 1.490,
        2.005, 2.004, 1.603, 1.643, 1.888, 1.522, 1.690, 1.681, 1.330, 1.271,
        1.592, 1.710, 1.238, 2.169, 1.936, 2.050, 1.905, 1.684, 0.978, 2.099],
       device='cuda:0')
b after update for 1 param tensor([ 99.305, 115.337,  81.506, 117.960, 110.835, 108.580, 119.329, 121.063,
        125.084, 116.101,  96.455,  95.537, 118.155, 111.603, 103.190, 117.218,
        115.796, 110.179, 111.605, 104.895, 113.671, 123.975, 123.487, 109.279,
        124.499, 116.033, 119.990, 122.901, 114.155, 119.476,  98.138, 116.520,
        127.522, 129.873, 109.094, 101.621, 119.633, 112.273, 108.459, 108.236,
        120.626, 105.219, 120.780, 119.289, 115.226, 112.605, 129.706, 105.606,
        121.735, 125.449, 119.305, 115.718, 115.876, 109.483, 121.771,  98.130,
        111.565, 116.114, 124.995, 125.615, 131.175, 107.650, 105.378, 121.212,
        100.957, 104.906, 104.103, 113.565, 132.334, 118.258, 118.647, 111.131,
        109.079, 127.052, 112.589, 121.596, 127.218, 112.389, 131.999, 131.781,
        116.667, 117.212, 122.621, 123.085, 112.453,  98.220, 104.035, 128.652,
        123.298, 124.699, 124.240, 108.465, 131.411, 106.554, 110.804, 121.498,
        115.576, 112.909, 127.696,  95.315, 116.328, 120.523, 103.180, 122.007,
        110.679, 120.880, 123.021, 118.040, 115.205, 126.594, 117.359, 114.725,
        119.732, 107.994, 125.998,  92.617, 110.745, 114.215, 132.679, 133.069,
        110.019,  95.588, 122.589, 137.580, 111.681, 105.097, 118.809, 125.836,
        124.898, 126.571, 124.148, 115.170, 122.966, 116.158, 104.156, 130.325,
        121.605, 117.808,  92.176, 126.819, 116.566, 119.712, 116.846, 111.225,
        125.068,  99.074, 108.751, 129.041,  88.929, 104.554, 109.690, 103.850,
         99.387, 110.256, 107.108, 118.001, 111.832, 116.327, 125.561, 106.410,
        109.636, 123.972, 118.825, 113.108, 119.276, 120.555, 114.937, 116.743,
        128.456, 124.781, 113.457, 115.078,  91.171, 117.710, 105.922, 116.988,
        113.361, 107.320, 119.680, 107.036, 124.130, 124.112, 110.993, 112.366,
        120.483, 108.160, 113.985, 113.684, 101.118,  98.860, 110.616, 114.643,
         97.562, 129.114, 122.000, 125.538, 121.003, 113.761,  86.693, 127.033],
       device='cuda:0')
clipping threshold 1.006451199552889
a after update for 1 param tensor([[[-0.102],
         [-0.238],
         [-0.040],
         [ 0.527],
         [-0.068],
         [-0.169],
         [ 0.184],
         [-0.206],
         [-0.049],
         [-0.283]],

        [[-0.089],
         [-0.138],
         [-0.288],
         [-0.395],
         [ 0.311],
         [ 0.245],
         [-0.148],
         [ 0.094],
         [ 0.081],
         [ 0.233]],

        [[ 0.045],
         [ 0.006],
         [ 0.021],
         [-0.337],
         [-0.010],
         [ 0.138],
         [ 0.224],
         [-0.025],
         [ 0.057],
         [-0.170]],

        [[ 0.068],
         [-0.141],
         [ 0.013],
         [ 0.014],
         [ 0.018],
         [ 0.033],
         [ 0.106],
         [-0.120],
         [-0.205],
         [-0.146]],

        [[-0.165],
         [ 0.509],
         [-0.123],
         [ 0.173],
         [-0.016],
         [ 0.161],
         [ 0.113],
         [-0.048],
         [-0.073],
         [-0.055]],

        [[ 0.036],
         [ 0.080],
         [-0.106],
         [ 0.059],
         [-0.527],
         [ 0.086],
         [-0.131],
         [-0.020],
         [ 0.132],
         [ 0.034]],

        [[-0.290],
         [-0.098],
         [ 0.022],
         [-0.028],
         [-0.141],
         [ 0.050],
         [ 0.196],
         [-0.177],
         [ 0.381],
         [-0.119]],

        [[ 0.178],
         [-0.117],
         [ 0.191],
         [ 0.018],
         [ 0.235],
         [ 0.042],
         [-0.079],
         [ 0.044],
         [-0.179],
         [-0.273]],

        [[-0.214],
         [ 0.248],
         [-0.141],
         [-0.066],
         [ 0.174],
         [ 0.016],
         [ 0.517],
         [-0.058],
         [ 0.005],
         [-0.091]],

        [[ 0.029],
         [-0.107],
         [ 0.203],
         [ 0.231],
         [ 0.018],
         [ 0.048],
         [ 0.093],
         [ 0.092],
         [-0.035],
         [ 0.147]],

        [[-0.197],
         [ 0.114],
         [-0.033],
         [-0.244],
         [-0.160],
         [ 0.130],
         [ 0.155],
         [ 0.342],
         [ 0.367],
         [-0.125]],

        [[ 0.029],
         [ 0.076],
         [-0.023],
         [ 0.106],
         [ 0.055],
         [ 0.144],
         [-0.568],
         [ 0.230],
         [-0.214],
         [ 0.003]],

        [[-0.201],
         [ 0.131],
         [-0.069],
         [ 0.163],
         [ 0.157],
         [-0.419],
         [ 0.001],
         [-0.099],
         [ 0.373],
         [-0.128]],

        [[-0.179],
         [ 0.091],
         [ 0.008],
         [-0.422],
         [ 0.085],
         [ 0.296],
         [-0.165],
         [-0.122],
         [ 0.169],
         [-0.180]],

        [[ 0.060],
         [-0.154],
         [ 0.182],
         [ 0.033],
         [ 0.269],
         [-0.005],
         [-0.350],
         [-0.038],
         [ 0.093],
         [ 0.392]],

        [[ 0.020],
         [ 0.082],
         [ 0.083],
         [ 0.105],
         [-0.248],
         [-0.517],
         [ 0.261],
         [ 0.013],
         [-0.061],
         [ 0.338]],

        [[-0.159],
         [ 0.037],
         [-0.149],
         [-0.004],
         [-0.191],
         [-0.039],
         [-0.151],
         [ 0.153],
         [-0.055],
         [-0.067]],

        [[-0.142],
         [ 0.301],
         [-0.155],
         [-0.055],
         [ 0.375],
         [ 0.191],
         [ 0.138],
         [ 0.352],
         [-0.091],
         [ 0.383]],

        [[ 0.215],
         [-0.110],
         [-0.089],
         [-0.134],
         [-0.163],
         [ 0.383],
         [ 0.171],
         [-0.090],
         [-0.061],
         [-0.058]],

        [[-0.197],
         [ 0.083],
         [ 0.044],
         [ 0.007],
         [ 0.571],
         [ 0.096],
         [ 0.005],
         [ 0.078],
         [ 0.071],
         [ 0.098]]], device='cuda:0')
s after update for 1 param tensor([[[1.866],
         [1.404],
         [1.842],
         [1.507],
         [1.699],
         [2.081],
         [2.118],
         [2.277],
         [2.047],
         [1.511]],

        [[1.541],
         [2.077],
         [1.766],
         [2.303],
         [1.391],
         [1.781],
         [1.791],
         [1.339],
         [1.696],
         [2.468]],

        [[2.124],
         [1.707],
         [1.856],
         [2.016],
         [1.052],
         [1.480],
         [1.760],
         [1.798],
         [1.784],
         [1.601]],

        [[1.752],
         [1.308],
         [1.824],
         [1.801],
         [1.574],
         [2.191],
         [1.372],
         [1.551],
         [1.707],
         [1.556]],

        [[2.206],
         [1.842],
         [1.550],
         [1.789],
         [1.866],
         [2.054],
         [1.936],
         [1.568],
         [2.138],
         [1.581]],

        [[1.947],
         [1.372],
         [1.954],
         [1.916],
         [2.339],
         [1.442],
         [1.411],
         [1.784],
         [1.584],
         [1.645]],

        [[1.064],
         [1.778],
         [0.932],
         [1.415],
         [1.701],
         [1.741],
         [1.851],
         [1.493],
         [1.535],
         [1.096]],

        [[2.337],
         [1.647],
         [1.499],
         [1.740],
         [2.096],
         [1.859],
         [1.387],
         [1.966],
         [1.791],
         [2.033]],

        [[1.031],
         [1.912],
         [1.880],
         [1.488],
         [2.256],
         [1.820],
         [1.866],
         [2.190],
         [1.169],
         [1.921]],

        [[1.286],
         [1.332],
         [1.619],
         [1.746],
         [1.902],
         [1.659],
         [2.048],
         [1.271],
         [1.711],
         [1.963]],

        [[2.135],
         [1.362],
         [2.227],
         [1.921],
         [1.675],
         [1.742],
         [1.482],
         [1.911],
         [2.018],
         [2.282]],

        [[1.465],
         [1.718],
         [1.736],
         [1.705],
         [2.101],
         [1.773],
         [1.702],
         [1.325],
         [1.801],
         [1.490]],

        [[2.200],
         [2.035],
         [1.664],
         [1.702],
         [2.042],
         [1.448],
         [1.124],
         [1.932],
         [1.935],
         [1.958]],

        [[1.500],
         [1.982],
         [1.823],
         [2.063],
         [1.740],
         [1.227],
         [1.924],
         [1.877],
         [1.577],
         [1.591]],

        [[1.511],
         [1.493],
         [1.782],
         [1.600],
         [2.099],
         [1.400],
         [1.285],
         [2.091],
         [2.259],
         [1.842]],

        [[1.520],
         [1.935],
         [1.773],
         [1.841],
         [2.194],
         [1.699],
         [1.876],
         [1.682],
         [1.680],
         [1.339]],

        [[1.492],
         [1.860],
         [1.732],
         [1.756],
         [2.120],
         [1.555],
         [1.539],
         [1.642],
         [2.206],
         [1.360]],

        [[1.995],
         [1.748],
         [1.621],
         [2.089],
         [2.013],
         [1.864],
         [1.258],
         [1.801],
         [1.746],
         [1.781]],

        [[1.784],
         [2.109],
         [2.110],
         [1.560],
         [1.616],
         [1.824],
         [1.652],
         [1.665],
         [1.762],
         [2.020]],

        [[1.753],
         [1.843],
         [2.241],
         [2.224],
         [2.207],
         [1.426],
         [2.031],
         [1.515],
         [1.644],
         [1.747]]], device='cuda:0')
b after update for 1 param tensor([[[119.749],
         [103.888],
         [118.977],
         [107.624],
         [114.291],
         [126.466],
         [127.597],
         [132.304],
         [125.439],
         [107.759]],

        [[108.834],
         [126.360],
         [116.518],
         [133.057],
         [103.405],
         [117.000],
         [117.335],
         [101.436],
         [114.183],
         [137.727]],

        [[127.790],
         [114.556],
         [119.446],
         [124.493],
         [ 89.938],
         [106.654],
         [116.308],
         [117.559],
         [117.105],
         [110.930]],

        [[116.050],
         [100.254],
         [118.419],
         [117.671],
         [110.002],
         [129.781],
         [102.694],
         [109.180],
         [114.560],
         [109.361]],

        [[130.211],
         [119.007],
         [109.165],
         [117.280],
         [119.780],
         [125.657],
         [121.994],
         [109.780],
         [128.197],
         [110.231]],

        [[122.341],
         [102.681],
         [122.558],
         [121.370],
         [134.091],
         [105.270],
         [104.157],
         [117.095],
         [110.329],
         [112.454]],

        [[ 90.431],
         [116.899],
         [ 84.624],
         [104.299],
         [114.358],
         [115.699],
         [119.277],
         [107.117],
         [108.636],
         [ 91.767]],

        [[134.017],
         [112.520],
         [107.355],
         [115.634],
         [126.928],
         [119.536],
         [103.272],
         [122.930],
         [117.340],
         [125.012]],

        [[ 89.005],
         [121.216],
         [120.220],
         [106.957],
         [131.693],
         [118.273],
         [119.762],
         [129.745],
         [ 94.774],
         [121.528]],

        [[ 99.411],
         [101.172],
         [111.565],
         [115.865],
         [120.915],
         [112.935],
         [125.467],
         [ 98.824],
         [114.666],
         [122.851]],

        [[128.099],
         [102.308],
         [130.848],
         [121.516],
         [113.462],
         [115.725],
         [106.748],
         [121.204],
         [124.543],
         [132.438]],

        [[106.105],
         [114.906],
         [115.502],
         [114.496],
         [127.079],
         [116.737],
         [114.382],
         [100.911],
         [117.655],
         [107.037]],

        [[130.040],
         [125.071],
         [113.110],
         [114.386],
         [125.277],
         [105.505],
         [ 92.950],
         [121.855],
         [121.944],
         [122.666]],

        [[107.365],
         [123.427],
         [118.374],
         [125.915],
         [115.644],
         [ 97.105],
         [121.607],
         [120.105],
         [110.112],
         [110.580]],

        [[107.754],
         [107.114],
         [117.025],
         [110.893],
         [127.033],
         [103.727],
         [ 99.379],
         [126.792],
         [131.764],
         [118.997]],

        [[108.082],
         [121.962],
         [116.728],
         [118.971],
         [129.855],
         [114.287],
         [120.074],
         [113.722],
         [113.651],
         [101.456]],

        [[107.099],
         [119.559],
         [115.397],
         [116.180],
         [127.651],
         [109.327],
         [108.777],
         [112.361],
         [130.228],
         [102.255]],

        [[123.842],
         [115.923],
         [111.617],
         [126.710],
         [124.388],
         [119.685],
         [ 98.324],
         [117.668],
         [115.845],
         [117.015]],

        [[117.112],
         [127.317],
         [127.340],
         [109.507],
         [111.450],
         [118.425],
         [112.690],
         [113.119],
         [116.380],
         [124.594]],

        [[116.093],
         [119.029],
         [131.255],
         [130.756],
         [130.245],
         [104.708],
         [124.948],
         [107.900],
         [112.416],
         [115.886]]], device='cuda:0')
clipping threshold 1.006451199552889
a after update for 1 param tensor([[ 0.031],
        [-0.066],
        [ 0.102],
        [-0.109],
        [ 0.111],
        [-0.199],
        [ 0.103],
        [-0.042],
        [-0.166],
        [-0.091],
        [ 0.005],
        [ 0.464],
        [ 0.112],
        [-0.046],
        [-0.300],
        [-0.148],
        [-0.138],
        [-0.045],
        [-0.421],
        [ 0.071]], device='cuda:0')
s after update for 1 param tensor([[2.228],
        [1.621],
        [1.114],
        [1.505],
        [1.954],
        [2.035],
        [1.439],
        [1.889],
        [1.796],
        [1.850],
        [1.941],
        [2.189],
        [1.732],
        [1.829],
        [2.121],
        [2.113],
        [2.052],
        [1.411],
        [1.589],
        [1.563]], device='cuda:0')
b after update for 1 param tensor([[130.876],
        [111.620],
        [ 92.546],
        [107.566],
        [122.554],
        [125.071],
        [105.188],
        [120.486],
        [117.489],
        [119.247],
        [122.138],
        [129.707],
        [115.378],
        [118.557],
        [127.683],
        [127.451],
        [125.579],
        [104.157],
        [110.533],
        [109.614]], device='cuda:0')
clipping threshold 1.006451199552889
||w||^2 1.1803362270909485
exp ma of ||w||^2 2.1166179735996202
||w|| 1.0864327991601452
exp ma of ||w|| 1.3772883707652295
||w||^2 2.334272470161288
exp ma of ||w||^2 1.937476690056057
||w|| 1.527832605412415
exp ma of ||w|| 1.340827685520735
v before min max tensor([[-106.535,   41.733,   95.347,  ...,  788.164,  223.335, -161.062],
        [-100.764,  433.741, -208.532,  ..., -176.001, -133.813, -181.445],
        [-119.436, -209.976,  755.148,  ..., -165.796,  -81.549,  -77.130],
        ...,
        [-171.289, -213.181, -125.013,  ..., -231.025, -103.981, -254.581],
        [  55.167,  525.945,  -97.644,  ...,  102.403,  -73.421,   28.164],
        [ 332.760, -184.937, -118.759,  ..., -108.771, -210.372,  -60.046]],
       device='cuda:0')
v tensor([[1.000e-12, 1.000e+01, 1.000e+01,  ..., 1.000e+01, 1.000e+01,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e-12,  ..., 1.000e+01, 1.000e-12,
         1.000e+01],
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([ 1.174e+02, -1.761e+02, -2.256e+02, -1.548e+02, -1.673e+02,  1.257e+02,
        -1.777e+02, -1.647e+02,  1.470e+02, -2.353e+02, -1.196e+02, -2.547e+02,
        -1.963e+01, -5.349e+01, -1.764e+02, -2.340e+02, -1.055e+02, -1.144e+02,
        -1.883e+02,  1.638e+02,  6.555e+02, -9.106e+01, -1.864e+02, -5.222e+01,
        -7.422e+01, -1.531e+02,  6.726e+01, -1.903e+02,  3.802e+03, -1.580e+02,
        -1.750e+02, -5.512e+01,  5.971e+02, -2.026e+02, -1.257e+02, -2.197e+02,
        -1.458e+02, -1.562e+02, -1.198e+02, -1.720e+02, -2.591e+02, -1.901e+02,
        -2.026e+02, -1.591e+02, -9.673e+01, -2.287e+02, -2.022e+02, -1.786e+02,
         3.549e+01,  2.515e+01, -3.267e+01, -2.202e+02,  1.036e+03, -1.150e+02,
        -1.776e+02, -8.793e+01, -1.529e+01, -1.862e+02, -1.612e+02, -8.147e+01,
        -8.895e+01,  1.228e+01, -1.665e+02,  3.491e+02, -9.906e+01, -2.016e+02,
        -1.832e+02,  2.519e+02, -5.175e+00, -1.983e+02, -1.878e+02, -1.103e+02,
        -2.040e+02,  2.397e+02, -1.411e+02, -1.353e+02,  3.824e+02, -1.670e+02,
         1.540e+02,  6.116e+01,  2.801e+01, -1.955e+02, -1.893e+00, -1.293e+02,
        -1.640e+02, -1.665e+02,  1.792e+02, -2.038e+02, -2.320e+02, -1.891e+02,
        -1.834e+02, -7.194e+01, -2.026e+02,  1.577e+02,  3.534e+02, -1.539e+02,
        -6.274e+01,  3.787e+02, -7.792e+01, -4.599e+01, -2.191e+02, -1.783e+02,
        -1.523e+02,  4.245e+02, -1.434e+02, -1.714e+01, -1.943e+02, -1.552e+01,
        -1.964e+02, -1.368e+02, -3.809e+01, -9.144e+01, -1.872e+02,  4.587e+02,
        -2.028e+02,  1.986e+02, -6.720e+01,  8.066e+01, -2.375e+02, -1.846e+02,
        -1.608e+02,  6.491e+01,  4.083e+02, -1.433e+02,  6.742e+02,  1.222e+02,
        -1.544e+02, -8.853e+01, -2.195e+02,  9.460e+01, -1.019e+02,  5.519e+01,
         2.314e+02, -1.293e+02, -7.608e+00, -1.569e+02, -2.168e+02,  3.311e+01,
         5.079e+01, -1.763e+02, -1.441e+02, -1.902e+02,  1.366e+02, -2.341e+02,
        -2.214e+02,  9.371e+01, -2.295e+02, -4.273e+01, -1.240e+02, -1.890e+02,
        -9.650e+01, -1.457e+02, -4.629e+01,  8.647e+02, -1.274e+02,  2.906e+02,
        -1.639e+02, -1.561e+02, -2.090e+02, -7.398e+01, -1.770e+02, -1.761e+02,
         1.960e+02, -1.279e+02,  7.315e+00, -1.597e+02, -1.495e+02,  3.089e+01,
        -6.737e+01, -1.635e+02, -2.187e+02, -1.306e+02,  5.125e+01, -1.071e+02,
        -1.139e+02,  1.243e+02, -1.892e+02, -1.494e+02, -5.387e+01,  4.885e+01,
         7.725e+01, -1.151e+02, -2.147e+02, -2.240e+01, -2.390e+02,  2.852e+02,
        -1.177e+02,  1.103e+03, -2.075e+02, -1.872e+02, -1.935e+02, -1.407e+02,
         2.183e+02, -1.691e+02, -2.076e+02, -1.752e+02, -2.299e+02, -2.139e+02,
        -2.170e+02, -2.683e+01], device='cuda:0')
v tensor([1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 7.315e+00, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12], device='cuda:0')
v before min max tensor([[[-2.475e+02],
         [-1.398e+02],
         [ 1.185e+02],
         [-1.663e+02],
         [-1.390e+02],
         [-2.174e+02],
         [-2.126e+02],
         [-1.221e+02],
         [-1.393e+01],
         [ 5.248e+01]],

        [[ 4.409e+01],
         [ 5.326e+02],
         [-1.289e+02],
         [-1.274e+02],
         [ 4.689e+02],
         [ 6.133e+02],
         [-2.290e+02],
         [-1.254e+02],
         [-1.670e+02],
         [ 3.362e+02]],

        [[ 1.203e+02],
         [-1.810e+02],
         [-2.122e+02],
         [ 3.530e+01],
         [ 5.564e+01],
         [-2.211e+02],
         [-3.441e+00],
         [ 2.362e+02],
         [-1.724e+02],
         [ 1.091e+02]],

        [[-1.637e+02],
         [-4.759e+01],
         [ 1.013e+02],
         [ 1.402e+02],
         [-2.503e+02],
         [-1.182e+02],
         [-1.856e+02],
         [-1.264e+02],
         [ 5.414e+02],
         [-1.817e+02]],

        [[-2.505e+02],
         [-1.969e+02],
         [-1.615e+02],
         [-2.052e+01],
         [-1.038e+02],
         [-1.373e+01],
         [-1.805e+02],
         [-1.628e+02],
         [-4.249e+01],
         [-1.421e+02]],

        [[-1.623e+02],
         [ 2.167e+02],
         [-1.031e+02],
         [ 1.276e+02],
         [-2.365e+02],
         [-1.585e+02],
         [-8.238e+01],
         [ 4.882e+02],
         [ 5.185e+02],
         [-1.235e+02]],

        [[ 1.775e+02],
         [-1.706e+02],
         [-4.700e+01],
         [ 2.969e+02],
         [-1.646e+02],
         [-1.672e+02],
         [-1.696e+02],
         [ 2.987e+02],
         [ 8.024e+00],
         [-1.212e+02]],

        [[ 1.501e+02],
         [ 2.236e+02],
         [ 4.318e+02],
         [-2.120e+02],
         [-2.012e+02],
         [ 2.581e+02],
         [ 2.869e+02],
         [ 1.746e+02],
         [ 3.298e+02],
         [-2.153e+02]],

        [[-1.790e+02],
         [-4.144e+01],
         [ 2.416e+02],
         [-1.376e+02],
         [ 5.866e+02],
         [-8.060e+01],
         [-1.020e+02],
         [-1.536e+02],
         [-1.442e+02],
         [-1.683e+02]],

        [[-1.978e+02],
         [-1.928e+02],
         [-1.108e+02],
         [ 7.054e-03],
         [-6.241e+01],
         [-8.357e+01],
         [-5.026e+01],
         [-2.145e+02],
         [ 3.656e+01],
         [-1.670e+02]],

        [[-1.823e+02],
         [-6.593e+01],
         [ 5.091e+01],
         [-1.135e+02],
         [-1.565e+02],
         [-1.291e+02],
         [-1.339e+02],
         [-2.145e+02],
         [-1.281e+02],
         [-1.899e+02]],

        [[-1.968e+02],
         [-1.402e+02],
         [-1.028e+02],
         [ 2.570e+02],
         [-9.317e+01],
         [ 1.999e+02],
         [-2.589e+02],
         [-2.146e+02],
         [-1.226e+01],
         [-4.875e+01]],

        [[ 6.739e+01],
         [-1.036e+02],
         [-7.469e+00],
         [-2.346e+02],
         [ 2.153e+02],
         [-1.418e+02],
         [-3.235e+00],
         [-1.085e+02],
         [-1.386e+02],
         [ 9.494e+00]],

        [[ 9.730e+01],
         [ 4.531e+02],
         [-2.151e+02],
         [ 4.854e+01],
         [ 9.021e+02],
         [-2.235e+02],
         [-1.661e+02],
         [ 4.922e+02],
         [-1.440e+02],
         [ 4.186e+02]],

        [[-1.156e+02],
         [-1.341e+02],
         [-2.094e+02],
         [-1.260e+02],
         [-1.746e+02],
         [-5.803e+01],
         [-7.055e+01],
         [ 5.272e+00],
         [ 6.628e+01],
         [-1.355e+02]],

        [[-9.267e+01],
         [ 6.154e+00],
         [-2.366e+01],
         [-2.082e+02],
         [-4.974e+01],
         [-1.517e+02],
         [-1.306e+02],
         [-1.840e+02],
         [-1.675e+02],
         [ 5.052e+02]],

        [[-1.601e+02],
         [-1.889e+02],
         [-1.919e+02],
         [-2.137e+02],
         [ 3.870e+00],
         [-7.795e+01],
         [-2.519e+02],
         [-1.596e+02],
         [ 4.914e+02],
         [-3.044e+01]],

        [[ 5.739e+01],
         [-2.068e+02],
         [-2.289e+02],
         [-1.249e+02],
         [-2.024e+02],
         [ 3.497e+02],
         [-1.955e+02],
         [-1.868e+02],
         [-1.148e+02],
         [-2.283e+02]],

        [[-1.994e+02],
         [ 1.730e+02],
         [-9.957e+01],
         [-1.443e+02],
         [-2.405e+01],
         [-1.164e+02],
         [ 1.455e+02],
         [-1.122e+02],
         [ 5.178e+01],
         [ 9.499e+01]],

        [[-5.318e+01],
         [-1.498e+02],
         [-1.444e+02],
         [-2.312e+02],
         [ 4.105e+02],
         [ 9.278e+01],
         [-1.240e+02],
         [-1.245e+02],
         [-1.237e+02],
         [-1.612e+02]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [8.024e+00],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.054e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [9.494e+00]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.272e+00],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [6.154e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.870e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[ -84.678],
        [ 250.575],
        [ 653.378],
        [-173.278],
        [-102.506],
        [-116.974],
        [ -54.485],
        [ -70.486],
        [-101.530],
        [-113.029],
        [ -71.131],
        [ -89.931],
        [ 382.693],
        [ -69.181],
        [ -72.828],
        [-261.233],
        [-161.987],
        [-241.095],
        [-114.125],
        [-222.356]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 0.012, -0.086, -0.381,  ..., -0.262,  0.115, -0.177],
        [-0.162, -0.330, -0.078,  ...,  0.232,  0.173,  0.107],
        [-0.026, -0.148,  0.042,  ..., -0.183,  0.133, -0.170],
        ...,
        [-0.107, -0.077, -0.054,  ...,  0.104,  0.135,  0.098],
        [ 0.044,  0.042,  0.159,  ..., -0.076, -0.009, -0.021],
        [-0.006, -0.079, -0.093,  ...,  0.019, -0.133, -0.088]],
       device='cuda:0')
s after update for 1 param tensor([[1.641, 1.314, 1.542,  ..., 2.341, 1.606, 1.549],
        [1.633, 1.706, 2.145,  ..., 1.987, 1.721, 2.073],
        [1.904, 1.973, 2.017,  ..., 1.364, 0.996, 1.319],
        ...,
        [1.362, 1.690, 1.586,  ..., 1.878, 1.457, 2.095],
        [1.960, 1.616, 1.630,  ..., 1.631, 1.273, 1.921],
        [2.288, 1.740, 1.611,  ..., 0.870, 1.654, 1.423]], device='cuda:0')
b after update for 1 param tensor([[110.010,  98.464, 106.632,  ..., 131.404, 108.848, 106.886],
        [109.736, 112.167, 125.788,  ..., 121.077, 112.678, 123.655],
        [118.496, 120.637, 121.959,  ..., 100.286,  85.708,  98.637],
        ...,
        [100.223, 111.664, 108.170,  ..., 117.684, 103.657, 124.318],
        [120.250, 109.162, 109.651,  ..., 109.688,  96.883, 119.019],
        [129.906, 113.291, 109.012,  ...,  80.114, 110.444, 102.444]],
       device='cuda:0')
clipping threshold 1.1153960137309957
a after update for 1 param tensor([-0.056,  0.039,  0.026, -0.089,  0.083, -0.204,  0.213,  0.100,  0.116,
         0.035, -0.065,  0.129,  0.267, -0.192,  0.205,  0.091,  0.154,  0.067,
        -0.058, -0.073,  0.116,  0.153, -0.155,  0.070,  0.102,  0.346, -0.126,
         0.074,  0.179,  0.060, -0.125, -0.170, -0.028, -0.125,  0.002, -0.242,
        -0.054, -0.039, -0.101, -0.060,  0.185,  0.033, -0.246, -0.024,  0.149,
        -0.197,  0.082,  0.144, -0.235,  0.079,  0.061,  0.185,  0.034, -0.221,
        -0.132,  0.138,  0.232, -0.038, -0.054, -0.241, -0.149,  0.132, -0.229,
        -0.252,  0.278, -0.130,  0.277,  0.097, -0.128,  0.033,  0.151, -0.440,
        -0.066, -0.036,  0.112,  0.004, -0.012,  0.161, -0.088,  0.200,  0.167,
        -0.134,  0.037,  0.346, -0.259, -0.065,  0.050, -0.021,  0.129, -0.116,
        -0.189,  0.067, -0.282,  0.069, -0.018,  0.128, -0.171, -0.173, -0.058,
        -0.240, -0.182,  0.171, -0.176,  0.084, -0.043, -0.024, -0.174,  0.001,
        -0.046,  0.395, -0.222,  0.016, -0.230, -0.128,  0.125, -0.065,  0.307,
        -0.081,  0.078, -0.243,  0.077,  0.018,  0.010,  0.038,  0.020, -0.071,
         0.483,  0.028,  0.018, -0.043, -0.023,  0.055, -0.095,  0.114, -0.008,
        -0.044, -0.056, -0.163,  0.394,  0.206,  0.143,  0.010,  0.212,  0.057,
         0.040, -0.005, -0.142,  0.099,  0.005,  0.093,  0.055,  0.095, -0.382,
         0.044, -0.134,  0.088,  0.119, -0.164,  0.163,  0.141,  0.172,  0.139,
         0.326, -0.088,  0.021,  0.152,  0.065,  0.105,  0.170,  0.043, -0.338,
         0.197,  0.139, -0.034,  0.230,  0.193, -0.076,  0.300, -0.167,  0.045,
         0.334,  0.185,  0.063,  0.198,  0.104,  0.073, -0.007,  0.015, -0.047,
        -0.184, -0.116,  0.397,  0.177, -0.233, -0.283, -0.114, -0.077,  0.056,
        -0.085,  0.183], device='cuda:0')
s after update for 1 param tensor([1.739, 1.644, 1.778, 1.453, 1.315, 1.592, 1.820, 2.160, 1.679, 1.859,
        1.081, 2.020, 2.090, 1.312, 1.457, 2.073, 1.892, 1.571, 1.959, 1.771,
        1.938, 1.519, 1.556, 2.041, 1.222, 1.771, 1.826, 1.516, 2.080, 1.726,
        1.433, 1.285, 1.872, 1.855, 1.940, 1.797, 1.232, 1.307, 1.726, 1.435,
        2.048, 1.798, 1.652, 1.653, 1.148, 1.819, 1.787, 1.519, 1.463, 1.809,
        1.323, 1.808, 2.068, 1.473, 1.398, 1.427, 1.701, 1.465, 1.269, 1.097,
        1.562, 1.751, 1.309, 1.946, 1.525, 1.739, 1.522, 2.323, 1.157, 1.973,
        1.616, 1.838, 1.616, 1.835, 1.585, 1.094, 1.517, 1.929, 2.341, 2.140,
        1.835, 1.831, 1.749, 1.584, 1.747, 1.617, 2.112, 1.609, 1.908, 1.647,
        1.477, 0.890, 1.739, 1.896, 1.886, 1.396, 1.872, 1.825, 1.567, 1.311,
        2.044, 1.573, 1.697, 1.806, 1.752, 1.370, 1.728, 1.607, 1.546, 1.999,
        1.088, 1.514, 2.005, 2.076, 1.787, 1.702, 1.627, 2.232, 1.925, 1.572,
        1.368, 1.512, 1.800, 1.286, 2.042, 1.903, 1.405, 2.020, 1.736, 1.936,
        1.258, 2.050, 1.563, 1.892, 1.484, 1.546, 1.704, 2.238, 2.015, 1.733,
        1.633, 1.522, 1.504, 2.446, 1.986, 2.117, 1.915, 1.689, 1.109, 1.772,
        1.331, 1.238, 1.718, 2.176, 1.660, 1.687, 1.329, 1.312, 2.071, 1.782,
        1.498, 1.449, 2.110, 1.242, 1.401, 1.545, 1.305, 1.923, 1.740, 1.474,
        1.905, 1.307, 1.578, 1.098, 1.325, 1.994, 1.848, 1.540, 1.477, 1.682,
        2.119, 2.117, 1.699, 1.911, 1.911, 2.088, 1.097, 1.838, 1.639, 1.505,
        1.680, 1.712, 1.787, 1.447, 1.658, 1.383, 1.809, 1.684, 1.756, 1.134],
       device='cuda:0')
b after update for 1 param tensor([113.259, 110.132, 114.506, 103.512,  98.488, 108.355, 115.848, 126.236,
        111.300, 117.093,  89.285, 122.050, 124.146,  98.359, 103.674, 123.665,
        118.148, 107.631, 120.204, 114.295, 119.552, 105.852, 107.147, 122.682,
         94.921, 114.285, 116.069, 105.728, 123.870, 112.831, 102.800,  97.337,
        117.496, 116.973, 119.636, 115.115,  95.344,  98.186, 112.830, 102.877,
        122.899, 115.159, 110.380, 110.413,  92.034, 115.828, 114.817, 105.837,
        103.873, 115.523,  98.775, 115.490, 123.517, 104.229, 101.552, 102.611,
        112.011, 103.956,  96.744,  89.955, 107.341, 113.655,  98.266, 119.819,
        106.071, 113.271, 105.952, 130.906,  92.397, 120.640, 109.187, 116.440,
        109.164, 116.348, 108.141,  89.812, 105.766, 119.269, 131.409, 125.625,
        116.335, 116.227, 113.575, 108.085, 113.518, 109.217, 124.823, 108.936,
        118.631, 110.227, 104.367,  81.001, 113.240, 118.264, 117.930, 101.488,
        117.516, 116.023, 107.493,  98.338, 122.791, 107.730, 111.869, 115.430,
        113.688, 100.536, 112.908, 108.868, 106.790, 121.413,  89.598, 105.677,
        121.621, 123.750, 114.814, 112.043, 109.535, 128.304, 119.144, 107.682,
        100.460, 105.612, 115.234,  97.392, 122.717, 118.489, 101.786, 122.073,
        113.160, 119.502,  96.314, 122.967, 107.366, 118.127, 104.621, 106.797,
        112.100, 128.485, 121.905, 113.067, 109.743, 105.951, 105.339, 134.331,
        121.045, 124.961, 118.839, 111.609,  90.445, 114.332,  99.091,  95.576,
        112.565, 126.680, 110.643, 111.558,  99.023,  98.357, 123.599, 114.657,
        105.107, 103.376, 124.738,  95.704, 101.645, 106.763,  98.095, 119.085,
        113.299, 104.272, 118.532,  98.186, 107.882,  90.001,  98.873, 121.287,
        116.764, 106.582, 104.359, 111.375, 125.004, 124.963, 111.953, 118.729,
        118.724, 124.104,  89.966, 116.419, 109.953, 105.358, 111.304, 112.366,
        114.806, 103.314, 110.578, 100.991, 115.511, 111.434, 113.793,  91.464],
       device='cuda:0')
clipping threshold 1.1153960137309957
a after update for 1 param tensor([[[-0.187],
         [-0.198],
         [-0.030],
         [ 0.485],
         [-0.185],
         [-0.195],
         [ 0.126],
         [-0.250],
         [ 0.020],
         [-0.156]],

        [[-0.123],
         [-0.113],
         [-0.266],
         [-0.387],
         [ 0.240],
         [ 0.080],
         [-0.084],
         [ 0.056],
         [ 0.032],
         [ 0.174]],

        [[ 0.065],
         [-0.007],
         [ 0.020],
         [-0.363],
         [-0.067],
         [ 0.205],
         [ 0.194],
         [ 0.049],
         [ 0.121],
         [-0.088]],

        [[ 0.169],
         [ 0.031],
         [ 0.002],
         [-0.056],
         [-0.015],
         [ 0.109],
         [-0.163],
         [-0.157],
         [-0.169],
         [-0.126]],

        [[-0.093],
         [ 0.453],
         [-0.245],
         [-0.031],
         [-0.017],
         [ 0.278],
         [ 0.084],
         [-0.141],
         [-0.090],
         [-0.031]],

        [[ 0.016],
         [ 0.092],
         [-0.076],
         [ 0.113],
         [-0.527],
         [ 0.265],
         [-0.143],
         [ 0.096],
         [ 0.059],
         [-0.119]],

        [[-0.243],
         [ 0.023],
         [ 0.174],
         [ 0.064],
         [-0.141],
         [ 0.089],
         [ 0.270],
         [-0.054],
         [ 0.224],
         [-0.065]],

        [[ 0.201],
         [-0.158],
         [ 0.178],
         [ 0.114],
         [ 0.146],
         [ 0.009],
         [ 0.079],
         [ 0.051],
         [-0.035],
         [-0.242]],

        [[-0.084],
         [ 0.236],
         [-0.091],
         [-0.070],
         [ 0.110],
         [ 0.128],
         [ 0.511],
         [ 0.029],
         [ 0.096],
         [-0.207]],

        [[ 0.043],
         [-0.103],
         [ 0.141],
         [ 0.213],
         [ 0.080],
         [ 0.116],
         [ 0.047],
         [ 0.175],
         [-0.060],
         [ 0.111]],

        [[-0.112],
         [ 0.166],
         [-0.010],
         [-0.304],
         [-0.131],
         [ 0.089],
         [ 0.246],
         [ 0.214],
         [ 0.189],
         [ 0.069]],

        [[-0.112],
         [ 0.180],
         [-0.024],
         [ 0.066],
         [ 0.050],
         [ 0.233],
         [-0.448],
         [ 0.300],
         [-0.123],
         [ 0.011]],

        [[-0.069],
         [ 0.072],
         [ 0.031],
         [ 0.216],
         [ 0.127],
         [-0.417],
         [-0.053],
         [-0.011],
         [ 0.451],
         [-0.111]],

        [[-0.205],
         [ 0.105],
         [ 0.083],
         [-0.271],
         [ 0.050],
         [ 0.102],
         [-0.047],
         [-0.158],
         [ 0.132],
         [-0.083]],

        [[ 0.085],
         [-0.116],
         [ 0.182],
         [ 0.048],
         [ 0.282],
         [-0.023],
         [-0.288],
         [-0.078],
         [ 0.020],
         [ 0.321]],

        [[-0.001],
         [ 0.144],
         [ 0.049],
         [ 0.069],
         [-0.268],
         [-0.415],
         [ 0.169],
         [ 0.025],
         [-0.020],
         [ 0.293]],

        [[-0.164],
         [ 0.080],
         [-0.103],
         [-0.054],
         [-0.108],
         [ 0.081],
         [-0.209],
         [ 0.228],
         [-0.196],
         [-0.123]],

        [[-0.035],
         [ 0.379],
         [-0.166],
         [ 0.227],
         [ 0.304],
         [-0.011],
         [ 0.156],
         [ 0.321],
         [-0.056],
         [ 0.324]],

        [[ 0.166],
         [ 0.002],
         [-0.013],
         [-0.137],
         [-0.103],
         [ 0.241],
         [ 0.159],
         [-0.155],
         [ 0.099],
         [-0.011]],

        [[-0.124],
         [ 0.019],
         [ 0.086],
         [ 0.117],
         [ 0.414],
         [ 0.116],
         [ 0.087],
         [ 0.141],
         [-0.035],
         [ 0.159]]], device='cuda:0')
s after update for 1 param tensor([[[1.946],
         [1.110],
         [1.890],
         [1.352],
         [1.475],
         [1.718],
         [1.723],
         [1.415],
         [1.316],
         [2.003]],

        [[1.892],
         [2.062],
         [1.015],
         [1.263],
         [1.644],
         [2.325],
         [2.023],
         [1.153],
         [1.749],
         [1.966]],

        [[1.735],
         [1.487],
         [2.117],
         [1.587],
         [1.803],
         [1.765],
         [1.608],
         [1.892],
         [1.664],
         [1.689]],

        [[1.577],
         [1.947],
         [1.726],
         [1.840],
         [1.972],
         [1.750],
         [2.323],
         [1.422],
         [2.214],
         [1.728]],

        [[2.022],
         [2.033],
         [1.677],
         [1.927],
         [1.522],
         [1.510],
         [1.610],
         [1.688],
         [1.663],
         [1.169]],

        [[1.465],
         [1.817],
         [1.497],
         [1.787],
         [1.912],
         [1.618],
         [1.408],
         [1.987],
         [1.891],
         [1.545]],

        [[2.168],
         [1.494],
         [1.146],
         [1.704],
         [1.369],
         [1.741],
         [1.747],
         [1.416],
         [1.972],
         [1.450]],

        [[1.758],
         [1.924],
         [1.846],
         [1.679],
         [1.582],
         [1.594],
         [2.083],
         [2.408],
         [1.740],
         [1.718]],

        [[1.506],
         [1.784],
         [1.917],
         [2.028],
         [1.738],
         [1.508],
         [1.432],
         [1.416],
         [1.682],
         [1.324]],

        [[1.571],
         [1.674],
         [1.210],
         [1.808],
         [1.574],
         [1.137],
         [0.694],
         [1.761],
         [1.479],
         [1.722]],

        [[1.959],
         [1.269],
         [1.983],
         [1.029],
         [1.856],
         [1.442],
         [1.630],
         [1.820],
         [1.564],
         [1.570]],

        [[1.702],
         [1.192],
         [1.395],
         [1.744],
         [0.944],
         [1.865],
         [2.071],
         [1.741],
         [1.232],
         [1.285]],

        [[1.911],
         [1.915],
         [1.097],
         [1.971],
         [2.059],
         [1.129],
         [1.168],
         [1.392],
         [1.108],
         [1.983]],

        [[1.374],
         [1.920],
         [1.897],
         [1.834],
         [1.906],
         [1.810],
         [1.547],
         [1.724],
         [1.902],
         [2.059]],

        [[0.951],
         [1.261],
         [1.692],
         [1.389],
         [1.434],
         [1.098],
         [1.612],
         [1.561],
         [1.999],
         [1.569]],

        [[1.233],
         [1.924],
         [1.648],
         [1.665],
         [1.627],
         [1.334],
         [1.882],
         [1.792],
         [1.574],
         [2.014]],

        [[1.296],
         [1.491],
         [1.728],
         [1.881],
         [1.884],
         [1.419],
         [2.045],
         [1.826],
         [2.058],
         [1.613]],

        [[1.744],
         [1.673],
         [1.841],
         [1.970],
         [1.879],
         [2.258],
         [1.597],
         [1.471],
         [1.010],
         [1.826]],

        [[1.619],
         [1.836],
         [1.851],
         [1.752],
         [1.666],
         [1.624],
         [1.972],
         [1.280],
         [1.608],
         [1.758]],

        [[1.480],
         [1.667],
         [1.387],
         [1.843],
         [1.788],
         [2.104],
         [1.809],
         [1.942],
         [1.038],
         [1.343]]], device='cuda:0')
b after update for 1 param tensor([[[119.809],
         [ 90.467],
         [118.057],
         [ 99.848],
         [104.308],
         [112.571],
         [112.726],
         [102.173],
         [ 98.525],
         [121.556]],

        [[118.122],
         [123.317],
         [ 86.539],
         [ 96.537],
         [110.124],
         [130.940],
         [122.140],
         [ 92.205],
         [113.590],
         [120.414]],

        [[113.122],
         [104.741],
         [124.952],
         [108.202],
         [115.317],
         [114.109],
         [108.903],
         [118.133],
         [110.793],
         [111.607]],

        [[107.847],
         [119.848],
         [112.829],
         [116.502],
         [120.613],
         [113.624],
         [130.896],
         [102.420],
         [127.777],
         [112.903]],

        [[122.120],
         [122.462],
         [111.205],
         [119.219],
         [105.971],
         [105.527],
         [108.986],
         [111.570],
         [110.766],
         [ 92.856]],

        [[103.950],
         [115.774],
         [105.067],
         [114.802],
         [118.750],
         [109.258],
         [101.899],
         [121.051],
         [118.092],
         [106.760]],

        [[126.464],
         [104.990],
         [ 91.953],
         [112.126],
         [100.481],
         [113.327],
         [113.516],
         [102.180],
         [120.619],
         [103.415]],

        [[113.872],
         [119.116],
         [116.678],
         [111.295],
         [108.010],
         [108.442],
         [123.940],
         [133.275],
         [113.283],
         [112.572]],

        [[105.398],
         [114.705],
         [118.914],
         [122.312],
         [113.218],
         [105.472],
         [102.762],
         [102.200],
         [111.381],
         [ 98.807]],

        [[107.654],
         [111.113],
         [ 94.466],
         [115.469],
         [107.765],
         [ 91.588],
         [ 71.528],
         [113.961],
         [104.439],
         [112.689]],

        [[120.205],
         [ 96.731],
         [120.947],
         [ 87.115],
         [117.007],
         [103.145],
         [109.632],
         [115.868],
         [107.417],
         [107.626]],

        [[112.040],
         [ 93.768],
         [101.444],
         [113.417],
         [ 83.455],
         [117.271],
         [123.602],
         [113.329],
         [ 95.322],
         [ 97.358]],

        [[118.728],
         [118.834],
         [ 89.971],
         [120.568],
         [123.242],
         [ 91.266],
         [ 92.836],
         [101.343],
         [ 90.412],
         [120.941]],

        [[100.679],
         [118.998],
         [118.287],
         [116.322],
         [118.573],
         [115.552],
         [106.829],
         [112.778],
         [118.442],
         [123.243]],

        [[ 83.748],
         [ 96.423],
         [111.730],
         [101.204],
         [102.846],
         [ 89.984],
         [109.034],
         [107.301],
         [121.441],
         [107.576]],

        [[ 95.381],
         [119.135],
         [110.260],
         [110.813],
         [109.559],
         [ 99.176],
         [117.825],
         [114.961],
         [107.734],
         [121.886]],

        [[ 97.767],
         [104.864],
         [112.906],
         [117.786],
         [117.876],
         [102.311],
         [122.810],
         [116.042],
         [123.201],
         [109.066]],

        [[113.414],
         [111.095],
         [116.522],
         [120.536],
         [117.741],
         [129.067],
         [108.519],
         [104.150],
         [ 86.331],
         [116.056]],

        [[109.275],
         [116.377],
         [116.832],
         [113.693],
         [110.866],
         [109.451],
         [120.615],
         [ 97.167],
         [108.907],
         [113.874]],

        [[104.484],
         [110.878],
         [101.147],
         [116.604],
         [114.831],
         [124.581],
         [115.521],
         [119.689],
         [ 87.508],
         [ 99.514]]], device='cuda:0')
clipping threshold 1.1153960137309957
a after update for 1 param tensor([[ 0.121],
        [-0.106],
        [ 0.107],
        [-0.135],
        [-0.041],
        [-0.128],
        [ 0.174],
        [-0.047],
        [-0.093],
        [ 0.050],
        [ 0.019],
        [ 0.290],
        [ 0.113],
        [ 0.049],
        [-0.201],
        [-0.104],
        [-0.273],
        [-0.038],
        [-0.457],
        [-0.020]], device='cuda:0')
s after update for 1 param tensor([[1.807],
        [1.914],
        [1.791],
        [1.561],
        [1.083],
        [1.821],
        [1.911],
        [1.144],
        [1.659],
        [1.636],
        [0.885],
        [1.833],
        [2.342],
        [1.516],
        [1.164],
        [2.241],
        [1.378],
        [2.076],
        [1.990],
        [1.986]], device='cuda:0')
b after update for 1 param tensor([[115.447],
        [118.820],
        [114.952],
        [107.288],
        [ 89.368],
        [115.902],
        [118.711],
        [ 91.852],
        [110.609],
        [109.837],
        [ 80.781],
        [116.279],
        [131.436],
        [105.751],
        [ 92.675],
        [128.569],
        [100.802],
        [123.755],
        [121.138],
        [121.028]], device='cuda:0')
clipping threshold 1.1153960137309957
||w||^2 1.9646515925544736
exp ma of ||w||^2 2.1321960776107365
||w|| 1.4016602985582753
exp ma of ||w|| 1.395578839507805
||w||^2 0.7417555630183698
exp ma of ||w||^2 2.021089193581873
||w|| 0.8612523225039046
exp ma of ||w|| 1.357593439388618
||w||^2 1.189800680484414
exp ma of ||w||^2 1.8979315965119694
||w|| 1.0907798496875591
exp ma of ||w|| 1.3245639484822866
||w||^2 2.608389553272561
exp ma of ||w||^2 1.7973587585437578
||w|| 1.6150509444821117
exp ma of ||w|| 1.289223942233798
||w||^2 1.46904035073864
exp ma of ||w||^2 1.8451971966403076
||w|| 1.212039748002779
exp ma of ||w|| 1.3053524755325139
||w||^2 1.8233918535893072
exp ma of ||w||^2 2.021621435582885
||w|| 1.3503302757434223
exp ma of ||w|| 1.3718429173969926
||w||^2 1.1888643703356723
exp ma of ||w||^2 2.039521889110096
||w|| 1.0903505722177946
exp ma of ||w|| 1.3757075374938512
cuda
Objective function 41.11 = squared loss an data 29.94 + 0.5*rho*h**2 5.571841 + alpha*h 3.581671 + L2reg 1.78 + L1reg 0.24 ; SHD = 91 ; DAG False
Proportion of microbatches that were clipped  0.7734833266372036
iteration 2 in inner loop, alpha 3.3929022201207317 rho 10.0 h 1.0556363707754173
4420
cuda
Objective function 91.26 = squared loss an data 29.94 + 0.5*rho*h**2 55.718407 + alpha*h 3.581671 + L2reg 1.78 + L1reg 0.24 ; SHD = 91 ; DAG False
||w||^2 16129928.292040437
exp ma of ||w||^2 6942461922.566463
||w|| 4016.2081982935642
exp ma of ||w|| 34293.00750153327
||w||^2 1.5238831157028798
exp ma of ||w||^2 43.574103995991145
||w|| 1.234456607460497
exp ma of ||w|| 1.69621767413215
||w||^2 2.576635866413044
exp ma of ||w||^2 2.958539948639016
||w|| 1.605190289782817
exp ma of ||w|| 1.6490264091404707
||w||^2 4.957846468973849
exp ma of ||w||^2 2.6989681132967926
||w|| 2.226622210653134
exp ma of ||w|| 1.5842776813322226
||w||^2 2.0315006444649035
exp ma of ||w||^2 2.981309055970502
||w|| 1.4253072105566937
exp ma of ||w|| 1.6529647208602793
||w||^2 2.975993681576405
exp ma of ||w||^2 3.0538280271685707
||w|| 1.725106860915116
exp ma of ||w|| 1.6680836488306137
||w||^2 3.0682125224109984
exp ma of ||w||^2 2.8817369321231308
||w|| 1.7516313888518322
exp ma of ||w|| 1.6230817036715375
||w||^2 2.1237873623412273
exp ma of ||w||^2 3.1171033829457393
||w|| 1.4573219830707376
exp ma of ||w|| 1.7025137886549273
cuda
Objective function 45.28 = squared loss an data 34.08 + 0.5*rho*h**2 7.702098 + alpha*h 1.331652 + L2reg 1.96 + L1reg 0.21 ; SHD = 83 ; DAG False
Proportion of microbatches that were clipped  0.7760103879240383
iteration 3 in inner loop, alpha 3.3929022201207317 rho 100.0 h 0.39248179370594016
iteration 2 in outer loop, alpha = 42.64108159071475, rho = 100.0, h = 0.39248179370594016
cuda
4420
cuda
Objective function 60.68 = squared loss an data 34.08 + 0.5*rho*h**2 7.702098 + alpha*h 16.735848 + L2reg 1.96 + L1reg 0.21 ; SHD = 83 ; DAG False
||w||^2 3852585237.3284826
exp ma of ||w||^2 70198648112.7834
||w|| 62069.19717000118
exp ma of ||w|| 192070.1483205202
||w||^2 35729.09409348995
exp ma of ||w||^2 733885670.2512995
||w|| 189.02141173287737
exp ma of ||w|| 4661.079394693252
||w||^2 8.455475524252458
exp ma of ||w||^2 1134325.7673359301
||w|| 2.9078300370297536
exp ma of ||w|| 11.236422509863942
||w||^2 2.545776321446171
exp ma of ||w||^2 64683.68228833574
||w|| 1.595548909136342
exp ma of ||w|| 2.508881713898753
||w||^2 1.7983004994617142
exp ma of ||w||^2 3.8190378557864375
||w|| 1.3410072704731002
exp ma of ||w|| 1.8431300068578984
||w||^2 5.0909661773342565
exp ma of ||w||^2 3.549948944377265
||w|| 2.256316949662493
exp ma of ||w|| 1.8199765606332845
||w||^2 2.8218548361694813
exp ma of ||w||^2 3.3266042901032065
||w|| 1.6798377410242578
exp ma of ||w|| 1.7636943063416735
||w||^2 5.913768405093948
exp ma of ||w||^2 3.219331052821325
||w|| 2.4318240900801085
exp ma of ||w|| 1.73542265496348
||w||^2 1.0769755296359282
exp ma of ||w||^2 3.363153345165021
||w|| 1.0377743153672325
exp ma of ||w|| 1.7663565915158221
||w||^2 3.4316202857942555
exp ma of ||w||^2 3.3336593829186105
||w|| 1.8524633021450805
exp ma of ||w|| 1.7630248734993705
||w||^2 7.833525279300087
exp ma of ||w||^2 3.6656798268925668
||w|| 2.798843561062334
exp ma of ||w|| 1.8505952144370428
||w||^2 5.633444719282145
exp ma of ||w||^2 3.709750213185545
||w|| 2.3734878805846353
exp ma of ||w|| 1.8564173141111067
||w||^2 4.218294060577911
exp ma of ||w||^2 3.6615533242026332
||w|| 2.0538485972870326
exp ma of ||w|| 1.8455377600803893
||w||^2 3.813179586573003
exp ma of ||w||^2 3.873676590505424
||w|| 1.952736435511204
exp ma of ||w|| 1.8739580263297115
||w||^2 2.864574192416772
exp ma of ||w||^2 3.1160374047140844
||w|| 1.6925053005579545
exp ma of ||w|| 1.7001359870118722
cuda
Objective function 51.96 = squared loss an data 35.64 + 0.5*rho*h**2 3.211699 + alpha*h 10.807136 + L2reg 2.11 + L1reg 0.20 ; SHD = 81 ; DAG True
Proportion of microbatches that were clipped  0.774154393914873
iteration 1 in inner loop, alpha 42.64108159071475 rho 100.0 h 0.25344421861234423
4420
cuda
Objective function 80.86 = squared loss an data 35.64 + 0.5*rho*h**2 32.116986 + alpha*h 10.807136 + L2reg 2.11 + L1reg 0.20 ; SHD = 81 ; DAG True
||w||^2 3.655729872907961
exp ma of ||w||^2 1509626.6359443336
||w|| 1.911996305673199
exp ma of ||w|| 11.956249630700441
||w||^2 4.82764212861052
exp ma of ||w||^2 13824.733335047307
||w|| 2.197189597784069
exp ma of ||w|| 2.226091574458473
||w||^2 2.629426199487891
exp ma of ||w||^2 3.957197420571233
||w|| 1.6215505540956443
exp ma of ||w|| 1.9131417726080018
||w||^2 2.4474392748879894
exp ma of ||w||^2 3.993113469066242
||w|| 1.564429376765851
exp ma of ||w|| 1.9179554302185449
||w||^2 4.875408336116345
exp ma of ||w||^2 4.153638120836421
||w|| 2.2080326845670433
exp ma of ||w|| 1.981201235878144
||w||^2 1.9151169920775986
exp ma of ||w||^2 4.290896334910474
||w|| 1.3838775206200866
exp ma of ||w|| 1.9884754575738808
cuda
Objective function 52.56 = squared loss an data 37.16 + 0.5*rho*h**2 7.695837 + alpha*h 5.290188 + L2reg 2.23 + L1reg 0.18 ; SHD = 76 ; DAG True
Proportion of microbatches that were clipped  0.7798457011055436
iteration 2 in inner loop, alpha 42.64108159071475 rho 1000.0 h 0.12406318318361897
4420
cuda
Objective function 121.82 = squared loss an data 37.16 + 0.5*rho*h**2 76.958367 + alpha*h 5.290188 + L2reg 2.23 + L1reg 0.18 ; SHD = 76 ; DAG True
||w||^2 1792044121527.494
exp ma of ||w||^2 1781059204936.9033
||w|| 1338672.522138067
exp ma of ||w|| 830592.2722521669
||w||^2 11074832368.996675
exp ma of ||w||^2 193288300440.33606
||w|| 105237.02945730023
exp ma of ||w|| 268813.65038526803
||w||^2 3591.895452803125
exp ma of ||w||^2 696956546.1250763
||w|| 59.932424052453655
exp ma of ||w|| 2030.1253048062515
||w||^2 6.458046915781649
exp ma of ||w||^2 197079.77809925197
||w|| 2.541268761028957
exp ma of ||w|| 3.5439439991923334
||w||^2 11.686303413273155
exp ma of ||w||^2 5.731188645177465
||w|| 3.418523572139463
exp ma of ||w|| 2.3002283626270636
||w||^2 2.9931869090210252
exp ma of ||w||^2 5.192797952508676
||w|| 1.7300829196951877
exp ma of ||w|| 2.2099248083772327
||w||^2 5.553352597848373
exp ma of ||w||^2 5.062368195039978
||w|| 2.3565552397192757
exp ma of ||w|| 2.1915410786710416
||w||^2 3.6301634514100796
exp ma of ||w||^2 4.801851570180625
||w|| 1.9052987827136403
exp ma of ||w|| 2.1352994087333323
||w||^2 9.129668147116686
exp ma of ||w||^2 4.727320267400232
||w|| 3.0215340718113186
exp ma of ||w|| 2.1041203177116685
||w||^2 3.9687479183592647
exp ma of ||w||^2 4.913628855562317
||w|| 1.9921716588585594
exp ma of ||w|| 2.1680939388274627
||w||^2 4.557905650440618
exp ma of ||w||^2 4.906289930164906
||w|| 2.134925209566044
exp ma of ||w|| 2.1644787059409847
||w||^2 9.44152201511643
exp ma of ||w||^2 4.477478324239192
||w|| 3.0727059760277147
exp ma of ||w|| 2.056470434094015
cuda
Objective function 52.06 = squared loss an data 38.45 + 0.5*rho*h**2 9.228985 + alpha*h 1.831978 + L2reg 2.38 + L1reg 0.17 ; SHD = 81 ; DAG True
Proportion of microbatches that were clipped  0.7810830209745594
iteration 3 in inner loop, alpha 42.64108159071475 rho 10000.0 h 0.042962739374345915
iteration 3 in outer loop, alpha = 472.2684753341739, rho = 10000.0, h = 0.042962739374345915
cuda
4420
cuda
Objective function 70.52 = squared loss an data 38.45 + 0.5*rho*h**2 9.228985 + alpha*h 20.289947 + L2reg 2.38 + L1reg 0.17 ; SHD = 81 ; DAG True
||w||^2 8.572097540047729
exp ma of ||w||^2 88313.08560575912
||w|| 2.9278144647582653
exp ma of ||w|| 3.141223886375427
||w||^2 27.049922854232026
exp ma of ||w||^2 558.1218434770287
||w|| 5.20095403308201
exp ma of ||w|| 2.467831281077131
||w||^2 7.976111944188754
exp ma of ||w||^2 7.012129493343555
||w|| 2.824201116101464
exp ma of ||w|| 2.282061399578261
||w||^2 3.6538386791742816
exp ma of ||w||^2 4.913444904249395
||w|| 1.911501681708463
exp ma of ||w|| 2.165822739841609
||w||^2 2.1941279710957415
exp ma of ||w||^2 5.057888678417606
||w|| 1.4812589142670978
exp ma of ||w|| 2.1958964780585735
||w||^2 3.982788676084213
exp ma of ||w||^2 5.059935293431349
||w|| 1.995692530447567
exp ma of ||w|| 2.1937597747298074
||w||^2 3.348600050044421
exp ma of ||w||^2 5.301666146108312
||w|| 1.829918044625065
exp ma of ||w|| 2.2273673173316686
||w||^2 2.6074822836915432
exp ma of ||w||^2 4.851441801284927
||w|| 1.6147700404985048
exp ma of ||w|| 2.1352911743622958
||w||^2 6.188800795665972
exp ma of ||w||^2 4.884935046618184
||w|| 2.487730048792668
exp ma of ||w|| 2.1502000900183282
||w||^2 3.733440137133805
exp ma of ||w||^2 5.0379795118711375
||w|| 1.932211204070043
exp ma of ||w|| 2.187628535580662
||w||^2 5.974937291153898
exp ma of ||w||^2 5.051477027206938
||w|| 2.444368485141694
exp ma of ||w|| 2.2053773297002213
||w||^2 8.439520477912229
exp ma of ||w||^2 4.889473192640358
||w|| 2.905085278939713
exp ma of ||w|| 2.1655267689341446
cuda
Objective function 57.91 = squared loss an data 38.60 + 0.5*rho*h**2 3.739526 + alpha*h 12.915530 + L2reg 2.48 + L1reg 0.18 ; SHD = 79 ; DAG True
Proportion of microbatches that were clipped  0.7796178343949045
iteration 1 in inner loop, alpha 472.2684753341739 rho 10000.0 h 0.027347856363849843
4420
cuda
Objective function 91.56 = squared loss an data 38.60 + 0.5*rho*h**2 37.395262 + alpha*h 12.915530 + L2reg 2.48 + L1reg 0.18 ; SHD = 79 ; DAG True
||w||^2 130.83701672359163
exp ma of ||w||^2 451703357.4813517
||w|| 11.438400968823904
exp ma of ||w|| 285.27253341262167
||w||^2 6.739191389566305
exp ma of ||w||^2 1109.1713224851346
||w|| 2.5959952599275495
exp ma of ||w|| 2.8556748777840606
||w||^2 5.217261497356656
exp ma of ||w||^2 18.53902189451201
||w|| 2.284132548114635
exp ma of ||w|| 2.407807211930229
||w||^2 2.7408877512771386
exp ma of ||w||^2 5.124185008746734
||w|| 1.6555626690878056
exp ma of ||w|| 2.21598090115125
||w||^2 10.935460643067197
exp ma of ||w||^2 5.539592603340569
||w|| 3.306880802669972
exp ma of ||w|| 2.304094627745189
||w||^2 2.8377919591115686
exp ma of ||w||^2 5.153444118230706
||w|| 1.6845747116443273
exp ma of ||w|| 2.221913345098093
||w||^2 6.519100293310589
exp ma of ||w||^2 5.685664276093419
||w|| 2.5532528847160028
exp ma of ||w|| 2.3498061344325185
||w||^2 3.1037991993287064
exp ma of ||w||^2 5.577689318717213
||w|| 1.7617602559169923
exp ma of ||w|| 2.3207365550337165
||w||^2 4.426971619034527
exp ma of ||w||^2 5.516271807217633
||w|| 2.1040369813847204
exp ma of ||w|| 2.3207339726345673
||w||^2 7.354180093682441
exp ma of ||w||^2 5.549980536880298
||w|| 2.711859158157451
exp ma of ||w|| 2.3115813893462804
||w||^2 11.590875261253569
exp ma of ||w||^2 5.796579128605553
||w|| 3.404537451880001
exp ma of ||w|| 2.369630487068982
cuda
Objective function 55.34 = squared loss an data 38.33 + 0.5*rho*h**2 8.214255 + alpha*h 6.053242 + L2reg 2.57 + L1reg 0.17 ; SHD = 77 ; DAG True
Proportion of microbatches that were clipped  0.7828603585497227
iteration 2 in inner loop, alpha 472.2684753341739 rho 100000.0 h 0.012817374589957353
iteration 4 in outer loop, alpha = 13289.643065291528, rho = 1000000.0, h = 0.012817374589957353
Threshold 0.3
[[0.007 2.178 0.536 0.65  0.686 0.723 0.743 0.664 0.184 0.23  0.435 0.25
  0.41  0.205 0.57  0.88  0.551 0.524 0.892 0.499]
 [0.003 0.008 0.117 0.201 0.295 0.453 0.674 0.123 0.031 0.157 0.081 0.038
  0.095 0.082 0.248 0.423 0.187 0.195 0.222 0.261]
 [0.014 0.06  0.012 0.104 0.283 0.093 0.248 0.166 0.011 0.141 0.039 0.058
  0.063 0.234 0.183 0.31  0.219 0.215 0.209 0.129]
 [0.012 0.046 0.072 0.01  0.253 0.094 0.139 0.116 0.023 0.044 0.065 0.052
  0.049 0.134 0.263 0.267 0.12  0.261 0.089 0.055]
 [0.006 0.028 0.03  0.036 0.006 0.008 0.03  0.008 0.009 0.016 0.02  0.017
  0.013 0.046 0.025 0.059 0.02  0.019 0.02  0.027]
 [0.008 0.025 0.063 0.056 0.608 0.007 0.186 0.222 0.013 0.094 0.046 0.024
  0.062 0.132 0.459 0.739 1.067 0.222 0.212 0.17 ]
 [0.006 0.011 0.029 0.052 0.258 0.034 0.008 0.045 0.014 0.052 0.008 0.018
  0.014 0.062 0.078 0.498 0.097 0.035 0.05  0.079]
 [0.011 0.047 0.045 0.082 0.574 0.028 0.157 0.009 0.011 0.036 0.057 0.037
  0.026 0.219 0.223 0.274 0.25  0.183 0.164 0.074]
 [0.046 0.112 0.747 0.384 0.864 0.463 0.53  0.499 0.009 0.233 0.477 0.26
  0.78  0.36  0.306 0.744 0.73  0.518 0.872 0.434]
 [0.026 0.025 0.052 0.152 0.636 0.098 0.138 0.184 0.023 0.009 0.085 0.035
  0.165 0.234 0.163 0.23  0.374 0.172 0.185 0.165]
 [0.022 0.128 0.182 0.12  0.34  0.13  0.687 0.091 0.008 0.07  0.007 0.04
  0.02  0.173 0.243 0.427 0.281 0.103 0.053 0.584]
 [0.022 0.242 0.128 0.104 0.19  0.34  0.43  0.184 0.034 0.221 0.184 0.007
  0.188 0.379 0.236 0.426 0.392 0.177 0.216 0.2  ]
 [0.019 0.055 0.098 0.132 0.548 0.132 0.399 0.278 0.009 0.03  0.389 0.05
  0.004 0.248 0.145 0.538 0.273 0.225 0.11  0.265]
 [0.019 0.066 0.033 0.048 0.118 0.058 0.111 0.034 0.02  0.048 0.054 0.024
  0.041 0.009 0.076 0.292 0.106 0.036 0.064 0.168]
 [0.013 0.026 0.044 0.029 0.385 0.017 0.105 0.035 0.015 0.033 0.014 0.037
  0.056 0.067 0.009 0.209 0.019 0.029 0.039 0.047]
 [0.003 0.016 0.023 0.023 0.13  0.009 0.014 0.025 0.008 0.02  0.015 0.012
  0.014 0.025 0.04  0.01  0.008 0.02  0.01  0.008]
 [0.008 0.022 0.037 0.08  0.284 0.009 0.099 0.037 0.011 0.019 0.027 0.019
  0.022 0.046 0.409 0.715 0.008 0.033 0.1   0.057]
 [0.012 0.051 0.038 0.028 0.389 0.062 0.16  0.049 0.014 0.041 0.056 0.026
  0.038 0.221 0.321 0.397 0.129 0.008 0.111 0.075]
 [0.01  0.03  0.024 0.068 0.273 0.037 0.201 0.034 0.008 0.03  0.127 0.043
  0.074 0.106 0.167 0.818 0.071 0.049 0.006 0.085]
 [0.011 0.026 0.05  0.104 0.27  0.053 0.131 0.082 0.016 0.029 0.012 0.034
  0.022 0.05  0.157 1.042 0.107 0.084 0.079 0.008]]
[[0.    2.178 0.536 0.65  0.686 0.723 0.743 0.664 0.    0.    0.435 0.
  0.41  0.    0.57  0.88  0.551 0.524 0.892 0.499]
 [0.    0.    0.    0.    0.    0.453 0.674 0.    0.    0.    0.    0.
  0.    0.    0.    0.423 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.31  0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.608 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.459 0.739 1.067 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.498 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.574 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.747 0.384 0.864 0.463 0.53  0.499 0.    0.    0.477 0.
  0.78  0.36  0.306 0.744 0.73  0.518 0.872 0.434]
 [0.    0.    0.    0.    0.636 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.374 0.    0.    0.   ]
 [0.    0.    0.    0.    0.34  0.    0.687 0.    0.    0.    0.    0.
  0.    0.    0.    0.427 0.    0.    0.    0.584]
 [0.    0.    0.    0.    0.    0.34  0.43  0.    0.    0.    0.    0.
  0.    0.379 0.    0.426 0.392 0.    0.    0.   ]
 [0.    0.    0.    0.    0.548 0.    0.399 0.    0.    0.    0.389 0.
  0.    0.    0.    0.538 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.385 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.409 0.715 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.389 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.321 0.397 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.818 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    1.042 0.    0.    0.    0.   ]]
{'fdr': 0.49206349206349204, 'tpr': 0.4, 'fpr': 0.2818181818181818, 'f1': 0.44755244755244755, 'shd': 77, 'npred': 63, 'ntrue': 80}
[2.178 0.536 0.65  0.686 0.723 0.743 0.664 0.184 0.23  0.435 0.25  0.41
 0.205 0.57  0.88  0.551 0.524 0.892 0.499 0.003 0.117 0.201 0.295 0.453
 0.674 0.123 0.031 0.157 0.081 0.038 0.095 0.082 0.248 0.423 0.187 0.195
 0.222 0.261 0.014 0.06  0.104 0.283 0.093 0.248 0.166 0.011 0.141 0.039
 0.058 0.063 0.234 0.183 0.31  0.219 0.215 0.209 0.129 0.012 0.046 0.072
 0.253 0.094 0.139 0.116 0.023 0.044 0.065 0.052 0.049 0.134 0.263 0.267
 0.12  0.261 0.089 0.055 0.006 0.028 0.03  0.036 0.008 0.03  0.008 0.009
 0.016 0.02  0.017 0.013 0.046 0.025 0.059 0.02  0.019 0.02  0.027 0.008
 0.025 0.063 0.056 0.608 0.186 0.222 0.013 0.094 0.046 0.024 0.062 0.132
 0.459 0.739 1.067 0.222 0.212 0.17  0.006 0.011 0.029 0.052 0.258 0.034
 0.045 0.014 0.052 0.008 0.018 0.014 0.062 0.078 0.498 0.097 0.035 0.05
 0.079 0.011 0.047 0.045 0.082 0.574 0.028 0.157 0.011 0.036 0.057 0.037
 0.026 0.219 0.223 0.274 0.25  0.183 0.164 0.074 0.046 0.112 0.747 0.384
 0.864 0.463 0.53  0.499 0.233 0.477 0.26  0.78  0.36  0.306 0.744 0.73
 0.518 0.872 0.434 0.026 0.025 0.052 0.152 0.636 0.098 0.138 0.184 0.023
 0.085 0.035 0.165 0.234 0.163 0.23  0.374 0.172 0.185 0.165 0.022 0.128
 0.182 0.12  0.34  0.13  0.687 0.091 0.008 0.07  0.04  0.02  0.173 0.243
 0.427 0.281 0.103 0.053 0.584 0.022 0.242 0.128 0.104 0.19  0.34  0.43
 0.184 0.034 0.221 0.184 0.188 0.379 0.236 0.426 0.392 0.177 0.216 0.2
 0.019 0.055 0.098 0.132 0.548 0.132 0.399 0.278 0.009 0.03  0.389 0.05
 0.248 0.145 0.538 0.273 0.225 0.11  0.265 0.019 0.066 0.033 0.048 0.118
 0.058 0.111 0.034 0.02  0.048 0.054 0.024 0.041 0.076 0.292 0.106 0.036
 0.064 0.168 0.013 0.026 0.044 0.029 0.385 0.017 0.105 0.035 0.015 0.033
 0.014 0.037 0.056 0.067 0.209 0.019 0.029 0.039 0.047 0.003 0.016 0.023
 0.023 0.13  0.009 0.014 0.025 0.008 0.02  0.015 0.012 0.014 0.025 0.04
 0.008 0.02  0.01  0.008 0.008 0.022 0.037 0.08  0.284 0.009 0.099 0.037
 0.011 0.019 0.027 0.019 0.022 0.046 0.409 0.715 0.033 0.1   0.057 0.012
 0.051 0.038 0.028 0.389 0.062 0.16  0.049 0.014 0.041 0.056 0.026 0.038
 0.221 0.321 0.397 0.129 0.111 0.075 0.01  0.03  0.024 0.068 0.273 0.037
 0.201 0.034 0.008 0.03  0.127 0.043 0.074 0.106 0.167 0.818 0.071 0.049
 0.085 0.011 0.026 0.05  0.104 0.27  0.053 0.131 0.082 0.016 0.029 0.012
 0.034 0.022 0.05  0.157 1.042 0.107 0.084 0.079]
[[0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0.]
 [0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1.]
 [0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0.]
 [0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.]
 [0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.]
 [0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]
 [0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]
[1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1.
 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.
 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.
 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1.
 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
aucroc, aucpr (0.750125, 0.5071529996346491)
Iterations 2250
Achieves (5.825547298234785, 1e-05)-DP
