samples  5000  SCM  10 2 RE mim  minibatch size  50  noise  0.6  minibatches per NN training  250  DP methodology  adap_quantile 0.0  box penalty  1
cpu
max degree  2.0  complexity indicator 1  625.0  complexity indicator 2  1086.9565217391305
model created with box penalty
model created with box penalty
cpu
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 0.2855731205864114
iteration 1 in outer loop, alpha = 0.2855731205864114, rho = 1.0, h = 0.2855731205864114
model created with box penalty
cpu
iteration 1 in inner loop,alpha 0.2855731205864114 rho 1.0 h 0.15778945700017388
iteration 2 in inner loop,alpha 0.2855731205864114 rho 10.0 h 0.057422677149482126
iteration 2 in outer loop, alpha = 0.8597998920812326, rho = 10.0, h = 0.057422677149482126
model created with box penalty
cpu
iteration 1 in inner loop,alpha 0.8597998920812326 rho 10.0 h 0.0378950349318643
iteration 2 in inner loop,alpha 0.8597998920812326 rho 100.0 h 0.016471852091774153
iteration 3 in inner loop,alpha 0.8597998920812326 rho 1000.0 h 0.001737601982998882
iteration 3 in outer loop, alpha = 2.5974018750801147, rho = 1000.0, h = 0.001737601982998882
model created with box penalty
cpu
iteration 1 in inner loop,alpha 2.5974018750801147 rho 1000.0 h 0.0009355762507770038
iteration 2 in inner loop,alpha 2.5974018750801147 rho 10000.0 h 0.0003313582199417908
iteration 4 in outer loop, alpha = 5.910984074498023, rho = 10000.0, h = 0.0003313582199417908
model created with box penalty
cpu
iteration 1 in inner loop,alpha 5.910984074498023 rho 10000.0 h 0.0001902268167022214
iteration 2 in inner loop,alpha 5.910984074498023 rho 100000.0 h 7.034699317998161e-05
iteration 5 in outer loop, alpha = 12.945683392496184, rho = 100000.0, h = 7.034699317998161e-05
model created with box penalty
cpu
iteration 1 in inner loop,alpha 12.945683392496184 rho 100000.0 h 4.035102040589322e-05
iteration 6 in outer loop, alpha = 53.29670379838941, rho = 1000000.0, h = 4.035102040589322e-05
Threshold 0.3
[[0.    0.    2.425 0.    0.139 0.    0.096 0.    0.    0.013]
 [2.391 0.    0.    0.    0.    0.    0.    0.    0.    0.013]
 [0.002 0.    0.    0.    0.    0.    1.048 0.    0.    0.   ]
 [2.185 0.    0.026 0.    0.79  0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.003]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.001 0.    0.002 0.    0.    0.    0.    0.    0.    0.021]
 [0.001 0.    0.    0.    0.062 0.    0.    0.    0.    2.961]
 [0.015 0.    0.    0.    0.    0.    1.416 0.    0.    2.676]
 [0.    0.    0.    0.    1.826 0.    0.02  0.    0.    0.   ]]
[[0.    0.    2.425 0.    0.    0.    0.    0.    0.    0.   ]
 [2.391 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    1.048 0.    0.    0.   ]
 [2.185 0.    0.    0.    0.79  0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    2.961]
 [0.    0.    0.    0.    0.    0.    1.416 0.    0.    2.676]
 [0.    0.    0.    0.    1.826 0.    0.    0.    0.    0.   ]]
{'fdr': 0.0, 'tpr': 1.0, 'fpr': 0.0, 'f1': 1.0, 'shd': 0, 'npred': 9, 'ntrue': 9}
[0.000e+00 2.425e+00 0.000e+00 1.392e-01 0.000e+00 9.592e-02 0.000e+00
 0.000e+00 1.287e-02 2.391e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00
 0.000e+00 0.000e+00 0.000e+00 1.278e-02 1.605e-03 0.000e+00 0.000e+00
 0.000e+00 0.000e+00 1.048e+00 0.000e+00 0.000e+00 0.000e+00 2.185e+00
 0.000e+00 2.555e-02 7.895e-01 0.000e+00 0.000e+00 0.000e+00 0.000e+00
 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00
 0.000e+00 0.000e+00 2.520e-03 0.000e+00 0.000e+00 0.000e+00 0.000e+00
 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 1.360e-03 0.000e+00
 1.796e-03 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 2.051e-02
 1.132e-03 0.000e+00 0.000e+00 0.000e+00 6.220e-02 0.000e+00 0.000e+00
 0.000e+00 2.961e+00 1.497e-02 0.000e+00 0.000e+00 0.000e+00 0.000e+00
 0.000e+00 1.416e+00 0.000e+00 2.676e+00 0.000e+00 0.000e+00 0.000e+00
 0.000e+00 1.826e+00 0.000e+00 2.029e-02 0.000e+00 0.000e+00]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (1.0, 1.0)
model created with box penalty
cpu
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cpu
[0.677 0.971 0.689 0.72  0.572 0.805 0.858 0.756 0.945 0.892 0.832 0.999
 0.701 0.819 0.962 0.884 0.92  0.795 0.857 0.662 0.911 0.542 1.    0.831
 0.714 0.796 0.787 0.638 0.895 0.724 0.98  0.773 0.774 1.043 0.695 0.666
 0.874 0.634 0.669 0.644 1.119 0.724 0.793 0.718 0.874 0.939 0.946 0.811
 0.665 0.591 0.727 0.612 0.705 0.758 0.93  0.992 1.106 0.61  0.742 1.111
 0.988 0.962 0.805 0.585 0.422 0.708 0.696 1.144 0.799 0.772 0.964 0.851
 0.734 0.693 0.799 0.876 0.556 0.783 0.827 0.857 0.498 0.664 0.728 0.759
 0.857 0.843 0.79  1.055 0.884 0.778]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.5747599451303156, 0.13480677069860666)
Objective function 18342.84 = squared loss an data 10.47 + 0.5*rho*h**2 14845.719911 + alpha*h 0.000000 + L2reg 0.36 + L1reg -0.10 + box penalty 3486.40 ; SHD = 55 ; DAG False
total norm for a microbatch 17833.089600785086 clip 12.12382569588748
total norm for a microbatch 1151.4454698823845 clip 28.403175956396126
total norm for a microbatch 703.3526326630791 clip 83.3280326215851
total norm for a microbatch 10.150626486465713 clip 11.021761705044424
total norm for a microbatch 7.11394178039755 clip 6.647941555758472
total norm for a microbatch 6.285391634525717 clip 6.577632300269388
total norm for a microbatch 7.915105351274381 clip 6.500868813420772
total norm for a microbatch 9.663778877149316 clip 6.648993465408475
total norm for a microbatch 11.475020996989814 clip 6.623427206569612
total norm for a microbatch 7.809364252099911 clip 7.092298276151154
total norm for a microbatch 7.686552204041383 clip 6.881499573504794
total norm for a microbatch 9.381171088255481 clip 6.335365251738989
total norm for a microbatch 8.245302244671526 clip 6.355655687194351
total norm for a microbatch 7.43001428832501 clip 6.926573775043865
cpu
[0.199 0.345 0.193 0.198 0.261 0.309 0.176 0.1   0.178 0.297 0.263 0.193
 0.16  0.231 0.153 0.168 0.321 0.102 0.431 0.193 0.249 0.144 0.213 0.245
 0.233 0.227 0.242 0.378 0.24  0.113 0.24  0.236 0.131 0.233 0.15  0.159
 0.277 0.17  0.114 0.213 0.24  0.191 0.134 0.19  0.392 0.133 0.148 0.112
 0.124 0.169 0.198 0.244 0.257 0.103 0.151 0.136 0.319 0.162 0.196 0.245
 0.294 0.207 0.152 0.194 0.211 0.158 0.203 0.208 0.203 0.107 0.109 0.278
 0.23  0.173 0.206 0.207 0.164 0.196 0.202 0.291 0.148 0.158 0.352 0.138
 0.146 0.313 0.315 0.252 0.224 0.244]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.7736625514403292, 0.29098131320353543)
Objective function 9.52 = squared loss an data 7.55 + 0.5*rho*h**2 0.197490 + alpha*h 0.000000 + L2reg 0.06 + L1reg 1.72 + box penalty 0.00 ; SHD = 14 ; DAG False
Proportion of microbatches that were clipped  0.7676520889323235
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 0.6284742344522254
iteration 1 in outer loop, alpha = 0.6284742344522254, rho = 1.0, h = 0.6284742344522254
cpu
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cpu
[0.199 0.345 0.193 0.198 0.261 0.309 0.176 0.1   0.178 0.297 0.263 0.193
 0.16  0.231 0.153 0.168 0.321 0.102 0.431 0.193 0.249 0.144 0.213 0.245
 0.233 0.227 0.242 0.378 0.24  0.113 0.24  0.236 0.131 0.233 0.15  0.159
 0.277 0.17  0.114 0.213 0.24  0.191 0.134 0.19  0.392 0.133 0.148 0.112
 0.124 0.169 0.198 0.244 0.257 0.103 0.151 0.136 0.319 0.162 0.196 0.245
 0.294 0.207 0.152 0.194 0.211 0.158 0.203 0.208 0.203 0.107 0.109 0.278
 0.23  0.173 0.206 0.207 0.164 0.196 0.202 0.291 0.148 0.158 0.352 0.138
 0.146 0.313 0.315 0.252 0.224 0.244]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.7736625514403292, 0.29098131320353543)
Objective function 9.92 = squared loss an data 7.55 + 0.5*rho*h**2 0.197490 + alpha*h 0.394980 + L2reg 0.06 + L1reg 1.72 + box penalty 0.00 ; SHD = 14 ; DAG False
total norm for a microbatch 14.013826787802712 clip 8.099787479195445
total norm for a microbatch 8.412994340146279 clip 8.340510365541478
total norm for a microbatch 8.163065089447139 clip 7.142323079598338
total norm for a microbatch 6.838825696006615 clip 8.260897259440593
total norm for a microbatch 11.213116422223866 clip 8.191602165436203
total norm for a microbatch 10.761323978861272 clip 8.762144241451843
total norm for a microbatch 9.045056352365101 clip 8.934793504036952
total norm for a microbatch 10.069478236790928 clip 8.793000577793926
total norm for a microbatch 13.778426406294436 clip 8.757737741636848
cpu
[0.174 0.352 0.178 0.189 0.252 0.157 0.146 0.159 0.087 0.414 0.154 0.131
 0.091 0.251 0.125 0.171 0.186 0.163 0.288 0.271 0.202 0.164 0.114 0.256
 0.178 0.116 0.159 0.574 0.271 0.068 0.196 0.326 0.12  0.185 0.125 0.106
 0.165 0.201 0.142 0.329 0.118 0.176 0.235 0.162 0.273 0.135 0.096 0.158
 0.084 0.197 0.218 0.232 0.153 0.186 0.147 0.086 0.26  0.143 0.146 0.129
 0.179 0.164 0.1   0.177 0.155 0.193 0.131 0.164 0.138 0.187 0.296 0.612
 0.194 0.199 0.169 0.197 0.181 0.16  0.446 0.126 0.366 0.291 0.117 0.154
 0.211 0.275 0.147 0.186 0.07  0.195]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9533607681755829, 0.8182518218015176)
Objective function 7.25 = squared loss an data 5.10 + 0.5*rho*h**2 0.234008 + alpha*h 0.429950 + L2reg 0.29 + L1reg 1.18 + box penalty 0.02 ; SHD = 7 ; DAG False
Proportion of microbatches that were clipped  0.7720937726576976
iteration 1 in inner loop, alpha 0.6284742344522254 rho 1.0 h 0.6841164905651951
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cpu
[0.174 0.352 0.178 0.189 0.252 0.157 0.146 0.159 0.087 0.414 0.154 0.131
 0.091 0.251 0.125 0.171 0.186 0.163 0.288 0.271 0.202 0.164 0.114 0.256
 0.178 0.116 0.159 0.574 0.271 0.068 0.196 0.326 0.12  0.185 0.125 0.106
 0.165 0.201 0.142 0.329 0.118 0.176 0.235 0.162 0.273 0.135 0.096 0.158
 0.084 0.197 0.218 0.232 0.153 0.186 0.147 0.086 0.26  0.143 0.146 0.129
 0.179 0.164 0.1   0.177 0.155 0.193 0.131 0.164 0.138 0.187 0.296 0.612
 0.194 0.199 0.169 0.197 0.181 0.16  0.446 0.126 0.366 0.291 0.117 0.154
 0.211 0.275 0.147 0.186 0.07  0.195]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9533607681755829, 0.8182518218015176)
Objective function 9.36 = squared loss an data 5.10 + 0.5*rho*h**2 2.340077 + alpha*h 0.429950 + L2reg 0.29 + L1reg 1.18 + box penalty 0.02 ; SHD = 7 ; DAG False
total norm for a microbatch 7.394715112648959 clip 9.660169071828111
total norm for a microbatch 13.453651764323473 clip 9.886993562676937
total norm for a microbatch 17.63427400558332 clip 9.342618503546113
total norm for a microbatch 29.069199068641588 clip 9.59333128301978
cpu
[0.155 0.359 0.146 0.172 0.136 0.153 0.164 0.157 0.163 0.306 0.119 0.169
 0.122 0.189 0.11  0.17  0.193 0.13  0.225 0.17  0.22  0.086 0.138 0.217
 0.07  0.152 0.145 0.435 0.128 0.096 0.173 0.11  0.125 0.095 0.145 0.224
 0.115 0.167 0.178 0.188 0.227 0.12  0.178 0.107 0.257 0.185 0.162 0.144
 0.156 0.155 0.159 0.256 0.129 0.188 0.121 0.111 0.25  0.216 0.155 0.138
 0.123 0.138 0.125 0.16  0.204 0.201 0.223 0.178 0.093 0.168 0.161 0.635
 0.16  0.129 0.2   0.057 0.23  0.155 0.385 0.234 0.311 0.127 0.131 0.144
 0.169 0.295 0.134 0.101 0.1   0.196]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9547325102880659, 0.8584104938271605)
Objective function 7.76 = squared loss an data 5.67 + 0.5*rho*h**2 0.300863 + alpha*h 0.154165 + L2reg 0.41 + L1reg 1.18 + box penalty 0.04 ; SHD = 3 ; DAG True
Proportion of microbatches that were clipped  0.7723054379680886
iteration 2 in inner loop, alpha 0.6284742344522254 rho 10.0 h 0.24530116534052837
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cpu
[0.155 0.359 0.146 0.172 0.136 0.153 0.164 0.157 0.163 0.306 0.119 0.169
 0.122 0.189 0.11  0.17  0.193 0.13  0.225 0.17  0.22  0.086 0.138 0.217
 0.07  0.152 0.145 0.435 0.128 0.096 0.173 0.11  0.125 0.095 0.145 0.224
 0.115 0.167 0.178 0.188 0.227 0.12  0.178 0.107 0.257 0.185 0.162 0.144
 0.156 0.155 0.159 0.256 0.129 0.188 0.121 0.111 0.25  0.216 0.155 0.138
 0.123 0.138 0.125 0.16  0.204 0.201 0.223 0.178 0.093 0.168 0.161 0.635
 0.16  0.129 0.2   0.057 0.23  0.155 0.385 0.234 0.311 0.127 0.131 0.144
 0.169 0.295 0.134 0.101 0.1   0.196]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9547325102880659, 0.8584104938271605)
Objective function 10.47 = squared loss an data 5.67 + 0.5*rho*h**2 3.008633 + alpha*h 0.154165 + L2reg 0.41 + L1reg 1.18 + box penalty 0.04 ; SHD = 3 ; DAG True
total norm for a microbatch 15.605833205445991 clip 11.422698552801219
total norm for a microbatch 31.168390866233377 clip 11.262378043683718
total norm for a microbatch 24.47539728504108 clip 9.918201676996187
total norm for a microbatch 11.875295534041834 clip 12.624609623230901
total norm for a microbatch 33.28993226661719 clip 11.836755061080687
total norm for a microbatch 8.748645916688009 clip 11.732823042324094
total norm for a microbatch 9.040077098461525 clip 11.654713724161748
total norm for a microbatch 17.69278190903767 clip 11.476405132800803
total norm for a microbatch 27.842414781508587 clip 11.045796122814682
total norm for a microbatch 14.269932053633816 clip 11.799263889006475
total norm for a microbatch 19.491590724008667 clip 12.158389581955912
total norm for a microbatch 15.63542897304202 clip 12.452901852189996
total norm for a microbatch 32.83594645473702 clip 12.277291550031173
cpu
[0.061 0.247 0.055 0.118 0.131 0.137 0.092 0.141 0.091 0.462 0.153 0.149
 0.228 0.108 0.084 0.14  0.138 0.16  0.277 0.114 0.165 0.106 0.117 0.248
 0.163 0.119 0.14  0.548 0.183 0.092 0.295 0.163 0.093 0.083 0.083 0.229
 0.176 0.072 0.141 0.065 0.152 0.114 0.052 0.158 0.267 0.109 0.088 0.135
 0.078 0.074 0.176 0.106 0.102 0.195 0.105 0.161 0.164 0.137 0.197 0.119
 0.113 0.072 0.157 0.221 0.146 0.117 0.186 0.244 0.154 0.068 0.163 0.682
 0.135 0.184 0.141 0.096 0.161 0.157 0.468 0.132 0.387 0.11  0.159 0.127
 0.098 0.189 0.115 0.105 0.057 0.104]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9835390946502057, 0.90079883805374)
Objective function 8.40 = squared loss an data 6.41 + 0.5*rho*h**2 0.254231 + alpha*h 0.044814 + L2reg 0.45 + L1reg 1.20 + box penalty 0.04 ; SHD = 4 ; DAG True
Proportion of microbatches that were clipped  0.7768693443403715
iteration 3 in inner loop, alpha 0.6284742344522254 rho 100.0 h 0.07130648671967066
iteration 2 in outer loop, alpha = 7.759122906419291, rho = 100.0, h = 0.07130648671967066
cpu
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cpu
[0.061 0.247 0.055 0.118 0.131 0.137 0.092 0.141 0.091 0.462 0.153 0.149
 0.228 0.108 0.084 0.14  0.138 0.16  0.277 0.114 0.165 0.106 0.117 0.248
 0.163 0.119 0.14  0.548 0.183 0.092 0.295 0.163 0.093 0.083 0.083 0.229
 0.176 0.072 0.141 0.065 0.152 0.114 0.052 0.158 0.267 0.109 0.088 0.135
 0.078 0.074 0.176 0.106 0.102 0.195 0.105 0.161 0.164 0.137 0.197 0.119
 0.113 0.072 0.157 0.221 0.146 0.117 0.186 0.244 0.154 0.068 0.163 0.682
 0.135 0.184 0.141 0.096 0.161 0.157 0.468 0.132 0.387 0.11  0.159 0.127
 0.098 0.189 0.115 0.105 0.057 0.104]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9835390946502057, 0.90079883805374)
Objective function 8.91 = squared loss an data 6.41 + 0.5*rho*h**2 0.254231 + alpha*h 0.553276 + L2reg 0.45 + L1reg 1.20 + box penalty 0.04 ; SHD = 4 ; DAG True
total norm for a microbatch 14.898143567075826 clip 12.642007029950975
total norm for a microbatch 18.80291788942333 clip 11.278360083599583
total norm for a microbatch 11.602941652538545 clip 12.1724530293526
total norm for a microbatch 17.780025349275544 clip 12.387550008309073
total norm for a microbatch 17.588714650847155 clip 13.656622067682848
total norm for a microbatch 11.519107457928396 clip 13.464891656700528
total norm for a microbatch 11.25651142651352 clip 13.391251533443974
total norm for a microbatch 14.799306411657318 clip 12.564111653517667
total norm for a microbatch 15.709596993615488 clip 12.207696258612538
total norm for a microbatch 17.385873659780213 clip 13.609314411900717
total norm for a microbatch 23.732821220924194 clip 13.609314411900717
total norm for a microbatch 11.774609072050103 clip 12.865551819482182
total norm for a microbatch 13.497349120301136 clip 13.464590252533474
cpu
[0.034 0.189 0.058 0.097 0.1   0.08  0.079 0.09  0.072 0.54  0.088 0.083
 0.111 0.089 0.07  0.1   0.073 0.157 0.226 0.178 0.139 0.135 0.167 0.205
 0.1   0.109 0.117 0.49  0.17  0.17  0.222 0.123 0.085 0.096 0.046 0.16
 0.156 0.061 0.111 0.077 0.129 0.113 0.066 0.112 0.093 0.142 0.179 0.124
 0.089 0.146 0.144 0.112 0.094 0.118 0.137 0.167 0.182 0.191 0.123 0.122
 0.094 0.06  0.12  0.203 0.178 0.09  0.125 0.223 0.254 0.179 0.184 0.716
 0.168 0.159 0.162 0.178 0.119 0.102 0.509 0.123 0.489 0.132 0.115 0.083
 0.079 0.346 0.134 0.074 0.027 0.032]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9849108367626885, 0.8966810966810967)
Objective function 8.90 = squared loss an data 6.71 + 0.5*rho*h**2 0.093028 + alpha*h 0.334684 + L2reg 0.50 + L1reg 1.24 + box penalty 0.03 ; SHD = 3 ; DAG True
Proportion of microbatches that were clipped  0.7749015194147439
iteration 1 in inner loop, alpha 7.759122906419291 rho 100.0 h 0.04313430045420752
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cpu
[0.034 0.189 0.058 0.097 0.1   0.08  0.079 0.09  0.072 0.54  0.088 0.083
 0.111 0.089 0.07  0.1   0.073 0.157 0.226 0.178 0.139 0.135 0.167 0.205
 0.1   0.109 0.117 0.49  0.17  0.17  0.222 0.123 0.085 0.096 0.046 0.16
 0.156 0.061 0.111 0.077 0.129 0.113 0.066 0.112 0.093 0.142 0.179 0.124
 0.089 0.146 0.144 0.112 0.094 0.118 0.137 0.167 0.182 0.191 0.123 0.122
 0.094 0.06  0.12  0.203 0.178 0.09  0.125 0.223 0.254 0.179 0.184 0.716
 0.168 0.159 0.162 0.178 0.119 0.102 0.509 0.123 0.489 0.132 0.115 0.083
 0.079 0.346 0.134 0.074 0.027 0.032]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9849108367626885, 0.8966810966810967)
Objective function 9.74 = squared loss an data 6.71 + 0.5*rho*h**2 0.930284 + alpha*h 0.334684 + L2reg 0.50 + L1reg 1.24 + box penalty 0.03 ; SHD = 3 ; DAG True
total norm for a microbatch 15.48387937961412 clip 13.96598742982743
total norm for a microbatch 21.264270306020713 clip 13.96598742982743
total norm for a microbatch 34.09025149719341 clip 14.54787764497556
total norm for a microbatch 15.508073104911633 clip 14.139483537512701
total norm for a microbatch 14.338092947973394 clip 13.507299887948799
total norm for a microbatch 12.303808214741528 clip 12.38260810657303
total norm for a microbatch 14.75867095054828 clip 12.639626190122723
total norm for a microbatch 9.078802899048535 clip 12.968224006588636
total norm for a microbatch 13.39275316824129 clip 13.256342880936472
total norm for a microbatch 11.813497201874057 clip 14.184481081548395
total norm for a microbatch 24.286785613104485 clip 14.02613168838319
total norm for a microbatch 15.178262443168615 clip 12.11662791865236
total norm for a microbatch 10.958288463872714 clip 13.857921087369004
total norm for a microbatch 32.89496555281974 clip 11.616342867737854
cpu
[0.022 0.166 0.021 0.073 0.083 0.128 0.067 0.071 0.073 0.723 0.159 0.104
 0.093 0.132 0.143 0.046 0.094 0.194 0.247 0.102 0.143 0.141 0.105 0.323
 0.107 0.055 0.172 0.708 0.114 0.138 0.247 0.141 0.171 0.065 0.084 0.096
 0.114 0.09  0.072 0.057 0.074 0.1   0.066 0.071 0.107 0.125 0.104 0.105
 0.132 0.102 0.146 0.092 0.075 0.098 0.11  0.044 0.095 0.057 0.124 0.117
 0.075 0.019 0.1   0.147 0.165 0.104 0.118 0.179 0.102 0.105 0.091 0.866
 0.137 0.099 0.183 0.071 0.161 0.17  0.819 0.136 0.477 0.109 0.069 0.051
 0.122 0.364 0.116 0.106 0.024 0.048]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9903978052126201, 0.9513888888888888)
Objective function 9.03 = squared loss an data 7.02 + 0.5*rho*h**2 0.150021 + alpha*h 0.134401 + L2reg 0.45 + L1reg 1.25 + box penalty 0.03 ; SHD = 2 ; DAG True
Proportion of microbatches that were clipped  0.7752935499437027
iteration 2 in inner loop, alpha 7.759122906419291 rho 1000.0 h 0.017321714821910916
iteration 3 in outer loop, alpha = 25.08083772833021, rho = 1000.0, h = 0.017321714821910916
cpu
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cpu
[0.022 0.166 0.021 0.073 0.083 0.128 0.067 0.071 0.073 0.723 0.159 0.104
 0.093 0.132 0.143 0.046 0.094 0.194 0.247 0.102 0.143 0.141 0.105 0.323
 0.107 0.055 0.172 0.708 0.114 0.138 0.247 0.141 0.171 0.065 0.084 0.096
 0.114 0.09  0.072 0.057 0.074 0.1   0.066 0.071 0.107 0.125 0.104 0.105
 0.132 0.102 0.146 0.092 0.075 0.098 0.11  0.044 0.095 0.057 0.124 0.117
 0.075 0.019 0.1   0.147 0.165 0.104 0.118 0.179 0.102 0.105 0.091 0.866
 0.137 0.099 0.183 0.071 0.161 0.17  0.819 0.136 0.477 0.109 0.069 0.051
 0.122 0.364 0.116 0.106 0.024 0.048]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9903978052126201, 0.9513888888888888)
Objective function 9.33 = squared loss an data 7.02 + 0.5*rho*h**2 0.150021 + alpha*h 0.434443 + L2reg 0.45 + L1reg 1.25 + box penalty 0.03 ; SHD = 2 ; DAG True
total norm for a microbatch 22.741442990514273 clip 13.23247187461277
total norm for a microbatch 15.861380604281408 clip 12.597211191741192
total norm for a microbatch 20.290534200358174 clip 14.214462729074597
total norm for a microbatch 10.068833722860978 clip 12.636464252694974
total norm for a microbatch 20.94332785997858 clip 11.222003016328076
total norm for a microbatch 17.61359345024102 clip 11.994450916739101
total norm for a microbatch 26.023898891770376 clip 11.085129510800783
total norm for a microbatch 23.471465561516904 clip 12.944549135096569
cpu
[0.015 0.155 0.014 0.131 0.096 0.086 0.042 0.083 0.104 0.816 0.149 0.081
 0.112 0.126 0.13  0.125 0.115 0.173 0.17  0.083 0.075 0.193 0.084 0.25
 0.053 0.057 0.084 0.65  0.126 0.122 0.215 0.108 0.128 0.087 0.085 0.132
 0.048 0.063 0.046 0.069 0.052 0.103 0.056 0.056 0.066 0.133 0.087 0.084
 0.131 0.221 0.121 0.087 0.049 0.097 0.112 0.039 0.091 0.088 0.123 0.064
 0.069 0.016 0.089 0.148 0.083 0.156 0.08  0.211 0.059 0.127 0.061 0.921
 0.134 0.092 0.104 0.166 0.11  0.194 0.551 0.099 0.525 0.069 0.071 0.06
 0.041 0.398 0.067 0.101 0.012 0.034]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9876543209876543, 0.9353667392883078)
Objective function 9.20 = squared loss an data 7.22 + 0.5*rho*h**2 0.047614 + alpha*h 0.244751 + L2reg 0.43 + L1reg 1.22 + box penalty 0.03 ; SHD = 3 ; DAG True
Proportion of microbatches that were clipped  0.7755036261079774
iteration 1 in inner loop, alpha 25.08083772833021 rho 1000.0 h 0.00975849036719012
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cpu
[0.015 0.155 0.014 0.131 0.096 0.086 0.042 0.083 0.104 0.816 0.149 0.081
 0.112 0.126 0.13  0.125 0.115 0.173 0.17  0.083 0.075 0.193 0.084 0.25
 0.053 0.057 0.084 0.65  0.126 0.122 0.215 0.108 0.128 0.087 0.085 0.132
 0.048 0.063 0.046 0.069 0.052 0.103 0.056 0.056 0.066 0.133 0.087 0.084
 0.131 0.221 0.121 0.087 0.049 0.097 0.112 0.039 0.091 0.088 0.123 0.064
 0.069 0.016 0.089 0.148 0.083 0.156 0.08  0.211 0.059 0.127 0.061 0.921
 0.134 0.092 0.104 0.166 0.11  0.194 0.551 0.099 0.525 0.069 0.071 0.06
 0.041 0.398 0.067 0.101 0.012 0.034]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9876543209876543, 0.9353667392883078)
Objective function 9.63 = squared loss an data 7.22 + 0.5*rho*h**2 0.476141 + alpha*h 0.244751 + L2reg 0.43 + L1reg 1.22 + box penalty 0.03 ; SHD = 3 ; DAG True
total norm for a microbatch 23.809261391911118 clip 18.43487909373632
total norm for a microbatch 22.316452775714943 clip 19.972693528374368
total norm for a microbatch 11.391545190626244 clip 12.24705124876258
total norm for a microbatch 18.772434991485152 clip 13.809180320599484
total norm for a microbatch 17.926791933559645 clip 12.55369025369695
total norm for a microbatch 16.445423881988052 clip 13.335634378289704
total norm for a microbatch 22.91734170432402 clip 12.083173945081516
total norm for a microbatch 15.414271435000924 clip 13.408489243418508
total norm for a microbatch 15.323607636799528 clip 11.541348962950039
total norm for a microbatch 16.175660457407268 clip 12.716571580801354
total norm for a microbatch 25.75935579950496 clip 13.369909780751888
total norm for a microbatch 19.314492405858076 clip 13.96234250976775
cpu
[0.006 0.278 0.011 0.045 0.031 0.091 0.063 0.06  0.06  0.936 0.144 0.051
 0.07  0.056 0.12  0.034 0.093 0.147 0.024 0.043 0.036 0.085 0.043 0.356
 0.076 0.099 0.179 0.854 0.112 0.163 0.137 0.028 0.065 0.099 0.062 0.092
 0.107 0.122 0.089 0.054 0.042 0.13  0.021 0.045 0.021 0.182 0.168 0.107
 0.168 0.212 0.067 0.079 0.063 0.061 0.114 0.05  0.033 0.09  0.088 0.104
 0.057 0.009 0.074 0.128 0.102 0.103 0.092 0.238 0.085 0.115 0.166 1.051
 0.112 0.082 0.078 0.088 0.135 0.084 0.688 0.048 0.551 0.093 0.042 0.07
 0.088 0.438 0.058 0.079 0.01  0.014]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9862825788751715, 0.9415204678362574)
Objective function 9.18 = squared loss an data 7.37 + 0.5*rho*h**2 0.079865 + alpha*h 0.100239 + L2reg 0.41 + L1reg 1.19 + box penalty 0.03 ; SHD = 2 ; DAG True
Proportion of microbatches that were clipped  0.7771396665869028
iteration 2 in inner loop, alpha 25.08083772833021 rho 10000.0 h 0.003996620404183915
iteration 4 in outer loop, alpha = 65.04704177016936, rho = 10000.0, h = 0.003996620404183915
cpu
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cpu
[0.006 0.278 0.011 0.045 0.031 0.091 0.063 0.06  0.06  0.936 0.144 0.051
 0.07  0.056 0.12  0.034 0.093 0.147 0.024 0.043 0.036 0.085 0.043 0.356
 0.076 0.099 0.179 0.854 0.112 0.163 0.137 0.028 0.065 0.099 0.062 0.092
 0.107 0.122 0.089 0.054 0.042 0.13  0.021 0.045 0.021 0.182 0.168 0.107
 0.168 0.212 0.067 0.079 0.063 0.061 0.114 0.05  0.033 0.09  0.088 0.104
 0.057 0.009 0.074 0.128 0.102 0.103 0.092 0.238 0.085 0.115 0.166 1.051
 0.112 0.082 0.078 0.088 0.135 0.084 0.688 0.048 0.551 0.093 0.042 0.07
 0.088 0.438 0.058 0.079 0.01  0.014]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9862825788751715, 0.9415204678362574)
Objective function 9.34 = squared loss an data 7.37 + 0.5*rho*h**2 0.079865 + alpha*h 0.259968 + L2reg 0.41 + L1reg 1.19 + box penalty 0.03 ; SHD = 2 ; DAG True
total norm for a microbatch 70.09724393994345 clip 20.90098806207217
total norm for a microbatch 33.44701070170447 clip 23.822865951435695
total norm for a microbatch 42.838280626965194 clip 23.822865951435695
total norm for a microbatch 28.3491119095351 clip 28.39206118031107
total norm for a microbatch 13.731626808564172 clip 14.828885379441193
total norm for a microbatch 18.872350435839927 clip 13.351853062880135
total norm for a microbatch 11.1602204243063 clip 14.125999894857936
total norm for a microbatch 19.031002138643316 clip 12.460009898926097
total norm for a microbatch 16.57714146743133 clip 13.801685547826137
total norm for a microbatch 11.513043494925846 clip 12.121581334933063
total norm for a microbatch 26.38196993449534 clip 14.338431266988795
total norm for a microbatch 21.048784094843725 clip 14.64925796776606
total norm for a microbatch 37.27500094245963 clip 12.812386070566587
total norm for a microbatch 12.712516014036341 clip 14.006055209530855
cpu
[0.008 0.325 0.004 0.059 0.045 0.066 0.048 0.041 0.052 1.32  0.187 0.089
 0.087 0.064 0.103 0.093 0.051 0.143 0.022 0.02  0.04  0.094 0.052 0.31
 0.089 0.085 0.202 1.017 0.059 0.123 0.349 0.065 0.098 0.115 0.098 0.16
 0.087 0.04  0.055 0.026 0.065 0.069 0.009 0.036 0.011 0.168 0.047 0.085
 0.071 0.099 0.093 0.052 0.075 0.133 0.06  0.057 0.035 0.061 0.106 0.114
 0.059 0.015 0.033 0.096 0.067 0.073 0.068 0.205 0.098 0.099 0.037 1.025
 0.111 0.07  0.065 0.055 0.14  0.058 0.725 0.099 0.616 0.063 0.053 0.041
 0.044 0.522 0.05  0.106 0.004 0.017]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (1.0, 1.0)
Objective function 9.09 = squared loss an data 7.37 + 0.5*rho*h**2 0.028307 + alpha*h 0.154771 + L2reg 0.38 + L1reg 1.14 + box penalty 0.03 ; SHD = 0 ; DAG True
Proportion of microbatches that were clipped  0.7725544137875232
iteration 1 in inner loop, alpha 65.04704177016936 rho 10000.0 h 0.0023793643885454685
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cpu
[0.008 0.325 0.004 0.059 0.045 0.066 0.048 0.041 0.052 1.32  0.187 0.089
 0.087 0.064 0.103 0.093 0.051 0.143 0.022 0.02  0.04  0.094 0.052 0.31
 0.089 0.085 0.202 1.017 0.059 0.123 0.349 0.065 0.098 0.115 0.098 0.16
 0.087 0.04  0.055 0.026 0.065 0.069 0.009 0.036 0.011 0.168 0.047 0.085
 0.071 0.099 0.093 0.052 0.075 0.133 0.06  0.057 0.035 0.061 0.106 0.114
 0.059 0.015 0.033 0.096 0.067 0.073 0.068 0.205 0.098 0.099 0.037 1.025
 0.111 0.07  0.065 0.055 0.14  0.058 0.725 0.099 0.616 0.063 0.053 0.041
 0.044 0.522 0.05  0.106 0.004 0.017]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (1.0, 1.0)
Objective function 9.35 = squared loss an data 7.37 + 0.5*rho*h**2 0.283069 + alpha*h 0.154771 + L2reg 0.38 + L1reg 1.14 + box penalty 0.03 ; SHD = 0 ; DAG True
total norm for a microbatch 2614.181340460255 clip 11.78710468671579
total norm for a microbatch 73.1767977248569 clip 48.5488030680947
total norm for a microbatch 53.062471703321975 clip 33.31959055748631
total norm for a microbatch 19.13896691958553 clip 19.900654594731677
total norm for a microbatch 10.545751875360514 clip 14.17626276390721
total norm for a microbatch 28.614914586069993 clip 12.834896683511476
total norm for a microbatch 9.765435472420988 clip 13.449968257848651
total norm for a microbatch 14.96292269189732 clip 13.573070638540756
total norm for a microbatch 12.221366495858616 clip 13.215763107259907
total norm for a microbatch 15.553410260890889 clip 14.600674421025081
total norm for a microbatch 13.465108992843906 clip 12.033499247982625
total norm for a microbatch 34.78189051867815 clip 11.971393899681804
total norm for a microbatch 16.466553632192547 clip 11.971393899681804
cpu
[0.003 0.422 0.003 0.036 0.035 0.066 0.027 0.053 0.035 1.589 0.191 0.06
 0.074 0.062 0.156 0.104 0.062 0.125 0.02  0.012 0.021 0.077 0.028 0.327
 0.071 0.021 0.042 1.05  0.051 0.152 0.189 0.08  0.149 0.15  0.117 0.208
 0.098 0.041 0.057 0.032 0.036 0.074 0.012 0.011 0.009 0.068 0.047 0.141
 0.057 0.133 0.122 0.097 0.033 0.152 0.033 0.029 0.016 0.024 0.073 0.052
 0.037 0.005 0.069 0.123 0.036 0.066 0.034 0.189 0.053 0.154 0.103 1.132
 0.075 0.034 0.113 0.038 0.275 0.098 0.789 0.032 0.719 0.071 0.028 0.053
 0.018 0.465 0.019 0.035 0.003 0.005]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9958847736625515, 0.9722222222222223)
Objective function 8.98 = squared loss an data 7.36 + 0.5*rho*h**2 0.060494 + alpha*h 0.071548 + L2reg 0.38 + L1reg 1.08 + box penalty 0.02 ; SHD = 1 ; DAG True
Proportion of microbatches that were clipped  0.7754264563887995
iteration 2 in inner loop, alpha 65.04704177016936 rho 100000.0 h 0.0010999476104913697
iteration 5 in outer loop, alpha = 1164.9946522615392, rho = 1000000.0, h = 0.0010999476104913697
Threshold 0.3
[[0.005 0.003 0.422 0.003 0.036 0.035 0.066 0.027 0.053 0.035]
 [1.589 0.006 0.191 0.06  0.074 0.062 0.156 0.104 0.062 0.125]
 [0.02  0.012 0.006 0.021 0.077 0.028 0.327 0.071 0.021 0.042]
 [1.05  0.051 0.152 0.004 0.189 0.08  0.149 0.15  0.117 0.208]
 [0.098 0.041 0.057 0.032 0.005 0.036 0.074 0.012 0.011 0.009]
 [0.068 0.047 0.141 0.057 0.133 0.004 0.122 0.097 0.033 0.152]
 [0.033 0.029 0.016 0.024 0.073 0.052 0.007 0.037 0.005 0.069]
 [0.123 0.036 0.066 0.034 0.189 0.053 0.154 0.005 0.103 1.132]
 [0.075 0.034 0.113 0.038 0.275 0.098 0.789 0.032 0.005 0.719]
 [0.071 0.028 0.053 0.018 0.465 0.019 0.035 0.003 0.005 0.005]]
[[0.    0.    0.422 0.    0.    0.    0.    0.    0.    0.   ]
 [1.589 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.327 0.    0.    0.   ]
 [1.05  0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    1.132]
 [0.    0.    0.    0.    0.    0.    0.789 0.    0.    0.719]
 [0.    0.    0.    0.    0.465 0.    0.    0.    0.    0.   ]]
{'fdr': 0.0, 'tpr': 0.8888888888888888, 'fpr': 0.0, 'f1': 0.9411764705882353, 'shd': 1, 'npred': 8, 'ntrue': 9}
[0.003 0.422 0.003 0.036 0.035 0.066 0.027 0.053 0.035 1.589 0.191 0.06
 0.074 0.062 0.156 0.104 0.062 0.125 0.02  0.012 0.021 0.077 0.028 0.327
 0.071 0.021 0.042 1.05  0.051 0.152 0.189 0.08  0.149 0.15  0.117 0.208
 0.098 0.041 0.057 0.032 0.036 0.074 0.012 0.011 0.009 0.068 0.047 0.141
 0.057 0.133 0.122 0.097 0.033 0.152 0.033 0.029 0.016 0.024 0.073 0.052
 0.037 0.005 0.069 0.123 0.036 0.066 0.034 0.189 0.053 0.154 0.103 1.132
 0.075 0.034 0.113 0.038 0.275 0.098 0.789 0.032 0.719 0.071 0.028 0.053
 0.018 0.465 0.019 0.035 0.003 0.005]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9958847736625515, 0.9722222222222223)
Iterations 2500
Achieves (13.610683049707138, 1e-05)-DP
