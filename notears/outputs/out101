samples  5000  graph  10 20 ER mim  minibatch size  50  noise  0.8  minibatches per NN training  250 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.2478778610411254
iteration 1 in outer loop, alpha = 1.2478778610411254, rho = 1.0, h = 1.2478778610411254
cuda
iteration 1 in inner loop,alpha 1.2478778610411254 rho 1.0 h 0.8084888745241194
iteration 2 in inner loop,alpha 1.2478778610411254 rho 10.0 h 0.33057833071344156
iteration 3 in inner loop,alpha 1.2478778610411254 rho 100.0 h 0.08917599829296385
iteration 2 in outer loop, alpha = 10.16547769033751, rho = 100.0, h = 0.08917599829296385
cuda
iteration 1 in inner loop,alpha 10.16547769033751 rho 100.0 h 0.04477612329798397
iteration 2 in inner loop,alpha 10.16547769033751 rho 1000.0 h 0.01475614729775998
iteration 3 in outer loop, alpha = 24.92162498809749, rho = 1000.0, h = 0.01475614729775998
cuda
iteration 1 in inner loop,alpha 24.92162498809749 rho 1000.0 h 0.006747604373583016
iteration 2 in inner loop,alpha 24.92162498809749 rho 10000.0 h 0.0009789684241319208
iteration 4 in outer loop, alpha = 34.7113092294167, rho = 10000.0, h = 0.0009789684241319208
cuda
iteration 1 in inner loop,alpha 34.7113092294167 rho 10000.0 h 0.0006091158976708755
iteration 2 in inner loop,alpha 34.7113092294167 rho 100000.0 h 0.0002643344431785266
iteration 5 in outer loop, alpha = 299.0457524079433, rho = 1000000.0, h = 0.0002643344431785266
Threshold 0.3
[[0.006 0.    0.001 0.    0.494 0.    0.08  0.001 0.    1.762]
 [2.827 0.006 0.58  0.    0.101 0.003 1.092 0.004 0.    1.022]
 [0.286 0.005 0.007 0.    0.09  0.003 1.2   0.01  0.    0.239]
 [1.805 2.982 1.104 0.    0.003 2.619 0.187 2.693 0.004 0.144]
 [0.    0.    0.001 0.    0.005 0.    0.002 0.001 0.    0.002]
 [0.392 0.278 0.724 0.    0.045 0.005 0.958 1.04  0.004 0.14 ]
 [0.012 0.001 0.002 0.    0.982 0.001 0.005 0.001 0.    0.019]
 [0.248 0.254 0.02  0.    0.01  0.001 0.248 0.002 0.006 0.035]
 [0.272 2.143 0.015 0.005 1.478 0.074 0.536 0.043 0.    0.085]
 [0.001 0.    0.002 0.    0.888 0.    0.055 0.001 0.    0.005]]
[[0.    0.    0.    0.    0.494 0.    0.    0.    0.    1.762]
 [2.827 0.    0.58  0.    0.    0.    1.092 0.    0.    1.022]
 [0.    0.    0.    0.    0.    0.    1.2   0.    0.    0.   ]
 [1.805 2.982 1.104 0.    0.    2.619 0.    2.693 0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.392 0.    0.724 0.    0.    0.    0.958 1.04  0.    0.   ]
 [0.    0.    0.    0.    0.982 0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    2.143 0.    0.    1.478 0.    0.536 0.    0.    0.   ]
 [0.    0.    0.    0.    0.888 0.    0.    0.    0.    0.   ]]
{'fdr': 0.09523809523809523, 'tpr': 0.95, 'fpr': 0.08, 'f1': 0.9268292682926829, 'shd': 2, 'npred': 21, 'ntrue': 20}
[2.089e-04 5.659e-04 1.724e-05 4.942e-01 8.761e-05 7.958e-02 5.795e-04
 1.600e-05 1.762e+00 2.827e+00 5.795e-01 6.121e-06 1.009e-01 3.262e-03
 1.092e+00 3.767e-03 5.929e-05 1.022e+00 2.857e-01 4.870e-03 5.859e-05
 8.977e-02 3.486e-03 1.200e+00 9.680e-03 7.257e-05 2.394e-01 1.805e+00
 2.982e+00 1.104e+00 3.242e-03 2.619e+00 1.873e-01 2.693e+00 3.590e-03
 1.436e-01 1.715e-04 1.642e-04 9.426e-04 3.184e-05 4.770e-04 1.793e-03
 5.271e-04 8.375e-05 1.865e-03 3.919e-01 2.785e-01 7.238e-01 9.559e-06
 4.514e-02 9.575e-01 1.040e+00 3.783e-03 1.403e-01 1.162e-02 1.100e-03
 1.837e-03 5.172e-06 9.821e-01 7.681e-04 1.237e-03 8.175e-05 1.865e-02
 2.478e-01 2.535e-01 1.976e-02 5.036e-07 9.612e-03 1.291e-03 2.476e-01
 5.891e-03 3.529e-02 2.720e-01 2.143e+00 1.521e-02 4.536e-03 1.478e+00
 7.416e-02 5.357e-01 4.333e-02 8.514e-02 9.830e-04 1.634e-04 2.188e-03
 1.584e-05 8.877e-01 3.237e-04 5.540e-02 8.919e-04 9.669e-06]
[[0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 1. 1. 0. 0. 1. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9657142857142857, 0.9419402177200167)
cuda
1210
cuda
Objective function 188.58 = squared loss an data 11.52 + 0.5*rho*h**2 176.710652 + alpha*h 0.000000 + L2reg 0.19 + L1reg 0.16 ; SHD = 55 ; DAG False
||w||^2 0.3089704968996317
exp ma of ||w||^2 0.27301120893093017
||w|| 0.5558511463509198
exp ma of ||w|| 0.49929434854569277
||w||^2 0.14229066180308356
exp ma of ||w||^2 0.2772749168669685
||w|| 0.37721434464119147
exp ma of ||w|| 0.4987619619762522
||w||^2 0.536923401227562
exp ma of ||w||^2 0.31287267513332473
||w|| 0.7327505723147284
exp ma of ||w|| 0.526781683112138
||w||^2 0.12037627987658917
exp ma of ||w||^2 0.29761121579237393
||w|| 0.3469528496447164
exp ma of ||w|| 0.518171877664325
||w||^2 0.3672472344884434
exp ma of ||w||^2 0.27907383450863055
||w|| 0.6060092693090127
exp ma of ||w|| 0.5040022434627615
cuda
Objective function 7.02 = squared loss an data 6.22 + 0.5*rho*h**2 0.503497 + alpha*h 0.000000 + L2reg 0.22 + L1reg 0.07 ; SHD = 24 ; DAG False
Proportion of microbatches that were clipped  0.7626462283178701
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 1.003491265671629
iteration 1 in outer loop, alpha = 1.003491265671629, rho = 1.0, h = 1.003491265671629
cuda
1210
cuda
Objective function 8.03 = squared loss an data 6.22 + 0.5*rho*h**2 0.503497 + alpha*h 1.006995 + L2reg 0.22 + L1reg 0.07 ; SHD = 24 ; DAG False
||w||^2 44399780.039884195
exp ma of ||w||^2 541278105.3076892
||w|| 6663.31599429925
exp ma of ||w|| 17409.155656815845
||w||^2 0.04379992049144959
exp ma of ||w||^2 54.37336996354101
||w|| 0.20928430541120274
exp ma of ||w|| 0.25476549465569587
||w||^2 0.17787961286352774
exp ma of ||w||^2 0.272896358429171
||w|| 0.4217577656232636
exp ma of ||w|| 0.47995697636604656
||w||^2 0.4349873280451443
exp ma of ||w||^2 0.25930584428385395
||w|| 0.6595356912594983
exp ma of ||w|| 0.4848540786016751
||w||^2 0.3781097512948963
exp ma of ||w||^2 0.2754543232373742
||w|| 0.6149062947270066
exp ma of ||w|| 0.49877174841954
||w||^2 0.6111477780671223
exp ma of ||w||^2 0.31992951568307365
||w|| 0.7817594118826598
exp ma of ||w|| 0.5287271426093637
||w||^2 0.023802276798187017
exp ma of ||w||^2 0.29589410803452226
||w|| 0.15427986517425732
exp ma of ||w|| 0.5075139392941913
||w||^2 0.8755033463787132
exp ma of ||w||^2 0.31815263637354585
||w|| 0.9356833579682355
exp ma of ||w|| 0.5294011374942549
cuda
Objective function 7.09 = squared loss an data 5.87 + 0.5*rho*h**2 0.189552 + alpha*h 0.617864 + L2reg 0.35 + L1reg 0.06 ; SHD = 13 ; DAG False
Proportion of microbatches that were clipped  0.7609101991060544
iteration 1 in inner loop, alpha 1.003491265671629 rho 1.0 h 0.6157144125015428
1210
cuda
Objective function 8.80 = squared loss an data 5.87 + 0.5*rho*h**2 1.895521 + alpha*h 0.617864 + L2reg 0.35 + L1reg 0.06 ; SHD = 13 ; DAG False
||w||^2 3633.620480186887
exp ma of ||w||^2 4492811.160438374
||w|| 60.27951957495089
exp ma of ||w|| 457.3137106350259
||w||^2 0.08855830535201355
exp ma of ||w||^2 65985.68472151854
||w|| 0.2975874751262451
exp ma of ||w|| 8.57274444375132
||w||^2 0.12343683778899811
exp ma of ||w||^2 0.7529123774315903
||w|| 0.35133579064621084
exp ma of ||w|| 0.3816766438001929
||w||^2 0.147806836984779
exp ma of ||w||^2 0.30580706490759874
||w|| 0.3844565475899442
exp ma of ||w|| 0.5122497253675984
||w||^2 0.21327085988691055
exp ma of ||w||^2 0.3382385350646307
||w|| 0.4618125809101681
exp ma of ||w|| 0.5417719796713154
||w||^2 0.07050802232325658
exp ma of ||w||^2 0.32010927354653973
||w|| 0.26553346742596606
exp ma of ||w|| 0.5216956345290835
||w||^2 0.058670199527654586
exp ma of ||w||^2 0.29827065846627476
||w|| 0.2422193211278873
exp ma of ||w|| 0.5101251720526301
||w||^2 0.1544390227387291
exp ma of ||w||^2 0.32092778395494026
||w|| 0.39298730607836313
exp ma of ||w|| 0.5285896617788663
||w||^2 0.3926698823156402
exp ma of ||w||^2 0.28467004290421544
||w|| 0.626633770487707
exp ma of ||w|| 0.4957875613040935
||w||^2 0.10373211780619637
exp ma of ||w||^2 0.2912331139505168
||w|| 0.3220747084236767
exp ma of ||w|| 0.4980216810320974
||w||^2 0.11029734142414346
exp ma of ||w||^2 0.3889590383449402
||w|| 0.3321104355845258
exp ma of ||w|| 0.5795292020772462
||w||^2 0.2822073524746508
exp ma of ||w||^2 0.32491764650692484
||w|| 0.5312319196684728
exp ma of ||w|| 0.5190279735841297
cuda
Objective function 7.50 = squared loss an data 6.39 + 0.5*rho*h**2 0.345556 + alpha*h 0.263808 + L2reg 0.45 + L1reg 0.05 ; SHD = 12 ; DAG True
Proportion of microbatches that were clipped  0.7624949698189135
iteration 2 in inner loop, alpha 1.003491265671629 rho 10.0 h 0.2628902482200459
1210
cuda
Objective function 10.61 = squared loss an data 6.39 + 0.5*rho*h**2 3.455564 + alpha*h 0.263808 + L2reg 0.45 + L1reg 0.05 ; SHD = 12 ; DAG True
||w||^2 0.4808032716581829
exp ma of ||w||^2 0.7168501693017453
||w|| 0.6933997920811505
exp ma of ||w|| 0.3995995872530379
||w||^2 0.06874439175338853
exp ma of ||w||^2 0.32726166423366304
||w|| 0.26219151731775864
exp ma of ||w|| 0.5315530432856784
||w||^2 1.0985536146875858
exp ma of ||w||^2 0.3042302625075364
||w|| 1.0481190842111339
exp ma of ||w|| 0.5174068413236595
v before min max tensor([[-6.848e-01, -2.882e-01, -6.879e-03, -7.783e-01, -8.859e-01, -6.573e-01,
         -1.446e+00, -9.180e-01, -6.891e-02, -8.326e-01],
        [ 9.631e-01, -6.926e-01,  1.514e-01, -6.289e-01, -1.386e+00, -5.246e-01,
         -4.820e-01,  9.585e-01, -6.146e-01, -3.217e-01],
        [-3.343e-01, -1.388e+00, -3.278e-01, -1.440e+00,  1.927e+00,  4.108e+00,
         -1.155e+00,  1.537e-01, -2.679e-02, -4.656e-01],
        [-5.755e-01, -1.765e+00, -2.224e-02, -1.743e+00,  5.287e-01, -2.565e-02,
          1.796e+00, -1.021e+00,  1.614e+00,  3.613e-01],
        [-1.780e+00,  3.058e-01, -6.931e-01, -7.898e-01,  5.458e-02, -1.134e+00,
         -9.776e-01, -6.962e-01, -6.640e-01,  8.760e+00],
        [-2.043e+00, -8.631e-01, -1.635e+00, -1.076e+00,  7.159e-01, -7.287e-01,
          2.566e+00, -6.923e-01,  8.935e-01, -1.156e+00],
        [-8.287e-01,  9.079e-01,  1.379e-01,  1.790e+00,  1.428e+00, -5.848e-01,
          3.144e+00,  1.713e-01, -2.616e-01, -1.219e+00],
        [-1.066e+00, -1.040e+00, -7.953e-01, -1.045e+00, -1.505e+00, -1.194e+00,
         -1.096e+00,  1.085e+00, -8.939e-01,  5.881e-02],
        [ 9.556e+00,  2.330e+00, -1.422e-01, -4.151e-01,  4.342e-01,  3.379e+00,
         -1.825e+00, -2.290e+00, -6.968e-01, -3.224e-02],
        [ 8.355e-01, -8.869e-01, -1.653e+00, -2.899e-02, -7.613e-01,  4.045e+00,
          3.094e+00,  7.814e-01, -4.334e-01, -1.117e+00],
        [ 6.198e+00, -1.358e+00, -1.047e+00, -1.447e-01,  1.280e+00, -1.187e+00,
         -1.236e+00, -1.242e-01, -1.328e+00, -1.646e+00],
        [-2.046e-01, -6.504e-01, -4.935e-02, -2.624e+00,  5.343e-01, -5.194e-01,
          7.470e+00,  7.078e-04, -3.029e-01, -2.113e-01],
        [-1.282e+00,  5.193e+00, -5.904e-01, -1.719e+00, -7.034e-01,  3.027e-01,
          1.634e+00,  2.889e-01, -4.192e-01, -1.511e+00],
        [ 4.956e+00, -1.095e+00, -1.015e+00, -6.058e-01, -1.317e+00, -8.850e-01,
          6.579e-01,  5.572e-01,  2.408e+00, -8.172e-01],
        [ 1.365e-01, -1.133e+00, -1.184e+00, -1.166e+00, -8.513e-01, -6.468e-01,
         -1.138e+00, -3.224e-01,  1.472e+00, -1.014e-01],
        [-7.089e-01,  6.008e-01, -3.129e-01,  1.498e+00, -1.075e+00, -1.311e+00,
         -3.769e-02, -1.658e+00, -4.638e-01, -5.716e-01],
        [-1.348e+00,  2.005e-01,  9.644e-01,  2.863e+00,  3.673e+00, -1.089e+00,
         -1.270e+00, -4.899e-01,  3.481e+00,  3.069e-01],
        [-1.101e+00, -4.161e-01, -1.051e+00, -1.222e+00, -1.131e+00,  3.126e-01,
         -1.238e+00, -6.534e-01, -5.361e-01, -9.099e-01],
        [-7.720e-01, -1.694e+00,  1.576e+00, -8.938e-01, -1.817e+00,  1.296e-01,
         -1.042e+00,  3.795e-02, -8.610e-01,  7.049e-01],
        [-4.066e-01, -8.690e-01, -6.789e-01,  3.292e+00, -6.133e-01, -1.665e-01,
         -1.375e+00,  2.634e-01, -1.663e+00, -9.031e-01],
        [-1.047e+00, -1.314e+00, -1.029e+00,  2.800e-01,  1.229e+00, -1.212e+00,
         -2.109e-01, -9.340e-01, -7.795e-01,  2.659e-01],
        [-1.334e+00, -8.590e-01,  2.432e+00, -3.996e-01,  7.459e-02, -1.270e+00,
          2.824e-02, -6.623e-01,  6.373e-01, -2.145e-01],
        [ 3.726e+00, -1.285e+00,  1.999e+00,  2.754e-01,  2.874e-01, -1.022e+00,
         -1.056e+00, -9.017e-01, -4.680e-01,  6.989e+00],
        [-7.185e-01, -3.350e-01,  1.666e-01, -6.673e-01, -5.600e-01, -1.002e+00,
         -8.562e-01,  9.004e-01, -6.747e-02,  6.275e-01],
        [-1.717e+00, -8.062e-01, -9.093e-01,  3.577e-01, -9.109e-01, -6.716e-01,
         -4.077e-01,  2.841e+00, -1.340e+00,  3.503e+00],
        [-5.210e-01, -5.198e-01,  2.557e+00, -4.060e-01,  2.185e+00, -5.409e-01,
         -6.553e-01, -8.113e-01,  1.567e+00, -1.275e+00],
        [ 2.392e+00, -7.656e-01, -6.096e-01, -7.450e-02,  3.143e-01,  2.723e-01,
         -9.257e-01, -1.054e+00, -4.520e-01, -1.276e+00],
        [ 1.016e+01,  4.363e+00, -4.140e-01, -4.866e-01, -7.209e-02, -1.253e+00,
          6.169e+00, -1.118e+00, -1.205e+00,  4.075e-01],
        [-5.056e-01, -7.785e-01, -2.351e+00, -6.803e-01, -1.043e+00, -5.332e-01,
          1.059e+00, -2.806e-01, -1.096e+00,  4.815e-01],
        [-5.127e-01,  1.904e-01, -1.602e+00,  3.675e+00, -4.276e-01, -7.460e-01,
         -1.058e-01,  2.985e-01, -4.942e-01, -1.403e+00],
        [ 2.937e-01, -1.023e+00, -1.282e+00, -5.323e-01, -1.243e+00, -1.507e+00,
         -5.753e-01, -2.248e-01,  1.491e+00, -4.051e-01],
        [-6.767e-01, -1.345e-02, -5.344e-01, -1.296e+00,  7.308e-01,  6.325e-02,
          2.277e-01,  1.262e-01, -5.879e-01,  6.508e-01],
        [-9.361e-01, -8.728e-01,  1.129e+00, -4.598e-01, -1.617e+00, -8.377e-01,
         -4.647e-01, -9.824e-01,  2.397e-01, -6.263e-01],
        [-7.671e-01,  5.498e-01, -8.723e-01, -1.464e+00, -4.516e-01, -1.671e+00,
         -1.226e+00,  3.031e+00, -4.583e-01, -1.499e+00],
        [ 1.128e+00,  1.486e+00, -1.166e+00, -4.591e-01, -1.209e+00, -5.241e-01,
         -1.878e+00, -3.197e-01, -1.425e+00, -1.743e+00],
        [-1.220e+00,  3.188e-01, -4.130e-01, -1.581e+00, -9.737e-02,  1.701e-01,
         -4.493e-01, -1.062e+00, -9.125e-01, -8.008e-01],
        [-5.540e-01, -1.166e+00, -1.325e+00,  5.201e+00, -9.821e-01, -1.433e+00,
         -5.527e-01, -1.059e-01, -6.833e-01,  2.576e-01],
        [-2.971e-01,  3.263e+00, -1.076e+00, -6.746e-01, -6.139e-01, -6.630e-01,
         -8.936e-01, -7.020e-01,  3.803e+00,  6.152e-02],
        [ 9.900e-01,  3.433e+00,  6.944e-01, -1.429e+00, -1.072e+00, -7.366e-01,
         -7.886e-01, -6.690e-01, -1.765e+00, -5.114e-01],
        [-1.455e+00, -1.367e+00,  3.808e-01,  2.618e-03,  6.873e-01,  2.133e-01,
          6.478e-01, -1.142e+00,  1.284e+00,  1.067e+00],
        [-7.413e-01,  2.878e-01,  1.401e+00, -1.301e+00, -7.347e-01, -6.817e-01,
         -1.121e+00, -4.380e-01, -5.798e-01, -1.304e+00],
        [ 6.651e+00, -1.515e+00,  1.213e+00,  2.421e-02, -1.956e+00, -4.615e-02,
          8.214e-01,  1.109e+00,  4.722e+00,  9.193e-01],
        [-4.107e-01, -4.534e-01, -9.375e-01, -9.749e-01,  6.143e-01, -2.695e-01,
         -4.769e-01, -1.178e+00,  4.531e+00, -6.541e-01],
        [-6.840e-01,  1.759e+00,  8.340e-01,  1.365e-01, -6.753e-01, -8.424e-02,
         -2.792e-01, -1.111e+00,  1.584e+00, -9.522e-01],
        [ 5.550e-01, -8.920e-01, -3.055e-01, -7.930e-01,  4.781e-02,  1.501e+00,
         -6.846e-01,  8.178e-02, -8.207e-01, -5.800e-01],
        [ 3.160e-01, -1.297e+00,  1.113e-01, -5.786e-01, -1.490e+00, -1.577e+00,
          2.699e-01,  1.620e+00, -7.962e-01, -1.202e+00],
        [-1.163e+00,  2.296e+01, -4.599e-01, -4.756e-01, -1.369e+00, -3.382e-01,
          2.358e-01, -1.563e+00, -1.660e-01,  3.283e-02],
        [ 1.160e-01,  9.026e-01,  1.088e+00, -1.612e+00, -3.717e-01, -6.490e-01,
          1.810e-01,  9.162e-01, -4.041e-01, -7.224e-01],
        [-1.701e+00,  3.052e+00,  8.863e-01, -6.424e-01, -1.479e+00,  3.812e+00,
         -1.323e+00, -6.694e-01, -2.178e-01,  7.966e-01],
        [-5.599e-01, -5.794e-01, -1.320e+00,  2.054e+00, -1.287e+00,  7.443e-01,
          7.893e-01,  4.883e-01,  9.249e+00,  4.163e-01],
        [-7.340e-01, -1.252e+00, -6.263e-01, -8.710e-02, -1.793e+00,  4.992e+00,
         -1.362e+00, -5.310e-01,  6.290e-01, -1.233e+00],
        [-1.095e+00, -1.764e+00, -1.044e+00, -7.574e-01, -1.351e+00, -4.459e-01,
          2.805e-01,  2.278e+00, -9.519e-01,  2.224e-01],
        [ 7.783e+00,  2.413e-01,  8.204e-01,  2.658e+00, -1.063e+00,  4.693e-01,
         -1.544e+00, -2.872e-01, -6.410e-01,  1.662e+00],
        [-1.161e+00, -1.203e+00, -2.123e+00, -2.796e-01, -8.541e-01, -9.646e-01,
          3.724e+00,  2.930e-01,  6.247e-01, -2.765e-01],
        [-1.208e+00,  5.559e-02, -1.128e+00,  3.080e-01, -2.700e-01, -1.876e+00,
         -1.646e+00,  4.468e-01, -4.010e-01,  4.111e+00],
        [-4.136e-01, -1.253e+00, -9.458e-01, -9.291e-01, -5.138e-01,  4.057e+00,
          3.750e-01, -1.888e-01,  2.245e-01, -1.183e+00],
        [ 6.114e-01, -1.263e+00,  1.801e-01, -1.307e+00,  1.350e+00, -1.156e+00,
         -1.403e+00,  1.363e+00, -9.776e-01, -5.424e-01],
        [-1.105e+00, -9.556e-01, -2.101e+00, -1.067e+00,  3.699e-01, -7.123e-01,
         -1.023e+00,  5.155e-01, -6.354e-01,  6.978e-01],
        [-7.583e-01, -8.782e-01, -1.099e+00,  1.124e+00,  1.780e-01,  2.026e+00,
          1.889e+00, -1.395e+00,  3.187e-01,  1.236e-01],
        [ 2.102e+00, -1.487e+00,  4.162e+00, -1.841e+00, -7.103e-01,  3.769e+00,
         -1.372e+00, -3.868e-02, -2.227e-01, -1.066e+00],
        [ 8.615e-01,  5.706e+00, -9.861e-01, -1.012e+00,  2.031e+00,  2.559e-01,
         -1.096e+00,  4.052e+00, -7.338e-01, -2.299e-01],
        [-1.972e+00, -6.754e-01,  8.205e+00, -5.114e-01,  1.045e+00, -3.587e-02,
         -1.738e+00, -6.377e-01, -6.985e-01, -5.075e-01],
        [ 1.324e+00, -8.486e-01, -3.405e-01, -1.406e+00,  7.554e-01, -1.460e+00,
          4.100e+00, -1.458e-02, -5.584e-01,  8.048e-01],
        [-1.977e-01, -1.335e+00, -7.602e-01, -1.170e+00, -4.890e-01, -1.071e-01,
         -1.850e+00, -1.781e-01, -7.355e-01,  4.858e-01],
        [ 3.015e-02, -1.632e+00, -1.816e+00, -6.915e-02, -1.013e+00, -1.603e+00,
          9.414e-01, -1.128e+00, -1.305e+00, -3.419e-01],
        [ 5.793e+00, -1.097e+00, -1.006e+00, -5.155e-01,  1.195e+00, -9.155e-01,
         -1.407e+00,  1.685e-01,  2.420e+00,  1.709e-01],
        [-1.793e+00, -1.483e+00, -1.239e-01,  5.595e-01, -8.779e-01, -5.621e-01,
          1.063e+00,  5.370e+00, -8.705e-01, -1.234e+00],
        [ 8.716e+00,  2.318e+00,  1.338e+00,  2.511e-01,  2.320e+00, -1.328e+00,
         -6.090e-01, -1.373e+00,  6.769e-01, -1.210e-01],
        [ 2.050e+00,  4.382e+00, -1.337e+00, -4.908e-01,  4.240e+00, -9.062e-01,
          1.452e+01,  2.479e-01,  3.181e-01, -2.253e+00],
        [-1.083e+00, -1.167e+00, -2.987e-01,  1.752e+00,  6.177e-01, -1.061e+00,
          6.914e-01, -7.904e-01, -1.285e+00, -9.384e-01],
        [-6.713e-01, -2.155e-01, -6.143e-01,  1.267e+00,  2.638e+00, -1.161e+00,
         -1.396e+00,  5.212e-01, -9.969e-01, -1.089e+00],
        [ 1.314e+00,  6.789e-01, -9.125e-01, -1.124e+00,  4.336e-01, -5.938e-01,
          6.781e-01, -2.048e+00,  1.516e+00, -1.485e+00],
        [-5.192e-01, -5.192e-01, -6.765e-01, -5.697e-01, -9.601e-01,  1.821e+00,
         -1.000e+00, -8.360e-01,  4.966e+00, -5.187e-01],
        [ 5.471e+00,  2.859e-01, -8.168e-01, -3.327e-01,  1.504e+00, -1.814e+00,
         -1.659e+00, -1.189e+00, -9.831e-01, -7.866e-01],
        [-4.465e-01,  4.191e-01,  5.005e+00,  1.200e+00, -9.536e-01, -2.220e+00,
         -4.507e-01, -5.095e-01, -1.213e+00,  5.965e-02],
        [-8.536e-01, -3.705e-01,  4.196e-01, -7.076e-01, -6.270e-01,  4.002e-01,
         -8.161e-01, -1.380e+00,  1.444e+00, -6.796e-01],
        [-1.550e+00, -6.677e-01,  2.585e+00, -5.897e-01,  1.333e-01, -1.598e+00,
         -4.738e-01,  7.450e-01,  2.530e+00, -9.124e-01],
        [-9.574e-01, -7.470e-01,  1.441e+00, -2.487e-01, -1.317e+00, -1.163e+00,
         -1.781e+00,  1.569e+00, -1.597e+00, -8.758e-01],
        [-5.254e-01, -1.340e+00,  4.359e+00, -3.943e-01,  7.764e-02,  1.762e+00,
         -1.040e+00, -6.948e-01,  5.536e+00, -1.864e+00],
        [ 3.589e-01, -1.674e+00, -9.173e-02, -4.263e-01, -1.138e+00, -7.485e-01,
         -1.296e-01,  1.480e+00,  7.803e-01, -8.132e-01],
        [ 3.306e+00,  9.296e-01,  2.342e+00, -8.260e-01, -6.416e-01, -5.400e-01,
          2.839e-01,  8.424e-01, -1.376e+00,  7.606e-01],
        [ 4.412e+00,  3.810e+00,  4.162e+00, -5.414e-01, -3.633e-01,  1.382e+00,
         -1.940e+00,  7.209e-01, -1.188e+00, -4.870e-01],
        [-1.136e+00, -1.163e+00,  1.193e-01,  1.283e+00,  2.052e-02, -1.172e+00,
         -7.894e-01,  1.225e-02,  2.188e-01, -7.838e-01],
        [-2.668e-01,  6.365e-01,  2.373e+00, -1.887e+00,  4.525e+00,  9.251e-01,
         -9.811e-01, -1.467e+00, -7.506e-01,  1.448e+00],
        [-1.150e+00,  2.004e-01, -1.584e-01, -1.015e+00, -1.459e+00,  1.064e+01,
         -9.541e-01, -7.105e-02, -1.371e+00, -8.446e-01],
        [ 4.478e-02, -5.076e-01,  2.857e-02,  7.715e-01,  5.242e-01,  3.213e+00,
         -4.279e-01,  2.020e+00, -1.025e+00,  1.925e-01],
        [-1.763e-01, -4.819e-01,  2.877e-01, -9.756e-01, -5.203e-01, -3.984e-01,
         -5.694e-01, -1.805e-01, -9.997e-01,  5.826e+00],
        [-1.036e+00, -1.413e+00,  1.309e-01,  1.944e+00, -2.390e+00, -2.194e-01,
         -5.592e-01, -6.038e-01, -6.159e-01,  6.620e+00],
        [-9.418e-01,  2.761e-01, -1.523e-01,  1.170e-01, -6.971e-01,  1.114e+00,
         -1.288e+00,  4.298e-01,  1.299e+00, -5.752e-01],
        [-1.650e+00, -1.279e+00, -9.863e-02, -1.087e+00, -4.319e-01, -7.193e-01,
         -6.249e-01, -7.026e-01,  1.561e+00,  9.261e-02],
        [-2.571e-01, -1.461e+00, -6.441e-01, -7.415e-01, -2.390e+00, -1.480e+00,
         -9.212e-01, -1.451e+00, -4.991e-01, -1.940e+00],
        [ 1.100e+01,  1.255e-01,  6.959e-01, -1.358e+00, -7.528e-01, -1.021e+00,
          4.048e-02,  2.294e+00,  1.425e-01,  4.119e+00],
        [-3.140e-01, -1.567e+00, -4.056e-01, -2.866e-01, -5.739e-01, -1.044e+00,
         -1.071e+00,  5.431e-01,  6.621e+00, -1.095e+00],
        [-1.800e+00, -9.844e-02, -6.384e-01,  6.628e-01, -4.794e-01, -9.500e-01,
         -2.286e+00,  1.088e+01, -9.260e-01, -1.545e+00],
        [-1.114e+00, -8.505e-01,  3.050e+00,  9.157e-02,  1.489e+00, -1.336e+00,
          3.693e+00,  2.199e-01,  2.973e+00, -1.235e+00],
        [ 6.575e-01, -1.146e+00, -1.008e+00,  2.286e+00,  9.466e+00, -8.051e-01,
         -8.333e-01, -4.411e-01, -1.039e+00,  3.628e+00],
        [ 1.045e+01, -8.895e-01,  6.362e-01, -1.207e+00, -2.609e-01, -4.372e-01,
         -9.264e-01, -9.612e-01, -7.155e-01,  8.580e-01],
        [ 9.153e-01,  8.645e-02,  4.775e-01, -1.311e+00,  6.367e-01,  3.064e-01,
         -4.501e-01, -1.146e+00, -4.514e-01, -1.186e+00],
        [-9.978e-01,  8.344e-01,  1.085e+01,  9.233e-01, -8.407e-01,  8.467e-01,
         -8.469e-01, -6.544e-01,  2.671e+00, -6.620e-01],
        [-1.324e+00,  6.011e-01,  1.695e+00, -1.017e+00,  1.297e+00,  4.536e+00,
         -4.414e-01,  1.678e+00,  8.115e-01,  4.965e+00]], device='cuda:0')
v tensor([[1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [9.631e-01, 1.000e-12, 1.514e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 9.585e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.927e+00, 4.108e+00,
         1.000e-12, 1.537e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.287e-01, 1.000e-12,
         1.796e+00, 1.000e-12, 1.614e+00, 3.613e-01],
        [1.000e-12, 3.058e-01, 1.000e-12, 1.000e-12, 5.458e-02, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 8.760e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 7.159e-01, 1.000e-12,
         2.566e+00, 1.000e-12, 8.935e-01, 1.000e-12],
        [1.000e-12, 9.079e-01, 1.379e-01, 1.790e+00, 1.428e+00, 1.000e-12,
         3.144e+00, 1.713e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.085e+00, 1.000e-12, 5.881e-02],
        [9.556e+00, 2.330e+00, 1.000e-12, 1.000e-12, 4.342e-01, 3.379e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [8.355e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 4.045e+00,
         3.094e+00, 7.814e-01, 1.000e-12, 1.000e-12],
        [6.198e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.280e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.343e-01, 1.000e-12,
         7.470e+00, 7.078e-04, 1.000e-12, 1.000e-12],
        [1.000e-12, 5.193e+00, 1.000e-12, 1.000e-12, 1.000e-12, 3.027e-01,
         1.634e+00, 2.889e-01, 1.000e-12, 1.000e-12],
        [4.956e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         6.579e-01, 5.572e-01, 2.408e+00, 1.000e-12],
        [1.365e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.472e+00, 1.000e-12],
        [1.000e-12, 6.008e-01, 1.000e-12, 1.498e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 2.005e-01, 9.644e-01, 2.863e+00, 3.673e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 3.481e+00, 3.069e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.126e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.576e+00, 1.000e-12, 1.000e-12, 1.296e-01,
         1.000e-12, 3.795e-02, 1.000e-12, 7.049e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 3.292e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 2.634e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 2.800e-01, 1.229e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 2.659e-01],
        [1.000e-12, 1.000e-12, 2.432e+00, 1.000e-12, 7.459e-02, 1.000e-12,
         2.824e-02, 1.000e-12, 6.373e-01, 1.000e-12],
        [3.726e+00, 1.000e-12, 1.999e+00, 2.754e-01, 2.874e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 6.989e+00],
        [1.000e-12, 1.000e-12, 1.666e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 9.004e-01, 1.000e-12, 6.275e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 3.577e-01, 1.000e-12, 1.000e-12,
         1.000e-12, 2.841e+00, 1.000e-12, 3.503e+00],
        [1.000e-12, 1.000e-12, 2.557e+00, 1.000e-12, 2.185e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.567e+00, 1.000e-12],
        [2.392e+00, 1.000e-12, 1.000e-12, 1.000e-12, 3.143e-01, 2.723e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e+01, 4.363e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         6.169e+00, 1.000e-12, 1.000e-12, 4.075e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.059e+00, 1.000e-12, 1.000e-12, 4.815e-01],
        [1.000e-12, 1.904e-01, 1.000e-12, 3.675e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 2.985e-01, 1.000e-12, 1.000e-12],
        [2.937e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.491e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 7.308e-01, 6.325e-02,
         2.277e-01, 1.262e-01, 1.000e-12, 6.508e-01],
        [1.000e-12, 1.000e-12, 1.129e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 2.397e-01, 1.000e-12],
        [1.000e-12, 5.498e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 3.031e+00, 1.000e-12, 1.000e-12],
        [1.128e+00, 1.486e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 3.188e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.701e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 5.201e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 2.576e-01],
        [1.000e-12, 3.263e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 3.803e+00, 6.152e-02],
        [9.900e-01, 3.433e+00, 6.944e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 3.808e-01, 2.618e-03, 6.873e-01, 2.133e-01,
         6.478e-01, 1.000e-12, 1.284e+00, 1.067e+00],
        [1.000e-12, 2.878e-01, 1.401e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [6.651e+00, 1.000e-12, 1.213e+00, 2.421e-02, 1.000e-12, 1.000e-12,
         8.214e-01, 1.109e+00, 4.722e+00, 9.193e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 6.143e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 4.531e+00, 1.000e-12],
        [1.000e-12, 1.759e+00, 8.340e-01, 1.365e-01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.584e+00, 1.000e-12],
        [5.550e-01, 1.000e-12, 1.000e-12, 1.000e-12, 4.781e-02, 1.501e+00,
         1.000e-12, 8.178e-02, 1.000e-12, 1.000e-12],
        [3.160e-01, 1.000e-12, 1.113e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         2.699e-01, 1.620e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         2.358e-01, 1.000e-12, 1.000e-12, 3.283e-02],
        [1.160e-01, 9.026e-01, 1.088e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         1.810e-01, 9.162e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 3.052e+00, 8.863e-01, 1.000e-12, 1.000e-12, 3.812e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 7.966e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 2.054e+00, 1.000e-12, 7.443e-01,
         7.893e-01, 4.883e-01, 9.249e+00, 4.163e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 4.992e+00,
         1.000e-12, 1.000e-12, 6.290e-01, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         2.805e-01, 2.278e+00, 1.000e-12, 2.224e-01],
        [7.783e+00, 2.413e-01, 8.204e-01, 2.658e+00, 1.000e-12, 4.693e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.662e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         3.724e+00, 2.930e-01, 6.247e-01, 1.000e-12],
        [1.000e-12, 5.559e-02, 1.000e-12, 3.080e-01, 1.000e-12, 1.000e-12,
         1.000e-12, 4.468e-01, 1.000e-12, 4.111e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 4.057e+00,
         3.750e-01, 1.000e-12, 2.245e-01, 1.000e-12],
        [6.114e-01, 1.000e-12, 1.801e-01, 1.000e-12, 1.350e+00, 1.000e-12,
         1.000e-12, 1.363e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.699e-01, 1.000e-12,
         1.000e-12, 5.155e-01, 1.000e-12, 6.978e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.124e+00, 1.780e-01, 2.026e+00,
         1.889e+00, 1.000e-12, 3.187e-01, 1.236e-01],
        [2.102e+00, 1.000e-12, 4.162e+00, 1.000e-12, 1.000e-12, 3.769e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [8.615e-01, 5.706e+00, 1.000e-12, 1.000e-12, 2.031e+00, 2.559e-01,
         1.000e-12, 4.052e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 8.205e+00, 1.000e-12, 1.045e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.324e+00, 1.000e-12, 1.000e-12, 1.000e-12, 7.554e-01, 1.000e-12,
         4.100e+00, 1.000e-12, 1.000e-12, 8.048e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 4.858e-01],
        [3.015e-02, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         9.414e-01, 1.000e-12, 1.000e-12, 1.000e-12],
        [5.793e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.195e+00, 1.000e-12,
         1.000e-12, 1.685e-01, 2.420e+00, 1.709e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 5.595e-01, 1.000e-12, 1.000e-12,
         1.063e+00, 5.370e+00, 1.000e-12, 1.000e-12],
        [8.716e+00, 2.318e+00, 1.338e+00, 2.511e-01, 2.320e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 6.769e-01, 1.000e-12],
        [2.050e+00, 4.382e+00, 1.000e-12, 1.000e-12, 4.240e+00, 1.000e-12,
         1.000e+01, 2.479e-01, 3.181e-01, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.752e+00, 6.177e-01, 1.000e-12,
         6.914e-01, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.267e+00, 2.638e+00, 1.000e-12,
         1.000e-12, 5.212e-01, 1.000e-12, 1.000e-12],
        [1.314e+00, 6.789e-01, 1.000e-12, 1.000e-12, 4.336e-01, 1.000e-12,
         6.781e-01, 1.000e-12, 1.516e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.821e+00,
         1.000e-12, 1.000e-12, 4.966e+00, 1.000e-12],
        [5.471e+00, 2.859e-01, 1.000e-12, 1.000e-12, 1.504e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 4.191e-01, 5.005e+00, 1.200e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 5.965e-02],
        [1.000e-12, 1.000e-12, 4.196e-01, 1.000e-12, 1.000e-12, 4.002e-01,
         1.000e-12, 1.000e-12, 1.444e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 2.585e+00, 1.000e-12, 1.333e-01, 1.000e-12,
         1.000e-12, 7.450e-01, 2.530e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.441e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.569e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 4.359e+00, 1.000e-12, 7.764e-02, 1.762e+00,
         1.000e-12, 1.000e-12, 5.536e+00, 1.000e-12],
        [3.589e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.480e+00, 7.803e-01, 1.000e-12],
        [3.306e+00, 9.296e-01, 2.342e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         2.839e-01, 8.424e-01, 1.000e-12, 7.606e-01],
        [4.412e+00, 3.810e+00, 4.162e+00, 1.000e-12, 1.000e-12, 1.382e+00,
         1.000e-12, 7.209e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.193e-01, 1.283e+00, 2.052e-02, 1.000e-12,
         1.000e-12, 1.225e-02, 2.188e-01, 1.000e-12],
        [1.000e-12, 6.365e-01, 2.373e+00, 1.000e-12, 4.525e+00, 9.251e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.448e+00],
        [1.000e-12, 2.004e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [4.478e-02, 1.000e-12, 2.857e-02, 7.715e-01, 5.242e-01, 3.213e+00,
         1.000e-12, 2.020e+00, 1.000e-12, 1.925e-01],
        [1.000e-12, 1.000e-12, 2.877e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 5.826e+00],
        [1.000e-12, 1.000e-12, 1.309e-01, 1.944e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 6.620e+00],
        [1.000e-12, 2.761e-01, 1.000e-12, 1.170e-01, 1.000e-12, 1.114e+00,
         1.000e-12, 4.298e-01, 1.299e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.561e+00, 9.261e-02],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.255e-01, 6.959e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         4.048e-02, 2.294e+00, 1.425e-01, 4.119e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 5.431e-01, 6.621e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 6.628e-01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 3.050e+00, 9.157e-02, 1.489e+00, 1.000e-12,
         3.693e+00, 2.199e-01, 2.973e+00, 1.000e-12],
        [6.575e-01, 1.000e-12, 1.000e-12, 2.286e+00, 9.466e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 3.628e+00],
        [1.000e+01, 1.000e-12, 6.362e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 8.580e-01],
        [9.153e-01, 8.645e-02, 4.775e-01, 1.000e-12, 6.367e-01, 3.064e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 8.344e-01, 1.000e+01, 9.233e-01, 1.000e-12, 8.467e-01,
         1.000e-12, 1.000e-12, 2.671e+00, 1.000e-12],
        [1.000e-12, 6.011e-01, 1.695e+00, 1.000e-12, 1.297e+00, 4.536e+00,
         1.000e-12, 1.678e+00, 8.115e-01, 4.965e+00]], device='cuda:0')
v before min max tensor([ 0.214, -0.627, -1.625,  0.660, -1.274,  0.172, -0.357, -0.767, -0.796,
        -0.645, -0.663,  0.505,  0.170, -0.898,  0.319,  2.836, -2.120,  0.065,
         1.634,  1.750, -0.715, -0.014, -1.373, -0.720, -1.125, -0.626, -1.112,
        -1.087,  1.051, -0.231, -1.792, -2.175, -1.360,  0.072, -0.585, -0.919,
        -0.185,  4.343, -0.835, -2.180, -1.516, -0.816, -1.032, -1.204, -1.142,
         1.433, -1.375, -0.404, -1.286,  4.147, -0.512, -1.128, -0.814, -1.055,
        -0.357, -1.094,  0.575, -0.375,  1.805, -1.545, -0.097, -0.299, -0.443,
        -0.794, -1.451, -1.209,  0.415, -1.472,  1.347, -1.244, -0.666, -1.301,
        -0.520, -0.956, -1.591, -0.797, -1.049, -0.695, -0.956,  1.325, -0.198,
         0.231,  0.363, -0.894, -1.223,  0.052,  0.644, -0.965,  3.842, -1.765,
        -1.853, -0.900, -0.764, -1.068, -0.574, -0.317, -1.272, -0.879,  0.515,
        -0.431], device='cuda:0')
v tensor([2.135e-01, 1.000e-12, 1.000e-12, 6.602e-01, 1.000e-12, 1.716e-01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.049e-01,
        1.698e-01, 1.000e-12, 3.192e-01, 2.836e+00, 1.000e-12, 6.546e-02,
        1.634e+00, 1.750e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.051e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 7.249e-02, 1.000e-12, 1.000e-12,
        1.000e-12, 4.343e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.433e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 4.147e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 5.746e-01, 1.000e-12, 1.805e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        4.147e-01, 1.000e-12, 1.347e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.325e+00, 1.000e-12, 2.312e-01, 3.634e-01, 1.000e-12,
        1.000e-12, 5.173e-02, 6.440e-01, 1.000e-12, 3.842e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 5.146e-01, 1.000e-12], device='cuda:0')
v before min max tensor([[[ 2.464e-01],
         [-1.010e+00],
         [-5.234e-01],
         [ 1.138e+01],
         [-5.630e-01],
         [ 2.199e-01],
         [ 1.407e+00],
         [-7.956e-01],
         [ 2.780e-01],
         [ 1.803e-01]],

        [[-1.286e+00],
         [-1.788e-01],
         [-1.958e+00],
         [ 1.282e+00],
         [ 4.124e-01],
         [-4.637e-01],
         [-1.467e+00],
         [ 1.006e+00],
         [-1.719e+00],
         [ 4.961e+00]],

        [[-1.351e+00],
         [-1.388e+00],
         [ 8.418e-01],
         [-6.432e-01],
         [-9.293e-01],
         [-7.768e-01],
         [-1.227e+00],
         [-6.087e-01],
         [ 7.717e+00],
         [-1.476e+00]],

        [[ 1.356e+00],
         [ 1.940e+00],
         [ 4.155e-01],
         [-1.082e+00],
         [-1.163e+00],
         [ 2.874e+00],
         [-2.184e+00],
         [-1.349e+00],
         [ 1.485e+00],
         [ 4.080e-01]],

        [[-2.903e-02],
         [ 4.188e-02],
         [-5.459e-03],
         [ 2.443e-02],
         [ 1.126e+00],
         [-1.411e+00],
         [-8.441e-01],
         [-2.438e-01],
         [-7.201e-01],
         [-8.035e-01]],

        [[-1.113e+00],
         [-8.328e-01],
         [-6.755e-01],
         [ 5.658e-01],
         [-7.999e-01],
         [-1.165e+00],
         [ 8.066e-01],
         [-2.107e+00],
         [-1.091e-01],
         [ 3.090e+00]],

        [[-7.923e-01],
         [-8.813e-01],
         [ 2.174e+00],
         [-4.197e-01],
         [ 4.566e-01],
         [-4.489e-01],
         [ 3.816e-01],
         [-1.281e+00],
         [-6.452e-01],
         [-1.800e+00]],

        [[ 3.069e-01],
         [-2.389e+00],
         [-1.041e-01],
         [-9.013e-01],
         [-1.441e+00],
         [-9.233e-01],
         [ 6.659e-01],
         [-5.475e-01],
         [-1.244e+00],
         [-2.115e-01]],

        [[-7.472e-01],
         [ 2.511e+00],
         [ 1.767e-02],
         [-1.350e+00],
         [-5.394e-01],
         [-1.047e+00],
         [ 2.067e-01],
         [ 7.725e-01],
         [-6.552e-01],
         [-1.075e+00]],

        [[-1.123e-01],
         [-5.877e-01],
         [-1.254e+00],
         [-6.124e-01],
         [ 5.960e-01],
         [-9.662e-01],
         [ 1.805e+00],
         [ 3.326e-02],
         [-1.389e+00],
         [-7.610e-01]]], device='cuda:0')
v tensor([[[2.464e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [2.199e-01],
         [1.407e+00],
         [1.000e-12],
         [2.780e-01],
         [1.803e-01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.282e+00],
         [4.124e-01],
         [1.000e-12],
         [1.000e-12],
         [1.006e+00],
         [1.000e-12],
         [4.961e+00]],

        [[1.000e-12],
         [1.000e-12],
         [8.418e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.717e+00],
         [1.000e-12]],

        [[1.356e+00],
         [1.940e+00],
         [4.155e-01],
         [1.000e-12],
         [1.000e-12],
         [2.874e+00],
         [1.000e-12],
         [1.000e-12],
         [1.485e+00],
         [4.080e-01]],

        [[1.000e-12],
         [4.188e-02],
         [1.000e-12],
         [2.443e-02],
         [1.126e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.658e-01],
         [1.000e-12],
         [1.000e-12],
         [8.066e-01],
         [1.000e-12],
         [1.000e-12],
         [3.090e+00]],

        [[1.000e-12],
         [1.000e-12],
         [2.174e+00],
         [1.000e-12],
         [4.566e-01],
         [1.000e-12],
         [3.816e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[3.069e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.659e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [2.511e+00],
         [1.767e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.067e-01],
         [7.725e-01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.960e-01],
         [1.000e-12],
         [1.805e+00],
         [3.326e-02],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[-0.082],
        [ 4.401],
        [-0.049],
        [-1.763],
        [ 1.106],
        [10.148],
        [14.397],
        [-0.440],
        [-0.797],
        [-2.160]], device='cuda:0')
v tensor([[1.000e-12],
        [4.401e+00],
        [1.000e-12],
        [1.000e-12],
        [1.106e+00],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 1.237e-02, -2.001e-02,  2.637e-02,  3.142e-02,  1.246e-02,  1.016e-02,
         -4.795e-02,  4.119e-02, -1.984e-03, -4.001e-02],
        [-1.662e-03,  2.369e-02,  8.303e-03, -1.055e-02,  1.202e-02,  1.713e-02,
          7.705e-03,  2.405e-02, -1.028e-02, -1.068e-02],
        [-2.733e-03, -2.622e-02,  1.410e-02,  7.732e-03, -1.386e-02,  1.647e-02,
          1.321e-02,  6.343e-03, -4.838e-02, -1.049e-02],
        [-4.894e-04, -3.151e-03, -6.635e-03, -1.241e-02,  6.193e-02,  4.286e-02,
         -2.887e-02, -1.940e-02, -3.847e-02, -2.901e-03],
        [-2.564e-03, -3.006e-02, -7.949e-03, -1.404e-02, -1.460e-02,  1.870e-02,
         -1.020e-03, -7.277e-03,  1.153e-02, -1.567e-02],
        [-4.929e-03,  4.597e-02,  4.922e-03,  6.180e-02, -1.466e-02, -2.235e-02,
         -7.185e-03,  6.831e-03, -1.236e-02, -9.984e-03],
        [-3.595e-03,  2.463e-02, -3.141e-03,  7.082e-03,  3.265e-03,  7.497e-02,
          2.238e-02, -2.278e-03, -2.198e-04,  4.470e-03],
        [-2.170e-04,  2.320e-02,  1.756e-02, -9.825e-04, -8.170e-03,  1.391e-02,
          8.114e-03, -2.009e-02, -1.387e-02,  4.600e-03],
        [ 6.897e-03,  5.826e-03, -1.792e-02,  6.134e-02, -3.420e-02,  1.563e-02,
         -6.425e-03, -8.225e-02,  5.591e-04, -7.887e-03],
        [ 1.345e-02, -3.315e-02, -3.292e-02, -3.715e-03, -1.136e-02, -3.701e-04,
         -2.131e-02,  1.358e-02,  2.459e-02,  4.256e-03],
        [ 1.802e-02, -1.721e-05,  2.642e-03, -1.807e-02,  1.040e-02,  2.171e-03,
          1.480e-02,  2.810e-02, -1.294e-02,  1.992e-02],
        [ 2.394e-02, -4.105e-04,  2.371e-02,  4.258e-02,  5.764e-03, -6.364e-03,
         -4.591e-02, -2.456e-02, -2.358e-02, -1.248e-03],
        [-3.796e-02,  3.381e-04, -4.931e-03, -6.143e-03, -1.521e-02,  6.404e-04,
         -1.393e-02,  2.649e-02, -3.741e-02,  1.696e-02],
        [ 2.778e-02, -4.999e-03,  7.719e-03,  3.751e-03,  2.586e-02, -1.082e-02,
         -7.436e-03,  3.086e-02, -1.995e-03, -1.560e-02],
        [-8.111e-03, -1.230e-02,  7.020e-03,  1.111e-02,  3.375e-02,  1.714e-02,
          1.746e-02,  2.160e-02,  1.680e-02,  8.183e-03],
        [-1.360e-02,  1.735e-02, -5.867e-03,  4.228e-03, -6.843e-02, -2.207e-03,
          7.580e-03, -3.762e-03,  5.065e-02, -2.948e-02],
        [ 3.926e-03, -2.035e-02, -1.194e-02, -1.932e-03, -1.407e-02,  2.949e-02,
         -1.665e-02, -2.494e-02, -2.046e-04,  6.872e-03],
        [ 8.894e-03, -1.792e-05, -1.854e-02, -2.805e-02, -3.672e-04,  7.659e-03,
          1.832e-02,  7.630e-03,  1.398e-02, -2.141e-02],
        [ 1.514e-02,  2.485e-03, -1.238e-02,  3.794e-02, -9.747e-03, -2.752e-03,
         -2.718e-03,  8.569e-03, -3.626e-02, -2.490e-02],
        [-2.492e-03, -5.274e-03, -2.653e-02,  2.019e-02, -1.357e-02,  2.871e-02,
          2.389e-02, -1.033e-02,  4.751e-02,  1.371e-03],
        [-1.470e-02,  2.245e-03, -1.429e-02,  5.059e-02,  6.186e-03,  9.456e-04,
         -3.512e-03, -1.313e-02, -5.986e-03, -9.351e-03],
        [-3.354e-02,  5.760e-03,  1.002e-02, -7.121e-03, -3.398e-03,  2.922e-02,
         -6.985e-03, -5.946e-03, -6.452e-03,  2.311e-04],
        [-1.894e-03,  1.718e-02, -4.287e-03, -5.440e-02,  1.163e-03, -3.580e-02,
         -6.031e-03,  2.955e-02,  2.887e-03,  2.309e-02],
        [ 2.375e-02, -3.359e-02, -3.243e-03,  1.865e-02, -3.651e-03, -2.058e-02,
         -7.835e-03,  1.109e-02, -2.554e-03, -5.928e-03],
        [-4.852e-02, -2.276e-03,  3.316e-03,  6.630e-03,  7.578e-03, -4.486e-03,
         -1.091e-03, -4.238e-02,  3.738e-02,  4.352e-03],
        [ 1.804e-03, -6.272e-03,  1.629e-03, -1.470e-02, -1.779e-03, -4.108e-02,
         -2.761e-03,  1.357e-02,  1.323e-02,  1.720e-03],
        [-3.343e-02,  1.694e-02, -1.336e-02, -1.325e-02,  3.531e-03,  1.282e-02,
          1.684e-02,  6.772e-04, -2.116e-02, -7.618e-03],
        [ 3.449e-02, -8.644e-03,  1.440e-02, -1.321e-02, -4.375e-02, -1.220e-02,
          1.013e-02, -8.711e-03, -1.124e-02, -2.399e-02],
        [ 4.780e-03,  2.763e-03, -2.000e-02,  1.986e-02, -2.500e-03,  2.544e-02,
         -4.204e-03,  2.200e-03, -1.460e-02, -1.840e-02],
        [ 3.590e-03, -1.316e-04, -4.338e-03, -2.179e-02, -8.856e-03,  5.926e-02,
          9.927e-03,  1.986e-02, -1.374e-02,  7.357e-02],
        [ 3.787e-03, -4.802e-03, -5.019e-03,  4.251e-03,  2.307e-02, -7.947e-03,
          5.044e-03,  5.597e-04, -5.977e-02, -3.220e-02],
        [ 6.883e-04,  1.237e-02,  5.398e-03,  1.150e-03,  5.703e-04,  5.155e-03,
         -1.154e-02,  1.600e-03, -2.979e-02, -8.408e-03],
        [ 8.088e-03, -1.807e-03,  4.737e-03,  1.264e-03,  1.862e-02, -3.249e-03,
         -1.739e-02, -8.772e-03, -1.944e-02,  2.804e-03],
        [ 1.897e-03, -8.840e-03, -4.626e-03,  6.780e-03, -6.116e-03,  4.944e-03,
          2.398e-02, -7.922e-03,  1.245e-03,  7.449e-03],
        [ 4.657e-03, -1.493e-03, -3.511e-03, -6.691e-03,  2.250e-03, -1.541e-02,
          1.572e-02, -3.022e-02, -5.588e-03, -7.102e-03],
        [ 4.080e-03, -6.034e-03, -1.122e-02, -1.499e-04,  3.659e-03, -4.273e-03,
         -1.121e-02,  1.768e-02, -1.551e-02, -9.555e-03],
        [ 1.342e-02,  3.853e-03,  3.216e-03,  1.697e-02, -2.179e-02,  3.121e-03,
          4.944e-03, -2.238e-02, -1.761e-02, -6.288e-03],
        [ 7.299e-04, -2.740e-03,  4.397e-03, -5.373e-04,  1.173e-03, -9.681e-04,
          8.011e-03,  5.158e-03, -5.983e-03, -1.594e-02],
        [ 3.090e-02, -7.786e-03, -9.089e-03,  6.388e-03,  3.856e-03, -6.022e-04,
          4.373e-04, -5.426e-03, -2.150e-02,  3.141e-03],
        [-2.569e-02, -1.749e-02, -1.940e-03,  6.598e-03,  2.185e-02,  7.269e-03,
         -3.115e-03,  1.424e-02,  3.387e-03,  5.051e-03],
        [-7.356e-03, -2.106e-02, -1.455e-02,  3.317e-02, -1.060e-03, -1.043e-02,
          5.038e-02, -2.539e-03, -5.506e-02,  8.040e-03],
        [ 1.713e-02, -5.764e-02, -1.980e-02,  6.392e-03,  4.267e-03,  1.513e-02,
         -9.372e-03,  3.101e-02, -3.257e-03,  1.766e-02],
        [-2.585e-04,  2.041e-02, -9.524e-03, -2.997e-02, -8.330e-03, -1.910e-02,
         -9.057e-03, -3.257e-03,  1.977e-02,  1.488e-02],
        [-1.571e-02, -4.124e-02, -1.378e-02, -1.359e-02, -6.068e-03, -1.282e-03,
          1.801e-02, -7.838e-03,  4.162e-04,  1.401e-02],
        [ 1.372e-02,  9.515e-03,  1.853e-02,  1.043e-02, -1.321e-02, -2.338e-02,
          3.263e-03, -2.881e-02,  1.452e-02, -5.920e-03],
        [ 4.071e-02,  1.452e-02,  5.499e-03,  1.920e-02,  4.039e-03, -5.724e-03,
          3.437e-02,  3.776e-02,  3.849e-02, -2.724e-02],
        [ 2.643e-02, -1.309e-02,  4.204e-03,  2.843e-02,  1.648e-03,  2.728e-02,
         -3.070e-03,  1.285e-02, -1.176e-02,  2.726e-02],
        [ 7.406e-03, -1.144e-02,  1.648e-03, -2.569e-02,  1.362e-02,  5.935e-03,
         -1.538e-03, -2.762e-03,  2.220e-03, -9.506e-04],
        [-6.499e-03,  3.893e-02, -3.701e-02, -1.384e-02, -1.639e-02,  2.633e-03,
          3.663e-03,  1.420e-02,  1.574e-02, -3.238e-03],
        [-2.136e-03, -6.049e-02, -2.454e-02,  1.670e-02,  1.588e-03,  7.814e-03,
         -2.374e-02,  3.729e-02, -6.722e-03, -8.311e-03],
        [-5.972e-03, -1.158e-02,  1.332e-02,  4.505e-02,  7.779e-03,  1.442e-02,
          3.890e-02,  2.616e-04,  2.649e-02, -4.486e-02],
        [-1.129e-02,  2.366e-02, -9.277e-03,  2.533e-02,  1.636e-02, -1.638e-03,
          5.637e-03,  9.658e-03,  1.398e-02,  2.553e-02],
        [-2.860e-02, -6.134e-02,  1.433e-02,  4.751e-03,  3.197e-02, -2.776e-04,
          1.121e-02, -8.410e-03, -2.751e-02,  1.668e-02],
        [ 2.414e-02,  1.786e-02,  7.478e-03,  3.711e-02,  4.511e-03, -2.244e-03,
          2.660e-02, -3.866e-02, -2.523e-02, -1.998e-02],
        [ 1.111e-03, -5.321e-03, -1.363e-02,  3.515e-02,  1.740e-02, -8.634e-03,
          1.088e-01, -2.514e-03, -3.044e-02, -7.785e-03],
        [ 1.828e-02,  1.422e-02, -1.235e-02,  1.657e-02, -4.790e-03, -5.920e-03,
         -4.294e-03,  3.682e-03,  1.407e-02,  2.147e-03],
        [-1.768e-03, -2.942e-03, -2.183e-02, -2.607e-02, -2.976e-03,  8.759e-03,
         -1.023e-01,  4.011e-03, -2.702e-02,  1.296e-02],
        [-1.579e-02,  1.058e-02, -6.426e-03,  9.053e-03, -9.737e-03, -5.210e-03,
          1.901e-02, -3.159e-02,  1.105e-02, -3.932e-02],
        [ 4.197e-03, -1.759e-02, -1.396e-02,  3.584e-02, -3.422e-03, -8.232e-04,
         -1.002e-02, -4.699e-03,  1.262e-02, -1.974e-03],
        [ 7.005e-03,  1.336e-03,  1.336e-02,  2.784e-02,  3.561e-02, -1.005e-02,
          3.197e-03,  3.897e-02,  1.083e-02, -1.102e-02],
        [ 9.808e-03, -6.265e-03,  3.445e-03,  3.759e-02, -8.321e-04,  7.619e-03,
         -3.916e-03,  2.707e-02,  3.694e-02, -4.434e-03],
        [-9.283e-03,  4.613e-04, -1.281e-02,  1.891e-02, -7.102e-03, -1.735e-02,
         -1.159e-02, -2.378e-02, -2.077e-02, -1.872e-02],
        [ 3.276e-03,  8.864e-03, -1.099e-02,  1.515e-02,  1.402e-03, -2.428e-02,
         -3.211e-03, -1.759e-02, -1.135e-03,  3.188e-02],
        [ 2.074e-02,  1.451e-02,  4.227e-02,  4.362e-02,  1.974e-02, -3.554e-02,
         -5.530e-03,  1.584e-03, -7.718e-03, -2.128e-02],
        [-2.496e-02,  4.386e-03, -1.882e-02, -2.394e-02,  3.047e-03,  8.741e-03,
         -1.277e-02, -4.260e-02,  4.631e-03,  4.106e-03],
        [ 4.983e-03, -1.516e-02,  1.922e-02,  2.774e-02,  1.128e-02, -2.784e-03,
         -8.202e-03, -1.359e-03, -4.746e-03, -2.554e-02],
        [-5.125e-04,  3.011e-03,  1.674e-03,  3.342e-03, -9.494e-03,  2.190e-02,
         -5.863e-03,  3.078e-02,  1.034e-02, -5.186e-03],
        [ 3.171e-02, -1.305e-02, -2.664e-02, -4.435e-02,  9.363e-03,  3.061e-02,
          3.250e-03,  6.065e-03,  1.112e-02,  2.437e-03],
        [ 4.662e-02, -1.112e-02, -1.758e-02, -2.592e-03, -1.249e-02,  5.822e-03,
          4.076e-03,  1.785e-03, -1.653e-03, -1.011e-02],
        [ 8.640e-03, -1.775e-03, -1.632e-03,  5.020e-02, -2.858e-02,  1.632e-02,
         -3.834e-04, -4.787e-02, -6.724e-03, -8.223e-03],
        [-1.969e-03, -5.563e-03, -1.249e-02, -5.121e-04, -1.330e-03,  8.566e-03,
          6.224e-03,  1.242e-03,  1.735e-03, -3.257e-03],
        [ 2.183e-03, -1.119e-02, -1.024e-02, -1.112e-03,  1.318e-02, -6.060e-03,
          1.758e-02,  3.575e-03,  2.656e-02,  4.870e-03],
        [-6.908e-03, -8.909e-03, -6.897e-03, -1.873e-02,  9.241e-03, -5.624e-03,
         -3.184e-02,  5.794e-03, -4.954e-03, -2.163e-02],
        [-2.442e-02, -1.448e-02,  5.299e-03, -4.561e-02, -6.966e-03, -2.591e-04,
          2.634e-02, -1.565e-03,  4.544e-02, -5.252e-02],
        [-2.017e-03,  1.647e-02,  1.997e-02,  2.276e-03, -7.275e-04, -2.172e-02,
          4.152e-03, -1.743e-03, -6.113e-03,  2.844e-04],
        [-1.547e-03,  4.227e-03,  1.760e-02,  6.607e-02, -2.098e-02, -8.412e-03,
          1.566e-03, -4.323e-03, -8.182e-03, -3.131e-02],
        [-3.016e-03,  1.566e-02,  8.905e-03,  2.727e-03,  3.203e-02,  1.168e-02,
          6.297e-03, -1.425e-03,  9.639e-03, -6.598e-03],
        [-1.451e-02, -3.179e-04,  7.518e-03,  8.453e-03,  6.625e-03,  3.652e-03,
         -1.977e-03, -6.345e-04, -3.922e-03, -2.918e-02],
        [ 3.820e-03, -3.205e-02, -6.030e-04,  7.797e-03, -1.009e-02,  2.364e-02,
          2.738e-02, -3.649e-03, -8.470e-03, -2.158e-02],
        [ 5.409e-03, -9.262e-03, -1.043e-02,  3.561e-03, -1.557e-02, -1.872e-03,
         -9.610e-04, -1.883e-03, -1.375e-02, -9.216e-03],
        [ 1.258e-02, -5.108e-03,  2.988e-02,  1.961e-03, -9.367e-03,  5.326e-03,
         -3.818e-02,  1.897e-02, -1.133e-02,  7.878e-03],
        [-2.600e-03,  2.377e-03,  2.200e-02, -3.376e-02,  3.444e-02, -1.279e-02,
          2.051e-02, -4.505e-02,  2.791e-03, -2.282e-02],
        [ 1.432e-02, -4.692e-03, -6.206e-03, -8.065e-03, -4.934e-03, -3.364e-02,
          9.461e-04, -1.356e-02,  9.619e-03, -1.082e-02],
        [-1.497e-02,  1.317e-02, -1.133e-03,  4.270e-03,  1.555e-02, -7.114e-03,
          5.358e-02, -1.564e-03,  1.611e-02,  3.183e-03],
        [ 1.585e-02, -6.808e-03, -9.158e-03,  1.506e-02,  2.015e-02, -2.207e-02,
         -1.913e-03,  3.249e-02,  2.015e-03, -8.348e-04],
        [-2.061e-02,  4.769e-03,  2.797e-04,  3.259e-02,  1.593e-03,  6.697e-03,
          1.811e-02, -1.127e-02, -8.597e-04,  1.513e-02],
        [-1.756e-02,  5.403e-03, -1.921e-02, -1.216e-02, -7.216e-03, -1.849e-03,
         -1.758e-02, -9.591e-03, -1.069e-03, -8.130e-03],
        [-2.791e-03,  1.879e-02, -3.158e-03, -2.749e-05, -1.733e-02,  1.265e-03,
         -1.774e-02,  1.684e-02,  6.513e-03, -1.647e-02],
        [-9.308e-04, -3.640e-03,  1.744e-02,  1.307e-02,  3.118e-03, -2.334e-02,
          1.296e-02, -7.706e-04, -5.143e-03,  4.146e-03],
        [-1.809e-03,  4.618e-03, -2.371e-02, -2.149e-02,  8.133e-03, -1.914e-02,
         -2.643e-04,  3.647e-02,  2.100e-02, -1.255e-03],
        [ 1.314e-02, -8.276e-03, -3.418e-02,  7.143e-04,  8.446e-03,  8.855e-03,
         -2.103e-02,  2.476e-02,  1.485e-02,  2.038e-02],
        [ 2.480e-02,  1.707e-03, -3.187e-03, -5.522e-02, -1.011e-02, -3.429e-03,
          6.111e-03, -2.527e-02, -1.963e-02,  1.588e-02],
        [-3.511e-03, -4.915e-02, -4.624e-03, -5.308e-03,  1.923e-03, -1.488e-02,
          1.843e-02,  1.484e-02,  6.371e-03,  9.378e-03],
        [-2.130e-02, -1.886e-03,  1.312e-02,  1.122e-02,  4.811e-03,  1.035e-02,
          3.871e-02,  1.079e-02, -8.315e-03, -1.365e-02],
        [ 2.437e-02,  6.048e-03, -1.862e-02, -1.308e-02, -6.545e-03, -3.507e-03,
          7.234e-03,  4.024e-03,  6.208e-02,  1.174e-04],
        [-3.010e-02,  6.443e-02,  1.103e-03, -1.778e-02,  4.388e-03, -4.635e-02,
          1.513e-02,  4.785e-03, -1.131e-02,  7.199e-03],
        [-6.399e-03, -2.766e-02, -8.848e-03, -5.958e-04, -1.119e-02,  2.607e-02,
          1.287e-02,  2.027e-02,  1.994e-02,  2.336e-03],
        [ 1.228e-02, -8.515e-03, -2.230e-02,  1.240e-03, -4.024e-02,  3.792e-04,
          3.562e-04,  9.769e-03, -2.784e-02, -1.342e-03],
        [-4.261e-03,  4.603e-02, -2.297e-03,  1.187e-02, -2.061e-02,  1.753e-02,
          1.718e-02, -3.661e-03, -2.475e-02,  1.744e-03],
        [ 1.592e-02, -3.780e-02, -2.615e-02, -3.233e-03,  2.578e-02, -4.260e-02,
         -5.108e-02,  6.519e-03, -1.953e-02,  1.677e-02]], device='cuda:0')
s after update for 1 param tensor([[0.746, 0.760, 0.863, 0.616, 0.717, 0.577, 0.857, 0.547, 1.271, 0.493],
        [0.542, 0.585, 0.573, 0.523, 0.993, 0.798, 0.638, 1.110, 0.551, 0.441],
        [0.693, 0.934, 0.842, 0.864, 0.850, 1.438, 0.851, 1.066, 0.946, 0.968],
        [0.589, 1.111, 1.503, 1.154, 0.630, 0.209, 0.817, 0.605, 0.582, 1.066],
        [1.341, 0.444, 0.669, 0.656, 0.372, 0.731, 0.840, 0.513, 0.738, 1.257],
        [1.213, 0.563, 1.033, 0.732, 0.519, 0.589, 0.645, 0.606, 0.766, 0.790],
        [0.666, 0.593, 1.451, 0.796, 0.554, 0.472, 0.780, 0.476, 0.218, 0.740],
        [0.673, 1.078, 0.476, 0.622, 0.963, 0.991, 0.676, 0.618, 0.538, 1.248],
        [1.347, 0.757, 0.942, 0.656, 0.971, 1.112, 1.103, 1.358, 0.619, 0.807],
        [1.338, 0.677, 0.980, 0.874, 0.889, 1.032, 0.669, 0.990, 0.826, 1.326],
        [1.130, 0.938, 0.734, 0.530, 1.009, 1.241, 0.760, 0.503, 0.787, 0.987],
        [0.544, 0.979, 0.491, 1.601, 0.721, 0.348, 1.293, 0.931, 0.330, 0.567],
        [0.827, 0.964, 1.155, 1.117, 0.628, 0.786, 1.679, 0.559, 0.417, 0.951],
        [1.662, 0.670, 0.737, 0.366, 0.878, 0.587, 0.504, 0.877, 0.721, 0.489],
        [0.921, 0.927, 0.963, 0.919, 0.512, 0.556, 0.884, 0.612, 0.597, 0.582],
        [0.420, 0.857, 0.750, 0.997, 0.651, 0.921, 0.709, 1.002, 0.284, 0.585],
        [0.799, 0.636, 0.937, 0.832, 1.207, 0.645, 0.771, 0.396, 0.885, 0.606],
        [0.900, 0.816, 0.700, 0.871, 0.699, 1.060, 0.811, 0.970, 0.341, 0.541],
        [0.486, 1.014, 0.735, 0.577, 1.086, 1.010, 0.673, 0.811, 0.516, 0.733],
        [0.872, 0.515, 1.320, 0.773, 0.692, 0.432, 0.816, 0.805, 1.061, 0.554],
        [0.665, 0.841, 1.198, 0.539, 0.669, 0.733, 0.889, 0.640, 0.652, 0.691],
        [0.797, 0.617, 1.006, 0.268, 0.446, 1.220, 0.490, 0.501, 0.801, 0.585],
        [0.839, 0.773, 0.691, 0.811, 0.862, 0.652, 0.631, 0.987, 0.805, 1.028],
        [0.644, 0.316, 0.752, 0.447, 0.359, 0.710, 0.584, 0.606, 0.222, 1.113],
        [1.093, 0.597, 0.675, 0.894, 0.540, 0.398, 0.620, 0.841, 0.829, 0.907],
        [0.582, 0.647, 0.787, 0.630, 0.529, 0.518, 0.403, 0.557, 0.724, 0.835],
        [0.943, 0.541, 1.058, 0.509, 0.813, 0.852, 0.651, 0.624, 0.279, 0.984],
        [1.395, 1.011, 1.328, 0.580, 0.608, 0.893, 1.268, 0.695, 0.714, 0.743],
        [0.710, 0.580, 1.467, 0.504, 0.690, 0.668, 0.868, 0.407, 0.653, 0.483],
        [0.367, 0.236, 0.968, 0.713, 0.903, 1.036, 0.387, 0.558, 0.381, 0.883],
        [0.630, 0.657, 0.803, 0.330, 0.760, 0.901, 0.881, 0.495, 1.042, 0.690],
        [0.478, 0.446, 0.317, 0.962, 0.660, 0.755, 0.696, 0.664, 0.538, 0.825],
        [0.846, 0.574, 0.651, 0.730, 0.971, 0.513, 0.645, 1.090, 0.522, 0.379],
        [0.515, 0.628, 0.615, 0.971, 0.929, 0.994, 0.910, 0.915, 0.348, 1.000],
        [0.857, 1.065, 0.691, 0.743, 0.828, 0.915, 1.113, 0.360, 0.881, 1.044],
        [1.023, 0.633, 0.398, 0.938, 0.738, 1.034, 0.282, 0.648, 0.675, 0.745],
        [0.786, 0.724, 0.918, 1.436, 1.185, 0.966, 0.651, 1.237, 0.594, 0.709],
        [0.432, 0.851, 0.639, 1.049, 0.371, 0.696, 0.551, 0.525, 0.871, 0.795],
        [0.925, 1.409, 0.741, 0.931, 0.730, 0.886, 0.549, 0.969, 1.108, 0.629],
        [0.974, 0.827, 0.618, 0.705, 0.914, 0.671, 0.682, 0.678, 0.920, 0.674],
        [0.742, 0.687, 0.702, 0.898, 0.576, 0.506, 1.017, 0.372, 0.663, 0.914],
        [1.080, 0.914, 0.892, 1.191, 1.247, 0.826, 0.512, 0.767, 1.077, 0.521],
        [0.802, 0.897, 0.570, 0.899, 1.216, 1.011, 0.304, 0.744, 0.857, 0.599],
        [0.405, 0.718, 0.665, 0.855, 0.703, 0.509, 0.894, 0.697, 0.656, 0.579],
        [0.381, 0.675, 0.578, 0.562, 0.849, 0.878, 0.739, 0.604, 0.627, 0.702],
        [0.540, 0.788, 0.467, 0.366, 0.905, 0.938, 0.626, 0.634, 1.066, 0.865],
        [0.745, 1.612, 0.364, 1.449, 0.952, 0.770, 0.753, 1.136, 0.601, 1.121],
        [0.773, 0.548, 0.630, 1.134, 0.682, 0.460, 0.908, 1.499, 1.032, 0.429],
        [1.240, 0.768, 0.743, 0.490, 1.615, 1.064, 0.914, 1.126, 0.542, 0.998],
        [0.512, 0.868, 0.872, 0.684, 0.769, 1.147, 1.000, 0.408, 1.469, 0.547],
        [0.635, 0.873, 0.487, 0.540, 1.367, 1.163, 0.891, 0.944, 0.634, 0.730],
        [0.726, 1.174, 0.648, 0.515, 0.801, 0.763, 0.667, 0.766, 0.902, 0.910],
        [1.216, 0.895, 0.656, 0.699, 0.879, 0.578, 1.081, 0.562, 0.443, 1.172],
        [0.695, 0.790, 1.258, 0.515, 1.048, 0.572, 1.016, 0.547, 0.539, 0.280],
        [0.728, 0.664, 0.672, 0.566, 0.547, 1.145, 1.009, 1.104, 0.520, 0.917],
        [0.266, 0.815, 0.563, 0.904, 0.843, 1.037, 1.199, 0.970, 0.816, 0.964],
        [0.517, 0.782, 0.672, 0.880, 0.928, 0.923, 1.018, 0.745, 0.584, 1.395],
        [0.699, 0.656, 1.268, 0.668, 0.734, 0.580, 0.729, 0.442, 0.382, 0.962],
        [0.451, 0.790, 0.666, 0.737, 0.664, 0.783, 0.753, 0.931, 0.532, 0.315],
        [0.824, 0.891, 1.277, 1.120, 1.111, 0.887, 0.813, 0.916, 0.361, 0.667],
        [0.418, 1.133, 0.626, 0.667, 0.915, 1.003, 1.088, 1.289, 0.500, 0.658],
        [1.400, 1.357, 1.542, 0.381, 1.021, 0.688, 1.050, 0.685, 0.738, 0.468],
        [0.955, 0.794, 0.537, 0.857, 1.111, 1.119, 1.200, 1.007, 0.638, 0.746],
        [0.305, 0.911, 1.134, 0.778, 0.307, 0.329, 1.139, 0.443, 0.515, 0.871],
        [1.079, 1.080, 1.212, 0.593, 1.273, 0.952, 1.204, 0.761, 1.017, 0.398],
        [1.067, 0.650, 0.600, 0.310, 0.613, 0.854, 0.857, 0.858, 1.147, 0.804],
        [1.098, 1.197, 0.337, 0.502, 1.191, 0.378, 0.526, 1.178, 0.732, 0.754],
        [1.283, 0.891, 0.784, 0.952, 0.999, 0.831, 0.551, 1.455, 0.832, 1.166],
        [1.084, 1.036, 0.804, 0.588, 1.066, 0.578, 1.530, 0.802, 0.532, 1.427],
        [0.645, 0.692, 0.374, 0.686, 0.575, 0.649, 0.635, 0.622, 1.041, 0.703],
        [0.459, 0.678, 0.410, 0.767, 0.955, 0.994, 0.827, 0.765, 0.711, 0.865],
        [0.644, 0.472, 0.877, 0.749, 1.266, 0.356, 0.508, 1.217, 0.644, 0.892],
        [1.182, 0.366, 0.702, 0.833, 0.580, 0.735, 0.745, 0.804, 1.039, 0.560],
        [1.088, 1.250, 0.562, 0.235, 0.678, 1.173, 1.134, 0.959, 0.682, 0.770],
        [0.314, 0.681, 1.215, 0.612, 0.566, 1.440, 0.419, 0.606, 0.741, 0.736],
        [0.528, 0.529, 1.429, 0.763, 0.388, 0.407, 0.515, 0.858, 0.698, 0.434],
        [0.979, 0.760, 0.942, 0.362, 0.651, 1.091, 1.079, 0.764, 0.826, 1.345],
        [0.615, 0.550, 0.851, 0.240, 0.936, 0.806, 1.291, 0.851, 1.040, 0.812],
        [0.319, 0.800, 1.032, 0.526, 0.600, 0.931, 0.964, 0.821, 1.192, 1.104],
        [0.471, 0.993, 0.499, 0.291, 0.862, 0.612, 0.634, 1.036, 0.536, 0.484],
        [0.795, 0.925, 0.609, 0.505, 0.433, 0.334, 0.744, 0.468, 0.815, 0.987],
        [0.869, 0.828, 1.121, 0.344, 0.688, 0.846, 1.248, 0.763, 0.705, 0.597],
        [0.689, 0.693, 0.363, 0.514, 0.579, 1.025, 0.469, 0.606, 0.744, 0.774],
        [0.335, 0.925, 0.599, 1.165, 0.960, 0.596, 0.989, 0.887, 0.587, 0.821],
        [0.681, 0.779, 0.445, 0.607, 1.286, 1.375, 0.565, 0.528, 1.022, 0.757],
        [0.705, 0.476, 0.300, 0.823, 0.459, 0.995, 0.468, 0.843, 0.618, 0.540],
        [0.631, 0.675, 0.511, 0.891, 0.833, 0.542, 0.462, 0.546, 1.054, 1.306],
        [0.614, 1.008, 0.422, 0.562, 1.427, 0.328, 0.382, 0.629, 0.644, 1.360],
        [0.707, 0.642, 0.437, 0.357, 0.669, 0.661, 0.785, 0.470, 0.961, 0.448],
        [1.068, 1.127, 0.542, 0.646, 0.848, 0.745, 0.373, 0.847, 0.837, 0.472],
        [0.643, 0.907, 0.418, 0.584, 1.422, 0.996, 1.010, 0.861, 0.996, 1.301],
        [1.437, 0.810, 0.975, 1.440, 0.716, 0.689, 0.730, 0.834, 0.342, 1.469],
        [0.353, 0.933, 0.793, 0.349, 0.512, 0.633, 0.971, 0.365, 1.014, 1.144],
        [1.242, 0.771, 0.788, 0.914, 0.880, 0.583, 1.599, 1.435, 0.729, 1.375],
        [0.831, 0.816, 1.114, 0.415, 0.584, 0.843, 0.798, 0.264, 1.349, 1.119],
        [1.186, 0.899, 0.597, 0.696, 1.225, 0.578, 0.659, 0.497, 0.731, 1.750],
        [1.678, 0.588, 0.833, 0.878, 0.664, 0.906, 0.840, 0.686, 0.536, 1.014],
        [0.757, 0.309, 0.719, 1.268, 0.408, 0.675, 0.430, 0.831, 0.347, 0.714],
        [0.680, 0.879, 1.396, 0.794, 0.509, 0.643, 0.729, 0.560, 0.781, 0.804],
        [0.785, 0.842, 0.923, 0.768, 0.875, 1.049, 0.814, 0.950, 0.802, 1.005]],
       device='cuda:0')
b after update for 1 param tensor([[26.670, 26.924, 28.687, 24.248, 26.157, 23.454, 28.598, 22.843, 34.823,
         21.692],
        [22.744, 23.622, 23.385, 22.336, 30.779, 27.590, 24.674, 32.549, 22.925,
         20.514],
        [25.706, 29.852, 28.350, 28.715, 28.477, 37.039, 28.498, 31.893, 30.039,
         30.392],
        [23.696, 32.562, 37.865, 33.186, 24.514, 14.134, 27.919, 24.019, 23.572,
         31.888],
        [35.763, 20.575, 25.264, 25.015, 18.850, 26.409, 28.317, 22.117, 26.527,
         34.629],
        [34.016, 23.170, 31.385, 26.423, 22.261, 23.713, 24.807, 24.045, 27.038,
         27.460],
        [25.214, 23.777, 37.203, 27.553, 22.986, 21.216, 27.272, 21.308, 14.414,
         26.570],
        [25.341, 32.068, 21.311, 24.356, 30.315, 30.755, 25.392, 24.278, 22.662,
         34.512],
        [35.844, 26.865, 29.983, 25.019, 30.441, 32.571, 32.446, 35.994, 24.296,
         27.748],
        [35.733, 25.413, 30.579, 28.874, 29.126, 31.371, 25.271, 30.740, 28.064,
         35.573],
        [32.838, 29.912, 26.457, 22.488, 31.022, 34.404, 26.930, 21.895, 27.401,
         30.688],
        [22.786, 30.560, 21.652, 39.078, 26.228, 18.209, 35.120, 29.808, 17.751,
         23.258],
        [28.086, 30.323, 33.194, 32.643, 24.483, 27.376, 40.020, 23.102, 19.950,
         30.121],
        [39.821, 25.286, 26.510, 18.695, 28.935, 23.662, 21.920, 28.930, 26.231,
         21.596],
        [29.645, 29.735, 30.314, 29.616, 22.097, 23.029, 29.049, 24.171, 23.875,
         23.571],
        [20.016, 28.594, 26.742, 30.836, 24.916, 29.638, 26.016, 30.916, 16.464,
         23.628],
        [27.601, 24.635, 29.894, 28.180, 33.931, 24.805, 27.113, 19.448, 29.054,
         24.053],
        [29.308, 27.902, 25.841, 28.829, 25.822, 31.803, 27.809, 30.418, 18.050,
         22.710],
        [21.535, 31.103, 26.472, 23.463, 32.184, 31.048, 25.335, 27.820, 22.177,
         26.446],
        [28.847, 22.173, 35.486, 27.152, 25.687, 20.298, 27.909, 27.720, 31.808,
         22.999],
        [25.181, 28.330, 33.801, 22.667, 25.267, 26.450, 29.118, 24.719, 24.941,
         25.678],
        [27.577, 24.269, 30.984, 15.989, 20.634, 34.119, 21.622, 21.870, 27.643,
         23.632],
        [28.295, 27.160, 25.682, 27.811, 28.681, 24.945, 24.530, 30.685, 27.713,
         31.312],
        [24.780, 17.373, 26.777, 20.656, 18.512, 26.028, 23.600, 24.051, 14.560,
         32.585],
        [32.288, 23.864, 25.382, 29.202, 22.693, 19.482, 24.313, 28.318, 28.122,
         29.412],
        [23.560, 24.835, 27.397, 24.511, 22.462, 22.240, 19.605, 23.043, 26.277,
         28.220],
        [29.990, 22.719, 31.771, 22.040, 27.857, 28.515, 24.918, 24.408, 16.329,
         30.632],
        [36.483, 31.062, 35.593, 23.519, 24.082, 29.182, 34.777, 25.744, 26.098,
         26.630],
        [26.024, 23.522, 37.416, 21.933, 25.664, 25.246, 28.772, 19.710, 24.964,
         21.460],
        [18.708, 15.018, 30.382, 26.085, 29.344, 31.440, 19.205, 23.076, 19.071,
         29.023],
        [24.520, 25.042, 27.677, 17.733, 26.924, 29.311, 28.993, 21.739, 31.529,
         25.653],
        [21.359, 20.633, 17.393, 30.299, 25.090, 26.837, 25.767, 25.165, 22.650,
         28.060],
        [28.403, 23.398, 24.918, 26.394, 30.444, 22.117, 24.813, 32.244, 22.316,
         19.010],
        [22.160, 24.485, 24.220, 30.438, 29.778, 30.787, 29.458, 29.544, 18.210,
         30.880],
        [28.592, 31.876, 25.678, 26.618, 28.099, 29.553, 32.585, 18.542, 28.984,
         31.563],
        [31.240, 24.576, 19.476, 29.918, 26.540, 31.415, 16.402, 24.856, 25.379,
         26.659],
        [27.382, 26.290, 29.600, 37.007, 33.617, 30.351, 24.912, 34.356, 23.809,
         26.002],
        [20.292, 28.485, 24.693, 31.641, 18.814, 25.770, 22.918, 22.384, 28.829,
         27.533],
        [29.702, 36.665, 26.595, 29.795, 26.385, 29.069, 22.892, 30.398, 32.514,
         24.496],
        [30.488, 28.091, 24.281, 25.941, 29.524, 25.296, 25.504, 25.438, 29.630,
         25.352],
        [26.601, 25.600, 25.880, 29.268, 23.438, 21.968, 31.155, 18.832, 25.147,
         29.533],
        [32.094, 29.528, 29.178, 33.711, 34.486, 28.065, 22.102, 27.043, 32.058,
         22.286],
        [27.657, 29.252, 23.323, 29.293, 34.058, 31.057, 17.021, 26.648, 28.599,
         23.898],
        [19.667, 26.168, 25.188, 28.556, 25.895, 22.030, 29.208, 25.792, 25.024,
         23.503],
        [19.068, 25.370, 23.489, 23.152, 28.468, 28.942, 26.550, 23.997, 24.465,
         25.884],
        [22.705, 27.413, 21.106, 18.677, 29.387, 29.919, 24.428, 24.597, 31.885,
         28.719],
        [26.654, 39.215, 18.646, 37.176, 30.141, 27.096, 26.803, 32.919, 23.939,
         32.709],
        [27.147, 22.864, 24.521, 32.884, 25.515, 20.953, 29.434, 37.812, 31.381,
         20.223],
        [34.397, 27.070, 26.631, 21.631, 39.255, 31.856, 29.524, 32.774, 22.732,
         30.850],
        [22.100, 28.770, 28.836, 25.543, 27.078, 33.085, 30.885, 19.720, 37.441,
         22.848],
        [24.621, 28.861, 21.546, 22.696, 36.118, 33.306, 29.147, 30.017, 24.596,
         26.396],
        [26.313, 33.469, 24.869, 22.158, 27.641, 26.972, 25.225, 27.027, 29.340,
         29.472],
        [34.063, 29.217, 25.012, 25.832, 28.955, 23.491, 32.108, 23.163, 20.561,
         33.441],
        [25.749, 27.455, 34.641, 22.169, 31.621, 23.351, 31.126, 22.849, 22.666,
         16.343],
        [26.347, 25.160, 25.323, 23.245, 22.849, 33.057, 31.029, 32.458, 22.265,
         29.583],
        [15.937, 27.884, 23.180, 29.373, 28.355, 31.451, 33.821, 30.414, 27.900,
         30.333],
        [22.200, 27.311, 25.321, 28.969, 29.760, 29.668, 31.160, 26.654, 23.611,
         36.484],
        [25.832, 25.010, 34.777, 25.252, 26.455, 23.514, 26.380, 20.534, 19.098,
         30.288],
        [20.744, 27.461, 25.209, 26.509, 25.168, 27.329, 26.803, 29.796, 22.530,
         17.342],
        [28.031, 29.151, 34.906, 32.695, 32.554, 29.097, 27.846, 29.559, 18.552,
         25.219],
        [19.977, 32.883, 24.430, 25.232, 29.545, 30.932, 32.217, 35.074, 21.843,
         25.061],
        [36.547, 35.985, 38.355, 19.073, 31.205, 25.628, 31.656, 25.556, 26.534,
         21.140],
        [30.181, 27.516, 22.644, 28.587, 32.559, 32.678, 33.834, 30.992, 24.667,
         26.679],
        [17.047, 29.479, 32.887, 27.244, 17.105, 17.717, 32.968, 20.548, 22.170,
         28.824],
        [32.090, 32.096, 34.009, 23.785, 34.844, 30.134, 33.897, 26.947, 31.155,
         19.497],
        [31.903, 24.905, 23.926, 17.191, 24.173, 28.540, 28.597, 28.603, 33.085,
         27.689],
        [32.366, 33.799, 17.933, 21.874, 33.703, 18.994, 22.411, 33.530, 26.433,
         26.826],
        [34.980, 29.162, 27.343, 30.134, 30.874, 28.164, 22.918, 37.256, 28.178,
         33.349],
        [32.152, 31.437, 27.700, 23.690, 31.893, 23.482, 38.202, 27.661, 22.538,
         36.893],
        [24.811, 25.687, 18.901, 25.582, 23.430, 24.892, 24.611, 24.355, 31.521,
         25.902],
        [20.924, 25.438, 19.780, 27.045, 30.190, 30.794, 28.091, 27.012, 26.040,
         28.730],
        [24.792, 21.217, 28.923, 26.734, 34.750, 18.419, 22.019, 34.081, 24.788,
         29.171],
        [33.583, 18.675, 25.886, 28.192, 23.529, 26.484, 26.667, 27.692, 31.478,
         23.105],
        [32.225, 34.539, 23.149, 14.980, 25.441, 33.459, 32.892, 30.250, 25.502,
         27.101],
        [17.306, 25.484, 34.045, 24.172, 23.230, 37.066, 19.982, 24.045, 26.594,
         26.495],
        [22.442, 22.460, 36.924, 26.977, 19.251, 19.697, 22.164, 28.605, 25.806,
         20.352],
        [30.557, 26.931, 29.981, 18.596, 24.928, 32.259, 32.080, 26.992, 28.070,
         35.822],
        [24.228, 22.914, 28.486, 15.145, 29.890, 27.732, 35.100, 28.501, 31.500,
         27.838],
        [17.448, 27.619, 31.381, 22.393, 23.925, 29.810, 30.325, 27.990, 33.720,
         32.455],
        [21.197, 30.785, 21.820, 16.672, 28.671, 24.168, 24.596, 31.438, 22.609,
         21.490],
        [27.535, 29.707, 24.095, 21.953, 20.322, 17.853, 26.647, 21.124, 27.892,
         30.691],
        [28.801, 28.099, 32.704, 18.109, 25.626, 28.411, 34.512, 26.974, 25.926,
         23.863],
        [25.635, 25.719, 18.621, 22.154, 23.500, 31.265, 21.142, 24.048, 26.650,
         27.180],
        [17.883, 29.699, 23.910, 33.335, 30.255, 23.840, 30.713, 29.097, 23.667,
         27.988],
        [25.497, 27.253, 20.609, 24.070, 35.033, 36.214, 23.225, 22.447, 31.223,
         26.878],
        [25.941, 21.320, 16.915, 28.023, 20.929, 30.804, 21.135, 28.354, 24.286,
         22.704],
        [24.528, 25.369, 22.072, 29.150, 28.197, 22.747, 21.006, 22.817, 31.711,
         35.295],
        [24.196, 31.017, 20.069, 23.159, 36.891, 17.695, 19.081, 24.505, 24.791,
         36.016],
        [25.975, 24.758, 20.417, 18.468, 25.262, 25.105, 27.370, 21.167, 30.273,
         20.673],
        [31.925, 32.785, 22.743, 24.829, 28.450, 26.667, 18.872, 28.431, 28.253,
         21.211],
        [24.774, 29.420, 19.977, 23.608, 36.833, 30.824, 31.039, 28.660, 30.818,
         35.236],
        [37.031, 27.798, 30.506, 37.065, 26.136, 25.630, 26.385, 28.199, 18.052,
         37.430],
        [18.358, 29.833, 27.510, 18.260, 22.093, 24.571, 30.442, 18.655, 31.102,
         33.034],
        [34.420, 27.124, 27.421, 29.533, 28.968, 23.580, 39.055, 37.001, 26.369,
         36.214],
        [28.154, 27.909, 32.602, 19.895, 23.596, 28.366, 27.590, 15.873, 35.872,
         32.672],
        [33.642, 29.288, 23.866, 25.760, 34.189, 23.481, 25.076, 21.765, 26.411,
         40.863],
        [40.005, 23.681, 28.190, 28.939, 25.167, 29.398, 28.313, 25.589, 22.606,
         31.103],
        [26.879, 17.166, 26.189, 34.781, 19.739, 25.374, 20.249, 28.151, 18.198,
         26.105],
        [25.470, 28.954, 36.501, 27.515, 22.029, 24.771, 26.373, 23.104, 27.291,
         27.700],
        [27.358, 28.338, 29.672, 27.070, 28.895, 31.630, 27.864, 30.104, 27.666,
         30.961]], device='cuda:0')
clipping threshold 0.3564964474085015
a after update for 1 param tensor([ 0.044, -0.028, -0.015, -0.004,  0.043, -0.010, -0.026,  0.031,  0.068,
         0.036, -0.000, -0.004, -0.056, -0.084,  0.005, -0.009, -0.022,  0.050,
        -0.000, -0.025, -0.022, -0.037,  0.098,  0.016, -0.002, -0.014,  0.018,
         0.021,  0.028, -0.026,  0.013,  0.023, -0.048, -0.002, -0.015,  0.012,
        -0.056, -0.031,  0.003, -0.040, -0.070, -0.031,  0.022,  0.013, -0.053,
        -0.023,  0.031, -0.031,  0.028, -0.004, -0.010, -0.005,  0.011,  0.034,
         0.001, -0.004, -0.025,  0.037, -0.043, -0.036,  0.006,  0.028, -0.033,
        -0.064,  0.028, -0.016,  0.025, -0.055,  0.028, -0.000,  0.002, -0.034,
         0.014,  0.039, -0.024, -0.053,  0.013, -0.020, -0.033,  0.021, -0.021,
         0.006,  0.033, -0.020,  0.025,  0.003, -0.014, -0.023,  0.038, -0.022,
        -0.002,  0.023, -0.022, -0.046, -0.002,  0.012,  0.064,  0.027, -0.017,
        -0.010], device='cuda:0')
s after update for 1 param tensor([0.872, 0.412, 1.018, 0.674, 0.801, 0.635, 0.811, 0.493, 0.479, 0.503,
        0.719, 0.460, 0.515, 0.718, 0.477, 0.755, 1.269, 0.278, 1.227, 0.668,
        0.888, 0.592, 0.876, 0.503, 0.678, 0.439, 0.670, 1.182, 0.659, 0.385,
        1.202, 1.289, 0.995, 0.482, 0.573, 0.598, 0.269, 1.136, 0.780, 1.298,
        1.089, 0.503, 0.626, 0.731, 0.697, 0.702, 0.818, 0.394, 0.762, 1.283,
        0.647, 0.741, 0.814, 0.866, 0.666, 0.995, 0.961, 0.417, 1.049, 0.917,
        0.729, 0.493, 0.656, 0.529, 0.862, 0.720, 1.519, 0.893, 0.672, 0.859,
        0.436, 0.827, 0.323, 0.640, 1.101, 0.699, 0.622, 0.412, 0.684, 0.676,
        0.672, 0.810, 0.459, 0.539, 0.751, 0.614, 0.862, 0.708, 1.134, 1.150,
        1.335, 0.854, 0.500, 0.708, 0.588, 0.641, 0.754, 0.548, 0.630, 0.578],
       device='cuda:0')
b after update for 1 param tensor([28.838, 19.824, 31.156, 25.349, 27.649, 24.606, 27.816, 21.695, 21.368,
        21.912, 26.189, 20.953, 22.160, 26.176, 21.322, 26.839, 34.799, 16.287,
        34.217, 25.243, 29.101, 23.765, 28.905, 21.905, 25.437, 20.457, 25.281,
        33.579, 25.078, 19.173, 33.858, 35.071, 30.813, 21.439, 23.379, 23.879,
        16.008, 32.923, 27.279, 35.191, 32.239, 21.901, 24.445, 26.412, 25.790,
        25.888, 27.932, 19.396, 26.963, 34.987, 24.844, 26.595, 27.872, 28.744,
        25.206, 30.806, 30.286, 19.956, 31.628, 29.580, 26.367, 21.682, 25.012,
        22.475, 28.685, 26.210, 38.070, 29.195, 25.314, 28.620, 20.387, 28.090,
        17.557, 24.706, 32.407, 25.824, 24.368, 19.829, 25.553, 25.401, 25.314,
        27.799, 20.928, 22.673, 26.762, 24.204, 28.674, 25.986, 32.893, 33.122,
        35.686, 28.538, 21.832, 25.990, 23.678, 24.728, 26.816, 22.860, 24.521,
        23.485], device='cuda:0')
clipping threshold 0.3564964474085015
a after update for 1 param tensor([[[-0.002],
         [-0.049],
         [ 0.027],
         [-0.013],
         [-0.014],
         [-0.027],
         [-0.014],
         [ 0.031],
         [ 0.036],
         [ 0.029]],

        [[ 0.078],
         [ 0.031],
         [ 0.011],
         [ 0.011],
         [-0.014],
         [ 0.044],
         [-0.028],
         [ 0.033],
         [ 0.004],
         [-0.022]],

        [[-0.003],
         [-0.073],
         [ 0.003],
         [ 0.003],
         [-0.005],
         [ 0.048],
         [ 0.020],
         [ 0.007],
         [-0.005],
         [-0.003]],

        [[-0.015],
         [ 0.001],
         [ 0.007],
         [-0.004],
         [-0.037],
         [-0.016],
         [ 0.016],
         [ 0.006],
         [-0.028],
         [ 0.014]],

        [[-0.000],
         [-0.052],
         [ 0.022],
         [-0.062],
         [ 0.027],
         [ 0.058],
         [ 0.025],
         [ 0.048],
         [-0.029],
         [-0.030]],

        [[ 0.059],
         [-0.036],
         [ 0.008],
         [ 0.014],
         [-0.002],
         [-0.018],
         [-0.037],
         [ 0.023],
         [ 0.005],
         [ 0.018]],

        [[-0.021],
         [-0.054],
         [ 0.026],
         [ 0.003],
         [-0.032],
         [-0.022],
         [ 0.003],
         [-0.005],
         [ 0.048],
         [-0.037]],

        [[-0.008],
         [-0.055],
         [-0.035],
         [ 0.002],
         [ 0.004],
         [-0.004],
         [ 0.026],
         [-0.085],
         [-0.070],
         [ 0.018]],

        [[ 0.021],
         [-0.021],
         [ 0.046],
         [ 0.046],
         [ 0.015],
         [ 0.015],
         [ 0.010],
         [ 0.003],
         [-0.008],
         [-0.039]],

        [[ 0.026],
         [ 0.023],
         [ 0.043],
         [ 0.001],
         [-0.055],
         [-0.009],
         [-0.007],
         [-0.024],
         [ 0.040],
         [ 0.045]]], device='cuda:0')
s after update for 1 param tensor([[[0.449],
         [0.598],
         [0.426],
         [1.432],
         [0.585],
         [1.033],
         [1.064],
         [0.962],
         [0.939],
         [0.369]],

        [[1.103],
         [0.715],
         [1.162],
         [0.604],
         [0.459],
         [0.770],
         [1.076],
         [0.697],
         [1.170],
         [1.240]],

        [[0.805],
         [0.855],
         [0.786],
         [0.435],
         [0.901],
         [0.511],
         [1.222],
         [0.723],
         [1.330],
         [0.895]],

        [[0.883],
         [1.275],
         [0.849],
         [0.768],
         [0.921],
         [1.186],
         [1.311],
         [0.827],
         [1.542],
         [0.584]],

        [[0.357],
         [1.101],
         [0.680],
         [0.988],
         [0.724],
         [1.024],
         [1.019],
         [1.051],
         [0.796],
         [0.566]],

        [[0.899],
         [0.814],
         [0.825],
         [0.924],
         [0.483],
         [0.860],
         [0.580],
         [1.285],
         [0.746],
         [1.169]],

        [[0.513],
         [0.638],
         [1.093],
         [0.526],
         [1.339],
         [0.711],
         [0.776],
         [0.790],
         [0.471],
         [1.079]],

        [[1.099],
         [1.472],
         [0.706],
         [0.771],
         [0.966],
         [0.677],
         [0.816],
         [0.588],
         [1.265],
         [0.570]],

        [[0.672],
         [0.709],
         [0.615],
         [0.892],
         [0.380],
         [0.646],
         [0.644],
         [0.569],
         [0.391],
         [0.709]],

        [[0.500],
         [0.732],
         [0.914],
         [0.477],
         [0.526],
         [0.590],
         [0.702],
         [1.025],
         [0.946],
         [1.432]]], device='cuda:0')
b after update for 1 param tensor([[[20.687],
         [23.892],
         [20.170],
         [36.962],
         [23.628],
         [31.393],
         [31.859],
         [30.293],
         [29.924],
         [18.772]],

        [[32.437],
         [26.123],
         [33.291],
         [23.996],
         [20.937],
         [27.112],
         [32.034],
         [25.792],
         [33.417],
         [34.391]],

        [[27.710],
         [28.562],
         [27.375],
         [20.367],
         [29.318],
         [22.080],
         [34.147],
         [26.254],
         [35.626],
         [29.226]],

        [[29.025],
         [34.870],
         [28.459],
         [27.060],
         [29.635],
         [33.635],
         [35.359],
         [28.091],
         [38.360],
         [23.598]],

        [[18.447],
         [32.407],
         [25.461],
         [30.701],
         [26.287],
         [31.256],
         [31.182],
         [31.671],
         [27.563],
         [23.230]],

        [[29.281],
         [27.862],
         [28.059],
         [29.696],
         [21.464],
         [28.636],
         [23.517],
         [35.014],
         [26.676],
         [33.395]],

        [[22.117],
         [24.680],
         [32.297],
         [22.396],
         [35.748],
         [26.046],
         [27.212],
         [27.453],
         [21.191],
         [32.082]],

        [[32.382],
         [37.470],
         [25.947],
         [27.118],
         [30.352],
         [25.407],
         [27.898],
         [23.679],
         [34.744],
         [23.320]],

        [[25.322],
         [26.003],
         [24.226],
         [29.179],
         [19.031],
         [24.818],
         [24.782],
         [23.301],
         [19.313],
         [26.003]],

        [[21.832],
         [26.423],
         [29.536],
         [21.324],
         [22.411],
         [23.732],
         [25.872],
         [31.267],
         [30.047],
         [36.967]]], device='cuda:0')
clipping threshold 0.3564964474085015
a after update for 1 param tensor([[-0.021],
        [-0.087],
        [ 0.003],
        [-0.003],
        [ 0.015],
        [-0.014],
        [-0.002],
        [ 0.005],
        [-0.018],
        [-0.034]], device='cuda:0')
s after update for 1 param tensor([[0.908],
        [1.179],
        [1.574],
        [1.047],
        [1.690],
        [1.505],
        [1.742],
        [1.413],
        [0.918],
        [1.305]], device='cuda:0')
b after update for 1 param tensor([[29.438],
        [33.541],
        [38.756],
        [31.612],
        [40.154],
        [37.898],
        [40.770],
        [36.716],
        [29.599],
        [35.287]], device='cuda:0')
clipping threshold 0.3564964474085015
||w||^2 0.190722062178063
exp ma of ||w||^2 0.3415738885869166
||w|| 0.4367173710514193
exp ma of ||w|| 0.5412787541891746
v before min max tensor([[-1.369e+00,  1.189e+00, -5.949e-01,  9.344e-01,  8.633e-02, -3.671e-01,
          1.770e+00, -3.575e-01, -2.005e+00, -4.772e-02],
        [ 3.695e+00, -9.791e-01,  1.409e+01, -9.502e-01, -2.303e-01, -1.132e+00,
          1.099e+00, -9.424e-01, -1.615e+00,  2.360e-01],
        [ 1.897e+00,  2.184e+00,  5.379e+00,  5.759e-02, -2.299e+00, -1.663e+00,
         -2.108e+00,  8.934e-01, -1.915e+00, -1.102e-01],
        [ 2.926e+00, -1.592e+00, -1.222e+00, -1.316e+00, -1.729e+00,  2.083e-01,
         -1.614e+00, -4.430e-01, -1.689e+00, -8.943e-01],
        [-9.689e-01, -2.961e+00, -1.064e-01, -2.580e+00, -1.030e+00, -1.628e+00,
         -1.452e+00,  5.870e-01, -7.495e-01, -1.564e-01],
        [-1.744e+00, -2.876e+00, -9.934e-01, -9.936e-01, -1.037e+00, -1.341e+00,
         -1.061e+00,  1.049e+00, -8.441e-01, -2.912e-01],
        [ 1.899e-01,  2.733e+00, -7.898e-01, -5.884e-01, -5.991e-01, -1.998e+00,
          2.860e+00, -8.033e-01,  1.764e-01, -4.033e-01],
        [-1.568e-01, -1.011e+00,  1.299e+00,  3.970e-01,  1.393e+00, -1.642e+00,
         -4.939e-01, -5.411e-01, -5.313e-01,  2.681e-01],
        [ 7.148e-01, -1.283e+00,  4.254e-01, -1.254e+00, -1.119e+00, -9.989e-01,
         -1.750e+00, -1.748e+00,  9.200e-01, -4.294e-01],
        [ 6.431e+00,  5.998e+00, -1.359e+00,  2.220e+00,  7.111e-01, -7.747e-01,
         -1.098e+00,  1.401e+00,  6.274e-01, -2.752e+00],
        [ 2.354e+00, -8.623e-01, -1.025e+00,  1.708e-01, -8.449e-01,  5.981e+00,
          5.326e+00,  3.760e-01, -6.139e-01, -9.190e-01],
        [-1.897e+00, -1.895e+00, -5.484e-01, -1.292e+00, -7.667e-01, -1.256e+00,
         -1.647e+00, -8.172e-01, -2.491e-01,  1.807e+00],
        [-9.351e-01,  1.157e-01, -1.630e+00, -1.133e+00,  1.922e+00, -1.911e+00,
         -1.356e+00, -9.303e-01, -5.885e-01, -1.089e+00],
        [-2.257e+00, -9.244e-01, -1.188e+00, -6.751e-01, -2.481e+00, -1.024e+00,
         -1.051e-01, -2.036e+00,  6.539e-01, -1.238e+00],
        [-2.257e+00,  2.366e-01,  5.834e+00, -1.435e+00,  2.627e+00, -1.063e+00,
         -1.967e+00, -9.032e-01, -7.339e-01,  5.797e-01],
        [ 7.515e-01,  1.159e-01, -5.711e-01,  7.422e-01, -5.009e-01, -2.037e-01,
         -6.948e-01, -1.780e+00,  7.427e-04, -1.277e+00],
        [-1.094e+00, -8.833e-01, -8.738e-01, -4.149e-01,  1.419e+00,  5.840e-01,
         -6.980e-01,  1.472e-01, -5.390e-01, -1.199e+00],
        [-6.053e-01, -1.990e+00, -1.152e+00, -1.363e+00,  1.264e+00, -1.039e+00,
         -1.318e+00,  1.125e+00, -1.656e+00,  1.535e+00],
        [-1.677e+00, -1.788e+00, -9.667e-01, -5.741e-04, -4.477e-01, -7.736e-01,
          5.984e-03, -5.967e-01, -1.296e+00, -9.936e-01],
        [-1.771e+00, -2.106e+00, -1.534e+00, -2.314e-01,  4.041e-01, -1.095e+00,
         -5.769e-01, -1.640e+00,  2.137e+00, -1.257e+00],
        [-7.677e-01, -1.915e+00, -2.321e+00, -1.260e-01, -1.240e+00, -1.869e+00,
         -1.094e+00,  7.689e-01,  7.295e-02,  6.032e+00],
        [-2.419e+00,  2.359e+00,  6.824e-01, -1.130e+00,  1.771e+01, -1.830e+00,
         -3.853e-01, -2.967e-01,  1.016e+00,  1.697e+00],
        [-8.780e-02, -7.680e-01,  1.432e+00,  1.941e-01,  3.467e-01, -1.620e-01,
         -1.091e+00, -1.284e+00, -7.938e-01,  1.339e+00],
        [-8.170e-01,  2.756e+00, -2.379e+00, -4.794e-01,  1.751e-01, -1.976e+00,
         -1.282e+00, -1.177e+00, -1.513e+00, -8.730e-01],
        [-1.741e+00,  7.534e+00,  3.204e+00, -6.448e-01, -1.780e+00,  1.599e+00,
          2.218e-01,  4.335e-01, -8.371e-01,  1.100e+01],
        [-6.414e-01, -3.793e-01, -1.373e+00,  1.433e+00, -2.476e-01, -9.511e-01,
         -1.653e+00,  1.910e+00, -1.258e+00, -9.027e-01],
        [ 2.365e+00, -6.197e-01,  3.382e-02,  3.355e-01, -1.629e+00, -1.465e+00,
         -2.410e+00, -1.776e+00, -1.123e+00, -2.040e+00],
        [-8.539e-01, -7.847e-01, -1.584e+00, -1.681e+00, -7.632e-01,  1.073e+01,
         -1.662e+00,  1.051e+00, -7.344e-01, -2.353e+00],
        [ 1.068e+00, -6.174e-01, -2.234e+00, -1.094e+00, -9.533e-01,  3.140e-01,
          1.686e+00,  1.573e+00,  4.218e+00, -6.125e-01],
        [-5.111e-01,  1.221e+00,  1.160e+00, -4.149e-01, -1.667e+00, -5.391e-01,
         -1.216e+00, -1.429e+00, -1.464e+00, -1.105e+00],
        [ 1.655e+00, -3.895e-01, -1.337e+00,  8.676e-01, -6.649e-01, -1.664e+00,
          2.629e-01, -1.457e+00, -1.282e+00, -7.367e-01],
        [-6.675e-01, -7.890e-01,  3.518e-01, -1.093e+00, -8.726e-01, -1.087e+00,
         -9.385e-01, -2.796e-01, -4.910e-01, -4.382e-01],
        [-7.827e-01, -1.127e+00,  1.100e+00, -1.472e+00,  1.055e-01,  7.782e+00,
         -8.160e-01, -1.699e+00, -1.553e-01, -1.276e+00],
        [-1.312e-01, -6.983e-01, -1.016e+00, -1.597e+00, -1.643e+00, -1.443e+00,
         -1.146e+00, -1.143e+00,  2.111e+00, -1.130e+00],
        [ 3.411e-01, -5.698e-01,  6.778e-01, -2.423e+00,  1.659e-01,  8.155e-01,
         -4.274e-01, -1.981e+00, -9.025e-01, -1.998e+00],
        [-1.565e+00,  6.609e-01, -8.437e-01, -1.233e+00,  6.417e-01, -8.553e-01,
          1.181e+00, -6.430e-01, -9.260e-01,  2.210e-01],
        [-1.104e+00, -2.370e+00, -9.674e-01, -1.220e+00, -2.647e+00, -7.820e-01,
         -8.701e-01,  1.574e+00,  4.589e+00,  5.709e-01],
        [-2.839e-01, -1.534e+00, -9.984e-01, -3.279e-01, -1.298e+00, -9.158e-01,
         -7.158e-01, -1.169e+00,  1.419e+00,  3.951e+00],
        [-1.441e+00, -1.461e+00, -5.528e-01, -6.819e-01, -1.402e+00, -2.359e-01,
         -6.488e-01, -1.136e+00,  1.801e+00, -2.327e-01],
        [-1.435e+00,  7.475e-01, -7.463e-01, -1.892e+00, -1.928e+00, -1.682e+00,
         -1.020e+00, -5.169e-01,  9.171e-01, -9.075e-01],
        [ 4.199e-01,  5.455e-01, -1.791e-02, -1.783e+00,  1.392e+00,  7.687e-01,
         -1.121e+00, -1.062e+00,  4.017e+00,  1.000e+00],
        [-1.326e+00, -9.365e-01, -1.126e+00, -1.401e-02, -1.631e+00,  1.555e+00,
         -1.332e+00, -9.564e-01, -1.265e+00, -7.742e-01],
        [-8.155e-01, -2.049e+00, -8.669e-01, -1.194e+00, -1.036e+00, -1.619e+00,
         -7.685e-01, -1.107e+00, -2.215e+00,  5.397e+00],
        [ 2.281e+00, -7.722e-01, -1.563e-01, -1.215e+00, -2.722e+00, -3.080e-01,
          8.349e-03,  5.347e+00,  2.017e+00, -1.062e-01],
        [-8.499e-01, -9.167e-01, -1.513e+00,  4.812e-01,  1.326e+00, -1.523e+00,
          2.138e+00, -4.133e-01, -1.498e+00,  3.438e+00],
        [ 1.339e+00, -1.469e+00, -8.901e-01, -7.382e-01, -7.826e-01,  1.580e+00,
         -7.706e-01,  1.102e-01, -1.044e+00,  1.107e+00],
        [-8.673e-01, -9.266e-01, -1.336e+00,  1.408e+00, -1.822e+00, -1.514e+00,
         -1.488e+00, -8.281e-01,  9.484e-01,  2.735e-01],
        [-1.081e+00,  2.854e+00, -6.498e-01,  3.170e+00,  2.253e+00, -2.752e+00,
         -4.045e-01, -1.220e+00, -1.156e-01, -1.654e+00],
        [ 3.143e+00, -1.306e+00,  4.054e+00, -1.523e+00, -1.817e+00,  4.663e-01,
         -2.113e+00, -9.601e-01, -6.629e-01, -8.067e-01],
        [-1.836e+00, -5.904e-01, -1.295e+00,  4.246e-01, -1.599e+00,  9.692e-01,
         -1.981e+00, -1.529e+00, -8.051e-01,  9.189e+00],
        [-9.099e-01,  5.543e-01, -1.152e+00, -2.205e+00,  1.126e-01, -1.613e+00,
          2.495e+00,  1.942e+00, -1.569e+00,  7.352e+00],
        [-4.818e-01,  1.341e+00,  4.370e-01,  6.123e-02, -1.491e+00, -1.156e+00,
          6.426e-03, -1.318e+00,  8.443e-01, -7.420e-01],
        [-1.480e+00, -3.404e-01, -2.225e-02, -9.970e-01, -5.623e-01, -8.919e-01,
         -7.646e-01, -6.784e-01, -1.357e+00, -6.835e-01],
        [-1.164e+00,  1.167e+00, -1.045e+00, -1.560e-02, -2.194e-01, -1.709e+00,
          2.507e+00, -5.922e-01, -8.690e-01, -7.095e-01],
        [-6.937e-01, -7.236e-01, -1.264e+00, -1.625e-01, -4.546e-01, -1.128e+00,
         -1.867e+00, -7.180e-01, -6.795e-01, -1.077e+00],
        [ 1.813e+00, -1.102e+00, -1.170e+00, -6.800e-01,  5.935e+00,  2.748e+00,
         -1.950e+00, -2.303e+00, -7.240e-01,  3.504e-01],
        [-2.104e+00, -7.981e-02, -7.070e-01, -1.373e+00, -1.676e+00, -1.279e+00,
         -8.966e-01, -1.117e+00, -3.973e-01, -1.043e+00],
        [-4.235e-01, -7.273e-01, -1.883e+00, -5.954e-01, -1.161e+00,  1.450e+00,
          9.669e-01, -7.985e-01,  2.223e+00,  2.874e+00],
        [-9.100e-01, -1.767e+00,  3.896e+00, -1.018e+00,  1.086e+00, -1.206e+00,
          2.938e+00, -1.122e-01, -5.966e-01, -4.466e-01],
        [-1.253e+00, -1.437e+00, -1.428e+00,  1.313e+00,  2.341e-01, -1.432e+00,
         -1.135e+00, -1.224e+00, -1.176e+00, -1.445e+00],
        [-9.733e-01, -1.671e+00, -7.357e-01, -2.275e-01, -6.864e-01, -2.014e+00,
         -1.611e+00,  4.670e-01,  1.515e+00, -1.086e+00],
        [ 1.477e+00, -6.646e-01, -3.429e-01, -3.499e-01,  5.577e-01,  5.942e-01,
         -1.669e+00, -7.738e-01, -7.226e-01, -6.110e-01],
        [-1.434e+00, -1.347e+00, -1.115e+00, -5.320e-01, -9.277e-01, -4.329e-01,
          3.751e-01, -1.120e+00, -2.319e+00,  3.277e+00],
        [-1.302e+00, -1.314e+00, -1.113e+00, -6.526e-01, -5.497e-01, -3.008e-01,
         -1.862e+00, -1.397e+00, -8.222e-01, -1.249e+00],
        [-5.950e-01, -1.700e+00,  3.589e-01,  6.954e-01, -2.699e-01, -6.309e-01,
         -1.233e+00,  1.792e-01,  2.068e+00,  1.788e+00],
        [ 6.817e-01, -9.942e-01, -9.382e-01, -7.386e-01,  3.147e+00, -8.550e-01,
         -7.354e-01, -5.092e-01, -7.221e-01, -2.249e-02],
        [ 2.903e-01, -8.119e-01, -6.312e-01,  3.893e+00, -6.863e-01, -2.786e+00,
         -1.341e+00,  1.229e+00, -2.399e+00, -1.544e+00],
        [-1.073e-01,  3.876e+00,  2.428e+00, -6.681e-01, -1.332e+00, -1.251e+00,
          5.452e+00, -1.718e+00, -1.066e+00, -2.001e+00],
        [-9.821e-01, -1.855e+00, -9.219e-01,  2.065e+00,  2.065e+00, -3.970e-01,
         -2.105e+00,  3.399e+00,  5.354e-01, -6.718e-01],
        [ 9.302e-01, -1.120e+00, -2.135e-01,  1.469e+00,  1.472e+00, -1.539e+00,
         -2.414e+00, -6.167e-01, -2.719e+00, -5.825e-01],
        [-1.105e+00,  2.839e+00,  1.594e+00, -1.420e+00, -1.334e+00,  7.536e+00,
          4.830e-01,  4.237e+00, -3.531e-02, -1.121e+00],
        [-5.686e-01, -5.288e-01, -3.641e-01, -8.630e-02,  1.260e+00, -9.242e-01,
         -1.652e+00,  9.950e-01,  1.603e+00, -7.296e-01],
        [-2.335e+00,  7.341e-01, -3.538e-01,  3.411e+00,  8.664e-01, -3.496e-01,
         -1.558e+00, -3.093e-01, -1.579e-01,  1.098e+00],
        [-1.389e+00, -1.068e+00, -1.107e+00, -4.362e-01, -1.351e+00, -9.055e-01,
         -1.127e+00,  7.544e-01, -2.014e-01, -6.971e-01],
        [-1.122e+00, -1.378e+00, -6.648e-01, -4.402e-01, -1.891e+00, -7.173e-01,
         -1.409e+00, -1.185e+00, -3.633e-01, -5.377e-01],
        [ 1.149e+00,  4.216e-01,  5.649e-01, -8.797e-01, -9.904e-02, -1.635e+00,
          5.073e+00,  3.601e-01, -5.510e-01,  2.712e+00],
        [-1.223e+00, -1.756e+00, -6.629e-01, -1.307e+00, -9.148e-01, -1.902e+00,
          1.284e+01, -1.179e+00, -1.137e+00,  7.669e-01],
        [-8.638e-01,  6.753e+00, -8.212e-01, -1.016e+00, -1.504e+00, -1.631e+00,
         -5.053e-02, -1.619e+00, -1.905e+00, -8.775e-01],
        [-5.898e-01, -1.346e+00,  1.700e-01, -9.901e-01, -4.609e-02, -8.021e-01,
          2.272e+00, -1.160e+00,  1.652e+00, -1.142e+00],
        [-1.317e+00, -1.860e+00, -2.785e-01, -1.950e+00,  1.007e+00, -7.807e-01,
         -4.088e-01, -1.133e+00,  1.310e+00, -2.108e+00],
        [ 1.272e+00, -2.042e+00, -7.745e-01, -1.431e+00, -4.869e-01, -6.524e-01,
         -2.508e+00, -3.185e-01,  9.504e+00,  1.164e+00],
        [-1.691e+00, -1.787e+00, -7.658e-01,  5.014e-01, -1.405e+00, -2.037e+00,
         -2.386e+00, -2.292e-01, -1.662e+00, -8.288e-01],
        [-2.088e+00, -1.203e+00, -1.750e+00, -1.168e+00, -1.634e+00, -8.755e-01,
         -3.629e-01,  1.761e+00, -6.839e-01, -1.229e+00],
        [-1.220e+00, -1.646e+00, -1.235e+00, -6.585e-01, -2.213e+00, -1.830e+00,
         -1.747e+00,  9.191e+00,  1.272e+00, -1.181e+00],
        [-4.323e-01, -2.046e+00, -1.588e+00, -6.562e-01, -1.933e+00, -1.805e+00,
          2.184e+00, -2.946e-01,  4.614e-01, -7.212e-01],
        [ 3.558e+00, -1.193e+00, -1.447e+00,  2.455e-01, -1.067e+00, -8.430e-01,
          1.745e+00, -5.283e-01, -8.191e-01, -1.259e-01],
        [-7.846e-01,  1.206e+00, -1.641e+00, -3.136e-01,  1.726e+00,  2.178e+00,
         -1.316e+00, -1.598e+00, -1.250e+00, -6.725e-01],
        [ 1.795e+00, -1.926e+00, -1.081e+00, -4.531e-01, -1.055e+00, -1.851e+00,
          3.900e+00, -7.050e-01, -1.383e+00, -1.479e+00],
        [-1.551e+00,  1.633e+00, -1.185e+00,  2.881e-01, -9.830e-01,  5.092e-01,
         -1.469e+00, -6.816e-02, -1.268e+00, -4.171e-01],
        [ 4.708e+00, -8.023e-01,  4.812e+00,  7.752e-01, -1.508e+00,  6.052e-01,
         -1.101e+00, -1.215e+00, -1.707e+00,  1.397e+00],
        [-1.700e-02,  2.143e-01,  4.024e-01, -8.279e-01,  1.604e+00,  5.090e+00,
         -7.040e-01,  1.521e-01,  1.118e+00,  2.057e+00],
        [-1.464e+00, -5.647e-02,  9.700e-01, -8.190e-01, -1.013e+00, -9.949e-01,
          6.890e-01, -4.668e-01, -1.510e+00,  1.559e+00],
        [-8.712e-01, -7.082e-01,  4.432e+00, -3.828e-01,  1.478e+00, -1.427e+00,
         -1.052e+00, -9.147e-02, -9.599e-01, -1.559e+00],
        [-1.232e+00, -6.630e-01, -1.933e+00, -2.259e+00,  1.684e+00, -1.820e+00,
         -1.505e+00,  9.835e+00, -8.059e-01,  3.428e+00],
        [ 6.765e-01, -2.528e-01, -3.125e-01, -7.043e-01, -9.282e-01,  6.400e-01,
         -1.528e+00,  1.608e+00,  2.338e+00, -2.200e+00],
        [-2.329e+00,  7.512e-01,  7.087e-01, -1.194e+00, -9.007e-01, -1.306e+00,
         -1.004e+00, -1.511e+00,  4.422e+00, -6.800e-01],
        [-1.369e+00, -1.848e+00, -4.658e-01,  2.177e+00, -1.378e+00, -3.093e+00,
          3.827e+00,  1.691e+00, -1.134e+00, -2.897e+00],
        [-7.833e-01, -8.433e-01, -6.406e-01, -6.218e-01, -1.014e+00, -3.851e-01,
         -2.064e+00, -1.682e+00, -1.608e+00, -9.969e-01],
        [ 5.088e+00, -8.059e-01, -1.361e+00, -1.579e+00, -1.227e+00,  8.133e-01,
         -1.347e+00, -1.028e+00, -6.491e-01, -7.702e-01],
        [-1.477e+00,  2.658e+00, -2.360e+00, -1.262e+00, -1.382e+00, -9.930e-01,
         -1.821e+00,  2.129e+00, -7.962e-01, -1.619e+00]], device='cuda:0')
v tensor([[1.000e-12, 1.189e+00, 1.000e-12, 9.344e-01, 8.633e-02, 1.000e-12,
         1.770e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [3.695e+00, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.099e+00, 1.000e-12, 1.000e-12, 2.360e-01],
        [1.897e+00, 2.184e+00, 5.379e+00, 5.759e-02, 1.000e-12, 1.000e-12,
         1.000e-12, 8.934e-01, 1.000e-12, 1.000e-12],
        [2.926e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.083e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 5.870e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.049e+00, 1.000e-12, 1.000e-12],
        [1.899e-01, 2.733e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         2.860e+00, 1.000e-12, 1.764e-01, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.299e+00, 3.970e-01, 1.393e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 2.681e-01],
        [7.148e-01, 1.000e-12, 4.254e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 9.200e-01, 1.000e-12],
        [6.431e+00, 5.998e+00, 1.000e-12, 2.220e+00, 7.111e-01, 1.000e-12,
         1.000e-12, 1.401e+00, 6.274e-01, 1.000e-12],
        [2.354e+00, 1.000e-12, 1.000e-12, 1.708e-01, 1.000e-12, 5.981e+00,
         5.326e+00, 3.760e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.807e+00],
        [1.000e-12, 1.157e-01, 1.000e-12, 1.000e-12, 1.922e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 6.539e-01, 1.000e-12],
        [1.000e-12, 2.366e-01, 5.834e+00, 1.000e-12, 2.627e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 5.797e-01],
        [7.515e-01, 1.159e-01, 1.000e-12, 7.422e-01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 7.427e-04, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.419e+00, 5.840e-01,
         1.000e-12, 1.472e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.264e+00, 1.000e-12,
         1.000e-12, 1.125e+00, 1.000e-12, 1.535e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         5.984e-03, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 4.041e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 2.137e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 7.689e-01, 7.295e-02, 6.032e+00],
        [1.000e-12, 2.359e+00, 6.824e-01, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.016e+00, 1.697e+00],
        [1.000e-12, 1.000e-12, 1.432e+00, 1.941e-01, 3.467e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.339e+00],
        [1.000e-12, 2.756e+00, 1.000e-12, 1.000e-12, 1.751e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 7.534e+00, 3.204e+00, 1.000e-12, 1.000e-12, 1.599e+00,
         2.218e-01, 4.335e-01, 1.000e-12, 1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.433e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 1.910e+00, 1.000e-12, 1.000e-12],
        [2.365e+00, 1.000e-12, 3.382e-02, 3.355e-01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
         1.000e-12, 1.051e+00, 1.000e-12, 1.000e-12],
        [1.068e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.140e-01,
         1.686e+00, 1.573e+00, 4.218e+00, 1.000e-12],
        [1.000e-12, 1.221e+00, 1.160e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.655e+00, 1.000e-12, 1.000e-12, 8.676e-01, 1.000e-12, 1.000e-12,
         2.629e-01, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 3.518e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.100e+00, 1.000e-12, 1.055e-01, 7.782e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 2.111e+00, 1.000e-12],
        [3.411e-01, 1.000e-12, 6.778e-01, 1.000e-12, 1.659e-01, 8.155e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 6.609e-01, 1.000e-12, 1.000e-12, 6.417e-01, 1.000e-12,
         1.181e+00, 1.000e-12, 1.000e-12, 2.210e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.574e+00, 4.589e+00, 5.709e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.419e+00, 3.951e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.801e+00, 1.000e-12],
        [1.000e-12, 7.475e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 9.171e-01, 1.000e-12],
        [4.199e-01, 5.455e-01, 1.000e-12, 1.000e-12, 1.392e+00, 7.687e-01,
         1.000e-12, 1.000e-12, 4.017e+00, 1.000e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.555e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 5.397e+00],
        [2.281e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         8.349e-03, 5.347e+00, 2.017e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 4.812e-01, 1.326e+00, 1.000e-12,
         2.138e+00, 1.000e-12, 1.000e-12, 3.438e+00],
        [1.339e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.580e+00,
         1.000e-12, 1.102e-01, 1.000e-12, 1.107e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.408e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 9.484e-01, 2.735e-01],
        [1.000e-12, 2.854e+00, 1.000e-12, 3.170e+00, 2.253e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [3.143e+00, 1.000e-12, 4.054e+00, 1.000e-12, 1.000e-12, 4.663e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 4.246e-01, 1.000e-12, 9.692e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 9.189e+00],
        [1.000e-12, 5.543e-01, 1.000e-12, 1.000e-12, 1.126e-01, 1.000e-12,
         2.495e+00, 1.942e+00, 1.000e-12, 7.352e+00],
        [1.000e-12, 1.341e+00, 4.370e-01, 6.123e-02, 1.000e-12, 1.000e-12,
         6.426e-03, 1.000e-12, 8.443e-01, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.167e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         2.507e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.813e+00, 1.000e-12, 1.000e-12, 1.000e-12, 5.935e+00, 2.748e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 3.504e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.450e+00,
         9.669e-01, 1.000e-12, 2.223e+00, 2.874e+00],
        [1.000e-12, 1.000e-12, 3.896e+00, 1.000e-12, 1.086e+00, 1.000e-12,
         2.938e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.313e+00, 2.341e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 4.670e-01, 1.515e+00, 1.000e-12],
        [1.477e+00, 1.000e-12, 1.000e-12, 1.000e-12, 5.577e-01, 5.942e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         3.751e-01, 1.000e-12, 1.000e-12, 3.277e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 3.589e-01, 6.954e-01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.792e-01, 2.068e+00, 1.788e+00],
        [6.817e-01, 1.000e-12, 1.000e-12, 1.000e-12, 3.147e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [2.903e-01, 1.000e-12, 1.000e-12, 3.893e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 1.229e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 3.876e+00, 2.428e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         5.452e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 2.065e+00, 2.065e+00, 1.000e-12,
         1.000e-12, 3.399e+00, 5.354e-01, 1.000e-12],
        [9.302e-01, 1.000e-12, 1.000e-12, 1.469e+00, 1.472e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 2.839e+00, 1.594e+00, 1.000e-12, 1.000e-12, 7.536e+00,
         4.830e-01, 4.237e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.260e+00, 1.000e-12,
         1.000e-12, 9.950e-01, 1.603e+00, 1.000e-12],
        [1.000e-12, 7.341e-01, 1.000e-12, 3.411e+00, 8.664e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.098e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 7.544e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.149e+00, 4.216e-01, 5.649e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         5.073e+00, 3.601e-01, 1.000e-12, 2.712e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e-12, 1.000e-12, 7.669e-01],
        [1.000e-12, 6.753e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.700e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         2.272e+00, 1.000e-12, 1.652e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.007e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.310e+00, 1.000e-12],
        [1.272e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 9.504e+00, 1.164e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 5.014e-01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.761e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 9.191e+00, 1.272e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         2.184e+00, 1.000e-12, 4.614e-01, 1.000e-12],
        [3.558e+00, 1.000e-12, 1.000e-12, 2.455e-01, 1.000e-12, 1.000e-12,
         1.745e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.206e+00, 1.000e-12, 1.000e-12, 1.726e+00, 2.178e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.795e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         3.900e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.633e+00, 1.000e-12, 2.881e-01, 1.000e-12, 5.092e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [4.708e+00, 1.000e-12, 4.812e+00, 7.752e-01, 1.000e-12, 6.052e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.397e+00],
        [1.000e-12, 2.143e-01, 4.024e-01, 1.000e-12, 1.604e+00, 5.090e+00,
         1.000e-12, 1.521e-01, 1.118e+00, 2.057e+00],
        [1.000e-12, 1.000e-12, 9.700e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         6.890e-01, 1.000e-12, 1.000e-12, 1.559e+00],
        [1.000e-12, 1.000e-12, 4.432e+00, 1.000e-12, 1.478e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.684e+00, 1.000e-12,
         1.000e-12, 9.835e+00, 1.000e-12, 3.428e+00],
        [6.765e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 6.400e-01,
         1.000e-12, 1.608e+00, 2.338e+00, 1.000e-12],
        [1.000e-12, 7.512e-01, 7.087e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 4.422e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 2.177e+00, 1.000e-12, 1.000e-12,
         3.827e+00, 1.691e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [5.088e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 8.133e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 2.658e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 2.129e+00, 1.000e-12, 1.000e-12]], device='cuda:0')
v before min max tensor([ 0.007, -0.634, -0.953, -0.685, -0.984,  1.627, -1.187, -0.665,  0.691,
        -0.916, -1.102, -0.467,  0.872,  6.800, -1.483, -0.644,  1.073, -1.009,
         2.107, -0.160, -1.051, -0.165,  0.363, -0.962, -1.292,  0.226, -0.187,
         4.812, -0.384, -0.982, -1.079, -0.896,  0.297, -0.165, -0.496, -0.569,
        -1.068, -0.911,  0.050, -0.432,  0.474, -0.971, -0.759,  3.007,  0.878,
         0.422, -1.395, -1.649, -1.067,  0.951,  7.025, -0.189, -1.130,  4.859,
        -1.015,  2.455, -0.291, -0.866,  0.756, -0.659,  3.608, -0.058, -2.041,
         1.749, -1.426, -1.143,  3.069,  1.775,  3.640, -0.768,  6.078, -1.707,
        -0.267, -0.134,  2.730,  2.405, -1.289, -1.430, -2.423, -1.529,  2.112,
        -0.628,  1.728, -0.824, -0.670, -1.499, -0.180, -1.485, -1.275, -1.220,
        -0.841,  1.496,  4.339, -1.917,  2.953,  2.168,  3.736, -0.109,  2.055,
        -0.484], device='cuda:0')
v tensor([7.166e-03, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.627e+00,
        1.000e-12, 1.000e-12, 6.906e-01, 1.000e-12, 1.000e-12, 1.000e-12,
        8.722e-01, 6.800e+00, 1.000e-12, 1.000e-12, 1.073e+00, 1.000e-12,
        2.107e+00, 1.000e-12, 1.000e-12, 1.000e-12, 3.631e-01, 1.000e-12,
        1.000e-12, 2.260e-01, 1.000e-12, 4.812e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 2.973e-01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 4.974e-02, 1.000e-12, 4.743e-01, 1.000e-12,
        1.000e-12, 3.007e+00, 8.778e-01, 4.218e-01, 1.000e-12, 1.000e-12,
        1.000e-12, 9.506e-01, 7.025e+00, 1.000e-12, 1.000e-12, 4.859e+00,
        1.000e-12, 2.455e+00, 1.000e-12, 1.000e-12, 7.555e-01, 1.000e-12,
        3.608e+00, 1.000e-12, 1.000e-12, 1.749e+00, 1.000e-12, 1.000e-12,
        3.069e+00, 1.775e+00, 3.640e+00, 1.000e-12, 6.078e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 2.730e+00, 2.405e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 2.112e+00, 1.000e-12, 1.728e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.496e+00, 4.339e+00, 1.000e-12, 2.953e+00, 2.168e+00,
        3.736e+00, 1.000e-12, 2.055e+00, 1.000e-12], device='cuda:0')
v before min max tensor([[[-1.100],
         [21.027],
         [ 3.687],
         [-1.377],
         [ 6.500],
         [-2.228],
         [ 5.203],
         [-1.573],
         [-0.987],
         [ 1.018]],

        [[-1.366],
         [ 0.087],
         [ 2.374],
         [-1.958],
         [ 3.948],
         [-0.719],
         [-0.355],
         [ 0.883],
         [-0.118],
         [-0.103]],

        [[-2.319],
         [-1.593],
         [ 1.648],
         [-0.731],
         [ 0.935],
         [-1.872],
         [-1.714],
         [-0.737],
         [-1.566],
         [ 0.639]],

        [[-1.124],
         [-0.864],
         [-0.964],
         [ 1.651],
         [ 0.395],
         [-0.758],
         [-1.719],
         [-0.421],
         [-2.008],
         [-0.476]],

        [[-1.151],
         [ 3.270],
         [ 1.043],
         [ 0.389],
         [ 2.607],
         [-0.624],
         [-2.324],
         [-1.613],
         [-1.299],
         [ 0.413]],

        [[-1.436],
         [-2.466],
         [-0.941],
         [ 1.076],
         [-1.876],
         [-1.697],
         [-2.432],
         [ 5.803],
         [-0.921],
         [-1.096]],

        [[-1.521],
         [-2.082],
         [-1.499],
         [-2.475],
         [ 0.021],
         [ 0.986],
         [-0.917],
         [ 6.520],
         [ 5.530],
         [-1.416]],

        [[-1.231],
         [-0.763],
         [-0.559],
         [-1.043],
         [-0.537],
         [-2.312],
         [ 5.990],
         [ 0.512],
         [ 5.907],
         [ 4.032]],

        [[-1.204],
         [-1.061],
         [-1.211],
         [ 2.244],
         [-0.928],
         [-1.466],
         [-0.051],
         [-0.683],
         [-1.449],
         [-2.425]],

        [[-0.305],
         [-1.328],
         [-0.945],
         [-0.810],
         [-1.093],
         [-0.237],
         [-0.722],
         [-1.493],
         [-0.756],
         [ 4.816]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e+01],
         [3.687e+00],
         [1.000e-12],
         [6.500e+00],
         [1.000e-12],
         [5.203e+00],
         [1.000e-12],
         [1.000e-12],
         [1.018e+00]],

        [[1.000e-12],
         [8.681e-02],
         [2.374e+00],
         [1.000e-12],
         [3.948e+00],
         [1.000e-12],
         [1.000e-12],
         [8.830e-01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.648e+00],
         [1.000e-12],
         [9.350e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.390e-01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.651e+00],
         [3.953e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [3.270e+00],
         [1.043e+00],
         [3.888e-01],
         [2.607e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.132e-01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.076e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.803e+00],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.146e-02],
         [9.861e-01],
         [1.000e-12],
         [6.520e+00],
         [5.530e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.990e+00],
         [5.115e-01],
         [5.907e+00],
         [4.032e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.244e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.816e+00]]], device='cuda:0')
v before min max tensor([[18.224],
        [-1.099],
        [ 2.688],
        [ 2.047],
        [-0.989],
        [-0.683],
        [ 0.197],
        [ 0.969],
        [-1.752],
        [ 4.880]], device='cuda:0')
v tensor([[1.000e+01],
        [1.000e-12],
        [2.688e+00],
        [2.047e+00],
        [1.000e-12],
        [1.000e-12],
        [1.966e-01],
        [9.689e-01],
        [1.000e-12],
        [4.880e+00]], device='cuda:0')
a after update for 1 param tensor([[ 6.979e-03, -1.539e-02,  2.263e-02,  3.018e-02,  1.371e-02,  1.150e-02,
         -2.267e-02,  1.075e-02,  2.954e-03, -3.623e-02],
        [ 3.713e-03, -9.304e-04,  8.756e-03,  3.440e-03,  7.691e-03, -1.069e-03,
         -3.251e-03,  9.684e-03, -1.988e-02, -4.252e-03],
        [ 9.106e-03, -8.822e-03,  9.718e-03,  1.188e-02, -8.731e-03,  1.581e-02,
         -5.627e-03,  6.309e-03, -2.859e-02,  4.596e-03],
        [ 1.745e-03,  3.775e-03, -1.722e-02,  2.039e-03,  3.028e-02,  3.582e-02,
          3.424e-03, -8.289e-03, -3.449e-02,  4.488e-03],
        [ 6.101e-03, -8.120e-03, -1.778e-02,  1.850e-03, -6.185e-03,  2.921e-02,
          1.451e-03, -1.844e-03,  1.892e-02, -2.153e-02],
        [-2.349e-03,  3.239e-02,  1.042e-02,  4.744e-02, -1.666e-02, -1.649e-02,
         -5.542e-04,  1.480e-02, -9.500e-03,  1.963e-03],
        [-3.770e-03,  5.677e-03, -2.876e-03,  1.651e-02,  3.221e-03,  4.222e-02,
          9.756e-03, -2.049e-03,  8.389e-04,  2.071e-03],
        [-2.488e-03,  1.174e-02,  1.017e-02,  3.560e-03,  3.958e-03,  1.491e-02,
          4.963e-03, -1.212e-02, -4.592e-03, -8.503e-03],
        [ 1.318e-03,  1.158e-02, -1.149e-02,  4.945e-02, -2.071e-02,  2.914e-02,
          1.447e-02, -6.350e-02, -6.340e-03, -7.357e-03],
        [ 1.218e-02, -1.655e-02, -2.478e-02, -1.522e-02, -7.182e-03, -5.942e-04,
         -1.638e-02,  1.239e-02,  1.913e-02, -9.267e-03],
        [ 5.417e-03,  2.094e-04, -8.076e-03, -1.233e-02,  1.256e-02,  8.376e-03,
          1.406e-03,  9.789e-03, -9.239e-03,  1.755e-02],
        [ 1.050e-02,  1.494e-03,  1.751e-02,  1.697e-02,  8.197e-03,  4.565e-03,
         -2.868e-02, -1.587e-02, -1.199e-02, -6.109e-03],
        [-1.335e-02, -2.088e-03,  6.382e-04, -1.069e-04, -1.697e-02, -4.810e-03,
          1.077e-02,  2.538e-02, -3.161e-02,  1.306e-02],
        [ 1.448e-02, -1.769e-03,  3.094e-03, -6.243e-03,  2.034e-02, -1.683e-02,
         -5.690e-04,  1.656e-02, -2.354e-03, -1.174e-02],
        [ 3.590e-03, -1.779e-02,  8.950e-03,  6.951e-04,  1.634e-02,  8.494e-03,
          7.987e-03, -4.177e-03,  3.214e-03,  1.829e-02],
        [-2.761e-02,  1.383e-02, -1.416e-02,  1.105e-02, -5.441e-02, -5.817e-03,
          3.693e-03,  4.051e-04,  3.797e-02, -1.834e-02],
        [-4.408e-03, -2.200e-02, -1.019e-02,  1.815e-02, -1.553e-02,  2.176e-02,
         -1.346e-03, -2.261e-02, -5.578e-03,  7.046e-03],
        [ 1.424e-02,  3.461e-03, -1.908e-02, -7.177e-03,  3.144e-03, -3.781e-03,
          3.678e-03,  5.377e-03, -5.933e-03, -1.813e-03],
        [-3.837e-04, -9.572e-03,  9.534e-03,  2.228e-02, -4.902e-04, -7.616e-03,
          1.653e-02, -6.104e-03, -3.170e-02, -1.424e-02],
        [ 4.534e-03, -3.207e-03, -2.161e-02,  1.804e-02, -1.236e-02,  2.093e-02,
          1.265e-02, -3.514e-02,  4.261e-02, -3.932e-03],
        [-7.902e-03, -2.188e-03, -8.920e-03,  3.074e-02, -2.215e-03,  5.284e-03,
          6.665e-03, -1.219e-02, -1.901e-02,  4.993e-03],
        [-2.067e-02,  9.339e-03,  2.775e-03, -1.778e-02,  3.793e-03,  8.202e-03,
         -2.224e-03, -6.723e-03, -1.082e-02, -5.030e-03],
        [ 4.672e-03,  1.756e-02,  4.028e-04, -2.459e-02,  3.797e-04, -2.730e-02,
          1.346e-02,  8.045e-03,  5.477e-03,  2.475e-02],
        [ 2.073e-02, -1.778e-02, -9.831e-04,  5.979e-03,  1.278e-03, -1.988e-02,
         -3.853e-03,  2.057e-02, -5.852e-04,  1.332e-02],
        [-2.714e-02, -1.293e-02,  4.895e-03, -4.430e-03,  1.563e-02, -1.153e-02,
         -7.302e-03, -3.902e-02,  2.292e-02, -1.526e-02],
        [ 7.831e-03,  8.199e-03,  5.947e-03, -1.912e-02,  7.789e-03, -1.699e-02,
          5.584e-04,  5.290e-03,  2.425e-02, -1.498e-03],
        [-1.293e-02,  1.641e-02, -1.003e-02, -1.227e-02,  1.508e-03,  2.705e-02,
          5.379e-03,  1.012e-02, -2.182e-02, -1.970e-02],
        [ 2.413e-02, -2.116e-03, -8.056e-04, -1.462e-02, -3.833e-02, -1.275e-02,
          4.373e-04, -1.124e-02, -6.273e-03, -1.398e-02],
        [ 3.483e-03,  9.025e-03, -7.225e-04,  6.336e-03,  5.476e-03,  2.692e-02,
         -2.065e-02, -5.195e-03, -2.696e-03, -6.645e-03],
        [-2.729e-03, -3.796e-03,  1.231e-04, -1.735e-02, -3.699e-03,  4.778e-02,
          4.805e-03,  2.252e-02,  3.819e-03,  6.117e-02],
        [ 3.308e-03, -1.248e-03, -4.412e-04,  1.195e-03,  2.075e-02, -8.321e-03,
         -7.500e-03,  1.353e-03, -4.910e-02, -3.827e-02],
        [-3.066e-03,  1.060e-02, -2.161e-03, -8.694e-04,  1.277e-02, -1.389e-03,
          1.272e-03, -2.579e-04, -3.635e-02, -1.143e-02],
        [ 6.102e-03, -1.662e-03, -4.539e-03, -7.076e-03,  7.118e-03, -2.878e-03,
         -1.564e-02,  2.660e-03, -2.348e-02, -5.078e-03],
        [-8.470e-03, -4.762e-03,  1.053e-02, -1.893e-03,  1.449e-02, -6.786e-03,
          2.694e-02,  4.192e-03, -3.403e-03,  2.752e-03],
        [ 8.158e-03,  3.516e-03, -1.377e-02, -8.866e-03, -3.141e-04,  9.302e-03,
          6.644e-03, -1.242e-02, -2.078e-02,  2.080e-02],
        [ 3.748e-03,  1.275e-03, -1.415e-03, -8.121e-04, -1.880e-03, -7.949e-03,
         -7.158e-04,  1.006e-02, -1.577e-02, -1.088e-03],
        [ 8.620e-03,  1.534e-02,  3.064e-03, -3.012e-03, -9.294e-03, -1.798e-04,
          5.380e-04, -3.092e-02, -1.031e-02, -1.279e-02],
        [-8.151e-03, -3.696e-03, -4.953e-03,  4.762e-03, -3.759e-03,  5.496e-03,
          8.611e-03,  2.471e-04,  1.122e-02, -1.369e-02],
        [ 1.186e-02, -2.902e-03, -1.009e-02,  9.780e-04,  4.531e-03, -6.144e-03,
          4.808e-03,  5.723e-05, -1.775e-02,  1.423e-02],
        [-6.184e-03, -7.929e-03, -1.182e-03,  8.896e-03,  2.092e-02,  7.460e-03,
         -4.240e-03,  4.513e-03,  2.070e-03,  7.963e-03],
        [-2.449e-03, -1.633e-03, -2.430e-02,  3.392e-02,  2.196e-03, -1.827e-03,
          3.903e-02,  7.347e-03, -5.342e-02,  1.913e-03],
        [ 1.689e-02, -2.463e-02, -1.870e-02, -5.600e-05,  1.343e-03,  1.257e-02,
          4.339e-03,  2.422e-02, -5.552e-03,  1.742e-02],
        [ 5.224e-03,  3.009e-02, -1.944e-02, -2.017e-02,  3.844e-03, -8.725e-03,
         -9.315e-03, -2.160e-03, -7.156e-05,  3.968e-03],
        [-1.017e-02, -2.015e-02, -1.673e-02, -1.115e-02, -1.445e-02, -5.068e-03,
          7.296e-03,  3.912e-03, -2.492e-03,  1.702e-02],
        [-9.477e-03, -7.580e-04,  5.107e-03,  7.392e-03, -1.483e-02, -2.361e-02,
          6.380e-03, -2.230e-02,  2.120e-03,  4.000e-03],
        [ 2.775e-02,  1.533e-02,  2.222e-02,  9.580e-03, -1.250e-03,  8.711e-03,
          3.858e-02,  3.228e-02,  2.576e-02, -1.854e-02],
        [ 4.741e-03, -1.131e-02,  2.878e-04,  2.535e-02, -3.954e-04,  5.185e-03,
          4.334e-03,  1.665e-02, -1.196e-02,  1.079e-02],
        [-8.442e-03, -8.072e-03, -1.108e-03, -1.549e-02,  1.290e-02,  8.895e-03,
          1.443e-03, -1.346e-02,  4.748e-03, -2.748e-03],
        [ 1.127e-02,  3.213e-02, -3.348e-02, -1.296e-02,  1.276e-03,  1.132e-03,
         -7.884e-03,  8.084e-03,  2.325e-02,  4.026e-03],
        [ 3.168e-03, -3.898e-02, -3.405e-02,  7.226e-03, -6.071e-03, -6.040e-03,
         -9.726e-03,  2.708e-02, -6.012e-03, -3.236e-03],
        [ 2.724e-03, -8.619e-03, -3.732e-03,  3.278e-02, -1.352e-03,  1.241e-02,
          9.585e-03, -6.267e-03,  1.884e-02, -3.405e-02],
        [-9.232e-03,  1.924e-02, -3.944e-03,  2.178e-02,  1.223e-02,  5.074e-03,
          5.921e-03, -6.962e-04,  3.629e-03,  3.377e-03],
        [-1.864e-02, -4.016e-02,  1.636e-03,  7.624e-03,  7.559e-03, -1.368e-03,
          5.682e-03, -5.176e-03, -3.143e-02,  1.767e-02],
        [ 3.660e-02,  9.917e-03,  7.930e-03,  2.556e-02, -9.391e-04,  1.149e-03,
          1.001e-02, -4.296e-02, -1.514e-02, -2.521e-02],
        [ 3.452e-03, -1.366e-02, -3.670e-03,  2.160e-02, -2.815e-03, -2.296e-03,
          7.708e-02,  3.054e-03, -1.178e-02, -8.161e-03],
        [ 1.884e-02,  5.185e-03, -2.659e-02, -5.062e-03,  1.553e-02,  3.785e-03,
          9.776e-03,  4.188e-03,  9.111e-03,  1.288e-03],
        [-1.841e-04,  1.050e-02, -2.445e-03, -2.817e-02, -7.048e-05,  9.260e-03,
         -6.359e-02, -1.422e-02, -9.830e-03,  1.325e-02],
        [-8.835e-03,  1.234e-02, -1.059e-02,  9.797e-03,  5.948e-03, -1.516e-03,
          8.786e-03, -2.153e-02,  4.687e-03, -3.749e-02],
        [-4.285e-03, -1.463e-02,  7.180e-03,  3.571e-02,  1.000e-02, -1.131e-02,
         -1.496e-02, -5.302e-03,  1.119e-02, -5.530e-03],
        [ 1.325e-02,  9.078e-03, -5.883e-03,  3.798e-02,  3.562e-02, -3.712e-03,
          8.305e-03,  2.876e-02,  3.556e-03,  4.383e-03],
        [ 1.148e-02, -6.880e-03,  7.160e-04,  3.213e-02,  3.714e-03, -1.783e-02,
         -3.614e-04,  1.745e-02,  2.978e-02, -1.237e-02],
        [-2.122e-03,  7.924e-03, -4.144e-04,  8.875e-03, -1.260e-02, -1.037e-02,
         -1.476e-02, -2.911e-02, -2.594e-02, -4.905e-03],
        [ 5.392e-03,  1.655e-02, -4.550e-03,  2.183e-03,  2.946e-03, -1.551e-03,
          9.065e-05, -1.698e-02, -4.824e-03,  2.718e-02],
        [ 1.250e-02,  8.640e-03,  1.693e-02,  3.166e-02,  6.553e-03, -2.042e-02,
         -6.517e-03, -1.111e-02, -6.878e-03, -2.000e-02],
        [-1.287e-02, -8.709e-03, -1.254e-02, -2.579e-02,  8.072e-03,  1.091e-03,
         -2.188e-03, -2.072e-02,  8.549e-03, -3.300e-03],
        [-1.317e-02, -2.939e-03,  1.407e-02,  4.452e-04,  7.416e-03, -1.220e-03,
         -1.055e-02,  9.536e-04,  1.885e-03, -2.203e-02],
        [ 1.758e-02, -7.342e-03, -4.638e-03,  9.909e-03, -2.757e-03, -3.065e-03,
         -4.792e-03,  6.013e-03, -3.241e-03, -3.766e-03],
        [ 8.936e-03,  7.997e-04, -1.341e-02, -4.054e-02,  1.060e-02,  1.791e-02,
          3.132e-03,  1.389e-02,  5.178e-03,  1.439e-02],
        [ 2.954e-02, -7.743e-03, -2.452e-02, -2.093e-03,  1.708e-02,  4.397e-03,
          5.339e-03,  1.298e-02,  9.043e-05, -2.007e-03],
        [ 3.045e-03,  7.470e-03,  7.451e-03,  3.400e-02, -1.135e-02, -4.143e-03,
         -8.336e-03, -3.549e-02,  4.250e-03, -2.854e-03],
        [ 1.340e-02,  5.719e-03, -4.551e-03, -4.408e-03, -7.992e-03,  1.391e-02,
         -7.863e-03, -1.224e-03, -2.468e-03, -1.768e-02],
        [ 5.030e-03, -4.418e-03, -2.408e-02, -9.483e-03,  6.260e-03,  4.363e-03,
          1.575e-02, -5.928e-04,  1.924e-02, -7.509e-04],
        [-5.978e-03, -7.656e-03, -2.383e-03, -1.969e-02, -1.450e-03, -1.050e-02,
         -1.225e-02, -8.130e-03, -6.387e-03, -1.971e-02],
        [ 3.327e-04, -1.391e-02,  2.549e-03, -3.118e-02, -1.190e-03,  8.290e-03,
          2.552e-02,  1.354e-03,  7.322e-03, -2.388e-02],
        [ 9.101e-03,  1.679e-02,  2.007e-02,  1.229e-02,  2.532e-03,  2.176e-03,
         -8.874e-03, -7.314e-03,  6.047e-03,  8.118e-04],
        [ 7.380e-03, -2.053e-03, -6.500e-03,  3.915e-02, -9.260e-03, -4.568e-03,
         -6.482e-03,  8.208e-03,  2.018e-03, -1.831e-02],
        [ 8.432e-03, -3.816e-03,  1.193e-02, -1.851e-02,  1.291e-02,  3.455e-03,
         -4.995e-03,  6.991e-03,  6.068e-03, -5.484e-03],
        [-2.020e-03,  1.292e-02, -7.796e-04,  4.441e-04,  1.189e-03,  9.566e-03,
         -5.567e-03,  2.755e-03, -2.449e-03, -2.846e-02],
        [-5.233e-04, -1.529e-02,  6.431e-03, -8.176e-03,  3.905e-04,  2.021e-02,
          2.123e-02, -6.623e-03, -1.743e-02,  3.456e-03],
        [ 1.454e-02, -1.620e-02, -6.970e-03, -1.013e-04, -7.162e-03,  8.895e-03,
         -4.068e-03,  1.213e-03, -1.226e-02, -1.131e-02],
        [-2.444e-04, -3.869e-03,  2.988e-02, -1.731e-03, -4.521e-03,  4.615e-03,
         -2.718e-02,  1.993e-02, -9.289e-03,  1.791e-03],
        [-8.692e-03, -9.545e-04,  1.361e-02, -2.520e-02,  1.499e-02, -6.610e-03,
          1.376e-02, -1.600e-02,  4.394e-03, -1.770e-02],
        [ 9.775e-03, -2.491e-03, -4.419e-03, -1.312e-02,  3.516e-03, -9.946e-04,
         -4.347e-03,  1.220e-04,  1.431e-03, -2.289e-03],
        [-5.066e-03, -3.515e-03,  1.171e-02, -4.154e-03,  2.591e-02,  2.950e-03,
          2.984e-02,  2.509e-03,  8.059e-03, -1.723e-03],
        [ 6.602e-03, -6.849e-03, -1.078e-02,  1.821e-02,  1.061e-02, -1.837e-02,
         -4.537e-03,  3.023e-02,  8.475e-04, -9.313e-03],
        [-3.485e-03,  4.310e-03,  1.180e-02,  1.314e-02,  2.531e-03,  4.549e-03,
          1.384e-02,  5.664e-03, -1.202e-03, -7.748e-03],
        [-8.071e-03,  5.525e-04, -6.045e-03, -1.970e-02, -1.969e-02,  7.474e-03,
         -5.025e-03, -2.223e-03,  7.729e-05,  2.665e-03],
        [ 7.736e-03,  7.447e-03,  5.646e-03,  5.958e-03, -5.635e-03, -2.248e-03,
         -1.443e-02,  1.007e-02,  4.557e-03, -1.029e-03],
        [ 3.994e-03,  8.451e-04,  1.468e-02,  1.327e-02,  7.269e-05, -1.154e-02,
         -1.653e-03, -6.104e-03, -9.568e-04, -4.218e-03],
        [-6.614e-03,  3.594e-03, -1.999e-03, -1.589e-02,  2.104e-03,  9.407e-03,
          1.208e-03,  2.913e-02,  6.187e-03, -4.087e-06],
        [ 1.942e-02,  2.513e-03, -1.980e-02,  2.701e-03,  1.401e-03,  1.281e-02,
         -2.325e-02,  2.189e-02,  1.535e-02,  2.999e-03],
        [ 1.003e-02,  1.548e-02,  3.460e-03, -4.792e-02,  2.045e-03,  4.135e-03,
          7.985e-03, -3.076e-02, -1.782e-02,  1.278e-02],
        [ 2.370e-03, -2.347e-02, -1.421e-02, -3.303e-03, -1.920e-03,  4.060e-03,
          2.689e-02,  9.725e-03,  3.914e-03,  5.384e-03],
        [-1.922e-02,  7.618e-04,  1.091e-02,  2.352e-02, -1.160e-02,  1.104e-02,
          4.576e-02, -3.500e-03,  3.856e-03, -1.016e-02],
        [ 1.279e-02,  2.005e-02, -1.658e-02, -1.142e-02, -3.997e-03, -5.386e-03,
          1.045e-02, -4.884e-03,  4.816e-02,  2.604e-03],
        [-8.948e-03,  6.478e-02, -4.702e-04, -1.172e-02,  1.192e-02, -4.028e-02,
          1.696e-03, -3.539e-03, -5.719e-03,  6.874e-03],
        [-6.555e-03, -2.952e-02, -1.178e-02,  5.446e-03,  7.214e-03,  1.034e-02,
          1.621e-02,  1.711e-02,  3.138e-02,  6.532e-03],
        [ 1.002e-02,  1.027e-03, -2.370e-02, -2.682e-04, -2.831e-02, -3.570e-04,
          3.933e-03,  8.775e-03, -1.645e-02,  2.603e-03],
        [-1.195e-02,  3.049e-02,  1.438e-02,  1.405e-02, -2.896e-02,  1.787e-02,
          1.367e-02, -1.456e-02, -2.312e-02, -4.002e-04],
        [ 4.589e-03, -3.498e-02, -1.969e-02,  8.141e-03,  1.025e-02, -3.733e-02,
         -1.816e-02,  4.116e-03, -3.222e-02,  1.488e-02]], device='cuda:0')
s after update for 1 param tensor([[0.739, 0.927, 0.392, 0.885, 0.454, 0.900, 1.161, 0.705, 1.346, 1.165],
        [1.255, 0.679, 1.282, 0.876, 0.443, 0.849, 0.493, 0.557, 0.920, 0.629],
        [1.153, 1.032, 1.195, 0.327, 1.173, 0.862, 1.070, 1.181, 0.964, 0.823],
        [1.089, 0.832, 0.610, 1.039, 0.942, 0.392, 1.273, 0.750, 0.843, 0.578],
        [0.597, 1.480, 0.836, 1.295, 0.629, 0.826, 0.727, 0.814, 0.427, 0.994],
        [1.170, 1.468, 0.634, 1.000, 0.543, 0.670, 0.666, 0.737, 0.753, 0.466],
        [0.581, 0.723, 0.872, 0.583, 0.470, 0.998, 0.660, 0.400, 1.095, 0.559],
        [0.930, 0.504, 0.665, 0.772, 0.647, 1.016, 0.636, 0.511, 0.536, 1.095],
        [1.034, 0.695, 0.759, 0.765, 1.190, 0.838, 1.189, 0.952, 1.273, 0.652],
        [1.089, 1.106, 0.790, 0.906, 0.775, 0.387, 0.559, 0.651, 0.779, 1.387],
        [1.134, 1.155, 0.595, 0.636, 0.725, 1.011, 1.019, 0.382, 0.430, 0.655],
        [0.953, 0.969, 0.276, 1.038, 0.509, 0.636, 0.857, 0.414, 0.656, 0.555],
        [0.490, 0.418, 0.981, 0.569, 0.809, 1.135, 0.930, 0.710, 0.356, 0.565],
        [1.290, 0.505, 0.704, 0.643, 1.236, 0.511, 0.446, 1.014, 0.614, 0.679],
        [1.138, 0.645, 1.112, 0.938, 1.009, 0.539, 1.041, 0.752, 0.773, 0.885],
        [1.195, 0.594, 0.938, 0.474, 0.568, 0.463, 0.430, 0.939, 0.458, 0.660],
        [0.594, 0.549, 0.950, 0.354, 0.711, 0.546, 0.510, 0.316, 0.467, 0.802],
        [0.534, 1.097, 0.588, 0.801, 0.479, 0.809, 0.676, 0.751, 0.860, 0.801],
        [1.162, 1.360, 0.690, 0.514, 0.475, 0.644, 0.575, 0.966, 0.687, 0.683],
        [0.893, 1.384, 0.796, 0.444, 0.665, 0.561, 0.497, 1.201, 0.634, 0.769],
        [0.447, 0.979, 1.238, 0.547, 1.093, 1.004, 0.620, 1.186, 0.641, 1.432],
        [1.210, 0.725, 0.947, 0.593, 1.366, 0.995, 0.477, 0.299, 0.893, 1.221],
        [0.612, 0.429, 0.969, 1.086, 0.922, 0.773, 0.621, 0.642, 0.419, 0.613],
        [0.523, 1.053, 1.467, 0.536, 0.244, 1.036, 0.659, 0.603, 0.842, 0.632],
        [0.957, 1.444, 1.744, 0.790, 0.899, 0.729, 0.781, 1.609, 0.708, 1.597],
        [0.339, 0.587, 1.066, 0.667, 0.407, 0.690, 1.072, 1.269, 0.631, 0.457],
        [1.240, 0.396, 1.098, 0.398, 1.323, 0.815, 1.328, 1.247, 0.833, 1.085],
        [0.825, 0.616, 0.875, 0.895, 0.381, 1.349, 1.172, 0.595, 0.494, 1.183],
        [0.565, 0.668, 1.145, 0.600, 0.497, 0.292, 1.216, 0.840, 0.996, 0.648],
        [0.255, 0.630, 1.210, 0.617, 1.014, 0.357, 0.631, 1.075, 0.729, 0.667],
        [0.930, 0.439, 0.820, 0.744, 0.720, 0.844, 0.868, 0.737, 0.786, 0.573],
        [0.333, 0.513, 0.563, 0.579, 0.532, 0.709, 0.571, 0.403, 0.802, 0.275],
        [0.474, 0.882, 0.789, 0.801, 0.987, 1.641, 0.466, 0.876, 0.526, 0.637],
        [0.969, 0.481, 0.694, 0.796, 0.979, 0.826, 0.923, 0.849, 0.506, 0.574],
        [0.540, 1.181, 0.988, 1.208, 0.567, 1.216, 0.818, 1.035, 0.453, 1.203],
        [0.877, 1.310, 0.509, 0.908, 1.033, 0.470, 1.072, 0.715, 0.519, 0.798],
        [0.570, 1.344, 0.897, 0.775, 1.477, 0.520, 0.443, 1.372, 1.007, 0.536],
        [0.630, 0.864, 0.500, 0.551, 0.900, 0.754, 0.513, 0.592, 0.639, 1.274],
        [0.848, 0.767, 0.798, 0.565, 0.702, 0.325, 0.755, 0.597, 0.643, 0.389],
        [0.716, 0.557, 0.386, 1.014, 1.036, 1.163, 0.698, 0.504, 0.805, 0.714],
        [0.628, 0.696, 0.763, 1.060, 0.659, 0.509, 1.200, 0.723, 0.914, 0.537],
        [0.662, 1.177, 0.561, 0.401, 1.046, 0.832, 0.666, 0.517, 0.757, 0.441],
        [0.410, 1.076, 0.435, 0.942, 0.521, 0.838, 0.413, 0.845, 1.174, 0.835],
        [0.816, 0.801, 0.541, 0.716, 1.364, 0.653, 0.463, 0.965, 1.017, 0.794],
        [0.825, 0.518, 0.755, 0.245, 0.750, 0.787, 1.103, 0.463, 0.856, 1.014],
        [1.187, 0.791, 0.962, 0.399, 0.919, 0.943, 0.768, 0.543, 0.582, 0.534],
        [0.539, 0.760, 0.891, 1.103, 1.083, 0.775, 0.812, 0.439, 0.472, 0.860],
        [1.150, 1.046, 0.355, 0.874, 1.171, 1.457, 1.255, 0.622, 0.477, 0.848],
        [1.122, 0.651, 1.143, 0.789, 0.906, 1.050, 1.058, 0.479, 0.406, 1.140],
        [1.166, 1.052, 0.710, 0.885, 0.870, 0.849, 0.990, 0.764, 0.851, 1.205],
        [0.467, 0.829, 1.009, 1.172, 0.412, 1.082, 0.996, 0.770, 1.152, 1.147],
        [0.247, 0.738, 0.489, 0.551, 0.743, 0.881, 0.334, 0.785, 0.457, 0.983],
        [0.849, 0.745, 0.505, 0.507, 0.873, 0.447, 0.387, 0.341, 1.127, 0.344],
        [0.613, 0.776, 0.525, 0.658, 0.586, 0.964, 0.657, 0.428, 0.633, 0.779],
        [0.427, 0.412, 0.669, 0.470, 0.472, 0.565, 0.932, 0.362, 0.372, 0.565],
        [0.526, 0.550, 0.718, 1.102, 1.200, 0.882, 1.000, 1.147, 0.676, 0.785],
        [1.166, 0.453, 1.006, 0.690, 0.866, 1.200, 0.990, 0.570, 0.699, 0.551],
        [0.557, 0.500, 0.967, 0.706, 0.585, 0.905, 0.628, 0.766, 0.722, 0.999],
        [0.530, 1.456, 1.334, 0.712, 0.735, 0.975, 0.617, 0.392, 0.543, 0.223],
        [1.089, 0.726, 0.785, 1.214, 0.601, 1.079, 0.998, 0.610, 0.628, 0.895],
        [0.773, 0.887, 0.662, 0.339, 0.582, 1.004, 1.389, 0.588, 0.580, 0.602],
        [1.191, 0.511, 1.038, 0.420, 0.724, 0.627, 1.069, 0.825, 0.536, 0.754],
        [0.859, 0.672, 0.590, 0.622, 0.582, 1.053, 0.761, 0.567, 1.248, 0.976],
        [0.653, 0.996, 0.879, 0.376, 0.392, 0.461, 0.975, 0.756, 0.484, 0.632],
        [0.358, 0.861, 0.643, 0.634, 0.698, 0.562, 0.886, 0.800, 1.253, 1.341],
        [0.901, 0.499, 0.473, 0.575, 0.731, 0.651, 0.468, 0.449, 0.860, 1.096],
        [1.092, 0.588, 0.333, 1.215, 0.363, 1.603, 0.716, 1.056, 1.477, 0.823],
        [1.007, 1.092, 0.985, 0.508, 1.031, 0.761, 0.925, 1.022, 0.619, 1.002],
        [0.863, 1.248, 0.824, 0.630, 1.761, 0.336, 1.049, 0.959, 0.496, 0.445],
        [0.974, 0.581, 0.724, 0.595, 0.715, 0.993, 1.211, 0.710, 1.496, 0.829],
        [0.704, 0.859, 0.827, 0.831, 0.734, 1.235, 0.459, 1.303, 0.258, 0.816],
        [0.420, 0.271, 0.692, 0.614, 1.219, 0.460, 0.841, 0.817, 0.511, 0.365],
        [1.167, 1.107, 0.353, 1.065, 0.647, 0.512, 0.875, 1.469, 0.560, 0.602],
        [0.722, 0.592, 0.617, 0.580, 0.694, 0.662, 0.638, 0.539, 0.944, 0.417],
        [0.572, 1.043, 0.797, 0.337, 1.000, 0.601, 0.833, 0.927, 0.708, 0.307],
        [0.786, 0.899, 1.076, 0.812, 0.791, 0.834, 0.915, 1.320, 0.335, 0.877],
        [0.615, 1.166, 0.714, 0.705, 0.681, 1.041, 1.409, 0.726, 0.579, 0.917],
        [0.431, 1.073, 0.869, 0.754, 0.841, 0.857, 0.695, 1.028, 1.449, 0.498],
        [0.303, 0.808, 1.120, 0.605, 0.591, 0.774, 0.751, 0.834, 0.650, 0.664],
        [0.744, 1.074, 0.255, 1.101, 1.162, 0.926, 0.210, 0.894, 0.670, 1.052],
        [0.880, 1.020, 0.589, 1.121, 0.469, 0.326, 1.268, 0.397, 1.303, 0.945],
        [0.865, 0.891, 0.538, 0.335, 0.702, 1.176, 1.207, 0.599, 1.486, 0.779],
        [1.145, 0.653, 1.131, 0.935, 0.861, 0.668, 0.901, 1.108, 0.627, 1.229],
        [0.624, 0.824, 0.786, 0.357, 1.179, 0.919, 0.942, 1.525, 0.802, 1.150],
        [0.536, 1.147, 1.242, 0.593, 0.963, 1.119, 0.611, 0.859, 0.703, 0.604],
        [1.044, 0.761, 0.750, 0.828, 0.602, 0.553, 0.680, 0.752, 0.411, 0.597],
        [0.677, 0.682, 0.820, 0.623, 0.705, 0.902, 1.031, 0.796, 0.654, 0.583],
        [0.879, 0.965, 0.689, 0.302, 0.791, 0.927, 0.761, 0.484, 0.726, 1.154],
        [0.869, 1.046, 0.886, 0.473, 0.590, 0.504, 0.887, 0.221, 0.722, 0.375],
        [0.805, 1.253, 0.813, 0.875, 0.806, 0.611, 0.548, 0.663, 0.884, 0.748],
        [0.699, 1.350, 1.130, 0.413, 1.027, 1.390, 0.630, 0.930, 0.907, 1.396],
        [0.900, 0.646, 0.955, 0.681, 0.521, 0.842, 0.916, 0.571, 0.802, 0.956],
        [0.434, 0.702, 1.082, 0.395, 0.433, 0.750, 0.531, 0.695, 0.489, 1.193],
        [0.768, 0.825, 0.982, 1.412, 0.807, 1.015, 0.850, 1.612, 0.959, 1.481],
        [0.928, 1.009, 0.623, 0.659, 1.189, 0.742, 0.895, 0.889, 1.331, 1.096],
        [1.221, 0.877, 0.584, 0.607, 0.467, 0.785, 0.539, 0.985, 0.865, 1.472],
        [1.069, 1.204, 0.435, 0.626, 0.985, 1.544, 0.717, 1.320, 0.796, 1.452],
        [0.832, 0.490, 0.472, 0.389, 0.775, 0.748, 1.040, 0.908, 0.852, 0.985],
        [0.932, 1.004, 0.893, 0.807, 0.731, 0.657, 0.677, 0.529, 0.433, 0.738],
        [1.170, 0.705, 1.176, 0.972, 0.997, 0.639, 0.913, 1.161, 0.871, 0.837]],
       device='cuda:0')
b after update for 1 param tensor([[26.815, 30.040, 19.539, 29.356, 21.030, 29.602, 33.621, 26.206, 36.202,
         33.677],
        [34.957, 25.705, 35.326, 29.208, 20.769, 28.749, 21.907, 23.282, 29.925,
         24.744],
        [33.505, 31.705, 34.108, 17.842, 33.800, 28.973, 32.273, 33.905, 30.629,
         28.300],
        [32.567, 28.463, 24.360, 31.810, 30.277, 19.541, 35.198, 27.028, 28.645,
         23.711],
        [24.117, 37.958, 28.531, 35.500, 24.746, 28.350, 26.598, 28.143, 20.378,
         31.105],
        [33.744, 37.799, 24.850, 31.202, 22.984, 25.547, 25.463, 26.794, 27.084,
         21.309],
        [23.775, 26.530, 29.145, 23.830, 21.392, 31.170, 25.353, 19.736, 32.646,
         23.333],
        [30.086, 22.147, 25.439, 27.419, 25.090, 31.455, 24.883, 22.306, 22.853,
         32.643],
        [31.722, 26.017, 27.191, 27.292, 34.043, 28.566, 34.017, 30.452, 35.205,
         25.185],
        [32.561, 32.813, 27.739, 29.707, 27.467, 19.404, 23.329, 25.184, 27.539,
         36.741],
        [33.232, 33.528, 24.063, 24.887, 26.571, 31.370, 31.495, 19.278, 20.449,
         25.252],
        [30.460, 30.707, 16.379, 31.792, 22.257, 24.886, 28.884, 20.068, 25.270,
         23.244],
        [21.832, 20.179, 30.910, 23.541, 28.061, 33.235, 30.087, 26.297, 18.611,
         23.450],
        [35.432, 22.182, 26.179, 25.015, 34.684, 22.310, 20.847, 31.422, 24.452,
         25.720],
        [33.289, 25.065, 32.905, 30.214, 31.346, 22.912, 31.840, 27.058, 27.431,
         29.347],
        [34.109, 24.057, 30.226, 21.480, 23.519, 21.221, 20.472, 30.236, 21.118,
         25.354],
        [24.042, 23.127, 30.414, 18.569, 26.318, 23.047, 22.293, 17.542, 21.318,
         27.942],
        [22.795, 32.680, 23.919, 27.923, 21.596, 28.059, 25.646, 27.044, 28.930,
         27.930],
        [33.637, 36.385, 25.912, 22.377, 21.505, 25.041, 23.651, 30.671, 25.853,
         25.796],
        [29.477, 36.704, 27.832, 20.781, 25.438, 23.374, 21.991, 34.200, 24.841,
         27.357],
        [20.860, 30.879, 34.717, 23.076, 32.624, 31.268, 24.568, 33.977, 24.988,
         37.335],
        [34.322, 26.566, 30.370, 24.021, 36.465, 31.118, 21.545, 17.070, 29.487,
         34.472],
        [24.416, 20.436, 30.708, 32.523, 29.952, 27.436, 24.578, 24.999, 20.204,
         24.425],
        [22.563, 32.015, 37.797, 22.837, 15.409, 31.755, 25.322, 24.223, 28.627,
         24.809],
        [30.522, 37.490, 41.208, 27.732, 29.579, 26.644, 27.582, 39.575, 26.259,
         39.436],
        [18.158, 23.898, 32.222, 25.474, 19.904, 25.926, 32.304, 35.154, 24.785,
         21.103],
        [34.747, 19.642, 32.695, 19.690, 35.885, 28.163, 35.951, 34.841, 28.483,
         32.504],
        [28.337, 24.497, 29.192, 29.515, 19.248, 36.233, 33.777, 24.059, 21.926,
         33.931],
        [23.454, 25.502, 33.391, 24.174, 21.991, 16.853, 34.402, 28.602, 31.139,
         25.123],
        [15.742, 24.756, 34.326, 24.519, 31.423, 18.648, 24.779, 32.351, 26.642,
         25.475],
        [30.093, 20.669, 28.251, 26.911, 26.470, 28.658, 29.062, 26.786, 27.663,
         23.627],
        [17.993, 22.354, 23.420, 23.746, 22.750, 26.280, 23.576, 19.801, 27.939,
         16.353],
        [21.483, 29.296, 27.715, 27.934, 30.999, 39.965, 21.293, 29.211, 22.636,
         24.898],
        [30.718, 21.636, 25.992, 27.833, 30.868, 28.359, 29.984, 28.753, 22.190,
         23.632],
        [22.934, 33.902, 31.021, 34.298, 23.488, 34.414, 28.214, 31.750, 20.992,
         34.224],
        [29.222, 35.715, 22.268, 29.739, 31.706, 21.402, 32.310, 26.379, 22.486,
         27.877],
        [23.560, 36.177, 29.546, 27.472, 37.926, 22.499, 20.769, 36.544, 31.310,
         22.834],
        [24.775, 29.005, 22.069, 23.166, 29.594, 27.096, 22.351, 24.010, 24.948,
         35.222],
        [28.739, 27.321, 27.875, 23.457, 26.147, 17.798, 27.111, 24.102, 25.012,
         19.465],
        [26.410, 23.287, 19.388, 31.424, 31.751, 33.647, 26.059, 22.147, 27.990,
         26.369],
        [24.727, 26.028, 27.262, 32.124, 25.330, 22.262, 34.178, 26.522, 29.825,
         22.859],
        [25.393, 33.850, 23.371, 19.748, 31.913, 28.462, 25.458, 22.438, 27.145,
         20.724],
        [19.983, 32.369, 20.580, 30.276, 22.532, 28.561, 20.059, 28.689, 33.803,
         28.509],
        [28.178, 27.917, 22.947, 26.397, 36.441, 25.216, 21.229, 30.653, 31.467,
         27.797],
        [28.338, 22.448, 27.111, 15.454, 27.023, 27.687, 32.773, 21.237, 28.861,
         31.423],
        [33.997, 27.757, 30.611, 19.704, 29.910, 30.294, 27.338, 22.991, 23.802,
         22.792],
        [22.908, 27.202, 29.460, 32.771, 32.473, 27.471, 28.108, 20.668, 21.429,
         28.927],
        [33.458, 31.911, 18.593, 29.170, 33.767, 37.668, 34.958, 24.612, 21.557,
         28.739],
        [33.046, 25.174, 33.351, 27.717, 29.699, 31.967, 32.089, 21.605, 19.889,
         33.318],
        [33.687, 32.004, 26.286, 29.349, 29.099, 28.747, 31.041, 27.279, 28.780,
         34.247],
        [21.328, 28.417, 31.336, 33.783, 20.035, 32.459, 31.133, 27.378, 33.494,
         33.418],
        [15.509, 26.800, 21.820, 23.164, 26.892, 29.286, 18.020, 27.640, 21.092,
         30.929],
        [28.748, 26.930, 22.176, 22.206, 29.147, 20.864, 19.405, 18.226, 33.119,
         18.310],
        [24.437, 27.482, 22.601, 25.310, 23.882, 30.635, 25.299, 20.410, 24.830,
         27.543],
        [20.387, 20.018, 25.516, 21.382, 21.446, 23.449, 30.127, 18.761, 19.039,
         23.458],
        [22.635, 23.138, 26.433, 32.754, 34.173, 29.309, 31.196, 33.420, 25.645,
         27.643],
        [33.691, 21.007, 31.298, 25.914, 29.036, 34.179, 31.044, 23.556, 26.092,
         23.157],
        [23.290, 22.063, 30.676, 26.221, 23.867, 29.677, 24.721, 27.308, 26.508,
         31.181],
        [22.717, 37.646, 36.035, 26.330, 26.746, 30.803, 24.513, 19.537, 22.998,
         14.725],
        [32.558, 26.577, 27.641, 34.384, 24.185, 32.413, 31.165, 24.366, 24.728,
         29.516],
        [27.425, 29.386, 25.388, 18.170, 23.813, 31.263, 36.768, 23.926, 23.770,
         24.204],
        [34.054, 22.301, 31.786, 20.224, 26.551, 24.703, 32.253, 28.335, 22.848,
         27.102],
        [28.914, 25.586, 23.964, 24.602, 23.798, 32.022, 27.228, 23.505, 34.856,
         30.830],
        [25.209, 31.140, 29.253, 19.127, 19.530, 21.175, 30.812, 27.122, 21.718,
         24.807],
        [18.673, 28.950, 25.013, 24.837, 26.070, 23.381, 29.361, 27.900, 34.930,
         36.132],
        [29.615, 22.037, 21.450, 23.666, 26.682, 25.171, 21.340, 20.896, 28.932,
         32.665],
        [32.609, 23.924, 18.007, 34.394, 18.793, 39.505, 26.400, 32.057, 37.922,
         28.304],
        [31.304, 32.600, 30.967, 22.232, 31.683, 27.222, 30.005, 31.543, 24.541,
         31.231],
        [28.993, 34.860, 28.320, 24.766, 41.408, 18.086, 31.961, 30.563, 21.979,
         20.820],
        [30.798, 23.778, 26.558, 24.067, 26.393, 31.096, 34.336, 26.291, 38.162,
         28.413],
        [26.173, 28.912, 28.369, 28.450, 26.727, 34.674, 21.141, 35.616, 15.846,
         28.178],
        [20.226, 16.248, 25.963, 24.454, 34.447, 21.170, 28.610, 28.197, 22.303,
         18.847],
        [33.711, 32.829, 18.538, 32.199, 25.102, 22.323, 29.195, 37.823, 23.345,
         24.218],
        [26.517, 24.005, 24.508, 23.758, 25.991, 25.388, 24.913, 22.915, 30.308,
         20.154],
        [23.606, 31.869, 27.858, 18.112, 31.195, 24.193, 28.483, 30.036, 26.252,
         17.284],
        [27.664, 29.576, 32.362, 28.124, 27.744, 28.500, 29.846, 35.845, 18.050,
         29.221],
        [24.462, 33.693, 26.365, 26.197, 25.758, 31.830, 37.031, 26.588, 23.737,
         29.875],
        [20.493, 32.315, 29.090, 27.101, 28.614, 28.890, 26.015, 31.639, 37.564,
         22.015],
        [17.180, 28.049, 33.015, 24.260, 23.980, 27.442, 27.031, 28.502, 25.147,
         25.425],
        [26.921, 32.343, 15.768, 32.741, 33.640, 30.028, 14.307, 29.506, 25.541,
         32.006],
        [29.265, 31.515, 23.954, 33.033, 21.364, 17.823, 35.130, 19.652, 35.611,
         30.330],
        [29.015, 29.454, 22.889, 18.069, 26.149, 33.837, 34.275, 24.156, 38.039,
         27.544],
        [33.388, 25.218, 33.176, 30.177, 28.960, 25.497, 29.617, 32.848, 24.711,
         34.593],
        [24.651, 28.326, 27.667, 18.634, 33.877, 29.908, 30.280, 38.535, 27.937,
         33.463],
        [22.837, 33.418, 34.776, 24.033, 30.617, 33.000, 24.394, 28.924, 26.156,
         24.243],
        [31.878, 27.218, 27.020, 28.395, 24.218, 23.212, 25.731, 27.049, 20.005,
         24.101],
        [25.669, 25.776, 28.249, 24.622, 26.207, 29.628, 31.689, 27.842, 25.225,
         23.823],
        [29.253, 30.656, 25.902, 17.154, 27.744, 30.044, 27.211, 21.714, 26.590,
         33.524],
        [29.088, 31.915, 29.377, 21.465, 23.964, 22.160, 29.384, 14.682, 26.518,
         19.111],
        [27.995, 34.923, 28.134, 29.188, 28.018, 24.395, 23.105, 25.404, 29.340,
         26.984],
        [26.083, 36.249, 33.170, 20.057, 31.615, 36.793, 24.771, 30.097, 29.712,
         36.870],
        [29.606, 25.074, 30.497, 25.742, 22.525, 28.631, 29.861, 23.582, 27.936,
         30.509],
        [20.555, 26.140, 32.450, 19.600, 20.522, 27.021, 22.736, 26.006, 21.811,
         34.082],
        [27.347, 28.335, 30.920, 37.081, 28.025, 31.438, 28.768, 39.621, 30.552,
         37.976],
        [30.058, 31.345, 24.631, 25.332, 34.017, 26.879, 29.520, 29.420, 36.001,
         32.667],
        [34.484, 29.216, 23.853, 24.306, 21.333, 27.637, 22.906, 30.967, 29.018,
         37.852],
        [32.266, 34.236, 20.573, 24.685, 30.963, 38.771, 26.424, 35.843, 27.835,
         37.603],
        [28.457, 21.843, 21.429, 19.451, 27.473, 26.981, 31.821, 29.728, 28.808,
         30.964],
        [30.126, 31.258, 29.483, 28.029, 26.677, 25.290, 25.665, 22.696, 20.521,
         26.798],
        [33.750, 26.196, 33.829, 30.769, 31.154, 24.936, 29.813, 33.618, 29.127,
         28.538]], device='cuda:0')
clipping threshold 0.3846723936744842
a after update for 1 param tensor([ 0.035, -0.022, -0.028, -0.005,  0.038,  0.006, -0.027,  0.021,  0.049,
         0.014, -0.002, -0.003, -0.046, -0.056,  0.004,  0.010, -0.011,  0.036,
        -0.003, -0.033, -0.030, -0.026,  0.078,  0.010,  0.003, -0.014,  0.016,
         0.028,  0.021, -0.011,  0.023,  0.021, -0.044, -0.001, -0.004,  0.010,
        -0.041, -0.013,  0.009, -0.021, -0.055, -0.026,  0.015,  0.017, -0.044,
        -0.020,  0.008, -0.017,  0.016, -0.008, -0.006, -0.003,  0.019,  0.025,
         0.012, -0.017, -0.028,  0.027, -0.045, -0.026, -0.018,  0.014, -0.009,
        -0.053,  0.012,  0.006,  0.018, -0.035,  0.026, -0.011, -0.002, -0.031,
         0.006,  0.026, -0.020, -0.048,  0.017, -0.012, -0.021,  0.016, -0.026,
        -0.001,  0.011, -0.021,  0.028, -0.013, -0.024, -0.026,  0.029, -0.007,
        -0.011,  0.021, -0.009, -0.019,  0.007, -0.002,  0.051,  0.022,  0.002,
         0.001], device='cuda:0')
s after update for 1 param tensor([0.668, 0.695, 0.692, 0.680, 0.491, 0.541, 0.606, 0.489, 0.649, 0.914,
        0.905, 0.578, 1.015, 1.177, 0.872, 0.757, 0.825, 0.632, 0.675, 0.404,
        0.524, 0.350, 0.971, 0.542, 0.742, 0.437, 0.694, 0.906, 0.416, 0.493,
        0.540, 0.448, 0.377, 0.455, 0.263, 0.638, 0.580, 0.857, 0.651, 0.679,
        0.628, 0.790, 0.574, 0.750, 0.794, 0.480, 1.070, 0.891, 0.736, 0.767,
        1.305, 0.911, 1.108, 1.155, 0.567, 1.106, 0.763, 0.503, 0.933, 0.662,
        0.968, 0.692, 1.018, 1.110, 0.962, 1.135, 1.376, 0.766, 0.896, 0.495,
        1.362, 0.878, 0.520, 0.340, 0.968, 0.741, 0.662, 0.736, 1.214, 0.772,
        0.915, 0.643, 0.918, 0.427, 0.902, 1.100, 1.159, 0.857, 0.637, 0.641,
        0.504, 1.199, 1.086, 1.284, 1.281, 1.277, 1.219, 0.730, 1.002, 0.542],
       device='cuda:0')
b after update for 1 param tensor([25.498, 26.011, 25.960, 25.731, 21.866, 22.941, 24.292, 21.823, 25.144,
        29.837, 29.676, 23.726, 31.442, 33.855, 29.133, 27.143, 28.346, 24.803,
        25.628, 19.839, 22.577, 18.446, 30.739, 22.966, 26.884, 20.627, 25.993,
        29.703, 20.130, 21.911, 22.927, 20.889, 19.160, 21.040, 15.994, 24.927,
        23.762, 28.877, 25.176, 25.720, 24.733, 27.736, 23.635, 27.026, 27.806,
        21.616, 32.271, 29.450, 26.766, 27.328, 35.643, 29.777, 32.846, 33.527,
        23.491, 32.820, 27.253, 22.121, 30.140, 25.386, 30.693, 25.948, 31.474,
        32.870, 30.604, 33.247, 36.601, 27.300, 29.542, 21.942, 36.410, 29.228,
        22.508, 18.207, 30.693, 26.866, 25.383, 26.766, 34.384, 27.414, 29.844,
        25.022, 29.891, 20.396, 29.640, 32.723, 33.594, 28.890, 24.910, 24.985,
        22.142, 34.170, 32.512, 35.356, 35.320, 35.254, 34.454, 26.663, 31.238,
        22.964], device='cuda:0')
clipping threshold 0.3846723936744842
a after update for 1 param tensor([[[-1.394e-03],
         [-3.344e-02],
         [ 3.135e-02],
         [-9.989e-03],
         [-9.664e-03],
         [-1.158e-02],
         [ 9.802e-03],
         [ 4.497e-03],
         [ 3.124e-02],
         [ 2.737e-02]],

        [[ 4.417e-02],
         [ 2.524e-02],
         [ 1.674e-02],
         [ 1.002e-02],
         [-2.672e-03],
         [ 3.960e-02],
         [-2.094e-02],
         [ 2.844e-02],
         [-5.458e-03],
         [-1.929e-02]],

        [[-5.720e-03],
         [-3.394e-02],
         [ 4.665e-03],
         [ 1.272e-02],
         [ 1.629e-02],
         [ 3.635e-02],
         [ 1.095e-02],
         [ 5.063e-03],
         [-1.473e-02],
         [ 8.443e-03]],

        [[-8.812e-03],
         [ 5.441e-04],
         [ 1.780e-02],
         [ 2.422e-03],
         [-1.416e-02],
         [-5.617e-03],
         [ 1.412e-02],
         [-1.304e-03],
         [-2.730e-02],
         [ 8.550e-03]],

        [[-1.424e-02],
         [-4.388e-02],
         [ 2.460e-02],
         [-5.644e-02],
         [ 1.399e-02],
         [ 4.264e-02],
         [ 1.260e-02],
         [ 3.355e-02],
         [-3.478e-02],
         [-3.429e-02]],

        [[ 6.182e-02],
         [-2.556e-02],
         [-4.566e-03],
         [ 5.837e-03],
         [-2.130e-03],
         [-1.614e-02],
         [-2.083e-02],
         [ 1.635e-02],
         [-2.414e-03],
         [ 1.955e-02]],

        [[-2.474e-02],
         [-4.016e-02],
         [ 3.962e-02],
         [-2.703e-03],
         [-3.873e-02],
         [-2.496e-02],
         [ 6.646e-03],
         [-1.036e-02],
         [ 2.933e-02],
         [-3.721e-02]],

        [[-7.002e-03],
         [-2.617e-02],
         [-2.912e-02],
         [ 4.920e-03],
         [ 2.835e-03],
         [ 7.757e-03],
         [ 1.636e-02],
         [-5.521e-02],
         [-6.968e-02],
         [ 2.185e-02]],

        [[-3.641e-03],
         [-1.138e-02],
         [ 2.294e-02],
         [ 3.331e-02],
         [ 1.513e-03],
         [ 1.457e-02],
         [ 1.224e-02],
         [ 5.334e-03],
         [-4.624e-04],
         [-3.570e-02]],

        [[ 3.708e-02],
         [ 5.697e-03],
         [ 3.345e-02],
         [ 3.849e-06],
         [-3.516e-02],
         [-1.099e-02],
         [ 1.067e-03],
         [-9.730e-03],
         [ 2.696e-02],
         [ 5.677e-02]]], device='cuda:0')
s after update for 1 param tensor([[[1.057],
         [1.411],
         [0.872],
         [0.792],
         [0.936],
         [1.117],
         [1.619],
         [1.244],
         [0.647],
         [0.711]],

        [[0.691],
         [0.334],
         [0.804],
         [1.059],
         [0.880],
         [0.375],
         [0.650],
         [0.966],
         [0.732],
         [1.354]],

        [[1.563],
         [0.809],
         [1.444],
         [0.616],
         [0.863],
         [1.048],
         [0.994],
         [0.622],
         [0.789],
         [0.763]],

        [[1.141],
         [1.247],
         [0.675],
         [0.753],
         [0.555],
         [0.838],
         [0.857],
         [0.546],
         [1.001],
         [0.493]],

        [[0.899],
         [0.818],
         [1.114],
         [0.492],
         [0.865],
         [0.579],
         [1.177],
         [0.814],
         [0.800],
         [1.383]],

        [[0.744],
         [1.302],
         [0.596],
         [0.861],
         [0.936],
         [0.917],
         [1.295],
         [1.259],
         [0.460],
         [0.553]],

        [[0.849],
         [1.043],
         [0.781],
         [1.314],
         [0.435],
         [0.929],
         [0.472],
         [1.259],
         [1.629],
         [0.786]],

        [[0.788],
         [0.420],
         [0.587],
         [0.532],
         [0.589],
         [1.340],
         [0.939],
         [0.956],
         [1.378],
         [0.946]],

        [[0.662],
         [0.604],
         [0.685],
         [1.147],
         [0.883],
         [0.748],
         [0.573],
         [1.048],
         [0.880],
         [1.469]],

        [[0.939],
         [0.919],
         [0.824],
         [0.569],
         [0.710],
         [0.801],
         [1.158],
         [1.135],
         [0.395],
         [1.322]]], device='cuda:0')
b after update for 1 param tensor([[[32.086],
         [37.064],
         [29.130],
         [27.772],
         [30.185],
         [32.976],
         [39.702],
         [34.799],
         [25.097],
         [26.306]],

        [[25.928],
         [18.045],
         [27.976],
         [32.111],
         [29.265],
         [19.096],
         [25.156],
         [30.659],
         [26.698],
         [36.311]],

        [[39.010],
         [28.062],
         [37.498],
         [24.480],
         [28.978],
         [31.936],
         [31.103],
         [24.604],
         [27.720],
         [27.257]],

        [[33.335],
         [34.842],
         [25.643],
         [27.079],
         [23.248],
         [28.561],
         [28.882],
         [23.056],
         [31.221],
         [21.899]],

        [[29.581],
         [28.222],
         [32.927],
         [21.878],
         [29.022],
         [23.732],
         [33.853],
         [28.147],
         [27.907],
         [36.696]],

        [[26.913],
         [35.605],
         [24.085],
         [28.945],
         [30.192],
         [29.873],
         [35.510],
         [35.004],
         [21.153],
         [23.212]],

        [[28.745],
         [31.868],
         [27.576],
         [35.772],
         [20.589],
         [30.077],
         [21.432],
         [35.011],
         [39.820],
         [27.662]],

        [[27.692],
         [20.226],
         [23.914],
         [22.769],
         [23.953],
         [36.124],
         [30.234],
         [30.506],
         [36.631],
         [30.353]],

        [[25.394],
         [24.244],
         [25.829],
         [33.423],
         [29.320],
         [26.992],
         [23.619],
         [31.941],
         [29.262],
         [37.817]],

        [[30.237],
         [29.906],
         [28.326],
         [23.532],
         [26.292],
         [27.922],
         [33.573],
         [33.244],
         [19.609],
         [35.874]]], device='cuda:0')
clipping threshold 0.3846723936744842
a after update for 1 param tensor([[-0.006],
        [-0.064],
        [ 0.003],
        [ 0.030],
        [ 0.002],
        [ 0.008],
        [-0.011],
        [-0.001],
        [-0.005],
        [-0.016]], device='cuda:0')
s after update for 1 param tensor([[1.273],
        [0.580],
        [0.727],
        [1.061],
        [0.978],
        [0.873],
        [1.311],
        [1.593],
        [0.902],
        [1.334]], device='cuda:0')
b after update for 1 param tensor([[35.208],
        [23.763],
        [26.608],
        [32.137],
        [30.854],
        [29.158],
        [35.724],
        [39.383],
        [29.639],
        [36.036]], device='cuda:0')
clipping threshold 0.3846723936744842
||w||^2 0.6060814696499711
exp ma of ||w||^2 0.3711083412769534
||w|| 0.7785123439290935
exp ma of ||w|| 0.5680544704612442
||w||^2 0.44432926391106353
exp ma of ||w||^2 0.31056773557596734
||w|| 0.6665802756690776
exp ma of ||w|| 0.518941903674137
||w||^2 0.2121859848154737
exp ma of ||w||^2 0.3444321055981652
||w|| 0.4606364996561537
exp ma of ||w|| 0.5460720967960568
||w||^2 0.2154005930697439
exp ma of ||w||^2 0.3586178253880067
||w|| 0.464112694363927
exp ma of ||w|| 0.5519244561236565
||w||^2 0.4003338327949164
exp ma of ||w||^2 0.34702382824467204
||w|| 0.6327193949887394
exp ma of ||w|| 0.5459392948345962
cuda
Objective function 8.18 = squared loss an data 7.22 + 0.5*rho*h**2 0.328040 + alpha*h 0.081282 + L2reg 0.50 + L1reg 0.05 ; SHD = 15 ; DAG True
Proportion of microbatches that were clipped  0.7622258326563769
iteration 3 in inner loop, alpha 1.003491265671629 rho 100.0 h 0.08099878439695729
iteration 2 in outer loop, alpha = 9.103369705367358, rho = 100.0, h = 0.08099878439695729
cuda
1210
cuda
Objective function 8.84 = squared loss an data 7.22 + 0.5*rho*h**2 0.328040 + alpha*h 0.737362 + L2reg 0.50 + L1reg 0.05 ; SHD = 15 ; DAG True
||w||^2 645.1136388841568
exp ma of ||w||^2 4285637.615641714
||w|| 25.3990873632136
exp ma of ||w|| 316.6960529046986
||w||^2 0.13542731675891798
exp ma of ||w||^2 23977.756520976614
||w|| 0.36800450643832877
exp ma of ||w|| 2.4545121145477444
||w||^2 0.09200971609007899
exp ma of ||w||^2 93.55425698359248
||w|| 0.30333103383939963
exp ma of ||w|| 0.3558965820581714
||w||^2 0.19743649423955273
exp ma of ||w||^2 0.3564743969103922
||w|| 0.44433826555851874
exp ma of ||w|| 0.5466300982118508
||w||^2 0.2776978678988846
exp ma of ||w||^2 0.35780457999853105
||w|| 0.5269704620743791
exp ma of ||w|| 0.5528661727601313
||w||^2 0.36193173453021266
exp ma of ||w||^2 0.3154261637026838
||w|| 0.6016076250598995
exp ma of ||w|| 0.5290970999680439
cuda
Objective function 8.61 = squared loss an data 7.60 + 0.5*rho*h**2 0.082515 + alpha*h 0.369814 + L2reg 0.51 + L1reg 0.05 ; SHD = 18 ; DAG True
Proportion of microbatches that were clipped  0.7634599838318512
iteration 1 in inner loop, alpha 9.103369705367358 rho 100.0 h 0.04062380631755147
1210
cuda
Objective function 9.35 = squared loss an data 7.60 + 0.5*rho*h**2 0.825147 + alpha*h 0.369814 + L2reg 0.51 + L1reg 0.05 ; SHD = 18 ; DAG True
||w||^2 1498539.4487284522
exp ma of ||w||^2 110540944.67855169
||w|| 1224.14845861458
exp ma of ||w|| 4689.840053901946
||w||^2 2.1526394438679897
exp ma of ||w||^2 1321721.2045305937
||w|| 1.4671875966855736
exp ma of ||w|| 83.76122683953972
||w||^2 1.000690080720544
exp ma of ||w||^2 292699.36335286836
||w|| 1.0003449808543772
exp ma of ||w|| 19.542543802698727
||w||^2 0.28144164734132837
exp ma of ||w||^2 0.2591731323757424
||w|| 0.5305107419660118
exp ma of ||w|| 0.47171920980958654
||w||^2 0.19501808756545327
exp ma of ||w||^2 0.2885256816159882
||w|| 0.441608522976463
exp ma of ||w|| 0.49907456710179
||w||^2 0.14345195321125784
exp ma of ||w||^2 0.3104869856102302
||w|| 0.37875051579008817
exp ma of ||w|| 0.5205909964192222
||w||^2 0.22886543346381058
exp ma of ||w||^2 0.288192079033519
||w|| 0.4783988225986876
exp ma of ||w|| 0.5069390614054748
||w||^2 0.0999756604100114
exp ma of ||w||^2 0.2901046681723952
||w|| 0.31618927940398517
exp ma of ||w|| 0.5009140621390202
||w||^2 0.3852383497965728
exp ma of ||w||^2 0.3361057190123056
||w|| 0.6206757203214677
exp ma of ||w|| 0.537102133056628
||w||^2 0.23594808700601658
exp ma of ||w||^2 0.3179706959054989
||w|| 0.4857448785175368
exp ma of ||w|| 0.5282741760224869
||w||^2 0.4768822520015095
exp ma of ||w||^2 0.2748387255425462
||w|| 0.6905666166283377
exp ma of ||w|| 0.4960407290376734
||w||^2 0.5915063696896447
exp ma of ||w||^2 0.2801177529367277
||w|| 0.769094512845882
exp ma of ||w|| 0.5003179713278235
||w||^2 0.7671925033309241
exp ma of ||w||^2 0.32486701868187806
||w|| 0.8758952581963919
exp ma of ||w|| 0.5280766229229202
cuda
Objective function 8.80 = squared loss an data 7.99 + 0.5*rho*h**2 0.114939 + alpha*h 0.138023 + L2reg 0.51 + L1reg 0.05 ; SHD = 14 ; DAG True
Proportion of microbatches that were clipped  0.767631892106307
iteration 2 in inner loop, alpha 9.103369705367358 rho 1000.0 h 0.01516173043460256
iteration 3 in outer loop, alpha = 24.265100139969917, rho = 1000.0, h = 0.01516173043460256
cuda
1210
cuda
Objective function 9.03 = squared loss an data 7.99 + 0.5*rho*h**2 0.114939 + alpha*h 0.367901 + L2reg 0.51 + L1reg 0.05 ; SHD = 14 ; DAG True
||w||^2 0.23000503062251082
exp ma of ||w||^2 41552.98169351511
||w|| 0.4795883970891193
exp ma of ||w|| 3.2861796789649387
||w||^2 0.0664204480693422
exp ma of ||w||^2 0.25380317261294155
||w|| 0.25772164842973944
exp ma of ||w|| 0.4654286916980731
||w||^2 0.37803224482220654
exp ma of ||w||^2 0.34006243756663
||w|| 0.614843268501987
exp ma of ||w|| 0.5415118041100722
||w||^2 0.21450514624814904
exp ma of ||w||^2 0.28167588900375085
||w|| 0.46314700284914834
exp ma of ||w|| 0.5003311352552853
||w||^2 0.22803476329969094
exp ma of ||w||^2 0.31890805677304984
||w|| 0.47752985592493685
exp ma of ||w|| 0.5216659194092842
||w||^2 0.17132896284449645
exp ma of ||w||^2 0.3037345170338318
||w|| 0.4139190293336324
exp ma of ||w|| 0.5049868374749943
||w||^2 0.09113125166389378
exp ma of ||w||^2 0.3175142768244457
||w|| 0.30187953170742426
exp ma of ||w|| 0.5204792167106669
||w||^2 0.1888679977634061
exp ma of ||w||^2 0.34080020565150787
||w|| 0.43458945887286093
exp ma of ||w|| 0.5450069094996773
||w||^2 0.3532526742690987
exp ma of ||w||^2 0.3000312351110016
||w|| 0.5943506324292914
exp ma of ||w|| 0.514366337018618
||w||^2 0.20430430108700787
exp ma of ||w||^2 0.2837902957956652
||w|| 0.4520003330607267
exp ma of ||w|| 0.49658753042697173
cuda
Objective function 9.02 = squared loss an data 8.14 + 0.5*rho*h**2 0.058156 + alpha*h 0.261693 + L2reg 0.51 + L1reg 0.05 ; SHD = 12 ; DAG True
Proportion of microbatches that were clipped  0.7662472124880535
iteration 1 in inner loop, alpha 24.265100139969917 rho 1000.0 h 0.010784761201566795
1210
cuda
Objective function 9.54 = squared loss an data 8.14 + 0.5*rho*h**2 0.581555 + alpha*h 0.261693 + L2reg 0.51 + L1reg 0.05 ; SHD = 12 ; DAG True
||w||^2 3803907623.332631
exp ma of ||w||^2 10773417694.036985
||w|| 61675.82689622111
exp ma of ||w|| 79473.20269820651
||w||^2 3224204.712039014
exp ma of ||w||^2 456166989.9436535
||w|| 1795.6070594757123
exp ma of ||w|| 10125.013924592964
||w||^2 0.15708499748232946
exp ma of ||w||^2 0.22355229421777378
||w|| 0.3963394977570737
exp ma of ||w|| 0.3935423071260398
||w||^2 0.2278943838100754
exp ma of ||w||^2 0.23546437124686004
||w|| 0.4773828482571147
exp ma of ||w|| 0.4507132401143853
||w||^2 0.14253745471353907
exp ma of ||w||^2 0.24672619073770855
||w|| 0.37754132848409994
exp ma of ||w|| 0.4643576194236031
||w||^2 0.16383709078850722
exp ma of ||w||^2 0.2570376396348727
||w|| 0.40476794683930595
exp ma of ||w|| 0.47396489300035827
||w||^2 0.9313102203508787
exp ma of ||w||^2 0.25172877836345936
||w|| 0.9650441546120461
exp ma of ||w|| 0.46746865362423395
||w||^2 0.16887906616231615
exp ma of ||w||^2 0.3263486535717929
||w|| 0.4109489824325109
exp ma of ||w|| 0.5377963493046383
||w||^2 0.14003140924299112
exp ma of ||w||^2 0.29304981193836854
||w|| 0.37420770868996156
exp ma of ||w|| 0.5047042457038491
||w||^2 0.16048502914270094
exp ma of ||w||^2 0.29287027922780307
||w|| 0.4006058276444577
exp ma of ||w|| 0.5032396660042027
||w||^2 0.32297337752290084
exp ma of ||w||^2 0.33225071128705785
||w|| 0.568307467417859
exp ma of ||w|| 0.5366750500968755
||w||^2 0.13160456959845168
exp ma of ||w||^2 0.2681508810991988
||w|| 0.36277344114261134
exp ma of ||w|| 0.4876474793115218
||w||^2 0.0561117182726058
exp ma of ||w||^2 0.27113825617085213
||w|| 0.23687912164774208
exp ma of ||w|| 0.4809211292730838
cuda
Objective function 9.05 = squared loss an data 8.32 + 0.5*rho*h**2 0.071083 + alpha*h 0.091491 + L2reg 0.51 + L1reg 0.05 ; SHD = 12 ; DAG True
Proportion of microbatches that were clipped  0.762336835402738
iteration 2 in inner loop, alpha 24.265100139969917 rho 10000.0 h 0.0037704818730190937
iteration 4 in outer loop, alpha = 61.96991887016085, rho = 10000.0, h = 0.0037704818730190937
cuda
1210
cuda
Objective function 9.19 = squared loss an data 8.32 + 0.5*rho*h**2 0.071083 + alpha*h 0.233656 + L2reg 0.51 + L1reg 0.05 ; SHD = 12 ; DAG True
||w||^2 152342712.49799824
exp ma of ||w||^2 4245081851.915003
||w|| 12342.719007495805
exp ma of ||w|| 35905.226929262644
||w||^2 57546693.325887606
exp ma of ||w||^2 1356038484.1081035
||w|| 7585.9536859835625
exp ma of ||w|| 16230.68383920082
||w||^2 30.764795788010183
exp ma of ||w||^2 4616877.698261857
||w|| 5.546602184041162
exp ma of ||w|| 113.28102351238718
||w||^2 0.3772057268801366
exp ma of ||w||^2 43124.01504506061
||w|| 0.6141707636155734
exp ma of ||w|| 1.7301419872792505
||w||^2 0.09296431869333843
exp ma of ||w||^2 463.79172284915785
||w|| 0.3049005062202069
exp ma of ||w|| 0.37996075649443956
||w||^2 0.08551026693095891
exp ma of ||w||^2 9.54068225189876
||w|| 0.29242138589877265
exp ma of ||w|| 0.370021656740643
||w||^2 0.09077375140347894
exp ma of ||w||^2 2.2042315870123628
||w|| 0.3012868258047121
exp ma of ||w|| 0.3644330454366194
||w||^2 0.07521501773776229
exp ma of ||w||^2 0.20779383656797779
||w|| 0.2742535646764911
exp ma of ||w|| 0.4269833120075852
||w||^2 0.12017413930816719
exp ma of ||w||^2 0.21579314589121654
||w|| 0.3466614188342383
exp ma of ||w|| 0.43810577011414936
||w||^2 0.21342823487260568
exp ma of ||w||^2 0.2298654665692539
||w|| 0.46198293785875433
exp ma of ||w|| 0.4468899561023072
||w||^2 0.09378792018871558
exp ma of ||w||^2 0.28045101267054434
||w|| 0.3062481349963059
exp ma of ||w|| 0.49824652363097655
||w||^2 0.4636865211597109
exp ma of ||w||^2 0.2713696086737588
||w|| 0.6809453143679828
exp ma of ||w|| 0.4901967775837676
||w||^2 0.11383896784082909
exp ma of ||w||^2 0.31397970411918225
||w|| 0.3374003080034591
exp ma of ||w|| 0.5213416721856754
||w||^2 0.45649758712814625
exp ma of ||w||^2 0.3140926594660767
||w|| 0.6756460516632553
exp ma of ||w|| 0.5174393552346466
||w||^2 0.4203918276088664
exp ma of ||w||^2 0.2988968185511305
||w|| 0.6483763009309227
exp ma of ||w|| 0.5104431102968185
||w||^2 0.5767082397974993
exp ma of ||w||^2 0.3180066746803996
||w|| 0.7594130890348805
exp ma of ||w|| 0.5231999434627171
||w||^2 0.34389690871413986
exp ma of ||w||^2 0.2824054826640444
||w|| 0.5864272407674629
exp ma of ||w|| 0.5015004024184978
||w||^2 0.29130965268746445
exp ma of ||w||^2 0.25993214921307045
||w|| 0.539731092941165
exp ma of ||w|| 0.4804196545118997
cuda
Objective function 9.09 = squared loss an data 8.31 + 0.5*rho*h**2 0.034966 + alpha*h 0.163878 + L2reg 0.53 + L1reg 0.05 ; SHD = 12 ; DAG True
Proportion of microbatches that were clipped  0.76312204503566
iteration 1 in inner loop, alpha 61.96991887016085 rho 10000.0 h 0.0026444790593433964
1210
cuda
Objective function 9.40 = squared loss an data 8.31 + 0.5*rho*h**2 0.349663 + alpha*h 0.163878 + L2reg 0.53 + L1reg 0.05 ; SHD = 12 ; DAG True
||w||^2 5895378618910.897
exp ma of ||w||^2 1730403542199.3625
||w|| 2428040.0776986564
exp ma of ||w|| 764569.0952303024
||w||^2 1250863.2413493444
exp ma of ||w||^2 34473158108.3665
||w|| 1118.4199753890953
exp ma of ||w|| 24538.68450862336
||w||^2 77.96958704986245
exp ma of ||w||^2 537626798.8835379
||w|| 8.830038904210017
exp ma of ||w|| 459.8304585435149
||w||^2 0.13479320692073574
exp ma of ||w||^2 0.2315424912269008
||w|| 0.36714194383199494
exp ma of ||w|| 0.4537588138279416
||w||^2 0.46199387305171524
exp ma of ||w||^2 0.23773288167235312
||w|| 0.6797013116448395
exp ma of ||w|| 0.4587239971246877
||w||^2 0.13948517968838925
exp ma of ||w||^2 0.2322604190668735
||w|| 0.37347714747811445
exp ma of ||w|| 0.45809372974016693
||w||^2 0.6331953140975398
exp ma of ||w||^2 0.24022403100024797
||w|| 0.7957357061848738
exp ma of ||w|| 0.4584179708190886
||w||^2 0.07826889606371874
exp ma of ||w||^2 0.22877492363960658
||w|| 0.2797657878721391
exp ma of ||w|| 0.45117964005744177
||w||^2 0.2428017851618966
exp ma of ||w||^2 0.24450697821733108
||w|| 0.49274921122402277
exp ma of ||w|| 0.4666521187683589
||w||^2 0.08897167799442253
exp ma of ||w||^2 0.2751927841276756
||w|| 0.2982812062373735
exp ma of ||w|| 0.5008536825790805
||w||^2 0.06696865780565281
exp ma of ||w||^2 0.24077241953859913
||w|| 0.2587830322985895
exp ma of ||w|| 0.46230888422914995
||w||^2 0.07922322209177314
exp ma of ||w||^2 0.26781717850350817
||w|| 0.28146620062055966
exp ma of ||w|| 0.48577395224492054
||w||^2 0.2731668001591459
exp ma of ||w||^2 0.2553424755873139
||w|| 0.5226536139348372
exp ma of ||w|| 0.4769515044012152
||w||^2 0.32821497474431127
exp ma of ||w||^2 0.24234413872312463
||w|| 0.5729004928818889
exp ma of ||w|| 0.46850164287751533
||w||^2 0.08260967784020158
exp ma of ||w||^2 0.2468882530706471
||w|| 0.2874189935272225
exp ma of ||w|| 0.47090684674027256
cuda
Objective function 9.10 = squared loss an data 8.37 + 0.5*rho*h**2 0.085176 + alpha*h 0.080883 + L2reg 0.51 + L1reg 0.05 ; SHD = 13 ; DAG True
Proportion of microbatches that were clipped  0.7637985056640154
iteration 2 in inner loop, alpha 61.96991887016085 rho 100000.0 h 0.0013051915564830097
iteration 5 in outer loop, alpha = 1367.1614753531705, rho = 1000000.0, h = 0.0013051915564830097
Threshold 0.3
[[0.003 0.021 0.309 0.003 0.272 0.06  0.136 0.019 0.021 0.822]
 [0.339 0.007 0.428 0.007 0.242 0.332 0.521 0.018 0.003 0.267]
 [0.021 0.012 0.004 0.003 0.097 0.007 0.459 0.013 0.007 0.176]
 [0.963 0.623 0.842 0.002 0.254 1.646 0.492 0.699 0.11  0.503]
 [0.012 0.016 0.019 0.014 0.006 0.033 0.013 0.017 0.006 0.412]
 [0.068 0.023 0.562 0.002 0.117 0.004 0.431 0.006 0.006 0.15 ]
 [0.033 0.008 0.01  0.005 0.276 0.01  0.006 0.008 0.008 0.147]
 [0.211 0.246 0.272 0.009 0.23  0.824 0.445 0.004 0.031 0.527]
 [0.206 1.224 0.471 0.05  0.65  0.564 0.503 0.222 0.003 0.347]
 [0.01  0.024 0.03  0.007 0.007 0.035 0.05  0.007 0.011 0.004]]
[[0.    0.    0.309 0.    0.    0.    0.    0.    0.    0.822]
 [0.339 0.    0.428 0.    0.    0.332 0.521 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.459 0.    0.    0.   ]
 [0.963 0.623 0.842 0.    0.    1.646 0.492 0.699 0.    0.503]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.412]
 [0.    0.    0.562 0.    0.    0.    0.431 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.824 0.445 0.    0.    0.527]
 [0.    1.224 0.471 0.    0.65  0.564 0.503 0.    0.    0.347]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]]
{'fdr': 0.38461538461538464, 'tpr': 0.8, 'fpr': 0.4, 'f1': 0.6956521739130435, 'shd': 13, 'npred': 26, 'ntrue': 20}
[0.021 0.309 0.003 0.272 0.06  0.136 0.019 0.021 0.822 0.339 0.428 0.007
 0.242 0.332 0.521 0.018 0.003 0.267 0.021 0.012 0.003 0.097 0.007 0.459
 0.013 0.007 0.176 0.963 0.623 0.842 0.254 1.646 0.492 0.699 0.11  0.503
 0.012 0.016 0.019 0.014 0.033 0.013 0.017 0.006 0.412 0.068 0.023 0.562
 0.002 0.117 0.431 0.006 0.006 0.15  0.033 0.008 0.01  0.005 0.276 0.01
 0.008 0.008 0.147 0.211 0.246 0.272 0.009 0.23  0.824 0.445 0.031 0.527
 0.206 1.224 0.471 0.05  0.65  0.564 0.503 0.222 0.347 0.01  0.024 0.03
 0.007 0.007 0.035 0.05  0.007 0.011]
[[0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 1. 1. 0. 0. 1. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9149999999999999, 0.8279477546718927)
Iterations 2500
Achieves (6.086687062773559, 1e-05)-DP
