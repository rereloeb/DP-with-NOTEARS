samples  5000  graph  20 80 ER mlp  minibatch size  50  noise  1.0  minibatches per NN training  250 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.7622777646747636
iteration 1 in outer loop, alpha = 1.7622777646747636, rho = 1.0, h = 1.7622777646747636
cuda
iteration 1 in inner loop,alpha 1.7622777646747636 rho 1.0 h 1.1769941079911774
iteration 2 in inner loop,alpha 1.7622777646747636 rho 10.0 h 0.5457542906119919
iteration 3 in inner loop,alpha 1.7622777646747636 rho 100.0 h 0.18750524172121885
iteration 2 in outer loop, alpha = 20.51280193679665, rho = 100.0, h = 0.18750524172121885
cuda
iteration 1 in inner loop,alpha 20.51280193679665 rho 100.0 h 0.10961679779989097
iteration 2 in inner loop,alpha 20.51280193679665 rho 1000.0 h 0.04277326740086096
iteration 3 in outer loop, alpha = 63.28606933765761, rho = 1000.0, h = 0.04277326740086096
cuda
iteration 1 in inner loop,alpha 63.28606933765761 rho 1000.0 h 0.0229533632536274
iteration 2 in inner loop,alpha 63.28606933765761 rho 10000.0 h 0.007744018065881875
iteration 4 in outer loop, alpha = 140.72624999647635, rho = 10000.0, h = 0.007744018065881875
cuda
iteration 1 in inner loop,alpha 140.72624999647635 rho 10000.0 h 0.004124562036381008
iteration 2 in inner loop,alpha 140.72624999647635 rho 100000.0 h 0.0013703652010690348
iteration 5 in outer loop, alpha = 277.7627701033798, rho = 100000.0, h = 0.0013703652010690348
cuda
iteration 1 in inner loop,alpha 277.7627701033798 rho 100000.0 h 0.0006717921657397596
iteration 6 in outer loop, alpha = 949.5549358431394, rho = 1000000.0, h = 0.0006717921657397596
Threshold 0.3
[[0.001 3.159 0.072 0.244 0.909 1.127 0.312 0.    1.978 1.127 0.12  1.163
  0.264 0.001 0.361 0.494 0.301 1.23  1.319 0.473]
 [0.    0.001 0.021 0.492 0.486 1.677 1.819 0.    0.544 0.455 0.086 0.673
  0.324 0.001 1.229 0.366 0.343 0.864 0.496 1.831]
 [0.004 0.011 0.    0.06  0.46  0.561 1.561 0.    0.204 0.573 0.095 0.182
  1.311 0.004 1.519 0.352 0.631 0.004 1.215 0.358]
 [0.    0.    0.    0.021 0.001 0.003 0.001 0.    0.    0.002 0.    0.
  0.    0.    0.219 0.164 0.202 0.    0.001 0.717]
 [0.    0.    0.    0.567 0.004 0.323 0.211 0.    0.    0.422 0.001 0.001
  0.002 0.    0.229 0.301 1.268 0.    0.334 1.093]
 [0.    0.    0.    0.523 0.002 0.003 0.001 0.    0.    0.    0.    0.
  0.    0.    0.366 1.746 1.849 0.    0.292 0.419]
 [0.    0.    0.    0.193 0.003 0.23  0.002 0.    0.    0.008 0.    0.
  0.    0.    0.36  0.259 0.278 0.    0.172 0.225]
 [2.566 0.134 0.004 0.1   0.715 0.226 0.722 0.001 0.311 0.484 0.133 0.399
  2.015 0.712 0.223 0.198 0.172 1.144 0.496 0.414]
 [0.    0.    0.002 0.331 1.621 0.952 1.316 0.    0.001 0.815 0.463 0.291
  1.808 0.    1.253 1.219 0.826 0.    1.362 0.781]
 [0.    0.    0.    0.11  0.015 2.222 0.153 0.    0.    0.007 0.001 0.001
  0.    0.    1.206 1.298 1.785 0.    0.832 0.183]
 [0.    0.    0.    0.918 0.113 0.591 2.355 0.    0.    0.258 0.001 0.
  0.    0.    1.539 0.551 1.068 0.    0.28  1.376]
 [0.    0.    0.    0.15  0.444 0.251 1.673 0.    0.    0.324 0.125 0.001
  0.138 0.    0.178 0.883 0.293 0.    0.125 0.174]
 [0.    0.    0.    0.108 0.143 1.413 1.117 0.    0.    0.197 2.167 0.001
  0.001 0.    0.309 0.356 0.322 0.    0.489 1.08 ]
 [0.152 0.036 0.03  0.718 0.349 1.663 0.31  0.001 0.297 0.355 1.729 0.533
  2.073 0.001 0.438 0.397 1.069 0.351 0.737 2.062]
 [0.    0.    0.    0.003 0.001 0.001 0.    0.    0.    0.    0.    0.
  0.    0.    0.002 0.255 0.002 0.    0.001 0.001]
 [0.    0.    0.    0.003 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.001 0.006 0.001 0.    0.001 0.   ]
 [0.    0.    0.    0.003 0.001 0.001 0.001 0.    0.    0.    0.    0.
  0.    0.    1.164 1.27  0.004 0.    0.001 0.001]
 [0.    0.    0.031 0.043 0.472 0.294 1.418 0.    3.194 0.588 0.096 0.738
  0.098 0.    0.355 0.206 0.203 0.001 0.418 0.198]
 [0.    0.    0.    0.741 0.001 0.001 0.001 0.    0.    0.    0.    0.
  0.    0.    0.34  1.142 0.422 0.    0.001 0.222]
 [0.    0.    0.    0.004 0.    0.    0.    0.    0.    0.001 0.    0.
  0.    0.    0.119 1.874 0.296 0.    0.001 0.002]]
[[0.    3.159 0.    0.    0.909 1.127 0.312 0.    1.978 1.127 0.    1.163
  0.    0.    0.361 0.494 0.301 1.23  1.319 0.473]
 [0.    0.    0.    0.492 0.486 1.677 1.819 0.    0.544 0.455 0.    0.673
  0.324 0.    1.229 0.366 0.343 0.864 0.496 1.831]
 [0.    0.    0.    0.    0.46  0.561 1.561 0.    0.    0.573 0.    0.
  1.311 0.    1.519 0.352 0.631 0.    1.215 0.358]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.717]
 [0.    0.    0.    0.567 0.    0.323 0.    0.    0.    0.422 0.    0.
  0.    0.    0.    0.301 1.268 0.    0.334 1.093]
 [0.    0.    0.    0.523 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.366 1.746 1.849 0.    0.    0.419]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.36  0.    0.    0.    0.    0.   ]
 [2.566 0.    0.    0.    0.715 0.    0.722 0.    0.311 0.484 0.    0.399
  2.015 0.712 0.    0.    0.    1.144 0.496 0.414]
 [0.    0.    0.    0.331 1.621 0.952 1.316 0.    0.    0.815 0.463 0.
  1.808 0.    1.253 1.219 0.826 0.    1.362 0.781]
 [0.    0.    0.    0.    0.    2.222 0.    0.    0.    0.    0.    0.
  0.    0.    1.206 1.298 1.785 0.    0.832 0.   ]
 [0.    0.    0.    0.918 0.    0.591 2.355 0.    0.    0.    0.    0.
  0.    0.    1.539 0.551 1.068 0.    0.    1.376]
 [0.    0.    0.    0.    0.444 0.    1.673 0.    0.    0.324 0.    0.
  0.    0.    0.    0.883 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    1.413 1.117 0.    0.    0.    2.167 0.
  0.    0.    0.309 0.356 0.322 0.    0.489 1.08 ]
 [0.    0.    0.    0.718 0.349 1.663 0.31  0.    0.    0.355 1.729 0.533
  2.073 0.    0.438 0.397 1.069 0.351 0.737 2.062]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    1.164 1.27  0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.472 0.    1.418 0.    3.194 0.588 0.    0.738
  0.    0.    0.355 0.    0.    0.    0.418 0.   ]
 [0.    0.    0.    0.741 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.34  1.142 0.422 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    1.874 0.    0.    0.    0.   ]]
{'fdr': 0.4444444444444444, 'tpr': 0.875, 'fpr': 0.509090909090909, 'f1': 0.6796116504854369, 'shd': 61, 'npred': 126, 'ntrue': 80}
[3.159e+00 7.177e-02 2.442e-01 9.090e-01 1.127e+00 3.116e-01 1.802e-04
 1.978e+00 1.127e+00 1.198e-01 1.163e+00 2.637e-01 1.351e-03 3.605e-01
 4.943e-01 3.013e-01 1.230e+00 1.319e+00 4.730e-01 4.089e-04 2.105e-02
 4.919e-01 4.860e-01 1.677e+00 1.819e+00 1.691e-04 5.442e-01 4.551e-01
 8.649e-02 6.726e-01 3.236e-01 1.177e-03 1.229e+00 3.663e-01 3.435e-01
 8.643e-01 4.957e-01 1.831e+00 3.525e-03 1.102e-02 5.984e-02 4.603e-01
 5.611e-01 1.561e+00 1.424e-04 2.040e-01 5.728e-01 9.539e-02 1.824e-01
 1.311e+00 4.034e-03 1.519e+00 3.524e-01 6.308e-01 3.966e-03 1.215e+00
 3.577e-01 7.622e-05 1.381e-05 8.123e-05 5.985e-04 2.820e-03 1.180e-03
 6.780e-05 9.044e-05 2.103e-03 4.663e-04 2.302e-04 8.941e-05 2.574e-06
 2.186e-01 1.642e-01 2.025e-01 1.802e-05 1.265e-03 7.171e-01 3.261e-06
 3.879e-06 5.635e-05 5.667e-01 3.234e-01 2.105e-01 1.734e-05 1.383e-04
 4.216e-01 1.154e-03 1.074e-03 2.213e-03 1.292e-04 2.293e-01 3.015e-01
 1.268e+00 4.579e-05 3.337e-01 1.093e+00 8.059e-05 1.862e-04 6.576e-05
 5.227e-01 1.806e-03 1.273e-03 4.684e-05 8.311e-05 4.501e-04 4.824e-05
 2.258e-04 2.372e-04 4.004e-05 3.656e-01 1.746e+00 1.849e+00 9.173e-06
 2.921e-01 4.190e-01 5.387e-05 9.769e-05 3.876e-06 1.932e-01 2.735e-03
 2.303e-01 3.727e-05 5.331e-05 7.524e-03 1.256e-04 2.024e-04 6.300e-05
 3.968e-06 3.601e-01 2.595e-01 2.781e-01 2.024e-06 1.725e-01 2.252e-01
 2.566e+00 1.339e-01 4.314e-03 9.989e-02 7.154e-01 2.257e-01 7.220e-01
 3.108e-01 4.842e-01 1.326e-01 3.990e-01 2.015e+00 7.115e-01 2.232e-01
 1.982e-01 1.719e-01 1.144e+00 4.957e-01 4.138e-01 1.019e-05 6.252e-06
 1.598e-03 3.312e-01 1.621e+00 9.522e-01 1.316e+00 1.035e-05 8.151e-01
 4.632e-01 2.914e-01 1.808e+00 2.350e-05 1.253e+00 1.219e+00 8.263e-01
 4.861e-05 1.362e+00 7.807e-01 2.918e-05 1.819e-05 7.153e-05 1.102e-01
 1.457e-02 2.222e+00 1.527e-01 5.491e-05 1.592e-04 5.179e-04 6.451e-04
 2.107e-04 1.253e-04 1.206e+00 1.298e+00 1.785e+00 3.185e-05 8.324e-01
 1.830e-01 6.501e-06 1.454e-05 6.482e-05 9.183e-01 1.125e-01 5.914e-01
 2.355e+00 2.054e-05 6.724e-05 2.585e-01 2.777e-04 2.132e-04 4.001e-05
 1.539e+00 5.512e-01 1.068e+00 1.260e-05 2.799e-01 1.376e+00 2.044e-05
 8.299e-05 2.258e-04 1.495e-01 4.439e-01 2.505e-01 1.673e+00 1.674e-05
 2.235e-04 3.241e-01 1.254e-01 1.385e-01 5.542e-05 1.778e-01 8.826e-01
 2.930e-01 1.701e-04 1.250e-01 1.740e-01 7.230e-06 3.432e-06 1.774e-04
 1.077e-01 1.431e-01 1.413e+00 1.117e+00 2.926e-05 2.164e-04 1.974e-01
 2.167e+00 8.821e-04 7.576e-05 3.090e-01 3.562e-01 3.216e-01 6.109e-05
 4.886e-01 1.080e+00 1.518e-01 3.622e-02 3.044e-02 7.181e-01 3.493e-01
 1.663e+00 3.105e-01 7.114e-04 2.972e-01 3.545e-01 1.729e+00 5.328e-01
 2.073e+00 4.384e-01 3.965e-01 1.069e+00 3.513e-01 7.368e-01 2.062e+00
 3.946e-05 7.410e-05 2.822e-05 3.390e-03 9.468e-04 6.559e-04 3.356e-04
 2.646e-05 7.074e-05 3.773e-05 7.965e-05 1.701e-04 5.172e-05 2.749e-05
 2.553e-01 2.264e-03 1.977e-06 5.245e-04 1.405e-03 2.433e-05 2.099e-05
 1.708e-05 2.519e-03 4.990e-04 9.636e-05 3.375e-04 1.314e-05 1.802e-05
 2.894e-04 7.685e-05 5.655e-05 1.520e-05 1.124e-05 1.120e-03 9.031e-04
 4.646e-06 5.426e-04 2.304e-04 4.748e-05 8.152e-05 2.435e-05 3.081e-03
 8.163e-04 5.833e-04 8.033e-04 3.852e-05 7.489e-06 4.724e-05 7.154e-05
 1.024e-04 2.116e-05 2.875e-05 1.164e+00 1.270e+00 4.941e-06 5.530e-04
 9.283e-04 8.678e-05 7.027e-05 3.112e-02 4.341e-02 4.721e-01 2.940e-01
 1.418e+00 8.442e-05 3.194e+00 5.878e-01 9.638e-02 7.381e-01 9.759e-02
 1.204e-04 3.551e-01 2.055e-01 2.035e-01 4.177e-01 1.975e-01 6.322e-05
 1.571e-05 1.413e-04 7.406e-01 9.633e-04 7.725e-04 9.231e-04 4.372e-05
 1.463e-04 4.574e-04 1.522e-04 2.610e-04 1.520e-04 2.076e-05 3.403e-01
 1.142e+00 4.217e-01 2.973e-06 2.223e-01 3.579e-05 7.201e-05 6.064e-05
 3.625e-03 2.658e-04 2.202e-04 4.449e-04 1.799e-05 6.267e-05 6.382e-04
 3.038e-04 1.116e-04 1.985e-04 5.897e-05 1.188e-01 1.874e+00 2.962e-01
 1.324e-05 6.836e-04]
[[0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0.]
 [0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1.]
 [0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0.]
 [0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.]
 [0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.]
 [0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]
 [0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]
[1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1.
 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.
 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.
 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1.
 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
aucroc, aucpr (0.937, 0.8897553212928283)
cuda
4420
cuda
Objective function 730.81 = squared loss an data 514.80 + 0.5*rho*h**2 215.201283 + alpha*h 0.000000 + L2reg 0.37 + L1reg 0.45 ; SHD = 206 ; DAG False
v before min max tensor([[-2.580e-02,  1.408e-04, -7.868e-03,  ..., -1.160e-04,  2.062e-02,
         -9.983e-04],
        [-1.719e-02, -6.928e-03, -9.867e-02,  ..., -1.129e-02,  1.147e-05,
         -1.363e-03],
        [-1.309e-02,  1.896e-03, -2.373e-02,  ..., -3.513e-03, -3.513e-03,
         -1.527e-03],
        ...,
        [ 4.951e-01, -1.278e-01, -5.333e-03,  ..., -7.484e-05,  5.367e-04,
         -1.892e-02],
        [-6.411e-03, -1.670e-02, -9.063e-04,  ...,  8.349e-04, -9.693e-04,
         -9.579e-03],
        [ 3.664e-02, -5.005e-04, -4.864e-03,  ..., -2.696e-04,  1.353e-02,
         -1.860e-02]], device='cuda:0')
v tensor([[1.000e-12, 1.408e-04, 1.000e-12,  ..., 1.000e-12, 2.062e-02,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.147e-05,
         1.000e-12],
        [1.000e-12, 1.896e-03, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        ...,
        [4.951e-01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 5.367e-04,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 8.349e-04, 1.000e-12,
         1.000e-12],
        [3.664e-02, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.353e-02,
         1.000e-12]], device='cuda:0')
v before min max tensor([-5.749e-04,  2.382e-02, -7.047e-05, -7.514e-03, -2.626e-04, -2.299e-01,
        -1.447e-03, -5.002e-03, -6.280e-03, -4.704e-03, -6.258e-04, -2.031e-03,
         6.907e-05, -3.208e-02, -4.089e-05, -2.800e-02, -2.433e-05, -2.002e-03,
         1.333e-03,  1.944e-05, -9.135e-04, -2.465e-02,  8.522e-05,  2.825e-05,
         3.800e-01,  2.851e-04, -2.107e-02,  1.543e-05,  5.198e-03, -9.158e-06,
        -2.167e-02, -4.847e-02, -6.943e-02, -9.149e-06,  8.132e-04, -1.629e-02,
        -4.794e-04, -7.195e-02, -6.228e-03, -1.200e-03, -4.454e-04, -3.202e-02,
        -6.916e-04, -2.530e-02, -9.081e-06,  2.776e-04,  3.358e-04, -9.073e-05,
        -1.383e-03,  4.602e-02, -4.675e-02,  2.491e-03, -1.431e-04, -1.149e-04,
        -2.634e-02,  5.247e-03, -3.417e-03, -1.807e-03, -4.778e-03, -2.611e-02,
         3.790e-05, -3.209e-02,  6.099e-03, -1.657e-03, -1.681e-02, -3.003e-05,
         9.776e-04, -1.527e-01, -7.128e-02,  1.356e-04, -5.735e-03, -1.523e-02,
        -6.367e-06, -3.190e-04,  2.386e-03, -4.717e-04,  1.465e-03, -2.959e-04,
        -6.099e-03, -5.080e-05,  6.786e-04,  2.345e-02,  9.592e-08, -4.977e-03,
        -2.872e-01, -2.798e-03, -4.029e-04, -1.408e-04,  5.163e-06, -6.626e-03,
         2.130e-02,  1.763e-02, -4.471e-03,  7.112e-02, -1.812e-04, -7.079e-04,
        -8.116e-04, -5.384e-04, -1.144e-02,  4.367e-04,  1.072e-04,  1.616e-04,
        -2.447e-02, -3.018e-03, -2.532e-02, -2.691e-03,  2.735e-01, -2.324e-03,
        -4.107e-04, -1.287e-02, -2.869e-03,  1.170e-04,  8.743e-04, -3.474e-02,
        -8.797e-03, -2.288e-03, -5.946e-04,  3.653e-04, -9.066e-02,  2.450e-03,
        -5.397e-05,  1.830e-02, -2.185e-03,  4.060e-03, -9.080e-04, -6.635e-04,
         4.302e-03,  1.850e-02, -3.570e-04, -6.386e-02,  8.085e-02,  1.243e-01,
         1.605e-03, -2.670e-03,  6.864e-04, -9.691e-03, -1.028e-04,  1.008e-05,
         5.535e-04, -1.292e-03, -9.379e-05, -9.119e-06, -1.805e-05, -6.974e-04,
        -2.723e-03,  4.141e-04,  5.057e-06,  3.747e-01, -1.092e-01, -7.741e-04,
        -7.080e-03, -9.362e-03,  1.313e-03, -3.145e-01, -6.771e-02,  2.109e-03,
        -4.188e-02,  6.181e-04, -1.490e-03, -6.031e-05, -3.618e-02, -2.214e-04,
        -2.648e-02, -9.842e-05, -3.933e-02,  3.665e-03,  5.102e-02, -2.501e-04,
         4.174e-02,  7.947e-04, -2.064e-03, -2.644e-01, -1.727e-04, -1.643e-03,
        -9.538e-05,  9.345e-04, -2.116e-03, -2.204e-03, -1.152e-04, -3.861e-06,
        -1.266e-03, -7.063e-05, -8.352e-04, -2.647e-05, -5.818e-03,  1.929e-01,
        -4.981e-03,  8.441e-02,  1.534e-03, -4.533e-04, -2.013e-02, -2.735e-05,
        -1.420e-02, -2.439e-03, -4.723e-03, -8.170e-03,  9.154e-03,  2.968e-06,
         5.302e-03, -1.059e-02], device='cuda:0')
v tensor([1.000e-12, 2.382e-02, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        6.907e-05, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.333e-03, 1.944e-05, 1.000e-12, 1.000e-12, 8.522e-05, 2.825e-05,
        3.800e-01, 2.851e-04, 1.000e-12, 1.543e-05, 5.198e-03, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 8.132e-04, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 2.776e-04, 3.358e-04, 1.000e-12,
        1.000e-12, 4.602e-02, 1.000e-12, 2.491e-03, 1.000e-12, 1.000e-12,
        1.000e-12, 5.247e-03, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        3.790e-05, 1.000e-12, 6.099e-03, 1.000e-12, 1.000e-12, 1.000e-12,
        9.776e-04, 1.000e-12, 1.000e-12, 1.356e-04, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 2.386e-03, 1.000e-12, 1.465e-03, 1.000e-12,
        1.000e-12, 1.000e-12, 6.786e-04, 2.345e-02, 9.592e-08, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.163e-06, 1.000e-12,
        2.130e-02, 1.763e-02, 1.000e-12, 7.112e-02, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 4.367e-04, 1.072e-04, 1.616e-04,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.735e-01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.170e-04, 8.743e-04, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 3.653e-04, 1.000e-12, 2.450e-03,
        1.000e-12, 1.830e-02, 1.000e-12, 4.060e-03, 1.000e-12, 1.000e-12,
        4.302e-03, 1.850e-02, 1.000e-12, 1.000e-12, 8.085e-02, 1.243e-01,
        1.605e-03, 1.000e-12, 6.864e-04, 1.000e-12, 1.000e-12, 1.008e-05,
        5.535e-04, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 4.141e-04, 5.057e-06, 3.747e-01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.313e-03, 1.000e-12, 1.000e-12, 2.109e-03,
        1.000e-12, 6.181e-04, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 3.665e-03, 5.102e-02, 1.000e-12,
        4.174e-02, 7.947e-04, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 9.345e-04, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.929e-01,
        1.000e-12, 8.441e-02, 1.534e-03, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 9.154e-03, 2.968e-06,
        5.302e-03, 1.000e-12], device='cuda:0')
v before min max tensor([[[ 1.357e-02],
         [-1.718e-02],
         [-4.557e-03],
         [-2.386e-02],
         [-1.534e-01],
         [-1.951e-02],
         [-1.841e-02],
         [-3.139e-03],
         [-1.828e-04],
         [ 1.265e-03]],

        [[-8.284e-02],
         [-3.881e-02],
         [-9.638e-02],
         [-4.133e-02],
         [-5.672e-02],
         [ 6.327e-02],
         [-3.686e-03],
         [-6.356e-04],
         [ 6.604e-03],
         [ 1.314e-01]],

        [[ 3.687e-04],
         [ 1.963e-01],
         [-2.511e-03],
         [-3.752e-01],
         [ 3.293e-02],
         [-6.702e-02],
         [ 3.458e-03],
         [-3.346e-03],
         [-1.386e-02],
         [-3.379e-04]],

        [[-3.865e-02],
         [-6.452e-06],
         [ 2.128e-03],
         [ 1.283e-03],
         [-1.609e-04],
         [-9.208e-04],
         [-3.533e-03],
         [ 1.582e-02],
         [ 1.135e-05],
         [-3.187e-02]],

        [[ 4.796e-02],
         [ 4.139e-01],
         [-7.277e-02],
         [-6.228e-02],
         [ 1.410e-02],
         [-1.313e-05],
         [ 2.128e-01],
         [ 6.549e-01],
         [-1.361e-01],
         [-6.369e-02]],

        [[ 7.627e-03],
         [-3.329e-03],
         [-1.126e-02],
         [-2.918e-02],
         [ 8.209e-04],
         [-1.452e-03],
         [-6.417e-03],
         [-2.797e-03],
         [-7.733e-03],
         [-9.030e-03]],

        [[ 1.447e-01],
         [-2.027e-02],
         [-8.611e-03],
         [ 4.510e-03],
         [-1.282e-01],
         [-9.823e-02],
         [-2.011e-01],
         [-1.726e-02],
         [ 1.558e-02],
         [-5.329e-02]],

        [[-5.626e-05],
         [ 1.389e-02],
         [-1.940e-04],
         [-4.535e-02],
         [-1.578e-02],
         [-3.420e-03],
         [ 2.073e-02],
         [ 1.836e-02],
         [-4.426e-03],
         [ 5.348e-04]],

        [[-3.129e-03],
         [-3.375e-02],
         [-4.835e-03],
         [ 1.338e-01],
         [ 2.799e-02],
         [-6.257e-05],
         [ 5.586e-01],
         [ 2.095e-03],
         [-1.220e-01],
         [-2.227e-02]],

        [[ 1.268e-02],
         [-6.000e-02],
         [ 5.428e-02],
         [-2.077e-02],
         [ 6.421e-04],
         [ 2.320e-01],
         [ 1.235e-04],
         [-4.622e-01],
         [-2.657e-02],
         [-1.490e-01]],

        [[-1.592e-02],
         [ 4.280e-04],
         [-3.632e-02],
         [-7.434e-02],
         [-1.231e-01],
         [ 1.219e-03],
         [-1.892e-02],
         [-1.562e-03],
         [ 2.233e-02],
         [ 2.143e-01]],

        [[ 7.476e-03],
         [ 3.912e-03],
         [-4.132e-03],
         [ 1.694e-02],
         [-2.429e-02],
         [ 6.392e-02],
         [-1.791e-03],
         [-1.744e-01],
         [ 1.648e-02],
         [-8.922e-04]],

        [[-1.005e-01],
         [-3.267e-02],
         [ 4.741e-01],
         [-1.339e-01],
         [-2.558e-02],
         [ 4.459e-01],
         [ 1.895e-02],
         [-2.003e-01],
         [-1.883e-01],
         [ 4.083e-03]],

        [[-8.930e-03],
         [-1.130e-03],
         [-2.763e-01],
         [-8.415e-03],
         [ 8.911e-04],
         [ 2.666e-03],
         [ 2.603e-02],
         [ 1.242e-02],
         [ 1.595e-02],
         [-1.722e-01]],

        [[-1.765e-02],
         [-9.104e-03],
         [-8.672e-03],
         [ 1.715e-03],
         [ 1.271e-02],
         [ 4.516e-02],
         [-8.588e-02],
         [ 1.878e-01],
         [-4.652e-04],
         [ 1.473e-04]],

        [[ 2.070e-03],
         [-1.442e-01],
         [ 3.317e-03],
         [ 1.055e-01],
         [-2.716e-02],
         [ 4.479e-01],
         [-1.298e-03],
         [-4.353e-03],
         [-6.763e-03],
         [-2.217e-02]],

        [[ 3.448e-02],
         [-1.517e-02],
         [-1.617e-02],
         [ 6.088e-04],
         [-1.733e-02],
         [-9.512e-03],
         [-4.038e-02],
         [-5.752e-02],
         [-7.727e-02],
         [-2.743e-01]],

        [[-7.474e-02],
         [-2.231e-01],
         [-2.095e-01],
         [ 8.933e-03],
         [-4.117e-01],
         [-8.299e-02],
         [-1.865e-02],
         [-7.066e-03],
         [ 3.611e-02],
         [-5.320e-02]],

        [[-4.450e-02],
         [ 2.675e-02],
         [-1.665e-03],
         [ 7.018e-03],
         [-4.928e-04],
         [-2.429e-02],
         [-8.886e-03],
         [-3.547e-03],
         [-4.071e-06],
         [ 2.232e-02]],

        [[ 1.004e-03],
         [-2.916e-02],
         [-8.488e-04],
         [-1.932e-03],
         [-2.511e-03],
         [-1.062e-04],
         [ 4.430e-03],
         [-1.138e-02],
         [ 1.851e-03],
         [ 7.943e-04]]], device='cuda:0')
v tensor([[[1.357e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.265e-03]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.327e-02],
         [1.000e-12],
         [1.000e-12],
         [6.604e-03],
         [1.314e-01]],

        [[3.687e-04],
         [1.963e-01],
         [1.000e-12],
         [1.000e-12],
         [3.293e-02],
         [1.000e-12],
         [3.458e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [2.128e-03],
         [1.283e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.582e-02],
         [1.135e-05],
         [1.000e-12]],

        [[4.796e-02],
         [4.139e-01],
         [1.000e-12],
         [1.000e-12],
         [1.410e-02],
         [1.000e-12],
         [2.128e-01],
         [6.549e-01],
         [1.000e-12],
         [1.000e-12]],

        [[7.627e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [8.209e-04],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.447e-01],
         [1.000e-12],
         [1.000e-12],
         [4.510e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.558e-02],
         [1.000e-12]],

        [[1.000e-12],
         [1.389e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.073e-02],
         [1.836e-02],
         [1.000e-12],
         [5.348e-04]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.338e-01],
         [2.799e-02],
         [1.000e-12],
         [5.586e-01],
         [2.095e-03],
         [1.000e-12],
         [1.000e-12]],

        [[1.268e-02],
         [1.000e-12],
         [5.428e-02],
         [1.000e-12],
         [6.421e-04],
         [2.320e-01],
         [1.235e-04],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [4.280e-04],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.219e-03],
         [1.000e-12],
         [1.000e-12],
         [2.233e-02],
         [2.143e-01]],

        [[7.476e-03],
         [3.912e-03],
         [1.000e-12],
         [1.694e-02],
         [1.000e-12],
         [6.392e-02],
         [1.000e-12],
         [1.000e-12],
         [1.648e-02],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [4.741e-01],
         [1.000e-12],
         [1.000e-12],
         [4.459e-01],
         [1.895e-02],
         [1.000e-12],
         [1.000e-12],
         [4.083e-03]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [8.911e-04],
         [2.666e-03],
         [2.603e-02],
         [1.242e-02],
         [1.595e-02],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.715e-03],
         [1.271e-02],
         [4.516e-02],
         [1.000e-12],
         [1.878e-01],
         [1.000e-12],
         [1.473e-04]],

        [[2.070e-03],
         [1.000e-12],
         [3.317e-03],
         [1.055e-01],
         [1.000e-12],
         [4.479e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[3.448e-02],
         [1.000e-12],
         [1.000e-12],
         [6.088e-04],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [8.933e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.611e-02],
         [1.000e-12]],

        [[1.000e-12],
         [2.675e-02],
         [1.000e-12],
         [7.018e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.232e-02]],

        [[1.004e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.430e-03],
         [1.000e-12],
         [1.851e-03],
         [7.943e-04]]], device='cuda:0')
v before min max tensor([[ 0.004],
        [-0.038],
        [-0.119],
        [-0.003],
        [ 0.472],
        [ 0.006],
        [ 0.047],
        [-0.012],
        [ 0.082],
        [ 0.417],
        [ 0.196],
        [ 0.048],
        [ 0.032],
        [-0.006],
        [-0.084],
        [-0.015],
        [ 0.004],
        [ 0.017],
        [-0.044],
        [ 0.047]], device='cuda:0')
v tensor([[3.767e-03],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [4.717e-01],
        [5.780e-03],
        [4.671e-02],
        [1.000e-12],
        [8.240e-02],
        [4.170e-01],
        [1.958e-01],
        [4.838e-02],
        [3.246e-02],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [3.742e-03],
        [1.733e-02],
        [1.000e-12],
        [4.721e-02]], device='cuda:0')
a after update for 1 param tensor([[ 1.383e-05, -2.205e-05, -4.594e-05,  ...,  5.939e-05,  1.275e-04,
         -1.053e-04],
        [-5.886e-05, -9.305e-07,  1.480e-04,  ..., -1.201e-04, -7.626e-06,
         -3.428e-05],
        [ 9.802e-05, -2.784e-05, -4.536e-05,  ...,  1.877e-05, -3.068e-04,
         -3.809e-06],
        ...,
        [ 1.784e-03, -3.331e-06, -2.527e-04,  ..., -7.190e-06,  4.181e-05,
          1.670e-04],
        [-2.223e-05,  3.064e-05, -3.222e-05,  ..., -1.911e-04,  1.308e-04,
         -8.931e-05],
        [ 2.056e-04,  1.683e-05, -1.220e-05,  ..., -2.463e-05,  3.202e-04,
         -8.668e-04]], device='cuda:0')
s after update for 1 param tensor([[6.189e-03, 3.754e-03, 1.707e-03,  ..., 6.538e-05, 4.543e-02,
         1.076e-03],
        [3.493e-03, 1.404e-03, 3.022e-02,  ..., 3.310e-03, 1.071e-03,
         2.760e-04],
        [3.530e-03, 1.378e-02, 5.562e-03,  ..., 7.169e-04, 1.083e-02,
         3.716e-04],
        ...,
        [2.396e-01, 2.942e-02, 3.548e-03,  ..., 5.554e-05, 7.326e-03,
         4.231e-03],
        [2.100e-03, 3.420e-03, 2.403e-04,  ..., 9.541e-03, 1.059e-03,
         6.426e-03],
        [6.085e-02, 1.774e-04, 1.379e-03,  ..., 6.611e-05, 3.729e-02,
         4.331e-02]], device='cuda:0')
b after update for 1 param tensor([[0.669, 0.521, 0.352,  ..., 0.069, 1.814, 0.279],
        [0.503, 0.319, 1.479,  ..., 0.490, 0.279, 0.141],
        [0.506, 0.999, 0.635,  ..., 0.228, 0.886, 0.164],
        ...,
        [4.166, 1.460, 0.507,  ..., 0.063, 0.728, 0.554],
        [0.390, 0.498, 0.132,  ..., 0.831, 0.277, 0.682],
        [2.099, 0.113, 0.316,  ..., 0.069, 1.643, 1.771]], device='cuda:0')
clipping threshold 2.782537623814828
a after update for 1 param tensor([ 3.603e-05,  5.147e-04, -1.866e-05,  2.632e-05,  3.593e-06, -5.003e-05,
         8.393e-05,  1.121e-04, -4.397e-05,  2.561e-05, -2.236e-05, -4.082e-05,
         2.373e-05, -1.041e-04, -4.677e-05, -9.549e-05,  1.846e-06, -6.089e-05,
         6.911e-05, -1.455e-05, -3.484e-05, -7.051e-05, -9.277e-05, -1.218e-05,
        -1.382e-03, -8.289e-05,  5.973e-05, -8.998e-06, -1.996e-04, -9.278e-07,
         1.193e-04, -2.332e-04,  4.580e-04,  7.910e-07,  8.809e-05,  9.017e-06,
         1.703e-05,  7.793e-05,  9.558e-07,  4.487e-05, -6.396e-05,  3.210e-05,
         5.602e-06, -1.775e-04, -4.390e-08,  3.890e-05, -2.083e-05,  1.036e-05,
         2.604e-05,  4.063e-04, -4.918e-04,  2.466e-04,  4.042e-06, -1.518e-05,
         6.535e-06,  1.337e-04, -8.180e-05,  6.610e-05, -4.668e-05, -2.233e-04,
        -2.615e-05,  6.983e-05, -7.980e-04, -3.868e-05, -2.166e-04, -4.716e-06,
         7.023e-05,  8.232e-05, -3.973e-04,  4.087e-05, -1.274e-05,  1.873e-04,
         4.578e-06, -8.195e-06,  7.176e-05,  1.004e-05,  1.128e-04, -1.303e-05,
        -4.154e-06,  7.414e-06,  3.741e-05,  5.001e-04, -7.217e-06,  2.057e-06,
        -5.730e-04,  7.370e-05, -4.020e-06,  1.243e-05,  3.994e-06,  7.677e-05,
        -2.243e-04, -2.465e-04, -1.557e-04, -4.346e-04,  1.150e-05, -2.225e-05,
         7.028e-06,  2.016e-06, -7.535e-05, -3.829e-05, -2.996e-05, -3.557e-05,
        -8.738e-05,  1.296e-05,  1.394e-04,  6.727e-05,  1.075e-03,  6.801e-05,
         1.317e-05,  3.091e-04, -1.824e-06, -1.522e-05, -1.067e-04,  9.872e-05,
        -4.085e-05,  3.778e-05,  2.599e-05, -7.609e-05, -1.518e-04, -8.217e-05,
        -2.209e-06,  2.171e-04, -3.896e-05,  1.196e-04,  1.151e-05, -2.729e-05,
         2.076e-04, -1.531e-04,  5.828e-05, -1.827e-05, -5.202e-04,  5.973e-04,
        -8.591e-05, -7.187e-05,  5.724e-05, -2.783e-05,  2.217e-05,  8.144e-06,
        -1.007e-04, -1.859e-04,  7.229e-07,  1.282e-05,  4.181e-06, -3.178e-05,
         8.889e-05, -4.872e-05, -1.582e-05, -1.334e-03,  1.560e-05, -3.533e-05,
        -5.958e-05, -3.738e-05,  1.698e-04,  7.115e-04, -4.235e-04, -8.207e-05,
        -6.511e-04,  1.276e-05, -2.143e-05,  2.633e-05,  5.002e-05, -1.489e-05,
         2.655e-04,  2.272e-05, -6.068e-05,  9.520e-05,  4.039e-04,  1.955e-05,
        -3.550e-04,  8.757e-05,  6.559e-05, -3.231e-04, -3.605e-06,  1.567e-05,
         7.356e-07,  3.888e-05, -5.443e-05,  1.520e-05, -1.187e-06, -2.316e-06,
         3.535e-05,  1.235e-04,  3.138e-05,  3.072e-06, -1.897e-05,  6.978e-04,
         1.376e-05,  4.155e-04, -6.028e-05, -6.188e-06, -1.700e-04, -1.341e-06,
         3.494e-05,  5.935e-05,  3.308e-04,  2.676e-05, -1.494e-04, -4.545e-05,
        -1.082e-04,  2.145e-05], device='cuda:0')
s after update for 1 param tensor([1.261e-04, 4.962e-02, 6.479e-05, 1.529e-03, 5.322e-05, 5.635e-02,
        3.894e-04, 2.309e-03, 1.677e-03, 9.586e-04, 1.417e-04, 1.171e-03,
        2.628e-03, 7.040e-03, 5.684e-05, 5.987e-03, 7.746e-06, 4.999e-04,
        1.160e-02, 1.395e-03, 5.236e-04, 8.357e-03, 3.062e-03, 1.681e-03,
        1.981e-01, 5.379e-03, 5.526e-03, 1.242e-03, 2.280e-02, 1.882e-06,
        4.604e-03, 1.199e-02, 2.443e-02, 1.882e-06, 9.040e-03, 3.687e-03,
        9.791e-05, 1.526e-02, 1.443e-03, 3.535e-04, 2.059e-04, 7.398e-03,
        1.562e-04, 9.525e-03, 1.882e-06, 5.269e-03, 5.795e-03, 2.246e-05,
        2.869e-04, 6.795e-02, 2.223e-02, 1.596e-02, 2.910e-05, 5.309e-05,
        6.241e-03, 2.291e-02, 1.489e-03, 6.963e-04, 1.010e-03, 6.633e-03,
        1.949e-03, 6.579e-03, 3.475e-02, 5.056e-04, 8.177e-03, 6.790e-06,
        9.889e-03, 3.209e-02, 1.986e-02, 3.701e-03, 1.518e-03, 3.326e-03,
        1.882e-06, 6.711e-05, 1.545e-02, 9.615e-05, 1.211e-02, 6.201e-05,
        1.494e-03, 1.565e-05, 8.239e-03, 4.993e-02, 9.796e-05, 1.083e-03,
        5.856e-02, 7.009e-04, 8.936e-05, 3.020e-05, 7.185e-04, 2.362e-03,
        4.615e-02, 4.203e-02, 1.435e-03, 8.482e-02, 4.494e-05, 1.452e-04,
        2.834e-04, 1.099e-04, 2.662e-03, 6.690e-03, 3.274e-03, 4.020e-03,
        7.915e-03, 6.247e-04, 5.853e-03, 9.527e-04, 1.669e-01, 7.731e-04,
        9.062e-05, 3.549e-03, 5.835e-04, 3.421e-03, 9.449e-03, 8.571e-03,
        1.852e-03, 1.771e-03, 1.206e-04, 6.047e-03, 2.599e-02, 1.565e-02,
        1.234e-05, 4.279e-02, 5.068e-04, 2.018e-02, 1.840e-04, 1.463e-04,
        2.093e-02, 4.338e-02, 1.720e-04, 1.432e-02, 9.099e-02, 1.116e-01,
        1.267e-02, 8.355e-04, 8.286e-03, 1.973e-03, 3.304e-05, 1.004e-03,
        7.444e-03, 1.774e-03, 2.192e-04, 3.420e-05, 5.209e-06, 3.193e-04,
        8.649e-04, 6.464e-03, 7.112e-04, 1.987e-01, 2.464e-02, 2.003e-04,
        1.758e-03, 2.474e-03, 1.155e-02, 7.675e-02, 2.270e-02, 1.452e-02,
        2.426e-02, 7.864e-03, 5.872e-04, 2.158e-05, 7.342e-03, 4.490e-05,
        1.036e-02, 6.395e-05, 1.235e-02, 1.915e-02, 7.199e-02, 5.594e-05,
        6.464e-02, 8.945e-03, 4.914e-03, 5.368e-02, 3.747e-05, 3.476e-04,
        2.539e-05, 9.668e-03, 4.552e-04, 5.354e-04, 2.341e-05, 1.882e-06,
        2.575e-04, 6.070e-04, 1.729e-04, 5.386e-06, 1.219e-03, 1.453e-01,
        1.057e-03, 1.021e-01, 1.238e-02, 1.094e-04, 1.182e-02, 5.615e-06,
        2.985e-03, 5.053e-04, 1.384e-02, 1.714e-03, 3.026e-02, 5.809e-04,
        2.303e-02, 2.296e-03], device='cuda:0')
b after update for 1 param tensor([0.096, 1.896, 0.068, 0.333, 0.062, 2.020, 0.168, 0.409, 0.348, 0.263,
        0.101, 0.291, 0.436, 0.714, 0.064, 0.658, 0.024, 0.190, 0.917, 0.318,
        0.195, 0.778, 0.471, 0.349, 3.788, 0.624, 0.633, 0.300, 1.285, 0.012,
        0.577, 0.932, 1.330, 0.012, 0.809, 0.517, 0.084, 1.051, 0.323, 0.160,
        0.122, 0.732, 0.106, 0.831, 0.012, 0.618, 0.648, 0.040, 0.144, 2.218,
        1.269, 1.075, 0.046, 0.062, 0.672, 1.288, 0.328, 0.225, 0.270, 0.693,
        0.376, 0.690, 1.586, 0.191, 0.770, 0.022, 0.846, 1.524, 1.199, 0.518,
        0.332, 0.491, 0.012, 0.070, 1.058, 0.083, 0.936, 0.067, 0.329, 0.034,
        0.772, 1.902, 0.084, 0.280, 2.059, 0.225, 0.080, 0.047, 0.228, 0.414,
        1.828, 1.745, 0.322, 2.478, 0.057, 0.103, 0.143, 0.089, 0.439, 0.696,
        0.487, 0.540, 0.757, 0.213, 0.651, 0.263, 3.477, 0.237, 0.081, 0.507,
        0.206, 0.498, 0.827, 0.788, 0.366, 0.358, 0.093, 0.662, 1.372, 1.065,
        0.030, 1.760, 0.192, 1.209, 0.115, 0.103, 1.231, 1.772, 0.112, 1.018,
        2.567, 2.843, 0.958, 0.246, 0.775, 0.378, 0.049, 0.270, 0.734, 0.358,
        0.126, 0.050, 0.019, 0.152, 0.250, 0.684, 0.227, 3.793, 1.336, 0.120,
        0.357, 0.423, 0.914, 2.358, 1.282, 1.026, 1.325, 0.755, 0.206, 0.040,
        0.729, 0.057, 0.866, 0.068, 0.946, 1.177, 2.283, 0.064, 2.164, 0.805,
        0.597, 1.972, 0.052, 0.159, 0.043, 0.837, 0.182, 0.197, 0.041, 0.012,
        0.137, 0.210, 0.112, 0.020, 0.297, 3.244, 0.277, 2.719, 0.947, 0.089,
        0.925, 0.020, 0.465, 0.191, 1.001, 0.352, 1.480, 0.205, 1.291, 0.408],
       device='cuda:0')
clipping threshold 2.782537623814828
a after update for 1 param tensor([[[ 2.592e-04],
         [-5.848e-05],
         [ 1.200e-04],
         [-2.852e-04],
         [-5.893e-04],
         [ 2.576e-04],
         [ 3.050e-04],
         [ 1.233e-04],
         [ 3.945e-05],
         [-8.896e-05]],

        [[ 2.608e-05],
         [-1.687e-04],
         [ 3.067e-04],
         [-1.817e-04],
         [-3.105e-04],
         [ 4.464e-04],
         [ 3.358e-04],
         [-2.486e-04],
         [-2.676e-04],
         [ 2.631e-04]],

        [[ 9.985e-05],
         [-5.923e-04],
         [ 8.506e-05],
         [-4.877e-04],
         [ 2.382e-04],
         [-3.144e-05],
         [ 1.498e-04],
         [ 2.367e-04],
         [ 4.303e-05],
         [-6.257e-06]],

        [[ 9.060e-05],
         [ 1.108e-04],
         [ 2.608e-04],
         [ 8.188e-05],
         [ 1.321e-05],
         [ 2.535e-05],
         [ 7.396e-05],
         [ 2.300e-04],
         [ 5.802e-06],
         [ 5.699e-04]],

        [[-7.421e-04],
         [-1.273e-03],
         [-2.136e-04],
         [ 1.085e-04],
         [-2.289e-04],
         [-9.670e-06],
         [ 7.089e-04],
         [-1.519e-03],
         [-9.480e-04],
         [ 3.524e-04]],

        [[ 1.548e-04],
         [-1.086e-04],
         [ 3.075e-05],
         [ 1.425e-04],
         [ 8.645e-05],
         [ 5.855e-05],
         [ 1.287e-06],
         [ 2.257e-04],
         [ 5.363e-05],
         [ 1.923e-04]],

        [[-7.426e-04],
         [ 4.471e-05],
         [-2.008e-04],
         [-1.876e-04],
         [ 6.663e-05],
         [ 1.128e-04],
         [-4.599e-04],
         [-2.479e-04],
         [-1.912e-04],
         [ 1.565e-04]],

        [[ 9.190e-08],
         [ 2.711e-04],
         [ 2.757e-05],
         [ 1.731e-05],
         [-5.533e-06],
         [ 4.578e-05],
         [-2.979e-04],
         [ 2.702e-04],
         [ 1.840e-05],
         [ 5.135e-05]],

        [[-1.903e-05],
         [-1.390e-04],
         [ 9.256e-05],
         [ 9.098e-04],
         [ 3.024e-04],
         [ 1.648e-05],
         [-1.020e-03],
         [-2.004e-04],
         [ 1.264e-03],
         [-1.226e-04]],

        [[ 7.306e-04],
         [ 1.006e-03],
         [ 6.622e-04],
         [-6.092e-05],
         [ 5.783e-04],
         [ 9.137e-04],
         [ 1.871e-05],
         [ 4.667e-04],
         [-1.929e-04],
         [-8.023e-05]],

        [[ 1.970e-04],
         [ 1.935e-04],
         [-6.409e-05],
         [ 5.601e-04],
         [ 4.991e-04],
         [ 8.412e-05],
         [ 1.703e-04],
         [ 4.492e-05],
         [ 3.146e-04],
         [ 1.085e-03]],

        [[-2.227e-04],
         [ 1.630e-04],
         [-1.024e-04],
         [ 5.101e-04],
         [ 5.448e-05],
         [ 1.093e-03],
         [ 7.894e-04],
         [ 1.638e-04],
         [ 3.856e-04],
         [-2.191e-05]],

        [[ 3.664e-04],
         [-3.250e-04],
         [ 1.185e-03],
         [ 5.176e-05],
         [-9.132e-05],
         [ 1.009e-03],
         [ 3.111e-04],
         [ 4.078e-04],
         [ 7.697e-04],
         [ 1.449e-04]],

        [[ 9.091e-05],
         [ 1.531e-04],
         [ 4.646e-04],
         [ 8.285e-05],
         [-6.988e-05],
         [ 2.409e-04],
         [ 4.874e-04],
         [ 1.509e-04],
         [ 3.304e-04],
         [ 1.059e-04]],

        [[ 3.227e-04],
         [-8.469e-05],
         [ 1.094e-04],
         [ 3.858e-04],
         [ 4.238e-04],
         [ 5.863e-04],
         [ 2.366e-05],
         [ 8.590e-04],
         [ 1.101e-04],
         [ 5.337e-05]],

        [[ 5.429e-04],
         [ 8.456e-04],
         [-3.223e-04],
         [ 8.409e-04],
         [-1.499e-04],
         [ 1.617e-03],
         [ 1.377e-05],
         [ 1.050e-04],
         [-1.179e-04],
         [ 4.902e-05]],

        [[-3.831e-04],
         [ 6.600e-05],
         [-5.854e-04],
         [ 3.873e-05],
         [ 2.740e-05],
         [ 5.016e-05],
         [-3.723e-04],
         [ 4.842e-04],
         [-2.113e-04],
         [-9.770e-04]],

        [[-7.009e-04],
         [-4.685e-04],
         [-9.248e-04],
         [-2.737e-04],
         [-5.564e-04],
         [-2.393e-04],
         [ 3.935e-05],
         [-1.828e-04],
         [ 2.791e-04],
         [ 2.115e-04]],

        [[ 9.384e-04],
         [-2.351e-04],
         [ 8.270e-05],
         [ 1.095e-04],
         [-5.531e-06],
         [-2.224e-04],
         [ 6.778e-05],
         [-1.009e-05],
         [-1.631e-05],
         [ 1.901e-04]],

        [[ 9.513e-05],
         [ 2.306e-04],
         [-1.084e-05],
         [ 6.783e-05],
         [-1.034e-04],
         [ 1.952e-05],
         [ 1.420e-04],
         [-8.537e-05],
         [ 1.051e-04],
         [-3.193e-05]]], device='cuda:0')
s after update for 1 param tensor([[[3.695e-02],
         [4.396e-03],
         [1.434e-03],
         [1.010e-02],
         [4.447e-02],
         [6.857e-03],
         [7.086e-03],
         [1.375e-03],
         [1.910e-04],
         [1.158e-02]],

        [[2.873e-02],
         [8.601e-03],
         [2.976e-02],
         [8.587e-03],
         [1.195e-02],
         [7.962e-02],
         [5.790e-03],
         [3.510e-03],
         [2.573e-02],
         [1.729e-01]],

        [[6.226e-03],
         [1.420e-01],
         [6.452e-04],
         [7.832e-02],
         [5.764e-02],
         [1.446e-02],
         [1.860e-02],
         [1.999e-03],
         [3.159e-03],
         [7.482e-05]],

        [[8.250e-03],
         [4.017e-04],
         [1.517e-02],
         [1.133e-02],
         [3.470e-05],
         [2.268e-04],
         [7.161e-04],
         [4.017e-02],
         [1.065e-03],
         [1.853e-02]],

        [[7.019e-02],
         [2.039e-01],
         [2.013e-02],
         [1.766e-02],
         [3.760e-02],
         [2.416e-05],
         [1.500e-01],
         [2.580e-01],
         [5.207e-02],
         [1.757e-02]],

        [[2.763e-02],
         [7.234e-04],
         [2.296e-03],
         [6.219e-03],
         [9.067e-03],
         [2.955e-04],
         [1.308e-03],
         [4.816e-03],
         [1.913e-03],
         [1.974e-03]],

        [[1.204e-01],
         [4.140e-03],
         [1.443e-02],
         [2.127e-02],
         [2.606e-02],
         [3.132e-02],
         [4.606e-02],
         [6.362e-03],
         [3.952e-02],
         [1.153e-02]],

        [[1.249e-05],
         [3.732e-02],
         [3.959e-05],
         [9.333e-03],
         [3.396e-03],
         [8.474e-04],
         [4.556e-02],
         [4.287e-02],
         [9.778e-04],
         [7.314e-03]],

        [[1.862e-03],
         [1.316e-02],
         [1.535e-03],
         [1.179e-01],
         [5.293e-02],
         [2.141e-04],
         [2.393e-01],
         [1.514e-02],
         [5.297e-02],
         [7.207e-03]],

        [[4.013e-02],
         [5.233e-02],
         [8.221e-02],
         [4.621e-03],
         [1.712e-02],
         [1.531e-01],
         [3.514e-03],
         [9.968e-02],
         [1.399e-02],
         [3.036e-02]],

        [[3.341e-03],
         [6.820e-03],
         [7.356e-03],
         [2.013e-02],
         [2.497e-02],
         [1.104e-02],
         [5.078e-03],
         [4.328e-04],
         [4.731e-02],
         [1.473e-01]],

        [[2.754e-02],
         [1.981e-02],
         [8.903e-04],
         [4.240e-02],
         [6.552e-03],
         [8.416e-02],
         [2.007e-02],
         [4.459e-02],
         [4.064e-02],
         [2.673e-04]],

        [[6.361e-02],
         [8.368e-03],
         [2.181e-01],
         [6.859e-02],
         [5.272e-03],
         [2.118e-01],
         [4.366e-02],
         [4.378e-02],
         [4.920e-02],
         [2.022e-02]],

        [[2.144e-03],
         [2.532e-03],
         [5.741e-02],
         [2.147e-03],
         [9.457e-03],
         [1.672e-02],
         [5.111e-02],
         [3.533e-02],
         [3.996e-02],
         [4.460e-02]],

        [[8.132e-03],
         [2.961e-03],
         [1.809e-03],
         [1.771e-02],
         [3.602e-02],
         [6.795e-02],
         [1.874e-02],
         [1.378e-01],
         [4.949e-04],
         [3.840e-03]],

        [[2.385e-02],
         [6.372e-02],
         [1.946e-02],
         [1.039e-01],
         [6.760e-03],
         [2.211e-01],
         [2.818e-04],
         [9.389e-04],
         [1.437e-02],
         [4.660e-03]],

        [[5.875e-02],
         [3.836e-03],
         [1.180e-02],
         [7.809e-03],
         [3.514e-03],
         [1.997e-03],
         [9.094e-03],
         [2.102e-02],
         [1.615e-02],
         [7.552e-02]],

        [[2.544e-02],
         [4.573e-02],
         [5.522e-02],
         [3.093e-02],
         [8.339e-02],
         [1.710e-02],
         [5.366e-03],
         [1.768e-03],
         [6.017e-02],
         [1.422e-02]],

        [[4.762e-02],
         [5.173e-02],
         [5.484e-04],
         [2.652e-02],
         [1.470e-04],
         [5.314e-03],
         [2.374e-03],
         [9.776e-04],
         [2.041e-05],
         [4.774e-02]],

        [[1.003e-02],
         [9.278e-03],
         [1.726e-04],
         [4.163e-04],
         [5.589e-04],
         [1.057e-04],
         [2.105e-02],
         [2.780e-03],
         [1.361e-02],
         [8.915e-03]]], device='cuda:0')
b after update for 1 param tensor([[[1.636],
         [0.564],
         [0.322],
         [0.855],
         [1.794],
         [0.705],
         [0.716],
         [0.315],
         [0.118],
         [0.916]],

        [[1.442],
         [0.789],
         [1.468],
         [0.789],
         [0.930],
         [2.401],
         [0.648],
         [0.504],
         [1.365],
         [3.538]],

        [[0.671],
         [3.207],
         [0.216],
         [2.381],
         [2.043],
         [1.023],
         [1.161],
         [0.380],
         [0.478],
         [0.074]],

        [[0.773],
         [0.171],
         [1.048],
         [0.906],
         [0.050],
         [0.128],
         [0.228],
         [1.706],
         [0.278],
         [1.158]],

        [[2.255],
         [3.842],
         [1.207],
         [1.131],
         [1.650],
         [0.042],
         [3.296],
         [4.322],
         [1.942],
         [1.128]],

        [[1.415],
         [0.229],
         [0.408],
         [0.671],
         [0.810],
         [0.146],
         [0.308],
         [0.591],
         [0.372],
         [0.378]],

        [[2.953],
         [0.548],
         [1.022],
         [1.241],
         [1.374],
         [1.506],
         [1.826],
         [0.679],
         [1.692],
         [0.914]],

        [[0.030],
         [1.644],
         [0.054],
         [0.822],
         [0.496],
         [0.248],
         [1.816],
         [1.762],
         [0.266],
         [0.728]],

        [[0.367],
         [0.976],
         [0.333],
         [2.922],
         [1.958],
         [0.125],
         [4.163],
         [1.047],
         [1.959],
         [0.722]],

        [[1.705],
         [1.947],
         [2.440],
         [0.578],
         [1.114],
         [3.329],
         [0.504],
         [2.687],
         [1.007],
         [1.483]],

        [[0.492],
         [0.703],
         [0.730],
         [1.207],
         [1.345],
         [0.894],
         [0.606],
         [0.177],
         [1.851],
         [3.266]],

        [[1.412],
         [1.198],
         [0.254],
         [1.752],
         [0.689],
         [2.469],
         [1.206],
         [1.797],
         [1.715],
         [0.139]],

        [[2.146],
         [0.778],
         [3.974],
         [2.229],
         [0.618],
         [3.917],
         [1.778],
         [1.781],
         [1.888],
         [1.210]],

        [[0.394],
         [0.428],
         [2.039],
         [0.394],
         [0.828],
         [1.100],
         [1.924],
         [1.599],
         [1.701],
         [1.797]],

        [[0.767],
         [0.463],
         [0.362],
         [1.132],
         [1.615],
         [2.218],
         [1.165],
         [3.159],
         [0.189],
         [0.527]],

        [[1.314],
         [2.148],
         [1.187],
         [2.742],
         [0.700],
         [4.001],
         [0.143],
         [0.261],
         [1.020],
         [0.581]],

        [[2.063],
         [0.527],
         [0.924],
         [0.752],
         [0.504],
         [0.380],
         [0.812],
         [1.234],
         [1.081],
         [2.339]],

        [[1.357],
         [1.820],
         [2.000],
         [1.497],
         [2.457],
         [1.113],
         [0.623],
         [0.358],
         [2.087],
         [1.015]],

        [[1.857],
         [1.935],
         [0.199],
         [1.386],
         [0.103],
         [0.620],
         [0.415],
         [0.266],
         [0.038],
         [1.859]],

        [[0.852],
         [0.820],
         [0.112],
         [0.174],
         [0.201],
         [0.087],
         [1.235],
         [0.449],
         [0.993],
         [0.803]]], device='cuda:0')
clipping threshold 2.782537623814828
a after update for 1 param tensor([[ 1.064e-04],
        [-2.198e-03],
        [ 6.222e-04],
        [-2.845e-04],
        [-2.267e-03],
        [ 3.525e-04],
        [ 4.383e-04],
        [ 6.446e-05],
        [ 5.634e-04],
        [ 1.352e-03],
        [ 7.918e-04],
        [ 5.353e-04],
        [ 6.100e-04],
        [ 2.647e-04],
        [-1.053e-04],
        [ 1.476e-04],
        [-9.057e-04],
        [-4.503e-04],
        [ 1.148e-04],
        [ 2.352e-04]], device='cuda:0')
s after update for 1 param tensor([[0.019],
        [0.127],
        [0.037],
        [0.004],
        [0.241],
        [0.029],
        [0.070],
        [0.003],
        [0.091],
        [0.205],
        [0.143],
        [0.070],
        [0.058],
        [0.007],
        [0.022],
        [0.003],
        [0.027],
        [0.044],
        [0.009],
        [0.069]], device='cuda:0')
b after update for 1 param tensor([[1.186],
        [3.037],
        [1.628],
        [0.538],
        [4.180],
        [1.451],
        [2.252],
        [0.470],
        [2.573],
        [3.854],
        [3.223],
        [2.246],
        [2.045],
        [0.703],
        [1.261],
        [0.461],
        [1.393],
        [1.788],
        [0.807],
        [2.233]], device='cuda:0')
clipping threshold 2.782537623814828
||w||^2 0.11558402623888692
exp ma of ||w||^2 0.23474306305918863
||w|| 0.3399765083632793
exp ma of ||w|| 0.46254129513562436
||w||^2 0.1449458547539665
exp ma of ||w||^2 0.23266920361014984
||w|| 0.38071755246372146
exp ma of ||w|| 0.4595609707611994
||w||^2 0.16079591137426524
exp ma of ||w||^2 0.19226656022607716
||w|| 0.4009936550299334
exp ma of ||w|| 0.42769880067925364
||w||^2 0.16953957296213643
exp ma of ||w||^2 0.23423214598962308
||w|| 0.41175183419401595
exp ma of ||w|| 0.45759959436800135
||w||^2 0.11049784897722084
exp ma of ||w||^2 0.3839927555415417
||w|| 0.3324121673122403
exp ma of ||w|| 0.5646920584792301
||w||^2 0.16053693372901748
exp ma of ||w||^2 0.3866644402442438
||w|| 0.40067060502240176
exp ma of ||w|| 0.5527287105968501
||w||^2 1.1576191309859059
exp ma of ||w||^2 0.41210757914992235
||w|| 1.0759271030074045
exp ma of ||w|| 0.5773338427530915
v before min max tensor([[-34.145,   8.929, -26.660,  ..., -23.054, -18.640,   4.508],
        [-40.789,  22.328,  -3.404,  ..., -12.275, -25.824, -23.345],
        [-27.228,  23.215, -27.658,  ..., -26.243, -32.405, -11.758],
        ...,
        [-23.469, -35.933, -24.353,  ..., -21.455, -16.756, -20.144],
        [-32.673, -14.978,  -0.425,  ..., -14.108, -29.726,   0.931],
        [-14.556, -28.265,  14.170,  ..., 111.956, -29.493,  -5.390]],
       device='cuda:0')
v tensor([[1.000e-12, 8.929e+00, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         4.508e+00],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         9.312e-01],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([-37.167, -19.818, -36.606, -25.357,  33.167, -31.361, -25.170, -23.141,
        -33.687, -17.416, -12.327,  -0.847,  -4.682, -28.118, -19.596, -33.451,
        -29.893,  22.284, -11.355,  14.408, -21.336,  31.925,  72.512,  78.368,
        -33.238,  -2.618, -16.146,  -1.177, -37.509, -37.547, -10.017, -34.552,
        -32.561, -30.535, -33.131, -29.411, -34.915, -30.333, -18.584, -25.908,
         50.770, -13.234,  -0.955, -36.619,  24.566, -12.981,   1.083,  -5.528,
        -25.595,  -5.334, -25.540, -16.741, -29.213, -33.383, -44.268,  54.437,
        -11.358, -26.630, -15.604, -40.003, -37.660, 175.631,  40.358, -29.688,
        -35.535, -35.093, -29.378,  68.010, -24.791,  92.836,  48.108, -35.904,
          6.445, -16.231, -26.869,  87.042, -19.851,  -6.621,  17.954, -11.354,
          1.126,  -7.894, -10.960, -26.818, -24.165, -15.557,  12.037, -37.927,
        -34.458, -12.104,  51.479,  25.813, -38.704, -38.482, -11.270, -28.501,
          1.661, -32.451,   1.317, -15.214,  16.215, -24.176,  -2.526, -12.182,
         85.551,  20.196, -16.161, -30.114, -27.883, -25.756,  -4.592, -25.585,
        -35.150, -18.234, -28.589, -25.789, -18.010,  -6.986,  31.746, -42.587,
         53.550,  -7.916, -18.695, -34.847, -39.040, -35.649, -30.303, -36.054,
        -31.365, -32.355, -14.640, -31.395,  69.909,  33.885, -14.499, -33.205,
        -39.162, -14.359, -10.883,  13.572,  -5.664,  -5.703, -34.053,  13.918,
        -14.358, -30.883, -25.508, -32.740, -25.040, -36.691, -38.548,  -0.369,
        -11.560,  -7.783, -11.372,  48.786, -20.111, -25.996,  79.925,  -1.201,
        -35.599,  16.179,   1.967,   6.800,  44.211,  -5.155, -19.123,  -3.059,
         27.971, -27.650, -28.880, -22.744, -29.152,  26.542, -25.471, -28.770,
        -35.189, -18.433,  -9.475, -45.094, -24.836, -24.215, -10.406,  17.988,
        -28.506, -22.692, -24.752, -17.538, -20.488, 127.354, -35.784, -33.579,
         -1.791, -28.066, -18.605, -11.928, -29.916,   5.697, -25.253, -31.621],
       device='cuda:0')
v tensor([1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.083e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        6.445e+00, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.126e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.661e+00, 1.000e-12, 1.317e+00, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.967e+00, 6.800e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.697e+00,
        1.000e-12, 1.000e-12], device='cuda:0')
v before min max tensor([[[-2.514e+01],
         [-1.931e+01],
         [-2.859e+01],
         [ 2.162e+01],
         [-2.564e+01],
         [ 1.059e+02],
         [-2.246e+01],
         [-3.391e+01],
         [-1.458e+01],
         [ 3.565e+01]],

        [[ 4.706e+01],
         [-4.378e+01],
         [ 3.873e+01],
         [ 4.636e+01],
         [-1.797e+01],
         [-3.324e+01],
         [ 6.161e+01],
         [-3.680e+01],
         [ 1.258e+02],
         [-3.567e+01]],

        [[-2.482e+01],
         [ 2.225e+02],
         [ 4.422e+01],
         [-2.760e+01],
         [-3.019e+01],
         [-2.114e+01],
         [-2.990e+01],
         [-1.675e+01],
         [ 1.981e+01],
         [ 5.563e+01]],

        [[-2.845e+01],
         [-1.174e+01],
         [ 4.668e+01],
         [-3.656e+01],
         [ 1.499e+00],
         [-3.516e+01],
         [-2.877e+01],
         [-3.298e+01],
         [-1.685e+01],
         [-1.952e+01]],

        [[ 8.164e+01],
         [-2.506e+01],
         [ 2.351e+01],
         [ 9.367e+00],
         [-3.166e+01],
         [ 9.704e+01],
         [-1.897e+01],
         [-5.767e+00],
         [-2.446e+01],
         [ 3.285e+02]],

        [[-3.971e+01],
         [ 2.306e+01],
         [ 3.070e+01],
         [-1.509e+01],
         [-9.490e+00],
         [-2.524e+00],
         [-2.428e+01],
         [ 1.629e+01],
         [-1.569e+01],
         [ 1.182e+01]],

        [[-3.710e+01],
         [-1.663e+01],
         [-2.955e+01],
         [-3.996e+01],
         [-3.470e+00],
         [-2.781e+01],
         [-1.501e+01],
         [-4.141e+01],
         [ 1.335e+01],
         [ 5.282e+01]],

        [[ 1.229e+02],
         [ 1.774e+01],
         [-4.142e+01],
         [-1.863e+00],
         [-2.095e+01],
         [ 2.140e+00],
         [ 9.217e+01],
         [ 1.217e+01],
         [-2.303e+01],
         [ 7.347e-01]],

        [[ 1.073e+02],
         [ 1.430e+02],
         [ 6.035e+01],
         [-3.003e+01],
         [-3.351e+01],
         [ 1.355e+01],
         [-4.098e+01],
         [ 1.452e+02],
         [ 4.416e-02],
         [-6.891e+00]],

        [[ 1.104e+02],
         [-5.360e+01],
         [ 1.091e+02],
         [-2.776e+01],
         [ 5.532e+01],
         [-3.621e+01],
         [-1.389e+01],
         [ 4.010e+02],
         [ 7.585e+00],
         [-2.904e+01]],

        [[-2.508e+01],
         [ 6.387e+01],
         [-2.223e+00],
         [-1.740e+01],
         [-2.975e+01],
         [-1.754e+01],
         [ 8.856e+00],
         [-1.875e+01],
         [-1.859e+01],
         [-3.017e+01]],

        [[-3.952e+00],
         [-1.837e+01],
         [ 4.795e+00],
         [-2.715e+01],
         [-2.712e+01],
         [ 2.489e+01],
         [-1.966e+01],
         [ 3.086e+00],
         [-3.571e+01],
         [-3.287e+01]],

        [[ 1.840e+01],
         [-2.374e+01],
         [ 1.696e+02],
         [-3.225e+01],
         [-4.334e+01],
         [ 1.579e+02],
         [-1.432e+01],
         [ 7.904e+01],
         [-3.681e+01],
         [-4.081e+01]],

        [[-2.230e+01],
         [ 6.642e+00],
         [ 2.967e+01],
         [-2.680e+01],
         [-1.164e+01],
         [ 3.100e+01],
         [-1.843e+01],
         [ 6.653e+01],
         [-1.480e+01],
         [-3.571e+01]],

        [[ 1.772e+00],
         [ 3.392e+00],
         [-3.541e+01],
         [-2.520e+01],
         [-3.542e+01],
         [-3.606e+01],
         [-1.091e+01],
         [-8.971e+00],
         [-1.352e+01],
         [-2.998e+01]],

        [[-2.701e+01],
         [-2.465e+01],
         [ 2.472e+01],
         [-3.313e+01],
         [-2.753e+01],
         [-2.924e+01],
         [ 1.388e+01],
         [-2.136e+01],
         [-3.063e+01],
         [-3.874e+01]],

        [[-2.477e+01],
         [-2.881e+01],
         [-2.253e+01],
         [-2.032e+01],
         [ 1.997e+01],
         [ 1.433e+01],
         [ 9.974e+01],
         [-1.670e+01],
         [-9.307e+00],
         [ 1.227e+02]],

        [[-4.325e+01],
         [-3.788e+01],
         [-6.704e+00],
         [-5.097e+01],
         [-4.116e+01],
         [ 6.703e+01],
         [-2.356e+01],
         [-1.522e+01],
         [ 2.181e+01],
         [ 1.390e+01]],

        [[-1.618e+01],
         [ 5.958e+01],
         [-3.242e+01],
         [-3.170e+01],
         [-3.031e+01],
         [-1.860e+01],
         [-2.301e+01],
         [-1.991e+01],
         [-2.723e+01],
         [-2.421e+00]],

        [[-2.390e+01],
         [ 1.768e+01],
         [-2.503e+01],
         [-3.752e+01],
         [-2.036e+01],
         [-2.849e+00],
         [-3.238e+01],
         [-2.273e+01],
         [ 2.456e+01],
         [-5.400e+00]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.499e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [9.367e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.140e+00],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [7.347e-01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [4.416e-02],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [7.585e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [8.856e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [4.795e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [3.086e+00],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [6.642e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.772e+00],
         [3.392e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[ 78.245],
        [  9.682],
        [-24.910],
        [-31.486],
        [192.387],
        [-12.389],
        [-27.408],
        [-12.422],
        [-40.346],
        [ 49.841],
        [ 77.312],
        [-41.493],
        [-26.597],
        [-41.456],
        [-21.585],
        [-36.144],
        [-21.734],
        [ 27.535],
        [ 97.925],
        [ -3.556]], device='cuda:0')
v tensor([[1.000e+01],
        [9.682e+00],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-0.008, -0.077, -0.037,  ...,  0.003, -0.000, -0.017],
        [-0.133, -0.017,  0.143,  ...,  0.082, -0.044, -0.039],
        [ 0.100, -0.076, -0.038,  ..., -0.032, -0.179,  0.123],
        ...,
        [-0.072,  0.094, -0.050,  ...,  0.011, -0.067,  0.138],
        [-0.036, -0.027, -0.075,  ...,  0.040, -0.053, -0.032],
        [ 0.042, -0.036,  0.042,  ...,  0.062, -0.065,  0.038]],
       device='cuda:0')
s after update for 1 param tensor([[1.711, 1.724, 1.776,  ..., 1.232, 1.314, 1.100],
        [2.095, 1.967, 1.255,  ..., 0.805, 1.543, 1.253],
        [1.683, 2.028, 1.364,  ..., 1.615, 1.524, 1.642],
        ...,
        [1.203, 1.680, 1.660,  ..., 1.639, 1.134, 1.582],
        [1.624, 1.579, 1.690,  ..., 1.583, 1.718, 1.401],
        [1.206, 1.321, 1.669,  ..., 1.642, 1.435, 1.147]], device='cuda:0')
b after update for 1 param tensor([[109.943, 110.332, 111.988,  ...,  93.289,  96.321,  88.139],
        [121.641, 117.870,  94.156,  ...,  75.412, 104.397,  94.090],
        [109.029, 119.681,  98.160,  ..., 106.797, 103.732, 107.697],
        ...,
        [ 92.171, 108.942, 108.284,  ..., 107.596,  89.490, 105.704],
        [107.102, 105.612, 109.247,  ..., 105.735, 110.143,  99.488],
        [ 92.290,  96.598, 108.556,  ..., 107.691, 100.683,  90.022]],
       device='cuda:0')
clipping threshold 0.3699354960278227
a after update for 1 param tensor([ 6.051e-02, -9.449e-02,  1.880e-02,  6.412e-04, -6.402e-02,  9.284e-03,
         4.895e-02, -7.540e-02,  4.562e-02,  7.110e-03,  8.009e-03,  1.327e-02,
        -8.082e-03, -3.397e-02, -1.360e-03,  1.281e-02, -9.535e-03, -6.247e-02,
         4.430e-02,  9.876e-02, -7.676e-02,  3.843e-02, -5.226e-02,  1.480e-01,
        -6.050e-03,  1.376e-01, -1.010e-01,  1.516e-02,  9.674e-02, -2.028e-02,
         5.377e-02, -1.004e-01, -1.080e-01, -8.083e-02, -3.591e-02, -3.235e-02,
         3.416e-02, -9.952e-02, -4.276e-03, -7.039e-02, -1.090e-02, -1.673e-01,
        -8.531e-03, -1.408e-01, -2.560e-02, -7.441e-02,  8.580e-02, -2.808e-02,
        -1.480e-01, -5.081e-02, -1.358e-02, -3.307e-02,  2.133e-02, -4.413e-02,
         1.124e-01,  1.521e-03,  4.483e-02, -1.207e-01,  8.117e-02, -3.824e-02,
        -3.139e-05, -2.496e-02,  1.039e-01, -5.167e-02, -9.291e-03, -6.143e-02,
        -5.180e-02,  2.379e-02, -7.728e-02, -9.106e-02, -9.758e-02,  2.939e-02,
         4.657e-02,  9.685e-02, -4.222e-02,  7.075e-02, -9.948e-02,  1.341e-02,
         9.980e-02, -5.492e-02, -4.927e-02, -4.860e-02, -2.659e-02,  1.060e-01,
         3.179e-02, -7.444e-03, -2.009e-02, -2.786e-02,  7.151e-02, -1.722e-02,
         6.244e-02,  2.492e-03, -1.072e-01,  5.513e-02,  6.557e-02, -4.093e-02,
        -7.489e-02,  2.347e-02, -4.859e-03,  3.244e-03,  4.657e-03,  1.066e-02,
         3.563e-02,  4.754e-02, -4.123e-02, -7.541e-02, -4.891e-02, -8.349e-02,
        -4.594e-02, -1.125e-02,  2.771e-02,  5.233e-03,  2.710e-02, -2.973e-03,
         6.829e-02, -6.745e-02, -9.285e-02, -2.883e-02, -3.766e-02, -1.123e-02,
        -1.066e-01,  1.118e-02, -4.799e-02,  7.798e-03, -9.331e-02, -7.355e-02,
        -9.965e-02,  1.096e-01,  8.955e-02, -2.310e-02,  3.025e-02,  2.455e-03,
         1.343e-01,  2.254e-02, -6.779e-02, -1.293e-01,  7.472e-02,  2.482e-02,
        -3.265e-02,  5.225e-02,  5.377e-02,  7.705e-02,  4.513e-03, -3.481e-03,
        -8.081e-02, -6.413e-02, -1.415e-01, -1.243e-03, -1.651e-02,  4.706e-02,
        -4.332e-02,  2.712e-02,  2.785e-02, -1.179e-02, -3.684e-02, -3.642e-02,
        -4.019e-02,  8.390e-02, -3.483e-02,  7.962e-02, -5.405e-02, -2.044e-02,
        -9.427e-02, -4.891e-03,  2.394e-02,  1.099e-01,  2.691e-02, -3.854e-02,
         1.038e-01, -9.844e-03, -7.275e-02, -5.753e-02, -5.828e-02, -3.366e-02,
         7.087e-03,  6.705e-03, -3.014e-02,  6.878e-02, -1.515e-02, -2.118e-02,
         4.884e-02,  9.419e-02, -1.249e-01, -1.351e-02, -3.847e-02, -6.504e-02,
         3.942e-02, -2.303e-02, -1.401e-02, -2.124e-02,  1.564e-02, -1.374e-01,
         1.318e-01, -4.005e-02,  9.939e-03,  7.114e-02,  4.497e-02,  4.212e-02,
        -1.290e-01,  8.142e-02], device='cuda:0')
s after update for 1 param tensor([1.920, 1.579, 1.932, 1.483, 1.676, 1.511, 1.591, 1.457, 1.670, 0.814,
        1.652, 0.878, 1.713, 1.562, 1.281, 1.571, 1.399, 1.918, 1.001, 1.918,
        1.940, 1.552, 2.096, 2.178, 1.567, 1.549, 1.705, 1.310, 1.764, 2.077,
        2.050, 1.771, 1.557, 1.769, 1.833, 1.404, 1.847, 1.500, 1.492, 1.583,
        1.660, 1.612, 1.634, 1.920, 1.704, 1.541, 1.835, 1.354, 1.273, 1.511,
        1.373, 1.100, 1.805, 1.783, 2.074, 1.971, 0.628, 1.252, 1.469, 2.071,
        1.833, 1.747, 2.021, 1.703, 1.895, 1.709, 1.745, 1.453, 1.160, 2.012,
        1.889, 1.737, 1.661, 1.321, 1.263, 1.747, 1.684, 0.369, 2.165, 0.678,
        1.459, 1.833, 1.524, 1.482, 1.447, 1.771, 1.893, 1.791, 1.649, 1.135,
        2.012, 2.310, 1.815, 2.151, 1.885, 1.332, 1.543, 1.542, 1.819, 1.464,
        1.681, 1.346, 1.265, 1.116, 1.689, 2.097, 1.370, 1.673, 1.434, 1.299,
        1.082, 1.275, 1.642, 0.869, 1.699, 1.261, 1.788, 1.383, 1.711, 2.009,
        2.126, 0.991, 1.291, 1.936, 1.962, 2.004, 1.687, 1.692, 1.886, 1.512,
        1.830, 1.566, 1.781, 2.058, 1.405, 1.578, 1.866, 1.032, 1.500, 2.088,
        1.084, 0.957, 1.591, 1.480, 1.693, 1.450, 2.072, 1.597, 1.473, 1.731,
        1.832, 1.064, 0.607, 1.232, 1.249, 2.176, 1.364, 1.382, 1.830, 2.084,
        1.666, 1.789, 1.794, 1.533, 1.982, 1.701, 1.664, 1.728, 1.888, 1.337,
        1.483, 1.141, 1.382, 1.991, 1.864, 1.404, 1.706, 1.477, 2.048, 2.192,
        1.362, 1.171, 1.382, 2.135, 1.753, 1.685, 1.369, 1.190, 1.215, 1.826,
        1.755, 2.044, 1.862, 1.382, 1.551, 0.768, 1.491, 1.627, 1.183, 1.508],
       device='cuda:0')
b after update for 1 param tensor([116.435, 105.594, 116.821, 102.359, 108.786, 103.297, 106.018, 101.444,
        108.597,  75.810, 108.032,  78.744, 109.989, 105.048,  95.116, 105.333,
         99.397, 116.392,  84.074, 116.400, 117.062, 104.702, 121.668, 124.020,
        105.195, 104.587, 109.736,  96.196, 111.624, 121.121, 120.314, 111.834,
        104.855, 111.760, 113.776,  99.565, 114.213, 102.920, 102.661, 105.740,
        108.262, 106.698, 107.417, 116.438, 109.708, 104.316, 113.834,  97.780,
         94.808, 103.303,  98.485,  88.136, 112.907, 112.230, 121.039, 117.978,
         66.600,  94.017, 101.874, 120.928, 113.784, 111.070, 119.487, 109.675,
        115.677, 109.878, 111.012, 101.289,  90.505, 119.198, 115.500, 110.764,
        108.324,  96.589,  94.435, 111.065, 109.070,  51.037, 123.650,  69.183,
        101.521, 113.782, 103.757, 102.315, 101.077, 111.852, 115.613, 112.455,
        107.919,  89.538, 119.211, 127.736, 113.232, 123.258, 115.396,  96.985,
        104.377, 104.366, 113.338, 101.695, 108.959,  97.488,  94.525,  88.789,
        109.219, 121.697,  98.374, 108.685, 100.640,  95.775,  87.409,  94.906,
        107.699,  78.330, 109.554,  94.381, 112.379,  98.822, 109.936, 119.117,
        122.529,  83.644,  95.484, 116.946, 117.711, 118.962, 109.160, 109.320,
        115.412, 103.339, 113.691, 105.155, 112.165, 120.550,  99.631, 105.569,
        114.795,  85.389, 102.943, 121.444,  87.506,  82.194, 106.017, 102.222,
        109.349, 101.211, 120.971, 106.211, 101.999, 110.572, 113.755,  86.703,
         65.502,  93.282,  93.917, 123.979,  98.141,  98.791, 113.677, 121.323,
        108.469, 112.420, 112.556, 104.060, 118.324, 109.620, 108.404, 110.484,
        115.478,  97.187, 102.352,  89.780,  98.782, 118.595, 114.739,  99.572,
        109.778, 102.128, 120.260, 124.432,  98.075,  90.928,  98.795, 122.806,
        111.266, 109.097,  98.312,  91.684,  92.652, 113.553, 111.333, 120.156,
        114.689,  98.785, 104.651,  73.640, 102.632, 107.195,  91.391, 103.205],
       device='cuda:0')
clipping threshold 0.3699354960278227
a after update for 1 param tensor([[[ 2.598e-01],
         [-1.469e-01],
         [-7.991e-06],
         [ 2.117e-01],
         [-5.412e-02],
         [ 1.927e-01],
         [ 2.784e-01],
         [-1.827e-01],
         [-5.492e-03],
         [ 2.395e-01]],

        [[-2.028e+00],
         [-1.156e+00],
         [-4.314e+00],
         [-4.397e+00],
         [-4.054e+00],
         [ 2.245e-02],
         [-1.438e-01],
         [-3.755e+00],
         [-4.068e+00],
         [-4.294e+00]],

        [[ 2.359e-01],
         [ 2.293e-01],
         [ 2.431e-01],
         [ 1.873e-01],
         [ 1.489e-01],
         [ 3.183e-01],
         [ 1.135e-01],
         [ 3.157e-01],
         [ 3.129e-01],
         [ 2.853e-02]],

        [[ 2.254e-01],
         [ 3.642e-01],
         [ 2.766e-01],
         [ 3.566e-01],
         [ 4.617e-02],
         [ 1.662e-01],
         [ 3.396e-01],
         [ 5.329e-02],
         [-8.480e-02],
         [ 3.087e-02]],

        [[-3.034e+00],
         [-3.087e+00],
         [-7.434e-01],
         [-3.084e+00],
         [-2.751e-02],
         [-4.748e-01],
         [-2.214e+00],
         [-3.144e-01],
         [-3.163e+00],
         [-2.600e+00]],

        [[ 8.578e-02],
         [ 1.148e+00],
         [-7.124e-01],
         [ 1.247e+00],
         [ 6.332e-01],
         [ 7.379e-01],
         [-3.233e-01],
         [-3.189e-01],
         [-1.341e+00],
         [-2.610e-01]],

        [[-9.957e-01],
         [ 2.496e-01],
         [-1.496e+00],
         [-1.198e+00],
         [-1.232e+00],
         [-1.244e+00],
         [ 2.929e-01],
         [-1.191e+00],
         [-9.819e-01],
         [-4.487e-02]],

        [[-5.788e-02],
         [-2.307e-02],
         [ 1.821e-01],
         [ 1.272e-01],
         [ 6.090e-02],
         [ 4.773e-03],
         [-5.349e-02],
         [ 1.229e-02],
         [-4.537e-02],
         [ 1.574e-01]],

        [[ 2.906e-01],
         [ 4.710e-01],
         [ 2.653e-01],
         [ 4.650e-01],
         [ 5.566e-01],
         [ 3.197e-01],
         [ 3.655e-01],
         [ 1.956e-01],
         [ 1.271e-01],
         [ 4.912e-01]],

        [[ 3.668e+00],
         [ 3.669e+00],
         [ 3.372e+00],
         [ 5.325e-03],
         [ 3.665e+00],
         [ 3.193e+00],
         [ 2.764e+00],
         [ 3.584e+00],
         [-7.908e-03],
         [-6.068e-02]],

        [[ 6.181e-01],
         [ 7.286e-01],
         [-4.877e-02],
         [ 4.963e-01],
         [ 6.203e-01],
         [ 2.168e-01],
         [ 5.512e-01],
         [-5.651e-02],
         [ 7.497e-02],
         [ 4.505e-01]],

        [[ 4.964e-02],
         [-7.279e-02],
         [ 5.144e-02],
         [ 2.619e-01],
         [ 1.173e+00],
         [ 1.421e+00],
         [ 1.508e+00],
         [ 1.261e+00],
         [ 1.348e+00],
         [ 1.002e+00]],

        [[ 1.300e+00],
         [ 1.520e-01],
         [ 1.111e+00],
         [-8.048e-02],
         [ 1.106e+00],
         [ 1.301e+00],
         [ 1.086e-01],
         [ 1.502e+00],
         [ 8.700e-02],
         [ 1.159e+00]],

        [[-8.847e-02],
         [ 7.598e-01],
         [ 8.498e-01],
         [ 6.783e-01],
         [ 3.293e-02],
         [ 9.139e-01],
         [ 2.124e-02],
         [-1.280e-01],
         [ 6.122e-01],
         [ 9.259e-01]],

        [[-6.967e-02],
         [-6.349e-02],
         [ 1.313e+00],
         [ 1.418e+00],
         [ 1.655e-02],
         [-4.828e-02],
         [ 1.488e+00],
         [ 1.678e+00],
         [-1.173e-01],
         [ 2.606e-01]],

        [[ 1.393e+00],
         [ 1.403e+00],
         [-5.949e-01],
         [ 1.272e+00],
         [-2.473e-01],
         [-3.722e-01],
         [-2.444e-01],
         [ 1.282e+00],
         [ 6.957e-01],
         [ 1.106e+00]],

        [[-1.037e+00],
         [ 3.294e-01],
         [-1.250e+00],
         [-1.331e+00],
         [-1.245e+00],
         [ 2.217e-01],
         [-1.544e+00],
         [ 3.077e-01],
         [-1.410e+00],
         [-1.271e+00]],

        [[-1.130e+00],
         [-9.853e-01],
         [-1.047e+00],
         [-7.431e-01],
         [-9.677e-01],
         [-7.571e-01],
         [ 1.144e-02],
         [ 2.517e-02],
         [-1.286e-01],
         [-3.848e-01]],

        [[ 5.963e-01],
         [ 3.364e-01],
         [-8.516e-02],
         [ 4.624e-01],
         [-1.913e-01],
         [-1.620e-01],
         [-2.347e-01],
         [-3.017e-02],
         [-1.579e-01],
         [ 4.555e-01]],

        [[-6.044e-02],
         [ 4.638e-01],
         [ 9.995e-02],
         [ 2.806e-01],
         [ 7.782e-02],
         [ 8.589e-02],
         [ 4.797e-01],
         [ 3.219e-01],
         [ 4.837e-01],
         [ 2.172e-01]]], device='cuda:0')
s after update for 1 param tensor([[[1.454],
         [1.308],
         [1.806],
         [1.933],
         [1.313],
         [1.956],
         [1.769],
         [1.780],
         [1.408],
         [1.522]],

        [[3.019],
         [2.663],
         [2.276],
         [2.404],
         [1.636],
         [1.597],
         [1.999],
         [1.750],
         [1.989],
         [1.669]],

        [[1.424],
         [2.335],
         [1.922],
         [1.632],
         [2.120],
         [1.149],
         [1.552],
         [0.887],
         [1.716],
         [1.688]],

        [[1.366],
         [1.580],
         [1.702],
         [2.127],
         [1.489],
         [1.693],
         [1.344],
         [1.782],
         [1.551],
         [1.718]],

        [[2.550],
         [2.557],
         [1.984],
         [2.722],
         [1.479],
         [2.247],
         [1.773],
         [1.620],
         [2.459],
         [2.556]],

        [[1.898],
         [1.504],
         [2.310],
         [1.344],
         [0.961],
         [1.682],
         [1.659],
         [2.338],
         [1.409],
         [1.812]],

        [[1.940],
         [0.965],
         [1.473],
         [1.950],
         [1.860],
         [1.808],
         [1.202],
         [1.963],
         [1.751],
         [2.145]],

        [[2.370],
         [1.593],
         [1.957],
         [2.123],
         [0.979],
         [0.979],
         [2.042],
         [1.575],
         [1.076],
         [1.556]],

        [[2.024],
         [2.458],
         [2.101],
         [1.886],
         [1.711],
         [1.911],
         [1.936],
         [1.685],
         [1.773],
         [1.822]],

        [[2.556],
         [2.611],
         [2.725],
         [1.297],
         [2.571],
         [2.411],
         [1.713],
         [2.420],
         [2.087],
         [1.420]],

        [[1.397],
         [2.200],
         [1.226],
         [1.223],
         [1.713],
         [1.639],
         [1.500],
         [1.114],
         [1.148],
         [1.741]],

        [[1.679],
         [1.526],
         [1.762],
         [1.371],
         [1.729],
         [2.593],
         [2.177],
         [2.289],
         [1.721],
         [1.958]],

        [[2.378],
         [1.111],
         [2.282],
         [1.923],
         [2.192],
         [2.375],
         [1.634],
         [2.152],
         [1.753],
         [2.468]],

        [[1.517],
         [1.509],
         [1.834],
         [1.891],
         [1.356],
         [2.036],
         [0.943],
         [1.893],
         [1.497],
         [1.673]],

        [[1.929],
         [1.853],
         [1.688],
         [1.897],
         [1.681],
         [1.764],
         [1.494],
         [1.532],
         [1.181],
         [1.753]],

        [[1.262],
         [1.718],
         [1.932],
         [2.052],
         [2.032],
         [1.739],
         [1.834],
         [1.001],
         [1.815],
         [1.835]],

        [[1.216],
         [1.348],
         [1.707],
         [1.018],
         [1.893],
         [1.975],
         [1.754],
         [0.914],
         [1.802],
         [2.059]],

        [[2.080],
         [2.011],
         [1.451],
         [2.508],
         [1.925],
         [2.299],
         [1.447],
         [1.174],
         [1.640],
         [1.668]],

        [[1.495],
         [1.707],
         [1.544],
         [1.688],
         [1.429],
         [1.226],
         [1.388],
         [1.155],
         [1.316],
         [1.787]],

        [[1.436],
         [1.737],
         [1.487],
         [1.842],
         [1.804],
         [0.600],
         [1.548],
         [1.916],
         [1.573],
         [1.495]]], device='cuda:0')
b after update for 1 param tensor([[[101.343],
         [ 96.112],
         [112.954],
         [116.833],
         [ 96.305],
         [117.543],
         [111.780],
         [112.116],
         [ 99.707],
         [103.686]],

        [[146.014],
         [137.142],
         [126.792],
         [130.303],
         [107.506],
         [106.194],
         [118.828],
         [111.185],
         [118.511],
         [108.582]],

        [[100.269],
         [128.412],
         [116.508],
         [107.349],
         [122.355],
         [ 90.080],
         [104.686],
         [ 79.150],
         [110.073],
         [109.182]],

        [[ 98.224],
         [105.646],
         [109.630],
         [122.567],
         [102.561],
         [109.335],
         [ 97.440],
         [112.188],
         [104.645],
         [110.165]],

        [[134.191],
         [134.393],
         [118.370],
         [138.661],
         [102.205],
         [125.963],
         [111.896],
         [106.978],
         [131.793],
         [134.346]],

        [[115.787],
         [103.057],
         [127.739],
         [ 97.413],
         [ 82.400],
         [108.985],
         [108.258],
         [128.510],
         [ 99.763],
         [113.125]],

        [[117.040],
         [ 82.569],
         [101.980],
         [117.347],
         [114.600],
         [112.998],
         [ 92.145],
         [117.756],
         [111.200],
         [123.085]],

        [[129.368],
         [106.080],
         [117.564],
         [122.436],
         [ 83.152],
         [ 83.156],
         [120.078],
         [105.481],
         [ 87.174],
         [104.843]],

        [[119.568],
         [131.746],
         [121.814],
         [115.420],
         [109.938],
         [116.164],
         [116.932],
         [109.090],
         [111.906],
         [113.426]],

        [[134.347],
         [135.788],
         [138.722],
         [ 95.723],
         [134.743],
         [130.485],
         [110.001],
         [130.727],
         [121.408],
         [100.145]],

        [[ 99.342],
         [124.653],
         [ 93.057],
         [ 92.954],
         [109.983],
         [107.605],
         [102.914],
         [ 88.714],
         [ 90.025],
         [110.896]],

        [[108.885],
         [103.810],
         [111.542],
         [ 98.402],
         [110.519],
         [135.340],
         [123.994],
         [127.136],
         [110.261],
         [117.594]],

        [[129.589],
         [ 88.561],
         [126.958],
         [116.550],
         [124.432],
         [129.506],
         [107.416],
         [123.272],
         [111.266],
         [132.015]],

        [[103.510],
         [103.224],
         [113.819],
         [115.570],
         [ 97.849],
         [119.924],
         [ 81.629],
         [115.621],
         [102.810],
         [108.717]],

        [[116.717],
         [114.412],
         [109.193],
         [115.747],
         [108.965],
         [111.610],
         [102.719],
         [104.021],
         [ 91.312],
         [111.265]],

        [[ 94.418],
         [110.152],
         [116.807],
         [120.397],
         [119.788],
         [110.825],
         [113.805],
         [ 84.088],
         [113.206],
         [113.840]],

        [[ 92.662],
         [ 97.587],
         [109.793],
         [ 84.777],
         [115.619],
         [118.118],
         [111.291],
         [ 80.338],
         [112.823],
         [120.588]],

        [[121.203],
         [119.180],
         [101.221],
         [133.084],
         [116.601],
         [127.421],
         [101.077],
         [ 91.057],
         [107.627],
         [108.554]],

        [[102.752],
         [109.799],
         [104.428],
         [109.192],
         [100.445],
         [ 93.049],
         [ 99.003],
         [ 90.308],
         [ 96.397],
         [112.336]],

        [[100.721],
         [110.758],
         [102.496],
         [114.066],
         [112.879],
         [ 65.117],
         [104.578],
         [116.318],
         [105.402],
         [102.762]]], device='cuda:0')
clipping threshold 0.3699354960278227
a after update for 1 param tensor([[ 0.127],
        [-4.219],
        [ 0.276],
        [ 0.161],
        [-3.035],
        [-0.215],
        [-1.111],
        [-0.014],
        [ 0.481],
        [ 3.721],
        [ 0.528],
        [ 1.359],
        [ 1.410],
        [ 0.892],
        [ 1.455],
        [ 0.796],
        [-1.053],
        [-0.818],
        [ 0.433],
        [ 0.130]], device='cuda:0')
s after update for 1 param tensor([[1.630],
        [2.145],
        [1.442],
        [1.479],
        [2.604],
        [1.350],
        [1.861],
        [1.311],
        [1.931],
        [2.788],
        [1.988],
        [2.201],
        [1.702],
        [1.948],
        [1.491],
        [2.068],
        [2.186],
        [2.080],
        [2.237],
        [1.658]], device='cuda:0')
b after update for 1 param tensor([[107.281],
        [123.078],
        [100.910],
        [102.193],
        [135.602],
        [ 97.657],
        [114.630],
        [ 96.208],
        [116.795],
        [140.333],
        [118.487],
        [124.672],
        [109.638],
        [117.300],
        [102.619],
        [120.840],
        [124.246],
        [121.214],
        [125.685],
        [108.197]], device='cuda:0')
clipping threshold 0.3699354960278227
||w||^2 0.12993380460477785
exp ma of ||w||^2 0.5921344202899153
||w|| 0.36046331936103826
exp ma of ||w|| 0.6844005461975471
||w||^2 0.49165634789230156
exp ma of ||w||^2 0.5629501001682876
||w|| 0.7011821075100972
exp ma of ||w|| 0.6932585270564516
||w||^2 0.3233312534146706
exp ma of ||w||^2 0.5894436039387595
||w|| 0.5686222413999216
exp ma of ||w|| 0.7166673069313857
||w||^2 0.22563199401894404
exp ma of ||w||^2 0.5978684738796496
||w|| 0.4750073620681516
exp ma of ||w|| 0.7158275187875532
||w||^2 1.7828575316527353
exp ma of ||w||^2 0.7543166417985876
||w|| 1.3352368822245495
exp ma of ||w|| 0.8217946375607562
cuda
Objective function 46.42 = squared loss an data 39.11 + 0.5*rho*h**2 5.886210 + alpha*h 0.000000 + L2reg 1.13 + L1reg 0.30 ; SHD = 137 ; DAG False
Proportion of microbatches that were clipped  0.7691003068971087
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 3.4310959205074703
iteration 1 in outer loop, alpha = 3.4310959205074703, rho = 1.0, h = 3.4310959205074703
cuda
4420
cuda
Objective function 58.20 = squared loss an data 39.11 + 0.5*rho*h**2 5.886210 + alpha*h 11.772419 + L2reg 1.13 + L1reg 0.30 ; SHD = 137 ; DAG False
||w||^2 42826412065.38504
exp ma of ||w||^2 93884171153.29352
||w|| 206945.43257918267
exp ma of ||w|| 230556.38384580772
||w||^2 613.1127680988433
exp ma of ||w||^2 59555911.256137796
||w|| 24.761114031861396
exp ma of ||w|| 679.1312830494658
||w||^2 1.2013377369507523
exp ma of ||w||^2 1281092.2541662673
||w|| 1.0960555355230648
exp ma of ||w|| 17.720514301503556
||w||^2 0.6802716404567523
exp ma of ||w||^2 0.9318051384504631
||w|| 0.8247858148978753
exp ma of ||w|| 0.9237228955689615
||w||^2 0.6123388797051941
exp ma of ||w||^2 0.944428692733509
||w|| 0.7825208493741199
exp ma of ||w|| 0.9224824413737207
||w||^2 1.1204777678383242
exp ma of ||w||^2 1.164092020584916
||w|| 1.058526224445254
exp ma of ||w|| 1.0070168222882057
||w||^2 0.4972596602362807
exp ma of ||w||^2 1.0605862360264378
||w|| 0.7051664060604991
exp ma of ||w|| 0.9810230169632614
||w||^2 2.588848867246219
exp ma of ||w||^2 1.161906059584769
||w|| 1.6089900146508738
exp ma of ||w|| 1.02369474440732
||w||^2 1.4527501134469607
exp ma of ||w||^2 1.0547303105233685
||w|| 1.2053008393952775
exp ma of ||w|| 0.9945385809204336
||w||^2 0.6349081987255542
exp ma of ||w||^2 1.0806239405380498
||w|| 0.7968112692009032
exp ma of ||w|| 0.9858372674049667
||w||^2 0.8745200247928144
exp ma of ||w||^2 1.0425825462706417
||w|| 0.9351577539606964
exp ma of ||w|| 0.9867724959610111
||w||^2 0.7170800544637702
exp ma of ||w||^2 1.1824285004112451
||w|| 0.8468057950107393
exp ma of ||w|| 1.0484639560022553
cuda
Objective function 43.16 = squared loss an data 30.13 + 0.5*rho*h**2 2.940933 + alpha*h 8.321286 + L2reg 1.48 + L1reg 0.28 ; SHD = 110 ; DAG False
Proportion of microbatches that were clipped  0.7674835137995604
iteration 1 in inner loop, alpha 3.4310959205074703 rho 1.0 h 2.42525598117993
4420
cuda
Objective function 69.63 = squared loss an data 30.13 + 0.5*rho*h**2 29.409333 + alpha*h 8.321286 + L2reg 1.48 + L1reg 0.28 ; SHD = 110 ; DAG False
||w||^2 216.1086408987086
exp ma of ||w||^2 20072515.81804191
||w|| 14.700634030500472
exp ma of ||w|| 187.09075436723788
||w||^2 1.3782291821337882
exp ma of ||w||^2 3.3374589989453907
||w|| 1.1739800603646504
exp ma of ||w|| 1.325243949453083
v before min max tensor([[-257.108, -229.228,  407.691,  ...,   34.510, -290.181, 1093.821],
        [-115.935,  -54.771, 3283.753,  ...,  -41.162, 1005.895, -296.660],
        [ 606.216,   65.700,  455.583,  ...,  281.794,  -45.998,  105.300],
        ...,
        [-128.000, -140.523,  -18.061,  ...,  129.872, -228.872, -150.932],
        [-102.489, -223.183, -275.324,  ..., -160.839,  -59.794, -242.907],
        [ -23.641,  -96.236, -194.461,  ...,  -38.429, -154.608, -255.911]],
       device='cuda:0')
v tensor([[1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e+01,
         1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.000e+01],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e+01, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([-1.476e+02,  3.246e+02, -2.918e+01, -2.947e+02, -2.235e+02, -1.151e+02,
         4.387e+02, -1.739e+02,  1.536e+02,  2.350e+01,  3.883e+02, -1.672e+02,
        -2.281e+02, -7.740e+01, -1.954e+02, -2.508e+01,  1.319e+03, -2.445e+02,
         7.817e+02,  1.132e+01, -1.023e+02,  3.348e+02,  1.233e+02, -2.345e+02,
         2.810e+02, -3.671e+01, -2.728e+02, -2.117e+02,  4.765e+02,  2.073e+02,
        -1.047e+02, -2.388e+02,  8.011e+01,  3.987e+01, -1.578e+02, -2.085e+02,
        -3.077e+02,  2.255e+02, -1.683e+02, -2.367e+02,  1.130e+03, -1.876e+02,
        -3.068e+02, -2.244e+02, -2.434e+02, -2.695e+02,  3.307e-01, -1.054e+02,
         7.087e+02, -1.166e+02, -2.343e+02,  1.193e+02,  1.142e+02, -2.140e+02,
        -2.449e+02,  1.163e+02,  5.649e+01, -2.605e+02,  2.905e+02,  1.836e+02,
         1.488e+02, -2.128e+02, -2.219e+02, -3.040e+02, -2.383e+01, -2.091e+02,
        -2.352e+02,  5.115e+02,  1.157e+02,  1.612e+02, -2.996e+02, -1.559e+02,
        -7.837e+01,  3.830e+02, -1.876e+02, -1.551e+02,  7.823e+01, -1.948e+02,
         5.555e+02,  2.593e+02, -2.493e+02, -2.886e+02,  5.291e+02,  2.452e+00,
        -2.001e+02, -1.106e+02, -1.868e+02,  2.578e+02,  7.468e+02,  9.759e+02,
         3.960e+03,  3.863e+02,  1.686e+03, -2.214e+02,  2.544e+02,  4.995e+02,
        -2.555e+02, -1.700e+02,  4.231e+02, -1.362e+02, -2.888e+02, -3.023e+02,
        -1.328e+02,  1.654e+03, -1.917e+02, -2.904e+02,  2.727e+02, -1.672e+01,
        -1.313e+00,  5.270e+02, -2.970e+02, -2.663e+02, -9.481e+01,  4.756e+01,
         2.980e+02, -1.761e+02, -1.704e+02, -2.685e+02, -2.975e+02,  1.399e+03,
        -2.409e+02, -1.834e+02,  1.311e+02,  1.354e+03, -2.648e+02, -1.984e+02,
        -2.531e+02,  5.367e+02, -2.354e+02,  1.731e+02, -3.215e+02, -2.850e+02,
         2.333e+02, -2.192e+02, -2.377e+02,  5.924e+02, -2.535e+02, -2.910e+02,
        -1.752e+02, -2.144e+02, -9.233e+01,  4.823e+02, -2.906e+02, -4.579e+01,
        -1.042e+01, -2.088e+02, -2.472e+02,  2.615e+02, -1.626e+02, -2.386e+02,
        -2.025e+02, -2.775e+02, -1.668e+02, -2.466e+02, -1.867e+01,  5.892e+01,
        -1.401e+02, -2.906e+02,  9.897e+02, -1.835e+02, -9.491e+01,  2.973e+02,
        -1.671e+02, -2.108e+02, -2.094e+02, -2.757e+02, -2.073e+02,  1.498e+02,
         3.646e+02, -3.234e+02, -2.672e+02,  3.984e+02, -1.581e+02, -1.339e+01,
        -1.649e+02, -1.840e+02, -1.263e+02, -1.648e+02, -2.974e+02, -1.816e+02,
        -3.208e+02, -2.337e+02, -2.672e+02,  6.920e+02, -2.704e+02, -2.465e+02,
         8.449e+01, -1.035e+02, -2.049e+02, -1.954e+02, -2.583e+02, -1.847e+02,
        -2.031e+02,  2.518e+02, -3.123e+02, -1.285e+02, -5.830e+01, -2.485e+02,
        -2.436e+01, -2.562e+01], device='cuda:0')
v tensor([1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.307e-01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 2.452e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12], device='cuda:0')
v before min max tensor([[[ 1.156e+02],
         [-7.248e+01],
         [-7.281e+01],
         [-2.091e+02],
         [-1.756e+02],
         [ 1.906e+02],
         [-3.294e+02],
         [ 5.684e+01],
         [ 9.565e+01],
         [ 1.289e+01]],

        [[ 7.081e+01],
         [-1.643e+02],
         [-2.886e+02],
         [ 4.036e+02],
         [-8.777e+01],
         [ 8.488e+01],
         [ 7.381e+01],
         [ 7.981e+02],
         [-1.841e+02],
         [ 2.902e+02]],

        [[ 2.423e+01],
         [-2.375e+02],
         [-1.223e+02],
         [ 2.475e+02],
         [-2.031e+02],
         [-4.952e+01],
         [ 9.435e+01],
         [-2.940e+02],
         [ 4.591e+02],
         [-2.545e+02]],

        [[-2.491e+02],
         [-1.158e+00],
         [-2.877e+02],
         [-2.303e+02],
         [-2.135e+02],
         [ 2.212e+03],
         [-1.812e+02],
         [ 9.806e+01],
         [-2.844e+02],
         [-2.275e+02]],

        [[-7.918e+01],
         [-1.694e+02],
         [-2.414e+02],
         [-2.711e+02],
         [ 5.099e+01],
         [ 6.689e+01],
         [ 1.385e+02],
         [-1.634e+02],
         [ 2.794e+03],
         [-2.683e+01]],

        [[-2.722e+02],
         [-1.826e+02],
         [ 1.352e+02],
         [ 7.361e+01],
         [-6.764e+01],
         [-2.356e+02],
         [ 3.267e+02],
         [ 1.110e+03],
         [-2.201e+02],
         [-2.659e+02]],

        [[-3.947e+01],
         [ 2.694e+01],
         [-1.538e+02],
         [-2.193e+02],
         [-6.340e+01],
         [-9.365e+01],
         [-2.964e+02],
         [-1.761e+02],
         [-5.560e+01],
         [-1.181e+02]],

        [[ 1.438e+02],
         [ 1.946e+02],
         [-1.744e+02],
         [-1.812e+02],
         [ 8.466e+01],
         [ 1.065e+03],
         [-1.049e+02],
         [-3.107e+02],
         [-2.681e+02],
         [ 1.318e+03]],

        [[-1.503e+02],
         [-1.919e+02],
         [ 3.130e+02],
         [-2.374e+02],
         [ 1.074e+02],
         [ 1.533e+02],
         [ 6.884e+02],
         [-2.094e+02],
         [-1.904e+02],
         [ 3.110e+02]],

        [[-1.991e+02],
         [-1.206e+02],
         [-2.666e+02],
         [-2.697e+02],
         [ 4.032e+02],
         [ 8.978e+01],
         [ 1.472e+02],
         [-8.776e+01],
         [-2.667e+02],
         [ 1.993e+02]],

        [[-1.885e+02],
         [ 5.719e+02],
         [ 1.029e+03],
         [-3.008e+02],
         [-2.552e+02],
         [ 2.316e+01],
         [-1.949e+02],
         [-2.174e+02],
         [-3.118e+02],
         [ 4.960e+02]],

        [[-2.295e+02],
         [ 5.023e+02],
         [-7.444e+01],
         [-2.832e+02],
         [ 5.863e+02],
         [-2.541e+02],
         [ 1.670e+02],
         [-1.081e+02],
         [ 5.505e+01],
         [-2.114e+02]],

        [[-1.949e+02],
         [ 4.919e+01],
         [-2.518e+02],
         [-2.670e+02],
         [-3.393e+02],
         [-1.161e+02],
         [-1.050e+02],
         [-1.390e+02],
         [ 6.908e+01],
         [ 4.801e+02]],

        [[-2.402e+02],
         [-2.009e+02],
         [-6.735e+01],
         [-3.332e+02],
         [ 2.270e+02],
         [-2.876e+01],
         [-2.646e+02],
         [ 6.476e+01],
         [-1.234e+02],
         [-2.597e+02]],

        [[-2.581e+02],
         [ 7.390e+02],
         [-2.415e+02],
         [-2.342e+02],
         [ 2.791e+01],
         [-2.306e+02],
         [-1.728e+02],
         [ 3.077e+03],
         [ 6.524e+02],
         [ 1.682e+02]],

        [[-3.998e+01],
         [-2.719e+02],
         [-2.815e+02],
         [ 5.360e+02],
         [ 9.401e+01],
         [ 6.940e+02],
         [ 1.034e+03],
         [-2.598e+02],
         [-2.122e+02],
         [ 1.946e+02]],

        [[-1.960e+02],
         [-2.628e+02],
         [-1.889e+02],
         [ 1.470e+01],
         [ 1.735e+01],
         [-7.936e+01],
         [-2.041e+02],
         [-2.555e+02],
         [ 1.687e+02],
         [-2.034e+02]],

        [[ 1.295e+02],
         [-2.793e+02],
         [-3.384e+01],
         [ 4.600e+02],
         [-2.816e+02],
         [-3.043e+02],
         [-1.884e+02],
         [-1.388e+02],
         [-1.919e+02],
         [ 1.586e+02]],

        [[-1.908e+02],
         [ 2.021e+02],
         [ 1.062e+02],
         [-2.487e+02],
         [-2.592e+02],
         [-7.927e+01],
         [ 7.777e+01],
         [-8.914e+01],
         [-2.491e+02],
         [-1.739e+02]],

        [[-2.789e+02],
         [ 2.639e+02],
         [-2.675e+02],
         [-2.486e+02],
         [-1.088e+02],
         [-1.840e+02],
         [ 6.664e+02],
         [-1.976e+02],
         [-2.339e+02],
         [-2.669e+02]]], device='cuda:0')
v tensor([[[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[ 133.328],
        [-258.112],
        [-100.618],
        [-150.588],
        [ 543.499],
        [ 528.909],
        [-214.417],
        [-243.466],
        [ 196.661],
        [-297.162],
        [ 484.714],
        [1705.407],
        [ 203.480],
        [-263.302],
        [1180.874],
        [-286.555],
        [1115.067],
        [-162.168],
        [-121.266],
        [-155.527]], device='cuda:0')
v tensor([[1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 0.042, -0.006, -0.412,  ..., -0.399,  0.154, -0.126],
        [-0.102, -0.456,  0.050,  ...,  0.493,  0.051,  0.095],
        [-0.056,  0.009,  0.144,  ..., -0.184,  0.152, -0.236],
        ...,
        [-0.014, -0.097,  0.017,  ...,  0.140,  0.141,  0.185],
        [ 0.036,  0.105,  0.156,  ...,  0.216,  0.018, -0.086],
        [ 0.099, -0.121, -0.279,  ...,  0.016,  0.211, -0.026]],
       device='cuda:0')
s after update for 1 param tensor([[1.583, 1.676, 2.082,  ..., 1.955, 1.779, 1.764],
        [1.554, 1.704, 2.333,  ..., 1.352, 1.793, 2.098],
        [1.692, 1.821, 1.712,  ..., 1.878, 1.254, 1.673],
        ...,
        [1.309, 1.738, 2.157,  ..., 1.698, 1.817, 1.944],
        [1.407, 1.778, 1.820,  ..., 1.609, 1.365, 1.658],
        [2.115, 1.780, 1.232,  ..., 1.147, 1.771, 1.567]], device='cuda:0')
b after update for 1 param tensor([[110.213, 113.411, 126.382,  ..., 122.475, 116.836, 116.336],
        [109.203, 114.325, 133.779,  ..., 101.854, 117.278, 126.875],
        [113.951, 118.187, 114.622,  ..., 120.037,  98.074, 113.299],
        ...,
        [100.210, 115.477, 128.658,  ..., 114.125, 118.077, 122.133],
        [103.881, 116.784, 118.178,  ..., 111.106, 102.325, 112.798],
        [127.374, 116.878,  97.215,  ...,  93.802, 116.565, 109.648]],
       device='cuda:0')
clipping threshold 0.9904761217824113
a after update for 1 param tensor([-0.140, -0.025,  0.052, -0.040, -0.028, -0.100,  0.247,  0.211,  0.204,
         0.127, -0.185,  0.195,  0.290, -0.148,  0.383,  0.058,  0.236,  0.183,
        -0.070,  0.005,  0.038,  0.257, -0.178,  0.229,  0.005,  0.357, -0.231,
        -0.099,  0.182,  0.311,  0.023, -0.140, -0.148, -0.080,  0.191, -0.308,
        -0.142, -0.055, -0.050, -0.187,  0.305,  0.081, -0.366, -0.078,  0.056,
        -0.264,  0.009,  0.057, -0.156,  0.136,  0.177,  0.374,  0.005, -0.213,
        -0.067,  0.256,  0.330, -0.262,  0.070, -0.188, -0.032,  0.083, -0.309,
        -0.439,  0.340, -0.016,  0.515,  0.013, -0.210,  0.052, -0.038, -0.423,
        -0.130, -0.204,  0.221,  0.112,  0.196,  0.392,  0.113,  0.215,  0.149,
        -0.187, -0.055,  0.345, -0.262,  0.122, -0.075, -0.345,  0.176, -0.079,
        -0.134,  0.116, -0.352,  0.027,  0.193,  0.056, -0.418, -0.374, -0.091,
        -0.185, -0.110,  0.257,  0.065,  0.213, -0.204, -0.017, -0.006, -0.067,
        -0.225,  0.369, -0.411,  0.101, -0.463, -0.063,  0.056,  0.014,  0.537,
        -0.052, -0.075, -0.343,  0.267,  0.131,  0.077, -0.045, -0.088, -0.345,
         0.526,  0.158,  0.128,  0.158, -0.005, -0.039,  0.032,  0.128, -0.072,
        -0.235,  0.091, -0.232,  0.607,  0.233, -0.024,  0.098,  0.210, -0.187,
        -0.427, -0.051,  0.039,  0.066, -0.053,  0.083,  0.214,  0.212, -0.466,
         0.237, -0.063,  0.043,  0.071, -0.236,  0.187,  0.045,  0.247,  0.314,
         0.395, -0.062,  0.128,  0.396,  0.185,  0.401,  0.223,  0.100, -0.370,
         0.227,  0.107, -0.069,  0.238,  0.295, -0.066,  0.362, -0.041,  0.074,
         0.292,  0.042,  0.334,  0.250,  0.102,  0.168, -0.270,  0.125, -0.247,
        -0.205, -0.031,  0.265,  0.151, -0.317, -0.215,  0.104, -0.190,  0.118,
        -0.050,  0.300], device='cuda:0')
s after update for 1 param tensor([1.286, 1.734, 0.956, 1.807, 1.600, 1.534, 1.882, 1.877, 2.037, 1.849,
        1.406, 1.225, 1.819, 1.623, 1.390, 1.896, 1.748, 1.507, 1.654, 1.545,
        1.695, 2.002, 1.851, 1.646, 2.076, 1.748, 1.670, 2.048, 1.694, 1.852,
        1.238, 1.780, 2.107, 2.194, 1.551, 1.276, 1.952, 1.585, 1.533, 1.526,
        1.892, 1.387, 1.899, 1.842, 1.733, 1.650, 2.029, 1.454, 2.023, 1.898,
        1.851, 1.722, 1.749, 1.537, 1.940, 1.253, 1.580, 1.761, 2.033, 2.054,
        2.239, 1.347, 1.450, 1.935, 1.270, 1.427, 1.448, 1.773, 2.294, 1.809,
        1.833, 1.607, 1.554, 2.102, 1.640, 1.925, 2.173, 1.646, 2.202, 2.259,
        1.776, 1.833, 1.956, 1.525, 1.646, 1.247, 1.414, 2.163, 1.980, 2.025,
        2.150, 1.531, 2.248, 1.477, 1.717, 1.921, 1.715, 1.779, 2.122, 1.118,
        1.766, 1.892, 1.377, 1.923, 1.596, 1.899, 1.971, 1.815, 1.729, 2.091,
        1.833, 1.633, 1.867, 1.517, 2.051, 1.119, 1.603, 1.697, 2.271, 2.306,
        1.556, 1.174, 1.958, 2.467, 1.623, 1.447, 1.837, 2.061, 2.049, 2.084,
        1.979, 1.746, 1.974, 1.758, 1.455, 2.223, 1.922, 1.782, 1.088, 2.094,
        1.795, 1.873, 1.778, 1.474, 1.778, 1.277, 1.534, 2.169, 1.029, 1.595,
        1.568, 1.701, 1.244, 1.627, 1.600, 1.814, 1.663, 1.789, 2.051, 1.445,
        1.618, 1.813, 1.841, 1.558, 1.853, 1.908, 1.743, 1.805, 2.267, 2.020,
        1.664, 1.723, 1.090, 1.795, 1.462, 1.796, 1.781, 1.499, 1.850, 1.500,
        1.994, 2.004, 1.710, 1.645, 1.888, 1.531, 1.681, 1.671, 1.343, 1.281,
        1.580, 1.706, 1.245, 2.151, 1.937, 2.055, 1.905, 1.700, 0.978, 2.122],
       device='cuda:0')
b after update for 1 param tensor([ 99.323, 115.328,  85.627, 117.761, 110.804, 108.486, 120.171, 119.989,
        125.024, 119.090, 103.874,  96.965, 118.120, 111.586, 103.268, 120.625,
        115.814, 107.528, 112.648, 108.869, 114.054, 123.920, 119.172, 112.394,
        126.193, 115.822, 113.201, 125.361, 114.005, 119.199,  97.452, 116.852,
        127.157, 129.751, 109.083,  98.944, 122.372, 110.281, 108.448, 108.192,
        120.490, 103.139, 120.721, 118.873, 115.294, 112.504, 124.780, 105.605,
        124.575, 120.673, 119.176, 114.932, 115.829, 108.597, 121.987,  98.066,
        110.110, 116.245, 124.878, 125.548, 131.054, 101.672, 105.467, 121.858,
         98.692, 104.623, 105.417, 116.619, 132.663, 117.797, 118.574, 111.031,
        109.208, 126.993, 112.188, 121.538, 129.120, 112.369, 129.967, 131.658,
        116.728, 118.592, 122.507, 108.180, 112.381,  97.832, 104.141, 128.833,
        123.264, 124.661, 128.444, 108.367, 131.328, 106.460, 114.785, 121.400,
        114.697, 116.826, 127.582,  92.609, 116.409, 120.469, 102.779, 121.469,
        110.666, 120.695, 122.970, 117.999, 115.175, 126.652, 118.581, 111.926,
        119.681, 107.896, 125.440,  92.640, 110.898, 114.116, 132.010, 133.024,
        109.266,  94.894, 122.561, 137.566, 111.576, 105.374, 118.733, 125.759,
        125.368, 126.452, 123.228, 115.747, 123.053, 116.133, 105.641, 130.582,
        121.423, 116.913,  91.371, 126.751, 117.357, 119.885, 116.780, 106.327,
        116.810,  98.998, 108.475, 128.999,  88.847, 110.632, 109.680, 114.251,
         97.698, 111.742, 110.808, 117.959, 112.959, 117.148, 125.444, 105.286,
        111.415, 117.945, 118.841, 109.349, 119.247, 121.001, 115.633, 117.670,
        131.870, 124.492, 112.980, 114.982,  91.434, 117.358, 105.922, 117.378,
        116.897, 107.231, 119.149, 107.263, 123.676, 124.006, 114.540, 112.339,
        120.370, 108.389, 113.581, 113.215, 101.518,  99.144, 110.094, 114.423,
         97.732, 128.475, 121.920, 125.556, 120.903, 114.207,  86.613, 127.606],
       device='cuda:0')
clipping threshold 0.9904761217824113
a after update for 1 param tensor([[[-0.104],
         [-0.274],
         [-0.057],
         [ 0.695],
         [-0.126],
         [-0.154],
         [ 0.242],
         [-0.314],
         [-0.070],
         [-0.310]],

        [[-0.002],
         [-0.188],
         [-0.328],
         [-0.470],
         [ 0.269],
         [ 0.212],
         [-0.115],
         [ 0.059],
         [ 0.123],
         [ 0.249]],

        [[ 0.062],
         [-0.013],
         [ 0.023],
         [-0.341],
         [-0.077],
         [ 0.170],
         [ 0.243],
         [ 0.019],
         [ 0.046],
         [-0.154]],

        [[ 0.133],
         [-0.196],
         [-0.049],
         [ 0.039],
         [-0.042],
         [ 0.017],
         [ 0.150],
         [-0.146],
         [-0.221],
         [-0.152]],

        [[-0.220],
         [ 0.548],
         [-0.201],
         [ 0.224],
         [-0.086],
         [ 0.117],
         [ 0.049],
         [-0.093],
         [-0.002],
         [-0.067]],

        [[ 0.033],
         [ 0.111],
         [-0.206],
         [ 0.017],
         [-0.522],
         [ 0.106],
         [-0.189],
         [-0.099],
         [ 0.167],
         [-0.024]],

        [[-0.330],
         [-0.176],
         [ 0.061],
         [-0.080],
         [-0.172],
         [ 0.092],
         [ 0.229],
         [-0.248],
         [ 0.412],
         [-0.236]],

        [[ 0.268],
         [-0.196],
         [ 0.212],
         [ 0.013],
         [ 0.275],
         [ 0.059],
         [ 0.007],
         [ 0.096],
         [-0.304],
         [-0.362]],

        [[-0.234],
         [ 0.394],
         [-0.144],
         [-0.162],
         [ 0.259],
         [-0.039],
         [ 0.629],
         [-0.149],
         [-0.018],
         [-0.079]],

        [[ 0.050],
         [-0.039],
         [ 0.221],
         [ 0.295],
         [-0.021],
         [ 0.024],
         [ 0.161],
         [ 0.114],
         [-0.129],
         [ 0.129]],

        [[-0.248],
         [ 0.166],
         [-0.033],
         [-0.425],
         [-0.150],
         [ 0.293],
         [ 0.165],
         [ 0.441],
         [ 0.509],
         [-0.088]],

        [[ 0.003],
         [ 0.017],
         [ 0.003],
         [ 0.099],
         [ 0.064],
         [ 0.191],
         [-0.732],
         [ 0.351],
         [-0.278],
         [ 0.052]],

        [[-0.203],
         [ 0.160],
         [-0.133],
         [ 0.199],
         [ 0.229],
         [-0.491],
         [-0.024],
         [-0.097],
         [ 0.515],
         [-0.156]],

        [[-0.248],
         [ 0.059],
         [-0.005],
         [-0.564],
         [ 0.049],
         [ 0.413],
         [-0.139],
         [-0.179],
         [ 0.223],
         [-0.209]],

        [[ 0.082],
         [-0.156],
         [ 0.206],
         [ 0.065],
         [ 0.270],
         [-0.063],
         [-0.341],
         [-0.020],
         [ 0.090],
         [ 0.511]],

        [[ 0.036],
         [ 0.122],
         [ 0.037],
         [ 0.139],
         [-0.283],
         [-0.596],
         [ 0.269],
         [-0.008],
         [-0.133],
         [ 0.362]],

        [[-0.207],
         [ 0.041],
         [-0.171],
         [ 0.018],
         [-0.288],
         [-0.081],
         [-0.175],
         [ 0.148],
         [-0.010],
         [-0.130]],

        [[-0.040],
         [ 0.371],
         [-0.205],
         [-0.081],
         [ 0.524],
         [ 0.246],
         [ 0.192],
         [ 0.455],
         [-0.159],
         [ 0.420]],

        [[ 0.279],
         [-0.173],
         [-0.105],
         [-0.194],
         [-0.197],
         [ 0.493],
         [ 0.168],
         [-0.093],
         [-0.035],
         [-0.163]],

        [[-0.266],
         [ 0.129],
         [-0.014],
         [ 0.008],
         [ 0.635],
         [ 0.133],
         [ 0.011],
         [ 0.065],
         [ 0.125],
         [ 0.118]]], device='cuda:0')
s after update for 1 param tensor([[[1.866],
         [1.418],
         [1.842],
         [1.506],
         [1.815],
         [2.094],
         [2.073],
         [2.385],
         [2.069],
         [1.825]],

        [[1.554],
         [2.080],
         [1.767],
         [2.310],
         [1.394],
         [1.782],
         [1.805],
         [1.339],
         [1.757],
         [2.468]],

        [[2.107],
         [1.700],
         [1.856],
         [2.007],
         [1.245],
         [1.480],
         [1.789],
         [1.801],
         [1.784],
         [1.601]],

        [[1.651],
         [1.343],
         [1.838],
         [1.630],
         [1.575],
         [2.215],
         [1.320],
         [1.559],
         [1.853],
         [1.556]],

        [[2.206],
         [1.825],
         [1.553],
         [1.809],
         [1.872],
         [2.038],
         [1.880],
         [1.602],
         [2.129],
         [1.570]],

        [[1.960],
         [1.374],
         [2.018],
         [1.922],
         [2.223],
         [1.442],
         [1.596],
         [1.880],
         [1.586],
         [1.646]],

        [[1.104],
         [1.780],
         [0.944],
         [1.545],
         [1.703],
         [1.742],
         [1.851],
         [1.483],
         [1.510],
         [1.177]],

        [[2.341],
         [1.659],
         [1.502],
         [1.582],
         [2.100],
         [1.861],
         [1.280],
         [1.971],
         [1.802],
         [2.033]],

        [[1.031],
         [1.959],
         [1.888],
         [1.491],
         [2.263],
         [1.811],
         [1.958],
         [2.244],
         [1.170],
         [1.972]],

        [[1.285],
         [1.341],
         [1.700],
         [1.744],
         [1.903],
         [1.682],
         [2.121],
         [1.272],
         [1.710],
         [1.765]],

        [[1.936],
         [1.363],
         [2.228],
         [1.969],
         [1.677],
         [2.035],
         [1.295],
         [1.921],
         [2.023],
         [2.085]],

        [[1.457],
         [1.709],
         [1.786],
         [1.752],
         [2.091],
         [1.780],
         [1.704],
         [1.476],
         [1.759],
         [1.498]],

        [[2.009],
         [2.032],
         [1.655],
         [1.695],
         [2.077],
         [1.416],
         [1.168],
         [1.935],
         [1.933],
         [1.948]],

        [[1.623],
         [1.961],
         [1.835],
         [2.064],
         [1.743],
         [1.326],
         [1.900],
         [1.882],
         [1.808],
         [1.595]],

        [[1.610],
         [1.535],
         [1.775],
         [1.606],
         [2.108],
         [1.421],
         [1.272],
         [2.091],
         [2.213],
         [1.874]],

        [[1.562],
         [1.799],
         [1.767],
         [1.934],
         [2.175],
         [1.612],
         [1.843],
         [1.775],
         [1.631],
         [1.339]],

        [[1.487],
         [1.855],
         [1.834],
         [1.756],
         [2.141],
         [1.564],
         [1.249],
         [1.632],
         [2.211],
         [1.369]],

        [[2.015],
         [1.743],
         [1.623],
         [2.191],
         [1.916],
         [1.864],
         [1.240],
         [1.809],
         [1.747],
         [1.784]],

        [[1.893],
         [2.111],
         [2.144],
         [1.560],
         [1.615],
         [1.827],
         [1.640],
         [1.647],
         [1.767],
         [1.905]],

        [[1.753],
         [1.797],
         [2.194],
         [2.204],
         [1.951],
         [1.480],
         [1.992],
         [1.515],
         [1.601],
         [1.760]]], device='cuda:0')
b after update for 1 param tensor([[[119.641],
         [104.291],
         [118.882],
         [107.494],
         [118.014],
         [126.760],
         [126.108],
         [135.271],
         [125.982],
         [118.342]],

        [[109.180],
         [126.314],
         [116.424],
         [133.128],
         [103.418],
         [116.918],
         [117.682],
         [101.341],
         [116.097],
         [137.611]],

        [[127.150],
         [114.192],
         [119.343],
         [124.094],
         [ 97.753],
         [106.554],
         [117.142],
         [117.555],
         [117.003],
         [110.828]],

        [[112.552],
         [101.495],
         [118.763],
         [111.817],
         [109.915],
         [130.348],
         [100.640],
         [109.351],
         [119.235],
         [109.259]],

        [[130.100],
         [118.327],
         [109.172],
         [117.820],
         [119.833],
         [125.034],
         [120.087],
         [110.862],
         [127.798],
         [109.752]],

        [[122.636],
         [102.668],
         [124.433],
         [121.424],
         [130.602],
         [105.176],
         [110.674],
         [120.110],
         [110.322],
         [112.371]],

        [[ 92.021],
         [116.858],
         [ 85.105],
         [108.881],
         [114.317],
         [115.615],
         [119.165],
         [106.653],
         [107.648],
         [ 95.028]],

        [[134.023],
         [112.825],
         [107.355],
         [110.158],
         [126.924],
         [119.503],
         [ 99.089],
         [122.962],
         [117.582],
         [124.897]],

        [[ 88.939],
         [122.598],
         [120.359],
         [106.946],
         [131.775],
         [117.890],
         [122.561],
         [131.220],
         [ 94.733],
         [123.014]],

        [[ 99.286],
         [101.438],
         [114.216],
         [115.685],
         [120.830],
         [113.604],
         [127.569],
         [ 98.795],
         [114.557],
         [116.379]],

        [[121.868],
         [102.258],
         [130.730],
         [122.913],
         [113.439],
         [124.942],
         [ 99.678],
         [121.392],
         [124.583],
         [126.470]],

        [[105.728],
         [114.499],
         [117.068],
         [115.929],
         [126.675],
         [116.873],
         [114.339],
         [106.406],
         [116.170],
         [107.221]],

        [[124.161],
         [124.872],
         [112.680],
         [114.042],
         [126.248],
         [104.220],
         [ 94.659],
         [121.837],
         [121.786],
         [122.249]],

        [[111.601],
         [122.674],
         [118.652],
         [125.837],
         [115.634],
         [100.871],
         [120.739],
         [120.169],
         [117.779],
         [110.617]],

        [[111.134],
         [108.538],
         [116.706],
         [111.013],
         [127.185],
         [104.424],
         [ 98.795],
         [126.675],
         [130.291],
         [119.892]],

        [[109.468],
         [117.493],
         [116.428],
         [121.827],
         [129.192],
         [111.208],
         [118.902],
         [116.698],
         [111.856],
         [101.361]],

        [[106.815],
         [119.301],
         [118.630],
         [116.073],
         [128.154],
         [109.545],
         [ 97.894],
         [111.896],
         [130.243],
         [102.498]],

        [[124.351],
         [115.658],
         [111.589],
         [129.652],
         [121.234],
         [119.593],
         [ 97.524],
         [117.799],
         [115.765],
         [116.986]],

        [[120.524],
         [127.265],
         [128.254],
         [109.414],
         [111.314],
         [118.385],
         [112.170],
         [112.400],
         [116.420],
         [120.900]],

        [[115.984],
         [117.429],
         [129.746],
         [130.046],
         [122.335],
         [106.563],
         [123.615],
         [107.798],
         [110.825],
         [116.197]]], device='cuda:0')
clipping threshold 0.9904761217824113
a after update for 1 param tensor([[-0.011],
        [-0.102],
        [ 0.063],
        [-0.166],
        [ 0.176],
        [-0.257],
        [ 0.127],
        [-0.015],
        [-0.228],
        [-0.134],
        [ 0.071],
        [ 0.580],
        [ 0.227],
        [-0.023],
        [-0.365],
        [-0.189],
        [-0.156],
        [-0.063],
        [-0.454],
        [ 0.065]], device='cuda:0')
s after update for 1 param tensor([[2.236],
        [1.622],
        [1.090],
        [1.545],
        [1.960],
        [2.015],
        [1.602],
        [1.894],
        [1.747],
        [1.851],
        [2.035],
        [2.207],
        [1.756],
        [1.830],
        [2.028],
        [2.024],
        [2.052],
        [1.412],
        [1.607],
        [1.582]], device='cuda:0')
b after update for 1 param tensor([[130.970],
        [111.561],
        [ 91.461],
        [108.877],
        [122.638],
        [124.333],
        [110.865],
        [120.560],
        [115.761],
        [119.175],
        [124.952],
        [130.127],
        [116.083],
        [118.495],
        [124.752],
        [124.604],
        [125.470],
        [104.073],
        [111.054],
        [110.182]], device='cuda:0')
clipping threshold 0.9904761217824113
||w||^2 1.1117504309986357
exp ma of ||w||^2 2.0118117578364805
||w|| 1.0543957658292429
exp ma of ||w|| 1.3416980590760097
||w||^2 2.9160864057552165
exp ma of ||w||^2 1.9040997810857514
||w|| 1.7076552362099373
exp ma of ||w|| 1.3232182731761641
v before min max tensor([[-168.860,   30.507,  106.877,  ..., 1150.393,  329.393, -233.643],
        [-121.438,  546.427, -333.081,  ..., -251.869, -219.893, -299.055],
        [-187.031, -362.392, 1090.724,  ..., -250.617, -128.857, -116.605],
        ...,
        [-261.240, -275.341, -236.107,  ..., -356.246, -162.600, -370.406],
        [  85.496,  353.296, -194.018,  ...,   50.824, -135.498,  -11.793],
        [ 473.018, -278.976, -177.426,  ..., -162.282, -321.366,  -43.025]],
       device='cuda:0')
v tensor([[1.000e-12, 1.000e+01, 1.000e+01,  ..., 1.000e+01, 1.000e+01,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e-12,  ..., 1.000e+01, 1.000e-12,
         1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([ 1.559e+02, -2.655e+02, -3.413e+02, -2.366e+02, -2.597e+02,  1.938e+02,
        -2.698e+02, -2.595e+02,  2.078e+02, -3.583e+02, -1.790e+02, -3.779e+02,
        -1.013e+01, -7.476e+01, -2.686e+02, -3.558e+02, -1.787e+02, -2.215e+02,
        -2.787e+02,  2.536e+02,  9.790e+02, -1.421e+02, -2.802e+02, -7.134e+01,
        -1.131e+02, -2.293e+02,  8.980e+01, -2.870e+02,  5.529e+03, -2.481e+02,
        -2.668e+02, -9.260e+01,  8.856e+02, -3.117e+02, -1.950e+02, -3.409e+02,
        -2.245e+02, -2.331e+02, -1.820e+02, -2.822e+02, -3.889e+02, -2.929e+02,
        -3.088e+02, -2.487e+02, -1.506e+02, -3.455e+02, -3.055e+02, -2.770e+02,
         2.398e+01,  1.804e+01, -5.133e+01, -3.348e+02,  1.522e+03, -1.659e+02,
        -2.567e+02, -1.284e+02, -1.973e+01, -2.901e+02, -2.435e+02, -1.179e+02,
        -1.456e+02,  1.999e+01, -2.513e+02,  4.984e+02, -1.557e+02, -3.037e+02,
        -2.781e+02,  3.569e+02, -4.411e+00, -3.145e+02, -2.819e+02, -1.857e+02,
        -3.073e+02,  3.313e+02, -2.200e+02, -2.056e+02,  5.756e+02, -2.426e+02,
         2.174e+02,  7.459e+01,  4.017e+01, -3.011e+02, -2.305e+01, -1.756e+02,
        -2.544e+02, -2.518e+02,  2.578e+02, -3.156e+02, -3.541e+02, -2.820e+02,
        -2.815e+02, -1.125e+02, -2.972e+02,  2.053e+02,  4.520e+02, -2.293e+02,
        -7.299e+01,  5.597e+02, -1.185e+02, -7.722e+01, -3.331e+02, -2.674e+02,
        -2.433e+02,  6.091e+02, -2.177e+02, -3.388e+01, -2.915e+02, -3.986e+01,
        -2.960e+02, -1.999e+02, -5.337e+01, -1.401e+02, -2.796e+02,  6.491e+02,
        -3.096e+02,  2.951e+02, -1.045e+02,  1.121e+02, -3.576e+02, -2.803e+02,
        -2.424e+02,  8.855e+01,  5.556e+02, -2.196e+02,  9.879e+02,  1.983e+02,
        -2.229e+02, -1.459e+02, -3.205e+02,  1.383e+02, -1.573e+02,  6.936e+01,
         3.377e+02, -2.036e+02, -1.650e+01, -2.296e+02, -3.067e+02,  1.214e+01,
         7.460e+01, -2.753e+02, -2.524e+02, -2.850e+02,  1.897e+02, -3.576e+02,
        -3.177e+02,  1.217e+02, -3.477e+02, -6.678e+01, -2.005e+02, -2.751e+02,
        -1.394e+02, -2.225e+02, -6.509e+01,  1.238e+03, -1.958e+02,  4.363e+02,
        -2.098e+02, -2.381e+02, -3.181e+02, -1.160e+02, -2.678e+02, -2.688e+02,
         2.692e+02, -1.920e+02,  5.713e+00, -2.599e+02, -2.273e+02,  5.762e+01,
        -1.166e+02, -2.527e+02, -3.323e+02, -2.023e+02,  7.313e+01, -1.629e+02,
        -1.685e+02,  1.712e+02, -2.812e+02, -2.296e+02, -9.452e+01,  7.592e+01,
         9.356e+01, -1.836e+02, -3.246e+02, -4.804e+01, -3.612e+02,  3.928e+02,
        -1.864e+02,  1.607e+03, -3.173e+02, -2.841e+02, -2.900e+02, -2.208e+02,
         2.067e+02, -2.557e+02, -3.151e+02, -2.698e+02, -3.470e+02, -3.233e+02,
        -3.253e+02, -4.964e+01], device='cuda:0')
v tensor([1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 5.713e+00, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12], device='cuda:0')
v before min max tensor([[[-373.525],
         [-210.658],
         [ 192.305],
         [-252.840],
         [-217.165],
         [-329.200],
         [-320.179],
         [-191.863],
         [ -46.862],
         [  48.268]],

        [[   8.944],
         [ 807.769],
         [-204.947],
         [-205.151],
         [ 541.170],
         [ 952.921],
         [-329.156],
         [-187.687],
         [-245.699],
         [ 511.950]],

        [[ 167.226],
         [-271.014],
         [-329.200],
         [  30.240],
         [  58.420],
         [-334.460],
         [ -29.215],
         [ 336.008],
         [-264.713],
         [ 145.972]],

        [[-241.733],
         [ -74.240],
         [ 138.429],
         [ 195.119],
         [-376.204],
         [-162.216],
         [-306.876],
         [-196.073],
         [ 754.711],
         [-279.458]],

        [[-375.619],
         [-289.817],
         [-245.390],
         [ -55.472],
         [-158.793],
         [ -29.072],
         [-275.892],
         [-246.664],
         [ -78.848],
         [-207.653]],

        [[-226.631],
         [ 287.176],
         [-205.390],
         [ 181.031],
         [-372.426],
         [-233.363],
         [-148.434],
         [ 683.503],
         [ 810.787],
         [-178.419]],

        [[ 270.407],
         [-267.453],
         [ -82.102],
         [ 422.941],
         [-245.125],
         [-270.389],
         [-256.717],
         [ 417.037],
         [   4.632],
         [-183.426]],

        [[ 223.513],
         [ 303.150],
         [ 609.842],
         [-322.285],
         [-303.665],
         [ 381.281],
         [ 426.143],
         [ 252.075],
         [ 484.389],
         [-325.263]],

        [[-276.601],
         [ -85.315],
         [ 356.174],
         [-219.859],
         [ 876.503],
         [-125.614],
         [-173.214],
         [-230.722],
         [-247.136],
         [-262.586]],

        [[-293.223],
         [-262.992],
         [-165.326],
         [  20.795],
         [-115.300],
         [ -97.667],
         [-103.693],
         [-313.582],
         [  52.032],
         [-255.772]],

        [[-269.997],
         [ -95.793],
         [  63.383],
         [-154.409],
         [-246.555],
         [-181.035],
         [-213.871],
         [-322.584],
         [-196.765],
         [-279.641]],

        [[-298.315],
         [-209.589],
         [-152.082],
         [ 363.060],
         [-137.133],
         [ 298.185],
         [-391.883],
         [-321.737],
         [ -33.765],
         [ -90.774]],

        [[  89.363],
         [-143.992],
         [  -4.102],
         [-354.359],
         [ 306.144],
         [-213.323],
         [ -26.152],
         [-167.125],
         [-209.190],
         [   4.092]],

        [[ 136.659],
         [ 624.273],
         [-323.127],
         [  47.381],
         [1286.564],
         [-343.775],
         [-246.733],
         [ 700.770],
         [-215.283],
         [ 626.099]],

        [[-159.740],
         [-239.395],
         [-281.766],
         [-193.687],
         [-223.331],
         [ -74.514],
         [-120.583],
         [   5.661],
         [  68.242],
         [-208.231]],

        [[-138.734],
         [  -3.652],
         [ -61.419],
         [-315.606],
         [ -91.893],
         [-227.127],
         [-187.685],
         [-288.965],
         [-262.290],
         [ 755.549]],

        [[-240.386],
         [-284.234],
         [-290.811],
         [-338.581],
         [   7.171],
         [-136.126],
         [-377.726],
         [-240.158],
         [ 698.697],
         [ -42.786]],

        [[  51.590],
         [-319.671],
         [-342.641],
         [-190.467],
         [-303.173],
         [ 505.097],
         [-295.272],
         [-281.863],
         [-170.590],
         [-345.796]],

        [[-299.055],
         [ 245.534],
         [-157.609],
         [-225.551],
         [ -36.274],
         [-174.113],
         [ 187.220],
         [-158.172],
         [  52.891],
         [ 132.725]],

        [[ -89.348],
         [-231.696],
         [-227.838],
         [-350.677],
         [ 595.940],
         [ 126.202],
         [-203.672],
         [-190.981],
         [-182.245],
         [-243.287]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[8.944e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [4.632e+00],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.092e+00]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.661e+00],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.171e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[-135.786],
        [ 410.019],
        [ 934.475],
        [-258.800],
        [-147.073],
        [-210.857],
        [-100.526],
        [-113.922],
        [-159.060],
        [-212.330],
        [-101.693],
        [-129.378],
        [ 562.368],
        [-110.203],
        [-115.379],
        [-386.338],
        [-242.573],
        [-370.629],
        [-209.482],
        [-339.460]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 0.026, -0.103, -0.462,  ..., -0.332,  0.165, -0.208],
        [-0.202, -0.420, -0.140,  ...,  0.313,  0.194,  0.089],
        [-0.060, -0.178,  0.073,  ..., -0.238,  0.165, -0.333],
        ...,
        [-0.132, -0.111, -0.048,  ...,  0.182,  0.143,  0.118],
        [ 0.059,  0.065,  0.200,  ..., -0.004, -0.004, -0.088],
        [ 0.009, -0.115, -0.170,  ...,  0.070, -0.116, -0.157]],
       device='cuda:0')
s after update for 1 param tensor([[1.637, 1.316, 1.481,  ..., 2.260, 1.646, 1.549],
        [1.600, 1.717, 2.153,  ..., 1.988, 1.747, 2.073],
        [1.902, 2.180, 2.017,  ..., 1.364, 1.017, 1.431],
        ...,
        [1.370, 1.598, 1.683,  ..., 1.882, 1.459, 2.026],
        [1.964, 1.691, 1.602,  ..., 1.680, 1.269, 1.636],
        [2.288, 1.740, 1.616,  ..., 0.866, 1.675, 1.242]], device='cuda:0')
b after update for 1 param tensor([[109.714,  98.384, 104.357,  ..., 128.938, 110.022, 106.742],
        [108.487, 112.384, 125.845,  ..., 120.915, 113.338, 123.480],
        [118.269, 126.609, 121.788,  ..., 100.142,  86.492, 102.592],
        ...,
        [100.386, 108.412, 111.270,  ..., 117.661, 103.601, 122.079],
        [120.191, 111.513, 108.549,  ..., 111.173,  96.610, 109.686],
        [129.726, 113.129, 109.024,  ...,  79.829, 111.004,  95.577]],
       device='cuda:0')
clipping threshold 1.088945188926506
a after update for 1 param tensor([-0.074,  0.008,  0.029, -0.081,  0.104, -0.214,  0.248,  0.139,  0.150,
         0.064, -0.151,  0.165,  0.363, -0.238,  0.239,  0.115,  0.192,  0.204,
        -0.061, -0.108,  0.087,  0.178, -0.234,  0.178,  0.156,  0.458, -0.174,
         0.013,  0.199,  0.133, -0.086, -0.214, -0.047, -0.110,  0.009, -0.323,
        -0.100, -0.066, -0.107, -0.087,  0.135,  0.097, -0.255, -0.060,  0.166,
        -0.271,  0.074,  0.227, -0.223,  0.054,  0.102,  0.202,  0.047, -0.243,
        -0.163,  0.160,  0.339, -0.050, -0.050, -0.270, -0.166,  0.114, -0.316,
        -0.347,  0.331, -0.145,  0.348,  0.087, -0.124,  0.046,  0.147, -0.458,
        -0.108, -0.120,  0.098, -0.043,  0.042,  0.300, -0.131,  0.236,  0.254,
        -0.205,  0.008,  0.340, -0.353, -0.058,  0.060, -0.078,  0.127, -0.147,
        -0.206,  0.092, -0.360,  0.036, -0.033,  0.120, -0.294, -0.218, -0.032,
        -0.311, -0.239,  0.250, -0.128,  0.118, -0.051, -0.024, -0.159,  0.039,
        -0.083,  0.412, -0.337,  0.036, -0.339, -0.183,  0.125, -0.014,  0.414,
        -0.061,  0.078, -0.299,  0.095,  0.028,  0.053,  0.010,  0.021, -0.161,
         0.642,  0.056,  0.024, -0.043, -0.035,  0.072, -0.094,  0.120,  0.015,
        -0.156, -0.050, -0.297,  0.533,  0.182,  0.124, -0.038,  0.217,  0.044,
        -0.113, -0.012, -0.123,  0.062, -0.007,  0.117,  0.110,  0.181, -0.507,
         0.026, -0.172,  0.062,  0.037, -0.268,  0.190,  0.185,  0.249,  0.221,
         0.442, -0.098,  0.033,  0.199,  0.108,  0.202,  0.223,  0.134, -0.390,
         0.284,  0.087, -0.041,  0.232,  0.248, -0.128,  0.374, -0.248,  0.004,
         0.401,  0.239,  0.138,  0.236,  0.104,  0.125, -0.063,  0.005, -0.116,
        -0.262, -0.119,  0.445,  0.308, -0.302, -0.298,  0.014, -0.021,  0.058,
        -0.072,  0.248], device='cuda:0')
s after update for 1 param tensor([1.739, 1.645, 1.782, 1.452, 1.353, 1.634, 1.822, 2.173, 1.680, 1.875,
        1.079, 1.975, 2.090, 1.346, 1.458, 2.082, 1.893, 1.724, 1.961, 1.779,
        1.953, 1.519, 1.536, 2.102, 1.230, 1.771, 1.809, 1.525, 2.081, 1.726,
        1.432, 1.286, 1.906, 1.855, 1.939, 1.841, 1.245, 1.301, 1.726, 1.559,
        2.048, 1.794, 1.652, 1.681, 1.149, 1.819, 1.771, 1.542, 1.503, 1.826,
        1.364, 1.807, 2.069, 1.471, 1.339, 1.428, 1.698, 1.511, 1.269, 1.086,
        1.562, 1.751, 1.310, 1.949, 1.521, 1.749, 1.525, 2.330, 1.160, 2.053,
        1.616, 1.838, 1.616, 1.889, 1.585, 1.094, 1.525, 1.929, 2.336, 2.140,
        1.835, 1.835, 1.749, 1.356, 1.751, 1.617, 2.173, 1.648, 1.919, 1.619,
        1.499, 0.890, 1.739, 1.896, 1.895, 1.396, 1.870, 1.789, 1.567, 1.294,
        2.045, 1.574, 1.696, 1.805, 1.753, 1.370, 1.729, 1.607, 1.546, 2.028,
        1.094, 1.506, 2.006, 2.076, 1.786, 1.702, 1.654, 2.232, 1.923, 1.572,
        1.366, 1.511, 1.708, 1.287, 2.064, 2.011, 1.312, 2.020, 1.680, 1.936,
        1.268, 2.052, 1.564, 1.892, 1.562, 1.548, 1.598, 2.236, 2.014, 1.733,
        1.810, 1.519, 1.528, 2.447, 1.964, 2.117, 1.943, 1.689, 1.171, 1.687,
        1.332, 1.271, 1.715, 2.179, 1.669, 1.687, 1.112, 1.338, 2.081, 1.752,
        1.503, 1.477, 2.110, 1.230, 1.343, 1.643, 1.307, 1.925, 1.835, 1.473,
        1.904, 1.307, 1.458, 1.097, 1.238, 1.996, 1.784, 1.555, 1.475, 1.710,
        2.118, 2.117, 1.708, 1.911, 1.911, 2.089, 1.163, 1.837, 1.657, 1.506,
        1.679, 1.712, 1.515, 1.445, 1.658, 1.405, 1.809, 1.685, 1.756, 1.138],
       device='cuda:0')
b after update for 1 param tensor([113.102, 109.984, 114.475, 103.353,  99.756, 109.614, 115.768, 126.408,
        111.147, 117.441,  89.073, 120.530, 123.973,  99.494, 103.539, 123.742,
        117.988, 112.598, 120.108, 114.402, 119.864, 105.708, 106.292, 124.341,
         95.124, 114.113, 115.349, 105.915, 123.713, 112.653, 102.611,  97.259,
        118.405, 116.805, 119.422, 116.354,  95.680,  97.820, 112.675, 107.085,
        122.721, 114.874, 110.228, 111.192,  91.930, 115.662, 114.114, 106.492,
        105.144, 115.882, 100.176, 115.269, 123.343, 104.006,  99.242, 102.466,
        111.744, 105.429,  96.605,  89.384, 107.187, 113.470,  98.144, 119.712,
        105.770, 113.425, 105.911, 130.894,  92.374, 122.892, 109.034, 116.273,
        109.027, 117.861, 107.959,  89.694, 105.907, 119.104, 131.065, 125.444,
        116.182, 116.187, 113.412,  99.870, 113.484, 109.043, 126.433, 110.081,
        118.796, 109.118, 104.984,  80.885, 113.083, 118.095, 118.051, 101.345,
        117.288, 114.720, 107.339,  97.563, 122.628, 107.583, 111.689, 115.224,
        113.531, 100.382, 112.753, 108.719, 106.644, 122.117,  89.716, 105.253,
        121.452, 123.572, 114.602, 111.887, 110.284, 128.121, 118.912, 107.539,
        100.247, 105.424, 112.071,  97.278, 123.213, 121.620,  98.231, 121.901,
        111.163, 119.330,  96.570, 122.837, 107.237, 117.964, 107.186, 106.700,
        108.406, 128.252, 121.705, 112.910, 115.382, 105.709, 106.026, 134.161,
        120.202, 124.782, 119.538, 111.459,  92.810, 111.394,  98.959,  96.691,
        112.316, 126.585, 110.780, 111.405,  90.446,  99.205, 123.718, 113.509,
        105.135, 104.221, 124.568,  95.095,  99.372, 109.915,  98.061, 118.995,
        116.163, 104.098, 118.335,  98.046, 103.546,  89.828,  95.411, 121.149,
        114.543, 106.951, 104.158, 112.130, 124.798, 124.784, 112.096, 118.564,
        118.554, 123.944,  92.468, 116.225, 110.401, 105.232, 111.111, 112.195,
        105.552, 103.084, 110.423, 101.668, 115.347, 111.323, 113.630,  91.485],
       device='cuda:0')
clipping threshold 1.088945188926506
a after update for 1 param tensor([[[-0.205],
         [-0.226],
         [-0.041],
         [ 0.638],
         [-0.262],
         [-0.195],
         [ 0.170],
         [-0.359],
         [ 0.020],
         [-0.151]],

        [[-0.056],
         [-0.152],
         [-0.307],
         [-0.464],
         [ 0.192],
         [ 0.019],
         [-0.058],
         [ 0.021],
         [ 0.059],
         [ 0.182]],

        [[ 0.090],
         [-0.013],
         [ 0.035],
         [-0.379],
         [-0.137],
         [ 0.260],
         [ 0.226],
         [ 0.110],
         [ 0.132],
         [-0.064]],

        [[ 0.236],
         [ 0.018],
         [-0.055],
         [-0.045],
         [-0.076],
         [ 0.108],
         [-0.184],
         [-0.196],
         [-0.186],
         [-0.131]],

        [[-0.133],
         [ 0.488],
         [-0.340],
         [-0.021],
         [-0.075],
         [ 0.274],
         [ 0.025],
         [-0.200],
         [-0.045],
         [-0.045]],

        [[-0.026],
         [ 0.126],
         [-0.171],
         [ 0.091],
         [-0.460],
         [ 0.324],
         [-0.205],
         [ 0.046],
         [ 0.066],
         [-0.210]],

        [[-0.274],
         [-0.015],
         [ 0.231],
         [ 0.042],
         [-0.171],
         [ 0.136],
         [ 0.322],
         [-0.093],
         [ 0.232],
         [-0.176]],

        [[ 0.288],
         [-0.234],
         [ 0.202],
         [ 0.133],
         [ 0.175],
         [ 0.020],
         [ 0.167],
         [ 0.100],
         [-0.119],
         [-0.318]],

        [[-0.079],
         [ 0.367],
         [-0.092],
         [-0.157],
         [ 0.173],
         [ 0.110],
         [ 0.626],
         [-0.029],
         [ 0.098],
         [-0.230]],

        [[ 0.047],
         [-0.057],
         [ 0.148],
         [ 0.263],
         [ 0.057],
         [ 0.100],
         [ 0.089],
         [ 0.207],
         [-0.151],
         [ 0.095]],

        [[-0.150],
         [ 0.222],
         [-0.005],
         [-0.477],
         [-0.122],
         [ 0.228],
         [ 0.278],
         [ 0.285],
         [ 0.289],
         [ 0.131]],

        [[-0.161],
         [ 0.152],
         [-0.001],
         [ 0.058],
         [ 0.063],
         [ 0.298],
         [-0.581],
         [ 0.428],
         [-0.167],
         [ 0.059]],

        [[-0.051],
         [ 0.088],
         [-0.006],
         [ 0.268],
         [ 0.186],
         [-0.490],
         [-0.084],
         [ 0.007],
         [ 0.604],
         [-0.136]],

        [[-0.274],
         [ 0.094],
         [ 0.096],
         [-0.365],
         [ 0.018],
         [ 0.165],
         [-0.005],
         [-0.208],
         [ 0.189],
         [-0.086]],

        [[ 0.110],
         [-0.109],
         [ 0.207],
         [ 0.081],
         [ 0.301],
         [-0.060],
         [-0.276],
         [-0.073],
         [ 0.012],
         [ 0.420]],

        [[ 0.005],
         [ 0.195],
         [ 0.018],
         [ 0.092],
         [-0.307],
         [-0.473],
         [ 0.174],
         [ 0.006],
         [-0.080],
         [ 0.317]],

        [[-0.210],
         [ 0.095],
         [-0.117],
         [-0.054],
         [-0.177],
         [ 0.071],
         [-0.242],
         [ 0.249],
         [-0.181],
         [-0.191]],

        [[ 0.063],
         [ 0.469],
         [-0.216],
         [ 0.263],
         [ 0.428],
         [ 0.006],
         [ 0.207],
         [ 0.417],
         [-0.105],
         [ 0.352]],

        [[ 0.226],
         [-0.027],
         [-0.014],
         [-0.187],
         [-0.129],
         [ 0.315],
         [ 0.158],
         [-0.174],
         [ 0.154],
         [-0.087]],

        [[-0.167],
         [ 0.048],
         [ 0.039],
         [ 0.159],
         [ 0.483],
         [ 0.158],
         [ 0.104],
         [ 0.140],
         [-0.012],
         [ 0.192]]], device='cuda:0')
s after update for 1 param tensor([[[1.946],
         [1.111],
         [1.958],
         [1.352],
         [1.487],
         [1.720],
         [1.718],
         [1.431],
         [1.319],
         [2.026]],

        [[1.839],
         [2.062],
         [1.068],
         [1.265],
         [1.454],
         [2.325],
         [1.977],
         [1.153],
         [1.765],
         [1.966]],

        [[1.733],
         [1.487],
         [2.117],
         [1.467],
         [1.720],
         [1.765],
         [1.611],
         [1.892],
         [1.664],
         [1.699]],

        [[1.567],
         [1.949],
         [1.727],
         [1.837],
         [1.961],
         [1.638],
         [2.390],
         [1.436],
         [2.174],
         [1.728]],

        [[2.022],
         [1.957],
         [1.677],
         [1.929],
         [1.523],
         [1.522],
         [1.624],
         [1.690],
         [1.474],
         [1.145]],

        [[1.477],
         [1.850],
         [1.873],
         [1.866],
         [1.944],
         [1.618],
         [1.425],
         [1.995],
         [2.082],
         [1.545]],

        [[2.146],
         [1.535],
         [1.062],
         [1.714],
         [1.369],
         [1.781],
         [1.751],
         [1.415],
         [1.883],
         [1.411]],

        [[1.759],
         [1.925],
         [1.804],
         [1.692],
         [1.582],
         [1.615],
         [2.011],
         [2.426],
         [1.741],
         [1.718]],

        [[1.526],
         [1.788],
         [1.918],
         [2.028],
         [1.739],
         [1.551],
         [1.568],
         [1.424],
         [1.852],
         [1.368]],

        [[1.528],
         [1.674],
         [1.261],
         [2.098],
         [1.575],
         [1.140],
         [0.713],
         [1.776],
         [1.463],
         [1.703]],

        [[1.941],
         [1.269],
         [2.004],
         [0.940],
         [1.856],
         [1.456],
         [1.692],
         [1.821],
         [1.626],
         [1.546]],

        [[1.694],
         [1.191],
         [1.401],
         [1.753],
         [0.942],
         [1.865],
         [2.071],
         [1.752],
         [1.227],
         [1.286]],

        [[1.892],
         [1.768],
         [1.096],
         [1.970],
         [2.062],
         [1.126],
         [1.172],
         [1.393],
         [1.108],
         [1.841]],

        [[1.387],
         [1.918],
         [1.898],
         [1.831],
         [1.906],
         [1.842],
         [1.545],
         [1.725],
         [1.856],
         [2.109]],

        [[0.876],
         [1.442],
         [1.503],
         [1.410],
         [1.240],
         [1.054],
         [1.611],
         [1.573],
         [2.032],
         [1.586]],

        [[1.191],
         [1.871],
         [1.648],
         [1.674],
         [1.625],
         [1.324],
         [1.879],
         [1.800],
         [1.569],
         [2.014]],

        [[1.295],
         [1.490],
         [1.738],
         [1.963],
         [1.971],
         [1.420],
         [2.027],
         [1.859],
         [2.058],
         [1.613]],

        [[1.746],
         [1.709],
         [1.830],
         [1.980],
         [1.870],
         [2.259],
         [1.595],
         [1.471],
         [1.011],
         [1.826]],

        [[1.630],
         [1.836],
         [1.854],
         [1.735],
         [1.666],
         [1.624],
         [1.971],
         [1.257],
         [1.608],
         [1.747]],

        [[1.476],
         [1.662],
         [1.431],
         [1.871],
         [1.761],
         [2.108],
         [1.805],
         [1.942],
         [1.032],
         [1.344]]], device='cuda:0')
b after update for 1 param tensor([[[119.637],
         [ 90.399],
         [119.992],
         [ 99.702],
         [104.588],
         [112.457],
         [112.405],
         [102.589],
         [ 98.496],
         [122.079]],

        [[116.298],
         [123.147],
         [ 88.629],
         [ 96.440],
         [103.403],
         [130.754],
         [120.594],
         [ 92.073],
         [113.930],
         [120.243]],

        [[112.898],
         [104.564],
         [124.773],
         [103.874],
         [112.481],
         [113.946],
         [108.841],
         [117.972],
         [110.635],
         [111.788]],

        [[107.362],
         [119.741],
         [112.710],
         [116.226],
         [120.101],
         [109.773],
         [132.575],
         [102.769],
         [126.443],
         [112.741]],

        [[121.946],
         [119.963],
         [111.054],
         [119.098],
         [105.838],
         [105.791],
         [109.297],
         [111.504],
         [104.122],
         [ 91.764]],

        [[104.210],
         [116.657],
         [117.380],
         [117.147],
         [119.566],
         [109.102],
         [102.380],
         [121.117],
         [123.755],
         [106.609]],

        [[125.642],
         [106.253],
         [ 88.363],
         [112.292],
         [100.345],
         [114.463],
         [113.481],
         [101.999],
         [117.674],
         [101.886]],

        [[113.726],
         [118.973],
         [115.200],
         [111.555],
         [107.870],
         [108.976],
         [121.607],
         [133.582],
         [113.152],
         [112.410]],

        [[105.944],
         [114.687],
         [118.764],
         [122.141],
         [113.082],
         [106.821],
         [107.380],
         [102.324],
         [116.709],
         [100.307]],

        [[105.995],
         [110.975],
         [ 96.322],
         [124.216],
         [107.613],
         [ 91.576],
         [ 72.408],
         [114.284],
         [103.728],
         [111.901]],

        [[119.467],
         [ 96.596],
         [121.395],
         [ 83.130],
         [116.845],
         [103.467],
         [111.559],
         [115.730],
         [109.347],
         [106.631]],

        [[111.624],
         [ 93.588],
         [101.504],
         [113.535],
         [ 83.254],
         [117.122],
         [123.429],
         [113.515],
         [ 94.977],
         [ 97.249]],

        [[117.977],
         [114.047],
         [ 89.789],
         [120.378],
         [123.160],
         [ 90.987],
         [ 92.854],
         [101.212],
         [ 90.274],
         [116.359]],

        [[100.987],
         [118.770],
         [118.149],
         [116.058],
         [118.410],
         [116.391],
         [106.586],
         [112.634],
         [116.824],
         [124.541]],

        [[ 80.262],
         [102.975],
         [105.150],
         [101.833],
         [ 95.517],
         [ 88.039],
         [108.847],
         [107.572],
         [122.254],
         [107.999]],

        [[ 93.585],
         [117.292],
         [110.084],
         [110.963],
         [109.328],
         [ 98.675],
         [117.565],
         [115.049],
         [107.421],
         [121.712]],

        [[ 97.607],
         [104.696],
         [113.046],
         [120.155],
         [120.414],
         [102.196],
         [122.105],
         [116.915],
         [123.038],
         [108.932]],

        [[113.318],
         [112.107],
         [116.008],
         [120.663],
         [117.289],
         [128.883],
         [108.321],
         [104.029],
         [ 86.212],
         [115.896]],

        [[109.486],
         [116.217],
         [116.774],
         [112.957],
         [110.705],
         [109.301],
         [120.415],
         [ 96.139],
         [108.766],
         [113.343]],

        [[104.202],
         [110.571],
         [102.607],
         [117.297],
         [113.809],
         [124.500],
         [115.231],
         [119.517],
         [ 87.130],
         [ 99.426]]], device='cuda:0')
clipping threshold 1.088945188926506
a after update for 1 param tensor([[ 0.105],
        [-0.155],
        [ 0.092],
        [-0.190],
        [-0.020],
        [-0.177],
        [ 0.229],
        [-0.027],
        [-0.135],
        [ 0.028],
        [ 0.085],
        [ 0.367],
        [ 0.217],
        [ 0.092],
        [-0.238],
        [-0.134],
        [-0.317],
        [-0.053],
        [-0.498],
        [-0.040]], device='cuda:0')
s after update for 1 param tensor([[1.709],
        [1.853],
        [1.840],
        [1.568],
        [1.084],
        [1.819],
        [1.819],
        [1.256],
        [1.654],
        [1.636],
        [0.903],
        [1.835],
        [2.348],
        [1.516],
        [1.060],
        [2.234],
        [1.378],
        [2.120],
        [1.991],
        [1.977]], device='cuda:0')
b after update for 1 param tensor([[112.100],
        [116.755],
        [116.336],
        [107.403],
        [ 89.282],
        [115.672],
        [115.658],
        [ 96.127],
        [110.295],
        [109.684],
        [ 81.507],
        [116.173],
        [131.416],
        [105.605],
        [ 88.289],
        [128.175],
        [100.659],
        [124.870],
        [121.003],
        [120.590]], device='cuda:0')
clipping threshold 1.088945188926506
||w||^2 1.5304911111995751
exp ma of ||w||^2 2.0670552528646358
||w|| 1.2371301916934916
exp ma of ||w|| 1.3689570469214445
||w||^2 0.5520119617385781
exp ma of ||w||^2 1.9479050801335536
||w|| 0.742975074776118
exp ma of ||w|| 1.324121129327651
||w||^2 1.1754521198467875
exp ma of ||w||^2 1.802265504180098
||w|| 1.0841826967106547
exp ma of ||w|| 1.2810242938023888
||w||^2 2.4995243479022116
exp ma of ||w||^2 1.7328267139913793
||w|| 1.5809884085287316
exp ma of ||w|| 1.2614340398703143
||w||^2 1.2572267911285457
exp ma of ||w||^2 1.7861399779360676
||w|| 1.1212612501681067
exp ma of ||w|| 1.282121746650331
||w||^2 1.7427612562675197
exp ma of ||w||^2 1.9695178762452241
||w|| 1.3201368324031868
exp ma of ||w|| 1.352770629509213
||w||^2 0.9795687322094997
exp ma of ||w||^2 1.9738467733498237
||w|| 0.9897316465636025
exp ma of ||w|| 1.348322566697599
cuda
Objective function 45.31 = squared loss an data 32.71 + 0.5*rho*h**2 6.732891 + alpha*h 3.981518 + L2reg 1.64 + L1reg 0.25 ; SHD = 101 ; DAG False
Proportion of microbatches that were clipped  0.7732422659702692
iteration 2 in inner loop, alpha 3.4310959205074703 rho 10.0 h 1.1604215273372027
4420
cuda
Objective function 105.90 = squared loss an data 32.71 + 0.5*rho*h**2 67.328906 + alpha*h 3.981518 + L2reg 1.64 + L1reg 0.25 ; SHD = 101 ; DAG False
||w||^2 3908210.977237748
exp ma of ||w||^2 5530356197.393132
||w|| 1976.9195677208893
exp ma of ||w|| 23966.383236909987
||w||^2 1.4682077265354694
exp ma of ||w||^2 35.235232860181306
||w|| 1.2116962187509992
exp ma of ||w|| 1.6786035886870676
||w||^2 2.281228116901539
exp ma of ||w||^2 2.850235457816209
||w|| 1.5103735024494898
exp ma of ||w|| 1.6142105448133737
||w||^2 4.696718286105634
exp ma of ||w||^2 2.5568933556229827
||w|| 2.16719133583208
exp ma of ||w|| 1.5411827020368658
||w||^2 1.9702100787389243
exp ma of ||w||^2 2.8830913643299616
||w|| 1.4036417202188471
exp ma of ||w|| 1.6214500359921986
||w||^2 2.6819256128710256
exp ma of ||w||^2 2.8379034554504865
||w|| 1.6376585764044427
exp ma of ||w|| 1.6042315717862632
||w||^2 3.005475376729238
exp ma of ||w||^2 2.7035289293859135
||w|| 1.7336306921398335
exp ma of ||w|| 1.5697153905744206
||w||^2 1.8520166336542456
exp ma of ||w||^2 2.9299757310647054
||w|| 1.3608881782329676
exp ma of ||w|| 1.6467083078531086
cuda
Objective function 49.84 = squared loss an data 37.01 + 0.5*rho*h**2 9.337789 + alpha*h 1.482757 + L2reg 1.80 + L1reg 0.21 ; SHD = 81 ; DAG True
Proportion of microbatches that were clipped  0.7754422983281934
iteration 3 in inner loop, alpha 3.4310959205074703 rho 100.0 h 0.4321525013741194
iteration 2 in outer loop, alpha = 46.646346057919416, rho = 100.0, h = 0.4321525013741194
cuda
4420
cuda
Objective function 68.51 = squared loss an data 37.01 + 0.5*rho*h**2 9.337789 + alpha*h 20.158335 + L2reg 1.80 + L1reg 0.21 ; SHD = 81 ; DAG True
||w||^2 1650690251.5115216
exp ma of ||w||^2 51382923754.69968
||w|| 40628.687543551314
exp ma of ||w|| 150023.80306030973
||w||^2 17738.98284791431
exp ma of ||w||^2 517488358.00457823
||w|| 133.18777289193747
exp ma of ||w|| 3024.7974616271717
||w||^2 7.342147221833068
exp ma of ||w||^2 799823.9569593634
||w|| 2.70963968487197
exp ma of ||w|| 8.088429751879863
||w||^2 2.9209937044972762
exp ma of ||w||^2 45610.26819993552
||w|| 1.7090914851163692
exp ma of ||w|| 2.337094780416228
||w||^2 1.7161140391392256
exp ma of ||w||^2 3.717127611024038
||w|| 1.310005358439127
exp ma of ||w|| 1.817260134703465
||w||^2 5.2508669154610415
exp ma of ||w||^2 3.5284257701080204
||w|| 2.2914770161319624
exp ma of ||w|| 1.8086811639629985
||w||^2 2.5527409538608783
exp ma of ||w||^2 3.2284301918992924
||w|| 1.597729937711902
exp ma of ||w|| 1.731018027234198
||w||^2 5.54680429944334
exp ma of ||w||^2 3.1480463011160515
||w|| 2.3551654505455324
exp ma of ||w|| 1.7184912511646757
||w||^2 1.4846499968191003
exp ma of ||w||^2 3.2435913945918013
||w|| 1.2184621441879515
exp ma of ||w|| 1.738498005948833
||w||^2 3.5193856400446473
exp ma of ||w||^2 3.2777439913270325
||w|| 1.8760025693065154
exp ma of ||w|| 1.7523805839690403
||w||^2 8.345202746959526
exp ma of ||w||^2 3.633693914961336
||w|| 2.8888064571652294
exp ma of ||w|| 1.8393945517824746
||w||^2 5.867123697927359
exp ma of ||w||^2 3.7390220904586995
||w|| 2.4222146267264093
exp ma of ||w|| 1.8681012916017028
||w||^2 4.217560003543403
exp ma of ||w||^2 3.649931120897837
||w|| 2.05366988670122
exp ma of ||w|| 1.8424040475599357
||w||^2 4.502147894536875
exp ma of ||w||^2 3.8105266206043824
||w|| 2.1218265467603317
exp ma of ||w|| 1.8662488227174772
||w||^2 2.493609113866433
exp ma of ||w||^2 3.101086415332614
||w|| 1.5791165612032676
exp ma of ||w|| 1.6953093331045592
cuda
Objective function 57.46 = squared loss an data 38.62 + 0.5*rho*h**2 3.819542 + alpha*h 12.892534 + L2reg 1.93 + L1reg 0.20 ; SHD = 82 ; DAG True
Proportion of microbatches that were clipped  0.774154393914873
iteration 1 in inner loop, alpha 46.646346057919416 rho 100.0 h 0.27638893948578414
4420
cuda
Objective function 91.84 = squared loss an data 38.62 + 0.5*rho*h**2 38.195423 + alpha*h 12.892534 + L2reg 1.93 + L1reg 0.20 ; SHD = 82 ; DAG True
||w||^2 4.2903576212050805
exp ma of ||w||^2 1189925.3144849434
||w|| 2.07131784649413
exp ma of ||w|| 8.62799881412817
||w||^2 5.091135466096882
exp ma of ||w||^2 10898.154515039492
||w|| 2.2563544637527326
exp ma of ||w|| 2.230057358952487
||w||^2 2.2995598873095844
exp ma of ||w||^2 3.8582140515761814
||w|| 1.5164299810111854
exp ma of ||w|| 1.889491856640061
||w||^2 2.4348043197958145
exp ma of ||w||^2 3.9328465293020254
||w|| 1.5603859521912566
exp ma of ||w|| 1.9068127684801504
||w||^2 4.571793233259601
exp ma of ||w||^2 4.244265247278234
||w|| 2.138175211075931
exp ma of ||w|| 2.004659093783398
||w||^2 2.19281466313801
exp ma of ||w||^2 4.220805309151414
||w|| 1.4808155398759193
exp ma of ||w|| 1.9782089727965078
cuda
Objective function 58.15 = squared loss an data 39.89 + 0.5*rho*h**2 9.568477 + alpha*h 6.452887 + L2reg 2.06 + L1reg 0.18 ; SHD = 77 ; DAG True
Proportion of microbatches that were clipped  0.7797661655929372
iteration 2 in inner loop, alpha 46.646346057919416 rho 1000.0 h 0.138336379490255
4420
cuda
Objective function 144.27 = squared loss an data 39.89 + 0.5*rho*h**2 95.684769 + alpha*h 6.452887 + L2reg 2.06 + L1reg 0.18 ; SHD = 77 ; DAG True
||w||^2 2066165525359.5544
exp ma of ||w||^2 2210238087824.88
||w|| 1437416.267251611
exp ma of ||w|| 924754.7957707954
||w||^2 8695133736.720886
exp ma of ||w||^2 212048487801.3002
||w|| 93247.70097284376
exp ma of ||w|| 250377.64704924173
||w||^2 4450.203055267135
exp ma of ||w||^2 750478356.3070117
||w|| 66.70984226684347
exp ma of ||w|| 1556.596327876187
||w||^2 7.127271750959189
exp ma of ||w||^2 212213.3409534022
||w|| 2.6696950670365314
exp ma of ||w|| 3.477594674488233
||w||^2 12.693256476770777
exp ma of ||w||^2 6.106229135830956
||w|| 3.5627596714865257
exp ma of ||w|| 2.379531103213098
||w||^2 2.9583359629492403
exp ma of ||w||^2 5.582233582523487
||w|| 1.7199813844775298
exp ma of ||w|| 2.2878132186331155
||w||^2 5.970643247936926
exp ma of ||w||^2 5.486457150598392
||w|| 2.4434899729560846
exp ma of ||w|| 2.276297389036643
||w||^2 5.277318822781252
exp ma of ||w||^2 5.146290103438242
||w|| 2.2972415682250857
exp ma of ||w|| 2.2146829928625684
||w||^2 11.357122578380832
exp ma of ||w||^2 5.124306773333583
||w|| 3.3700330233368385
exp ma of ||w|| 2.1893546176539282
||w||^2 3.6235881825712215
exp ma of ||w||^2 5.047849226256897
||w|| 1.9035724789382782
exp ma of ||w|| 2.19746995862823
||w||^2 4.076162023040751
exp ma of ||w||^2 5.004252069054435
||w|| 2.0189507232819603
exp ma of ||w|| 2.184967427353772
||w||^2 11.17795201606068
exp ma of ||w||^2 4.75173097769479
||w|| 3.343344435750029
exp ma of ||w|| 2.120989815841947
cuda
Objective function 58.84 = squared loss an data 41.95 + 0.5*rho*h**2 12.191257 + alpha*h 2.303334 + L2reg 2.23 + L1reg 0.17 ; SHD = 82 ; DAG True
Proportion of microbatches that were clipped  0.7814817768562087
iteration 3 in inner loop, alpha 46.646346057919416 rho 10000.0 h 0.0493786527836555
iteration 3 in outer loop, alpha = 540.4328738944744, rho = 10000.0, h = 0.0493786527836555
cuda
4420
cuda
Objective function 83.22 = squared loss an data 41.95 + 0.5*rho*h**2 12.191257 + alpha*h 26.685847 + L2reg 2.23 + L1reg 0.17 ; SHD = 82 ; DAG True
||w||^2 9.840444641522758
exp ma of ||w||^2 83174.86208595178
||w|| 3.136948300741145
exp ma of ||w|| 3.295261472418676
||w||^2 27.89805535521302
exp ma of ||w||^2 526.5911942180004
||w|| 5.281860974619932
exp ma of ||w|| 2.5877597499607483
||w||^2 9.29909480923452
exp ma of ||w||^2 7.3830554455094655
||w|| 3.049441720911308
exp ma of ||w|| 2.3833124575825373
||w||^2 4.31698420883027
exp ma of ||w||^2 5.211125128664505
||w|| 2.077735355821398
exp ma of ||w|| 2.2302649351518977
||w||^2 2.3936204207513256
exp ma of ||w||^2 5.4098542623785395
||w|| 1.5471329680254784
exp ma of ||w|| 2.271566669263385
||w||^2 4.219094512862175
exp ma of ||w||^2 5.471487878364492
||w|| 2.054043454472708
exp ma of ||w|| 2.286149703029267
||w||^2 4.207998931196838
exp ma of ||w||^2 5.685000851714165
||w|| 2.051340764279996
exp ma of ||w|| 2.3074080406244266
||w||^2 3.3395010611581815
exp ma of ||w||^2 5.210132944143831
||w|| 1.8274301795576708
exp ma of ||w|| 2.2217924581758854
||w||^2 6.801680666587155
exp ma of ||w||^2 5.200330236438968
||w|| 2.6080031952793226
exp ma of ||w|| 2.2237566526473813
||w||^2 4.36622453805096
exp ma of ||w||^2 5.352902527967458
||w|| 2.0895512767221005
exp ma of ||w|| 2.2609380072159992
||w||^2 5.508014952615738
exp ma of ||w||^2 5.503711362771666
||w|| 2.3469160514632255
exp ma of ||w|| 2.305632353052234
||w||^2 8.606331639806513
exp ma of ||w||^2 5.467431676707523
||w|| 2.9336549967244805
exp ma of ||w|| 2.298418998036167
cuda
Objective function 67.14 = squared loss an data 41.99 + 0.5*rho*h**2 5.211270 + alpha*h 17.447312 + L2reg 2.31 + L1reg 0.17 ; SHD = 89 ; DAG True
Proportion of microbatches that were clipped  0.7802547770700637
iteration 1 in inner loop, alpha 540.4328738944744 rho 10000.0 h 0.032283958280665104
4420
cuda
Objective function 114.04 = squared loss an data 41.99 + 0.5*rho*h**2 52.112698 + alpha*h 17.447312 + L2reg 2.31 + L1reg 0.17 ; SHD = 89 ; DAG True
||w||^2 125.86670459608527
exp ma of ||w||^2 462498829.76875585
||w|| 11.219033139985159
exp ma of ||w|| 277.5348652671664
||w||^2 8.679642849424072
exp ma of ||w||^2 1138.6131128632092
||w|| 2.9461233595055165
exp ma of ||w|| 3.358624622541265
||w||^2 5.3154882878547784
exp ma of ||w||^2 20.663403263200156
||w|| 2.3055342738408333
exp ma of ||w|| 2.7589311221560857
||w||^2 3.873189011752283
exp ma of ||w||^2 6.055945568889339
||w|| 1.968041923271017
exp ma of ||w|| 2.419147900844242
||w||^2 12.172058235954541
exp ma of ||w||^2 6.353613432423909
||w|| 3.488847694576899
exp ma of ||w|| 2.475486288568609
||w||^2 3.4280430050152892
exp ma of ||w||^2 5.915366840786099
||w|| 1.851497503378087
exp ma of ||w|| 2.384270560628758
||w||^2 8.13285047868838
exp ma of ||w||^2 6.75297015853547
||w|| 2.8518152953317966
exp ma of ||w|| 2.563539822201497
||w||^2 3.9812614213424693
exp ma of ||w||^2 6.649579377694852
||w|| 1.9953098559728686
exp ma of ||w|| 2.5403747586968297
||w||^2 6.43289174540775
exp ma of ||w||^2 6.750717182587031
||w|| 2.5363145990605642
exp ma of ||w|| 2.5728869727508643
||w||^2 8.576873386546685
exp ma of ||w||^2 6.48724703356472
||w|| 2.928629950428474
exp ma of ||w|| 2.510876514657601
||w||^2 13.0549357177654
exp ma of ||w||^2 7.242425865185278
||w|| 3.6131614574725828
exp ma of ||w|| 2.6590266230828616
cuda
Objective function 65.86 = squared loss an data 42.53 + 0.5*rho*h**2 12.287989 + alpha*h 8.472219 + L2reg 2.41 + L1reg 0.17 ; SHD = 88 ; DAG True
Proportion of microbatches that were clipped  0.7841466355816384
iteration 2 in inner loop, alpha 540.4328738944744 rho 100000.0 h 0.01567672736964454
iteration 4 in outer loop, alpha = 16217.160243539014, rho = 1000000.0, h = 0.01567672736964454
Threshold 0.3
[[0.008 1.958 0.476 0.521 0.594 0.891 0.718 0.539 0.142 0.286 0.609 0.174
  0.374 0.214 0.611 0.756 0.566 0.402 0.744 0.371]
 [0.003 0.01  0.092 0.139 0.232 0.334 0.441 0.083 0.034 0.224 0.058 0.03
  0.086 0.102 0.163 0.359 0.14  0.136 0.17  0.078]
 [0.02  0.078 0.012 0.042 0.299 0.081 0.22  0.187 0.016 0.345 0.139 0.06
  0.078 0.436 0.163 0.326 0.24  0.251 0.282 0.078]
 [0.011 0.067 0.167 0.011 0.317 0.111 0.154 0.193 0.025 0.572 0.158 0.058
  0.139 0.239 0.297 0.259 0.159 0.318 0.201 0.065]
 [0.008 0.042 0.033 0.03  0.009 0.013 0.031 0.013 0.008 0.017 0.064 0.016
  0.02  0.063 0.025 0.056 0.036 0.067 0.023 0.023]
 [0.007 0.035 0.08  0.056 0.528 0.009 0.177 0.241 0.013 0.209 0.174 0.024
  0.105 0.2   0.66  0.576 0.834 0.247 0.288 0.169]
 [0.01  0.025 0.033 0.052 0.251 0.042 0.011 0.047 0.021 0.111 0.058 0.03
  0.03  0.147 0.049 0.498 0.116 0.038 0.121 0.025]
 [0.018 0.085 0.044 0.057 0.465 0.029 0.142 0.01  0.011 0.117 0.363 0.036
  0.03  0.333 0.141 0.269 0.318 0.201 0.178 0.041]
 [0.06  0.16  0.678 0.223 0.737 0.456 0.402 0.502 0.007 0.358 0.669 0.244
  0.733 0.5   0.275 0.625 0.702 0.551 0.769 0.362]
 [0.016 0.025 0.028 0.012 0.389 0.041 0.045 0.064 0.017 0.009 0.048 0.012
  0.044 0.158 0.065 0.139 0.292 0.047 0.074 0.046]
 [0.013 0.098 0.031 0.047 0.146 0.037 0.128 0.022 0.01  0.087 0.007 0.021
  0.012 0.099 0.048 0.082 0.074 0.04  0.025 0.015]
 [0.034 0.307 0.135 0.089 0.182 0.374 0.296 0.174 0.039 0.5   0.265 0.007
  0.306 0.42  0.226 0.369 0.41  0.192 0.275 0.139]
 [0.017 0.064 0.098 0.062 0.394 0.093 0.3   0.202 0.008 0.177 0.496 0.02
  0.007 0.268 0.093 0.335 0.264 0.207 0.093 0.098]
 [0.017 0.061 0.014 0.041 0.099 0.036 0.057 0.022 0.012 0.073 0.105 0.021
  0.04  0.008 0.026 0.264 0.104 0.031 0.063 0.029]
 [0.015 0.027 0.061 0.028 0.432 0.016 0.153 0.044 0.026 0.142 0.112 0.039
  0.115 0.296 0.009 0.207 0.345 0.082 0.127 0.046]
 [0.006 0.021 0.023 0.021 0.146 0.01  0.016 0.03  0.011 0.043 0.071 0.019
  0.022 0.033 0.029 0.011 0.016 0.026 0.013 0.009]
 [0.011 0.048 0.034 0.048 0.209 0.012 0.091 0.027 0.009 0.021 0.1   0.02
  0.026 0.062 0.03  0.594 0.011 0.032 0.109 0.025]
 [0.015 0.066 0.037 0.025 0.196 0.06  0.148 0.05  0.015 0.231 0.258 0.026
  0.043 0.296 0.081 0.356 0.151 0.011 0.121 0.066]
 [0.015 0.05  0.02  0.032 0.246 0.028 0.075 0.034 0.012 0.085 0.297 0.031
  0.098 0.133 0.06  0.716 0.075 0.054 0.007 0.074]
 [0.025 0.16  0.104 0.106 0.318 0.059 0.402 0.208 0.023 0.193 0.619 0.067
  0.126 0.326 0.179 1.118 0.253 0.205 0.102 0.008]]
[[0.    1.958 0.476 0.521 0.594 0.891 0.718 0.539 0.    0.    0.609 0.
  0.374 0.    0.611 0.756 0.566 0.402 0.744 0.371]
 [0.    0.    0.    0.    0.    0.334 0.441 0.    0.    0.    0.    0.
  0.    0.    0.    0.359 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.345 0.    0.
  0.    0.436 0.    0.326 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.317 0.    0.    0.    0.    0.572 0.    0.
  0.    0.    0.    0.    0.    0.318 0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.528 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.66  0.576 0.834 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.498 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.465 0.    0.    0.    0.    0.    0.363 0.
  0.    0.333 0.    0.    0.318 0.    0.    0.   ]
 [0.    0.    0.678 0.    0.737 0.456 0.402 0.502 0.    0.358 0.669 0.
  0.733 0.5   0.    0.625 0.702 0.551 0.769 0.362]
 [0.    0.    0.    0.    0.389 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.307 0.    0.    0.    0.374 0.    0.    0.    0.5   0.    0.
  0.306 0.42  0.    0.369 0.41  0.    0.    0.   ]
 [0.    0.    0.    0.    0.394 0.    0.3   0.    0.    0.    0.496 0.
  0.    0.    0.    0.335 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.432 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.345 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.594 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.356 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.716 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.318 0.    0.402 0.    0.    0.    0.619 0.
  0.    0.326 0.    1.118 0.    0.    0.    0.   ]]
{'fdr': 0.6086956521739131, 'tpr': 0.3375, 'fpr': 0.38181818181818183, 'f1': 0.3624161073825503, 'shd': 88, 'npred': 69, 'ntrue': 80}
[1.958 0.476 0.521 0.594 0.891 0.718 0.539 0.142 0.286 0.609 0.174 0.374
 0.214 0.611 0.756 0.566 0.402 0.744 0.371 0.003 0.092 0.139 0.232 0.334
 0.441 0.083 0.034 0.224 0.058 0.03  0.086 0.102 0.163 0.359 0.14  0.136
 0.17  0.078 0.02  0.078 0.042 0.299 0.081 0.22  0.187 0.016 0.345 0.139
 0.06  0.078 0.436 0.163 0.326 0.24  0.251 0.282 0.078 0.011 0.067 0.167
 0.317 0.111 0.154 0.193 0.025 0.572 0.158 0.058 0.139 0.239 0.297 0.259
 0.159 0.318 0.201 0.065 0.008 0.042 0.033 0.03  0.013 0.031 0.013 0.008
 0.017 0.064 0.016 0.02  0.063 0.025 0.056 0.036 0.067 0.023 0.023 0.007
 0.035 0.08  0.056 0.528 0.177 0.241 0.013 0.209 0.174 0.024 0.105 0.2
 0.66  0.576 0.834 0.247 0.288 0.169 0.01  0.025 0.033 0.052 0.251 0.042
 0.047 0.021 0.111 0.058 0.03  0.03  0.147 0.049 0.498 0.116 0.038 0.121
 0.025 0.018 0.085 0.044 0.057 0.465 0.029 0.142 0.011 0.117 0.363 0.036
 0.03  0.333 0.141 0.269 0.318 0.201 0.178 0.041 0.06  0.16  0.678 0.223
 0.737 0.456 0.402 0.502 0.358 0.669 0.244 0.733 0.5   0.275 0.625 0.702
 0.551 0.769 0.362 0.016 0.025 0.028 0.012 0.389 0.041 0.045 0.064 0.017
 0.048 0.012 0.044 0.158 0.065 0.139 0.292 0.047 0.074 0.046 0.013 0.098
 0.031 0.047 0.146 0.037 0.128 0.022 0.01  0.087 0.021 0.012 0.099 0.048
 0.082 0.074 0.04  0.025 0.015 0.034 0.307 0.135 0.089 0.182 0.374 0.296
 0.174 0.039 0.5   0.265 0.306 0.42  0.226 0.369 0.41  0.192 0.275 0.139
 0.017 0.064 0.098 0.062 0.394 0.093 0.3   0.202 0.008 0.177 0.496 0.02
 0.268 0.093 0.335 0.264 0.207 0.093 0.098 0.017 0.061 0.014 0.041 0.099
 0.036 0.057 0.022 0.012 0.073 0.105 0.021 0.04  0.026 0.264 0.104 0.031
 0.063 0.029 0.015 0.027 0.061 0.028 0.432 0.016 0.153 0.044 0.026 0.142
 0.112 0.039 0.115 0.296 0.207 0.345 0.082 0.127 0.046 0.006 0.021 0.023
 0.021 0.146 0.01  0.016 0.03  0.011 0.043 0.071 0.019 0.022 0.033 0.029
 0.016 0.026 0.013 0.009 0.011 0.048 0.034 0.048 0.209 0.012 0.091 0.027
 0.009 0.021 0.1   0.02  0.026 0.062 0.03  0.594 0.032 0.109 0.025 0.015
 0.066 0.037 0.025 0.196 0.06  0.148 0.05  0.015 0.231 0.258 0.026 0.043
 0.296 0.081 0.356 0.151 0.121 0.066 0.015 0.05  0.02  0.032 0.246 0.028
 0.075 0.034 0.012 0.085 0.297 0.031 0.098 0.133 0.06  0.716 0.075 0.054
 0.074 0.025 0.16  0.104 0.106 0.318 0.059 0.402 0.208 0.023 0.193 0.619
 0.067 0.126 0.326 0.179 1.118 0.253 0.205 0.102]
[[0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0.]
 [0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1.]
 [0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0.]
 [0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.]
 [0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.]
 [0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]
 [0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]
[1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1.
 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.
 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.
 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1.
 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
aucroc, aucpr (0.6675, 0.4129387245072229)
Iterations 2250
Achieves (3.524517146579602, 1e-05)-DP
