samples  5000  graph  20 40 ER mlp  minibatch size  50  noise  0.6  minibatches per NN training  250 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.5634617290166446
iteration 1 in outer loop, alpha = 1.5634617290166446, rho = 1.0, h = 1.5634617290166446
cuda
iteration 1 in inner loop,alpha 1.5634617290166446 rho 1.0 h 1.0381693524821998
iteration 2 in inner loop,alpha 1.5634617290166446 rho 10.0 h 0.44591711636684295
iteration 3 in inner loop,alpha 1.5634617290166446 rho 100.0 h 0.13747666157667737
iteration 2 in outer loop, alpha = 15.311127886684382, rho = 100.0, h = 0.13747666157667737
cuda
iteration 1 in inner loop,alpha 15.311127886684382 rho 100.0 h 0.07305387155436094
iteration 2 in inner loop,alpha 15.311127886684382 rho 1000.0 h 0.023889279379787354
iteration 3 in outer loop, alpha = 39.200407266471736, rho = 1000.0, h = 0.023889279379787354
cuda
iteration 1 in inner loop,alpha 39.200407266471736 rho 1000.0 h 0.00901402265018092
iteration 2 in inner loop,alpha 39.200407266471736 rho 10000.0 h 0.0033117238755835388
iteration 4 in outer loop, alpha = 72.31764602230712, rho = 10000.0, h = 0.0033117238755835388
cuda
iteration 1 in inner loop,alpha 72.31764602230712 rho 10000.0 h 0.0014070408669155654
iteration 2 in inner loop,alpha 72.31764602230712 rho 100000.0 h 0.00050899050887665
iteration 5 in outer loop, alpha = 123.21669690997211, rho = 100000.0, h = 0.00050899050887665
cuda
iteration 1 in inner loop,alpha 123.21669690997211 rho 100000.0 h 0.0002597991427819579
iteration 6 in outer loop, alpha = 383.01583969193007, rho = 1000000.0, h = 0.0002597991427819579
Threshold 0.3
[[0.    0.011 0.045 2.313 0.035 0.03  0.042 0.    1.996 0.014 1.853 0.002
  0.1   0.002 0.212 0.941 0.001 0.001 0.038 0.212]
 [0.033 0.005 0.219 0.057 0.402 0.113 0.028 0.002 3.053 0.047 0.014 0.011
  0.6   0.002 1.79  1.573 0.29  0.    0.225 0.341]
 [0.001 0.    0.003 0.07  0.127 1.222 0.    0.    2.295 0.077 0.06  0.
  2.299 0.001 1.415 0.876 0.001 0.    3.748 2.293]
 [0.    0.    0.    0.003 0.001 0.002 0.    0.    0.001 0.    0.    0.
  0.    0.    0.145 1.494 0.    0.    0.    0.001]
 [0.    0.    0.    1.685 0.001 0.191 0.    0.    0.001 0.029 0.018 0.
  0.374 0.003 0.088 0.345 0.    0.    0.032 0.18 ]
 [0.001 0.    0.    0.118 0.003 0.001 0.    0.    0.004 0.034 0.069 0.
  0.233 0.    1.893 0.447 0.    0.    0.001 0.17 ]
 [0.001 0.016 0.579 0.057 0.229 0.102 0.005 0.    0.035 0.001 0.017 0.
  0.036 0.001 0.065 1.635 0.007 0.005 0.064 0.022]
 [0.005 0.014 0.703 0.049 0.187 0.094 4.465 0.001 0.152 0.009 0.003 0.053
  0.006 0.004 0.14  0.23  0.061 0.006 0.062 0.054]
 [0.    0.    0.    0.06  1.002 0.112 0.001 0.    0.002 0.047 0.043 0.
  0.285 0.001 0.292 0.526 0.    0.    0.018 0.218]
 [0.    0.    0.    0.095 0.    0.    0.    0.    0.    0.001 0.839 0.
  0.    0.    0.173 0.248 0.    0.    0.    0.169]
 [0.    0.    0.    0.097 0.001 0.001 0.    0.    0.001 0.    0.001 0.
  0.    0.    1.242 0.28  0.    0.    0.    2.33 ]
 [0.003 0.003 2.807 0.07  0.02  0.229 3.6   0.004 0.217 0.015 0.015 0.001
  0.226 0.001 0.607 0.356 0.008 0.022 0.208 0.179]
 [0.    0.    0.    0.108 0.001 0.002 0.    0.    0.002 3.21  0.123 0.
  0.002 0.    0.347 0.54  0.    0.    0.    0.416]
 [0.003 0.009 0.017 0.051 0.031 0.129 0.001 0.004 0.095 0.03  0.076 0.023
  0.275 0.    0.177 0.171 0.005 0.023 2.63  0.224]
 [0.    0.    0.    0.006 0.    0.    0.    0.    0.001 0.    0.    0.
  0.    0.    0.005 0.274 0.    0.    0.    0.004]
 [0.    0.    0.    0.    0.    0.001 0.    0.    0.    0.    0.    0.
  0.    0.    0.006 0.009 0.    0.    0.    0.   ]
 [0.008 0.006 0.34  0.063 0.36  0.205 0.028 0.003 0.268 0.046 0.057 0.01
  0.397 0.001 1.818 1.508 0.003 0.    0.328 0.487]
 [0.003 4.273 0.004 0.05  0.198 0.004 0.008 0.    0.594 0.004 0.001 0.003
  1.395 0.001 0.147 0.247 2.988 0.001 1.417 1.034]
 [0.004 0.001 0.    0.064 0.018 1.236 0.    0.    0.085 0.047 0.017 0.
  1.035 0.    0.39  1.337 0.    0.    0.003 0.476]
 [0.    0.    0.    2.101 0.    0.001 0.    0.    0.    0.    0.    0.
  0.    0.    0.207 0.335 0.    0.    0.    0.003]]
[[0.    0.    0.    2.313 0.    0.    0.    0.    1.996 0.    1.853 0.
  0.    0.    0.    0.941 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.402 0.    0.    0.    3.053 0.    0.    0.
  0.6   0.    1.79  1.573 0.    0.    0.    0.341]
 [0.    0.    0.    0.    0.    1.222 0.    0.    2.295 0.    0.    0.
  2.299 0.    1.415 0.876 0.    0.    3.748 2.293]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    1.494 0.    0.    0.    0.   ]
 [0.    0.    0.    1.685 0.    0.    0.    0.    0.    0.    0.    0.
  0.374 0.    0.    0.345 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    1.893 0.447 0.    0.    0.    0.   ]
 [0.    0.    0.579 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    1.635 0.    0.    0.    0.   ]
 [0.    0.    0.703 0.    0.    0.    4.465 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    1.002 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.526 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.839 0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    1.242 0.    0.    0.    0.    2.33 ]
 [0.    0.    2.807 0.    0.    0.    3.6   0.    0.    0.    0.    0.
  0.    0.    0.607 0.356 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    3.21  0.    0.
  0.    0.    0.347 0.54  0.    0.    0.    0.416]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    2.63  0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.34  0.    0.36  0.    0.    0.    0.    0.    0.    0.
  0.397 0.    1.818 1.508 0.    0.    0.328 0.487]
 [0.    4.273 0.    0.    0.    0.    0.    0.    0.594 0.    0.    0.
  1.395 0.    0.    0.    2.988 0.    1.417 1.034]
 [0.    0.    0.    0.    0.    1.236 0.    0.    0.    0.    0.    0.
  1.035 0.    0.39  1.337 0.    0.    0.    0.476]
 [0.    0.    0.    2.101 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.335 0.    0.    0.    0.   ]]
{'fdr': 0.3442622950819672, 'tpr': 1.0, 'fpr': 0.14, 'f1': 0.7920792079207921, 'shd': 21, 'npred': 61, 'ntrue': 40}
[1.068e-02 4.515e-02 2.313e+00 3.537e-02 3.013e-02 4.165e-02 4.799e-04
 1.996e+00 1.446e-02 1.853e+00 1.891e-03 1.003e-01 2.062e-03 2.117e-01
 9.409e-01 1.304e-03 1.063e-03 3.772e-02 2.119e-01 3.296e-02 2.190e-01
 5.712e-02 4.020e-01 1.134e-01 2.761e-02 1.803e-03 3.053e+00 4.652e-02
 1.429e-02 1.062e-02 6.000e-01 1.694e-03 1.790e+00 1.573e+00 2.905e-01
 3.712e-04 2.249e-01 3.410e-01 6.427e-04 2.433e-04 7.011e-02 1.275e-01
 1.222e+00 3.365e-04 5.737e-05 2.295e+00 7.675e-02 5.953e-02 2.386e-04
 2.299e+00 6.721e-04 1.415e+00 8.757e-01 1.426e-03 6.833e-05 3.748e+00
 2.293e+00 9.890e-06 1.303e-04 1.667e-04 5.121e-04 1.633e-03 1.198e-04
 3.171e-05 5.236e-04 1.759e-05 6.174e-05 7.834e-05 6.331e-05 7.114e-06
 1.450e-01 1.494e+00 2.746e-04 7.997e-05 2.729e-04 9.667e-04 1.127e-05
 1.159e-04 1.443e-04 1.685e+00 1.912e-01 3.167e-04 1.210e-05 7.183e-04
 2.892e-02 1.759e-02 4.548e-05 3.744e-01 2.581e-03 8.846e-02 3.453e-01
 3.051e-04 2.813e-05 3.249e-02 1.803e-01 5.616e-04 4.753e-04 8.946e-05
 1.176e-01 2.542e-03 7.435e-05 1.049e-05 4.093e-03 3.431e-02 6.910e-02
 2.908e-05 2.326e-01 7.124e-06 1.893e+00 4.471e-01 3.099e-05 1.645e-05
 7.048e-04 1.701e-01 7.863e-04 1.638e-02 5.793e-01 5.661e-02 2.293e-01
 1.021e-01 1.686e-04 3.492e-02 1.455e-03 1.671e-02 2.453e-05 3.567e-02
 8.309e-04 6.460e-02 1.635e+00 6.784e-03 4.714e-03 6.409e-02 2.193e-02
 4.854e-03 1.379e-02 7.029e-01 4.929e-02 1.871e-01 9.435e-02 4.465e+00
 1.517e-01 8.636e-03 3.357e-03 5.256e-02 6.129e-03 4.083e-03 1.403e-01
 2.302e-01 6.145e-02 5.960e-03 6.195e-02 5.376e-02 4.131e-05 2.379e-04
 3.542e-04 6.003e-02 1.002e+00 1.120e-01 5.929e-04 2.024e-05 4.747e-02
 4.334e-02 7.207e-05 2.848e-01 6.056e-04 2.917e-01 5.256e-01 2.653e-04
 4.155e-05 1.754e-02 2.184e-01 3.920e-04 1.703e-05 4.436e-05 9.458e-02
 9.245e-05 3.434e-04 3.824e-05 8.850e-06 1.694e-04 8.387e-01 3.088e-05
 1.473e-04 9.735e-06 1.733e-01 2.477e-01 7.328e-05 1.178e-05 3.203e-05
 1.692e-01 5.260e-05 1.904e-04 1.086e-05 9.719e-02 5.535e-04 5.874e-04
 2.662e-04 7.013e-06 1.149e-03 4.096e-04 9.090e-06 1.599e-05 9.226e-06
 1.242e+00 2.799e-01 1.985e-04 1.624e-05 4.464e-05 2.330e+00 2.734e-03
 3.014e-03 2.807e+00 6.979e-02 1.966e-02 2.286e-01 3.600e+00 3.586e-03
 2.168e-01 1.533e-02 1.477e-02 2.264e-01 1.227e-03 6.067e-01 3.557e-01
 8.203e-03 2.238e-02 2.084e-01 1.793e-01 1.332e-04 4.828e-05 1.447e-04
 1.084e-01 6.950e-04 1.703e-03 4.656e-05 1.038e-05 1.552e-03 3.210e+00
 1.233e-01 4.174e-05 2.571e-05 3.469e-01 5.397e-01 3.984e-04 3.684e-05
 2.269e-04 4.158e-01 2.814e-03 8.568e-03 1.692e-02 5.100e-02 3.121e-02
 1.285e-01 7.214e-04 4.100e-03 9.538e-02 3.050e-02 7.626e-02 2.345e-02
 2.746e-01 1.772e-01 1.711e-01 4.831e-03 2.317e-02 2.630e+00 2.240e-01
 9.711e-06 4.458e-04 9.560e-05 6.262e-03 4.750e-04 1.266e-04 1.581e-04
 1.242e-05 5.694e-04 2.214e-04 1.894e-04 2.710e-05 2.991e-05 8.272e-06
 2.745e-01 3.787e-04 7.545e-05 5.100e-05 3.550e-03 6.820e-06 2.034e-04
 4.505e-05 1.468e-04 3.118e-05 5.222e-04 3.915e-04 3.282e-05 3.841e-05
 8.963e-05 6.136e-05 1.144e-05 3.201e-05 1.307e-05 6.297e-03 3.398e-05
 2.868e-05 4.021e-05 8.716e-05 7.708e-03 5.956e-03 3.398e-01 6.253e-02
 3.600e-01 2.054e-01 2.848e-02 2.612e-03 2.677e-01 4.628e-02 5.669e-02
 1.000e-02 3.972e-01 5.892e-04 1.818e+00 1.508e+00 4.108e-04 3.275e-01
 4.874e-01 3.416e-03 4.273e+00 3.576e-03 5.048e-02 1.977e-01 4.043e-03
 7.942e-03 4.818e-04 5.938e-01 3.881e-03 7.279e-04 2.544e-03 1.395e+00
 8.408e-04 1.469e-01 2.470e-01 2.988e+00 1.417e+00 1.034e+00 3.635e-03
 9.288e-04 3.927e-04 6.386e-02 1.833e-02 1.236e+00 1.269e-04 2.508e-05
 8.550e-02 4.737e-02 1.672e-02 8.334e-05 1.035e+00 1.100e-05 3.897e-01
 1.337e+00 2.549e-04 1.461e-04 4.757e-01 2.831e-05 4.165e-05 1.630e-04
 2.101e+00 2.096e-04 1.118e-03 9.333e-05 3.384e-05 4.967e-04 3.030e-05
 5.084e-05 5.738e-05 3.757e-05 4.465e-05 2.068e-01 3.349e-01 2.338e-05
 8.779e-05 1.198e-04]
[[0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.9993382352941177, 0.9940659034796031)
cuda
4420
cuda
Objective function 737.19 = squared loss an data 521.17 + 0.5*rho*h**2 215.201283 + alpha*h 0.000000 + L2reg 0.37 + L1reg 0.45 ; SHD = 208 ; DAG False
v before min max tensor([[-2.513e-03, -5.175e-06, -5.666e-04,  ..., -8.193e-05,  1.542e-03,
         -2.329e-05],
        [-3.845e-03, -6.532e-04, -3.537e-03,  ..., -3.569e-04, -2.929e-04,
         -1.317e-04],
        [-1.839e-03,  2.530e-04, -1.746e-03,  ..., -2.242e-04,  3.649e-04,
         -1.123e-04],
        ...,
        [ 2.248e-02, -5.831e-03, -3.402e-04,  ...,  1.497e-05,  7.859e-05,
         -8.816e-04],
        [-4.162e-04, -7.059e-04, -1.722e-04,  ..., -2.013e-04, -3.063e-05,
          3.670e-03],
        [ 2.853e-03, -5.739e-05, -4.893e-04,  ..., -1.116e-04,  7.009e-04,
         -2.813e-03]], device='cuda:0')
v tensor([[1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.542e-03,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 2.530e-04, 1.000e-12,  ..., 1.000e-12, 3.649e-04,
         1.000e-12],
        ...,
        [2.248e-02, 1.000e-12, 1.000e-12,  ..., 1.497e-05, 7.859e-05,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         3.670e-03],
        [2.853e-03, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 7.009e-04,
         1.000e-12]], device='cuda:0')
v before min max tensor([-4.053e-05,  1.355e-03, -6.152e-06, -4.186e-05, -1.997e-05, -1.079e-02,
        -1.345e-04, -1.991e-04, -4.078e-04, -2.862e-04, -9.341e-05, -3.116e-06,
         2.821e-06, -1.673e-03, -5.800e-05, -1.508e-03, -8.610e-04, -1.218e-04,
         1.056e-04,  5.300e-05, -6.010e-05, -1.196e-03, -5.268e-05, -6.253e-07,
         1.803e-02, -5.531e-05, -1.215e-03, -7.828e-06,  9.415e-05, -4.574e-05,
        -1.348e-03, -2.291e-03, -1.754e-03, -2.096e-05, -1.449e-05, -9.091e-04,
        -4.792e-05, -3.303e-03, -4.386e-04, -3.589e-04, -2.969e-05, -1.455e-03,
        -1.053e-04, -1.300e-03, -7.278e-04, -8.643e-05,  2.246e-05, -2.392e-04,
        -2.069e-04,  4.987e-04, -7.020e-03, -9.390e-04, -1.051e-05, -1.114e-05,
        -1.702e-03,  2.374e-04, -2.526e-04, -3.156e-04, -1.996e-04, -1.330e-03,
        -7.752e-06, -1.311e-03, -2.922e-05, -1.509e-04, -1.072e-03, -2.314e-04,
         2.891e-05, -1.033e-02, -3.634e-03, -5.491e-04, -3.269e-04, -8.395e-04,
        -1.218e-06, -2.520e-05,  2.099e-04, -3.300e-05,  8.383e-05, -2.993e-05,
        -3.485e-04, -4.880e-06,  6.617e-05,  1.087e-03, -3.156e-04, -2.979e-04,
        -1.184e-02, -1.519e-04, -1.140e-03, -1.771e-04, -1.426e-04, -2.457e-04,
         1.129e-03,  1.223e-03, -2.478e-04,  3.582e-03, -1.745e-05, -5.541e-05,
        -5.387e-05, -4.567e-05, -2.875e-03, -9.278e-06,  6.794e-05,  3.332e-05,
        -1.107e-03, -1.033e-04, -1.316e-03, -1.497e-04,  1.260e-02, -7.677e-05,
        -3.476e-05, -7.407e-04, -1.390e-04,  1.425e-05,  4.914e-05, -1.962e-03,
        -4.742e-04, -1.516e-04, -4.409e-05,  5.944e-06, -1.652e-03,  1.686e-04,
        -5.531e-06,  4.771e-05, -1.877e-04,  1.144e-04, -1.012e-04, -1.666e-05,
         7.389e-05,  9.457e-04, -3.293e-04, -2.912e-03,  3.950e-03,  6.752e-03,
         9.671e-05, -1.738e-04,  3.609e-05, -5.503e-04, -9.232e-06,  4.770e-07,
         5.983e-05, -5.231e-05,  1.014e-05,  2.772e-05, -5.813e-06, -2.212e-04,
        -1.284e-04, -1.138e-05, -1.106e-06,  2.723e-02, -4.586e-03, -5.475e-05,
        -1.596e-03, -5.960e-04, -2.609e-05, -2.300e-03, -3.292e-03,  1.509e-03,
        -1.673e-03,  6.710e-05, -2.459e-04, -1.128e-03, -1.991e-03, -1.914e-05,
        -1.273e-03, -3.052e-04, -1.550e-03,  2.647e-04,  2.286e-03, -1.309e-05,
         2.816e-03,  1.850e-05, -5.345e-05, -1.106e-02, -1.510e-05, -1.582e-04,
        -4.890e-06,  1.450e-03, -1.654e-06, -1.469e-04, -1.431e-05,  3.543e-06,
        -1.392e-03, -1.195e-06, -1.227e-04, -1.678e-06, -4.607e-04,  6.009e-03,
        -3.222e-04,  3.564e-03,  3.166e-03, -2.774e-05, -1.162e-03, -8.348e-04,
        -8.349e-04, -1.699e-04, -3.656e-04, -4.334e-04,  6.990e-04,  1.239e-05,
         3.774e-04, -1.069e-03], device='cuda:0')
v tensor([1.000e-12, 1.355e-03, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        2.821e-06, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.056e-04, 5.300e-05, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.803e-02, 1.000e-12, 1.000e-12, 1.000e-12, 9.415e-05, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.246e-05, 1.000e-12,
        1.000e-12, 4.987e-04, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 2.374e-04, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        2.891e-05, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 2.099e-04, 1.000e-12, 8.383e-05, 1.000e-12,
        1.000e-12, 1.000e-12, 6.617e-05, 1.087e-03, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.129e-03, 1.223e-03, 1.000e-12, 3.582e-03, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 6.794e-05, 3.332e-05,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.260e-02, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.425e-05, 4.914e-05, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 5.944e-06, 1.000e-12, 1.686e-04,
        1.000e-12, 4.771e-05, 1.000e-12, 1.144e-04, 1.000e-12, 1.000e-12,
        7.389e-05, 9.457e-04, 1.000e-12, 1.000e-12, 3.950e-03, 6.752e-03,
        9.671e-05, 1.000e-12, 3.609e-05, 1.000e-12, 1.000e-12, 4.770e-07,
        5.983e-05, 1.000e-12, 1.014e-05, 2.772e-05, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 2.723e-02, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.509e-03,
        1.000e-12, 6.710e-05, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 2.647e-04, 2.286e-03, 1.000e-12,
        2.816e-03, 1.850e-05, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.450e-03, 1.000e-12, 1.000e-12, 1.000e-12, 3.543e-06,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 6.009e-03,
        1.000e-12, 3.564e-03, 3.166e-03, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 6.990e-04, 1.239e-05,
        3.774e-04, 1.000e-12], device='cuda:0')
v before min max tensor([[[ 7.951e-04],
         [-3.275e-03],
         [-4.437e-04],
         [-1.686e-03],
         [-1.149e-02],
         [-1.379e-03],
         [-6.519e-04],
         [-1.747e-04],
         [ 4.870e-04],
         [-1.167e-05]],

        [[-2.056e-06],
         [ 1.324e-05],
         [ 8.618e-02],
         [ 5.376e-04],
         [ 1.379e-01],
         [ 3.424e-03],
         [-2.123e-02],
         [ 2.091e-03],
         [ 5.358e-01],
         [-5.678e-02]],

        [[-1.702e-03],
         [ 2.618e-03],
         [-3.042e-04],
         [-2.518e-03],
         [-1.106e-02],
         [-1.053e-03],
         [-1.446e-03],
         [-8.237e-04],
         [ 1.674e-04],
         [ 3.376e-02]],

        [[ 2.951e-01],
         [ 2.041e-01],
         [-1.465e-03],
         [ 9.008e-02],
         [ 2.302e-01],
         [ 3.049e-01],
         [ 1.732e-04],
         [-9.969e-03],
         [-2.528e-02],
         [ 1.085e-01]],

        [[ 1.354e-01],
         [ 1.578e-03],
         [ 4.057e-01],
         [ 3.053e-04],
         [ 7.414e-03],
         [ 4.595e-02],
         [ 9.919e-03],
         [-2.704e-02],
         [-1.596e-04],
         [ 4.217e-01]],

        [[ 6.886e-01],
         [ 4.556e-02],
         [ 8.953e-02],
         [-3.865e-04],
         [ 3.240e-04],
         [ 9.502e-02],
         [-1.700e-03],
         [ 2.042e-01],
         [ 2.628e-04],
         [-2.441e-04]],

        [[-1.661e-04],
         [ 5.482e-02],
         [-7.472e-03],
         [-1.262e-04],
         [ 7.789e-02],
         [ 1.282e-01],
         [ 4.708e-02],
         [-3.703e-03],
         [-3.110e-02],
         [ 2.604e-02]],

        [[ 6.704e-06],
         [ 9.560e-04],
         [-1.908e-03],
         [-3.395e-04],
         [-1.628e-03],
         [-3.184e-04],
         [ 2.985e-03],
         [ 5.106e-04],
         [-6.532e-04],
         [-1.035e-05]],

        [[ 4.237e-01],
         [ 8.263e-02],
         [-6.460e-03],
         [-3.084e-04],
         [-4.998e-03],
         [-1.407e-03],
         [ 1.026e-01],
         [ 1.744e-03],
         [ 1.194e-01],
         [ 4.123e-03]],

        [[-2.095e-04],
         [ 2.749e-02],
         [ 4.665e-02],
         [-1.387e-03],
         [ 2.385e-02],
         [ 4.864e-02],
         [ 8.400e-02],
         [-4.665e-02],
         [-2.332e-02],
         [-1.458e-02]],

        [[-4.937e-03],
         [ 5.935e-02],
         [-1.503e-03],
         [ 2.556e-02],
         [-1.445e-02],
         [ 2.738e-03],
         [ 4.699e-06],
         [-8.643e-05],
         [ 1.994e-03],
         [ 1.889e-01]],

        [[ 5.213e-04],
         [ 1.375e-04],
         [-2.209e-04],
         [-6.633e-05],
         [-6.955e-04],
         [-5.986e-04],
         [-2.578e-04],
         [ 1.354e-04],
         [-3.341e-05],
         [-3.261e-04]],

        [[ 6.276e-02],
         [-1.900e-03],
         [ 3.420e-02],
         [-3.123e-03],
         [-4.260e-04],
         [ 3.338e-03],
         [ 9.193e-02],
         [-2.721e-03],
         [-4.201e-03],
         [ 1.048e-01]],

        [[-6.560e-04],
         [-1.773e-04],
         [-4.041e-03],
         [-3.705e-04],
         [ 6.759e-05],
         [-4.886e-05],
         [-3.366e-06],
         [ 7.767e-04],
         [ 7.085e-06],
         [-4.624e-04]],

        [[ 2.857e-01],
         [-3.125e-03],
         [-2.328e-03],
         [ 2.479e-01],
         [ 4.620e-04],
         [ 6.861e-03],
         [ 6.915e-02],
         [ 4.099e-01],
         [ 8.933e-05],
         [ 1.786e-04]],

        [[-2.651e-03],
         [-6.129e-03],
         [ 5.862e-01],
         [-1.259e-02],
         [ 4.165e-01],
         [ 1.196e-01],
         [ 4.317e-01],
         [ 7.806e-03],
         [ 9.432e-04],
         [ 3.904e-01]],

        [[ 5.566e-02],
         [-8.795e-04],
         [ 5.427e-02],
         [-2.331e-02],
         [ 1.922e-02],
         [-1.591e-04],
         [ 6.489e-03],
         [-7.636e-04],
         [ 5.131e-03],
         [ 1.456e-02]],

        [[-2.681e-04],
         [-6.074e-04],
         [-1.467e-03],
         [-2.569e-03],
         [-4.950e-03],
         [-1.853e-03],
         [-8.341e-04],
         [-1.093e-04],
         [ 3.211e-04],
         [ 2.703e-03]],

        [[-9.895e-03],
         [ 1.199e-01],
         [ 1.054e-02],
         [ 1.027e-03],
         [-1.949e-02],
         [ 7.762e-03],
         [ 1.136e-03],
         [ 2.654e-02],
         [ 2.874e-02],
         [-5.860e-03]],

        [[-3.695e-03],
         [-9.230e-03],
         [ 2.468e-02],
         [ 8.833e-02],
         [ 1.077e-01],
         [-6.890e-03],
         [-1.313e-03],
         [ 1.437e-01],
         [-1.061e-03],
         [ 1.427e-01]]], device='cuda:0')
v tensor([[[7.951e-04],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.870e-04],
         [1.000e-12]],

        [[1.000e-12],
         [1.324e-05],
         [8.618e-02],
         [5.376e-04],
         [1.379e-01],
         [3.424e-03],
         [1.000e-12],
         [2.091e-03],
         [5.358e-01],
         [1.000e-12]],

        [[1.000e-12],
         [2.618e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.674e-04],
         [3.376e-02]],

        [[2.951e-01],
         [2.041e-01],
         [1.000e-12],
         [9.008e-02],
         [2.302e-01],
         [3.049e-01],
         [1.732e-04],
         [1.000e-12],
         [1.000e-12],
         [1.085e-01]],

        [[1.354e-01],
         [1.578e-03],
         [4.057e-01],
         [3.053e-04],
         [7.414e-03],
         [4.595e-02],
         [9.919e-03],
         [1.000e-12],
         [1.000e-12],
         [4.217e-01]],

        [[6.886e-01],
         [4.556e-02],
         [8.953e-02],
         [1.000e-12],
         [3.240e-04],
         [9.502e-02],
         [1.000e-12],
         [2.042e-01],
         [2.628e-04],
         [1.000e-12]],

        [[1.000e-12],
         [5.482e-02],
         [1.000e-12],
         [1.000e-12],
         [7.789e-02],
         [1.282e-01],
         [4.708e-02],
         [1.000e-12],
         [1.000e-12],
         [2.604e-02]],

        [[6.704e-06],
         [9.560e-04],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.985e-03],
         [5.106e-04],
         [1.000e-12],
         [1.000e-12]],

        [[4.237e-01],
         [8.263e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.026e-01],
         [1.744e-03],
         [1.194e-01],
         [4.123e-03]],

        [[1.000e-12],
         [2.749e-02],
         [4.665e-02],
         [1.000e-12],
         [2.385e-02],
         [4.864e-02],
         [8.400e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [5.935e-02],
         [1.000e-12],
         [2.556e-02],
         [1.000e-12],
         [2.738e-03],
         [4.699e-06],
         [1.000e-12],
         [1.994e-03],
         [1.889e-01]],

        [[5.213e-04],
         [1.375e-04],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.354e-04],
         [1.000e-12],
         [1.000e-12]],

        [[6.276e-02],
         [1.000e-12],
         [3.420e-02],
         [1.000e-12],
         [1.000e-12],
         [3.338e-03],
         [9.193e-02],
         [1.000e-12],
         [1.000e-12],
         [1.048e-01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.759e-05],
         [1.000e-12],
         [1.000e-12],
         [7.767e-04],
         [7.085e-06],
         [1.000e-12]],

        [[2.857e-01],
         [1.000e-12],
         [1.000e-12],
         [2.479e-01],
         [4.620e-04],
         [6.861e-03],
         [6.915e-02],
         [4.099e-01],
         [8.933e-05],
         [1.786e-04]],

        [[1.000e-12],
         [1.000e-12],
         [5.862e-01],
         [1.000e-12],
         [4.165e-01],
         [1.196e-01],
         [4.317e-01],
         [7.806e-03],
         [9.432e-04],
         [3.904e-01]],

        [[5.566e-02],
         [1.000e-12],
         [5.427e-02],
         [1.000e-12],
         [1.922e-02],
         [1.000e-12],
         [6.489e-03],
         [1.000e-12],
         [5.131e-03],
         [1.456e-02]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.211e-04],
         [2.703e-03]],

        [[1.000e-12],
         [1.199e-01],
         [1.054e-02],
         [1.027e-03],
         [1.000e-12],
         [7.762e-03],
         [1.136e-03],
         [2.654e-02],
         [2.874e-02],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [2.468e-02],
         [8.833e-02],
         [1.077e-01],
         [1.000e-12],
         [1.000e-12],
         [1.437e-01],
         [1.000e-12],
         [1.427e-01]]], device='cuda:0')
v before min max tensor([[ 1.093e-03],
        [ 6.364e-01],
        [ 1.785e-03],
        [ 7.373e-01],
        [ 8.091e-02],
        [ 3.917e-01],
        [ 4.186e-01],
        [-1.384e-03],
        [-1.989e-02],
        [ 1.060e-01],
        [ 1.454e-01],
        [-2.200e-04],
        [ 4.775e-02],
        [-1.843e-04],
        [ 4.609e-03],
        [ 4.832e-01],
        [ 6.329e-02],
        [-5.724e-05],
        [ 1.348e-02],
        [-5.869e-02]], device='cuda:0')
v tensor([[1.093e-03],
        [6.364e-01],
        [1.785e-03],
        [7.373e-01],
        [8.091e-02],
        [3.917e-01],
        [4.186e-01],
        [1.000e-12],
        [1.000e-12],
        [1.060e-01],
        [1.454e-01],
        [1.000e-12],
        [4.775e-02],
        [1.000e-12],
        [4.609e-03],
        [4.832e-01],
        [6.329e-02],
        [1.000e-12],
        [1.348e-02],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-1.403e-05, -2.085e-06, -1.661e-05,  ...,  3.763e-05,  2.463e-05,
         -3.949e-05],
        [-5.002e-05, -1.511e-05,  3.318e-05,  ..., -1.632e-05,  3.135e-06,
          3.605e-06],
        [ 7.383e-05, -9.998e-06, -2.386e-05,  ...,  5.908e-06, -7.106e-05,
          7.336e-06],
        ...,
        [ 4.065e-04, -4.782e-06, -5.233e-05,  ..., -6.654e-06,  1.725e-05,
          1.361e-04],
        [-2.010e-05,  7.415e-06, -1.778e-05,  ..., -7.451e-05,  6.449e-05,
         -1.248e-04],
        [ 5.415e-05, -1.130e-05,  5.858e-06,  ..., -1.491e-05,  1.111e-04,
         -1.756e-04]], device='cuda:0')
s after update for 1 param tensor([[3.235e-03, 3.040e-05, 6.830e-04,  ..., 1.889e-04, 1.243e-02,
         5.601e-04],
        [4.309e-03, 7.683e-04, 7.435e-03,  ..., 5.465e-04, 7.063e-04,
         1.741e-04],
        [2.122e-03, 5.037e-03, 2.469e-03,  ..., 2.470e-04, 6.380e-03,
         1.267e-04],
        ...,
        [5.358e-02, 7.162e-03, 9.060e-04,  ..., 1.224e-03, 2.804e-03,
         2.912e-03],
        [1.060e-03, 7.841e-04, 2.620e-04,  ..., 1.813e-03, 1.291e-03,
         1.955e-02],
        [1.702e-02, 7.005e-05, 6.485e-04,  ..., 1.373e-04, 9.053e-03,
         1.182e-02]], device='cuda:0')
b after update for 1 param tensor([[0.340, 0.033, 0.156,  ..., 0.082, 0.667, 0.142],
        [0.393, 0.166, 0.516,  ..., 0.140, 0.159, 0.079],
        [0.276, 0.425, 0.297,  ..., 0.094, 0.478, 0.067],
        ...,
        [1.385, 0.506, 0.180,  ..., 0.209, 0.317, 0.323],
        [0.195, 0.168, 0.097,  ..., 0.255, 0.215, 0.837],
        [0.781, 0.050, 0.152,  ..., 0.070, 0.569, 0.651]], device='cuda:0')
clipping threshold 2.782537623814828
a after update for 1 param tensor([ 9.591e-06,  1.218e-04, -5.670e-06,  4.160e-06,  2.978e-06, -2.614e-05,
         2.530e-05,  2.443e-05, -9.313e-06,  8.023e-06, -1.682e-05,  2.637e-06,
         6.280e-06, -2.639e-05, -8.209e-05, -2.001e-05,  2.020e-05, -1.533e-05,
         1.946e-05, -1.209e-05, -8.638e-06, -1.254e-05, -1.070e-05, -1.154e-06,
        -3.069e-04, -8.611e-06,  1.042e-05, -5.115e-06, -2.770e-05, -7.247e-06,
         2.038e-05, -5.247e-05,  7.449e-05, -8.591e-06,  1.135e-05, -2.396e-06,
         8.950e-06,  1.175e-05, -1.075e-05,  1.399e-05, -3.239e-05,  8.496e-06,
        -1.701e-05, -3.697e-05, -3.059e-05, -1.040e-05, -4.490e-06, -3.293e-06,
         8.049e-06,  4.529e-05, -2.883e-04,  6.140e-05, -2.020e-06, -3.649e-06,
         8.471e-06,  2.639e-05, -1.843e-05,  3.116e-05, -6.210e-06, -4.838e-05,
        -4.521e-06,  1.416e-05, -1.520e-04, -1.102e-05, -5.356e-05, -2.830e-06,
         9.879e-06,  4.837e-05, -9.819e-05,  2.148e-05, -2.743e-06,  4.530e-05,
         1.588e-06, -2.979e-06,  2.178e-05,  2.777e-06,  2.808e-05, -4.187e-06,
        -5.187e-07,  2.744e-06,  1.288e-05,  1.098e-04,  1.642e-05,  1.793e-06,
        -1.275e-04,  2.579e-05,  1.397e-05,  2.142e-05, -1.528e-05,  1.494e-05,
        -5.370e-05, -6.530e-05, -3.944e-05, -9.751e-05,  2.271e-06, -7.938e-06,
         3.952e-07,  4.161e-06, -4.779e-05, -7.050e-06, -1.669e-05, -1.558e-05,
        -1.585e-05,  1.465e-06,  3.007e-05,  1.862e-05,  2.324e-04,  1.219e-05,
         6.025e-06,  7.188e-05, -9.473e-07, -5.484e-06, -3.047e-05,  2.186e-05,
        -9.968e-06,  1.018e-05,  8.351e-06, -1.746e-05, -2.695e-05, -2.182e-05,
        -1.726e-06,  1.044e-05, -1.044e-05,  2.070e-05,  4.416e-06, -1.781e-05,
         2.766e-05, -2.995e-05,  4.659e-05, -1.039e-05, -1.118e-04,  1.406e-04,
        -2.151e-05, -1.995e-05,  1.355e-05, -4.548e-06,  3.170e-06,  2.370e-06,
        -2.978e-05, -3.516e-05, -9.374e-07,  1.076e-05,  3.974e-06, -2.241e-05,
         1.624e-05, -8.264e-06, -2.512e-05, -3.631e-04,  2.019e-06, -7.947e-06,
        -8.527e-06, -1.633e-06,  3.344e-05,  6.066e-05, -1.090e-04, -7.650e-05,
        -1.429e-04,  6.461e-06,  1.158e-06, -1.098e-06,  1.609e-05, -3.692e-06,
         5.890e-05,  1.852e-05, -8.216e-06,  2.489e-05,  8.626e-05,  1.093e-05,
        -9.450e-05,  1.442e-05,  1.369e-05, -7.591e-05, -1.085e-06,  5.946e-06,
         2.752e-06,  5.276e-05, -1.258e-06, -3.546e-07, -1.499e-06, -4.025e-06,
         5.490e-05,  8.345e-06,  7.292e-06,  4.354e-07, -8.744e-06,  1.264e-04,
        -6.535e-07,  7.007e-05, -1.021e-04, -7.899e-07, -3.959e-05,  5.283e-05,
         6.573e-06,  7.092e-06,  6.537e-05,  4.442e-06, -3.905e-05, -1.351e-05,
        -2.722e-05,  1.737e-06], device='cuda:0')
s after update for 1 param tensor([4.763e-05, 1.194e-02, 3.202e-05, 4.939e-05, 2.205e-05, 1.434e-02,
        1.925e-04, 5.227e-04, 5.724e-04, 3.150e-04, 1.514e-04, 3.472e-06,
        5.312e-04, 2.014e-03, 1.234e-03, 1.740e-03, 1.326e-03, 1.676e-04,
        3.282e-03, 2.302e-03, 1.949e-04, 2.170e-03, 1.882e-04, 2.714e-06,
        4.336e-02, 1.524e-04, 1.709e-03, 7.653e-05, 3.069e-03, 5.828e-05,
        1.494e-03, 3.041e-03, 3.538e-03, 4.737e-05, 1.155e-04, 1.073e-03,
        5.259e-05, 3.688e-03, 6.398e-04, 4.829e-04, 1.720e-04, 1.837e-03,
        1.214e-04, 2.471e-03, 9.732e-04, 9.884e-05, 1.499e-03, 2.623e-04,
        2.453e-04, 7.067e-03, 1.977e-02, 2.280e-03, 1.440e-05, 2.377e-05,
        2.163e-03, 4.874e-03, 5.184e-04, 6.799e-04, 2.217e-04, 1.766e-03,
        4.090e-05, 1.438e-03, 4.790e-03, 2.462e-04, 3.056e-03, 2.535e-04,
        1.702e-03, 1.164e-02, 5.570e-03, 1.334e-03, 4.781e-04, 9.921e-04,
        1.882e-06, 2.852e-05, 4.582e-03, 3.661e-05, 2.898e-03, 3.381e-05,
        4.588e-04, 8.968e-06, 2.573e-03, 1.086e-02, 3.788e-04, 3.593e-04,
        1.305e-02, 2.518e-04, 1.266e-03, 2.640e-04, 1.754e-04, 5.105e-04,
        1.063e-02, 1.108e-02, 4.368e-04, 1.911e-02, 2.132e-05, 6.076e-05,
        9.545e-05, 5.085e-05, 3.493e-03, 4.806e-04, 2.609e-03, 1.825e-03,
        1.925e-03, 1.142e-04, 1.616e-03, 3.179e-04, 3.592e-02, 1.374e-04,
        4.548e-05, 1.040e-03, 1.535e-04, 1.194e-03, 2.330e-03, 2.549e-03,
        5.367e-04, 6.504e-04, 4.835e-05, 7.739e-04, 2.628e-03, 4.107e-03,
        7.652e-06, 2.184e-03, 2.329e-04, 3.387e-03, 1.108e-04, 8.096e-05,
        2.734e-03, 9.842e-03, 6.930e-04, 3.464e-03, 2.021e-02, 2.604e-02,
        3.112e-03, 2.948e-04, 1.900e-03, 6.145e-04, 1.106e-05, 2.184e-04,
        2.448e-03, 3.430e-04, 1.012e-03, 1.665e-03, 7.150e-06, 6.022e-04,
        2.433e-04, 2.435e-04, 1.008e-04, 5.431e-02, 5.670e-03, 7.233e-05,
        1.907e-03, 7.790e-04, 3.869e-04, 3.649e-03, 6.462e-03, 1.229e-02,
        5.751e-03, 2.591e-03, 3.993e-04, 1.254e-03, 2.193e-03, 2.190e-05,
        2.671e-03, 5.704e-04, 2.733e-03, 5.147e-03, 1.530e-02, 2.800e-05,
        1.680e-02, 1.367e-03, 1.289e-03, 1.215e-02, 1.768e-05, 1.825e-04,
        1.189e-05, 1.207e-02, 1.882e-06, 1.767e-04, 1.567e-05, 5.953e-04,
        1.562e-03, 1.874e-05, 1.438e-04, 1.882e-06, 5.336e-04, 2.589e-02,
        3.598e-04, 2.218e-02, 1.783e-02, 3.549e-05, 3.979e-03, 1.713e-03,
        9.320e-04, 1.876e-04, 3.481e-03, 4.825e-04, 8.365e-03, 1.116e-03,
        6.146e-03, 1.282e-03], device='cuda:0')
b after update for 1 param tensor([0.041, 0.654, 0.034, 0.042, 0.028, 0.717, 0.083, 0.137, 0.143, 0.106,
        0.074, 0.011, 0.138, 0.269, 0.210, 0.250, 0.218, 0.077, 0.343, 0.287,
        0.084, 0.279, 0.082, 0.010, 1.246, 0.074, 0.247, 0.052, 0.332, 0.046,
        0.231, 0.330, 0.356, 0.041, 0.064, 0.196, 0.043, 0.363, 0.151, 0.132,
        0.078, 0.256, 0.066, 0.298, 0.187, 0.060, 0.232, 0.097, 0.094, 0.503,
        0.841, 0.286, 0.023, 0.029, 0.278, 0.418, 0.136, 0.156, 0.089, 0.251,
        0.038, 0.227, 0.414, 0.094, 0.331, 0.095, 0.247, 0.646, 0.447, 0.219,
        0.131, 0.189, 0.008, 0.032, 0.405, 0.036, 0.322, 0.035, 0.128, 0.018,
        0.304, 0.624, 0.116, 0.113, 0.684, 0.095, 0.213, 0.097, 0.079, 0.135,
        0.617, 0.630, 0.125, 0.827, 0.028, 0.047, 0.058, 0.043, 0.354, 0.131,
        0.306, 0.256, 0.263, 0.064, 0.241, 0.107, 1.134, 0.070, 0.040, 0.193,
        0.074, 0.207, 0.289, 0.302, 0.139, 0.153, 0.042, 0.166, 0.307, 0.384,
        0.017, 0.280, 0.091, 0.348, 0.063, 0.054, 0.313, 0.594, 0.158, 0.352,
        0.851, 0.966, 0.334, 0.103, 0.261, 0.148, 0.020, 0.088, 0.296, 0.111,
        0.190, 0.244, 0.016, 0.147, 0.093, 0.093, 0.060, 1.395, 0.451, 0.051,
        0.261, 0.167, 0.118, 0.362, 0.481, 0.664, 0.454, 0.305, 0.120, 0.212,
        0.280, 0.028, 0.309, 0.143, 0.313, 0.429, 0.740, 0.032, 0.776, 0.221,
        0.215, 0.660, 0.025, 0.081, 0.021, 0.657, 0.008, 0.080, 0.024, 0.146,
        0.237, 0.026, 0.072, 0.008, 0.138, 0.963, 0.114, 0.891, 0.799, 0.036,
        0.378, 0.248, 0.183, 0.082, 0.353, 0.131, 0.547, 0.200, 0.469, 0.214],
       device='cuda:0')
clipping threshold 2.782537623814828
a after update for 1 param tensor([[[ 7.314e-05],
         [-3.428e-06],
         [ 4.748e-05],
         [-3.655e-05],
         [-1.353e-04],
         [ 9.084e-05],
         [ 1.169e-04],
         [ 3.918e-05],
         [ 8.826e-05],
         [-6.233e-07]],

        [[ 6.235e-06],
         [-1.516e-05],
         [-9.713e-04],
         [-4.913e-05],
         [-1.072e-03],
         [ 1.023e-04],
         [-1.059e-04],
         [-1.547e-04],
         [-1.858e-03],
         [-4.255e-04]],

        [[-2.389e-05],
         [-5.136e-05],
         [-2.681e-05],
         [-2.458e-04],
         [-4.816e-05],
         [-1.408e-04],
         [-4.155e-05],
         [-6.560e-05],
         [-3.833e-05],
         [-4.847e-04]],

        [[-1.182e-03],
         [-1.186e-03],
         [ 1.699e-05],
         [-1.017e-03],
         [-1.290e-03],
         [-1.489e-03],
         [-4.251e-05],
         [-1.284e-05],
         [-6.467e-04],
         [-9.380e-04]],

        [[ 1.224e-03],
         [-7.158e-05],
         [ 1.339e-03],
         [ 3.822e-05],
         [ 5.751e-04],
         [ 8.193e-04],
         [ 1.467e-04],
         [ 7.803e-04],
         [ 6.505e-06],
         [ 1.662e-03]],

        [[ 1.742e-03],
         [ 4.560e-04],
         [ 1.091e-03],
         [ 5.544e-06],
         [ 1.064e-04],
         [ 1.265e-03],
         [ 5.069e-05],
         [ 1.040e-03],
         [ 6.499e-05],
         [ 2.845e-05]],

        [[-2.567e-08],
         [ 8.334e-04],
         [ 1.035e-04],
         [ 5.687e-06],
         [ 1.326e-03],
         [ 7.068e-04],
         [ 3.952e-04],
         [ 1.165e-04],
         [ 3.273e-04],
         [ 5.943e-04]],

        [[-1.902e-05],
         [ 7.051e-05],
         [ 3.856e-05],
         [-2.705e-06],
         [ 2.035e-05],
         [-2.009e-07],
         [-1.149e-04],
         [ 4.957e-05],
         [ 2.141e-05],
         [ 1.482e-06]],

        [[-1.376e-03],
         [-5.942e-04],
         [-1.120e-04],
         [ 2.016e-05],
         [-4.720e-05],
         [-6.369e-05],
         [-6.179e-04],
         [-1.097e-04],
         [-7.980e-04],
         [-1.503e-04]],

        [[ 3.023e-05],
         [ 5.291e-04],
         [ 4.715e-04],
         [ 9.496e-06],
         [ 4.122e-04],
         [ 4.161e-04],
         [ 6.094e-04],
         [ 5.406e-04],
         [ 1.422e-04],
         [-1.971e-05]],

        [[ 3.970e-04],
         [ 6.137e-04],
         [-1.325e-05],
         [ 6.785e-04],
         [ 6.522e-04],
         [ 1.017e-04],
         [ 4.557e-06],
         [ 8.596e-06],
         [ 8.713e-05],
         [ 9.739e-04]],

        [[-5.841e-05],
         [ 2.592e-05],
         [-2.668e-05],
         [-3.309e-06],
         [ 1.019e-05],
         [ 4.427e-05],
         [ 9.169e-06],
         [-1.302e-05],
         [ 1.887e-05],
         [-4.402e-06]],

        [[ 4.193e-04],
         [-6.517e-05],
         [ 3.273e-04],
         [ 4.685e-07],
         [ 7.195e-05],
         [ 8.506e-05],
         [ 6.540e-04],
         [ 1.603e-05],
         [ 9.185e-05],
         [ 6.644e-04]],

        [[-3.186e-06],
         [ 5.839e-06],
         [ 1.149e-05],
         [ 8.887e-06],
         [-1.614e-05],
         [ 8.973e-06],
         [ 3.972e-05],
         [ 3.640e-05],
         [ 2.155e-05],
         [-2.032e-05]],

        [[ 1.426e-03],
         [ 2.666e-05],
         [ 5.124e-05],
         [ 1.144e-03],
         [ 6.584e-05],
         [ 2.322e-04],
         [ 9.085e-04],
         [ 1.258e-03],
         [ 4.289e-05],
         [ 4.196e-05]],

        [[-1.035e-04],
         [ 6.368e-05],
         [-1.743e-03],
         [-4.868e-04],
         [-1.592e-03],
         [-6.257e-04],
         [-1.575e-03],
         [-2.065e-04],
         [-4.585e-05],
         [-1.359e-03]],

        [[-4.906e-04],
         [ 4.817e-06],
         [-7.943e-04],
         [-1.630e-04],
         [-4.257e-04],
         [ 2.806e-06],
         [-5.005e-04],
         [ 2.399e-05],
         [-3.957e-04],
         [-8.750e-04]],

        [[ 6.026e-07],
         [ 3.335e-06],
         [-5.161e-05],
         [ 2.744e-05],
         [-1.134e-05],
         [-2.052e-05],
         [ 1.144e-05],
         [-1.680e-05],
         [ 2.282e-05],
         [ 1.779e-04]],

        [[ 1.543e-04],
         [-6.989e-04],
         [-4.488e-04],
         [ 6.678e-05],
         [-3.712e-04],
         [-3.882e-04],
         [-3.477e-04],
         [-3.533e-04],
         [-4.230e-04],
         [-1.134e-04]],

        [[-5.373e-04],
         [-2.197e-04],
         [-6.426e-04],
         [-8.006e-04],
         [-1.169e-03],
         [-7.318e-04],
         [-3.617e-05],
         [-9.636e-04],
         [ 1.578e-05],
         [-7.643e-04]]], device='cuda:0')
s after update for 1 param tensor([[[9.100e-03],
         [4.408e-03],
         [8.373e-04],
         [2.652e-03],
         [1.586e-02],
         [2.981e-03],
         [2.783e-03],
         [5.371e-04],
         [7.068e-03],
         [5.136e-05]],

        [[3.234e-05],
         [1.152e-03],
         [1.056e-01],
         [7.333e-03],
         [1.285e-01],
         [1.854e-02],
         [2.535e-02],
         [1.509e-02],
         [2.439e-01],
         [6.644e-02]],

        [[1.869e-03],
         [1.621e-02],
         [4.474e-04],
         [1.478e-02],
         [2.098e-02],
         [9.893e-03],
         [1.585e-03],
         [1.341e-03],
         [4.097e-03],
         [5.986e-02]],

        [[1.763e-01],
         [1.476e-01],
         [2.127e-03],
         [1.086e-01],
         [1.632e-01],
         [1.869e-01],
         [4.166e-03],
         [1.216e-02],
         [4.503e-02],
         [1.154e-01]],

        [[1.331e-01],
         [1.344e-02],
         [2.050e-01],
         [5.552e-03],
         [4.567e-02],
         [7.898e-02],
         [3.254e-02],
         [4.910e-02],
         [1.864e-04],
         [2.237e-01]],

        [[2.721e-01],
         [6.846e-02],
         [1.124e-01],
         [6.094e-04],
         [6.275e-03],
         [1.276e-01],
         [1.893e-03],
         [1.502e-01],
         [5.155e-03],
         [2.683e-04]],

        [[8.571e-04],
         [8.863e-02],
         [8.324e-03],
         [1.391e-04],
         [1.376e-01],
         [1.142e-01],
         [7.283e-02],
         [5.463e-03],
         [3.407e-02],
         [6.353e-02]],

        [[8.213e-04],
         [9.799e-03],
         [2.090e-03],
         [3.803e-04],
         [2.082e-03],
         [3.504e-04],
         [1.730e-02],
         [7.150e-03],
         [7.384e-04],
         [1.147e-05]],

        [[2.092e-01],
         [9.233e-02],
         [7.349e-03],
         [6.200e-04],
         [6.025e-03],
         [1.576e-03],
         [1.024e-01],
         [1.343e-02],
         [1.107e-01],
         [2.041e-02]],

        [[4.553e-04],
         [5.998e-02],
         [7.085e-02],
         [1.532e-03],
         [4.987e-02],
         [7.038e-02],
         [9.221e-02],
         [5.748e-02],
         [3.617e-02],
         [1.668e-02]],

        [[1.852e-02],
         [7.854e-02],
         [1.647e-03],
         [6.175e-02],
         [4.412e-02],
         [1.658e-02],
         [6.855e-04],
         [1.223e-04],
         [1.414e-02],
         [1.409e-01]],

        [[7.290e-03],
         [3.729e-03],
         [2.695e-04],
         [8.131e-05],
         [9.698e-04],
         [1.032e-03],
         [2.928e-04],
         [3.707e-03],
         [1.222e-04],
         [7.701e-04]],

        [[8.177e-02],
         [2.350e-03],
         [5.867e-02],
         [1.098e-02],
         [2.281e-03],
         [1.827e-02],
         [9.689e-02],
         [3.036e-03],
         [5.046e-03],
         [1.040e-01]],

        [[7.207e-04],
         [2.799e-04],
         [5.528e-03],
         [4.345e-04],
         [2.606e-03],
         [9.848e-05],
         [3.298e-04],
         [8.859e-03],
         [8.635e-04],
         [1.114e-03]],

        [[1.784e-01],
         [3.432e-03],
         [2.586e-03],
         [1.605e-01],
         [6.823e-03],
         [2.687e-02],
         [9.008e-02],
         [2.066e-01],
         [2.998e-03],
         [4.229e-03]],

        [[2.932e-03],
         [8.356e-03],
         [2.516e-01],
         [2.780e-02],
         [2.187e-01],
         [1.096e-01],
         [2.167e-01],
         [2.802e-02],
         [9.797e-03],
         [2.042e-01]],

        [[7.486e-02],
         [1.034e-03],
         [8.345e-02],
         [2.624e-02],
         [4.491e-02],
         [1.742e-04],
         [3.114e-02],
         [8.364e-04],
         [3.018e-02],
         [7.457e-02]],

        [[3.245e-04],
         [8.160e-04],
         [1.641e-03],
         [2.968e-03],
         [5.748e-03],
         [2.047e-03],
         [1.336e-03],
         [1.336e-04],
         [5.668e-03],
         [1.823e-02]],

        [[1.609e-02],
         [1.098e-01],
         [3.643e-02],
         [1.294e-02],
         [2.509e-02],
         [2.989e-02],
         [1.321e-02],
         [5.277e-02],
         [5.439e-02],
         [2.277e-02]],

        [[2.676e-02],
         [1.385e-02],
         [5.917e-02],
         [9.785e-02],
         [1.242e-01],
         [5.136e-02],
         [1.607e-03],
         [1.269e-01],
         [1.471e-03],
         [1.199e-01]]], device='cuda:0')
b after update for 1 param tensor([[[0.571],
         [0.397],
         [0.173],
         [0.308],
         [0.754],
         [0.327],
         [0.316],
         [0.139],
         [0.503],
         [0.043]],

        [[0.034],
         [0.203],
         [1.945],
         [0.513],
         [2.145],
         [0.815],
         [0.953],
         [0.735],
         [2.956],
         [1.543]],

        [[0.259],
         [0.762],
         [0.127],
         [0.728],
         [0.867],
         [0.595],
         [0.238],
         [0.219],
         [0.383],
         [1.464]],

        [[2.513],
         [2.299],
         [0.276],
         [1.973],
         [2.418],
         [2.587],
         [0.386],
         [0.660],
         [1.270],
         [2.033]],

        [[2.183],
         [0.694],
         [2.710],
         [0.446],
         [1.279],
         [1.682],
         [1.080],
         [1.326],
         [0.082],
         [2.831]],

        [[3.122],
         [1.566],
         [2.007],
         [0.148],
         [0.474],
         [2.138],
         [0.260],
         [2.319],
         [0.430],
         [0.098]],

        [[0.175],
         [1.782],
         [0.546],
         [0.071],
         [2.220],
         [2.023],
         [1.615],
         [0.442],
         [1.105],
         [1.509]],

        [[0.172],
         [0.592],
         [0.274],
         [0.117],
         [0.273],
         [0.112],
         [0.787],
         [0.506],
         [0.163],
         [0.020]],

        [[2.737],
         [1.819],
         [0.513],
         [0.149],
         [0.465],
         [0.238],
         [1.915],
         [0.693],
         [1.992],
         [0.855]],

        [[0.128],
         [1.466],
         [1.593],
         [0.234],
         [1.336],
         [1.588],
         [1.817],
         [1.435],
         [1.138],
         [0.773]],

        [[0.814],
         [1.677],
         [0.243],
         [1.487],
         [1.257],
         [0.771],
         [0.157],
         [0.066],
         [0.712],
         [2.247]],

        [[0.511],
         [0.365],
         [0.098],
         [0.054],
         [0.186],
         [0.192],
         [0.102],
         [0.364],
         [0.066],
         [0.166]],

        [[1.711],
         [0.290],
         [1.450],
         [0.627],
         [0.286],
         [0.809],
         [1.863],
         [0.330],
         [0.425],
         [1.930]],

        [[0.161],
         [0.100],
         [0.445],
         [0.125],
         [0.306],
         [0.059],
         [0.109],
         [0.563],
         [0.176],
         [0.200]],

        [[2.528],
         [0.351],
         [0.304],
         [2.398],
         [0.494],
         [0.981],
         [1.796],
         [2.720],
         [0.328],
         [0.389]],

        [[0.324],
         [0.547],
         [3.002],
         [0.998],
         [2.799],
         [1.981],
         [2.786],
         [1.002],
         [0.592],
         [2.704]],

        [[1.638],
         [0.192],
         [1.729],
         [0.969],
         [1.268],
         [0.079],
         [1.056],
         [0.173],
         [1.040],
         [1.634]],

        [[0.108],
         [0.171],
         [0.242],
         [0.326],
         [0.454],
         [0.271],
         [0.219],
         [0.069],
         [0.451],
         [0.808]],

        [[0.759],
         [1.983],
         [1.142],
         [0.681],
         [0.948],
         [1.035],
         [0.688],
         [1.375],
         [1.396],
         [0.903]],

        [[0.979],
         [0.704],
         [1.456],
         [1.872],
         [2.110],
         [1.356],
         [0.240],
         [2.132],
         [0.230],
         [2.072]]], device='cuda:0')
clipping threshold 2.782537623814828
a after update for 1 param tensor([[ 6.422e-05],
        [-2.307e-03],
        [-1.378e-04],
        [-1.972e-03],
        [ 7.527e-04],
        [ 1.504e-03],
        [ 1.336e-03],
        [ 1.616e-05],
        [-8.847e-04],
        [ 7.083e-04],
        [ 7.851e-04],
        [ 4.080e-06],
        [ 5.220e-04],
        [ 1.160e-06],
        [ 7.713e-04],
        [-1.609e-03],
        [-8.343e-04],
        [-6.476e-06],
        [-3.281e-04],
        [-4.880e-04]], device='cuda:0')
s after update for 1 param tensor([[1.051e-02],
        [2.836e-01],
        [1.374e-02],
        [2.851e-01],
        [9.525e-02],
        [2.062e-01],
        [2.093e-01],
        [1.724e-03],
        [6.557e-02],
        [1.040e-01],
        [1.241e-01],
        [2.960e-04],
        [6.965e-02],
        [2.287e-04],
        [6.279e-02],
        [2.285e-01],
        [8.736e-02],
        [1.483e-04],
        [3.893e-02],
        [6.602e-02]], device='cuda:0')
b after update for 1 param tensor([[0.613],
        [3.187],
        [0.702],
        [3.195],
        [1.847],
        [2.718],
        [2.738],
        [0.249],
        [1.533],
        [1.930],
        [2.108],
        [0.103],
        [1.580],
        [0.091],
        [1.500],
        [2.861],
        [1.769],
        [0.073],
        [1.181],
        [1.538]], device='cuda:0')
clipping threshold 2.782537623814828
||w||^2 0.1494399755884843
exp ma of ||w||^2 0.17651536641246257
||w|| 0.3865746701330602
exp ma of ||w|| 0.40791968495471326
||w||^2 0.19552496769398614
exp ma of ||w||^2 0.17979715070805405
||w|| 0.44218205265929345
exp ma of ||w|| 0.4097386076599442
||w||^2 0.19148058400591322
exp ma of ||w||^2 0.209358386662132
||w|| 0.4375849449031733
exp ma of ||w|| 0.4433207137431313
||w||^2 0.14527543747672125
exp ma of ||w||^2 0.21757851486115126
||w|| 0.3811501508286744
exp ma of ||w|| 0.4543113942343897
||w||^2 0.12495391234225935
exp ma of ||w||^2 0.34874159722486797
||w|| 0.3534882067937477
exp ma of ||w|| 0.5617859907598984
||w||^2 1.1715514412333667
exp ma of ||w||^2 0.5062663567355631
||w|| 1.0823822990207141
exp ma of ||w|| 0.6840628489524317
||w||^2 0.42117869867269947
exp ma of ||w||^2 0.5863727994195044
||w|| 0.648982818472646
exp ma of ||w|| 0.7408928963947254
v before min max tensor([[-33.311,   0.343, -25.782,  ..., -22.742, -20.042,   4.068],
        [-42.409,  12.202,  -7.040,  ..., -13.245, -26.352, -24.124],
        [-26.251,   3.121, -28.638,  ..., -26.324, -31.567,  -6.094],
        ...,
        [-24.482, -34.298, -22.111,  ..., -20.346,  -9.637, -25.434],
        [-32.532, -29.157,  -1.006,  ..., -12.340, -29.375,  -2.736],
        [-14.578, -32.635,  16.547,  ..., 106.118, -30.988,   1.561]],
       device='cuda:0')
v tensor([[1.000e-12, 3.433e-01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         4.068e+00],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 3.121e+00, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.561e+00]], device='cuda:0')
v before min max tensor([-35.948, -19.994, -35.858, -24.898,  29.186, -31.528, -27.341, -22.904,
        -31.812, -15.013,  -9.083,  -1.307,   3.933, -26.460, -20.189, -33.414,
        -29.528,  36.421, -10.115,  16.400, -23.552,  26.201,  68.136,  64.921,
        -32.868,  -6.595, -18.153,  -1.374, -36.862, -41.061, -12.853, -36.432,
        -32.750, -30.734, -36.004, -27.812, -34.012, -29.964, -15.749, -24.040,
         50.511, -13.103,  -1.119, -33.657,  22.089, -13.521,  -0.576,  -7.122,
        -25.050,  -6.651, -26.215, -17.713, -28.131, -32.054, -43.676,  50.638,
        -11.423, -26.021, -18.494, -38.661, -34.644, 156.815,  38.662, -27.824,
        -29.850, -30.673, -29.892,  88.847, -23.318,  86.831,  48.779, -36.145,
          4.647, -14.987, -26.535,  83.059, -21.201,  -6.393,  11.999, -10.656,
          3.444,  -9.100,  -9.407, -24.455, -22.788, -17.012,  10.158, -37.615,
        -34.870, -12.712,  52.023,  25.914, -38.393, -37.662, -14.527, -27.928,
          0.324, -32.494,   0.467, -16.637,  15.160, -22.616,  -4.229, -13.249,
         66.347,  22.078, -16.916, -30.051, -27.131, -24.672,  -4.328, -25.188,
        -34.211, -17.958, -28.733, -24.720, -18.445,  -8.410,  30.265, -42.018,
         46.176,  -8.317, -18.051, -34.018, -38.626, -35.876, -29.974, -34.306,
        -29.674, -36.466, -15.626, -31.687,  70.929,  31.231, -13.565, -33.178,
        -37.964, -14.013, -11.126,   9.388,  -7.495,  -6.150, -31.039,  12.135,
        -20.979, -31.699, -25.787, -32.755, -24.923, -33.446, -38.698,  -1.247,
        -12.040,  -7.652, -11.416,  46.638, -20.883, -27.558,  74.725,   1.411,
        -34.777,   9.135,   5.873,  11.346,  43.032,  -6.204, -21.744,  -5.136,
         30.133, -27.699, -28.776, -21.287, -30.852,  22.093, -25.714, -31.987,
        -33.927, -17.521, -10.716, -44.521, -22.303, -25.631, -14.545,  17.067,
        -26.491, -27.582, -24.085, -13.527, -10.268, 131.792, -34.877, -32.123,
          1.236, -27.667, -17.518, -11.968, -29.154,   4.256, -24.874, -31.148],
       device='cuda:0')
v tensor([1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        3.933e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        4.647e+00, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 3.444e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        3.244e-01, 1.000e-12, 4.675e-01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 9.388e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.411e+00, 1.000e-12, 9.135e+00,
        5.873e+00, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.236e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 4.256e+00,
        1.000e-12, 1.000e-12], device='cuda:0')
v before min max tensor([[[-24.807],
         [-18.954],
         [-24.154],
         [  6.990],
         [-22.944],
         [ 81.475],
         [-23.202],
         [-33.509],
         [-15.498],
         [ 36.024]],

        [[ 93.757],
         [  0.941],
         [ 25.946],
         [ 19.211],
         [-25.645],
         [-34.368],
         [ -6.943],
         [-44.166],
         [133.307],
         [-41.198]],

        [[-29.740],
         [183.333],
         [ 30.312],
         [-35.101],
         [-38.721],
         [-14.554],
         [-26.560],
         [-23.022],
         [  7.377],
         [ 64.496]],

        [[-14.896],
         [ 64.122],
         [ 77.083],
         [-37.664],
         [-13.872],
         [-33.181],
         [-21.713],
         [-42.629],
         [-16.396],
         [-30.457]],

        [[ 53.256],
         [ 26.396],
         [-53.260],
         [-23.578],
         [ 30.030],
         [443.144],
         [-13.037],
         [-36.536],
         [  2.034],
         [-47.454]],

        [[-41.019],
         [191.047],
         [ -1.407],
         [-14.038],
         [-39.322],
         [-54.883],
         [  3.506],
         [ -8.530],
         [-21.181],
         [-16.334]],

        [[-19.023],
         [-23.756],
         [-30.740],
         [-39.674],
         [-28.885],
         [-53.099],
         [-30.548],
         [-43.316],
         [ -0.808],
         [ 15.776]],

        [[114.093],
         [ 14.348],
         [-39.880],
         [  3.517],
         [-21.351],
         [  3.465],
         [ 84.644],
         [  8.365],
         [-22.959],
         [ -2.724]],

        [[-14.315],
         [-15.349],
         [ 57.650],
         [-33.637],
         [-20.587],
         [  7.634],
         [-33.495],
         [155.759],
         [-48.341],
         [114.916]],

        [[-19.280],
         [-22.788],
         [  1.234],
         [-26.896],
         [ -7.030],
         [-24.391],
         [-19.900],
         [163.898],
         [  9.043],
         [-27.718]],

        [[-30.239],
         [ 57.003],
         [  0.640],
         [-13.063],
         [-27.825],
         [-23.011],
         [ -2.005],
         [-19.546],
         [-19.337],
         [-33.544]],

        [[ -5.147],
         [-17.438],
         [  4.277],
         [-22.120],
         [-35.456],
         [-23.811],
         [-48.252],
         [ 68.965],
         [-17.085],
         [-27.545]],

        [[-21.346],
         [-30.546],
         [ 28.296],
         [-30.661],
         [-33.225],
         [ 13.813],
         [-13.640],
         [-16.688],
         [-36.292],
         [-44.585]],

        [[-20.148],
         [ 74.707],
         [-27.362],
         [-33.469],
         [-14.156],
         [-27.763],
         [-17.076],
         [ 65.424],
         [ 30.021],
         [ -7.242]],

        [[108.904],
         [-33.525],
         [-38.798],
         [ 20.876],
         [-36.753],
         [-34.765],
         [ 51.195],
         [-34.118],
         [-19.487],
         [-21.986]],

        [[-21.417],
         [-25.807],
         [193.734],
         [-38.311],
         [ 65.603],
         [ 74.988],
         [-59.146],
         [ 32.553],
         [-12.914],
         [ 29.956]],

        [[-25.303],
         [-26.142],
         [-20.876],
         [-26.057],
         [  8.856],
         [ 45.706],
         [ 80.289],
         [-23.958],
         [-15.487],
         [ 65.381]],

        [[-23.553],
         [-33.126],
         [ 56.452],
         [-33.562],
         [-23.696],
         [  3.270],
         [-22.757],
         [-10.430],
         [ 21.053],
         [-11.204]],

        [[ 98.340],
         [ -2.441],
         [-21.824],
         [-26.059],
         [-38.212],
         [-28.531],
         [ 77.508],
         [ 20.318],
         [-13.166],
         [ 49.005]],

        [[-36.748],
         [ 11.325],
         [ -7.166],
         [-11.433],
         [-31.998],
         [ 31.672],
         [-26.623],
         [-40.354],
         [ 15.682],
         [ 31.479]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.990e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [9.409e-01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.377e+00],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [2.034e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.506e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [3.517e+00],
         [1.000e-12],
         [3.465e+00],
         [1.000e+01],
         [8.365e+00],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [7.634e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.234e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [9.043e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [6.398e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [4.277e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [8.856e+00],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [3.270e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]]], device='cuda:0')
v before min max tensor([[ 75.906],
        [-16.927],
        [-12.064],
        [-29.474],
        [-18.122],
        [ 92.328],
        [-35.009],
        [ -6.371],
        [  4.751],
        [-22.429],
        [ 79.935],
        [ 11.816],
        [-27.518],
        [ -7.600],
        [ 35.207],
        [121.232],
        [ -5.212],
        [-12.678],
        [-40.124],
        [ 53.288]], device='cuda:0')
v tensor([[1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [4.751e+00],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01]], device='cuda:0')
a after update for 1 param tensor([[-0.022, -0.028, -0.035,  ...,  0.015, -0.058, -0.005],
        [-0.027, -0.003,  0.101,  ...,  0.018,  0.002, -0.020],
        [ 0.023, -0.027, -0.015,  ..., -0.042, -0.075,  0.042],
        ...,
        [-0.037, -0.015, -0.037,  ..., -0.002, -0.013,  0.029],
        [-0.001, -0.042, -0.055,  ..., -0.007, -0.050, -0.052],
        [ 0.008,  0.006,  0.025,  ...,  0.041, -0.047, -0.004]],
       device='cuda:0')
s after update for 1 param tensor([[1.709, 1.458, 1.773,  ..., 1.175, 1.328, 1.062],
        [2.053, 1.850, 1.210,  ..., 0.823, 1.508, 1.241],
        [1.604, 1.770, 1.369,  ..., 1.558, 1.520, 1.706],
        ...,
        [1.213, 1.636, 1.415,  ..., 1.646, 0.713, 1.439],
        [1.602, 1.909, 1.671,  ..., 1.651, 1.658, 1.544],
        [1.224, 1.577, 1.671,  ..., 1.628, 1.460, 1.390]], device='cuda:0')
b after update for 1 param tensor([[110.131, 101.732, 112.192,  ...,  91.312,  97.082,  86.801],
        [120.722, 114.585,  92.674,  ...,  76.439, 103.440,  93.844],
        [106.698, 112.081,  98.576,  ..., 105.140, 103.861, 110.049],
        ...,
        [ 92.784, 107.748, 100.227,  ..., 108.076,  71.162, 101.077],
        [106.629, 116.410, 108.917,  ..., 108.260, 108.493, 104.683],
        [ 93.215, 105.799, 108.905,  ..., 107.495, 101.783,  99.330]],
       device='cuda:0')
clipping threshold 0.6222417329238724
a after update for 1 param tensor([ 0.046, -0.073, -0.007,  0.007, -0.024, -0.008,  0.007, -0.052,  0.032,
        -0.020, -0.014, -0.011,  0.026, -0.026, -0.016,  0.022, -0.013, -0.058,
         0.013,  0.053, -0.034,  0.053, -0.042,  0.070, -0.011,  0.063, -0.064,
         0.014,  0.064, -0.001,  0.021, -0.063, -0.096, -0.058, -0.043, -0.017,
         0.061, -0.095, -0.021, -0.029, -0.005, -0.127,  0.001, -0.081, -0.029,
        -0.055,  0.068, -0.038, -0.084, -0.055,  0.002, -0.015, -0.002, -0.037,
         0.066,  0.022,  0.040, -0.114,  0.014, -0.037, -0.004, -0.006,  0.042,
        -0.015, -0.032, -0.028, -0.037,  0.023, -0.041, -0.075, -0.057,  0.016,
         0.038,  0.035, -0.028,  0.047, -0.074,  0.017,  0.035, -0.035, -0.015,
        -0.040, -0.017,  0.069,  0.029, -0.008, -0.023, -0.022,  0.018,  0.004,
         0.051, -0.003, -0.066,  0.031,  0.016, -0.014, -0.057,  0.010, -0.005,
        -0.036, -0.004, -0.009,  0.051,  0.021,  0.019, -0.032, -0.025, -0.049,
        -0.011,  0.018,  0.028,  0.007,  0.032, -0.011,  0.062, -0.029, -0.062,
        -0.016, -0.030,  0.019, -0.065,  0.010, -0.053,  0.007, -0.079, -0.048,
        -0.082,  0.097,  0.012, -0.028,  0.045,  0.009,  0.072,  0.008, -0.028,
        -0.055,  0.050,  0.011, -0.025,  0.024,  0.039,  0.068, -0.017, -0.016,
        -0.068, -0.041, -0.092,  0.003, -0.001, -0.019, -0.036,  0.021,  0.024,
         0.010, -0.024, -0.044, -0.017,  0.053, -0.036,  0.033, -0.030, -0.023,
        -0.077, -0.000, -0.008,  0.077,  0.010, -0.035,  0.059,  0.014, -0.047,
        -0.018, -0.047,  0.000, -0.006,  0.010, -0.033,  0.025, -0.016, -0.002,
         0.030,  0.076, -0.116,  0.017, -0.040, -0.055,  0.012, -0.012, -0.003,
         0.010,  0.002, -0.130,  0.070, -0.022, -0.020,  0.021,  0.045,  0.024,
        -0.077,  0.050], device='cuda:0')
s after update for 1 param tensor([1.856, 1.589, 1.880, 1.436, 1.700, 1.525, 1.651, 1.415, 1.585, 0.704,
        1.653, 0.870, 1.514, 1.570, 1.221, 1.577, 1.387, 1.961, 1.177, 2.014,
        2.014, 1.532, 2.090, 2.150, 1.548, 1.502, 1.720, 1.262, 1.739, 2.196,
        2.002, 1.843, 1.559, 1.756, 1.838, 1.333, 1.747, 1.485, 1.547, 1.521,
        1.703, 1.593, 1.498, 1.791, 1.686, 1.540, 1.819, 1.318, 1.280, 1.466,
        1.389, 1.226, 1.756, 1.720, 2.063, 1.965, 0.656, 1.224, 1.501, 2.026,
        1.702, 1.783, 2.114, 1.680, 1.589, 1.551, 1.743, 1.711, 1.097, 1.952,
        1.876, 1.757, 1.599, 1.344, 1.251, 1.725, 1.802, 0.360, 2.134, 0.648,
        1.533, 1.806, 1.424, 1.368, 1.353, 1.751, 1.913, 1.784, 1.660, 1.122,
        2.005, 2.319, 1.802, 2.112, 1.835, 1.309, 1.411, 1.544, 1.920, 1.455,
        1.680, 1.296, 1.251, 1.117, 1.550, 2.075, 1.338, 1.638, 1.421, 1.264,
        0.991, 1.254, 1.603, 0.859, 1.701, 1.231, 1.815, 1.431, 1.715, 1.980,
        2.118, 1.011, 1.233, 1.893, 1.962, 1.972, 1.667, 1.615, 1.913, 1.708,
        1.795, 1.576, 1.774, 2.093, 1.382, 1.610, 1.818, 1.042, 1.452, 1.906,
        1.057, 0.955, 1.455, 1.431, 1.693, 1.486, 2.014, 1.550, 1.428, 1.613,
        1.859, 1.099, 0.630, 1.021, 1.304, 2.161, 1.352, 1.409, 1.809, 2.211,
        1.639, 1.754, 1.879, 1.597, 1.987, 1.675, 1.652, 1.686, 1.909, 1.331,
        1.472, 1.087, 1.465, 1.988, 1.830, 1.561, 1.647, 1.475, 2.089, 2.149,
        1.284, 1.260, 1.240, 2.132, 1.692, 1.685, 1.288, 1.123, 0.720, 1.816,
        1.717, 1.962, 1.853, 1.379, 1.419, 0.724, 1.452, 1.452, 1.167, 1.486],
       device='cuda:0')
b after update for 1 param tensor([114.776, 106.201, 115.499, 100.962, 109.847, 104.046, 108.246, 100.215,
        106.061,  70.686, 108.304,  78.583, 103.647, 105.569,  93.080, 105.809,
         99.202, 117.983,  91.392, 119.573, 119.545, 104.275, 121.790, 123.521,
        104.809, 103.253, 110.474,  94.652, 111.102, 124.834, 119.193, 114.374,
        105.201, 111.654, 114.203,  97.277, 111.360, 102.679, 104.784, 103.911,
        109.953, 106.336, 103.105, 112.757, 109.379, 104.541, 113.616,  96.723,
         95.304, 102.018,  99.305,  93.291, 111.646, 110.480, 121.012, 118.087,
         68.219,  93.220, 103.222, 119.904, 109.896, 112.507, 122.479, 109.196,
        106.185, 104.936, 111.213, 110.211,  88.252, 117.703, 115.387, 111.663,
        106.539,  97.654,  94.240, 110.644, 113.089,  50.531, 123.070,  67.812,
        104.323, 113.210, 100.544,  98.543,  98.002, 111.482, 116.537, 112.531,
        108.551,  89.221, 119.290, 128.281, 113.101, 122.439, 114.128,  96.372,
        100.079, 104.678, 116.730, 101.608, 109.183,  95.899,  94.219,  89.041,
        104.899, 121.349,  97.448, 107.838, 100.417,  94.728,  83.875,  94.332,
        106.662,  78.082, 109.871,  93.460, 113.498, 100.771, 110.327, 118.548,
        122.596,  84.726,  93.545, 115.898, 117.998, 118.311, 108.788, 107.071,
        116.517, 110.112, 112.879, 105.759, 112.206, 121.883,  99.034, 106.881,
        113.603,  86.001, 101.505, 116.300,  86.626,  82.312, 101.621, 100.774,
        109.604, 102.702, 119.557, 104.874, 100.672, 107.007, 114.854,  88.302,
         66.891,  85.146,  96.213, 123.833,  97.962, 100.010, 113.321, 125.256,
        107.863, 111.590, 115.479, 106.473, 118.747, 109.030, 108.281, 109.394,
        116.404,  97.213, 102.201,  87.827, 101.954, 118.797, 113.966, 105.272,
        108.109, 102.327, 121.765, 123.499,  95.469,  94.559,  93.822, 123.018,
        109.592, 109.370,  95.596,  89.289,  71.488, 113.534, 110.388, 117.999,
        114.693,  98.945, 100.353,  71.700, 101.506, 101.517,  90.998, 102.714],
       device='cuda:0')
clipping threshold 0.6222417329238724
a after update for 1 param tensor([[[-2.574e-02],
         [ 1.654e-02],
         [-8.595e-02],
         [ 8.299e-02],
         [ 4.602e-02],
         [-1.014e-02],
         [ 2.187e-02],
         [-6.407e-02],
         [ 7.912e-02],
         [ 2.388e-02]],

        [[-1.010e+00],
         [-2.698e-01],
         [-3.251e+00],
         [-3.078e+00],
         [-3.127e+00],
         [-3.302e-02],
         [-1.175e+00],
         [-3.017e+00],
         [-3.290e+00],
         [-3.334e+00]],

        [[-1.648e-01],
         [-2.395e-01],
         [ 3.859e-02],
         [-1.173e-01],
         [-3.176e-01],
         [ 1.532e-01],
         [-1.848e-01],
         [ 1.898e-02],
         [ 1.145e-01],
         [-3.051e-01]],

        [[-1.620e+00],
         [-1.527e+00],
         [-6.973e-01],
         [-1.525e+00],
         [-1.653e+00],
         [-1.617e+00],
         [-4.771e-02],
         [-1.564e+00],
         [-1.713e+00],
         [-1.533e+00]],

        [[ 1.634e+00],
         [ 3.987e-01],
         [ 1.592e+00],
         [-8.851e-02],
         [ 1.635e+00],
         [ 1.546e+00],
         [ 1.151e-02],
         [ 1.698e+00],
         [-2.700e-02],
         [ 1.668e+00]],

        [[ 1.187e+00],
         [ 1.171e+00],
         [ 1.077e+00],
         [ 2.372e-01],
         [ 6.777e-01],
         [ 1.029e+00],
         [ 4.759e-01],
         [ 1.065e+00],
         [ 3.003e-02],
         [ 7.954e-02]],

        [[ 5.158e-01],
         [ 9.288e-01],
         [-5.279e-02],
         [ 7.563e-01],
         [ 9.849e-01],
         [ 1.065e+00],
         [ 1.156e+00],
         [ 5.899e-01],
         [ 8.998e-01],
         [ 1.150e+00]],

        [[-3.633e-02],
         [ 1.586e-02],
         [ 1.567e-01],
         [ 4.580e-02],
         [ 4.516e-02],
         [ 6.253e-03],
         [-4.460e-02],
         [-5.535e-02],
         [ 6.821e-02],
         [ 3.458e-02]],

        [[-2.461e+00],
         [-2.104e+00],
         [-9.203e-01],
         [ 7.177e-03],
         [-2.492e-02],
         [-7.741e-02],
         [-2.690e-01],
         [ 3.325e-02],
         [-2.387e+00],
         [-1.943e+00]],

        [[ 5.280e-01],
         [ 6.008e-01],
         [ 3.780e-01],
         [-2.143e-02],
         [ 5.445e-01],
         [ 4.304e-01],
         [ 4.757e-01],
         [ 6.021e-01],
         [-1.661e-02],
         [-9.791e-02]],

        [[ 4.028e-01],
         [ 4.699e-01],
         [-3.191e-03],
         [ 3.437e-01],
         [ 4.191e-01],
         [ 2.190e-01],
         [ 2.669e-01],
         [-1.957e-02],
         [ 6.742e-02],
         [ 3.128e-01]],

        [[-2.847e-02],
         [-6.749e-02],
         [-3.085e-02],
         [ 7.692e-03],
         [ 6.319e-02],
         [ 3.621e-02],
         [ 1.076e-01],
         [-2.407e-02],
         [ 9.691e-02],
         [ 4.442e-02]],

        [[ 4.539e-01],
         [ 1.048e-02],
         [ 9.869e-02],
         [-6.149e-02],
         [ 1.543e-02],
         [ 3.150e-01],
         [ 2.427e-01],
         [ 1.589e-01],
         [-1.806e-01],
         [ 2.020e-01]],

        [[-3.752e-02],
         [ 8.494e-02],
         [ 9.475e-03],
         [ 2.192e-02],
         [ 8.011e-03],
         [-1.107e-02],
         [-5.404e-03],
         [-8.477e-02],
         [-2.604e-02],
         [ 5.883e-02]],

        [[ 2.081e+00],
         [ 1.975e-01],
         [ 1.125e+00],
         [ 2.054e+00],
         [ 1.008e+00],
         [ 1.049e-01],
         [ 1.889e+00],
         [ 2.186e+00],
         [ 1.761e-02],
         [ 1.006e+00]],

        [[-7.313e-01],
         [ 7.587e-02],
         [-1.653e+00],
         [-7.115e-01],
         [-1.685e+00],
         [-1.697e+00],
         [-1.646e+00],
         [-1.241e+00],
         [-3.628e-02],
         [-1.737e+00]],

        [[-2.311e-01],
         [ 2.712e-01],
         [-6.960e-01],
         [-7.325e-01],
         [-4.026e-01],
         [-1.878e-01],
         [-6.977e-01],
         [-1.253e-01],
         [-6.782e-01],
         [-3.141e-01]],

        [[-1.514e-01],
         [-3.700e-02],
         [-5.580e-02],
         [ 8.882e-02],
         [-1.306e-01],
         [ 5.471e-03],
         [ 9.720e-02],
         [ 2.430e-03],
         [-3.109e-02],
         [ 7.012e-02]],

        [[ 4.331e-01],
         [-4.662e-01],
         [-6.538e-01],
         [-3.358e-01],
         [-2.652e-01],
         [-5.292e-01],
         [-2.905e-02],
         [-6.485e-01],
         [-5.735e-01],
         [-3.287e-01]],

        [[-9.099e-01],
         [-7.581e-02],
         [-8.425e-01],
         [-8.510e-01],
         [-7.908e-01],
         [-8.119e-01],
         [-3.798e-01],
         [-8.342e-01],
         [-2.652e-02],
         [-8.314e-01]]], device='cuda:0')
s after update for 1 param tensor([[[1.474],
         [1.265],
         [1.692],
         [1.730],
         [1.173],
         [1.703],
         [1.743],
         [1.730],
         [1.454],
         [1.533]],

        [[2.276],
         [2.245],
         [2.242],
         [2.663],
         [2.195],
         [1.611],
         [2.071],
         [2.161],
         [2.741],
         [2.065]],

        [[1.462],
         [2.338],
         [1.942],
         [1.761],
         [2.057],
         [1.334],
         [1.415],
         [1.090],
         [1.520],
         [1.565]],

        [[2.253],
         [2.360],
         [2.301],
         [1.937],
         [2.357],
         [2.092],
         [1.050],
         [2.169],
         [2.054],
         [1.454]],

        [[2.585],
         [1.821],
         [2.551],
         [1.551],
         [2.817],
         [2.728],
         [1.097],
         [2.501],
         [1.442],
         [2.243]],

        [[2.398],
         [2.345],
         [2.158],
         [1.356],
         [1.974],
         [2.573],
         [1.925],
         [2.347],
         [1.543],
         [1.022]],

        [[1.732],
         [1.231],
         [1.476],
         [2.037],
         [1.724],
         [2.499],
         [1.484],
         [2.069],
         [1.374],
         [1.973]],

        [[2.273],
         [1.613],
         [1.916],
         [1.999],
         [1.001],
         [0.992],
         [2.044],
         [1.582],
         [1.082],
         [1.357]],

        [[2.046],
         [2.322],
         [2.130],
         [1.763],
         [1.234],
         [1.792],
         [2.049],
         [1.866],
         [2.291],
         [2.240]],

        [[1.866],
         [1.518],
         [1.476],
         [1.260],
         [0.937],
         [1.143],
         [1.202],
         [2.386],
         [2.098],
         [1.398]],

        [[1.685],
         [2.127],
         [1.223],
         [1.186],
         [1.483],
         [1.373],
         [1.156],
         [1.125],
         [1.157],
         [1.793]],

        [[1.640],
         [1.536],
         [1.689],
         [1.283],
         [1.816],
         [1.262],
         [2.338],
         [1.673],
         [1.846],
         [1.323]],

        [[1.296],
         [1.441],
         [1.836],
         [1.904],
         [1.939],
         [1.527],
         [1.332],
         [1.550],
         [1.703],
         [2.122]],

        [[1.511],
         [1.725],
         [1.641],
         [1.569],
         [1.340],
         [1.620],
         [0.894],
         [1.867],
         [1.601],
         [1.182]],

        [[2.211],
         [1.914],
         [1.827],
         [2.378],
         [1.753],
         [1.747],
         [2.362],
         [1.813],
         [1.284],
         [1.442]],

        [[1.873],
         [1.213],
         [2.466],
         [1.884],
         [2.429],
         [2.353],
         [2.781],
         [2.224],
         [1.489],
         [2.220]],

        [[1.441],
         [1.298],
         [1.470],
         [1.259],
         [1.693],
         [2.195],
         [1.870],
         [1.139],
         [1.653],
         [1.745]],

        [[1.482],
         [1.652],
         [1.686],
         [1.831],
         [1.790],
         [1.508],
         [1.402],
         [1.129],
         [1.556],
         [1.627]],

        [[2.215],
         [1.456],
         [1.611],
         [1.310],
         [1.817],
         [1.360],
         [2.273],
         [1.979],
         [1.002],
         [1.817]],

        [[1.721],
         [1.592],
         [1.465],
         [1.662],
         [1.526],
         [1.902],
         [1.446],
         [2.005],
         [1.643],
         [1.920]]], device='cuda:0')
b after update for 1 param tensor([[[102.269],
         [ 94.772],
         [109.579],
         [110.811],
         [ 91.238],
         [109.945],
         [111.225],
         [110.799],
         [101.586],
         [104.299]],

        [[127.097],
         [126.238],
         [126.132],
         [137.476],
         [124.813],
         [106.925],
         [121.242],
         [123.852],
         [139.482],
         [121.070]],

        [[101.854],
         [128.816],
         [117.400],
         [111.809],
         [120.842],
         [ 97.305],
         [100.197],
         [ 87.959],
         [103.881],
         [105.398]],

        [[126.446],
         [129.429],
         [127.803],
         [117.249],
         [129.327],
         [121.848],
         [ 86.344],
         [124.085],
         [120.737],
         [101.586]],

        [[135.463],
         [113.681],
         [134.561],
         [104.920],
         [141.387],
         [139.143],
         [ 88.241],
         [133.245],
         [101.171],
         [126.161]],

        [[130.470],
         [129.004],
         [123.768],
         [ 98.120],
         [118.360],
         [135.129],
         [116.898],
         [129.059],
         [104.651],
         [ 85.162]],

        [[110.880],
         [ 93.476],
         [102.366],
         [120.228],
         [110.609],
         [133.172],
         [102.613],
         [121.168],
         [ 98.769],
         [118.348]],

        [[127.020],
         [107.009],
         [116.602],
         [119.112],
         [ 84.294],
         [ 83.908],
         [120.455],
         [105.980],
         [ 87.616],
         [ 98.129]],

        [[120.512],
         [128.363],
         [122.960],
         [111.871],
         [ 93.596],
         [112.779],
         [120.587],
         [115.071],
         [127.507],
         [126.101]],

        [[115.071],
         [103.788],
         [102.346],
         [ 94.576],
         [ 81.569],
         [ 90.050],
         [ 92.378],
         [130.131],
         [122.030],
         [ 99.593]],

        [[109.365],
         [122.869],
         [ 93.175],
         [ 91.738],
         [102.590],
         [ 98.719],
         [ 90.562],
         [ 89.346],
         [ 90.600],
         [112.814]],

        [[107.877],
         [104.405],
         [109.476],
         [ 95.427],
         [113.522],
         [ 94.657],
         [128.808],
         [108.956],
         [114.463],
         [ 96.915]],

        [[ 95.913],
         [101.115],
         [114.142],
         [116.235],
         [117.298],
         [104.118],
         [ 97.216],
         [104.891],
         [109.951],
         [122.720]],

        [[103.571],
         [110.636],
         [107.937],
         [105.522],
         [ 97.519],
         [107.243],
         [ 79.671],
         [115.104],
         [106.605],
         [ 91.589]],

        [[125.281],
         [116.567],
         [113.869],
         [129.925],
         [111.541],
         [111.363],
         [129.481],
         [113.441],
         [ 95.475],
         [101.177]],

        [[115.287],
         [ 92.770],
         [132.299],
         [115.636],
         [131.303],
         [129.218],
         [140.493],
         [125.639],
         [102.786],
         [125.523]],

        [[101.136],
         [ 95.964],
         [102.142],
         [ 94.515],
         [109.625],
         [124.815],
         [115.206],
         [ 89.909],
         [108.331],
         [111.287]],

        [[102.561],
         [108.283],
         [109.394],
         [113.990],
         [112.722],
         [103.438],
         [ 99.756],
         [ 89.499],
         [105.103],
         [107.475]],

        [[125.396],
         [101.646],
         [106.944],
         [ 96.416],
         [113.549],
         [ 98.253],
         [127.001],
         [118.508],
         [ 84.347],
         [113.548]],

        [[110.531],
         [106.311],
         [101.981],
         [108.622],
         [104.085],
         [116.178],
         [101.309],
         [119.282],
         [107.985],
         [116.742]]], device='cuda:0')
clipping threshold 0.6222417329238724
a after update for 1 param tensor([[-1.816e-03],
        [-3.235e+00],
        [-9.910e-02],
        [-1.594e+00],
        [ 1.679e+00],
        [ 1.131e+00],
        [ 8.406e-01],
        [-4.197e-02],
        [-2.230e+00],
        [ 5.502e-01],
        [ 3.437e-01],
        [-1.823e-02],
        [ 2.115e-01],
        [ 2.348e-02],
        [ 1.943e+00],
        [-1.715e+00],
        [-4.538e-01],
        [ 4.608e-02],
        [ 1.045e-01],
        [-9.678e-01]], device='cuda:0')
s after update for 1 param tensor([[1.677],
        [2.248],
        [1.359],
        [2.254],
        [2.608],
        [2.292],
        [1.721],
        [0.829],
        [2.530],
        [1.640],
        [1.962],
        [1.637],
        [1.546],
        [1.738],
        [2.218],
        [2.531],
        [1.979],
        [1.190],
        [2.160],
        [1.908]], device='cuda:0')
b after update for 1 param tensor([[109.099],
        [126.307],
        [ 98.220],
        [126.473],
        [136.052],
        [127.558],
        [110.529],
        [ 76.691],
        [134.002],
        [107.876],
        [118.004],
        [107.793],
        [104.734],
        [111.068],
        [125.473],
        [134.036],
        [118.505],
        [ 91.901],
        [123.808],
        [116.384]], device='cuda:0')
clipping threshold 0.6222417329238724
||w||^2 0.510891397346328
exp ma of ||w||^2 0.6812664608945801
||w|| 0.7147666733601449
exp ma of ||w|| 0.7923389461009087
||w||^2 0.48269839742898274
exp ma of ||w||^2 0.8822018948742371
||w|| 0.6947649943894574
exp ma of ||w|| 0.9063601722300086
||w||^2 1.7801555330930816
exp ma of ||w||^2 0.8610685136305581
||w|| 1.33422469363038
exp ma of ||w|| 0.8809893578157102
||w||^2 0.3967101968278671
exp ma of ||w||^2 0.8799233236355225
||w|| 0.6298493445482556
exp ma of ||w|| 0.8890617814375849
||w||^2 0.410432840052999
exp ma of ||w||^2 0.8542164665740718
||w|| 0.6406503258822234
exp ma of ||w|| 0.886023804593948
cuda
Objective function 38.56 = squared loss an data 30.79 + 0.5*rho*h**2 6.355908 + alpha*h 0.000000 + L2reg 1.13 + L1reg 0.29 ; SHD = 120 ; DAG False
Proportion of microbatches that were clipped  0.7704732676465837
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 3.565363369109157
iteration 1 in outer loop, alpha = 3.565363369109157, rho = 1.0, h = 3.565363369109157
cuda
4420
cuda
Objective function 51.27 = squared loss an data 30.79 + 0.5*rho*h**2 6.355908 + alpha*h 12.711816 + L2reg 1.13 + L1reg 0.29 ; SHD = 120 ; DAG False
||w||^2 117802737265.3883
exp ma of ||w||^2 149406718580.04462
||w|| 343224.0336360324
exp ma of ||w|| 297759.4247912363
||w||^2 16017.99333084949
exp ma of ||w||^2 177562812.0433831
||w|| 126.56221130673045
exp ma of ||w|| 2373.508168067981
||w||^2 2.5560825779057983
exp ma of ||w||^2 3819688.771055204
||w|| 1.5987753369081592
exp ma of ||w|| 59.73151076381922
||w||^2 1.623630237248036
exp ma of ||w||^2 1.356767271699965
||w|| 1.274217499977157
exp ma of ||w|| 1.1197924732850482
||w||^2 0.8142531848580491
exp ma of ||w||^2 1.1047155310944627
||w|| 0.902359786813469
exp ma of ||w|| 1.0109666577855319
||w||^2 1.4495016165337629
exp ma of ||w||^2 1.3523977873154578
||w|| 1.2039524976234581
exp ma of ||w|| 1.1169418701305536
||w||^2 1.158459010966256
exp ma of ||w||^2 1.3090653254818903
||w|| 1.0763173374828894
exp ma of ||w|| 1.1058209802148506
||w||^2 1.0525392354171828
exp ma of ||w||^2 1.2741637672354515
||w|| 1.0259333484282411
exp ma of ||w|| 1.0894090698831864
||w||^2 0.5011968895168109
exp ma of ||w||^2 1.1745354928900928
||w|| 0.7079526040045413
exp ma of ||w|| 1.0484048358300624
||w||^2 0.5824498409402171
exp ma of ||w||^2 1.1449779457705287
||w|| 0.7631840151236248
exp ma of ||w|| 1.0343703469638112
||w||^2 0.9173189953500236
exp ma of ||w||^2 1.292692280899173
||w|| 0.9577677147148068
exp ma of ||w|| 1.0937765786399416
||w||^2 2.132435173114266
exp ma of ||w||^2 1.3172118844770169
||w|| 1.460285990179412
exp ma of ||w|| 1.1067470712977845
cuda
Objective function 31.41 = squared loss an data 20.98 + 0.5*rho*h**2 1.806886 + alpha*h 6.777728 + L2reg 1.59 + L1reg 0.26 ; SHD = 93 ; DAG False
Proportion of microbatches that were clipped  0.768541887161117
iteration 1 in inner loop, alpha 3.565363369109157 rho 1.0 h 1.9009922462584186
4420
cuda
Objective function 47.68 = squared loss an data 20.98 + 0.5*rho*h**2 18.068858 + alpha*h 6.777728 + L2reg 1.59 + L1reg 0.26 ; SHD = 93 ; DAG False
||w||^2 769.9253499098259
exp ma of ||w||^2 43260653.00835112
||w|| 27.74752871716373
exp ma of ||w|| 505.74204843780427
||w||^2 2.891723169538081
exp ma of ||w||^2 5.556024810801013
||w|| 1.7005067390451827
exp ma of ||w|| 1.5216309417609064
v before min max tensor([[-113.860, -119.218,  143.426,  ...,    9.481, -130.737,  442.610],
        [ -62.212,  -17.140, 1247.652,  ...,  -19.971,  376.339, -135.394],
        [ 269.492,   25.619,  192.050,  ...,  130.152,  -13.497,   14.468],
        ...,
        [ -64.347, -117.647,  -49.433,  ...,   11.293,  -62.218, -116.385],
        [ -50.098, -119.527, -104.513,  ...,  -80.142,  -23.685, -119.539],
        [ -24.083,  -35.991,  -88.707,  ...,  -29.936,  -66.076, -111.227]],
       device='cuda:0')
v tensor([[1.000e-12, 1.000e-12, 1.000e+01,  ..., 9.481e+00, 1.000e-12,
         1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e+01,
         1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.000e+01],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e+01, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([-7.171e+01,  1.425e+02, -1.431e+01, -1.445e+02, -1.014e+02, -6.022e+01,
         1.601e+02, -8.341e+01,  5.364e+01,  2.263e-01,  1.045e+02, -6.375e+01,
        -1.063e+02, -5.289e+01, -8.847e+01, -2.684e+01,  4.984e+02, -1.093e+02,
         3.185e+02,  4.486e+00, -5.328e+01,  1.204e+02,  6.442e+01, -1.047e+02,
         9.830e+01, -4.530e+01, -1.214e+02, -8.779e+01,  2.020e+02,  8.017e+01,
        -4.352e+01, -1.039e+02,  2.603e+01,  8.050e+00, -7.838e+01, -9.582e+01,
        -1.341e+02,  8.489e+01, -7.712e+01, -1.016e+02,  4.609e+02, -9.485e+01,
        -1.321e+02, -1.011e+02, -1.123e+02, -1.201e+02, -8.507e+00, -5.726e+01,
         2.917e+02, -5.928e+01, -1.102e+02,  5.802e+01,  3.771e+01, -9.907e+01,
        -1.081e+02,  3.283e+01,  2.737e+01, -1.129e+02,  1.143e+02,  6.224e+01,
         6.088e+01, -1.107e+02, -9.833e+01, -1.358e+02, -1.655e+01, -9.440e+01,
        -1.036e+02,  2.151e+02,  4.693e+01,  6.055e+01, -1.433e+02, -7.027e+01,
        -2.416e+01,  1.745e+02, -8.768e+01, -7.923e+01,  1.192e+01, -7.839e+01,
         2.317e+02,  9.403e+01, -1.143e+02, -1.218e+02,  1.807e+02,  5.280e+00,
        -9.605e+01, -5.587e+01, -8.544e+01,  8.505e+01,  2.864e+02,  3.767e+02,
         1.567e+03,  1.791e+02,  7.395e+02, -9.775e+01,  1.195e+02,  1.772e+02,
        -9.826e+01, -8.601e+01,  1.743e+02, -6.797e+01, -1.363e+02, -1.335e+02,
        -7.131e+01,  7.532e+02, -8.759e+01, -1.295e+02,  1.015e+02, -1.900e+01,
        -2.138e+01,  1.914e+02, -1.420e+02, -1.144e+02, -3.827e+01,  2.009e+01,
         1.087e+02, -6.128e+01, -7.405e+01, -1.201e+02, -1.263e+02,  5.786e+02,
        -9.625e+01, -7.840e+01,  3.913e+01,  5.371e+02, -1.173e+02, -9.575e+01,
        -1.118e+02,  2.004e+02, -1.011e+02,  5.815e+01, -1.410e+02, -1.232e+02,
         1.054e+02, -9.960e+01, -1.010e+02,  2.588e+02, -1.127e+02, -1.257e+02,
        -7.896e+01, -9.700e+01, -4.612e+01,  2.060e+02, -1.369e+02, -2.152e+01,
        -1.721e+00, -9.048e+01, -1.115e+02,  1.009e+02, -6.965e+01, -8.046e+01,
        -1.026e+02, -1.018e+02, -8.898e+01, -8.926e+01,  2.568e+01,  5.679e+01,
        -8.555e+01, -1.191e+02,  4.360e+02, -5.652e+01, -3.575e+01,  1.683e+02,
        -7.749e+01, -8.876e+01, -9.194e+01, -1.277e+02, -8.958e+01,  5.231e+01,
         1.299e+02, -1.458e+02, -1.192e+02,  1.670e+02, -6.596e+01, -1.856e+01,
        -7.834e+01, -8.948e+01, -5.801e+01, -7.990e+01, -1.323e+02, -8.503e+01,
        -1.387e+02, -1.043e+02, -1.123e+02,  2.789e+02, -1.198e+02, -1.100e+02,
         4.812e+01, -5.163e+01, -8.869e+01, -8.538e+01, -1.156e+02, -8.503e+01,
        -9.000e+01,  7.324e+01, -1.395e+02, -5.466e+01, -2.916e+01, -1.064e+02,
        -1.298e+01, -2.391e+01], device='cuda:0')
v tensor([1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 2.263e-01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 4.486e+00, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 8.050e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 5.280e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12], device='cuda:0')
v before min max tensor([[[ 1.398e+01],
         [-3.239e+01],
         [-4.850e+01],
         [-8.474e+01],
         [-9.571e+01],
         [ 7.210e+01],
         [-1.458e+02],
         [ 1.446e+01],
         [ 3.459e+01],
         [-7.919e-02]],

        [[ 4.175e+00],
         [-5.640e+01],
         [-1.286e+02],
         [ 1.470e+02],
         [-3.124e+01],
         [-1.709e+00],
         [ 2.526e+01],
         [ 4.178e+02],
         [-8.916e+01],
         [ 1.088e+02]],

        [[-3.568e+01],
         [-1.150e+02],
         [-6.767e+01],
         [ 9.092e+01],
         [-8.824e+01],
         [-8.285e+00],
         [-1.265e+01],
         [-1.258e+02],
         [ 1.973e+02],
         [-1.061e+02]],

        [[-9.438e+01],
         [-2.371e+01],
         [-1.557e+02],
         [-1.095e+02],
         [-8.803e+01],
         [ 9.936e+02],
         [-8.883e+01],
         [ 3.784e+00],
         [-1.308e+02],
         [-8.086e+01]],

        [[-1.330e+01],
         [-9.056e+01],
         [-1.015e+02],
         [-1.433e+02],
         [ 1.202e+01],
         [ 5.527e+01],
         [ 5.673e+01],
         [-5.835e+01],
         [ 9.940e+02],
         [ 8.147e+00]],

        [[-1.020e+02],
         [-6.313e+01],
         [ 1.077e+02],
         [ 2.869e+01],
         [-3.934e+01],
         [-1.159e+02],
         [ 7.998e+01],
         [ 4.255e+02],
         [-6.490e+01],
         [-1.051e+02]],

        [[-4.655e+01],
         [ 4.851e+00],
         [-7.823e+01],
         [-6.536e+01],
         [ 7.055e-02],
         [-8.071e+01],
         [-1.344e+02],
         [-9.504e+01],
         [-5.746e+01],
         [-6.344e+01]],

        [[ 2.127e+01],
         [ 6.724e+01],
         [-9.215e+01],
         [-1.048e+02],
         [-1.099e+01],
         [ 3.488e+02],
         [-1.731e+01],
         [-1.421e+02],
         [-1.106e+02],
         [ 4.867e+02]],

        [[-6.667e+01],
         [-8.726e+01],
         [ 1.292e+02],
         [-1.110e+02],
         [ 3.820e+01],
         [ 2.694e+01],
         [ 3.163e+02],
         [-1.097e+02],
         [-8.512e+01],
         [ 1.195e+02]],

        [[-8.065e+01],
         [-3.645e+01],
         [-1.171e+02],
         [-1.153e+02],
         [ 1.315e+02],
         [ 6.108e+01],
         [ 2.576e+01],
         [-1.653e+01],
         [-1.199e+02],
         [ 7.257e+01]],

        [[-8.545e+01],
         [ 2.170e+02],
         [ 4.272e+02],
         [-1.459e+02],
         [-1.069e+02],
         [-2.900e+01],
         [-1.034e+02],
         [-1.116e+02],
         [-1.294e+02],
         [ 1.564e+02]],

        [[-1.053e+02],
         [ 2.511e+02],
         [-2.381e+01],
         [-1.232e+02],
         [ 2.239e+02],
         [-1.051e+02],
         [ 4.240e+01],
         [-5.385e+01],
         [-4.541e+00],
         [-1.187e+02]],

        [[-6.120e+01],
         [ 7.498e+01],
         [-9.790e+01],
         [-1.120e+02],
         [-1.399e+02],
         [-2.590e+01],
         [-3.936e+01],
         [-3.116e+01],
         [-2.305e+01],
         [ 1.517e+02]],

        [[-1.060e+02],
         [-3.606e+01],
         [ 1.248e+01],
         [-1.290e+02],
         [ 1.102e+02],
         [-6.942e+01],
         [-1.283e+02],
         [ 6.498e+01],
         [-1.388e+01],
         [-1.041e+02]],

        [[-1.001e+02],
         [ 4.500e+02],
         [-1.027e+02],
         [-1.517e+02],
         [-5.994e+01],
         [-7.717e+01],
         [-6.433e+01],
         [ 1.528e+03],
         [ 2.090e+02],
         [ 2.135e+01]],

        [[-5.740e+00],
         [-1.206e+02],
         [-1.249e+02],
         [ 3.142e+02],
         [ 3.908e+01],
         [ 2.460e+02],
         [ 3.980e+02],
         [-1.187e+02],
         [-7.944e+01],
         [ 1.047e+02]],

        [[-5.807e+01],
         [-1.258e+02],
         [-1.239e+02],
         [-3.574e+01],
         [ 6.687e+01],
         [-7.053e+01],
         [-8.907e+01],
         [-1.127e+02],
         [ 1.349e+02],
         [-9.778e+01]],

        [[ 4.156e+01],
         [-1.258e+02],
         [ 2.123e+00],
         [ 1.516e+02],
         [-1.284e+02],
         [-1.338e+02],
         [-8.310e+01],
         [-7.926e+01],
         [-8.259e+01],
         [ 9.187e+01]],

        [[-7.428e+01],
         [ 5.292e+01],
         [ 4.271e+01],
         [-1.101e+02],
         [-1.129e+02],
         [-4.748e+01],
         [ 2.236e+01],
         [-4.159e+01],
         [-1.046e+02],
         [-7.733e+01]],

        [[-1.265e+02],
         [ 1.270e+02],
         [-1.039e+02],
         [-1.048e+02],
         [-9.518e+01],
         [-7.997e+01],
         [ 2.428e+02],
         [-1.062e+02],
         [-9.078e+01],
         [-1.065e+02]]], device='cuda:0')
v tensor([[[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[4.175e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [3.784e+00],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [8.147e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [4.851e+00],
         [1.000e-12],
         [1.000e-12],
         [7.055e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [2.123e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[  20.184],
        [-126.954],
        [ -14.954],
        [ -39.474],
        [ 294.998],
        [ 172.580],
        [ -78.731],
        [ -76.858],
        [  76.087],
        [-116.730],
        [ 135.288],
        [ 753.148],
        [ 193.510],
        [ -90.698],
        [ 331.447],
        [-134.541],
        [ 564.449],
        [ -89.080],
        [ -44.487],
        [ -84.638]], device='cuda:0')
v tensor([[1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 0.029,  0.036, -0.244,  ..., -0.260,  0.090, -0.080],
        [-0.082, -0.207,  0.062,  ...,  0.296,  0.044,  0.043],
        [-0.030, -0.047,  0.086,  ..., -0.029,  0.052,  0.039],
        ...,
        [-0.006, -0.106, -0.049,  ...,  0.062,  0.076,  0.134],
        [ 0.020,  0.029,  0.056,  ...,  0.067, -0.013,  0.038],
        [ 0.037,  0.033, -0.167,  ..., -0.076,  0.021, -0.026]],
       device='cuda:0')
s after update for 1 param tensor([[1.582, 1.710, 1.887,  ..., 1.833, 1.804, 1.749],
        [1.554, 1.556, 2.241,  ..., 1.316, 1.938, 2.091],
        [1.851, 1.820, 1.703,  ..., 1.874, 1.046, 1.639],
        ...,
        [1.230, 1.715, 2.184,  ..., 1.667, 1.756, 2.007],
        [1.395, 1.741, 1.493,  ..., 1.666, 1.400, 1.640],
        [2.099, 1.880, 1.238,  ..., 1.277, 1.588, 1.558]], device='cuda:0')
b after update for 1 param tensor([[110.818, 115.210, 121.008,  ..., 119.276, 118.330, 116.504],
        [109.816, 109.909, 131.871,  ..., 101.057, 122.648, 127.390],
        [119.855, 118.849, 114.968,  ..., 120.606,  90.095, 112.782],
        ...,
        [ 97.704, 115.360, 130.196,  ..., 113.736, 116.728, 124.805],
        [104.036, 116.236, 107.638,  ..., 113.717, 104.243, 112.834],
        [127.638, 120.800,  98.010,  ...,  99.547, 111.007, 109.974]],
       device='cuda:0')
clipping threshold 1.1078602803754565
a after update for 1 param tensor([-2.693e-02,  6.056e-02,  3.140e-02, -5.378e-02, -2.963e-02, -1.370e-01,
         1.676e-01,  1.054e-01,  1.426e-01,  5.469e-02, -5.781e-02,  1.039e-01,
         1.330e-01, -1.193e-01,  2.779e-01,  7.831e-03,  1.076e-01,  5.812e-02,
         1.015e-03,  9.906e-02,  6.810e-02,  1.758e-01, -7.507e-02,  1.113e-02,
         1.097e-02,  1.901e-01, -1.312e-01,  4.742e-02,  1.855e-01,  1.406e-01,
        -9.996e-02, -4.351e-02, -1.113e-01, -7.566e-02,  4.885e-02, -1.728e-01,
        -6.700e-02, -1.058e-02, -6.304e-02, -8.861e-02,  2.557e-01, -2.693e-02,
        -3.119e-01,  9.168e-04,  6.592e-02, -1.522e-01,  3.403e-02, -3.912e-02,
        -7.742e-02,  1.573e-01,  3.936e-02,  2.787e-01, -1.133e-02, -1.558e-01,
        -6.748e-02,  1.516e-01,  1.118e-01, -2.004e-01,  5.328e-02, -1.191e-01,
        -2.414e-02,  9.937e-02, -1.478e-01, -2.543e-01,  2.566e-01,  1.097e-02,
         2.627e-01,  5.289e-02, -1.722e-01, -5.197e-03,  1.386e-02, -2.958e-01,
        -2.834e-02, -3.848e-02,  1.800e-01,  1.535e-01,  5.364e-02,  1.051e-01,
         1.289e-01,  1.576e-01,  1.542e-02, -2.501e-02,  6.770e-02,  3.166e-01,
        -1.444e-01,  5.668e-02, -8.543e-02, -1.525e-01,  1.835e-01, -9.817e-03,
        -6.531e-02,  1.409e-01, -2.325e-01,  6.217e-02,  9.236e-02,  8.549e-02,
        -1.520e-01, -1.966e-01, -1.152e-01, -8.632e-02, -8.482e-02,  9.805e-02,
        -7.671e-02,  8.262e-02, -1.697e-01, -3.515e-02, -7.190e-02, -7.855e-02,
        -5.009e-02,  3.198e-01, -1.718e-01,  6.433e-02, -2.390e-01,  5.897e-03,
         9.780e-02, -8.446e-02,  2.928e-01, -9.643e-02,  7.727e-03, -2.503e-01,
         1.730e-01,  3.687e-02,  9.989e-03, -4.662e-02, -2.534e-02, -1.205e-01,
         2.375e-01,  8.644e-02,  8.550e-02,  1.032e-01, -8.353e-03, -2.516e-03,
        -1.787e-04,  1.284e-01, -5.338e-02,  1.422e-02,  6.428e-02, -1.412e-02,
         3.031e-01,  2.349e-01,  3.000e-02,  1.705e-01,  1.950e-01, -1.042e-01,
        -1.220e-01, -3.757e-02, -2.001e-02,  9.760e-02, -2.337e-02,  5.314e-02,
         8.918e-02,  4.048e-02, -1.938e-01,  1.714e-01, -1.328e-02,  8.551e-02,
         1.904e-01, -1.123e-02,  1.136e-01,  4.819e-02,  6.493e-02,  9.123e-02,
         1.500e-01, -6.665e-02,  8.384e-02,  2.914e-01,  8.455e-02,  1.704e-01,
         1.426e-01, -6.703e-02, -2.344e-01,  9.581e-02,  1.884e-01, -2.670e-02,
         2.279e-01,  1.759e-01, -3.342e-02,  1.895e-01,  3.687e-02,  1.120e-01,
         1.759e-01,  4.502e-02,  9.468e-02,  1.261e-01,  3.922e-02,  9.912e-02,
        -8.659e-02,  8.610e-02, -6.929e-02, -5.064e-02, -2.161e-02,  1.206e-01,
         5.100e-02, -1.370e-01, -1.880e-01, -3.965e-02, -2.193e-01,  3.462e-02,
        -8.035e-02,  2.148e-01], device='cuda:0')
s after update for 1 param tensor([1.284, 1.729, 0.838, 1.994, 1.597, 1.534, 1.778, 1.872, 2.035, 1.565,
        1.199, 1.088, 1.796, 1.594, 1.361, 1.827, 1.728, 1.520, 1.651, 1.105,
        1.672, 1.997, 2.180, 1.550, 2.209, 1.952, 1.667, 1.991, 1.793, 1.850,
        1.221, 1.746, 2.328, 2.202, 1.545, 1.318, 1.871, 1.587, 1.541, 1.491,
        1.883, 1.470, 1.818, 1.841, 1.749, 1.650, 2.114, 1.446, 2.030, 2.046,
        1.942, 1.780, 1.724, 1.535, 1.924, 1.150, 1.706, 1.741, 2.030, 2.043,
        2.235, 1.548, 1.439, 1.906, 1.229, 1.428, 1.441, 1.878, 2.110, 1.782,
        1.967, 1.602, 1.328, 2.100, 1.628, 1.896, 2.230, 1.644, 2.180, 2.259,
        1.752, 1.751, 1.953, 1.767, 1.698, 1.317, 1.398, 2.139, 2.063, 1.988,
        2.021, 1.548, 2.245, 1.474, 1.729, 1.919, 1.613, 1.768, 2.121, 1.188,
        1.872, 1.882, 1.374, 2.045, 1.591, 1.900, 1.964, 1.797, 1.721, 2.055,
        1.951, 1.575, 1.865, 1.514, 2.069, 0.860, 1.626, 1.695, 2.214, 2.280,
        1.485, 1.147, 1.954, 2.465, 1.611, 1.436, 1.839, 2.058, 2.023, 2.236,
        1.946, 1.694, 2.022, 1.755, 1.387, 2.184, 1.924, 1.732, 1.085, 2.056,
        1.802, 1.831, 1.884, 1.576, 1.748, 1.245, 1.532, 2.160, 1.024, 1.314,
        1.555, 1.400, 1.365, 1.500, 1.789, 1.879, 1.673, 1.768, 2.031, 1.438,
        1.552, 1.825, 1.834, 1.558, 1.833, 1.884, 1.742, 1.815, 2.230, 2.020,
        1.644, 1.723, 1.093, 1.802, 1.377, 1.876, 1.727, 1.496, 1.832, 1.500,
        1.923, 2.001, 1.655, 1.679, 1.883, 1.532, 1.901, 1.628, 1.316, 1.289,
        1.588, 1.708, 1.238, 2.168, 1.935, 2.050, 1.885, 1.659, 0.978, 1.849],
       device='cuda:0')
b after update for 1 param tensor([ 99.840, 115.850,  80.643, 124.402, 111.314, 109.102, 117.481, 120.528,
        125.680, 110.207,  96.461,  91.878, 118.077, 111.229, 102.761, 119.086,
        115.817, 108.614, 113.187,  92.587, 113.911, 124.499, 130.084, 109.696,
        130.938, 123.095, 113.742, 124.302, 117.950, 119.809,  97.347, 116.406,
        134.407, 130.717, 109.500, 101.144, 120.490, 110.982, 109.371, 107.590,
        120.898, 106.821, 118.790, 119.546, 116.515, 113.148, 128.095, 105.935,
        125.524, 126.015, 122.782, 117.537, 115.660, 109.158, 122.184,  94.474,
        115.052, 116.227, 125.509, 125.922, 131.703, 109.597, 105.683, 121.638,
         97.665, 105.258, 105.749, 120.722, 127.983, 117.588, 123.547, 111.504,
        101.528, 127.662, 112.411, 121.306, 131.556, 112.945, 130.071, 132.417,
        116.606, 116.565, 123.127, 117.093, 114.786, 101.107, 104.175, 128.852,
        126.543, 124.221, 125.226, 109.608, 131.991, 106.963, 115.838, 122.046,
        111.898, 117.141, 128.311,  96.024, 120.524, 120.850, 103.249, 125.978,
        111.106, 121.433, 123.447, 118.095, 115.557, 126.291, 123.065, 110.545,
        120.302, 108.400, 126.732,  81.710, 112.352, 114.687, 131.072, 133.035,
        107.365,  94.369, 123.146, 138.326, 111.802, 105.561, 119.464, 126.396,
        125.290, 131.734, 122.881, 114.650, 125.266, 116.711, 103.740, 130.181,
        122.208, 115.937,  91.752, 126.331, 118.260, 119.192, 120.911, 110.580,
        116.479,  98.318, 109.056, 129.481,  89.139, 100.970, 109.863, 104.250,
        102.910, 107.880, 117.827, 120.776, 113.943, 117.137, 125.539, 105.659,
        109.756, 119.017, 119.295, 109.969, 119.271, 120.936, 116.281, 118.683,
        131.566, 125.225, 112.961, 115.632,  92.106, 118.262, 103.375, 120.673,
        115.766, 107.759, 119.257, 107.880, 122.167, 124.623, 113.347, 114.161,
        120.893, 109.024, 121.476, 112.410, 101.064, 100.004, 111.002, 115.133,
         98.034, 129.716, 122.536, 126.148, 120.957, 113.456,  87.108, 119.781],
       device='cuda:0')
clipping threshold 1.1078602803754565
a after update for 1 param tensor([[[-1.119e-01],
         [-1.166e-01],
         [ 2.044e-02],
         [ 3.334e-01],
         [ 9.066e-02],
         [-1.351e-01],
         [ 1.263e-01],
         [-1.195e-01],
         [-1.933e-02],
         [-2.809e-01]],

        [[-1.733e-01],
         [-7.642e-02],
         [-1.876e-01],
         [-2.995e-01],
         [ 2.738e-01],
         [ 1.601e-01],
         [-1.037e-01],
         [ 1.577e-01],
         [-4.823e-04],
         [ 1.831e-01]],

        [[-1.049e-02],
         [-3.138e-02],
         [ 2.634e-02],
         [-3.243e-01],
         [-2.831e-02],
         [ 1.179e-01],
         [ 1.659e-01],
         [-8.059e-02],
         [ 6.236e-02],
         [-2.523e-01]],

        [[-6.558e-02],
         [-2.136e-01],
         [-7.098e-02],
         [-6.012e-02],
         [-4.185e-02],
         [-2.094e-02],
         [ 4.305e-02],
         [-1.284e-01],
         [-1.721e-01],
         [-1.221e-01]],

        [[-9.724e-02],
         [ 3.647e-01],
         [-3.991e-02],
         [ 1.496e-01],
         [-9.359e-02],
         [ 1.220e-01],
         [ 1.297e-01],
         [-2.159e-02],
         [-1.403e-01],
         [-6.786e-02]],

        [[-5.470e-02],
         [ 2.247e-02],
         [-1.850e-02],
         [ 2.561e-02],
         [-3.164e-01],
         [-5.750e-03],
         [-2.378e-02],
         [ 9.553e-02],
         [ 4.103e-02],
         [ 7.712e-02]],

        [[-2.178e-01],
         [-1.537e-03],
         [-5.940e-02],
         [ 7.472e-02],
         [ 2.277e-02],
         [ 9.918e-02],
         [ 2.007e-01],
         [-3.738e-02],
         [ 4.424e-01],
         [-7.081e-02]],

        [[ 1.711e-01],
         [-5.129e-02],
         [ 1.198e-01],
         [ 5.587e-02],
         [ 1.624e-01],
         [ 4.285e-02],
         [-8.383e-02],
         [ 1.863e-02],
         [-6.973e-02],
         [-1.414e-01]],

        [[-1.528e-01],
         [ 9.477e-02],
         [-1.971e-01],
         [ 3.146e-02],
         [ 7.998e-02],
         [ 6.444e-02],
         [ 3.247e-01],
         [ 4.489e-02],
         [-1.128e-02],
         [-6.865e-02]],

        [[ 6.059e-02],
         [-4.710e-02],
         [ 1.091e-01],
         [ 1.986e-01],
         [ 1.698e-02],
         [ 9.595e-02],
         [ 5.274e-02],
         [ 4.934e-02],
         [ 5.356e-02],
         [ 1.371e-01]],

        [[-1.577e-01],
         [ 7.497e-02],
         [ 6.098e-02],
         [-1.095e-01],
         [-8.292e-02],
         [-1.886e-03],
         [ 1.227e-01],
         [ 2.898e-01],
         [ 2.654e-01],
         [-1.254e-01]],

        [[ 9.531e-03],
         [ 7.304e-02],
         [-7.742e-02],
         [ 8.127e-02],
         [ 4.043e-03],
         [ 4.432e-02],
         [-4.709e-01],
         [ 8.145e-02],
         [-1.940e-01],
         [-5.729e-02]],

        [[-1.612e-01],
         [ 7.955e-02],
         [-1.303e-02],
         [ 1.190e-01],
         [ 1.147e-01],
         [-3.365e-01],
         [ 2.548e-02],
         [-8.710e-02],
         [ 1.806e-01],
         [-5.751e-02]],

        [[-1.030e-01],
         [ 4.859e-02],
         [-1.730e-02],
         [-3.158e-01],
         [ 8.410e-02],
         [ 1.548e-01],
         [-1.776e-01],
         [-1.125e-01],
         [ 6.763e-02],
         [-1.865e-01]],

        [[ 1.373e-01],
         [-1.172e-01],
         [ 1.272e-01],
         [ 1.737e-03],
         [ 2.209e-01],
         [ 8.677e-02],
         [-2.959e-01],
         [-3.876e-02],
         [ 2.303e-02],
         [ 2.544e-01]],

        [[-7.639e-02],
         [-4.945e-03],
         [ 8.141e-02],
         [ 4.339e-02],
         [-2.180e-01],
         [-3.789e-01],
         [ 2.038e-01],
         [-3.562e-02],
         [-3.854e-02],
         [ 2.536e-01]],

        [[-9.136e-02],
         [ 3.332e-02],
         [-1.014e-01],
         [-2.811e-02],
         [-1.361e-01],
         [-5.635e-02],
         [-1.440e-01],
         [ 5.463e-02],
         [ 1.028e-03],
         [ 2.526e-02]],

        [[-2.105e-01],
         [ 2.311e-01],
         [-9.213e-02],
         [-9.652e-03],
         [ 1.738e-01],
         [ 1.659e-01],
         [ 1.130e-01],
         [ 2.707e-01],
         [-6.768e-03],
         [ 3.718e-01]],

        [[ 2.957e-01],
         [-1.258e-01],
         [-1.520e-01],
         [-1.349e-01],
         [-1.559e-01],
         [ 1.885e-01],
         [ 1.683e-01],
         [-1.077e-01],
         [-1.251e-01],
         [-2.054e-02]],

        [[-1.677e-01],
         [-5.008e-02],
         [ 3.290e-02],
         [ 2.303e-02],
         [ 5.112e-01],
         [ 3.904e-02],
         [-2.995e-02],
         [ 6.727e-02],
         [-1.440e-02],
         [ 1.048e-01]]], device='cuda:0')
s after update for 1 param tensor([[[1.981],
         [1.627],
         [1.839],
         [1.484],
         [1.762],
         [2.070],
         [2.014],
         [2.271],
         [2.063],
         [1.528]],

        [[1.308],
         [1.666],
         [1.765],
         [2.100],
         [1.391],
         [1.161],
         [1.534],
         [1.457],
         [1.754],
         [2.466]],

        [[1.854],
         [1.618],
         [1.891],
         [1.977],
         [1.242],
         [1.472],
         [1.391],
         [1.801],
         [1.813],
         [1.599]],

        [[1.429],
         [1.322],
         [2.153],
         [1.712],
         [1.591],
         [2.200],
         [1.443],
         [1.337],
         [1.805],
         [1.155]],

        [[2.184],
         [1.725],
         [1.565],
         [2.035],
         [1.786],
         [2.130],
         [1.727],
         [1.572],
         [2.090],
         [1.902]],

        [[1.967],
         [1.163],
         [2.018],
         [2.079],
         [2.214],
         [1.597],
         [1.597],
         [1.859],
         [1.463],
         [1.450]],

        [[1.076],
         [1.634],
         [1.127],
         [1.158],
         [1.563],
         [1.687],
         [1.853],
         [1.481],
         [1.530],
         [1.249]],

        [[2.292],
         [1.646],
         [1.548],
         [1.754],
         [1.793],
         [1.826],
         [1.552],
         [1.977],
         [1.769],
         [2.026]],

        [[1.042],
         [1.953],
         [1.839],
         [1.552],
         [2.259],
         [1.784],
         [2.099],
         [2.451],
         [1.169],
         [1.919]],

        [[1.309],
         [1.436],
         [1.816],
         [1.743],
         [1.770],
         [1.678],
         [2.267],
         [1.351],
         [1.751],
         [1.858]],

        [[1.941],
         [1.368],
         [2.179],
         [2.116],
         [1.559],
         [1.645],
         [1.504],
         [1.972],
         [2.001],
         [1.932]],

        [[1.464],
         [1.718],
         [1.649],
         [1.709],
         [2.097],
         [1.771],
         [1.697],
         [1.320],
         [1.505],
         [1.737]],

        [[2.200],
         [2.088],
         [1.663],
         [1.692],
         [2.017],
         [1.563],
         [1.261],
         [1.899],
         [1.660],
         [1.956]],

        [[1.667],
         [1.807],
         [2.092],
         [2.037],
         [1.738],
         [1.755],
         [1.912],
         [1.924],
         [1.771],
         [1.569]],

        [[1.396],
         [1.632],
         [1.479],
         [2.082],
         [1.846],
         [1.148],
         [1.590],
         [2.063],
         [2.209],
         [2.078]],

        [[1.595],
         [1.857],
         [1.767],
         [2.093],
         [2.193],
         [1.418],
         [1.920],
         [1.810],
         [1.366],
         [1.527]],

        [[1.517],
         [1.939],
         [2.075],
         [1.658],
         [2.171],
         [1.360],
         [1.235],
         [1.812],
         [2.193],
         [1.361]],

        [[1.991],
         [1.745],
         [1.684],
         [2.238],
         [1.959],
         [1.836],
         [1.322],
         [1.853],
         [1.744],
         [1.777]],

        [[1.830],
         [2.104],
         [2.356],
         [1.544],
         [1.616],
         [1.530],
         [1.667],
         [1.656],
         [1.772],
         [2.020]],

        [[1.753],
         [1.901],
         [2.284],
         [2.192],
         [2.185],
         [1.540],
         [2.096],
         [1.647],
         [1.451],
         [1.653]]], device='cuda:0')
b after update for 1 param tensor([[[124.010],
         [112.355],
         [119.457],
         [107.302],
         [116.937],
         [126.751],
         [125.032],
         [132.767],
         [126.522],
         [108.894]],

        [[100.748],
         [113.704],
         [117.041],
         [127.669],
         [103.897],
         [ 94.920],
         [109.119],
         [106.326],
         [116.682],
         [138.341]],

        [[119.955],
         [112.048],
         [121.132],
         [123.877],
         [ 98.185],
         [106.871],
         [103.916],
         [118.241],
         [118.619],
         [111.400]],

        [[105.316],
         [101.300],
         [129.275],
         [115.260],
         [111.129],
         [130.677],
         [105.818],
         [101.861],
         [118.363],
         [ 94.660]],

        [[130.200],
         [115.720],
         [110.219],
         [125.682],
         [117.734],
         [128.578],
         [115.781],
         [110.443],
         [127.365],
         [121.496]],

        [[123.569],
         [ 95.017],
         [125.150],
         [127.034],
         [131.089],
         [111.334],
         [111.331],
         [120.116],
         [106.574],
         [106.094]],

        [[ 91.367],
         [112.614],
         [ 93.530],
         [ 94.800],
         [110.132],
         [114.436],
         [119.936],
         [107.222],
         [108.953],
         [ 98.455]],

        [[133.373],
         [113.026],
         [109.615],
         [116.668],
         [117.964],
         [119.043],
         [109.754],
         [123.872],
         [117.166],
         [125.382]],

        [[ 89.908],
         [123.111],
         [119.469],
         [109.767],
         [132.400],
         [117.654],
         [127.629],
         [137.921],
         [ 95.235],
         [122.041]],

        [[100.790],
         [105.579],
         [118.715],
         [116.296],
         [117.205],
         [114.114],
         [132.632],
         [102.405],
         [116.562],
         [120.098]],

        [[122.746],
         [103.036],
         [130.046],
         [128.135],
         [109.983],
         [112.991],
         [108.023],
         [123.721],
         [124.624],
         [122.451]],

        [[106.599],
         [115.455],
         [113.143],
         [115.169],
         [127.577],
         [117.231],
         [114.748],
         [101.226],
         [108.071],
         [116.094]],

        [[130.664],
         [127.311],
         [113.623],
         [114.602],
         [125.123],
         [110.135],
         [ 98.934],
         [121.401],
         [113.499],
         [123.198]],

        [[113.760],
         [118.415],
         [127.422],
         [125.726],
         [116.143],
         [116.709],
         [121.804],
         [122.188],
         [117.242],
         [110.348]],

        [[104.087],
         [112.531],
         [107.121],
         [127.128],
         [119.701],
         [ 94.396],
         [111.071],
         [126.541],
         [130.937],
         [126.985]],

        [[111.254],
         [120.050],
         [117.101],
         [127.445],
         [130.467],
         [104.894],
         [122.069],
         [118.510],
         [102.958],
         [108.872]],

        [[108.521],
         [122.669],
         [126.907],
         [113.446],
         [129.795],
         [102.729],
         [ 97.886],
         [118.591],
         [130.454],
         [102.765]],

        [[124.301],
         [116.390],
         [114.333],
         [131.801],
         [123.292],
         [119.380],
         [101.282],
         [119.937],
         [116.330],
         [117.424]],

        [[119.189],
         [127.789],
         [135.210],
         [109.460],
         [112.005],
         [108.954],
         [113.748],
         [113.353],
         [117.263],
         [125.211]],

        [[116.653],
         [121.452],
         [133.136],
         [130.420],
         [130.234],
         [109.325],
         [127.530],
         [113.046],
         [106.117],
         [113.281]]], device='cuda:0')
clipping threshold 1.1078602803754565
a after update for 1 param tensor([[ 2.015e-02],
        [-3.190e-02],
        [ 5.548e-02],
        [ 4.625e-02],
        [ 9.320e-02],
        [-1.906e-01],
        [ 5.688e-02],
        [-3.115e-02],
        [ 2.693e-02],
        [-4.728e-02],
        [ 1.484e-02],
        [ 3.026e-01],
        [ 4.579e-02],
        [-1.107e-01],
        [-2.063e-01],
        [-8.044e-02],
        [-1.207e-01],
        [-1.578e-04],
        [-2.650e-01],
        [ 9.243e-03]], device='cuda:0')
s after update for 1 param tensor([[2.228],
        [1.784],
        [1.146],
        [1.676],
        [2.070],
        [2.150],
        [1.301],
        [1.885],
        [1.896],
        [1.617],
        [1.865],
        [2.429],
        [1.857],
        [1.885],
        [2.230],
        [2.094],
        [2.039],
        [1.408],
        [1.569],
        [1.591]], device='cuda:0')
b after update for 1 param tensor([[131.497],
        [117.680],
        [ 94.300],
        [114.045],
        [126.735],
        [129.186],
        [100.487],
        [120.967],
        [121.292],
        [112.036],
        [120.312],
        [137.297],
        [120.056],
        [120.954],
        [131.544],
        [127.482],
        [125.810],
        [104.533],
        [110.349],
        [111.131]], device='cuda:0')
clipping threshold 1.1078602803754565
||w||^2 1.0484744825456014
exp ma of ||w||^2 2.358592367091237
||w|| 1.023950429730659
exp ma of ||w|| 1.4480131212366258
||w||^2 4.17241298777422
exp ma of ||w||^2 2.0930184507704896
||w|| 2.0426485228188964
exp ma of ||w|| 1.3934446689492546
v before min max tensor([[ -66.014,   46.468,   50.079,  ...,  486.829,  158.733,  -87.803],
        [ -71.570,  246.327, -126.787,  ..., -107.493,  -63.086, -120.057],
        [ -78.891, -128.285,  485.205,  ..., -100.283,  -52.724,  -53.900],
        ...,
        [-105.542, -138.878,  -90.659,  ..., -137.732,  -79.740, -146.270],
        [  66.149,   -7.782,  -89.590,  ...,  -47.979,  -62.290,  -24.955],
        [ 223.411, -142.455,  -69.116,  ...,  -68.797, -134.497,   15.902]],
       device='cuda:0')
v tensor([[1.000e-12, 1.000e+01, 1.000e+01,  ..., 1.000e+01, 1.000e+01,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e+01]], device='cuda:0')
v before min max tensor([ 8.581e+01, -1.104e+02, -1.390e+02, -9.694e+01, -1.057e+02,  7.769e+01,
        -1.086e+02, -9.785e+01,  9.701e+01, -1.437e+02, -7.197e+01, -1.494e+02,
        -1.920e+01, -3.516e+01, -1.067e+02, -1.416e+02, -5.649e+01, -7.473e+01,
        -1.096e+02,  1.117e+02,  4.423e+02, -5.287e+01, -1.156e+02, -3.231e+01,
        -3.839e+01, -9.592e+01,  3.802e+01, -1.183e+02,  2.643e+03, -9.536e+01,
        -1.058e+02, -3.574e+01,  3.972e+02, -1.251e+02, -7.507e+01, -1.340e+02,
        -9.135e+01, -9.721e+01, -6.879e+01, -1.189e+02, -1.594e+02, -1.140e+02,
        -1.242e+02, -9.165e+01, -5.798e+01, -1.392e+02, -1.230e+02, -1.097e+02,
         9.230e+00,  2.479e+01, -1.826e+01, -1.347e+02,  6.672e+02, -6.623e+01,
        -1.145e+02, -5.837e+01, -7.506e+00, -1.164e+02, -9.937e+01, -4.708e+01,
        -6.823e+01, -7.937e+00, -1.026e+02,  1.914e+02, -7.206e+01, -1.436e+02,
        -1.106e+02,  1.286e+02,  1.144e+01, -1.170e+02, -1.168e+02, -6.942e+01,
        -1.212e+02,  1.445e+02, -8.602e+01, -8.228e+01,  2.479e+02, -1.026e+02,
         9.426e+01,  4.559e+01,  1.329e+01, -1.158e+02,  1.426e+01, -7.184e+01,
        -9.691e+01, -1.034e+02,  1.245e+02, -1.262e+02, -1.277e+02, -1.222e+02,
        -1.145e+02, -3.707e+01, -1.175e+02,  1.040e+02,  2.008e+02, -9.636e+01,
        -4.349e+01,  2.405e+02, -4.647e+01, -2.364e+01, -1.352e+02, -1.094e+02,
        -8.770e+01,  2.289e+02, -8.827e+01, -1.167e+01, -1.188e+02, -6.189e+00,
        -1.212e+02, -8.062e+01, -2.579e+01, -5.335e+01, -1.150e+02,  3.313e+02,
        -1.197e+02,  1.226e+02, -4.536e+01,  4.803e+01, -1.466e+02, -1.154e+02,
        -1.067e+02,  4.095e+01,  1.961e+02, -8.795e+01,  4.370e+02,  8.053e+01,
        -9.031e+01, -4.783e+01, -1.238e+02,  6.349e+01, -6.083e+01,  3.382e+01,
         1.481e+02, -7.581e+01,  2.522e-02, -1.059e+02, -1.257e+02,  3.416e+01,
         2.845e+01, -1.064e+02, -8.957e+01, -1.154e+02,  1.043e+02, -1.459e+02,
        -1.516e+02,  7.095e+01, -1.272e+02, -3.415e+01, -8.752e+01, -1.041e+02,
        -3.415e+01, -8.612e+01, -3.584e+01,  6.035e+02, -9.696e+01,  1.854e+02,
        -1.013e+02, -8.864e+01, -1.134e+02, -7.081e+01, -1.111e+02, -1.046e+02,
         1.392e+02, -7.866e+01,  1.277e+01, -1.037e+02, -9.443e+01,  1.840e+01,
        -4.556e+01, -9.906e+01, -1.322e+02, -7.921e+01,  2.720e+01, -6.612e+01,
        -7.185e+01,  9.003e+01, -1.063e+02, -9.183e+01, -2.740e+01,  3.430e+01,
         2.397e+01, -5.781e+01, -1.324e+02, -6.443e+00, -1.378e+02,  1.769e+02,
        -7.141e+01,  7.344e+02, -1.266e+02, -1.137e+02, -1.122e+02, -8.325e+01,
         1.002e+02, -9.485e+01, -1.286e+02, -1.069e+02, -1.412e+02, -1.318e+02,
        -1.292e+02, -2.068e+01], device='cuda:0')
v tensor([1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        9.230e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 2.522e-02, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12], device='cuda:0')
v before min max tensor([[[-1.506e+02],
         [-8.847e+01],
         [ 9.186e+01],
         [-9.980e+01],
         [-9.550e+01],
         [-1.249e+02],
         [-1.288e+02],
         [-7.817e+01],
         [-9.904e+00],
         [ 4.377e+01]],

        [[ 3.558e+01],
         [ 3.338e+02],
         [-5.002e+01],
         [-8.282e+01],
         [ 2.767e+02],
         [ 3.791e+02],
         [-1.352e+02],
         [-7.692e+01],
         [-1.030e+02],
         [ 2.149e+02]],

        [[ 7.371e+01],
         [-9.526e+01],
         [-1.477e+02],
         [ 3.263e+01],
         [ 4.875e+01],
         [-1.406e+02],
         [-2.012e+01],
         [ 1.673e+02],
         [-1.158e+02],
         [ 8.675e+01]],

        [[-9.349e+01],
         [-1.233e+01],
         [ 9.116e+01],
         [ 1.280e+02],
         [-1.356e+02],
         [-7.924e+01],
         [-1.187e+02],
         [-1.012e+02],
         [ 4.495e+02],
         [-1.205e+02]],

        [[-1.446e+02],
         [-1.265e+02],
         [-7.727e+01],
         [-2.838e+01],
         [-5.169e+01],
         [-2.914e+01],
         [-1.238e+02],
         [-1.118e+02],
         [-3.648e+01],
         [-9.744e+01]],

        [[-1.091e+02],
         [ 1.055e+02],
         [-4.721e+01],
         [ 6.979e+01],
         [-1.525e+02],
         [-9.419e+01],
         [-2.891e+01],
         [ 3.239e+02],
         [ 4.694e+02],
         [-8.987e+01]],

        [[ 6.876e+01],
         [-9.036e+01],
         [ 2.610e-01],
         [ 2.079e+02],
         [-1.090e+02],
         [-9.278e+01],
         [-1.093e+02],
         [ 2.524e+02],
         [-1.012e+01],
         [-6.681e+01]],

        [[ 1.145e+02],
         [ 1.582e+02],
         [ 3.152e+02],
         [-1.296e+02],
         [-1.157e+02],
         [ 1.797e+02],
         [ 1.692e+02],
         [ 1.090e+02],
         [ 1.747e+02],
         [-1.311e+02]],

        [[-1.110e+02],
         [-2.396e+01],
         [ 1.462e+02],
         [-6.322e+01],
         [ 4.673e+02],
         [-5.990e+01],
         [-8.089e+01],
         [-1.055e+02],
         [-7.340e+01],
         [-1.101e+02]],

        [[-1.231e+02],
         [-1.034e+02],
         [-7.406e+01],
         [ 1.037e+01],
         [-4.260e+01],
         [-3.541e+01],
         [-4.187e+01],
         [-1.309e+02],
         [ 3.528e+01],
         [-1.107e+02]],

        [[-1.207e+02],
         [-4.344e+01],
         [ 4.149e+01],
         [-7.480e+01],
         [-7.926e+01],
         [-8.404e+01],
         [-9.546e+01],
         [-1.393e+02],
         [-7.108e+01],
         [-1.087e+02]],

        [[-1.168e+02],
         [-7.315e+01],
         [-4.435e+01],
         [ 1.752e+02],
         [-4.637e+01],
         [ 1.343e+02],
         [-1.594e+02],
         [-1.097e+02],
         [-2.145e+01],
         [-3.584e+01]],

        [[ 2.681e+01],
         [-7.539e+01],
         [-2.382e+01],
         [-1.310e+02],
         [ 1.001e+02],
         [-9.507e+01],
         [ 1.910e+01],
         [-8.453e+01],
         [-9.947e+01],
         [ 4.531e+01]],

        [[ 6.963e+01],
         [ 2.812e+02],
         [-1.299e+02],
         [ 3.502e+01],
         [ 5.809e+02],
         [-1.406e+02],
         [-1.019e+02],
         [ 3.184e+02],
         [-8.254e+01],
         [ 2.703e+02]],

        [[-8.956e+01],
         [-1.001e+02],
         [-1.111e+02],
         [-6.836e+01],
         [-1.044e+02],
         [-3.608e+01],
         [-2.293e+01],
         [ 4.336e+00],
         [ 3.513e+00],
         [-6.962e+01]],

        [[-6.794e+01],
         [ 8.507e+00],
         [-1.915e+01],
         [-1.351e+02],
         [-5.517e+01],
         [-8.506e+01],
         [-4.698e+01],
         [-1.068e+02],
         [-8.741e+01],
         [ 3.093e+02]],

        [[-1.028e+02],
         [-1.209e+02],
         [-1.180e+02],
         [-1.434e+02],
         [ 1.730e+01],
         [-4.850e+01],
         [-1.512e+02],
         [-9.324e+01],
         [ 3.080e+02],
         [-1.598e+01]],

        [[ 6.056e+01],
         [-1.331e+02],
         [-1.215e+02],
         [-5.883e+01],
         [-1.290e+02],
         [ 2.151e+02],
         [-1.238e+02],
         [-9.500e+01],
         [-6.804e+01],
         [-1.418e+02]],

        [[-1.405e+02],
         [ 7.872e+01],
         [-6.952e+01],
         [-1.089e+02],
         [ 1.953e+01],
         [-6.050e+01],
         [ 8.907e+01],
         [-5.420e+01],
         [ 2.214e+01],
         [ 9.206e+01]],

        [[-6.534e+01],
         [-9.328e+01],
         [-1.031e+02],
         [-1.262e+02],
         [ 3.791e+02],
         [ 1.183e+01],
         [-1.186e+02],
         [-1.180e+02],
         [-6.976e+01],
         [-9.847e+01]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [2.610e-01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.336e+00],
         [3.513e+00],
         [1.000e-12]],

        [[1.000e-12],
         [8.507e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[ -44.115],
        [ 125.516],
        [ 348.383],
        [-109.405],
        [ -41.499],
        [ -39.125],
        [   3.402],
        [ -36.006],
        [ -77.263],
        [ -79.107],
        [ -66.482],
        [ -41.488],
        [ 323.881],
        [ -51.914],
        [ -52.822],
        [-128.640],
        [ -99.226],
        [-132.050],
        [ -72.068],
        [-154.461]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [3.402e+00],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 0.017, -0.087, -0.280,  ..., -0.228,  0.125, -0.139],
        [-0.126, -0.175, -0.072,  ...,  0.187,  0.102,  0.046],
        [ 0.004, -0.162,  0.042,  ..., -0.079,  0.050, -0.052],
        ...,
        [-0.092, -0.178, -0.054,  ...,  0.101,  0.041,  0.061],
        [ 0.026, -0.029,  0.112,  ..., -0.042, -0.005, -0.001],
        [-0.025,  0.061, -0.081,  ..., -0.015, -0.135, -0.017]],
       device='cuda:0')
s after update for 1 param tensor([[1.637, 1.382, 1.544,  ..., 2.285, 1.563, 1.521],
        [1.678, 1.705, 2.109,  ..., 1.986, 1.606, 2.072],
        [1.922, 1.962, 2.016,  ..., 1.363, 0.996, 1.292],
        ...,
        [1.347, 1.860, 1.574,  ..., 1.762, 1.414, 1.867],
        [1.952, 0.810, 1.579,  ..., 1.216, 1.272, 1.490],
        [2.287, 1.837, 1.617,  ..., 0.882, 1.734, 1.662]], device='cuda:0')
b after update for 1 param tensor([[110.297, 101.344, 107.137,  ..., 130.342, 107.791, 106.345],
        [111.676, 112.575, 125.219,  ..., 121.495, 109.246, 124.120],
        [119.527, 120.772, 122.417,  ..., 100.660,  86.050,  97.983],
        ...,
        [100.067, 117.601, 108.168,  ..., 114.436, 102.541, 117.795],
        [120.459,  77.597, 108.345,  ...,  95.075,  97.256, 105.235],
        [130.383, 116.853, 109.619,  ...,  80.991, 113.537, 111.136]],
       device='cuda:0')
clipping threshold 1.1702407666724517
a after update for 1 param tensor([ 5.353e-03,  7.394e-02,  1.866e-02, -7.507e-02,  6.252e-02, -1.973e-01,
         1.679e-01,  6.777e-02,  9.971e-02,  1.380e-02, -4.066e-02,  8.397e-02,
         1.910e-01, -1.708e-01,  1.757e-01,  5.839e-02,  7.998e-02,  8.381e-02,
         8.116e-03,  6.876e-03,  9.227e-02,  1.231e-01, -1.208e-01,  2.354e-04,
         1.148e-01,  2.778e-01, -9.976e-02,  1.028e-01,  1.878e-01,  3.053e-02,
        -1.517e-01, -9.657e-02, -3.100e-02, -9.065e-02, -5.745e-02, -1.803e-01,
        -4.390e-02, -3.098e-02, -1.021e-01, -2.969e-02,  1.352e-01, -1.447e-03,
        -2.292e-01,  1.309e-03,  1.324e-01, -1.620e-01,  7.585e-02,  8.584e-02,
        -1.224e-01,  9.319e-02,  2.825e-03,  1.626e-01,  1.555e-02, -1.699e-01,
        -1.289e-01,  9.610e-02,  1.302e-01, -6.178e-02, -3.274e-02, -1.791e-01,
        -1.143e-01,  1.086e-01, -1.612e-01, -1.958e-01,  2.364e-01, -8.115e-02,
         1.620e-01,  8.997e-02, -1.093e-01, -8.087e-03,  1.336e-01, -3.137e-01,
        -2.218e-02,  3.731e-03,  8.921e-02,  3.702e-02, -3.698e-02,  7.309e-02,
        -4.353e-02,  1.638e-01,  9.791e-02, -5.561e-02,  8.588e-02,  2.968e-01,
        -2.095e-01, -6.072e-02,  5.072e-03,  1.159e-02,  1.399e-01, -6.368e-02,
        -1.148e-01,  1.170e-01, -2.303e-01,  6.068e-02, -4.621e-02,  1.209e-01,
        -8.767e-02, -9.871e-02, -6.676e-02, -1.763e-01, -1.684e-01,  1.085e-01,
        -1.830e-01,  2.595e-02, -6.370e-02, -3.542e-02, -1.631e-01, -1.082e-03,
         2.891e-02,  3.386e-01, -1.409e-01,  2.030e-02, -1.711e-01, -8.380e-02,
         1.318e-01, -8.023e-02,  2.244e-01, -8.776e-02,  1.059e-01, -2.146e-01,
         6.052e-02, -2.371e-02, -5.175e-05, -1.031e-02,  3.856e-02, -1.523e-02,
         3.374e-01,  2.106e-02,  1.516e-02, -2.846e-02, -3.010e-02,  6.622e-02,
        -7.906e-02,  1.190e-01,  5.626e-03,  4.005e-02, -3.548e-02, -8.973e-02,
         2.716e-01,  1.914e-01,  1.214e-01,  5.637e-02,  1.862e-01,  4.216e-02,
         5.424e-02, -1.218e-02, -1.199e-01,  8.586e-02,  7.808e-03,  6.510e-02,
         3.353e-02,  2.861e-02, -2.460e-01,  3.671e-02, -9.818e-02,  8.570e-02,
         1.411e-01, -5.385e-02,  1.173e-01,  1.296e-01,  8.424e-02,  6.139e-02,
         1.910e-01, -9.178e-02,  1.485e-02,  1.554e-01,  3.482e-02,  5.816e-02,
         1.467e-01, -2.654e-02, -2.421e-01,  1.385e-01,  1.513e-01, -1.074e-02,
         2.062e-01,  1.453e-01, -7.528e-02,  2.039e-01, -1.135e-01,  5.421e-02,
         2.504e-01,  1.789e-01, -1.362e-02,  1.307e-01,  4.131e-02,  6.908e-02,
         3.128e-02,  4.977e-03,  2.327e-03, -1.031e-01, -8.163e-02,  2.425e-01,
         1.663e-01, -1.420e-01, -2.343e-01, -7.216e-02, -8.876e-02, -2.787e-03,
        -9.157e-02,  1.821e-01], device='cuda:0')
s after update for 1 param tensor([1.739, 1.644, 1.777, 1.483, 1.347, 1.592, 1.813, 2.150, 1.679, 1.844,
        1.063, 1.930, 1.905, 1.403, 1.455, 2.076, 1.891, 1.727, 1.888, 1.750,
        2.040, 1.519, 1.574, 2.040, 1.251, 1.820, 1.603, 1.519, 2.196, 1.725,
        1.430, 1.282, 1.988, 1.856, 1.939, 1.796, 1.234, 1.301, 1.882, 1.573,
        2.047, 1.800, 1.644, 1.652, 1.151, 1.802, 1.779, 1.525, 1.449, 1.894,
        1.334, 1.812, 2.056, 1.392, 1.462, 1.588, 1.708, 1.483, 1.268, 1.135,
        1.562, 1.484, 1.309, 1.946, 1.518, 2.123, 1.525, 2.337, 1.414, 1.992,
        1.630, 1.838, 1.555, 1.688, 1.584, 1.089, 1.541, 1.868, 2.240, 2.140,
        1.833, 1.828, 1.989, 1.486, 1.689, 1.622, 2.194, 1.618, 1.772, 1.767,
        1.469, 0.892, 1.738, 1.896, 1.896, 1.396, 1.644, 1.886, 1.567, 1.300,
        2.053, 1.573, 1.696, 1.611, 1.752, 1.332, 1.728, 1.634, 1.546, 1.987,
        1.112, 1.501, 2.005, 2.227, 1.736, 1.743, 1.680, 2.232, 1.917, 1.569,
        1.446, 1.509, 1.590, 1.286, 2.061, 1.910, 1.398, 2.020, 1.591, 1.951,
        1.260, 1.940, 1.569, 1.892, 1.557, 1.643, 1.603, 2.233, 2.014, 1.729,
        1.783, 1.483, 1.627, 2.425, 2.091, 2.145, 1.768, 1.688, 1.250, 1.556,
        1.330, 1.224, 1.656, 1.996, 2.017, 1.800, 1.377, 1.143, 1.930, 1.762,
        1.497, 1.381, 2.073, 1.230, 1.406, 1.640, 1.348, 1.926, 1.847, 1.473,
        1.902, 1.307, 1.486, 1.098, 1.362, 2.002, 1.679, 1.520, 1.473, 1.745,
        2.112, 2.117, 1.704, 1.914, 1.794, 2.089, 1.051, 1.833, 1.638, 1.506,
        1.652, 1.581, 1.514, 1.405, 1.658, 1.365, 1.807, 1.681, 1.756, 1.095],
       device='cuda:0')
b after update for 1 param tensor([113.703, 110.558, 114.917, 104.990, 100.070, 108.777, 116.090, 126.422,
        111.733, 117.075,  88.872, 119.792, 119.014, 102.106, 104.004, 124.239,
        118.567, 113.302, 118.462, 114.062, 123.137, 106.255, 108.167, 123.154,
         96.423, 116.302, 109.156, 106.244, 127.772, 113.248, 103.113,  97.622,
        121.568, 117.454, 120.047, 115.530,  95.761,  98.350, 118.280, 108.133,
        123.355, 115.677, 110.544, 110.810,  92.511, 115.743, 115.008, 106.474,
        103.773, 118.654,  99.590, 116.045, 123.616, 101.726, 104.259, 108.650,
        112.694, 105.008,  97.105,  91.848, 107.743, 105.038,  98.629, 120.273,
        106.232, 125.617, 106.455, 131.799, 102.524, 121.701, 110.087, 116.882,
        107.504, 112.016, 108.497,  89.986, 107.022, 117.850, 129.031, 126.114,
        116.738, 116.580, 121.589, 105.112, 112.050, 109.791, 127.706, 109.664,
        114.761, 114.608, 104.502,  81.439, 113.675, 118.719, 118.711, 101.879,
        110.557, 118.401, 107.912,  98.294, 123.533, 108.121, 112.278, 109.443,
        114.123,  99.504, 113.331, 110.198, 107.185, 121.532,  90.936, 105.622,
        122.095, 128.666, 113.610, 113.819, 111.760, 128.800, 119.361, 107.998,
        103.689, 105.925, 108.716,  97.790, 123.767, 119.150, 101.949, 122.545,
        108.746, 120.430,  96.766, 120.079, 107.997, 118.587, 107.597, 110.499,
        109.157, 128.837, 122.350, 113.382, 115.119, 104.981, 109.970, 134.268,
        124.685, 126.278, 114.636, 112.021,  96.409, 107.549,  99.438,  95.389,
        110.936, 121.795, 122.456, 115.669, 101.173,  92.165, 119.791, 114.442,
        105.480, 101.312, 124.148,  95.602, 102.216, 110.420, 100.109, 119.657,
        117.173, 104.656, 118.920,  98.568, 105.117,  90.349, 100.620, 121.996,
        111.734, 106.284, 104.644, 113.882, 125.293, 125.443, 112.537, 119.280,
        115.492, 124.607,  88.387, 116.738, 110.348, 105.814, 110.799, 108.405,
        106.099, 102.184, 111.003, 100.744, 115.903, 111.796, 114.236,  90.214],
       device='cuda:0')
clipping threshold 1.1702407666724517
a after update for 1 param tensor([[[-0.169],
         [-0.084],
         [ 0.051],
         [ 0.311],
         [-0.006],
         [-0.149],
         [ 0.089],
         [-0.146],
         [ 0.044],
         [-0.169]],

        [[-0.181],
         [-0.064],
         [-0.176],
         [-0.303],
         [ 0.202],
         [ 0.017],
         [-0.065],
         [ 0.109],
         [-0.038],
         [ 0.131]],

        [[-0.007],
         [-0.037],
         [ 0.053],
         [-0.339],
         [-0.090],
         [ 0.198],
         [ 0.151],
         [-0.005],
         [ 0.127],
         [-0.189]],

        [[-0.006],
         [-0.083],
         [-0.108],
         [-0.118],
         [-0.095],
         [ 0.018],
         [-0.192],
         [-0.175],
         [-0.159],
         [-0.128]],

        [[-0.024],
         [ 0.350],
         [-0.108],
         [ 0.007],
         [-0.068],
         [ 0.236],
         [ 0.112],
         [-0.081],
         [-0.127],
         [-0.027]],

        [[-0.073],
         [ 0.011],
         [ 0.016],
         [ 0.045],
         [-0.310],
         [ 0.121],
         [-0.024],
         [ 0.177],
         [ 0.018],
         [-0.028]],

        [[-0.126],
         [ 0.091],
         [ 0.070],
         [ 0.177],
         [ 0.061],
         [ 0.181],
         [ 0.267],
         [ 0.101],
         [ 0.348],
         [-0.023]],

        [[ 0.179],
         [-0.098],
         [ 0.124],
         [ 0.131],
         [ 0.111],
         [ 0.020],
         [ 0.068],
         [ 0.027],
         [ 0.030],
         [-0.117]],

        [[-0.067],
         [ 0.085],
         [-0.174],
         [ 0.035],
         [ 0.018],
         [ 0.131],
         [ 0.308],
         [ 0.127],
         [ 0.051],
         [-0.194]],

        [[ 0.060],
         [-0.050],
         [ 0.053],
         [ 0.178],
         [ 0.059],
         [ 0.126],
         [ 0.009],
         [ 0.113],
         [ 0.009],
         [ 0.098]],

        [[-0.124],
         [ 0.100],
         [ 0.076],
         [-0.190],
         [-0.085],
         [-0.025],
         [ 0.177],
         [ 0.178],
         [ 0.141],
         [ 0.004]],

        [[-0.114],
         [ 0.129],
         [-0.101],
         [ 0.050],
         [-0.015],
         [ 0.128],
         [-0.385],
         [ 0.130],
         [-0.124],
         [-0.046]],

        [[-0.054],
         [ 0.023],
         [ 0.050],
         [ 0.161],
         [ 0.073],
         [-0.359],
         [-0.028],
         [-0.032],
         [ 0.226],
         [-0.059]],

        [[-0.128],
         [ 0.037],
         [ 0.025],
         [-0.222],
         [ 0.053],
         [-0.022],
         [-0.084],
         [-0.147],
         [ 0.028],
         [-0.124]],

        [[ 0.162],
         [-0.070],
         [ 0.127],
         [ 0.014],
         [ 0.246],
         [ 0.074],
         [-0.240],
         [-0.073],
         [-0.002],
         [ 0.207]],

        [[-0.119],
         [ 0.041],
         [ 0.064],
         [-0.021],
         [-0.233],
         [-0.295],
         [ 0.130],
         [-0.050],
         [-0.018],
         [ 0.194]],

        [[-0.099],
         [ 0.066],
         [-0.076],
         [-0.072],
         [-0.069],
         [ 0.011],
         [-0.178],
         [ 0.089],
         [-0.122],
         [-0.031]],

        [[-0.117],
         [ 0.305],
         [-0.107],
         [ 0.226],
         [ 0.126],
         [ 0.011],
         [ 0.128],
         [ 0.251],
         [ 0.023],
         [ 0.312]],

        [[ 0.304],
         [-0.057],
         [-0.099],
         [-0.152],
         [-0.119],
         [ 0.078],
         [ 0.163],
         [-0.163],
         [ 0.011],
         [ 0.004]],

        [[-0.089],
         [-0.110],
         [ 0.032],
         [ 0.090],
         [ 0.378],
         [ 0.043],
         [ 0.002],
         [ 0.082],
         [-0.110],
         [ 0.130]]], device='cuda:0')
s after update for 1 param tensor([[[1.925],
         [1.146],
         [1.973],
         [1.349],
         [1.549],
         [1.601],
         [1.712],
         [1.414],
         [1.318],
         [2.004]],

        [[1.684],
         [2.028],
         [0.641],
         [1.305],
         [1.546],
         [2.313],
         [1.943],
         [1.165],
         [1.665],
         [1.966]],

        [[1.707],
         [1.341],
         [2.119],
         [1.567],
         [1.691],
         [1.792],
         [1.623],
         [1.798],
         [1.667],
         [1.637]],

        [[1.585],
         [1.948],
         [1.759],
         [2.042],
         [1.767],
         [1.751],
         [2.393],
         [1.416],
         [2.170],
         [1.741]],

        [[2.020],
         [1.898],
         [1.397],
         [1.807],
         [1.458],
         [1.467],
         [1.638],
         [1.762],
         [1.609],
         [1.419]],

        [[1.580],
         [1.620],
         [1.954],
         [1.772],
         [1.961],
         [1.631],
         [1.460],
         [1.993],
         [2.042],
         [1.562]],

        [[2.110],
         [1.295],
         [1.110],
         [1.687],
         [1.428],
         [1.819],
         [1.689],
         [1.471],
         [1.843],
         [1.443]],

        [[1.872],
         [1.886],
         [1.960],
         [1.662],
         [1.477],
         [1.716],
         [2.079],
         [2.384],
         [1.619],
         [1.717]],

        [[1.468],
         [1.788],
         [1.746],
         [1.785],
         [1.881],
         [1.504],
         [1.673],
         [1.513],
         [1.454],
         [1.414]],

        [[1.573],
         [1.585],
         [1.222],
         [2.074],
         [1.680],
         [1.140],
         [0.752],
         [1.804],
         [1.551],
         [1.712]],

        [[1.906],
         [0.976],
         [1.976],
         [1.123],
         [1.727],
         [1.421],
         [1.631],
         [1.826],
         [1.295],
         [1.396]],

        [[1.677],
         [0.995],
         [1.386],
         [1.776],
         [0.877],
         [1.864],
         [2.048],
         [1.460],
         [1.395],
         [1.312]],

        [[1.850],
         [1.669],
         [1.157],
         [1.862],
         [2.130],
         [1.220],
         [1.547],
         [1.532],
         [1.293],
         [1.803]],

        [[1.391],
         [1.878],
         [1.882],
         [1.644],
         [1.906],
         [1.873],
         [1.546],
         [1.729],
         [1.819],
         [2.058]],

        [[1.243],
         [1.451],
         [1.424],
         [1.430],
         [1.412],
         [1.257],
         [1.653],
         [1.421],
         [1.865],
         [1.595]],

        [[1.230],
         [1.973],
         [1.296],
         [1.767],
         [1.759],
         [1.345],
         [1.780],
         [1.814],
         [1.441],
         [2.062]],

        [[1.379],
         [1.548],
         [1.761],
         [2.002],
         [2.045],
         [1.460],
         [1.969],
         [1.653],
         [2.020],
         [1.613]],

        [[1.743],
         [1.709],
         [1.614],
         [1.984],
         [1.836],
         [2.256],
         [1.601],
         [1.211],
         [1.010],
         [1.826]],

        [[1.813],
         [1.843],
         [1.801],
         [1.819],
         [1.943],
         [1.643],
         [1.973],
         [1.258],
         [1.644],
         [1.725]],

        [[1.456],
         [1.672],
         [1.353],
         [1.615],
         [1.838],
         [2.114],
         [1.945],
         [1.971],
         [1.012],
         [1.267]]], device='cuda:0')
b after update for 1 param tensor([[[119.614],
         [ 92.312],
         [121.105],
         [100.153],
         [107.295],
         [109.091],
         [112.802],
         [102.540],
         [ 98.990],
         [122.065]],

        [[111.875],
         [122.792],
         [ 69.041],
         [ 98.484],
         [107.207],
         [131.123],
         [120.179],
         [ 93.070],
         [111.240],
         [120.877]],

        [[112.652],
         [ 99.844],
         [125.519],
         [107.928],
         [112.108],
         [115.422],
         [109.823],
         [115.603],
         [111.317],
         [110.320]],

        [[108.543],
         [120.342],
         [114.356],
         [123.204],
         [114.606],
         [114.090],
         [133.368],
         [102.598],
         [127.014],
         [113.756]],

        [[122.534],
         [118.780],
         [101.902],
         [115.897],
         [104.114],
         [104.412],
         [110.334],
         [114.435],
         [109.354],
         [102.699]],

        [[108.376],
         [109.744],
         [120.527],
         [114.775],
         [120.729],
         [110.120],
         [104.185],
         [121.710],
         [123.191],
         [107.744]],

        [[125.233],
         [ 98.117],
         [ 90.840],
         [111.990],
         [103.034],
         [116.283],
         [112.044],
         [104.569],
         [117.036],
         [103.565]],

        [[117.978],
         [118.390],
         [120.699],
         [111.167],
         [104.788],
         [112.942],
         [124.327],
         [133.119],
         [109.716],
         [112.985]],

        [[104.459],
         [115.280],
         [113.924],
         [115.198],
         [118.238],
         [105.748],
         [111.510],
         [106.066],
         [103.946],
         [102.530]],

        [[108.132],
         [108.544],
         [ 95.292],
         [124.154],
         [111.762],
         [ 92.043],
         [ 74.742],
         [115.799],
         [107.387],
         [112.802]],

        [[119.029],
         [ 85.172],
         [121.195],
         [ 91.359],
         [113.293],
         [102.794],
         [110.118],
         [116.504],
         [ 98.122],
         [101.860]],

        [[111.653],
         [ 86.011],
         [101.500],
         [114.896],
         [ 80.729],
         [117.722],
         [123.385],
         [104.171],
         [101.832],
         [ 98.763]],

        [[117.279],
         [111.379],
         [ 92.749],
         [117.639],
         [125.824],
         [ 95.221],
         [107.249],
         [106.727],
         [ 98.043],
         [115.768]],

        [[101.696],
         [118.166],
         [118.277],
         [110.548],
         [119.031],
         [118.010],
         [107.199],
         [113.369],
         [116.298],
         [123.679]],

        [[ 96.129],
         [103.859],
         [102.900],
         [103.105],
         [102.462],
         [ 96.661],
         [110.837],
         [102.770],
         [117.755],
         [108.882]],

        [[ 95.616],
         [121.102],
         [ 98.170],
         [114.622],
         [114.358],
         [100.002],
         [115.043],
         [116.138],
         [103.509],
         [123.801]],

        [[101.246],
         [107.287],
         [114.427],
         [121.999],
         [123.287],
         [104.162],
         [120.987],
         [110.839],
         [122.531],
         [109.492]],

        [[113.842],
         [112.712],
         [109.544],
         [121.451],
         [116.825],
         [129.513],
         [109.098],
         [ 94.882],
         [ 86.653],
         [116.496]],

        [[116.106],
         [117.062],
         [115.721],
         [116.288],
         [120.195],
         [110.525],
         [121.120],
         [ 96.692],
         [110.550],
         [113.236]],

        [[104.044],
         [111.500],
         [100.288],
         [109.553],
         [116.902],
         [125.366],
         [120.228],
         [121.045],
         [ 86.750],
         [ 97.040]]], device='cuda:0')
clipping threshold 1.1702407666724517
a after update for 1 param tensor([[ 0.105],
        [-0.069],
        [ 0.077],
        [ 0.011],
        [-0.002],
        [-0.143],
        [ 0.092],
        [-0.018],
        [ 0.086],
        [ 0.047],
        [ 0.019],
        [ 0.142],
        [ 0.031],
        [-0.041],
        [-0.122],
        [-0.047],
        [-0.235],
        [ 0.004],
        [-0.259],
        [-0.049]], device='cuda:0')
s after update for 1 param tensor([[1.708],
        [1.867],
        [1.744],
        [1.506],
        [0.980],
        [1.396],
        [1.888],
        [0.920],
        [1.669],
        [1.753],
        [1.094],
        [1.860],
        [2.332],
        [1.522],
        [1.123],
        [1.815],
        [1.411],
        [1.956],
        [2.007],
        [1.997]], device='cuda:0')
b after update for 1 param tensor([[112.669],
        [117.795],
        [113.859],
        [105.811],
        [ 85.331],
        [101.856],
        [118.459],
        [ 82.700],
        [111.369],
        [114.169],
        [ 90.166],
        [117.576],
        [131.654],
        [106.377],
        [ 91.385],
        [116.170],
        [102.427],
        [120.582],
        [122.148],
        [121.849]], device='cuda:0')
clipping threshold 1.1702407666724517
||w||^2 2.1494794497637058
exp ma of ||w||^2 1.9598396575300818
||w|| 1.4661103129586484
exp ma of ||w|| 1.3562381391966236
||w||^2 4.648055176328275
exp ma of ||w||^2 2.1244760811790995
||w|| 2.1559348729329173
exp ma of ||w|| 1.390040435091926
||w||^2 1.7592160000789019
exp ma of ||w||^2 2.0077371440371814
||w|| 1.3263544021410347
exp ma of ||w|| 1.372566818695673
||w||^2 0.41145583795281154
exp ma of ||w||^2 1.702791259466109
||w|| 0.6414482348193122
exp ma of ||w|| 1.263233356884963
||w||^2 3.6137787957490004
exp ma of ||w||^2 1.8911896294459638
||w|| 1.900994159840845
exp ma of ||w|| 1.3295774199393624
||w||^2 1.4184297741557783
exp ma of ||w||^2 2.055966394089164
||w|| 1.190978494413639
exp ma of ||w|| 1.3828652309628013
||w||^2 0.7937228278286452
exp ma of ||w||^2 1.9658040423004062
||w|| 0.8909112345394715
exp ma of ||w|| 1.351278938970985
cuda
Objective function 32.95 = squared loss an data 23.37 + 0.5*rho*h**2 4.203532 + alpha*h 3.269083 + L2reg 1.86 + L1reg 0.25 ; SHD = 84 ; DAG False
Proportion of microbatches that were clipped  0.7732422659702692
iteration 2 in inner loop, alpha 3.565363369109157 rho 10.0 h 0.9169004128649085
4420
cuda
Objective function 70.78 = squared loss an data 23.37 + 0.5*rho*h**2 42.035318 + alpha*h 3.269083 + L2reg 1.86 + L1reg 0.25 ; SHD = 84 ; DAG False
||w||^2 301172985.5753107
exp ma of ||w||^2 9494351246.590395
||w|| 17354.336218228305
exp ma of ||w|| 48852.896220096314
||w||^2 5.806028688669255
exp ma of ||w||^2 59.14651720263556
||w|| 2.409570229038626
exp ma of ||w|| 1.8152352575819046
||w||^2 1.9770882803556256
exp ma of ||w||^2 2.968651301858498
||w|| 1.4060897127692904
exp ma of ||w|| 1.6585126186904842
||w||^2 6.401335916182613
exp ma of ||w||^2 2.7716353518416423
||w|| 2.5300861479765095
exp ma of ||w|| 1.6079218246389386
||w||^2 2.034353294655145
exp ma of ||w||^2 2.5724119704668555
||w|| 1.4263075736513302
exp ma of ||w|| 1.5501382788884068
||w||^2 2.1160214874729113
exp ma of ||w||^2 2.5981262029633396
||w|| 1.4546551094582219
exp ma of ||w|| 1.569579734556679
||w||^2 3.254149666408695
exp ma of ||w||^2 2.7234864627922897
||w|| 1.8039261809754563
exp ma of ||w|| 1.5965384448843978
||w||^2 1.9499176151025999
exp ma of ||w||^2 2.620037151803362
||w|| 1.396394505540107
exp ma of ||w|| 1.5667937408848593
cuda
Objective function 33.84 = squared loss an data 24.90 + 0.5*rho*h**2 5.444970 + alpha*h 1.176567 + L2reg 2.09 + L1reg 0.23 ; SHD = 87 ; DAG True
Proportion of microbatches that were clipped  0.7751988313585457
iteration 3 in inner loop, alpha 3.565363369109157 rho 100.0 h 0.32999908127473887
iteration 2 in outer loop, alpha = 36.565271496583044, rho = 100.0, h = 0.32999908127473887
cuda
4420
cuda
Objective function 44.73 = squared loss an data 24.90 + 0.5*rho*h**2 5.444970 + alpha*h 12.066506 + L2reg 2.09 + L1reg 0.23 ; SHD = 87 ; DAG True
||w||^2 6764487371.077813
exp ma of ||w||^2 80407757878.69148
||w|| 82246.50370123834
exp ma of ||w|| 206799.72381246596
||w||^2 180687.69656189604
exp ma of ||w||^2 858454891.2392329
||w|| 425.0737542614176
exp ma of ||w|| 5792.29117834597
||w||^2 1.8611564912950966
exp ma of ||w||^2 1327047.058353269
||w|| 1.3642420940929423
exp ma of ||w|| 13.409658413391663
||w||^2 7.919938118632091
exp ma of ||w||^2 75672.29331533724
||w|| 2.814238461579276
exp ma of ||w|| 2.5274459868186505
||w||^2 0.8659966164566651
exp ma of ||w||^2 2.7890018205447222
||w|| 0.9305893919751423
exp ma of ||w|| 1.5811067775319014
||w||^2 4.605957979925828
exp ma of ||w||^2 2.682870574317552
||w|| 2.146149570725635
exp ma of ||w|| 1.5925463459401514
||w||^2 1.310479190426976
exp ma of ||w||^2 2.5165028417581885
||w|| 1.1447616303960295
exp ma of ||w|| 1.540119419329305
||w||^2 1.6529636784161283
exp ma of ||w||^2 2.338065159094635
||w|| 1.2856763505704414
exp ma of ||w|| 1.4863313926889374
||w||^2 3.204986360604999
exp ma of ||w||^2 2.534944128900829
||w|| 1.7902475696408582
exp ma of ||w|| 1.5439308783868402
||w||^2 1.3610806855555084
exp ma of ||w||^2 2.4186920752831336
||w|| 1.1666536270699666
exp ma of ||w|| 1.5127252238636433
||w||^2 4.575780612501013
exp ma of ||w||^2 2.549600559372886
||w|| 2.1391074336042624
exp ma of ||w|| 1.5429739658848618
||w||^2 2.339345752293536
exp ma of ||w||^2 2.5714814169788216
||w|| 1.5294919915754825
exp ma of ||w|| 1.5631270323809043
||w||^2 4.007648244983991
exp ma of ||w||^2 2.5470393377084264
||w|| 2.0019111481242096
exp ma of ||w|| 1.5483286602338053
||w||^2 2.4820673746356765
exp ma of ||w||^2 2.5266230049450282
||w|| 1.5754578301673696
exp ma of ||w|| 1.5319944447994491
||w||^2 1.6583079485436756
exp ma of ||w||^2 2.2785057392945127
||w|| 1.2877530619430402
exp ma of ||w|| 1.4595647928879585
cuda
Objective function 35.40 = squared loss an data 23.47 + 0.5*rho*h**2 2.031585 + alpha*h 7.370573 + L2reg 2.30 + L1reg 0.24 ; SHD = 84 ; DAG True
Proportion of microbatches that were clipped  0.7729406052759347
iteration 1 in inner loop, alpha 36.565271496583044 rho 100.0 h 0.20157304608626347
4420
cuda
Objective function 53.69 = squared loss an data 23.47 + 0.5*rho*h**2 20.315846 + alpha*h 7.370573 + L2reg 2.30 + L1reg 0.24 ; SHD = 84 ; DAG True
||w||^2 9.53280069284029
exp ma of ||w||^2 1449369.4537620023
||w|| 3.087523391464474
exp ma of ||w|| 13.375443457855525
||w||^2 2.7121236426169246
exp ma of ||w||^2 13272.013589773278
||w|| 1.646852647511891
exp ma of ||w|| 1.9969327086550497
||w||^2 1.624513518099931
exp ma of ||w||^2 2.5466353962486816
||w|| 1.2745640502147906
exp ma of ||w|| 1.5544721711998486
||w||^2 1.8734553757961732
exp ma of ||w||^2 2.65394071361527
||w|| 1.3687422605429311
exp ma of ||w|| 1.580835078105792
||w||^2 2.863302060374345
exp ma of ||w||^2 2.574859754937431
||w|| 1.6921294455136537
exp ma of ||w|| 1.5715820703542351
||w||^2 1.8536259840816596
exp ma of ||w||^2 2.5208400704418072
||w|| 1.3614793366341111
exp ma of ||w|| 1.546708529016144
cuda
Objective function 33.22 = squared loss an data 23.76 + 0.5*rho*h**2 3.603415 + alpha*h 3.104137 + L2reg 2.51 + L1reg 0.24 ; SHD = 72 ; DAG True
Proportion of microbatches that were clipped  0.7778573132903842
iteration 2 in inner loop, alpha 36.565271496583044 rho 1000.0 h 0.08489304758309402
4420
cuda
Objective function 65.65 = squared loss an data 23.76 + 0.5*rho*h**2 36.034148 + alpha*h 3.104137 + L2reg 2.51 + L1reg 0.24 ; SHD = 72 ; DAG True
||w||^2 5369690175815.93
exp ma of ||w||^2 1675788682793.9849
||w|| 2317259.1947850655
exp ma of ||w|| 822152.044337621
||w||^2 5549120352.024942
exp ma of ||w||^2 310986565756.17426
||w|| 74492.41808415767
exp ma of ||w|| 279193.5345235259
||w||^2 2122.727810499286
exp ma of ||w||^2 1102586404.5079417
||w|| 46.07307033939985
exp ma of ||w|| 2016.7793074808596
||w||^2 4.6567254090827985
exp ma of ||w||^2 311771.0658170938
||w|| 2.1579447187272427
exp ma of ||w|| 2.967432866941919
||w||^2 1.839525822453114
exp ma of ||w||^2 2.989066922745891
||w|| 1.356291201200212
exp ma of ||w|| 1.6331531532523529
||w||^2 1.6830499429982648
exp ma of ||w||^2 2.656729607890772
||w|| 1.297324147234709
exp ma of ||w|| 1.5843675623267846
||w||^2 3.373587814216493
exp ma of ||w||^2 2.72247832246373
||w|| 1.8367329185857406
exp ma of ||w|| 1.6100841693425603
||w||^2 6.487506438695541
exp ma of ||w||^2 2.612510963411248
||w|| 2.5470583893376966
exp ma of ||w|| 1.5798155601088923
||w||^2 1.9131175402365317
exp ma of ||w||^2 2.660916097164759
||w|| 1.3831549227170945
exp ma of ||w|| 1.590782904408684
||w||^2 1.6422407576190483
exp ma of ||w||^2 2.675790225577059
||w|| 1.2814994177209167
exp ma of ||w|| 1.5913089190911447
||w||^2 1.2346774306039734
exp ma of ||w||^2 2.6479990225760015
||w|| 1.1111603982341944
exp ma of ||w|| 1.5778308127919503
||w||^2 4.230882175613486
exp ma of ||w||^2 2.7040078774776557
||w|| 2.056910833170336
exp ma of ||w|| 1.6047906184433414
cuda
Objective function 30.94 = squared loss an data 22.94 + 0.5*rho*h**2 4.037428 + alpha*h 1.039049 + L2reg 2.68 + L1reg 0.24 ; SHD = 76 ; DAG True
Proportion of microbatches that were clipped  0.7778929739213654
iteration 3 in inner loop, alpha 36.565271496583044 rho 10000.0 h 0.028416292543639088
iteration 3 in outer loop, alpha = 320.7281969329739, rho = 10000.0, h = 0.028416292543639088
cuda
4420
cuda
Objective function 39.01 = squared loss an data 22.94 + 0.5*rho*h**2 4.037428 + alpha*h 9.113906 + L2reg 2.68 + L1reg 0.24 ; SHD = 76 ; DAG True
||w||^2 4.7193915576648235
exp ma of ||w||^2 379315.6253549435
||w|| 2.172416064584504
exp ma of ||w|| 2.6414794255399023
||w||^2 3.7987597995760285
exp ma of ||w||^2 2373.8336015352425
||w|| 1.9490407383059054
exp ma of ||w|| 1.9087097604669245
||w||^2 2.4061032708130337
exp ma of ||w||^2 9.619059803333302
||w|| 1.5511619099285006
exp ma of ||w|| 1.680192196570415
||w||^2 5.107010274991522
exp ma of ||w||^2 2.5536428649676908
||w|| 2.2598695260991333
exp ma of ||w|| 1.553719356929439
||w||^2 3.1557346437022287
exp ma of ||w||^2 2.5622783518799808
||w|| 1.7764387531525618
exp ma of ||w|| 1.5655750751672268
||w||^2 2.701190367615546
exp ma of ||w||^2 2.868276180567608
||w|| 1.6435298499314048
exp ma of ||w|| 1.6625103176831024
||w||^2 1.3743902776642845
exp ma of ||w||^2 2.7228458742215658
||w|| 1.1723439246502216
exp ma of ||w|| 1.6162636603597331
||w||^2 1.3690547073456587
exp ma of ||w||^2 2.85145691900344
||w|| 1.170066112382398
exp ma of ||w|| 1.6526773079175237
||w||^2 2.2812712720913537
exp ma of ||w||^2 2.8763166981343575
||w|| 1.5103877886461323
exp ma of ||w|| 1.661810505382352
||w||^2 2.467136164481428
exp ma of ||w||^2 2.7899825875376387
||w|| 1.5707119928495574
exp ma of ||w|| 1.6358933809789007
||w||^2 2.090243145763255
exp ma of ||w||^2 2.955111398702106
||w|| 1.4457673207550568
exp ma of ||w|| 1.6884364539039007
||w||^2 1.7371460634026288
exp ma of ||w||^2 2.919095999603921
||w|| 1.3180083700047693
exp ma of ||w|| 1.6744318291796263
cuda
Objective function 34.41 = squared loss an data 22.79 + 0.5*rho*h**2 2.052687 + alpha*h 6.498505 + L2reg 2.82 + L1reg 0.25 ; SHD = 73 ; DAG True
Proportion of microbatches that were clipped  0.7772292993630573
iteration 1 in inner loop, alpha 320.7281969329739 rho 10000.0 h 0.02026172044389085
4420
cuda
Objective function 52.88 = squared loss an data 22.79 + 0.5*rho*h**2 20.526866 + alpha*h 6.498505 + L2reg 2.82 + L1reg 0.25 ; SHD = 73 ; DAG True
||w||^2 155.37953961363382
exp ma of ||w||^2 25795300402.11395
||w|| 12.465132956115383
exp ma of ||w|| 996.094006995454
||w||^2 8.36033227698694
exp ma of ||w||^2 62873.58364130231
||w|| 2.8914239185887185
exp ma of ||w|| 3.0942115045328253
||w||^2 5.764946440198865
exp ma of ||w||^2 723.1474551050034
||w|| 2.4010302872306433
exp ma of ||w|| 2.2670482212855525
||w||^2 1.5568093631703228
exp ma of ||w||^2 2.966506700900428
||w|| 1.2477216689511819
exp ma of ||w|| 1.6755898978882147
||w||^2 2.8478711488583315
exp ma of ||w||^2 2.7905254355522913
||w|| 1.68756367253456
exp ma of ||w|| 1.632637846563805
||w||^2 2.1833853781788646
exp ma of ||w||^2 2.911626620355562
||w|| 1.4776282949980568
exp ma of ||w|| 1.665916199205689
||w||^2 1.6607441260230247
exp ma of ||w||^2 2.8315726071835976
||w|| 1.2886986172193344
exp ma of ||w|| 1.6416934650473956
||w||^2 3.9447017166901537
exp ma of ||w||^2 2.899839487266155
||w|| 1.986127316334518
exp ma of ||w|| 1.656240905561763
||w||^2 2.023353600702369
exp ma of ||w||^2 2.969947204434897
||w|| 1.4224463436988999
exp ma of ||w|| 1.6885022590099334
||w||^2 1.8673424147157063
exp ma of ||w||^2 2.692188062476789
||w|| 1.3665073782148804
exp ma of ||w|| 1.6069317268897596
||w||^2 3.6858771745835646
exp ma of ||w||^2 2.983529720827793
||w|| 1.9198638427199894
exp ma of ||w|| 1.6947831647436618
cuda
Objective function 30.87 = squared loss an data 22.04 + 0.5*rho*h**2 3.123162 + alpha*h 2.534833 + L2reg 2.93 + L1reg 0.24 ; SHD = 68 ; DAG True
Proportion of microbatches that were clipped  0.7793230967119543
iteration 2 in inner loop, alpha 320.7281969329739 rho 100000.0 h 0.00790336938144165
iteration 4 in outer loop, alpha = 8224.097578374623, rho = 1000000.0, h = 0.00790336938144165
Threshold 0.3
[[0.005 0.14  0.008 0.238 0.067 0.103 0.069 0.008 0.294 0.132 0.152 0.055
  0.048 0.098 0.561 0.319 0.081 0.012 0.415 0.07 ]
 [0.046 0.006 0.016 0.108 0.032 0.206 0.103 0.008 1.301 0.201 0.059 0.056
  0.062 0.044 0.923 0.768 0.23  0.001 0.179 0.029]
 [0.761 0.267 0.007 0.566 0.302 0.864 0.826 0.088 1.445 1.113 0.171 0.729
  0.897 0.565 0.881 0.728 0.243 0.036 3.109 0.829]
 [0.025 0.065 0.006 0.006 0.007 0.063 0.058 0.011 0.266 0.498 0.044 0.04
  0.048 0.057 0.273 0.237 0.047 0.008 0.08  0.004]
 [0.117 0.136 0.031 0.963 0.006 0.295 0.171 0.009 1.229 0.534 0.504 0.333
  0.184 0.134 0.477 0.211 0.2   0.013 0.205 0.262]
 [0.074 0.028 0.008 0.079 0.023 0.005 0.091 0.013 0.371 0.24  0.034 0.027
  0.058 0.103 0.36  0.249 0.029 0.004 0.492 0.027]
 [0.069 0.059 0.012 0.082 0.031 0.042 0.007 0.001 0.244 0.11  0.053 0.072
  0.01  0.044 0.195 0.874 0.066 0.007 0.159 0.016]
 [0.604 0.701 0.05  0.641 0.442 0.463 3.862 0.007 1.051 0.733 0.816 0.22
  0.167 0.489 1.532 1.055 0.49  0.139 0.703 0.241]
 [0.024 0.004 0.003 0.019 0.003 0.016 0.026 0.002 0.004 0.092 0.014 0.013
  0.008 0.017 0.117 0.052 0.017 0.001 0.032 0.005]
 [0.042 0.017 0.003 0.012 0.008 0.027 0.036 0.008 0.074 0.007 0.021 0.011
  0.003 0.041 0.107 0.085 0.022 0.003 0.084 0.007]
 [0.041 0.104 0.029 0.162 0.011 0.185 0.11  0.012 0.553 0.183 0.004 0.061
  0.023 0.099 0.297 0.272 0.085 0.008 0.094 0.033]
 [0.086 0.102 0.008 0.176 0.018 0.243 0.096 0.023 0.64  0.651 0.12  0.004
  0.141 0.223 0.379 0.367 0.21  0.015 0.352 0.05 ]
 [0.118 0.087 0.007 0.11  0.035 0.12  0.357 0.028 0.481 1.529 0.328 0.045
  0.004 0.216 0.36  0.603 0.133 0.006 0.213 0.138]
 [0.085 0.121 0.008 0.102 0.028 0.074 0.14  0.011 0.359 0.11  0.086 0.033
  0.038 0.005 0.281 0.268 0.077 0.008 0.712 0.031]
 [0.014 0.008 0.004 0.018 0.014 0.01  0.028 0.003 0.061 0.06  0.007 0.018
  0.015 0.018 0.008 0.083 0.006 0.001 0.018 0.012]
 [0.016 0.009 0.006 0.022 0.011 0.019 0.007 0.002 0.127 0.07  0.02  0.017
  0.011 0.022 0.084 0.01  0.006 0.001 0.045 0.003]
 [0.055 0.027 0.021 0.131 0.023 0.195 0.096 0.011 0.251 0.241 0.064 0.052
  0.053 0.076 0.96  0.913 0.008 0.002 0.372 0.065]
 [0.454 3.393 0.188 0.482 0.427 0.828 0.546 0.046 1.33  0.802 0.651 0.456
  0.703 0.601 1.046 1.289 2.343 0.006 1.008 0.458]
 [0.016 0.029 0.001 0.053 0.016 0.01  0.042 0.006 0.103 0.068 0.059 0.017
  0.024 0.009 0.34  0.199 0.014 0.003 0.006 0.022]
 [0.065 0.22  0.004 1.288 0.023 0.241 0.275 0.042 0.508 0.518 0.191 0.113
  0.058 0.273 0.449 0.589 0.064 0.01  0.212 0.003]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.561 0.319 0.    0.    0.415 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    1.301 0.    0.    0.
  0.    0.    0.923 0.768 0.    0.    0.    0.   ]
 [0.761 0.    0.    0.566 0.302 0.864 0.826 0.    1.445 1.113 0.    0.729
  0.897 0.565 0.881 0.728 0.    0.    3.109 0.829]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.498 0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.963 0.    0.    0.    0.    1.229 0.534 0.504 0.333
  0.    0.    0.477 0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.371 0.    0.    0.
  0.    0.    0.36  0.    0.    0.    0.492 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.874 0.    0.    0.    0.   ]
 [0.604 0.701 0.    0.641 0.442 0.463 3.862 0.    1.051 0.733 0.816 0.
  0.    0.489 1.532 1.055 0.49  0.    0.703 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.553 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.64  0.651 0.    0.
  0.    0.    0.379 0.367 0.    0.    0.352 0.   ]
 [0.    0.    0.    0.    0.    0.    0.357 0.    0.481 1.529 0.328 0.
  0.    0.    0.36  0.603 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.359 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.712 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.96  0.913 0.    0.    0.372 0.   ]
 [0.454 3.393 0.    0.482 0.427 0.828 0.546 0.    1.33  0.802 0.651 0.456
  0.703 0.601 1.046 1.289 2.343 0.    1.008 0.458]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.34  0.    0.    0.    0.    0.   ]
 [0.    0.    0.    1.288 0.    0.    0.    0.    0.508 0.518 0.    0.
  0.    0.    0.449 0.589 0.    0.    0.    0.   ]]
{'fdr': 0.6823529411764706, 'tpr': 0.675, 'fpr': 0.38666666666666666, 'f1': 0.432, 'shd': 68, 'npred': 85, 'ntrue': 40}
[1.404e-01 7.664e-03 2.377e-01 6.672e-02 1.032e-01 6.925e-02 8.035e-03
 2.936e-01 1.317e-01 1.524e-01 5.534e-02 4.820e-02 9.784e-02 5.613e-01
 3.191e-01 8.083e-02 1.247e-02 4.148e-01 6.957e-02 4.638e-02 1.649e-02
 1.075e-01 3.159e-02 2.056e-01 1.033e-01 7.682e-03 1.301e+00 2.007e-01
 5.881e-02 5.580e-02 6.175e-02 4.439e-02 9.229e-01 7.676e-01 2.303e-01
 1.113e-03 1.791e-01 2.942e-02 7.608e-01 2.668e-01 5.664e-01 3.020e-01
 8.644e-01 8.257e-01 8.837e-02 1.445e+00 1.113e+00 1.707e-01 7.287e-01
 8.967e-01 5.652e-01 8.811e-01 7.282e-01 2.433e-01 3.592e-02 3.109e+00
 8.290e-01 2.461e-02 6.465e-02 6.235e-03 6.580e-03 6.315e-02 5.806e-02
 1.065e-02 2.655e-01 4.985e-01 4.368e-02 3.962e-02 4.769e-02 5.700e-02
 2.728e-01 2.372e-01 4.727e-02 8.191e-03 8.031e-02 3.671e-03 1.168e-01
 1.356e-01 3.088e-02 9.625e-01 2.950e-01 1.710e-01 8.625e-03 1.229e+00
 5.342e-01 5.038e-01 3.334e-01 1.837e-01 1.343e-01 4.766e-01 2.115e-01
 2.002e-01 1.259e-02 2.054e-01 2.623e-01 7.367e-02 2.832e-02 8.332e-03
 7.933e-02 2.346e-02 9.057e-02 1.279e-02 3.706e-01 2.402e-01 3.421e-02
 2.733e-02 5.779e-02 1.032e-01 3.604e-01 2.488e-01 2.911e-02 4.389e-03
 4.920e-01 2.749e-02 6.851e-02 5.948e-02 1.176e-02 8.226e-02 3.052e-02
 4.169e-02 7.174e-04 2.439e-01 1.095e-01 5.306e-02 7.154e-02 1.000e-02
 4.360e-02 1.953e-01 8.741e-01 6.554e-02 7.042e-03 1.591e-01 1.641e-02
 6.037e-01 7.013e-01 5.015e-02 6.406e-01 4.415e-01 4.634e-01 3.862e+00
 1.051e+00 7.333e-01 8.163e-01 2.204e-01 1.669e-01 4.894e-01 1.532e+00
 1.055e+00 4.901e-01 1.389e-01 7.030e-01 2.415e-01 2.368e-02 4.138e-03
 3.385e-03 1.856e-02 3.032e-03 1.591e-02 2.559e-02 2.136e-03 9.195e-02
 1.426e-02 1.276e-02 7.873e-03 1.693e-02 1.174e-01 5.205e-02 1.732e-02
 1.294e-03 3.173e-02 4.722e-03 4.197e-02 1.747e-02 3.435e-03 1.153e-02
 8.392e-03 2.706e-02 3.605e-02 7.608e-03 7.389e-02 2.097e-02 1.063e-02
 2.514e-03 4.136e-02 1.074e-01 8.452e-02 2.246e-02 2.570e-03 8.416e-02
 7.186e-03 4.108e-02 1.036e-01 2.874e-02 1.617e-01 1.079e-02 1.849e-01
 1.099e-01 1.222e-02 5.528e-01 1.829e-01 6.051e-02 2.271e-02 9.942e-02
 2.973e-01 2.717e-01 8.475e-02 7.887e-03 9.438e-02 3.277e-02 8.568e-02
 1.023e-01 8.226e-03 1.757e-01 1.830e-02 2.434e-01 9.552e-02 2.324e-02
 6.399e-01 6.511e-01 1.203e-01 1.414e-01 2.231e-01 3.790e-01 3.674e-01
 2.105e-01 1.457e-02 3.518e-01 5.025e-02 1.178e-01 8.672e-02 7.368e-03
 1.099e-01 3.543e-02 1.199e-01 3.569e-01 2.806e-02 4.807e-01 1.529e+00
 3.284e-01 4.456e-02 2.162e-01 3.604e-01 6.027e-01 1.328e-01 5.976e-03
 2.132e-01 1.376e-01 8.488e-02 1.207e-01 8.257e-03 1.018e-01 2.766e-02
 7.350e-02 1.404e-01 1.118e-02 3.585e-01 1.102e-01 8.568e-02 3.316e-02
 3.752e-02 2.808e-01 2.682e-01 7.688e-02 7.795e-03 7.117e-01 3.139e-02
 1.433e-02 7.858e-03 4.273e-03 1.794e-02 1.374e-02 1.039e-02 2.803e-02
 3.237e-03 6.122e-02 6.015e-02 7.443e-03 1.842e-02 1.477e-02 1.773e-02
 8.273e-02 6.397e-03 1.280e-03 1.824e-02 1.226e-02 1.580e-02 8.993e-03
 5.862e-03 2.228e-02 1.077e-02 1.937e-02 6.891e-03 2.387e-03 1.271e-01
 6.968e-02 1.990e-02 1.707e-02 1.068e-02 2.243e-02 8.424e-02 6.305e-03
 1.213e-03 4.545e-02 3.374e-03 5.540e-02 2.681e-02 2.140e-02 1.311e-01
 2.313e-02 1.949e-01 9.622e-02 1.136e-02 2.513e-01 2.412e-01 6.449e-02
 5.222e-02 5.322e-02 7.604e-02 9.600e-01 9.125e-01 1.732e-03 3.718e-01
 6.488e-02 4.537e-01 3.393e+00 1.883e-01 4.823e-01 4.273e-01 8.280e-01
 5.459e-01 4.561e-02 1.330e+00 8.022e-01 6.508e-01 4.558e-01 7.029e-01
 6.015e-01 1.046e+00 1.289e+00 2.343e+00 1.008e+00 4.584e-01 1.571e-02
 2.894e-02 1.158e-03 5.296e-02 1.604e-02 9.840e-03 4.186e-02 5.758e-03
 1.026e-01 6.801e-02 5.853e-02 1.714e-02 2.434e-02 9.235e-03 3.401e-01
 1.993e-01 1.364e-02 3.392e-03 2.236e-02 6.464e-02 2.199e-01 4.382e-03
 1.288e+00 2.287e-02 2.412e-01 2.755e-01 4.234e-02 5.080e-01 5.183e-01
 1.914e-01 1.131e-01 5.821e-02 2.732e-01 4.487e-01 5.894e-01 6.404e-02
 1.022e-02 2.117e-01]
[[0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.8158823529411764, 0.5371636716377217)
Iterations 2250
Achieves (13.034436291409676, 1e-05)-DP
