samples  5000  graph  20 40 ER mlp  minibatch size  50  noise  1.0  minibatches per NN training  250 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.5649078160676773
iteration 1 in outer loop, alpha = 1.5649078160676773, rho = 1.0, h = 1.5649078160676773
cuda
iteration 1 in inner loop,alpha 1.5649078160676773 rho 1.0 h 1.036308758706106
iteration 2 in inner loop,alpha 1.5649078160676773 rho 10.0 h 0.4426674246293274
iteration 3 in inner loop,alpha 1.5649078160676773 rho 100.0 h 0.13993048622051063
iteration 2 in outer loop, alpha = 15.55795643811874, rho = 100.0, h = 0.13993048622051063
cuda
iteration 1 in inner loop,alpha 15.55795643811874 rho 100.0 h 0.0744602656357678
iteration 2 in inner loop,alpha 15.55795643811874 rho 1000.0 h 0.024333775194953944
iteration 3 in outer loop, alpha = 39.89173163307268, rho = 1000.0, h = 0.024333775194953944
cuda
iteration 1 in inner loop,alpha 39.89173163307268 rho 1000.0 h 0.009611812723026247
iteration 2 in inner loop,alpha 39.89173163307268 rho 10000.0 h 0.0029879033843300817
iteration 4 in outer loop, alpha = 69.7707654763735, rho = 10000.0, h = 0.0029879033843300817
cuda
iteration 1 in inner loop,alpha 69.7707654763735 rho 10000.0 h 0.0011764299267653655
iteration 2 in inner loop,alpha 69.7707654763735 rho 100000.0 h 0.0004609600890645993
iteration 5 in outer loop, alpha = 115.86677438283343, rho = 100000.0, h = 0.0004609600890645993
cuda
iteration 1 in inner loop,alpha 115.86677438283343 rho 100000.0 h 0.0002678358105114853
iteration 6 in outer loop, alpha = 383.70258489431876, rho = 1000000.0, h = 0.0002678358105114853
Threshold 0.3
[[0.    0.012 0.032 2.276 0.039 0.033 0.042 0.004 1.986 0.014 1.827 0.004
  0.106 0.003 0.22  0.78  0.003 0.002 0.035 0.217]
 [0.028 0.005 0.195 0.058 0.374 0.12  0.033 0.002 3.046 0.054 0.017 0.008
  0.61  0.002 1.784 1.608 0.286 0.    0.221 0.299]
 [0.004 0.002 0.003 0.071 0.133 1.104 0.    0.    2.288 0.078 0.063 0.
  2.24  0.003 1.29  0.779 0.002 0.    3.744 2.135]
 [0.    0.    0.    0.004 0.001 0.002 0.    0.    0.001 0.    0.    0.
  0.    0.    0.135 1.635 0.    0.    0.    0.001]
 [0.    0.    0.    1.662 0.002 0.181 0.001 0.    0.001 0.037 0.02  0.
  0.375 0.001 0.087 0.389 0.001 0.    0.04  0.175]
 [0.003 0.001 0.    0.122 0.002 0.001 0.    0.    0.002 0.045 0.062 0.
  0.266 0.    1.866 0.401 0.    0.    0.001 0.095]
 [0.002 0.019 0.531 0.053 0.19  0.102 0.006 0.    0.035 0.003 0.015 0.
  0.038 0.002 0.065 1.688 0.009 0.001 0.053 0.024]
 [0.004 0.015 0.479 0.049 0.183 0.1   4.448 0.001 0.143 0.009 0.004 0.043
  0.013 0.003 0.128 0.28  0.065 0.008 0.062 0.044]
 [0.    0.    0.    0.063 0.963 0.121 0.001 0.    0.003 0.051 0.046 0.
  0.272 0.002 0.288 0.334 0.001 0.    0.018 0.237]
 [0.    0.    0.    0.101 0.    0.    0.    0.    0.    0.002 0.82  0.
  0.    0.    0.178 0.239 0.    0.    0.    0.174]
 [0.    0.    0.    0.105 0.001 0.001 0.001 0.    0.001 0.    0.002 0.
  0.    0.    1.342 0.275 0.001 0.    0.    2.265]
 [0.005 0.001 2.585 0.066 0.015 0.204 3.575 0.008 0.222 0.013 0.013 0.002
  0.222 0.004 0.554 0.301 0.007 0.037 0.211 0.15 ]
 [0.    0.    0.    0.128 0.001 0.001 0.    0.    0.001 3.188 0.134 0.
  0.002 0.    0.345 0.456 0.001 0.    0.    0.405]
 [0.004 0.008 0.017 0.051 0.025 0.113 0.003 0.02  0.095 0.023 0.077 0.03
  0.283 0.    0.167 0.155 0.008 0.028 2.622 0.247]
 [0.    0.    0.    0.006 0.001 0.    0.    0.    0.001 0.    0.    0.
  0.    0.    0.006 0.21  0.    0.    0.    0.005]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.009 0.006 0.    0.    0.    0.   ]
 [0.006 0.006 0.289 0.067 0.311 0.208 0.033 0.003 0.272 0.057 0.053 0.008
  0.413 0.002 1.84  1.474 0.003 0.001 0.329 0.432]
 [0.004 4.262 0.011 0.056 0.227 0.006 0.015 0.003 0.586 0.005 0.004 0.004
  1.32  0.004 0.171 0.16  2.989 0.001 1.416 0.965]
 [0.002 0.001 0.    0.064 0.015 1.197 0.    0.    0.08  0.055 0.015 0.
  1.039 0.    0.359 1.377 0.    0.    0.003 0.485]
 [0.    0.    0.    2.083 0.    0.001 0.    0.    0.001 0.    0.    0.
  0.    0.    0.209 0.326 0.    0.    0.    0.003]]
[[0.    0.    0.    2.276 0.    0.    0.    0.    1.986 0.    1.827 0.
  0.    0.    0.    0.78  0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.374 0.    0.    0.    3.046 0.    0.    0.
  0.61  0.    1.784 1.608 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    1.104 0.    0.    2.288 0.    0.    0.
  2.24  0.    1.29  0.779 0.    0.    3.744 2.135]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    1.635 0.    0.    0.    0.   ]
 [0.    0.    0.    1.662 0.    0.    0.    0.    0.    0.    0.    0.
  0.375 0.    0.    0.389 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    1.866 0.401 0.    0.    0.    0.   ]
 [0.    0.    0.531 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    1.688 0.    0.    0.    0.   ]
 [0.    0.    0.479 0.    0.    0.    4.448 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.963 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.334 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.82  0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    1.342 0.    0.    0.    0.    2.265]
 [0.    0.    2.585 0.    0.    0.    3.575 0.    0.    0.    0.    0.
  0.    0.    0.554 0.301 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    3.188 0.    0.
  0.    0.    0.345 0.456 0.    0.    0.    0.405]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    2.622 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.311 0.    0.    0.    0.    0.    0.    0.
  0.413 0.    1.84  1.474 0.    0.    0.329 0.432]
 [0.    4.262 0.    0.    0.    0.    0.    0.    0.586 0.    0.    0.
  1.32  0.    0.    0.    2.989 0.    1.416 0.965]
 [0.    0.    0.    0.    0.    1.197 0.    0.    0.    0.    0.    0.
  1.039 0.    0.359 1.377 0.    0.    0.    0.485]
 [0.    0.    0.    2.083 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.326 0.    0.    0.    0.   ]]
{'fdr': 0.3220338983050847, 'tpr': 1.0, 'fpr': 0.12666666666666668, 'f1': 0.8080808080808081, 'shd': 19, 'npred': 59, 'ntrue': 40}
[1.160e-02 3.222e-02 2.276e+00 3.915e-02 3.284e-02 4.225e-02 3.569e-03
 1.986e+00 1.425e-02 1.827e+00 3.824e-03 1.058e-01 3.242e-03 2.199e-01
 7.799e-01 2.875e-03 1.791e-03 3.506e-02 2.169e-01 2.807e-02 1.955e-01
 5.789e-02 3.738e-01 1.197e-01 3.303e-02 2.111e-03 3.046e+00 5.447e-02
 1.744e-02 8.017e-03 6.103e-01 2.089e-03 1.784e+00 1.608e+00 2.858e-01
 4.439e-04 2.205e-01 2.992e-01 4.203e-03 1.844e-03 7.082e-02 1.331e-01
 1.104e+00 3.636e-04 9.348e-05 2.288e+00 7.780e-02 6.256e-02 3.516e-04
 2.240e+00 2.815e-03 1.290e+00 7.790e-01 1.979e-03 7.271e-05 3.744e+00
 2.135e+00 1.852e-05 1.757e-04 2.354e-04 7.949e-04 2.024e-03 2.734e-04
 6.505e-05 6.291e-04 6.206e-05 1.279e-04 1.317e-04 7.734e-05 6.554e-05
 1.346e-01 1.635e+00 4.376e-04 1.185e-04 3.033e-04 1.265e-03 1.903e-05
 1.392e-04 1.623e-04 1.662e+00 1.809e-01 1.120e-03 8.242e-05 8.259e-04
 3.652e-02 1.998e-02 8.067e-05 3.747e-01 1.426e-03 8.688e-02 3.892e-01
 1.071e-03 4.150e-05 3.976e-02 1.748e-01 2.789e-03 8.924e-04 1.104e-04
 1.224e-01 2.457e-03 1.996e-04 2.321e-05 1.698e-03 4.485e-02 6.151e-02
 4.612e-05 2.657e-01 2.681e-05 1.866e+00 4.011e-01 4.165e-04 1.893e-05
 8.018e-04 9.542e-02 1.685e-03 1.875e-02 5.309e-01 5.335e-02 1.904e-01
 1.024e-01 2.178e-04 3.534e-02 2.508e-03 1.546e-02 3.074e-05 3.780e-02
 1.783e-03 6.518e-02 1.688e+00 8.718e-03 8.461e-04 5.312e-02 2.368e-02
 4.217e-03 1.457e-02 4.791e-01 4.890e-02 1.830e-01 1.002e-01 4.448e+00
 1.430e-01 8.717e-03 3.982e-03 4.335e-02 1.334e-02 3.023e-03 1.278e-01
 2.795e-01 6.521e-02 7.686e-03 6.198e-02 4.388e-02 6.061e-05 3.270e-04
 4.131e-04 6.272e-02 9.634e-01 1.208e-01 7.484e-04 1.127e-04 5.095e-02
 4.552e-02 1.123e-04 2.716e-01 1.890e-03 2.883e-01 3.344e-01 7.697e-04
 7.164e-05 1.765e-02 2.373e-01 1.654e-04 3.500e-05 5.381e-05 1.015e-01
 1.094e-04 3.271e-04 3.481e-05 3.804e-05 1.754e-04 8.197e-01 1.963e-05
 1.663e-04 1.129e-04 1.778e-01 2.390e-01 7.333e-05 1.483e-05 3.479e-05
 1.736e-01 7.539e-05 8.068e-05 4.968e-05 1.049e-01 8.826e-04 9.042e-04
 9.673e-04 8.624e-06 1.035e-03 1.035e-04 4.903e-05 3.377e-05 1.400e-04
 1.342e+00 2.754e-01 5.343e-04 3.309e-05 1.108e-04 2.265e+00 4.723e-03
 8.092e-04 2.585e+00 6.633e-02 1.483e-02 2.037e-01 3.575e+00 7.501e-03
 2.215e-01 1.341e-02 1.300e-02 2.221e-01 3.618e-03 5.538e-01 3.014e-01
 7.205e-03 3.720e-02 2.115e-01 1.497e-01 5.329e-05 2.575e-04 1.767e-04
 1.279e-01 5.537e-04 1.363e-03 1.014e-04 2.731e-05 8.496e-04 3.188e+00
 1.341e-01 6.313e-05 2.074e-05 3.453e-01 4.565e-01 5.186e-04 9.579e-05
 2.305e-04 4.050e-01 3.560e-03 8.492e-03 1.717e-02 5.092e-02 2.545e-02
 1.127e-01 3.262e-03 2.033e-02 9.525e-02 2.327e-02 7.685e-02 2.977e-02
 2.831e-01 1.671e-01 1.552e-01 8.125e-03 2.789e-02 2.622e+00 2.472e-01
 1.562e-05 4.867e-04 1.132e-04 5.592e-03 6.040e-04 1.439e-04 1.015e-04
 2.156e-05 7.558e-04 2.112e-04 1.902e-04 4.595e-05 7.886e-05 5.238e-05
 2.096e-01 4.131e-04 9.660e-05 4.994e-05 4.834e-03 1.126e-05 3.422e-04
 5.268e-05 1.232e-04 3.059e-05 2.636e-04 4.564e-04 4.454e-05 1.405e-04
 1.670e-04 5.706e-05 1.684e-05 3.669e-05 5.323e-05 9.296e-03 2.885e-05
 3.807e-05 4.534e-05 9.888e-05 6.263e-03 6.034e-03 2.890e-01 6.691e-02
 3.109e-01 2.076e-01 3.306e-02 2.819e-03 2.718e-01 5.717e-02 5.312e-02
 8.130e-03 4.126e-01 1.597e-03 1.840e+00 1.474e+00 5.022e-04 3.287e-01
 4.324e-01 4.246e-03 4.262e+00 1.126e-02 5.596e-02 2.274e-01 6.113e-03
 1.543e-02 2.813e-03 5.860e-01 4.980e-03 3.751e-03 3.789e-03 1.320e+00
 4.165e-03 1.707e-01 1.601e-01 2.989e+00 1.416e+00 9.653e-01 2.018e-03
 9.890e-04 4.652e-04 6.391e-02 1.549e-02 1.197e+00 1.570e-04 2.091e-06
 7.999e-02 5.516e-02 1.507e-02 1.241e-04 1.039e+00 1.742e-05 3.586e-01
 1.377e+00 1.406e-04 1.433e-04 4.848e-01 2.613e-05 4.233e-04 2.139e-04
 2.083e+00 4.834e-04 1.313e-03 4.782e-04 5.024e-05 6.256e-04 2.094e-04
 7.335e-05 9.675e-05 3.444e-05 1.215e-04 2.088e-01 3.259e-01 1.656e-04
 1.618e-04 1.220e-04]
[[0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.9990441176470589, 0.9917801658432559)
cuda
4420
cuda
Objective function 737.19 = squared loss an data 521.17 + 0.5*rho*h**2 215.201283 + alpha*h 0.000000 + L2reg 0.37 + L1reg 0.45 ; SHD = 208 ; DAG False
v before min max tensor([[-3.199e-02,  4.047e-05, -9.407e-03,  ..., -6.957e-04,  2.410e-02,
         -1.150e-03],
        [-2.558e-03, -1.128e-02, -1.081e-01,  ..., -4.792e-03, -3.214e-03,
         -7.802e-04],
        [-1.687e-02,  2.377e-03, -2.798e-02,  ..., -2.902e-03, -4.722e-03,
         -1.816e-03],
        ...,
        [ 6.221e-01, -1.583e-01, -6.415e-03,  ..., -1.215e-05,  6.900e-04,
         -2.342e-02],
        [-7.597e-03, -1.414e-02, -8.203e-04,  ..., -1.731e-03, -7.073e-04,
         -8.063e-03],
        [ 4.477e-02, -1.774e-04, -7.147e-03,  ..., -3.858e-04,  1.589e-02,
         -2.886e-02]], device='cuda:0')
v tensor([[1.000e-12, 4.047e-05, 1.000e-12,  ..., 1.000e-12, 2.410e-02,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 2.377e-03, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        ...,
        [6.221e-01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 6.900e-04,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [4.477e-02, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.589e-02,
         1.000e-12]], device='cuda:0')
v before min max tensor([-6.546e-04,  2.623e-02, -8.503e-05, -7.799e-04, -2.993e-04, -2.799e-01,
        -1.681e-03, -5.617e-03, -6.421e-03, -5.389e-03, -7.551e-04, -6.098e-06,
         9.236e-05, -3.814e-02, -6.183e-05, -3.285e-02, -1.762e-03, -2.289e-03,
         3.522e-03, -2.194e-05, -1.059e-03, -3.031e-02, -6.047e-04,  2.000e-06,
         4.885e-01, -4.478e-04, -2.489e-02, -8.148e-06,  3.593e-03, -6.074e-04,
        -2.759e-02, -5.904e-02, -5.516e-02, -1.667e-04,  4.348e-04, -2.064e-02,
        -7.481e-04, -8.506e-02, -7.386e-03, -3.581e-03, -5.444e-04, -3.691e-02,
        -9.957e-04, -3.015e-02, -6.477e-03, -6.977e-05,  3.482e-04, -2.991e-03,
        -1.979e-03,  3.821e-02, -1.536e-01,  8.421e-04, -1.549e-04, -1.349e-04,
        -3.368e-02,  5.077e-03, -4.290e-03, -2.408e-03, -5.725e-03, -3.324e-02,
        -6.068e-05, -2.331e-02,  3.963e-03, -2.216e-03, -1.009e-02, -3.451e-05,
         7.856e-04, -2.381e-01, -8.939e-02, -2.125e-04, -6.711e-03, -1.791e-02,
        -6.717e-06, -3.652e-04,  2.924e-03, -5.160e-04,  1.552e-03, -3.688e-04,
        -7.109e-03, -5.291e-05,  9.285e-04,  2.878e-02, -1.872e-03, -5.701e-03,
        -3.455e-01, -3.071e-03, -7.148e-03, -2.642e-03, -5.490e-04, -6.440e-03,
         1.747e-02,  2.141e-02, -9.424e-04,  8.404e-02, -1.283e-04, -7.991e-04,
        -9.252e-04, -5.558e-04, -2.332e-02,  4.287e-04,  1.462e-04,  1.966e-04,
        -1.997e-02, -3.356e-03, -2.899e-02, -3.029e-03,  3.362e-01, -9.348e-04,
        -4.717e-04, -1.528e-02, -2.258e-03,  1.446e-04,  1.122e-03, -4.960e-02,
        -9.414e-03, -2.613e-03, -7.326e-04,  1.519e-04, -4.099e-02,  2.560e-03,
        -5.719e-05,  1.486e-04, -2.336e-03,  2.239e-04, -1.119e-03, -4.032e-06,
         7.831e-04,  2.313e-02, -5.853e-03, -7.533e-02,  9.661e-02,  1.471e-01,
         1.794e-03, -3.333e-03,  4.514e-04, -1.200e-02, -1.247e-04,  4.128e-06,
         7.572e-04, -3.356e-04,  4.743e-06,  1.260e-04, -2.989e-05, -2.772e-03,
        -1.073e-03,  2.385e-04,  9.925e-05,  1.864e-01, -1.334e-01, -9.272e-04,
        -1.655e-02, -1.235e-02,  4.307e-04, -3.428e-01, -8.308e-02,  6.879e-03,
        -4.817e-02,  9.567e-04, -3.623e-03,  8.009e-05, -4.345e-02, -2.444e-04,
        -3.197e-02, -3.147e-04, -4.678e-02,  4.391e-03,  5.949e-02, -2.689e-04,
         4.829e-02, -6.081e-06, -1.448e-03, -3.201e-01, -1.852e-04, -2.205e-03,
        -2.277e-05,  2.875e-02, -5.208e-04, -2.732e-03, -1.823e-04,  1.375e-05,
        -3.374e-03, -1.982e-05, -9.056e-05, -1.018e-05, -7.884e-03,  2.238e-01,
        -6.644e-03,  9.751e-02,  2.305e-03, -4.832e-04, -2.407e-02, -1.617e-03,
        -1.669e-02, -2.418e-03, -6.689e-03, -1.098e-03,  1.119e-02,  4.334e-05,
         6.267e-03, -1.028e-02], device='cuda:0')
v tensor([1.000e-12, 2.623e-02, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        9.236e-05, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        3.522e-03, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.000e-06,
        4.885e-01, 1.000e-12, 1.000e-12, 1.000e-12, 3.593e-03, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 4.348e-04, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.482e-04, 1.000e-12,
        1.000e-12, 3.821e-02, 1.000e-12, 8.421e-04, 1.000e-12, 1.000e-12,
        1.000e-12, 5.077e-03, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 3.963e-03, 1.000e-12, 1.000e-12, 1.000e-12,
        7.856e-04, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 2.924e-03, 1.000e-12, 1.552e-03, 1.000e-12,
        1.000e-12, 1.000e-12, 9.285e-04, 2.878e-02, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.747e-02, 2.141e-02, 1.000e-12, 8.404e-02, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 4.287e-04, 1.462e-04, 1.966e-04,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.362e-01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.446e-04, 1.122e-03, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.519e-04, 1.000e-12, 2.560e-03,
        1.000e-12, 1.486e-04, 1.000e-12, 2.239e-04, 1.000e-12, 1.000e-12,
        7.831e-04, 2.313e-02, 1.000e-12, 1.000e-12, 9.661e-02, 1.471e-01,
        1.794e-03, 1.000e-12, 4.514e-04, 1.000e-12, 1.000e-12, 4.128e-06,
        7.572e-04, 1.000e-12, 4.743e-06, 1.260e-04, 1.000e-12, 1.000e-12,
        1.000e-12, 2.385e-04, 9.925e-05, 1.864e-01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 4.307e-04, 1.000e-12, 1.000e-12, 6.879e-03,
        1.000e-12, 9.567e-04, 1.000e-12, 8.009e-05, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 4.391e-03, 5.949e-02, 1.000e-12,
        4.829e-02, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 2.875e-02, 1.000e-12, 1.000e-12, 1.000e-12, 1.375e-05,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.238e-01,
        1.000e-12, 9.751e-02, 2.305e-03, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.119e-02, 4.334e-05,
        6.267e-03, 1.000e-12], device='cuda:0')
v before min max tensor([[[ 3.753e-03],
         [-3.090e-02],
         [ 1.584e-04],
         [-3.138e-02],
         [-2.366e-01],
         [-2.082e-02],
         [-2.244e-02],
         [-3.523e-03],
         [ 1.010e-03],
         [ 2.686e-04]],

        [[ 2.655e-04],
         [-1.242e-02],
         [-1.588e-01],
         [ 2.714e-02],
         [-5.754e-02],
         [ 7.457e-02],
         [-1.635e-01],
         [ 5.271e-04],
         [ 2.183e-01],
         [ 2.809e-01]],

        [[-4.666e-03],
         [ 1.411e-01],
         [-5.000e-03],
         [-7.044e-02],
         [ 1.147e-02],
         [-5.311e-02],
         [-6.238e-04],
         [-8.871e-03],
         [ 2.926e-03],
         [ 5.521e-02]],

        [[ 9.764e-02],
         [-2.059e-02],
         [-1.963e-02],
         [-1.239e-01],
         [-1.077e-01],
         [ 7.325e-02],
         [ 1.287e-03],
         [ 4.178e-03],
         [-1.589e-02],
         [-5.481e-02]],

        [[-7.245e-02],
         [ 8.222e-03],
         [ 2.430e-01],
         [-7.311e-04],
         [-7.074e-02],
         [-9.607e-02],
         [ 2.639e-01],
         [-7.505e-03],
         [-9.954e-04],
         [ 3.334e-01]],

        [[ 9.030e-01],
         [ 2.787e-03],
         [-1.766e-01],
         [-2.735e-03],
         [ 1.242e-05],
         [-3.808e-01],
         [-1.450e-02],
         [ 2.872e-01],
         [ 1.680e-03],
         [-2.051e-03]],

        [[ 9.933e-04],
         [-1.468e-01],
         [-6.621e-02],
         [-2.187e-03],
         [-5.114e-01],
         [ 2.879e-02],
         [-3.634e-01],
         [-8.108e-03],
         [-4.980e-02],
         [-1.778e-01]],

        [[-1.277e-04],
         [ 1.698e-02],
         [-8.850e-03],
         [-4.790e-03],
         [-2.837e-02],
         [-5.673e-03],
         [ 3.386e-02],
         [ 1.317e-02],
         [-6.213e-03],
         [-1.022e-05]],

        [[ 5.021e-01],
         [ 1.119e-01],
         [-7.503e-02],
         [-7.185e-04],
         [-2.023e-02],
         [-1.116e-02],
         [ 2.336e-01],
         [ 3.754e-02],
         [-2.130e-02],
         [ 5.940e-03]],

        [[-1.584e-05],
         [-7.183e-02],
         [-2.856e-02],
         [-2.052e-02],
         [ 1.168e-02],
         [ 7.508e-02],
         [ 6.450e-02],
         [-2.575e-01],
         [-2.343e-01],
         [-1.932e-01]],

        [[-1.847e-02],
         [ 9.977e-03],
         [-1.926e-02],
         [-8.306e-02],
         [-1.773e-01],
         [ 3.804e-03],
         [-1.288e-03],
         [-1.407e-03],
         [ 1.608e-02],
         [ 2.957e-01]],

        [[ 1.234e-02],
         [ 9.242e-04],
         [-4.678e-03],
         [-1.135e-03],
         [-1.324e-02],
         [-4.610e-03],
         [-3.524e-03],
         [-1.608e-03],
         [-5.495e-04],
         [-1.690e-03]],

        [[-1.739e-01],
         [-3.156e-02],
         [ 2.132e-01],
         [-6.589e-02],
         [-6.088e-02],
         [ 2.038e-03],
         [ 8.287e-02],
         [-7.192e-02],
         [-7.000e-02],
         [ 7.746e-02]],

        [[-1.338e-02],
         [-3.543e-03],
         [-1.168e-01],
         [-1.413e-02],
         [ 1.706e-03],
         [ 2.036e-06],
         [ 2.412e-04],
         [ 1.339e-02],
         [-1.109e-03],
         [-4.231e-04]],

        [[ 1.373e-01],
         [-5.071e-02],
         [-1.439e-02],
         [ 9.955e-02],
         [ 2.575e-03],
         [ 1.047e-01],
         [-1.409e-01],
         [ 3.573e-01],
         [-7.575e-04],
         [ 9.602e-04]],

        [[-1.915e-02],
         [-6.314e-02],
         [ 3.831e-01],
         [-3.372e-02],
         [ 1.753e-01],
         [-3.005e-02],
         [ 2.307e-01],
         [ 1.281e-02],
         [ 1.105e-02],
         [ 9.954e-02]],

        [[ 4.816e-02],
         [-3.956e-03],
         [-1.248e-02],
         [-1.390e-02],
         [-4.718e-02],
         [-1.815e-04],
         [-1.469e-02],
         [-6.959e-02],
         [-3.866e-02],
         [-3.016e-01]],

        [[-1.056e-03],
         [-4.367e-03],
         [-4.059e-02],
         [-3.271e-02],
         [-1.215e-01],
         [-3.466e-02],
         [-1.891e-02],
         [-2.536e-03],
         [ 3.558e-02],
         [ 3.528e-02]],

        [[-1.281e-01],
         [ 2.812e-01],
         [ 1.092e-03],
         [ 4.939e-02],
         [-7.851e-02],
         [-3.643e-02],
         [-6.543e-02],
         [ 8.624e-03],
         [ 4.160e-03],
         [-9.441e-03]],

        [[-4.588e-02],
         [-7.212e-02],
         [-6.780e-02],
         [ 2.915e-02],
         [-1.220e-01],
         [-2.157e-01],
         [-1.755e-02],
         [ 6.093e-02],
         [-7.234e-03],
         [ 1.856e-01]]], device='cuda:0')
v tensor([[[3.753e-03],
         [1.000e-12],
         [1.584e-04],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.010e-03],
         [2.686e-04]],

        [[2.655e-04],
         [1.000e-12],
         [1.000e-12],
         [2.714e-02],
         [1.000e-12],
         [7.457e-02],
         [1.000e-12],
         [5.271e-04],
         [2.183e-01],
         [2.809e-01]],

        [[1.000e-12],
         [1.411e-01],
         [1.000e-12],
         [1.000e-12],
         [1.147e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.926e-03],
         [5.521e-02]],

        [[9.764e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.325e-02],
         [1.287e-03],
         [4.178e-03],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [8.222e-03],
         [2.430e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.639e-01],
         [1.000e-12],
         [1.000e-12],
         [3.334e-01]],

        [[9.030e-01],
         [2.787e-03],
         [1.000e-12],
         [1.000e-12],
         [1.242e-05],
         [1.000e-12],
         [1.000e-12],
         [2.872e-01],
         [1.680e-03],
         [1.000e-12]],

        [[9.933e-04],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.879e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.698e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.386e-02],
         [1.317e-02],
         [1.000e-12],
         [1.000e-12]],

        [[5.021e-01],
         [1.119e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.336e-01],
         [3.754e-02],
         [1.000e-12],
         [5.940e-03]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.168e-02],
         [7.508e-02],
         [6.450e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [9.977e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.804e-03],
         [1.000e-12],
         [1.000e-12],
         [1.608e-02],
         [2.957e-01]],

        [[1.234e-02],
         [9.242e-04],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [2.132e-01],
         [1.000e-12],
         [1.000e-12],
         [2.038e-03],
         [8.287e-02],
         [1.000e-12],
         [1.000e-12],
         [7.746e-02]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.706e-03],
         [2.036e-06],
         [2.412e-04],
         [1.339e-02],
         [1.000e-12],
         [1.000e-12]],

        [[1.373e-01],
         [1.000e-12],
         [1.000e-12],
         [9.955e-02],
         [2.575e-03],
         [1.047e-01],
         [1.000e-12],
         [3.573e-01],
         [1.000e-12],
         [9.602e-04]],

        [[1.000e-12],
         [1.000e-12],
         [3.831e-01],
         [1.000e-12],
         [1.753e-01],
         [1.000e-12],
         [2.307e-01],
         [1.281e-02],
         [1.105e-02],
         [9.954e-02]],

        [[4.816e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.558e-02],
         [3.528e-02]],

        [[1.000e-12],
         [2.812e-01],
         [1.092e-03],
         [4.939e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [8.624e-03],
         [4.160e-03],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.915e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.093e-02],
         [1.000e-12],
         [1.856e-01]]], device='cuda:0')
v before min max tensor([[ 1.944e-03],
        [ 7.924e-02],
        [-1.543e-02],
        [ 8.979e-01],
        [-1.429e-01],
        [ 5.004e-01],
        [ 3.390e-01],
        [-9.288e-03],
        [-2.087e-01],
        [ 1.095e-01],
        [ 2.520e-01],
        [-1.976e-03],
        [ 9.533e-03],
        [-1.126e-04],
        [-2.257e-01],
        [ 2.914e-01],
        [ 2.782e-02],
        [-1.068e-04],
        [-2.408e-02],
        [ 3.703e-02]], device='cuda:0')
v tensor([[1.944e-03],
        [7.924e-02],
        [1.000e-12],
        [8.979e-01],
        [1.000e-12],
        [5.004e-01],
        [3.390e-01],
        [1.000e-12],
        [1.000e-12],
        [1.095e-01],
        [2.520e-01],
        [1.000e-12],
        [9.533e-03],
        [1.000e-12],
        [1.000e-12],
        [2.914e-01],
        [2.782e-02],
        [1.000e-12],
        [1.000e-12],
        [3.703e-02]], device='cuda:0')
a after update for 1 param tensor([[ 1.515e-05, -1.838e-05, -5.205e-05,  ...,  9.726e-05,  1.367e-04,
         -1.199e-04],
        [-9.873e-05, -5.914e-05,  1.767e-04,  ..., -8.259e-05, -6.257e-06,
         -3.954e-06],
        [ 1.149e-04, -3.208e-05, -5.034e-05,  ...,  1.478e-05, -3.459e-04,
          4.244e-06],
        ...,
        [ 2.007e-03, -5.630e-06, -2.606e-04,  ..., -1.189e-05,  4.737e-05,
          1.985e-04],
        [-2.504e-05,  4.901e-05, -4.146e-05,  ..., -3.669e-04,  1.256e-04,
         -1.233e-04],
        [ 2.293e-04,  3.794e-05, -1.671e-05,  ..., -2.530e-05,  3.397e-04,
         -9.512e-04]], device='cuda:0')
s after update for 1 param tensor([[6.836e-03, 2.014e-03, 1.835e-03,  ..., 2.492e-04, 4.911e-02,
         1.221e-03],
        [6.946e-04, 2.126e-03, 3.077e-02,  ..., 1.322e-03, 1.191e-03,
         1.549e-04],
        [3.938e-03, 1.543e-02, 5.889e-03,  ..., 5.306e-04, 1.257e-02,
         3.727e-04],
        ...,
        [2.691e-01, 3.242e-02, 3.533e-03,  ..., 5.087e-05, 8.307e-03,
         4.832e-03],
        [2.272e-03, 2.648e-03, 2.271e-04,  ..., 7.716e-03, 8.224e-04,
         7.445e-03],
        [6.724e-02, 1.678e-04, 1.815e-03,  ..., 7.801e-05, 4.031e-02,
         4.779e-02]], device='cuda:0')
b after update for 1 param tensor([[0.747, 0.405, 0.387,  ..., 0.143, 2.001, 0.316],
        [0.238, 0.416, 1.584,  ..., 0.328, 0.312, 0.112],
        [0.567, 1.122, 0.693,  ..., 0.208, 1.012, 0.174],
        ...,
        [4.684, 1.626, 0.537,  ..., 0.064, 0.823, 0.628],
        [0.430, 0.465, 0.136,  ..., 0.793, 0.259, 0.779],
        [2.342, 0.117, 0.385,  ..., 0.080, 1.813, 1.974]], device='cuda:0')
clipping threshold 2.782537623814828
a after update for 1 param tensor([ 3.811e-05,  5.462e-04, -1.956e-05,  2.946e-05,  3.961e-06, -4.940e-05,
         9.048e-05,  1.199e-04, -4.424e-05,  2.715e-05, -4.996e-05, -5.852e-07,
         2.634e-05, -1.114e-04, -4.653e-05, -1.047e-04,  4.804e-06, -6.549e-05,
         1.017e-04, -1.206e-05, -3.725e-05, -7.695e-05, -7.604e-05, -6.134e-06,
        -1.558e-03, -5.962e-05,  6.667e-05,  2.309e-06, -1.662e-04, -2.492e-05,
         1.280e-04, -2.547e-04,  3.994e-04, -3.295e-06,  7.887e-05,  5.452e-06,
         2.782e-05,  7.687e-05, -1.629e-05,  6.169e-05, -9.671e-05,  3.780e-05,
        -3.900e-05, -1.792e-04, -7.791e-05,  1.341e-05, -2.082e-05, -9.607e-07,
         1.988e-05,  3.688e-04, -1.117e-03,  2.498e-04, -9.338e-08, -1.545e-05,
         9.758e-06,  1.281e-04, -8.174e-05,  7.601e-05, -4.311e-05, -2.401e-04,
        -2.200e-05,  5.240e-05, -8.089e-04, -4.332e-05, -1.918e-04,  2.036e-06,
         6.332e-05,  1.413e-04, -4.408e-04,  3.465e-05, -1.469e-05,  2.029e-04,
         4.939e-06, -9.200e-06,  7.983e-05,  9.388e-06,  1.179e-04, -1.520e-05,
        -4.063e-06,  8.940e-06,  4.541e-05,  5.286e-04,  2.964e-05,  9.512e-06,
        -6.156e-04,  9.695e-05,  7.094e-06,  7.151e-05, -3.289e-05,  8.021e-05,
        -2.114e-04, -2.727e-04, -6.436e-05, -4.722e-04,  1.335e-05, -2.235e-05,
         7.767e-06,  1.825e-05, -1.153e-04, -4.401e-05, -3.346e-05, -3.868e-05,
        -9.061e-05,  1.433e-05,  1.526e-04,  7.200e-05,  1.191e-03,  3.958e-05,
         1.255e-05,  3.326e-04, -5.216e-06, -1.764e-05, -1.232e-04,  1.091e-04,
        -3.988e-05,  4.856e-05,  3.442e-05, -6.797e-05, -1.452e-04, -8.411e-05,
        -5.472e-06,  1.883e-05, -4.172e-05,  3.065e-05,  1.217e-05, -6.067e-06,
         9.334e-05, -1.724e-04,  1.814e-04, -1.676e-05, -5.709e-04,  6.490e-04,
        -9.087e-05, -7.950e-05,  4.657e-05, -1.375e-05,  8.523e-06,  6.057e-06,
        -1.017e-04, -8.190e-05, -3.624e-06,  2.700e-05,  4.579e-06, -5.598e-05,
         3.925e-05, -4.894e-05, -5.753e-05, -8.633e-04,  1.856e-05, -3.579e-05,
        -5.743e-05, -2.824e-05,  1.585e-04,  7.337e-04, -4.827e-04, -1.514e-04,
        -7.122e-04,  2.347e-05, -6.751e-06, -2.257e-05,  5.445e-05, -1.634e-05,
         2.969e-04,  2.863e-06, -7.130e-05,  1.017e-04,  4.364e-04,  2.689e-05,
        -3.820e-04, -1.254e-06,  7.818e-05, -3.471e-04, -3.650e-06,  1.966e-05,
         1.373e-05,  2.318e-04, -2.928e-05, -1.613e-06, -5.702e-06, -8.420e-06,
         6.396e-05,  1.010e-04, -3.450e-06,  2.005e-06, -2.753e-05,  7.592e-04,
         6.680e-06,  4.581e-04, -7.998e-05, -4.539e-06, -1.937e-04,  4.933e-05,
         3.651e-05,  4.504e-05,  3.469e-04,  2.531e-06, -1.632e-04, -5.081e-05,
        -1.167e-04,  2.459e-05], device='cuda:0')
s after update for 1 param tensor([1.284e-04, 5.197e-02, 6.620e-05, 1.434e-04, 5.424e-05, 6.141e-02,
        4.049e-04, 2.345e-03, 1.532e-03, 9.822e-04, 2.190e-04, 1.882e-06,
        3.039e-03, 7.467e-03, 5.636e-05, 6.284e-03, 3.966e-04, 5.117e-04,
        1.885e-02, 4.406e-05, 5.375e-04, 9.109e-03, 7.981e-04, 4.472e-04,
        2.246e-01, 5.291e-04, 5.845e-03, 1.882e-06, 1.896e-02, 1.274e-04,
        5.199e-03, 1.302e-02, 1.781e-02, 3.396e-05, 6.616e-03, 4.128e-03,
        1.355e-04, 1.611e-02, 1.645e-03, 8.490e-04, 3.373e-04, 7.696e-03,
        1.851e-04, 9.732e-03, 1.388e-03, 3.462e-05, 5.901e-03, 5.427e-04,
        3.824e-04, 6.188e-02, 6.861e-02, 9.519e-03, 2.914e-05, 5.419e-05,
        7.107e-03, 2.253e-02, 1.548e-03, 8.234e-04, 1.069e-03, 7.390e-03,
        9.283e-05, 4.251e-03, 3.097e-02, 5.926e-04, 4.731e-03, 6.385e-06,
        8.865e-03, 4.458e-02, 2.212e-02, 3.967e-04, 1.598e-03, 3.499e-03,
        1.882e-06, 6.844e-05, 1.710e-02, 9.439e-05, 1.246e-02, 6.883e-05,
        1.556e-03, 1.580e-05, 9.637e-03, 5.505e-02, 3.725e-04, 1.129e-03,
        6.300e-02, 7.762e-04, 1.295e-03, 6.331e-04, 1.048e-04, 2.136e-03,
        4.180e-02, 4.631e-02, 2.614e-04, 9.219e-02, 3.177e-05, 1.472e-04,
        2.909e-04, 1.042e-04, 4.832e-03, 6.674e-03, 3.825e-03, 4.434e-03,
        5.829e-03, 6.240e-04, 6.025e-03, 9.733e-04, 1.850e-01, 2.706e-04,
        9.238e-05, 3.747e-03, 4.129e-04, 3.803e-03, 1.072e-02, 1.065e-02,
        1.762e-03, 2.081e-03, 1.333e-04, 3.901e-03, 1.073e-02, 1.600e-02,
        1.341e-05, 3.854e-03, 4.885e-04, 4.732e-03, 2.028e-04, 1.882e-06,
        8.869e-03, 4.852e-02, 1.933e-03, 1.508e-02, 9.939e-02, 1.214e-01,
        1.340e-02, 9.354e-04, 6.719e-03, 2.221e-03, 2.420e-05, 6.425e-04,
        8.704e-03, 3.529e-04, 7.199e-04, 3.551e-03, 7.973e-06, 1.022e-03,
        3.031e-04, 4.931e-03, 3.151e-03, 1.378e-01, 2.690e-02, 2.094e-04,
        3.401e-03, 2.708e-03, 6.692e-03, 7.540e-02, 2.555e-02, 2.624e-02,
        2.576e-02, 9.783e-03, 1.021e-03, 2.830e-03, 7.889e-03, 4.442e-05,
        1.141e-02, 6.771e-05, 1.316e-02, 2.096e-02, 7.771e-02, 6.054e-05,
        6.952e-02, 1.882e-06, 5.064e-03, 5.816e-02, 3.587e-05, 4.204e-04,
        2.332e-05, 5.367e-02, 1.018e-04, 5.424e-04, 3.306e-05, 1.173e-03,
        6.183e-04, 3.665e-04, 2.815e-05, 1.882e-06, 1.491e-03, 1.561e-01,
        1.241e-03, 1.107e-01, 1.518e-02, 1.025e-04, 1.310e-02, 4.468e-04,
        3.135e-03, 4.394e-04, 1.372e-02, 2.018e-04, 3.346e-02, 2.093e-03,
        2.504e-02, 1.986e-03], device='cuda:0')
b after update for 1 param tensor([0.102, 2.059, 0.073, 0.108, 0.067, 2.238, 0.182, 0.437, 0.353, 0.283,
        0.134, 0.012, 0.498, 0.780, 0.068, 0.716, 0.180, 0.204, 1.240, 0.060,
        0.209, 0.862, 0.255, 0.191, 4.280, 0.208, 0.690, 0.012, 1.243, 0.102,
        0.651, 1.031, 1.205, 0.053, 0.734, 0.580, 0.105, 1.146, 0.366, 0.263,
        0.166, 0.792, 0.123, 0.891, 0.336, 0.053, 0.694, 0.210, 0.177, 2.246,
        2.365, 0.881, 0.049, 0.066, 0.761, 1.356, 0.355, 0.259, 0.295, 0.776,
        0.087, 0.589, 1.589, 0.220, 0.621, 0.023, 0.850, 1.907, 1.343, 0.180,
        0.361, 0.534, 0.012, 0.075, 1.181, 0.088, 1.008, 0.075, 0.356, 0.036,
        0.887, 2.119, 0.174, 0.303, 2.267, 0.252, 0.325, 0.227, 0.092, 0.417,
        1.846, 1.943, 0.146, 2.742, 0.051, 0.110, 0.154, 0.092, 0.628, 0.738,
        0.558, 0.601, 0.689, 0.226, 0.701, 0.282, 3.884, 0.149, 0.087, 0.553,
        0.184, 0.557, 0.935, 0.932, 0.379, 0.412, 0.104, 0.564, 0.935, 1.142,
        0.033, 0.561, 0.200, 0.621, 0.129, 0.012, 0.850, 1.989, 0.397, 1.109,
        2.847, 3.147, 1.045, 0.276, 0.740, 0.426, 0.044, 0.229, 0.842, 0.170,
        0.242, 0.538, 0.025, 0.289, 0.157, 0.634, 0.507, 3.352, 1.481, 0.131,
        0.527, 0.470, 0.739, 2.480, 1.443, 1.463, 1.449, 0.893, 0.289, 0.480,
        0.802, 0.060, 0.965, 0.074, 1.036, 1.307, 2.517, 0.070, 2.381, 0.012,
        0.643, 2.178, 0.054, 0.185, 0.044, 2.092, 0.091, 0.210, 0.052, 0.309,
        0.225, 0.173, 0.048, 0.012, 0.349, 3.568, 0.318, 3.004, 1.113, 0.091,
        1.034, 0.191, 0.506, 0.189, 1.058, 0.128, 1.652, 0.413, 1.429, 0.402],
       device='cuda:0')
clipping threshold 2.782537623814828
a after update for 1 param tensor([[[ 2.027e-04],
         [-6.964e-05],
         [ 3.882e-05],
         [-2.862e-04],
         [-6.928e-04],
         [ 1.925e-04],
         [ 2.646e-04],
         [ 1.388e-04],
         [ 8.003e-05],
         [-3.246e-05]],

        [[ 3.906e-05],
         [-3.653e-05],
         [ 3.380e-04],
         [ 4.106e-04],
         [-3.083e-04],
         [ 4.855e-04],
         [ 1.264e-04],
         [-2.893e-04],
         [-1.424e-03],
         [ 5.880e-04]],

        [[-5.745e-05],
         [-4.811e-04],
         [-4.495e-05],
         [-3.173e-04],
         [ 3.458e-04],
         [-2.025e-04],
         [-3.527e-05],
         [-1.032e-04],
         [-1.380e-04],
         [-6.451e-04]],

        [[-6.347e-04],
         [-7.437e-04],
         [ 1.488e-04],
         [-4.837e-04],
         [-8.169e-04],
         [-1.182e-03],
         [-9.293e-05],
         [ 1.466e-04],
         [ 7.884e-05],
         [-3.585e-04]],

        [[ 8.931e-04],
         [-1.563e-04],
         [ 9.426e-04],
         [ 5.889e-05],
         [-5.967e-04],
         [ 4.386e-04],
         [ 7.892e-04],
         [-2.585e-04],
         [ 4.724e-06],
         [ 2.113e-03]],

        [[ 1.756e-03],
         [ 1.182e-04],
         [ 8.063e-04],
         [-8.804e-06],
         [ 1.433e-04],
         [ 1.150e-03],
         [ 2.713e-06],
         [ 1.363e-03],
         [ 1.601e-04],
         [ 6.113e-05]],

        [[-4.376e-05],
         [ 5.430e-04],
         [ 2.585e-04],
         [ 3.142e-07],
         [ 1.536e-03],
         [ 2.611e-04],
         [-3.279e-04],
         [ 2.427e-04],
         [ 9.095e-05],
         [ 4.608e-04]],

        [[-2.221e-05],
         [ 2.980e-04],
         [ 3.638e-05],
         [-1.144e-05],
         [ 1.412e-05],
         [ 1.548e-05],
         [-3.825e-04],
         [ 2.279e-04],
         [ 3.176e-05],
         [ 9.578e-07]],

        [[-1.478e-03],
         [-6.775e-04],
         [-2.274e-04],
         [ 9.806e-05],
         [-1.015e-04],
         [-1.142e-04],
         [-8.449e-04],
         [-4.494e-04],
         [-3.564e-04],
         [-2.007e-04]],

        [[ 9.628e-06],
         [ 3.774e-04],
         [ 2.357e-04],
         [ 8.297e-06],
         [ 2.874e-04],
         [ 3.777e-04],
         [ 4.927e-04],
         [ 1.698e-04],
         [-6.918e-05],
         [-6.389e-05]],

        [[ 2.079e-04],
         [ 4.523e-04],
         [-4.900e-05],
         [ 6.639e-04],
         [ 6.674e-04],
         [ 1.120e-04],
         [-1.691e-05],
         [ 2.557e-05],
         [ 2.423e-04],
         [ 1.250e-03]],

        [[-2.695e-04],
         [ 6.490e-05],
         [-9.753e-05],
         [ 2.028e-07],
         [ 5.595e-05],
         [ 1.285e-04],
         [ 5.919e-05],
         [-6.887e-06],
         [ 2.170e-05],
         [-2.018e-05]],

        [[ 4.157e-04],
         [-3.457e-04],
         [ 7.696e-04],
         [-1.233e-04],
         [-4.619e-04],
         [ 5.120e-05],
         [ 5.948e-04],
         [ 6.936e-05],
         [ 2.583e-04],
         [ 5.558e-04]],

        [[-1.213e-05],
         [ 1.659e-05],
         [ 1.178e-05],
         [ 2.164e-05],
         [-8.655e-05],
         [ 6.083e-06],
         [ 1.240e-04],
         [ 1.531e-04],
         [ 6.724e-05],
         [ 7.877e-06]],

        [[ 1.621e-03],
         [-5.346e-05],
         [ 5.188e-05],
         [ 8.731e-04],
         [ 1.947e-04],
         [ 8.964e-04],
         [ 2.788e-04],
         [ 1.134e-03],
         [ 1.178e-04],
         [ 9.678e-05]],

        [[-1.288e-04],
         [ 1.196e-04],
         [-1.443e-03],
         [-3.348e-04],
         [-1.413e-03],
         [ 7.416e-04],
         [-1.185e-03],
         [-2.589e-04],
         [-1.714e-04],
         [-7.370e-04]],

        [[-4.122e-04],
         [ 2.990e-05],
         [-9.462e-04],
         [-2.345e-05],
         [-2.449e-04],
         [ 5.686e-06],
         [-4.100e-04],
         [ 3.891e-04],
         [-1.866e-04],
         [-1.092e-03]],

        [[-1.896e-05],
         [-4.745e-05],
         [-2.239e-04],
         [ 5.330e-05],
         [-5.024e-05],
         [-8.539e-05],
         [ 5.782e-05],
         [-4.836e-05],
         [ 2.881e-04],
         [ 7.894e-04]],

        [[ 6.801e-04],
         [-1.010e-03],
         [-2.176e-04],
         [ 4.025e-04],
         [-2.793e-04],
         [-3.151e-04],
         [-2.052e-04],
         [-2.306e-04],
         [-1.769e-04],
         [-2.717e-05]],

        [[-2.100e-04],
         [-2.559e-04],
         [-4.896e-04],
         [-5.427e-04],
         [-1.261e-03],
         [-3.891e-04],
         [-6.668e-05],
         [-8.813e-04],
         [ 7.280e-05],
         [-6.895e-04]]], device='cuda:0')
s after update for 1 param tensor([[[1.951e-02],
         [7.063e-03],
         [3.980e-03],
         [1.079e-02],
         [5.825e-02],
         [5.534e-03],
         [6.582e-03],
         [1.478e-03],
         [1.005e-02],
         [5.183e-03]],

        [[5.154e-03],
         [2.272e-03],
         [3.706e-02],
         [5.217e-02],
         [1.108e-02],
         [8.643e-02],
         [3.213e-02],
         [8.344e-03],
         [1.498e-01],
         [1.781e-01]],

        [[8.554e-04],
         [1.193e-01],
         [1.018e-03],
         [1.726e-02],
         [4.393e-02],
         [1.798e-02],
         [1.132e-04],
         [1.947e-03],
         [1.711e-02],
         [7.483e-02]],

        [[9.921e-02],
         [1.975e-02],
         [5.591e-03],
         [2.312e-02],
         [3.821e-02],
         [8.818e-02],
         [1.134e-02],
         [2.101e-02],
         [1.030e-02],
         [1.374e-02]],

        [[2.528e-02],
         [2.875e-02],
         [1.561e-01],
         [7.915e-04],
         [4.375e-02],
         [1.781e-02],
         [1.669e-01],
         [4.392e-02],
         [1.851e-04],
         [2.146e-01]],

        [[3.032e-01],
         [1.672e-02],
         [3.911e-02],
         [9.188e-04],
         [1.436e-03],
         [8.028e-02],
         [2.891e-03],
         [1.761e-01],
         [1.298e-02],
         [3.839e-04]],

        [[9.979e-03],
         [3.356e-02],
         [1.261e-02],
         [4.409e-04],
         [1.334e-01],
         [5.409e-02],
         [6.590e-02],
         [2.463e-03],
         [1.624e-02],
         [3.704e-02]],

        [[3.409e-05],
         [4.126e-02],
         [1.605e-03],
         [8.860e-04],
         [5.541e-03],
         [1.070e-03],
         [5.822e-02],
         [3.630e-02],
         [1.219e-03],
         [1.882e-06]],

        [[2.243e-01],
         [1.059e-01],
         [1.393e-02],
         [6.935e-04],
         [4.993e-03],
         [2.023e-03],
         [1.529e-01],
         [6.164e-02],
         [8.428e-03],
         [2.440e-02]],

        [[5.252e-06],
         [1.926e-02],
         [1.668e-02],
         [3.791e-03],
         [3.419e-02],
         [8.683e-02],
         [8.037e-02],
         [5.131e-02],
         [8.539e-02],
         [3.542e-02]],

        [[3.519e-03],
         [3.213e-02],
         [3.490e-03],
         [2.228e-02],
         [3.233e-02],
         [1.950e-02],
         [2.334e-04],
         [3.018e-04],
         [4.019e-02],
         [1.730e-01]],

        [[3.532e-02],
         [9.621e-03],
         [8.800e-04],
         [2.670e-04],
         [3.053e-03],
         [1.425e-03],
         [7.213e-04],
         [1.548e-03],
         [1.349e-04],
         [6.336e-04]],

        [[8.577e-02],
         [7.534e-03],
         [1.461e-01],
         [4.341e-02],
         [1.372e-02],
         [1.428e-02],
         [9.119e-02],
         [1.343e-02],
         [1.363e-02],
         [8.815e-02]],

        [[2.426e-03],
         [8.121e-04],
         [2.683e-02],
         [2.680e-03],
         [1.307e-02],
         [4.513e-04],
         [4.947e-03],
         [3.668e-02],
         [6.278e-04],
         [1.280e-04]],

        [[1.303e-01],
         [1.063e-02],
         [2.624e-03],
         [1.031e-01],
         [1.610e-02],
         [1.041e-01],
         [2.566e-02],
         [1.901e-01],
         [5.774e-04],
         [9.801e-03]],

        [[3.473e-03],
         [1.369e-02],
         [1.964e-01],
         [7.248e-03],
         [1.440e-01],
         [2.940e-02],
         [1.524e-01],
         [3.579e-02],
         [3.340e-02],
         [1.003e-01]],

        [[6.944e-02],
         [8.282e-04],
         [2.108e-02],
         [4.862e-03],
         [1.031e-02],
         [3.297e-05],
         [4.327e-03],
         [1.700e-02],
         [7.880e-03],
         [7.606e-02]],

        [[1.913e-04],
         [9.313e-04],
         [7.512e-03],
         [6.606e-03],
         [2.297e-02],
         [6.378e-03],
         [5.196e-03],
         [4.678e-04],
         [5.971e-02],
         [6.689e-02]],

        [[4.234e-02],
         [1.678e-01],
         [1.051e-02],
         [7.125e-02],
         [1.436e-02],
         [7.422e-03],
         [1.189e-02],
         [2.946e-02],
         [2.040e-02],
         [5.710e-02]],

        [[8.321e-03],
         [1.394e-02],
         [1.583e-02],
         [5.419e-02],
         [6.036e-02],
         [3.913e-02],
         [3.648e-03],
         [8.231e-02],
         [1.805e-03],
         [1.366e-01]]], device='cuda:0')
b after update for 1 param tensor([[[1.261],
         [0.759],
         [0.570],
         [0.938],
         [2.179],
         [0.672],
         [0.733],
         [0.347],
         [0.905],
         [0.650]],

        [[0.648],
         [0.430],
         [1.738],
         [2.063],
         [0.950],
         [2.655],
         [1.619],
         [0.825],
         [3.495],
         [3.811]],

        [[0.264],
         [3.119],
         [0.288],
         [1.186],
         [1.893],
         [1.211],
         [0.096],
         [0.398],
         [1.181],
         [2.470]],

        [[2.844],
         [1.269],
         [0.675],
         [1.373],
         [1.765],
         [2.682],
         [0.962],
         [1.309],
         [0.916],
         [1.059]],

        [[1.436],
         [1.531],
         [3.568],
         [0.254],
         [1.889],
         [1.205],
         [3.689],
         [1.892],
         [0.123],
         [4.183]],

        [[4.972],
         [1.168],
         [1.786],
         [0.274],
         [0.342],
         [2.559],
         [0.486],
         [3.790],
         [1.029],
         [0.177]],

        [[0.902],
         [1.654],
         [1.014],
         [0.190],
         [3.298],
         [2.100],
         [2.318],
         [0.448],
         [1.151],
         [1.738]],

        [[0.053],
         [1.834],
         [0.362],
         [0.269],
         [0.672],
         [0.295],
         [2.179],
         [1.721],
         [0.315],
         [0.012]],

        [[4.277],
         [2.939],
         [1.066],
         [0.238],
         [0.638],
         [0.406],
         [3.531],
         [2.242],
         [0.829],
         [1.411]],

        [[0.021],
         [1.253],
         [1.166],
         [0.556],
         [1.670],
         [2.661],
         [2.560],
         [2.045],
         [2.639],
         [1.700]],

        [[0.536],
         [1.619],
         [0.533],
         [1.348],
         [1.624],
         [1.261],
         [0.138],
         [0.157],
         [1.810],
         [3.756]],

        [[1.697],
         [0.886],
         [0.268],
         [0.148],
         [0.499],
         [0.341],
         [0.243],
         [0.355],
         [0.105],
         [0.227]],

        [[2.645],
         [0.784],
         [3.452],
         [1.881],
         [1.058],
         [1.079],
         [2.727],
         [1.047],
         [1.054],
         [2.681]],

        [[0.445],
         [0.257],
         [1.479],
         [0.467],
         [1.033],
         [0.192],
         [0.635],
         [1.729],
         [0.226],
         [0.102]],

        [[3.259],
         [0.931],
         [0.463],
         [2.900],
         [1.146],
         [2.913],
         [1.447],
         [3.937],
         [0.217],
         [0.894]],

        [[0.532],
         [1.056],
         [4.002],
         [0.769],
         [3.427],
         [1.548],
         [3.525],
         [1.708],
         [1.650],
         [2.859]],

        [[2.380],
         [0.260],
         [1.311],
         [0.630],
         [0.917],
         [0.052],
         [0.594],
         [1.177],
         [0.802],
         [2.490]],

        [[0.125],
         [0.276],
         [0.783],
         [0.734],
         [1.369],
         [0.721],
         [0.651],
         [0.195],
         [2.207],
         [2.336]],

        [[1.858],
         [3.699],
         [0.926],
         [2.410],
         [1.082],
         [0.778],
         [0.985],
         [1.550],
         [1.290],
         [2.158]],

        [[0.824],
         [1.066],
         [1.136],
         [2.102],
         [2.219],
         [1.786],
         [0.545],
         [2.591],
         [0.384],
         [3.337]]], device='cuda:0')
clipping threshold 2.782537623814828
a after update for 1 param tensor([[ 6.326e-05],
        [-2.505e-03],
        [ 3.885e-05],
        [-2.200e-03],
        [-8.177e-05],
        [ 1.821e-03],
        [ 1.114e-03],
        [ 1.222e-05],
        [-2.591e-04],
        [ 6.882e-04],
        [ 8.787e-04],
        [-3.763e-06],
        [ 4.199e-04],
        [ 1.161e-05],
        [ 1.255e-04],
        [-1.323e-03],
        [-9.374e-04],
        [-1.722e-05],
        [-2.249e-04],
        [ 2.424e-04]], device='cuda:0')
s after update for 1 param tensor([[1.396e-02],
        [1.615e-01],
        [2.948e-03],
        [3.084e-01],
        [2.590e-02],
        [2.396e-01],
        [1.844e-01],
        [1.861e-03],
        [4.350e-02],
        [1.049e-01],
        [1.618e-01],
        [4.224e-04],
        [3.158e-02],
        [3.749e-05],
        [4.343e-02],
        [1.715e-01],
        [5.443e-02],
        [7.086e-05],
        [9.205e-03],
        [8.755e-02]], device='cuda:0')
b after update for 1 param tensor([[1.067],
        [3.629],
        [0.490],
        [5.015],
        [1.453],
        [4.420],
        [3.877],
        [0.390],
        [1.883],
        [2.925],
        [3.632],
        [0.186],
        [1.605],
        [0.055],
        [1.882],
        [3.740],
        [2.107],
        [0.076],
        [0.866],
        [2.672]], device='cuda:0')
clipping threshold 2.782537623814828
||w||^2 0.15598617357571912
exp ma of ||w||^2 0.18299683021774554
||w|| 0.3949508495695624
exp ma of ||w|| 0.4114014404142301
||w||^2 0.15976505083856615
exp ma of ||w||^2 0.1706966485656799
||w|| 0.39970620565431075
exp ma of ||w|| 0.3972285883770494
||w||^2 0.14903086648321145
exp ma of ||w||^2 0.1605814342115745
||w|| 0.3860451611964738
exp ma of ||w|| 0.39001270262005766
||w||^2 0.11767731179697354
exp ma of ||w||^2 0.17444221450664105
||w|| 0.34304126835844917
exp ma of ||w|| 0.4075186954229585
||w||^2 0.18386965615885137
exp ma of ||w||^2 0.310530841830831
||w|| 0.4288002520508254
exp ma of ||w|| 0.5343249272992702
||w||^2 0.48186882444329626
exp ma of ||w||^2 0.4761412831364236
||w|| 0.6941677206866481
exp ma of ||w|| 0.6592234314210722
||w||^2 0.5971689084021058
exp ma of ||w||^2 0.4845266638112748
||w|| 0.7727670466590212
exp ma of ||w|| 0.6744334227948988
v before min max tensor([[ -85.107,    4.932,  -62.106,  ...,  -61.452,  -48.793,   16.372],
        [-103.982,   45.799,   -9.754,  ...,  -34.002,  -70.960,  -63.780],
        [ -68.012,   38.563,  -74.801,  ...,  -67.345,  -81.706,  -18.543],
        ...,
        [ -62.897,  -75.122,  -48.927,  ...,  -53.162,  -37.117,  -41.988],
        [ -81.542,  -67.370,   12.829,  ...,  -26.462,  -73.248,   19.908],
        [ -38.797,  -79.308,   49.402,  ...,  297.963,  -83.651,   -2.416]],
       device='cuda:0')
v tensor([[1.000e-12, 4.932e+00, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e+01],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([ -93.902,  -51.215,  -91.825,  -64.552,   95.424,  -80.416,  -70.472,
         -58.210,  -85.823,  -44.965,  -17.608,   -1.373,    8.751,  -68.558,
         -56.870,  -85.093,  -74.241,   80.889,  -25.560,   51.881,  -55.202,
          80.527,  191.224,  187.068,  -82.764,  -10.088,  -37.103,    1.404,
         -92.450, -104.117,  -26.672,  -91.891,  -81.988,  -73.918,  -81.063,
         -70.205,  -90.199,  -74.783,  -41.149,  -67.541,  145.852,  -28.603,
           2.591,  -91.176,   67.813,  -30.417,    6.535,  -12.428,  -63.199,
         -11.263,  -65.246,  -49.389,  -70.278,  -85.008, -111.950,  146.692,
         -40.601,  -67.968,  -41.247,  -96.759,  -92.900,  489.220,  118.379,
         -69.285,  -84.898,  -80.462,  -74.964,  229.501,  -67.046,  243.045,
         136.659,  -88.425,   19.058,  -37.049,  -66.875,  233.017,  -52.104,
         -16.173,   48.763,  -32.161,   14.219,  -18.213,  -18.023,  -67.265,
         -68.156,  -40.532,   35.536,  -94.016,  -94.996,  -33.681,  147.618,
          75.408, -101.980,  -94.440,  -29.718,  -73.349,   10.314,  -82.220,
           9.302,  -39.052,   45.745,  -62.127,   -6.053,  -32.677,  209.971,
          71.268,  -42.234,  -78.112,  -67.819,  -61.712,   -9.802,  -63.232,
         -87.343,  -45.082,  -70.862,  -64.651,  -41.734,  -17.610,   93.233,
        -105.445,  137.115,  -18.399,  -44.777,  -87.133,  -96.223,  -89.016,
         -76.209,  -91.283,  -73.804,  -94.358,  -35.763,  -77.904,  194.716,
          94.141,  -32.859,  -95.434, -103.372,  -34.391,  -23.689,   39.060,
         -15.930,  -12.224,  -82.568,   36.328,  -34.892,  -91.740,  -62.994,
         -81.677,  -63.299,  -87.386,  -95.196,    1.997,  -35.451,  -18.767,
         -26.321,  132.791,  -50.590,  -66.263,  223.408,   18.250,  -94.110,
          41.317,   18.820,   35.038,  130.078,   -7.474,  -48.272,   -3.390,
          86.491,  -68.931,  -74.787,  -56.377,  -84.628,   68.540,  -64.340,
         -84.601,  -87.202,  -41.811,  -19.131, -112.720,  -59.591,  -66.158,
         -16.978,   44.615,  -63.416,  -60.189,  -65.602,  -42.346,  -57.842,
         339.934,  -88.178,  -84.129,    7.484,  -73.885,  -45.262,  -30.834,
         -73.673,   19.139,  -62.694,  -82.423], device='cuda:0')
v tensor([1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        8.751e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.404e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        2.591e+00, 1.000e-12, 1.000e+01, 1.000e-12, 6.535e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 9.302e+00, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.997e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        7.484e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12], device='cuda:0')
v before min max tensor([[[-5.438e+01],
         [-5.189e+01],
         [-6.270e+01],
         [ 4.893e+01],
         [-5.633e+01],
         [ 2.613e+02],
         [-4.915e+01],
         [-8.663e+01],
         [-3.486e+01],
         [ 9.722e+01]],

        [[-1.758e+01],
         [-5.621e+01],
         [-2.368e+01],
         [-7.271e+01],
         [-9.373e+01],
         [-9.247e+01],
         [ 9.491e+01],
         [-9.006e+01],
         [ 1.217e+02],
         [-1.850e+01]],

        [[-7.630e+01],
         [ 5.491e+02],
         [ 9.493e+01],
         [-9.090e+01],
         [-9.313e+01],
         [-3.075e+01],
         [-7.719e+01],
         [-6.973e+01],
         [ 2.143e+01],
         [ 1.839e+02]],

        [[-5.907e+01],
         [ 1.451e+02],
         [ 1.639e+02],
         [-9.595e+01],
         [-9.364e+01],
         [-7.809e+01],
         [-7.739e+01],
         [-1.022e+02],
         [ 1.877e+01],
         [-7.866e+01]],

        [[ 5.195e+00],
         [ 8.066e+00],
         [-9.949e+01],
         [-6.049e+01],
         [-4.481e+01],
         [ 7.500e+02],
         [-3.212e+01],
         [-1.006e+02],
         [ 8.642e+00],
         [-8.216e+01]],

        [[-6.836e+01],
         [ 5.661e+02],
         [-3.531e+01],
         [-4.700e+01],
         [-8.758e+01],
         [-1.280e+02],
         [ 7.265e+01],
         [-5.640e+01],
         [-2.142e+00],
         [-2.771e+01]],

        [[-6.395e+01],
         [-4.066e+01],
         [-8.131e+01],
         [-1.059e+02],
         [-6.169e+01],
         [-1.083e+02],
         [-7.167e+01],
         [-1.117e+02],
         [ 3.599e+01],
         [ 1.631e+02]],

        [[ 3.246e+02],
         [ 4.630e+01],
         [-1.002e+02],
         [ 1.720e+01],
         [-6.110e+01],
         [ 1.499e+01],
         [ 2.382e+02],
         [ 3.220e+01],
         [-5.816e+01],
         [ 1.637e+00]],

        [[ 9.669e+01],
         [ 1.441e+02],
         [-9.364e+00],
         [-8.328e+01],
         [-5.260e+01],
         [ 2.290e+01],
         [-1.036e+02],
         [ 4.197e+02],
         [-8.070e+01],
         [ 9.718e+00]],

        [[-5.663e+01],
         [-4.108e+01],
         [-8.517e+00],
         [-7.411e+01],
         [-5.265e+01],
         [-5.574e+01],
         [-6.000e+01],
         [ 3.873e+02],
         [ 3.264e+01],
         [-7.643e+01]],

        [[-7.026e+01],
         [ 1.606e+02],
         [ 6.498e+00],
         [-5.025e+01],
         [-7.608e+01],
         [-6.153e+01],
         [ 2.203e+01],
         [-4.960e+01],
         [-4.911e+01],
         [-8.417e+01]],

        [[-7.859e+00],
         [-4.171e+01],
         [ 1.906e+01],
         [-6.566e+01],
         [-9.469e+01],
         [-7.135e+01],
         [-1.194e+02],
         [ 1.908e+02],
         [-3.891e+01],
         [-6.748e+01]],

        [[-5.210e+01],
         [-6.093e+01],
         [ 1.161e+02],
         [-7.345e+01],
         [-7.432e+01],
         [ 4.240e+00],
         [-3.029e+01],
         [-3.953e+01],
         [-9.207e+01],
         [-8.844e+01]],

        [[-5.447e+01],
         [ 1.925e+02],
         [-5.536e+01],
         [-8.611e+01],
         [-3.005e+01],
         [-6.012e+01],
         [-4.731e+01],
         [ 1.819e+02],
         [ 7.108e+01],
         [-1.615e+01]],

        [[ 1.311e+02],
         [ 2.415e+01],
         [-9.098e+01],
         [-3.094e+01],
         [-7.028e+01],
         [-9.816e+01],
         [ 9.492e+00],
         [-4.545e+01],
         [-4.736e+01],
         [-8.904e+01]],

        [[-5.877e+01],
         [-8.959e+01],
         [ 4.825e+02],
         [-7.237e+01],
         [ 2.310e+02],
         [ 1.724e+02],
         [-1.413e+02],
         [ 9.166e+01],
         [-2.778e+01],
         [ 9.538e+01]],

        [[-7.389e+01],
         [-6.886e+01],
         [-4.285e+01],
         [-5.907e+01],
         [ 4.565e+01],
         [ 8.611e+01],
         [ 1.950e+02],
         [-4.768e+01],
         [-3.960e+01],
         [ 2.036e+02]],

        [[-5.235e+01],
         [-8.239e+01],
         [ 1.599e+02],
         [-9.171e+01],
         [-5.183e+01],
         [ 6.317e-01],
         [-5.576e+01],
         [-3.155e+01],
         [ 6.979e+01],
         [-2.390e+01]],

        [[ 9.131e+01],
         [ 4.387e+01],
         [-8.337e+01],
         [-7.214e+01],
         [-9.993e+01],
         [-6.416e+01],
         [ 7.796e+01],
         [ 5.040e+00],
         [-6.012e+01],
         [ 8.244e+01]],

        [[-8.725e+01],
         [ 1.590e+01],
         [-3.754e+01],
         [-4.855e+01],
         [-7.779e+01],
         [ 4.839e+01],
         [-8.185e+01],
         [-9.235e+01],
         [ 5.080e+01],
         [ 2.617e+01]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[5.195e+00],
         [8.066e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [8.642e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.637e+00]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [9.718e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [6.498e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [4.240e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [9.492e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [6.317e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [5.040e+00],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]]], device='cuda:0')
v before min max tensor([[ 194.833],
        [-101.278],
        [ -23.570],
        [ -81.981],
        [-105.294],
        [ 359.363],
        [ -79.792],
        [ -18.934],
        [ -65.951],
        [ -68.128],
        [ 210.895],
        [  46.677],
        [ -64.120],
        [ -25.533],
        [ -13.833],
        [ 295.747],
        [ -22.427],
        [ -38.243],
        [ -42.169],
        [  98.231]], device='cuda:0')
v tensor([[1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01]], device='cuda:0')
a after update for 1 param tensor([[-0.019, -0.047, -0.060,  ...,  0.028, -0.050, -0.019],
        [-0.136, -0.015,  0.178,  ...,  0.086, -0.019, -0.042],
        [ 0.066, -0.046, -0.030,  ..., -0.055, -0.184,  0.135],
        ...,
        [-0.069, -0.008, -0.075,  ...,  0.004, -0.050,  0.102],
        [-0.017, -0.087, -0.076,  ...,  0.003, -0.078, -0.125],
        [ 0.034, -0.010,  0.024,  ...,  0.076, -0.125,  0.023]],
       device='cuda:0')
s after update for 1 param tensor([[1.727, 1.750, 1.776,  ..., 1.276, 1.349, 1.391],
        [2.105, 2.090, 1.263,  ..., 0.901, 1.632, 1.317],
        [1.692, 2.057, 1.451,  ..., 1.665, 1.558, 1.654],
        ...,
        [1.266, 1.531, 1.511,  ..., 1.721, 0.868, 1.763],
        [1.638, 1.908, 1.966,  ..., 1.668, 1.772, 1.761],
        [1.313, 1.537, 1.696,  ..., 1.650, 1.585, 1.181]], device='cuda:0')
b after update for 1 param tensor([[112.380, 113.111, 113.939,  ...,  96.577,  99.322, 100.860],
        [124.062, 123.617,  96.108,  ...,  81.158, 109.219,  98.126],
        [111.210, 122.631, 103.000,  ..., 110.344, 106.729, 109.981],
        ...,
        [ 96.193, 105.792, 105.118,  ..., 112.178,  79.680, 113.536],
        [109.427, 118.114, 119.896,  ..., 110.422, 113.823, 113.480],
        [ 97.987, 106.009, 111.363,  ..., 109.849, 107.657,  92.924]],
       device='cuda:0')
clipping threshold 0.5744015150659727
a after update for 1 param tensor([ 0.085, -0.145, -0.007,  0.011, -0.067, -0.007,  0.032, -0.065,  0.047,
        -0.015, -0.009,  0.003,  0.023, -0.047, -0.022,  0.004, -0.014, -0.091,
         0.041,  0.098, -0.065,  0.090, -0.051,  0.096, -0.007,  0.120, -0.111,
         0.017,  0.122, -0.001,  0.041, -0.097, -0.156, -0.104, -0.072, -0.032,
         0.088, -0.137, -0.004, -0.077, -0.003, -0.197, -0.020, -0.140, -0.051,
        -0.097,  0.108, -0.052, -0.127, -0.086, -0.020, -0.026,  0.003, -0.054,
         0.114,  0.029,  0.042, -0.184,  0.047, -0.044,  0.004, -0.009,  0.097,
        -0.037, -0.030, -0.049, -0.044,  0.039, -0.069, -0.127, -0.102,  0.023,
         0.081,  0.069, -0.053,  0.092, -0.126,  0.018,  0.101, -0.064, -0.045,
        -0.073, -0.035,  0.120,  0.052, -0.026, -0.018, -0.041,  0.034, -0.010,
         0.088, -0.011, -0.112,  0.058,  0.039, -0.033, -0.084,  0.001, -0.013,
        -0.054,  0.000, -0.008,  0.083,  0.034, -0.009, -0.046, -0.031, -0.099,
        -0.053,  0.027,  0.027,  0.008,  0.033, -0.027,  0.105, -0.077, -0.103,
        -0.019, -0.056,  0.009, -0.101,  0.019, -0.091,  0.022, -0.134, -0.077,
        -0.132,  0.152,  0.039, -0.026,  0.072,  0.009,  0.137,  0.025, -0.070,
        -0.130,  0.076,  0.026, -0.034,  0.055,  0.072,  0.098, -0.031, -0.014,
        -0.114, -0.061, -0.151,  0.009, -0.001, -0.002, -0.054,  0.044,  0.028,
        -0.001, -0.045, -0.054, -0.039,  0.081, -0.029,  0.048, -0.059, -0.023,
        -0.124, -0.004,  0.005,  0.138,  0.006, -0.047,  0.107,  0.003, -0.078,
        -0.052, -0.053, -0.008, -0.003,  0.006, -0.055,  0.057, -0.018, -0.007,
         0.054,  0.122, -0.171,  0.023, -0.068, -0.073,  0.024, -0.015,  0.004,
        -0.006,  0.019, -0.194,  0.131, -0.040, -0.014,  0.049,  0.055,  0.053,
        -0.139,  0.097], device='cuda:0')
s after update for 1 param tensor([1.954, 1.678, 1.942, 1.524, 1.779, 1.564, 1.779, 1.476, 1.726, 0.845,
        1.655, 0.908, 1.911, 1.624, 1.445, 1.616, 1.401, 2.020, 1.201, 2.011,
        2.050, 1.563, 2.098, 2.174, 1.566, 1.538, 1.715, 1.333, 1.748, 2.266,
        2.111, 1.880, 1.573, 1.746, 1.844, 1.352, 1.897, 1.497, 1.526, 1.719,
        1.737, 1.683, 1.829, 1.962, 1.725, 1.539, 2.027, 1.364, 1.306, 1.468,
        1.423, 1.300, 1.804, 1.851, 2.122, 1.975, 0.915, 1.283, 1.481, 2.060,
        1.825, 1.899, 2.116, 1.709, 1.872, 1.604, 1.765, 1.639, 1.260, 2.070,
        1.888, 1.730, 1.774, 1.403, 1.265, 1.749, 1.874, 0.368, 2.247, 0.806,
        1.873, 1.894, 1.620, 1.531, 1.668, 1.786, 1.922, 1.791, 1.820, 1.332,
        2.032, 2.340, 1.921, 2.152, 1.843, 1.378, 1.919, 1.564, 2.210, 1.470,
        1.680, 1.424, 1.282, 1.196, 1.645, 2.136, 1.399, 1.751, 1.416, 1.284,
        1.091, 1.271, 1.641, 0.869, 1.724, 1.284, 1.798, 1.488, 1.774, 1.998,
        2.129, 1.034, 1.293, 1.965, 1.965, 2.001, 1.729, 1.724, 1.938, 1.773,
        1.829, 1.565, 1.779, 2.082, 1.427, 1.843, 1.992, 1.047, 1.510, 2.148,
        1.092, 0.956, 1.553, 1.533, 1.697, 1.727, 2.092, 1.601, 1.482, 1.658,
        1.821, 1.166, 0.749, 1.290, 1.269, 2.184, 1.379, 1.391, 1.860, 2.400,
        1.779, 1.789, 2.027, 1.653, 2.025, 1.751, 1.651, 1.782, 1.898, 1.337,
        1.550, 1.156, 1.607, 1.992, 1.944, 1.664, 1.707, 1.483, 2.086, 2.193,
        1.392, 1.288, 1.309, 2.134, 1.835, 1.730, 1.429, 1.233, 1.405, 1.831,
        1.765, 2.088, 2.149, 1.484, 1.538, 0.765, 1.490, 1.738, 1.181, 1.584],
       device='cuda:0')
b after update for 1 param tensor([119.515, 110.750, 119.174, 105.553, 114.041, 106.927, 114.063, 103.883,
        112.348,  78.604, 110.018,  81.478, 118.219, 108.970, 102.793, 108.714,
        101.213, 121.515,  93.699, 121.259, 122.424, 106.913, 123.856, 126.068,
        106.991, 106.053, 111.988,  98.717, 113.051, 128.717, 124.243, 117.226,
        107.250, 112.977, 116.112,  99.438, 117.765, 104.628, 105.614, 112.121,
        112.705, 110.940, 115.649, 119.761, 112.315, 106.061, 121.749,  99.870,
         97.736, 103.587, 101.991,  97.485, 114.857, 116.324, 124.556, 120.163,
         81.777,  96.870, 104.069, 122.721, 115.516, 117.825, 124.370, 111.771,
        116.977, 108.277, 113.600, 109.472,  95.976, 123.018, 117.476, 112.478,
        113.875, 101.280,  96.156, 113.072, 117.051,  51.880, 128.178,  76.771,
        117.035, 117.686, 108.819, 105.809, 110.420, 114.284, 118.533, 114.434,
        115.345,  98.699, 121.888, 130.787, 118.513, 125.427, 116.086, 100.383,
        118.442, 106.948, 127.119, 103.655, 110.838, 102.034,  96.825,  93.513,
        109.660, 124.959, 101.132, 113.163, 101.732,  96.905,  89.298,  96.384,
        109.539,  79.714, 112.281,  96.883, 114.659, 104.303, 113.878, 120.857,
        124.770,  86.955,  97.247, 119.877, 119.853, 120.949, 112.448, 112.274,
        119.049, 113.852, 115.625, 106.970, 114.064, 123.394, 102.155, 116.088,
        120.684,  87.505, 105.070, 125.320,  89.365,  83.624, 106.549, 105.862,
        111.379, 112.368, 123.688, 108.189, 104.097, 110.090, 115.399,  92.325,
         73.978,  97.130,  96.339, 126.373, 100.393, 100.839, 116.616, 132.465,
        114.040, 114.368, 121.740, 109.924, 121.673, 113.150, 109.884, 114.134,
        117.791,  98.877, 106.462,  91.942, 108.397, 120.676, 119.223, 110.296,
        111.727, 104.114, 123.497, 126.627, 100.877,  97.027,  97.822, 124.924,
        115.845, 112.466, 102.208,  94.953, 101.364, 115.715, 113.586, 123.553,
        125.358, 104.177, 106.041,  74.812, 104.357, 112.718,  92.920, 107.621],
       device='cuda:0')
clipping threshold 0.5744015150659727
a after update for 1 param tensor([[[-0.043],
         [ 0.029],
         [-0.122],
         [ 0.114],
         [ 0.109],
         [ 0.021],
         [ 0.057],
         [-0.130],
         [ 0.146],
         [ 0.045]],

        [[-0.190],
         [-0.133],
         [-3.736],
         [-3.218],
         [-3.462],
         [-0.015],
         [-0.223],
         [-3.168],
         [-3.670],
         [-3.163]],

        [[-0.214],
         [-0.269],
         [ 0.028],
         [-0.210],
         [-0.429],
         [ 0.139],
         [-0.220],
         [ 0.024],
         [ 0.142],
         [-0.408]],

        [[-1.776],
         [-1.661],
         [-0.671],
         [-1.614],
         [-1.798],
         [-1.812],
         [-0.009],
         [-1.428],
         [-1.736],
         [-1.699]],

        [[ 1.951],
         [ 0.058],
         [ 1.892],
         [-0.166],
         [ 1.961],
         [ 1.758],
         [ 0.014],
         [ 2.052],
         [-0.056],
         [ 2.001]],

        [[ 1.798],
         [ 1.779],
         [ 1.614],
         [ 0.211],
         [ 0.283],
         [ 1.547],
         [ 0.731],
         [ 1.655],
         [ 0.296],
         [ 0.113]],

        [[ 0.547],
         [ 1.030],
         [-0.072],
         [ 0.743],
         [ 0.954],
         [ 1.180],
         [ 1.084],
         [ 0.687],
         [ 1.049],
         [ 1.104]],

        [[-0.007],
         [ 0.007],
         [ 0.185],
         [ 0.079],
         [ 0.080],
         [ 0.060],
         [-0.053],
         [-0.078],
         [ 0.044],
         [ 0.062]],

        [[-3.087],
         [-2.489],
         [-0.263],
         [ 0.020],
         [ 0.047],
         [-0.096],
         [-0.079],
         [ 0.015],
         [-2.797],
         [-1.851]],

        [[ 0.568],
         [ 0.759],
         [ 0.508],
         [-0.027],
         [ 0.751],
         [ 0.027],
         [ 0.667],
         [ 0.774],
         [ 0.008],
         [-0.139]],

        [[ 0.600],
         [ 0.692],
         [ 0.004],
         [ 0.500],
         [ 0.646],
         [ 0.342],
         [ 0.223],
         [-0.044],
         [ 0.089],
         [ 0.465]],

        [[-0.038],
         [-0.122],
         [-0.006],
         [ 0.046],
         [ 0.096],
         [ 0.059],
         [ 0.184],
         [-0.067],
         [ 0.186],
         [ 0.058]],

        [[ 0.511],
         [ 0.104],
         [ 0.117],
         [-0.113],
         [-0.061],
         [ 0.255],
         [ 0.466],
         [ 0.296],
         [-0.104],
         [ 0.376]],

        [[-0.078],
         [ 0.120],
         [ 0.039],
         [ 0.044],
         [ 0.018],
         [ 0.006],
         [-0.012],
         [-0.141],
         [-0.044],
         [ 0.083]],

        [[ 2.340],
         [ 0.020],
         [ 1.431],
         [ 2.442],
         [ 0.401],
         [ 0.118],
         [ 2.280],
         [ 2.446],
         [ 0.016],
         [ 1.172]],

        [[-0.075],
         [ 0.095],
         [-2.014],
         [-1.089],
         [-1.965],
         [-2.065],
         [-2.021],
         [-1.413],
         [-0.054],
         [-2.129]],

        [[-0.530],
         [ 0.209],
         [-0.886],
         [-0.951],
         [-0.589],
         [-0.181],
         [-0.962],
         [-0.138],
         [-0.868],
         [-0.470]],

        [[-0.217],
         [-0.053],
         [-0.108],
         [ 0.156],
         [-0.178],
         [ 0.052],
         [ 0.117],
         [ 0.021],
         [-0.130],
         [ 0.098]],

        [[ 0.162],
         [-0.690],
         [-0.450],
         [-0.269],
         [-0.311],
         [-0.577],
         [-0.307],
         [-0.983],
         [-0.811],
         [-0.420]],

        [[-1.064],
         [-0.160],
         [-0.985],
         [-1.002],
         [-0.914],
         [-0.909],
         [-0.479],
         [-0.962],
         [-0.040],
         [-0.824]]], device='cuda:0')
s after update for 1 param tensor([[[1.479],
         [1.415],
         [1.840],
         [1.951],
         [1.183],
         [1.816],
         [1.783],
         [1.859],
         [1.483],
         [1.586]],

        [[1.576],
         [1.291],
         [1.935],
         [2.156],
         [1.812],
         [1.744],
         [1.855],
         [2.025],
         [2.314],
         [1.875]],

        [[1.533],
         [2.397],
         [2.067],
         [1.771],
         [2.082],
         [1.462],
         [1.580],
         [1.325],
         [1.683],
         [1.706]],

        [[2.394],
         [2.331],
         [2.127],
         [1.870],
         [2.421],
         [1.883],
         [1.457],
         [1.926],
         [2.186],
         [1.480]],

        [[2.218],
         [1.894],
         [1.984],
         [1.622],
         [2.518],
         [2.541],
         [1.160],
         [1.961],
         [1.660],
         [1.715]],

        [[2.296],
         [2.168],
         [2.081],
         [1.309],
         [1.654],
         [2.519],
         [2.040],
         [2.390],
         [1.861],
         [1.089]],

        [[1.737],
         [0.922],
         [1.578],
         [1.992],
         [1.878],
         [2.195],
         [1.616],
         [2.126],
         [1.677],
         [2.163]],

        [[2.404],
         [1.619],
         [1.937],
         [2.148],
         [1.149],
         [1.291],
         [2.055],
         [1.658],
         [1.100],
         [1.730]],

        [[2.122],
         [2.281],
         [1.903],
         [1.777],
         [1.293],
         [1.851],
         [1.952],
         [1.859],
         [1.961],
         [2.006]],

        [[1.924],
         [1.683],
         [1.164],
         [1.393],
         [1.377],
         [1.282],
         [1.252],
         [2.410],
         [2.142],
         [1.543]],

        [[1.569],
         [2.125],
         [1.478],
         [1.543],
         [1.731],
         [1.589],
         [1.534],
         [1.154],
         [1.286],
         [1.872]],

        [[1.673],
         [1.500],
         [1.948],
         [1.542],
         [2.014],
         [1.529],
         [2.338],
         [1.639],
         [1.868],
         [1.325]],

        [[1.296],
         [1.158],
         [1.988],
         [1.908],
         [1.701],
         [1.139],
         [1.425],
         [1.419],
         [1.756],
         [1.704]],

        [[1.518],
         [1.708],
         [1.622],
         [1.620],
         [1.362],
         [1.627],
         [1.002],
         [1.890],
         [1.636],
         [1.202]],

        [[2.300],
         [2.086],
         [1.839],
         [1.919],
         [1.918],
         [1.856],
         [2.053],
         [1.459],
         [1.313],
         [1.683]],

        [[1.751],
         [1.713],
         [2.474],
         [1.758],
         [2.369],
         [2.324],
         [2.700],
         [2.139],
         [1.507],
         [2.184]],

        [[1.449],
         [1.294],
         [1.513],
         [1.246],
         [1.737],
         [2.090],
         [1.820],
         [1.059],
         [1.537],
         [1.684]],

        [[1.527],
         [1.698],
         [1.701],
         [2.046],
         [2.022],
         [1.484],
         [1.438],
         [1.235],
         [1.653],
         [1.676]],

        [[2.124],
         [1.794],
         [1.582],
         [1.368],
         [1.892],
         [1.363],
         [2.104],
         [1.779],
         [1.190],
         [2.008]],

        [[1.697],
         [1.575],
         [1.451],
         [1.606],
         [1.682],
         [1.903],
         [1.642],
         [2.048],
         [1.714],
         [1.791]]], device='cuda:0')
b after update for 1 param tensor([[[104.002],
         [101.701],
         [115.981],
         [119.440],
         [ 93.016],
         [115.241],
         [114.185],
         [116.575],
         [104.141],
         [107.684]],

        [[107.353],
         [ 97.169],
         [118.943],
         [125.563],
         [115.096],
         [112.911],
         [116.446],
         [121.664],
         [130.077],
         [117.098]],

        [[105.885],
         [132.375],
         [122.921],
         [113.801],
         [123.380],
         [103.395],
         [107.486],
         [ 98.436],
         [110.921],
         [111.694]],

        [[132.300],
         [130.540],
         [124.694],
         [116.940],
         [133.045],
         [117.324],
         [103.219],
         [118.672],
         [126.427],
         [104.012]],

        [[127.344],
         [117.672],
         [120.436],
         [108.895],
         [135.692],
         [136.303],
         [ 92.097],
         [119.726],
         [110.179],
         [111.986]],

        [[129.569],
         [125.900],
         [123.361],
         [ 97.848],
         [109.958],
         [135.709],
         [122.142],
         [132.191],
         [116.645],
         [ 89.251]],

        [[112.680],
         [ 82.106],
         [107.396],
         [120.689],
         [117.165],
         [126.677],
         [108.691],
         [124.669],
         [110.729],
         [125.764]],

        [[132.575],
         [108.800],
         [119.005],
         [125.312],
         [ 91.672],
         [ 97.158],
         [122.571],
         [110.094],
         [ 89.680],
         [112.462]],

        [[124.571],
         [129.129],
         [117.953],
         [113.972],
         [ 97.216],
         [116.329],
         [119.478],
         [116.589],
         [119.742],
         [121.112]],

        [[118.605],
         [110.917],
         [ 92.257],
         [100.929],
         [100.329],
         [ 96.819],
         [ 95.661],
         [132.755],
         [125.155],
         [106.229]],

        [[107.114],
         [124.652],
         [103.960],
         [106.206],
         [112.509],
         [107.775],
         [105.901],
         [ 91.852],
         [ 96.955],
         [116.986]],

        [[110.599],
         [104.721],
         [119.346],
         [106.188],
         [121.358],
         [105.740],
         [130.743],
         [109.472],
         [116.873],
         [ 98.439]],

        [[ 97.347],
         [ 92.019],
         [120.559],
         [118.111],
         [111.518],
         [ 91.253],
         [102.061],
         [101.865],
         [113.306],
         [111.615]],

        [[105.361],
         [111.762],
         [108.904],
         [108.820],
         [ 99.796],
         [109.071],
         [ 85.576],
         [117.552],
         [109.360],
         [ 93.732]],

        [[129.683],
         [123.486],
         [115.961],
         [118.443],
         [118.416],
         [116.503],
         [122.514],
         [103.299],
         [ 97.977],
         [110.942]],

        [[113.158],
         [111.910],
         [134.484],
         [113.376],
         [131.612],
         [130.349],
         [140.513],
         [125.046],
         [104.982],
         [126.375]],

        [[102.938],
         [ 97.261],
         [105.163],
         [ 95.464],
         [112.707],
         [123.602],
         [115.362],
         [ 87.994],
         [106.016],
         [110.947]],

        [[105.647],
         [111.411],
         [111.505],
         [122.316],
         [121.584],
         [104.148],
         [102.549],
         [ 95.027],
         [109.945],
         [110.705]],

        [[124.614],
         [114.530],
         [107.536],
         [100.002],
         [117.601],
         [ 99.813],
         [124.019],
         [114.057],
         [ 93.293],
         [121.158]],

        [[111.401],
         [107.304],
         [103.003],
         [108.356],
         [110.896],
         [117.968],
         [109.581],
         [122.369],
         [111.936],
         [114.425]]], device='cuda:0')
clipping threshold 0.5744015150659727
a after update for 1 param tensor([[-0.007],
        [-3.736],
        [-0.206],
        [-1.776],
        [ 2.047],
        [ 1.753],
        [ 0.990],
        [-0.045],
        [-2.753],
        [ 0.779],
        [ 0.537],
        [-0.039],
        [ 0.407],
        [ 0.014],
        [ 2.368],
        [-2.128],
        [-0.685],
        [ 0.075],
        [-0.098],
        [-1.202]], device='cuda:0')
s after update for 1 param tensor([[1.717],
        [2.167],
        [1.330],
        [2.245],
        [2.380],
        [2.363],
        [1.499],
        [0.955],
        [1.745],
        [1.649],
        [1.888],
        [1.772],
        [1.505],
        [1.704],
        [1.723],
        [2.426],
        [1.980],
        [1.288],
        [2.187],
        [1.931]], device='cuda:0')
b after update for 1 param tensor([[112.031],
        [125.880],
        [ 98.630],
        [128.129],
        [131.919],
        [131.439],
        [104.707],
        [ 83.570],
        [112.965],
        [109.810],
        [117.494],
        [113.810],
        [104.907],
        [111.608],
        [112.252],
        [133.172],
        [120.314],
        [ 97.035],
        [126.442],
        [118.812]], device='cuda:0')
clipping threshold 0.5744015150659727
||w||^2 0.42030483271453434
exp ma of ||w||^2 0.7030535107683972
||w|| 0.6483092107278242
exp ma of ||w|| 0.8058598718777097
||w||^2 0.634564455466438
exp ma of ||w||^2 0.7234309118619647
||w|| 0.7965955407020793
exp ma of ||w|| 0.8253328463873566
||w||^2 1.6649813217467866
exp ma of ||w||^2 0.7967150016096629
||w|| 1.290341552359989
exp ma of ||w|| 0.8491705469130146
||w||^2 0.5274374395237345
exp ma of ||w||^2 0.8321868833814745
||w|| 0.7262488826316599
exp ma of ||w|| 0.8690524201168919
||w||^2 0.427498603318612
exp ma of ||w||^2 0.8168682442318708
||w|| 0.6538337734612766
exp ma of ||w|| 0.8680625280205282
cuda
Objective function 56.59 = squared loss an data 46.30 + 0.5*rho*h**2 8.994185 + alpha*h 0.000000 + L2reg 0.99 + L1reg 0.31 ; SHD = 151 ; DAG False
Proportion of microbatches that were clipped  0.770069455661444
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 4.241269844477493
iteration 1 in outer loop, alpha = 4.241269844477493, rho = 1.0, h = 4.241269844477493
cuda
4420
cuda
Objective function 74.58 = squared loss an data 46.30 + 0.5*rho*h**2 8.994185 + alpha*h 17.988370 + L2reg 0.99 + L1reg 0.31 ; SHD = 151 ; DAG False
||w||^2 72379617597.72307
exp ma of ||w||^2 119733077643.41405
||w|| 269034.60297464166
exp ma of ||w|| 262979.1552037426
||w||^2 1664.7624344842557
exp ma of ||w||^2 72380862.95352656
||w|| 40.80150039501312
exp ma of ||w|| 711.5784051657954
||w||^2 1.8618750639361776
exp ma of ||w||^2 1556952.9888216592
||w|| 1.364505428327853
exp ma of ||w|| 18.672577149105848
||w||^2 1.99877833466364
exp ma of ||w||^2 1.3852562039954512
||w|| 1.4137815724727918
exp ma of ||w|| 1.1313384516507647
||w||^2 0.8989044970302884
exp ma of ||w||^2 1.1487871260477618
||w|| 0.9481057414815546
exp ma of ||w|| 1.025842384218795
||w||^2 1.8254775140501676
exp ma of ||w||^2 1.3892659811147001
||w|| 1.3511023329304732
exp ma of ||w|| 1.1297429128031824
||w||^2 1.1893481039528324
exp ma of ||w||^2 1.4670765409321245
||w|| 1.0905723744680278
exp ma of ||w|| 1.1676345067092122
||w||^2 1.2747452077704535
exp ma of ||w||^2 1.4149483849666282
||w|| 1.1290461495308566
exp ma of ||w|| 1.1360772877443361
||w||^2 0.9407992659631758
exp ma of ||w||^2 1.2983110698179596
||w|| 0.969948073848892
exp ma of ||w|| 1.1015832397160235
||w||^2 1.1072493795707308
exp ma of ||w||^2 1.3010966116695928
||w|| 1.0522591788959272
exp ma of ||w|| 1.0930244027569447
||w||^2 1.6342438255968703
exp ma of ||w||^2 1.4908964866390744
||w|| 1.27837546346794
exp ma of ||w|| 1.167102235709849
||w||^2 2.035188042311521
exp ma of ||w||^2 1.4661355033910095
||w|| 1.4266001690423007
exp ma of ||w|| 1.1634494558620108
cuda
Objective function 43.59 = squared loss an data 28.94 + 0.5*rho*h**2 2.864729 + alpha*h 10.152025 + L2reg 1.35 + L1reg 0.27 ; SHD = 113 ; DAG False
Proportion of microbatches that were clipped  0.7694374338516649
iteration 1 in inner loop, alpha 4.241269844477493 rho 1.0 h 2.3936286595107106
4420
cuda
Objective function 69.37 = squared loss an data 28.94 + 0.5*rho*h**2 28.647291 + alpha*h 10.152025 + L2reg 1.35 + L1reg 0.27 ; SHD = 113 ; DAG False
||w||^2 990.6596840121242
exp ma of ||w||^2 26513746.55230287
||w|| 31.474746766449517
exp ma of ||w|| 221.09086302815743
||w||^2 4.084274418428206
exp ma of ||w||^2 5.058954498445223
||w|| 2.0209587869197643
exp ma of ||w|| 1.7161717639096816
v before min max tensor([[-434.297, -413.707,  493.346,  ...,   28.952, -503.659, 1601.810],
        [-271.652, -148.715, 4632.555,  ..., -115.276, 1457.675, -510.494],
        [ 872.231,   24.911,  643.769,  ...,  392.634,  -92.657,   83.044],
        ...,
        [-256.141, -389.901, -168.547,  ...,  -25.124, -437.967, -326.006],
        [-181.964, -415.386, -387.706,  ..., -227.807, -137.894, -449.908],
        [-120.674, -224.292, -339.654,  ..., -105.566, -315.208, -420.516]],
       device='cuda:0')
v tensor([[1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e+01,
         1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.000e+01],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([-270.178,  437.755,  -83.910, -557.139, -390.726, -220.250,  515.993,
        -342.742,  171.841,  -21.204,  385.492, -271.686, -419.552, -210.878,
        -353.941, -121.136, 1856.056, -426.191, 1110.711,  -23.196, -206.209,
         453.134,  154.560, -410.022,  289.893, -140.043, -464.491, -370.212,
         737.708,  281.299, -202.610, -418.581,  105.096,  -19.320, -298.110,
        -382.858, -516.296,  267.695, -299.519, -405.720, 1618.810, -340.630,
        -525.194, -388.371, -416.654, -458.743,  -85.728, -214.723, 1022.347,
        -263.492, -409.025,  111.887,  111.680, -371.366, -425.020,  147.658,
          60.244, -440.581,  366.920,  211.111,  177.361, -459.482, -374.367,
        -518.386, -111.065, -355.685, -400.414,  827.920,  113.898,  202.180,
        -557.489, -292.697, -140.520,  557.791, -304.049, -300.240,   42.095,
        -336.804,  796.591,  317.643, -436.632, -488.698,  722.617,  -56.598,
        -370.002, -209.347, -327.811,  303.910, 1003.733, 1340.014, 5372.949,
         636.099, 2562.601, -382.161,  349.377,  678.780, -431.037, -302.627,
         573.643, -255.769, -491.937, -517.292, -257.343, 2439.400, -351.156,
        -491.842,  414.757,  -79.311,  -73.476,  720.626, -497.785, -480.249,
        -189.008,   32.579,  373.770, -299.061, -302.392, -454.418, -501.737,
        2108.969, -383.908, -292.259,   98.640, 1932.890, -451.067, -363.386,
        -434.196,  714.005, -415.245,  202.282, -548.487, -480.098,  318.401,
        -379.232, -379.720,  796.234, -439.507, -495.813, -306.957, -362.069,
        -208.705,  672.595, -486.828,  -96.805,  -40.138, -355.312, -426.400,
         352.676, -271.622, -366.910, -390.645, -393.004, -291.408, -380.966,
         -30.029,   70.529, -263.452, -480.617, 1437.731, -306.497, -192.994,
         479.834, -320.839, -345.867, -385.775, -476.357, -374.540,  160.725,
         451.227, -553.902, -455.342,  539.800, -272.883,  -94.138, -300.885,
        -370.254, -247.443, -308.830, -506.730, -320.998, -544.804, -414.495,
        -451.725,  942.033, -462.200, -421.361,   86.950, -168.748, -347.876,
        -338.034, -439.597, -328.660, -344.161,  274.306, -536.349, -253.513,
        -156.676, -421.523,  -82.143, -108.179], device='cuda:0')
v tensor([1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12], device='cuda:0')
v before min max tensor([[[ 4.822e+01],
         [-1.554e+02],
         [-1.705e+02],
         [-3.399e+02],
         [-3.200e+02],
         [ 2.506e+02],
         [-5.789e+02],
         [-1.654e+01],
         [ 1.032e+02],
         [ 3.437e+00]],

        [[ 4.705e+01],
         [-3.104e+02],
         [-4.912e+02],
         [ 5.014e+02],
         [-1.814e+02],
         [-8.429e+00],
         [ 8.146e+01],
         [ 1.341e+03],
         [-3.355e+02],
         [ 3.407e+02]],

        [[-1.140e+02],
         [-4.176e+02],
         [-2.902e+02],
         [ 2.030e+02],
         [-3.433e+02],
         [-7.356e+01],
         [-2.744e+01],
         [-4.805e+02],
         [ 7.079e+02],
         [-4.270e+02]],

        [[-3.748e+02],
         [-9.840e+01],
         [-5.882e+02],
         [-3.999e+02],
         [-3.540e+02],
         [ 3.471e+03],
         [-3.419e+02],
         [-1.348e+00],
         [-5.355e+02],
         [-3.764e+02]],

        [[-9.419e+01],
         [-3.754e+02],
         [-3.910e+02],
         [-5.445e+02],
         [-2.594e+01],
         [ 1.923e+02],
         [ 2.598e+02],
         [-2.254e+02],
         [ 3.579e+03],
         [-2.343e-01]],

        [[-4.417e+02],
         [-2.973e+02],
         [ 3.029e+02],
         [-2.488e+01],
         [-2.567e+02],
         [-4.105e+02],
         [ 3.349e+02],
         [ 1.503e+03],
         [-3.145e+02],
         [-4.579e+02]],

        [[-1.716e+02],
         [ 8.058e+00],
         [-3.763e+02],
         [-1.887e+02],
         [-3.725e+01],
         [-3.161e+02],
         [-4.624e+02],
         [-3.668e+02],
         [-2.657e+02],
         [-2.450e+02]],

        [[ 2.176e+01],
         [ 1.795e+02],
         [-3.581e+02],
         [-3.563e+02],
         [-8.979e+01],
         [ 1.211e+03],
         [-9.150e+01],
         [-5.392e+02],
         [-4.259e+02],
         [ 1.334e+03]],

        [[-2.483e+02],
         [-3.194e+02],
         [ 3.813e+02],
         [-4.093e+02],
         [ 1.291e+02],
         [ 1.502e+02],
         [ 9.889e+02],
         [-3.753e+02],
         [-3.267e+02],
         [ 3.725e+02]],

        [[-3.323e+02],
         [-2.011e+02],
         [-4.638e+02],
         [-4.475e+02],
         [ 5.029e+02],
         [ 1.033e+02],
         [ 1.598e+02],
         [-1.500e+02],
         [-4.421e+02],
         [ 2.786e+02]],

        [[-3.522e+02],
         [ 7.287e+02],
         [ 1.626e+03],
         [-5.284e+02],
         [-3.837e+02],
         [-1.002e+02],
         [-4.074e+02],
         [-4.435e+02],
         [-5.041e+02],
         [ 5.338e+02]],

        [[-3.980e+02],
         [ 7.533e+02],
         [-1.903e+02],
         [-4.748e+02],
         [ 7.000e+02],
         [-4.131e+02],
         [ 1.435e+02],
         [-2.487e+02],
         [-4.548e+01],
         [-3.873e+02]],

        [[-2.887e+02],
         [ 1.103e+02],
         [-4.033e+02],
         [-4.473e+02],
         [-5.499e+02],
         [-2.016e+02],
         [-1.739e+02],
         [-2.146e+02],
         [-3.544e+01],
         [ 6.114e+02]],

        [[-4.011e+02],
         [-1.863e+02],
         [ 1.360e+01],
         [-5.022e+02],
         [ 3.484e+02],
         [-2.767e+02],
         [-4.343e+02],
         [ 1.947e+02],
         [-7.912e+01],
         [-3.537e+02]],

        [[-4.714e+02],
         [ 1.440e+03],
         [-3.909e+02],
         [-4.691e+02],
         [-1.398e+02],
         [-3.057e+02],
         [-2.548e+02],
         [ 5.090e+03],
         [ 7.841e+02],
         [ 1.247e+02]],

        [[-1.850e+02],
         [-4.278e+02],
         [-4.922e+02],
         [ 7.935e+02],
         [ 4.682e+01],
         [ 9.805e+02],
         [ 1.556e+03],
         [-4.772e+02],
         [-3.374e+02],
         [ 2.176e+02]],

        [[-3.244e+02],
         [-4.293e+02],
         [-3.777e+02],
         [-9.047e+01],
         [ 5.186e+01],
         [-2.297e+02],
         [-3.440e+02],
         [-4.791e+02],
         [ 2.866e+02],
         [-3.629e+02]],

        [[ 1.690e+02],
         [-4.775e+02],
         [-5.874e+01],
         [ 6.147e+02],
         [-5.101e+02],
         [-5.138e+02],
         [-3.165e+02],
         [-2.983e+02],
         [-3.408e+02],
         [ 2.156e+02]],

        [[-2.882e+02],
         [ 1.801e+02],
         [ 1.321e+02],
         [-4.328e+02],
         [-4.325e+02],
         [-1.832e+02],
         [ 4.303e+01],
         [-1.814e+02],
         [-4.164e+02],
         [-3.479e+02]],

        [[-4.871e+02],
         [ 4.404e+02],
         [-4.637e+02],
         [-4.596e+02],
         [-2.593e+02],
         [-3.292e+02],
         [ 9.210e+02],
         [-3.746e+02],
         [-3.567e+02],
         [-4.269e+02]]], device='cuda:0')
v tensor([[[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [3.437e+00]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [8.058e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[ 104.424],
        [-448.109],
        [-138.629],
        [-174.313],
        [ 915.088],
        [ 660.859],
        [-353.783],
        [-324.459],
        [ 257.518],
        [-458.708],
        [ 451.949],
        [2498.129],
        [ 519.242],
        [-355.620],
        [1447.885],
        [-569.656],
        [1635.007],
        [-314.267],
        [-217.123],
        [-361.742]], device='cuda:0')
v tensor([[1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 0.055, -0.006, -0.439,  ..., -0.514,  0.241, -0.247],
        [-0.105, -0.363,  0.056,  ...,  0.578,  0.039,  0.094],
        [-0.071, -0.004,  0.182,  ..., -0.168,  0.126, -0.230],
        ...,
        [-0.009, -0.152, -0.031,  ...,  0.163,  0.218,  0.205],
        [ 0.070,  0.001,  0.137,  ...,  0.223, -0.045,  0.028],
        [ 0.103,  0.100, -0.267,  ..., -0.009,  0.154,  0.031]],
       device='cuda:0')
s after update for 1 param tensor([[1.570, 1.610, 1.944,  ..., 1.904, 1.810, 1.766],
        [1.554, 1.559, 2.266,  ..., 1.220, 1.938, 2.098],
        [1.691, 1.821, 1.712,  ..., 1.878, 1.102, 1.673],
        ...,
        [1.295, 1.559, 2.153,  ..., 1.345, 1.944, 1.942],
        [1.407, 1.665, 1.460,  ..., 1.405, 1.222, 1.631],
        [2.127, 1.946, 1.242,  ..., 1.373, 1.750, 1.547]], device='cuda:0')
b after update for 1 param tensor([[109.631, 111.017, 122.003,  ..., 120.729, 117.727, 116.289],
        [109.090, 109.264, 131.723,  ...,  96.658, 121.826, 126.743],
        [113.791, 118.064, 114.503,  ..., 119.912,  91.867, 113.181],
        ...,
        [ 99.558, 109.268, 128.384,  ..., 101.484, 122.011, 121.935],
        [103.773, 112.894, 105.723,  ..., 103.734,  96.739, 111.745],
        [127.612, 122.050,  97.520,  ..., 102.530, 115.747, 108.818]],
       device='cuda:0')
clipping threshold 1.289726885935637
a after update for 1 param tensor([-0.148, -0.024,  0.081, -0.060, -0.043, -0.110,  0.228,  0.245,  0.236,
         0.128, -0.207,  0.196,  0.291, -0.224,  0.412,  0.046,  0.231,  0.230,
        -0.021,  0.020,  0.041,  0.297, -0.220,  0.235,  0.046,  0.424, -0.237,
        -0.137,  0.269,  0.331, -0.004, -0.149, -0.075, -0.134,  0.152, -0.352,
        -0.161, -0.112, -0.095, -0.246,  0.360,  0.072, -0.438, -0.046,  0.059,
        -0.305, -0.005,  0.035, -0.154,  0.184,  0.189,  0.379,  0.016, -0.219,
        -0.080,  0.224,  0.355, -0.340,  0.061, -0.252, -0.043,  0.094, -0.347,
        -0.479,  0.399, -0.026,  0.601, -0.008, -0.247,  0.009, -0.002, -0.479,
        -0.122, -0.179,  0.232,  0.156,  0.216,  0.417,  0.121,  0.257,  0.136,
        -0.182, -0.041,  0.367, -0.318,  0.135, -0.166, -0.369,  0.182, -0.049,
        -0.149,  0.188, -0.387,  0.016,  0.195,  0.094, -0.418, -0.391, -0.129,
        -0.214, -0.137,  0.272,  0.054,  0.241, -0.274, -0.032, -0.005, -0.073,
        -0.254,  0.430, -0.481,  0.120, -0.530, -0.082,  0.112, -0.016,  0.596,
        -0.058, -0.071, -0.409,  0.335,  0.110,  0.129, -0.059, -0.092, -0.304,
         0.568,  0.181,  0.170,  0.157, -0.016, -0.038,  0.061,  0.171, -0.068,
        -0.221,  0.097, -0.283,  0.634,  0.310, -0.058,  0.114,  0.247, -0.235,
        -0.392, -0.053,  0.022,  0.083, -0.070,  0.086,  0.273,  0.219, -0.510,
         0.309, -0.073,  0.053,  0.075, -0.241,  0.177,  0.068,  0.243,  0.323,
         0.381, -0.094,  0.166,  0.519,  0.187,  0.465,  0.298,  0.076, -0.463,
         0.284,  0.116, -0.066,  0.282,  0.351, -0.083,  0.380, -0.039,  0.086,
         0.295,  0.069,  0.362,  0.241,  0.142,  0.234, -0.299,  0.160, -0.260,
        -0.192, -0.027,  0.289,  0.129, -0.318, -0.240,  0.108, -0.269,  0.131,
        -0.033,  0.383], device='cuda:0')
s after update for 1 param tensor([1.284, 1.734, 1.043, 2.009, 1.600, 1.534, 1.775, 1.951, 2.037, 1.573,
        1.211, 1.151, 1.819, 1.612, 1.390, 1.896, 1.748, 1.544, 1.654, 1.178,
        1.682, 1.981, 2.051, 1.636, 2.008, 1.750, 1.670, 1.937, 1.797, 1.852,
        1.238, 1.780, 2.311, 2.050, 1.532, 1.379, 1.880, 1.591, 1.534, 1.526,
        1.918, 1.431, 1.899, 1.842, 1.706, 1.650, 2.162, 1.454, 2.035, 2.048,
        1.851, 1.727, 1.749, 1.508, 1.927, 1.203, 1.722, 1.755, 2.033, 2.054,
        2.239, 1.695, 1.441, 1.908, 1.247, 1.419, 1.448, 1.906, 2.250, 1.913,
        2.003, 1.607, 1.488, 2.102, 1.505, 1.925, 2.261, 1.646, 2.306, 2.259,
        1.771, 1.813, 1.956, 1.494, 1.701, 1.260, 1.398, 2.163, 1.980, 1.985,
        2.030, 1.713, 2.248, 1.477, 1.695, 1.921, 1.739, 1.706, 2.122, 1.171,
        1.768, 1.892, 1.377, 1.935, 1.596, 1.899, 2.101, 1.759, 1.729, 2.050,
        1.800, 1.730, 1.866, 1.517, 2.055, 1.119, 1.632, 1.695, 2.218, 2.308,
        1.484, 1.104, 1.943, 2.470, 1.623, 1.447, 1.831, 2.061, 2.023, 2.222,
        1.982, 1.727, 1.979, 1.758, 1.364, 2.185, 1.917, 1.782, 1.105, 2.056,
        1.790, 1.871, 1.751, 1.564, 1.773, 1.277, 1.541, 2.160, 1.029, 1.469,
        1.560, 1.412, 1.245, 1.627, 1.608, 1.691, 1.598, 1.770, 1.988, 1.453,
        1.754, 1.910, 1.841, 1.475, 1.853, 1.893, 1.743, 1.774, 2.130, 2.015,
        1.653, 1.723, 1.090, 1.795, 1.462, 1.967, 1.781, 1.499, 1.847, 1.500,
        1.976, 2.004, 1.716, 1.645, 1.888, 1.533, 1.693, 1.620, 1.313, 1.301,
        1.580, 1.696, 1.241, 2.170, 1.957, 2.091, 1.905, 1.700, 0.979, 2.025],
       device='cuda:0')
b after update for 1 param tensor([ 99.158, 115.206,  89.368, 124.007, 110.688, 108.373, 116.574, 122.216,
        124.893, 109.744,  96.290,  93.893, 117.997, 111.089, 103.161, 120.496,
        115.691, 108.712, 112.530,  94.949, 113.471, 123.157, 125.304, 111.919,
        123.990, 115.737, 113.083, 121.767, 117.290, 119.074,  97.350, 116.731,
        133.023, 125.285, 108.297, 102.757, 119.966, 110.363, 108.363, 108.079,
        121.167, 104.682, 120.595, 118.749, 114.301, 112.385, 128.665, 105.492,
        124.814, 125.209, 119.052, 114.991, 115.713, 107.456, 121.477,  95.973,
        114.819, 115.934, 124.748, 125.417, 130.916, 113.902, 105.021, 120.864,
         97.726, 104.215, 105.307, 120.795, 131.265, 121.014, 123.852, 110.915,
        106.750, 126.861, 107.335, 121.411, 131.566, 112.252, 132.861, 131.521,
        116.437, 117.814, 122.379, 106.945, 114.136,  98.228, 103.442, 128.696,
        123.123, 123.276, 124.665, 114.511, 131.179, 106.349, 113.906, 121.272,
        115.375, 114.283, 127.449,  94.689, 116.345, 120.342, 102.672, 121.718,
        110.551, 120.566, 126.844, 116.033, 115.055, 125.297, 117.401, 115.098,
        119.533, 107.783, 125.424,  92.543, 111.771, 113.922, 130.308, 132.938,
        106.575,  91.934, 121.953, 137.514, 111.460, 105.262, 118.408, 125.627,
        124.467, 130.431, 123.172, 114.979, 123.081, 116.012, 102.208, 129.331,
        121.139, 116.791,  91.990, 125.478, 117.084, 119.685, 115.789, 109.412,
        116.517,  98.869, 108.621, 128.597,  88.755, 106.046, 109.286, 103.985,
         97.633, 111.625, 110.960, 113.775, 110.597, 116.399, 123.375, 105.484,
        115.893, 120.944, 118.717, 106.258, 119.123, 120.392, 115.513, 116.541,
        127.691, 124.195, 112.503, 114.861,  91.338, 117.236, 105.812, 122.725,
        116.775, 107.119, 118.915, 107.151, 123.002, 123.873, 114.606, 112.222,
        120.245, 108.333, 113.843, 111.369, 100.245,  99.821, 109.979, 113.953,
         97.490, 128.905, 122.405, 126.522, 120.779, 114.088,  86.564, 124.515],
       device='cuda:0')
clipping threshold 1.289726885935637
a after update for 1 param tensor([[[-1.275e-01],
         [-2.626e-01],
         [ 6.598e-02],
         [ 7.301e-01],
         [ 5.969e-02],
         [-1.179e-01],
         [ 2.527e-01],
         [-2.650e-01],
         [-6.933e-02],
         [-3.764e-01]],

        [[-5.732e-02],
         [-1.935e-01],
         [-4.111e-01],
         [-5.479e-01],
         [ 2.760e-01],
         [ 1.752e-01],
         [-1.373e-01],
         [ 4.205e-02],
         [ 6.962e-02],
         [ 2.960e-01]],

        [[ 1.956e-02],
         [-4.602e-02],
         [ 1.536e-02],
         [-4.135e-01],
         [-1.475e-01],
         [ 1.807e-01],
         [ 1.665e-01],
         [-2.994e-02],
         [-5.468e-02],
         [-3.096e-01]],

        [[-8.429e-02],
         [-4.638e-01],
         [-2.725e-01],
         [-9.297e-02],
         [-2.146e-01],
         [-1.010e-01],
         [ 1.055e-01],
         [-2.139e-01],
         [-3.220e-01],
         [-1.931e-01]],

        [[-2.543e-01],
         [ 5.825e-01],
         [-1.734e-01],
         [ 2.873e-01],
         [ 9.873e-02],
         [ 1.806e-01],
         [ 6.254e-02],
         [-6.471e-02],
         [-3.168e-02],
         [-7.401e-02]],

        [[ 3.398e-02],
         [ 4.189e-02],
         [-1.836e-01],
         [-5.294e-02],
         [-6.478e-01],
         [ 3.411e-02],
         [-2.814e-02],
         [ 5.908e-02],
         [ 2.862e-01],
         [ 1.057e-01]],

        [[-2.478e-01],
         [-1.473e-01],
         [ 9.150e-02],
         [ 1.886e-02],
         [-3.553e-03],
         [ 2.711e-01],
         [ 2.952e-01],
         [-1.173e-01],
         [ 6.917e-01],
         [-2.066e-01]],

        [[ 3.288e-01],
         [-2.513e-01],
         [ 2.256e-01],
         [ 1.533e-01],
         [ 3.097e-01],
         [ 8.972e-02],
         [-1.385e-03],
         [ 1.156e-01],
         [-2.688e-01],
         [-3.632e-01]],

        [[-3.170e-01],
         [ 3.237e-01],
         [-2.287e-01],
         [-1.070e-01],
         [ 2.521e-01],
         [ 5.299e-03],
         [ 6.496e-01],
         [-3.305e-02],
         [-9.755e-02],
         [-1.973e-01]],

        [[ 7.532e-02],
         [-7.563e-02],
         [ 2.275e-01],
         [ 3.737e-01],
         [-2.802e-02],
         [ 7.523e-02],
         [ 1.599e-01],
         [ 1.369e-01],
         [-1.142e-01],
         [ 1.795e-01]],

        [[-3.246e-01],
         [ 1.902e-01],
         [ 8.579e-02],
         [-4.024e-01],
         [-1.952e-01],
         [ 2.475e-01],
         [ 1.724e-01],
         [ 5.682e-01],
         [ 6.258e-01],
         [-1.024e-01]],

        [[ 6.996e-03],
         [ 3.886e-02],
         [-9.013e-02],
         [ 7.442e-02],
         [-3.716e-03],
         [ 1.398e-01],
         [-8.765e-01],
         [ 2.736e-01],
         [-3.931e-01],
         [-2.812e-02]],

        [[-2.395e-01],
         [ 1.529e-01],
         [-1.184e-01],
         [ 2.002e-01],
         [ 1.960e-01],
         [-5.974e-01],
         [-1.173e-02],
         [-1.054e-01],
         [ 4.390e-01],
         [-1.076e-01]],

        [[-2.589e-01],
         [-8.553e-04],
         [-9.409e-02],
         [-6.919e-01],
         [ 6.908e-02],
         [ 3.384e-01],
         [-1.976e-01],
         [-2.355e-01],
         [ 1.591e-01],
         [-2.974e-01]],

        [[ 2.733e-01],
         [-1.443e-01],
         [ 2.385e-01],
         [ 4.978e-02],
         [ 3.679e-01],
         [-3.451e-02],
         [-4.083e-01],
         [-2.436e-02],
         [ 6.975e-02],
         [ 5.432e-01]],

        [[-1.141e-01],
         [ 4.216e-02],
         [ 2.119e-02],
         [ 1.120e-01],
         [-3.033e-01],
         [-6.635e-01],
         [ 3.078e-01],
         [-1.785e-01],
         [-1.865e-01],
         [ 3.581e-01]],

        [[-2.513e-01],
         [ 3.754e-02],
         [-1.313e-01],
         [ 9.987e-03],
         [-3.145e-01],
         [-1.901e-01],
         [-2.152e-01],
         [ 5.885e-03],
         [ 7.217e-03],
         [-8.365e-02]],

        [[-9.177e-02],
         [ 4.259e-01],
         [-2.059e-01],
         [-8.711e-02],
         [ 5.155e-01],
         [ 3.315e-01],
         [ 2.064e-01],
         [ 5.368e-01],
         [-1.520e-01],
         [ 4.983e-01]],

        [[ 4.455e-01],
         [-3.852e-01],
         [-2.383e-01],
         [-2.810e-01],
         [-2.261e-01],
         [ 4.333e-01],
         [ 2.641e-01],
         [-1.994e-01],
         [-1.209e-01],
         [-2.053e-01]],

        [[-3.441e-01],
         [ 4.174e-02],
         [-6.718e-02],
         [-1.418e-02],
         [ 6.599e-01],
         [ 9.345e-02],
         [-8.872e-02],
         [ 7.178e-02],
         [ 5.613e-02],
         [ 1.671e-01]]], device='cuda:0')
s after update for 1 param tensor([[[1.866],
         [1.591],
         [1.909],
         [1.474],
         [1.699],
         [2.071],
         [2.120],
         [2.093],
         [2.069],
         [1.637]],

        [[1.541],
         [1.984],
         [1.767],
         [2.264],
         [1.394],
         [1.168],
         [1.808],
         [1.440],
         [1.757],
         [2.468]],

        [[1.897],
         [1.644],
         [1.886],
         [1.908],
         [1.237],
         [1.536],
         [1.420],
         [1.769],
         [1.835],
         [1.718]],

        [[1.491],
         [1.347],
         [2.146],
         [1.634],
         [1.578],
         [2.199],
         [1.408],
         [1.458],
         [1.936],
         [1.484]],

        [[2.208],
         [1.700],
         [1.572],
         [2.030],
         [1.532],
         [2.064],
         [1.880],
         [1.603],
         [2.045],
         [1.526]],

        [[1.970],
         [1.290],
         [2.020],
         [1.815],
         [2.279],
         [1.477],
         [1.608],
         [1.857],
         [1.472],
         [1.646]],

        [[1.089],
         [1.628],
         [1.423],
         [0.882],
         [1.735],
         [1.688],
         [1.664],
         [1.462],
         [1.530],
         [1.177]],

        [[2.297],
         [1.684],
         [1.535],
         [1.584],
         [1.824],
         [1.808],
         [1.386],
         [1.971],
         [1.806],
         [1.785]],

        [[1.031],
         [1.949],
         [1.880],
         [1.533],
         [2.263],
         [1.792],
         [1.958],
         [2.368],
         [1.174],
         [1.975]],

        [[1.309],
         [1.431],
         [1.709],
         [1.745],
         [1.773],
         [1.670],
         [2.047],
         [1.361],
         [1.723],
         [1.972]],

        [[2.195],
         [1.363],
         [2.228],
         [2.110],
         [1.422],
         [1.772],
         [1.511],
         [1.971],
         [2.020],
         [1.988]],

        [[1.468],
         [1.708],
         [1.925],
         [1.716],
         [2.105],
         [1.780],
         [1.699],
         [1.466],
         [1.448],
         [1.492]],

        [[2.009],
         [2.088],
         [1.666],
         [1.696],
         [2.007],
         [1.546],
         [1.201],
         [1.876],
         [1.642],
         [1.952]],

        [[1.610],
         [1.824],
         [2.099],
         [2.023],
         [1.743],
         [1.748],
         [1.663],
         [1.924],
         [1.769],
         [1.375]],

        [[1.700],
         [1.652],
         [1.508],
         [1.735],
         [1.914],
         [1.149],
         [1.561],
         [2.097],
         [2.225],
         [2.070]],

        [[1.571],
         [1.735],
         [1.871],
         [1.934],
         [2.206],
         [1.574],
         [1.822],
         [1.812],
         [1.293],
         [1.447]],

        [[1.526],
         [1.818],
         [1.817],
         [1.443],
         [2.141],
         [1.578],
         [1.238],
         [1.815],
         [2.211],
         [1.369]],

        [[1.996],
         [1.743],
         [1.623],
         [2.232],
         [2.013],
         [1.847],
         [1.240],
         [1.906],
         [1.747],
         [1.784]],

        [[1.814],
         [2.101],
         [2.259],
         [1.599],
         [1.611],
         [1.657],
         [1.658],
         [1.642],
         [1.767],
         [2.020]],

        [[1.753],
         [1.968],
         [2.312],
         [2.224],
         [2.151],
         [1.540],
         [2.040],
         [1.651],
         [1.457],
         [1.685]]], device='cuda:0')
b after update for 1 param tensor([[[119.516],
         [110.362],
         [120.902],
         [106.248],
         [114.042],
         [125.917],
         [127.400],
         [126.584],
         [125.854],
         [111.938]],

        [[108.631],
         [123.245],
         [116.300],
         [131.657],
         [103.310],
         [ 94.564],
         [117.655],
         [105.008],
         [115.976],
         [137.464]],

        [[120.500],
         [112.186],
         [120.164],
         [120.855],
         [ 97.307],
         [108.458],
         [104.273],
         [116.367],
         [118.535],
         [114.695]],

        [[106.852],
         [101.569],
         [128.185],
         [111.857],
         [109.930],
         [129.743],
         [103.834],
         [105.658],
         [121.762],
         [106.575]],

        [[130.023],
         [114.097],
         [109.702],
         [124.674],
         [108.311],
         [125.703],
         [119.962],
         [110.797],
         [125.135],
         [108.104]],

        [[122.809],
         [ 99.374],
         [124.376],
         [117.878],
         [132.080],
         [106.326],
         [110.945],
         [119.242],
         [106.174],
         [112.243]],

        [[ 91.320],
         [111.630],
         [104.387],
         [ 82.185],
         [115.259],
         [113.684],
         [112.880],
         [105.796],
         [108.247],
         [ 94.929]],

        [[132.606],
         [113.538],
         [108.423],
         [110.113],
         [118.178],
         [117.654],
         [103.002],
         [122.834],
         [117.594],
         [116.908]],

        [[ 88.849],
         [122.169],
         [119.983],
         [108.345],
         [131.638],
         [117.133],
         [122.431],
         [134.654],
         [ 94.816],
         [122.953]],

        [[100.110],
         [104.676],
         [114.378],
         [115.570],
         [116.502],
         [113.076],
         [125.185],
         [102.086],
         [114.849],
         [122.870]],

        [[129.640],
         [102.156],
         [130.596],
         [127.090],
         [104.340],
         [116.474],
         [107.558],
         [122.836],
         [124.376],
         [123.375]],

        [[106.004],
         [114.362],
         [121.404],
         [114.637],
         [126.945],
         [116.744],
         [114.057],
         [105.952],
         [105.292],
         [106.889]],

        [[124.032],
         [126.428],
         [112.952],
         [113.951],
         [123.954],
         [108.814],
         [ 95.911],
         [119.852],
         [112.119],
         [122.257]],

        [[111.037],
         [118.172],
         [126.783],
         [124.456],
         [115.511],
         [115.672],
         [112.823],
         [121.356],
         [116.372],
         [102.611]],

        [[114.090],
         [112.448],
         [107.453],
         [115.254],
         [121.059],
         [ 93.778],
         [109.331],
         [126.704],
         [130.518],
         [125.897]],

        [[109.684],
         [115.261],
         [119.674],
         [121.689],
         [129.948],
         [109.770],
         [118.098],
         [117.790],
         [ 99.478],
         [105.255]],

        [[108.090],
         [117.967],
         [117.962],
         [105.127],
         [128.020],
         [109.919],
         [ 97.353],
         [117.885],
         [130.107],
         [102.391]],

        [[123.607],
         [115.532],
         [111.473],
         [130.719],
         [124.157],
         [118.909],
         [ 97.427],
         [120.797],
         [115.644],
         [116.869]],

        [[117.843],
         [126.838],
         [131.506],
         [110.642],
         [111.060],
         [112.642],
         [112.655],
         [112.115],
         [116.299],
         [124.359]],

        [[115.863],
         [122.753],
         [133.045],
         [130.499],
         [128.336],
         [108.587],
         [124.973],
         [112.417],
         [105.614],
         [113.595]]], device='cuda:0')
clipping threshold 1.289726885935637
a after update for 1 param tensor([[ 0.038],
        [-0.206],
        [-0.005],
        [-0.135],
        [ 0.273],
        [-0.336],
        [ 0.128],
        [ 0.023],
        [-0.185],
        [-0.100],
        [ 0.149],
        [ 0.511],
        [ 0.215],
        [-0.111],
        [-0.441],
        [-0.237],
        [-0.224],
        [-0.085],
        [-0.441],
        [ 0.093]], device='cuda:0')
s after update for 1 param tensor([[2.236],
        [1.635],
        [1.353],
        [1.673],
        [1.927],
        [2.017],
        [1.449],
        [1.888],
        [1.736],
        [1.670],
        [1.913],
        [2.436],
        [2.046],
        [1.892],
        [2.259],
        [2.117],
        [2.028],
        [1.412],
        [1.726],
        [1.605]], device='cuda:0')
b after update for 1 param tensor([[130.833],
        [111.876],
        [101.793],
        [113.162],
        [121.477],
        [124.262],
        [105.321],
        [120.245],
        [115.277],
        [113.072],
        [121.033],
        [136.564],
        [125.168],
        [120.348],
        [131.516],
        [127.326],
        [124.601],
        [103.966],
        [114.951],
        [110.865]], device='cuda:0')
clipping threshold 1.289726885935637
||w||^2 1.307387873946539
exp ma of ||w||^2 2.989932749238292
||w|| 1.143410632251834
exp ma of ||w|| 1.645545530533515
||w||^2 2.8917057509568815
exp ma of ||w||^2 2.534068712507886
||w|| 1.700501617452004
exp ma of ||w|| 1.529590234700506
v before min max tensor([[-187.141,  146.547,  217.012,  ..., 1821.111,  549.949, -292.270],
        [-133.976,  861.580, -392.927,  ..., -304.582, -234.597, -358.704],
        [-198.855, -398.495, 1705.207,  ..., -311.920, -146.539, -122.769],
        ...,
        [-342.338, -332.799, -336.374,  ..., -420.452, -242.628, -492.477],
        [ 300.598,  -31.684, -267.445,  ..., -102.890, -172.840,  -81.405],
        [ 846.896, -398.733, -185.920,  ..., -209.737, -445.086,   29.771]],
       device='cuda:0')
v tensor([[1.000e-12, 1.000e+01, 1.000e+01,  ..., 1.000e+01, 1.000e+01,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e+01]], device='cuda:0')
v before min max tensor([ 3.014e+02, -3.237e+02, -4.312e+02, -3.021e+02, -3.861e+02,  3.434e+02,
        -3.163e+02, -2.942e+02,  3.569e+02, -4.442e+02, -2.185e+02, -4.908e+02,
         2.585e+01, -8.248e+01, -3.249e+02, -4.370e+02, -1.657e+02, -2.399e+02,
        -3.370e+02,  3.833e+02,  1.492e+03, -1.487e+02, -3.552e+02, -1.349e+01,
        -9.447e+01, -2.654e+02,  1.850e+02, -3.582e+02,  8.743e+03, -2.962e+02,
        -3.274e+02, -7.157e+01,  1.393e+03, -3.618e+02, -2.337e+02, -4.159e+02,
        -2.795e+02, -2.865e+02, -1.563e+02, -3.772e+02, -4.912e+02, -3.595e+02,
        -3.923e+02, -2.764e+02, -1.750e+02, -4.326e+02, -3.980e+02, -3.626e+02,
         6.695e+01,  1.147e+02, -2.101e+01, -4.223e+02,  2.327e+03, -1.872e+02,
        -3.234e+02, -1.362e+02,  4.318e+01, -3.659e+02, -3.065e+02, -1.416e+02,
        -1.384e+02,  1.226e+02, -3.169e+02,  7.932e+02, -1.549e+02, -4.789e+02,
        -3.514e+02,  6.412e+02,  2.922e+00, -4.011e+02, -3.560e+02, -2.115e+02,
        -3.866e+02,  5.823e+02, -2.681e+02, -2.583e+02,  9.041e+02, -2.752e+02,
         4.110e+02,  2.041e+02,  9.569e+01, -3.660e+02,  4.217e+01, -2.103e+02,
        -2.952e+02, -3.094e+02,  4.331e+02, -3.889e+02, -4.343e+02, -3.925e+02,
        -3.517e+02, -1.245e+02, -3.597e+02,  3.661e+02,  6.942e+02, -2.799e+02,
        -7.418e+01,  9.083e+02, -1.100e+02, -5.922e+01, -4.069e+02, -3.274e+02,
        -2.913e+02,  9.658e+02, -2.499e+02,  1.583e+00, -3.581e+02,  3.414e+00,
        -3.738e+02, -2.019e+02, -3.487e+01, -1.468e+02, -3.359e+02,  1.131e+03,
        -3.800e+02,  4.960e+02, -1.029e+02,  2.445e+02, -4.488e+02, -3.524e+02,
        -3.335e+02,  1.738e+02,  8.239e+02, -2.653e+02,  1.564e+03,  3.684e+02,
        -2.833e+02, -1.067e+02, -3.949e+02,  2.382e+02, -1.657e+02,  1.741e+02,
         5.483e+02, -2.218e+02,  4.738e+01, -2.777e+02, -3.869e+02,  9.851e+01,
         1.577e+02, -3.322e+02, -3.040e+02, -3.612e+02,  3.571e+02, -4.308e+02,
        -4.103e+02,  2.772e+02, -4.325e+02, -4.118e+01, -2.920e+02, -3.201e+02,
        -9.567e+01, -2.530e+02,  1.443e+01,  2.178e+03, -1.693e+02,  8.964e+02,
        -3.261e+02, -3.017e+02, -3.444e+02, -1.553e+02, -3.383e+02, -3.375e+02,
         4.575e+02, -2.420e+02,  9.536e+01, -3.123e+02, -2.965e+02,  1.475e+02,
        -1.250e+02, -3.185e+02, -4.051e+02, -2.465e+02,  1.446e+02, -1.961e+02,
        -2.298e+02,  3.458e+02, -3.102e+02, -2.816e+02, -7.958e+01,  2.024e+02,
         1.730e+02, -1.603e+02, -4.075e+02,  4.019e+00, -4.231e+02,  6.330e+02,
        -2.177e+02,  2.513e+03, -4.012e+02, -3.544e+02, -3.574e+02, -2.587e+02,
         3.764e+02, -3.097e+02, -3.983e+02, -3.415e+02, -4.789e+02, -4.527e+02,
        -4.022e+02, -3.405e+01], device='cuda:0')
v tensor([1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 2.922e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.583e+00, 1.000e-12, 3.414e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 4.019e+00, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12], device='cuda:0')
v before min max tensor([[[-470.555],
         [-270.342],
         [ 377.650],
         [-310.353],
         [-290.840],
         [-414.763],
         [-399.252],
         [-219.905],
         [   5.645],
         [ 165.257]],

        [[ 122.159],
         [1155.159],
         [-154.729],
         [-245.233],
         [ 924.127],
         [1366.490],
         [-421.730],
         [-242.554],
         [-303.235],
         [ 794.482]],

        [[ 266.203],
         [-291.976],
         [-439.195],
         [  90.381],
         [ 168.155],
         [-453.396],
         [  -8.160],
         [ 528.761],
         [-348.631],
         [ 259.832]],

        [[-284.688],
         [  89.839],
         [ 258.298],
         [ 421.807],
         [-428.920],
         [-193.819],
         [-262.639],
         [-303.965],
         [1481.294],
         [-302.059]],

        [[-455.016],
         [-374.968],
         [-282.863],
         [ -50.304],
         [-116.380],
         [ -17.632],
         [-367.793],
         [-310.235],
         [-100.116],
         [-295.900]],

        [[-277.359],
         [ 345.733],
         [-148.836],
         [ 224.274],
         [-459.020],
         [-240.609],
         [-127.162],
         [1204.395],
         [1431.781],
         [-251.777]],

        [[ 475.649],
         [-312.719],
         [ -99.008],
         [ 682.988],
         [-322.605],
         [-342.477],
         [-307.174],
         [ 663.692],
         [  82.102],
         [-227.660]],

        [[ 411.351],
         [ 541.419],
         [1077.061],
         [-400.344],
         [-392.574],
         [ 622.347],
         [ 648.153],
         [ 436.848],
         [ 822.692],
         [-402.461]],

        [[-346.860],
         [ -80.893],
         [ 682.391],
         [-184.522],
         [1769.025],
         [-152.171],
         [-226.349],
         [-306.505],
         [-223.591],
         [-342.472]],

        [[-381.027],
         [-304.239],
         [-199.025],
         [  94.092],
         [-117.815],
         [ -92.539],
         [-120.300],
         [-390.770],
         [ 119.441],
         [-338.639]],

        [[-327.599],
         [ -88.946],
         [ 148.117],
         [-225.958],
         [-261.093],
         [-217.770],
         [-243.201],
         [-441.308],
         [-195.798],
         [-347.923]],

        [[-358.266],
         [-222.381],
         [-127.861],
         [ 595.909],
         [-135.506],
         [ 567.825],
         [-499.086],
         [-332.296],
         [ -37.579],
         [ -99.469]],

        [[  88.995],
         [-211.270],
         [ -81.281],
         [-440.605],
         [ 362.109],
         [-255.131],
         [  91.829],
         [-272.096],
         [-311.391],
         [ 250.328]],

        [[ 245.825],
         [ 986.008],
         [-396.288],
         [ 119.556],
         [1982.381],
         [-434.166],
         [-292.775],
         [1110.224],
         [-254.589],
         [ 935.233]],

        [[-197.274],
         [-282.963],
         [-368.895],
         [-207.141],
         [-274.294],
         [ -71.889],
         [-106.828],
         [  64.857],
         [ 109.280],
         [-226.419]],

        [[-155.321],
         [ 109.358],
         [-106.173],
         [-378.394],
         [-189.537],
         [-226.772],
         [ -38.234],
         [-377.249],
         [-319.903],
         [1499.852]],

        [[-312.631],
         [-358.773],
         [-371.342],
         [-414.650],
         [  73.626],
         [-112.371],
         [-459.371],
         [-307.405],
         [1008.268],
         [ -16.579]],

        [[ 140.401],
         [-409.455],
         [-412.275],
         [-169.571],
         [-386.737],
         [ 782.366],
         [-375.194],
         [-358.523],
         [-202.415],
         [-439.677]],

        [[-424.971],
         [ 402.288],
         [-191.591],
         [-309.548],
         [ 118.417],
         [-178.884],
         [ 353.923],
         [-156.582],
         [  92.342],
         [ 348.900]],

        [[-155.103],
         [-289.027],
         [-306.433],
         [-392.056],
         [1100.887],
         [ 132.101],
         [-330.197],
         [-315.617],
         [-208.846],
         [-339.415]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.645e+00],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[-107.761],
        [ 532.740],
        [1401.926],
        [-305.745],
        [-128.206],
        [-174.638],
        [-127.239],
        [-127.725],
        [-208.349],
        [-242.170],
        [-115.939],
        [ -99.397],
        [1311.206],
        [-108.963],
        [-161.465],
        [-316.692],
        [-318.382],
        [-415.204],
        [-228.453],
        [-470.413]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 0.029, -0.196, -0.508,  ..., -0.440,  0.268, -0.342],
        [-0.248, -0.303, -0.183,  ...,  0.375,  0.184,  0.101],
        [-0.068, -0.247,  0.093,  ..., -0.245,  0.137, -0.363],
        ...,
        [-0.182, -0.279, -0.109,  ...,  0.205,  0.153,  0.087],
        [ 0.063, -0.069,  0.229,  ..., -0.034, -0.039, -0.040],
        [-0.021,  0.094, -0.126,  ...,  0.063, -0.252, -0.137]],
       device='cuda:0')
s after update for 1 param tensor([[1.635, 1.371, 1.558,  ..., 2.342, 1.585, 1.648],
        [1.600, 1.705, 2.112,  ..., 1.980, 1.883, 2.073],
        [1.902, 1.962, 2.017,  ..., 1.364, 1.001, 1.431],
        ...,
        [1.415, 1.696, 1.810,  ..., 1.737, 1.436, 2.063],
        [2.065, 0.764, 1.548,  ..., 1.237, 1.256, 1.596],
        [2.289, 1.843, 1.617,  ..., 0.895, 1.838, 1.807]], device='cuda:0')
b after update for 1 param tensor([[110.443, 101.116, 107.793,  ..., 132.149, 108.732, 110.850],
        [109.246, 112.768, 125.498,  ..., 121.530, 118.503, 124.345],
        [119.095, 120.973, 122.640,  ..., 100.843,  86.425, 103.311],
        ...,
        [102.718, 112.472, 116.180,  ..., 113.824, 103.496, 124.036],
        [124.093,  75.488, 107.464,  ...,  96.036,  96.789, 109.092],
        [130.663, 117.238, 109.811,  ...,  81.707, 117.089, 116.097]],
       device='cuda:0')
clipping threshold 1.2179991983518468
a after update for 1 param tensor([-0.069,  0.026,  0.062, -0.108,  0.129, -0.254,  0.245,  0.161,  0.165,
         0.050, -0.159,  0.150,  0.406, -0.325,  0.235,  0.133,  0.172,  0.255,
        -0.006, -0.125,  0.104,  0.202, -0.293,  0.186,  0.235,  0.561, -0.175,
         0.004,  0.300,  0.119, -0.137, -0.239,  0.060, -0.164, -0.058, -0.364,
        -0.111, -0.134, -0.179, -0.119,  0.147,  0.098, -0.304, -0.037,  0.197,
        -0.315,  0.088,  0.261, -0.244,  0.084,  0.102,  0.193,  0.062, -0.260,
        -0.195,  0.126,  0.372, -0.079, -0.096, -0.360, -0.200,  0.142, -0.358,
        -0.355,  0.383, -0.200,  0.393,  0.086, -0.129,  0.005,  0.229, -0.529,
        -0.097, -0.087,  0.078, -0.044,  0.028,  0.318, -0.193,  0.279,  0.280,
        -0.214,  0.031,  0.358, -0.436, -0.090,  0.014, -0.039,  0.126, -0.149,
        -0.237,  0.160, -0.393,  0.030, -0.069,  0.171, -0.269, -0.200, -0.052,
        -0.377, -0.295,  0.281, -0.185,  0.127, -0.086, -0.044, -0.208,  0.061,
        -0.073,  0.498, -0.393,  0.034, -0.383, -0.231,  0.195, -0.035,  0.455,
        -0.063,  0.130, -0.356,  0.117, -0.010,  0.083,  0.005,  0.035, -0.091,
         0.734,  0.053,  0.040, -0.088, -0.056,  0.099, -0.096,  0.165,  0.039,
        -0.128, -0.086, -0.382,  0.562,  0.246,  0.137, -0.057,  0.256,  0.051,
        -0.029,  0.002, -0.182,  0.082, -0.006,  0.124,  0.144,  0.177, -0.590,
         0.045, -0.219,  0.072,  0.028, -0.285,  0.193,  0.250,  0.253,  0.235,
         0.441, -0.150,  0.034,  0.271,  0.090,  0.232,  0.302,  0.121, -0.479,
         0.347,  0.088, -0.032,  0.266,  0.280, -0.154,  0.407, -0.302, -0.006,
         0.446,  0.335,  0.128,  0.243,  0.137,  0.168, -0.052,  0.015, -0.098,
        -0.270, -0.152,  0.516,  0.340, -0.319, -0.346,  0.005, -0.047,  0.047,
        -0.076,  0.318], device='cuda:0')
s after update for 1 param tensor([1.739, 1.645, 1.786, 1.509, 1.594, 1.634, 1.813, 2.221, 1.680, 1.844,
        1.058, 2.042, 2.154, 1.404, 1.458, 2.082, 1.893, 1.729, 1.961, 1.759,
        1.952, 1.517, 1.558, 2.122, 1.220, 1.771, 1.809, 1.512, 2.152, 1.726,
        1.432, 1.286, 1.986, 1.840, 1.985, 1.777, 1.235, 1.302, 1.820, 1.664,
        2.050, 1.797, 1.652, 1.652, 1.146, 1.819, 1.862, 1.616, 1.476, 1.894,
        1.323, 1.807, 2.069, 1.388, 1.338, 1.592, 1.981, 1.511, 1.269, 1.137,
        1.562, 1.829, 1.309, 1.946, 1.519, 2.162, 1.525, 2.339, 1.091, 2.073,
        1.635, 1.921, 1.611, 1.889, 1.604, 1.094, 1.536, 1.875, 2.251, 2.252,
        1.835, 1.834, 2.023, 1.353, 1.689, 1.618, 2.150, 1.610, 1.890, 1.823,
        1.482, 0.918, 1.739, 1.896, 1.893, 1.396, 1.872, 1.903, 1.567, 1.298,
        2.045, 1.574, 1.750, 1.806, 1.753, 1.427, 1.742, 1.705, 1.546, 2.011,
        1.090, 1.516, 2.006, 2.224, 1.786, 1.756, 1.681, 2.232, 1.917, 1.573,
        1.450, 1.506, 1.716, 1.287, 2.087, 2.011, 1.404, 2.020, 1.645, 1.950,
        1.186, 2.029, 1.564, 1.892, 1.849, 1.543, 1.597, 2.236, 2.015, 1.729,
        1.866, 1.532, 1.614, 2.443, 1.964, 2.157, 1.943, 1.688, 1.366, 1.599,
        1.331, 1.239, 2.032, 2.179, 1.669, 1.902, 1.369, 1.336, 1.926, 1.898,
        1.516, 1.456, 2.074, 1.220, 1.494, 1.641, 1.358, 1.923, 1.836, 1.473,
        1.903, 1.307, 1.399, 1.097, 1.385, 2.010, 1.614, 1.567, 1.475, 1.867,
        2.116, 2.117, 1.709, 2.021, 1.795, 2.089, 1.098, 1.833, 1.668, 1.507,
        1.704, 1.711, 1.515, 1.447, 1.660, 1.410, 1.982, 1.870, 1.756, 1.122],
       device='cuda:0')
b after update for 1 param tensor([113.891, 110.753, 115.417, 106.072, 109.024, 110.382, 116.272, 128.698,
        111.925, 117.288,  88.810, 123.408, 126.735, 102.340, 104.264, 124.608,
        118.814, 113.550, 120.949, 114.530, 120.670, 106.365, 107.811, 125.788,
         95.400, 114.915, 116.148, 106.201, 126.691, 113.442, 103.329,  97.940,
        121.716, 117.157, 121.673, 115.129,  95.967,  98.528, 116.512, 111.407,
        123.643, 115.779, 111.000, 110.995,  92.434, 116.471, 117.840, 109.770,
        104.905, 118.855,  99.322, 116.091, 124.207, 101.745,  99.904, 108.948,
        121.547, 106.146,  97.281,  92.073, 107.937, 116.780,  98.797, 120.476,
        106.454, 126.972, 106.652, 132.073,  90.205, 124.335, 110.425, 119.686,
        109.602, 118.686, 109.365,  90.322, 107.042, 118.243, 129.565, 129.600,
        116.981, 116.944, 122.847, 100.454, 112.246, 109.836, 126.637, 109.582,
        118.728, 116.610, 105.144,  82.766, 113.873, 118.922, 118.821, 102.054,
        118.171, 119.121, 108.091,  98.404, 123.491, 108.336, 114.240, 116.067,
        114.326, 103.151, 113.987, 112.759, 107.391, 122.454,  90.146, 106.328,
        122.300, 128.796, 115.417, 114.430, 111.959, 129.014, 119.572, 108.301,
        103.981, 105.998, 113.118,  97.981, 124.772, 122.471, 102.330, 122.755,
        110.772, 120.585,  94.035, 123.022, 108.007, 118.790, 117.421, 107.282,
        109.147, 129.150, 122.582, 113.570, 117.981, 106.885, 109.705, 134.975,
        121.030, 126.847, 120.391, 112.206, 100.950, 109.217,  99.621,  96.143,
        123.093, 127.471, 111.578, 119.117, 101.047,  99.816, 119.866, 118.978,
        106.345, 104.209, 124.370,  95.402, 105.550, 110.632, 100.643, 119.749,
        117.030, 104.803, 119.138,  98.733, 102.162,  90.457, 101.650, 122.433,
        109.702, 108.089, 104.873, 118.011, 125.628, 125.658, 112.897, 122.763,
        115.698, 124.815,  90.478, 116.910, 111.522, 106.023, 112.717, 112.950,
        106.282, 103.895, 111.264, 102.551, 121.584, 118.083, 114.427,  91.483],
       device='cuda:0')
clipping threshold 1.2179991983518468
a after update for 1 param tensor([[[-2.595e-01],
         [-1.990e-01],
         [ 1.164e-01],
         [ 6.657e-01],
         [-1.048e-01],
         [-1.640e-01],
         [ 1.803e-01],
         [-3.038e-01],
         [ 5.553e-02],
         [-1.883e-01]],

        [[-1.138e-01],
         [-1.466e-01],
         [-3.841e-01],
         [-5.662e-01],
         [ 1.657e-01],
         [-7.653e-02],
         [-7.000e-02],
         [-9.619e-03],
         [-1.542e-02],
         [ 1.994e-01]],

        [[ 2.186e-02],
         [-2.965e-02],
         [ 6.019e-02],
         [-4.755e-01],
         [-2.340e-01],
         [ 3.407e-01],
         [ 1.531e-01],
         [ 1.065e-01],
         [ 7.085e-02],
         [-2.210e-01]],

        [[ 1.312e-02],
         [-2.025e-01],
         [-3.169e-01],
         [-2.065e-01],
         [-2.977e-01],
         [-2.232e-02],
         [-3.249e-01],
         [-3.077e-01],
         [-3.061e-01],
         [-1.744e-01]],

        [[-9.996e-02],
         [ 5.710e-01],
         [-3.008e-01],
         [ 6.831e-04],
         [ 1.173e-01],
         [ 4.265e-01],
         [ 6.331e-02],
         [-1.650e-01],
         [-4.743e-02],
         [ 1.567e-03]],

        [[-3.383e-02],
         [ 2.473e-02],
         [-8.788e-02],
         [-5.880e-03],
         [-6.232e-01],
         [ 2.635e-01],
         [-3.881e-02],
         [ 2.463e-01],
         [ 2.006e-01],
         [-9.157e-02]],

        [[-1.164e-01],
         [ 5.086e-02],
         [ 3.475e-01],
         [ 2.087e-01],
         [ 5.782e-02],
         [ 4.014e-01],
         [ 4.197e-01],
         [ 1.190e-01],
         [ 5.226e-01],
         [-1.154e-01]],

        [[ 3.549e-01],
         [-3.002e-01],
         [ 2.375e-01],
         [ 3.038e-01],
         [ 2.160e-01],
         [ 5.831e-02],
         [ 2.533e-01],
         [ 1.314e-01],
         [-3.805e-02],
         [-2.957e-01]],

        [[-1.612e-01],
         [ 2.820e-01],
         [-1.900e-01],
         [-1.130e-01],
         [ 1.191e-01],
         [ 1.888e-01],
         [ 6.326e-01],
         [ 1.095e-01],
         [ 3.810e-02],
         [-4.284e-01]],

        [[ 7.516e-02],
         [-9.894e-02],
         [ 1.133e-01],
         [ 3.310e-01],
         [ 6.052e-02],
         [ 1.466e-01],
         [ 6.073e-02],
         [ 2.384e-01],
         [-1.582e-01],
         [ 1.088e-01]],

        [[-2.379e-01],
         [ 2.386e-01],
         [ 1.292e-01],
         [-5.040e-01],
         [-1.794e-01],
         [ 1.720e-01],
         [ 2.947e-01],
         [ 3.603e-01],
         [ 3.644e-01],
         [ 1.423e-01]],

        [[-2.046e-01],
         [ 1.793e-01],
         [-1.110e-01],
         [ 3.053e-02],
         [-1.784e-02],
         [ 2.936e-01],
         [-7.135e-01],
         [ 3.640e-01],
         [-2.559e-01],
         [-2.436e-02]],

        [[-5.707e-02],
         [ 5.440e-02],
         [ 1.907e-02],
         [ 2.855e-01],
         [ 1.111e-01],
         [-6.264e-01],
         [-1.078e-01],
         [-2.179e-02],
         [ 5.267e-01],
         [-1.102e-01]],

        [[-2.966e-01],
         [-1.103e-03],
         [-1.200e-02],
         [-4.914e-01],
         [ 2.004e-02],
         [-8.781e-03],
         [-4.614e-02],
         [-2.909e-01],
         [ 7.152e-02],
         [-1.948e-01]],

        [[ 3.379e-01],
         [-7.169e-02],
         [ 2.577e-01],
         [ 7.565e-02],
         [ 4.241e-01],
         [-3.564e-02],
         [-3.662e-01],
         [-9.208e-02],
         [-9.145e-03],
         [ 4.523e-01]],

        [[-1.765e-01],
         [ 1.192e-01],
         [ 6.256e-03],
         [-5.424e-03],
         [-3.450e-01],
         [-5.163e-01],
         [ 1.792e-01],
         [-1.957e-01],
         [-1.426e-01],
         [ 3.003e-01]],

        [[-2.612e-01],
         [ 9.540e-02],
         [-9.025e-02],
         [-8.716e-02],
         [-1.740e-01],
         [-3.719e-02],
         [-2.957e-01],
         [ 1.009e-01],
         [-2.197e-01],
         [-1.746e-01]],

        [[ 2.424e-02],
         [ 5.667e-01],
         [-2.298e-01],
         [ 3.637e-01],
         [ 3.891e-01],
         [ 3.439e-02],
         [ 2.213e-01],
         [ 4.789e-01],
         [-8.656e-02],
         [ 4.079e-01]],

        [[ 4.329e-01],
         [-2.346e-01],
         [-1.525e-01],
         [-3.003e-01],
         [-1.730e-01],
         [ 1.917e-01],
         [ 2.639e-01],
         [-3.209e-01],
         [ 1.026e-01],
         [-1.235e-01]],

        [[-1.908e-01],
         [-1.076e-01],
         [-4.442e-02],
         [ 1.320e-01],
         [ 4.617e-01],
         [ 9.469e-02],
         [-1.125e-02],
         [ 1.249e-01],
         [-1.438e-01],
         [ 2.188e-01]]], device='cuda:0')
s after update for 1 param tensor([[[1.946],
         [1.132],
         [2.015],
         [1.348],
         [1.614],
         [1.717],
         [1.723],
         [1.390],
         [1.518],
         [2.012]],

        [[1.814],
         [2.054],
         [0.642],
         [1.272],
         [1.454],
         [2.313],
         [2.024],
         [1.163],
         [1.695],
         [1.966]],

        [[1.711],
         [1.344],
         [2.119],
         [1.559],
         [1.699],
         [1.876],
         [1.623],
         [1.795],
         [1.669],
         [1.655]],

        [[1.553],
         [2.191],
         [1.758],
         [2.009],
         [1.783],
         [1.751],
         [2.394],
         [1.427],
         [2.180],
         [1.723]],

        [[2.022],
         [1.947],
         [1.653],
         [1.806],
         [1.248],
         [1.651],
         [1.624],
         [1.764],
         [1.464],
         [1.378]],

        [[1.478],
         [1.629],
         [1.962],
         [1.884],
         [1.925],
         [1.621],
         [1.602],
         [2.062],
         [2.075],
         [1.561]],

        [[2.200],
         [1.533],
         [1.166],
         [1.672],
         [1.446],
         [1.861],
         [1.757],
         [1.413],
         [2.031],
         [1.468]],

        [[1.801],
         [1.926],
         [1.925],
         [1.664],
         [1.623],
         [1.668],
         [2.017],
         [2.383],
         [1.849],
         [1.693]],

        [[1.501],
         [1.787],
         [1.917],
         [1.951],
         [1.958],
         [1.541],
         [1.616],
         [1.441],
         [1.500],
         [1.421]],

        [[1.573],
         [1.619],
         [1.262],
         [2.098],
         [1.681],
         [1.139],
         [0.693],
         [1.805],
         [1.464],
         [1.775]],

        [[1.965],
         [1.269],
         [1.981],
         [1.091],
         [1.716],
         [1.487],
         [1.632],
         [1.966],
         [1.381],
         [1.535]],

        [[1.666],
         [0.994],
         [1.417],
         [1.777],
         [0.878],
         [1.966],
         [2.071],
         [1.472],
         [1.439],
         [1.285]],

        [[1.831],
         [1.669],
         [1.209],
         [2.048],
         [2.209],
         [1.065],
         [1.543],
         [1.386],
         [1.291],
         [2.032]],

        [[1.385],
         [1.906],
         [1.883],
         [1.594],
         [1.906],
         [1.873],
         [1.520],
         [1.729],
         [1.952],
         [2.045]],

        [[0.891],
         [1.453],
         [1.555],
         [1.423],
         [1.212],
         [1.257],
         [1.648],
         [1.706],
         [2.033],
         [1.594]],

        [[1.409],
         [2.023],
         [1.360],
         [1.575],
         [1.761],
         [1.320],
         [1.877],
         [1.894],
         [1.541],
         [2.234]],

        [[1.337],
         [1.486],
         [1.736],
         [1.987],
         [2.042],
         [1.479],
         [1.969],
         [1.880],
         [2.022],
         [1.613]],

        [[1.744],
         [1.709],
         [1.778],
         [1.984],
         [1.896],
         [2.257],
         [1.595],
         [1.482],
         [1.011],
         [1.826]],

        [[1.812],
         [1.990],
         [1.898],
         [1.766],
         [1.943],
         [1.785],
         [1.973],
         [1.256],
         [1.650],
         [1.903]],

        [[1.456],
         [1.679],
         [1.357],
         [1.618],
         [1.782],
         [2.111],
         [1.958],
         [1.952],
         [1.013],
         [1.448]]], device='cuda:0')
b after update for 1 param tensor([[[120.475],
         [ 91.872],
         [122.587],
         [100.285],
         [109.724],
         [113.162],
         [113.359],
         [101.813],
         [106.404],
         [122.498]],

        [[116.301],
         [123.757],
         [ 69.176],
         [ 97.416],
         [104.127],
         [131.348],
         [122.859],
         [ 93.151],
         [112.426],
         [121.084]],

        [[112.975],
         [100.114],
         [125.715],
         [107.841],
         [112.551],
         [118.282],
         [110.016],
         [115.701],
         [111.573],
         [111.105]],

        [[107.620],
         [127.838],
         [114.519],
         [122.400],
         [115.318],
         [114.272],
         [133.628],
         [103.150],
         [127.516],
         [113.345]],

        [[122.806],
         [120.494],
         [111.036],
         [116.072],
         [ 96.485],
         [110.959],
         [110.062],
         [114.706],
         [104.476],
         [101.379]],

        [[104.980],
         [110.212],
         [120.967],
         [118.525],
         [119.830],
         [109.960],
         [109.299],
         [124.018],
         [124.399],
         [107.905]],

        [[128.102],
         [106.928],
         [ 93.234],
         [111.681],
         [103.836],
         [117.815],
         [114.472],
         [102.644],
         [123.081],
         [104.637]],

        [[115.911],
         [119.865],
         [119.805],
         [111.393],
         [110.007],
         [111.532],
         [122.648],
         [133.326],
         [117.435],
         [112.384]],

        [[105.811],
         [115.459],
         [119.574],
         [120.635],
         [120.836],
         [107.211],
         [109.792],
         [103.678],
         [105.787],
         [102.944]],

        [[108.311],
         [109.874],
         [ 97.035],
         [125.087],
         [111.955],
         [ 92.153],
         [ 71.910],
         [116.011],
         [104.500],
         [115.073]],

        [[121.055],
         [ 97.273],
         [121.543],
         [ 90.223],
         [113.135],
         [105.314],
         [110.320],
         [121.088],
         [101.497],
         [106.983]],

        [[111.481],
         [ 86.092],
         [102.804],
         [115.106],
         [ 80.937],
         [121.097],
         [124.282],
         [104.781],
         [103.613],
         [ 97.906]],

        [[116.858],
         [111.560],
         [ 94.956],
         [123.602],
         [128.363],
         [ 89.130],
         [107.280],
         [101.659],
         [ 98.128],
         [123.093]],

        [[101.645],
         [119.224],
         [118.496],
         [109.034],
         [119.239],
         [118.185],
         [106.479],
         [113.555],
         [120.670],
         [123.512]],

        [[ 81.513],
         [104.102],
         [107.676],
         [103.033],
         [ 95.085],
         [ 96.822],
         [110.848],
         [112.808],
         [123.146],
         [109.032]],

        [[102.499],
         [122.824],
         [100.696],
         [108.391],
         [114.608],
         [ 99.213],
         [118.331],
         [118.866],
         [107.197],
         [129.087]],

        [[ 99.847],
         [105.284],
         [113.786],
         [121.748],
         [123.406],
         [105.023],
         [121.192],
         [118.401],
         [122.787],
         [109.695]],

        [[114.046],
         [112.891],
         [115.145],
         [121.631],
         [118.919],
         [129.749],
         [109.080],
         [105.142],
         [ 86.816],
         [116.708]],

        [[116.250],
         [121.820],
         [118.990],
         [114.766],
         [120.381],
         [115.393],
         [121.298],
         [ 96.790],
         [110.930],
         [119.141]],

        [[104.216],
         [111.915],
         [100.610],
         [109.868],
         [115.274],
         [125.485],
         [120.833],
         [120.657],
         [ 86.925],
         [103.932]]], device='cuda:0')
clipping threshold 1.2179991983518468
a after update for 1 param tensor([[ 0.192],
        [-0.280],
        [ 0.049],
        [-0.180],
        [ 0.082],
        [-0.245],
        [ 0.230],
        [ 0.044],
        [-0.076],
        [ 0.074],
        [ 0.147],
        [ 0.237],
        [ 0.183],
        [ 0.006],
        [-0.289],
        [-0.157],
        [-0.447],
        [-0.091],
        [-0.481],
        [-0.045]], device='cuda:0')
s after update for 1 param tensor([[1.709],
        [1.891],
        [1.897],
        [1.506],
        [0.953],
        [1.512],
        [1.653],
        [1.225],
        [1.653],
        [1.618],
        [0.881],
        [1.861],
        [2.369],
        [1.523],
        [1.413],
        [1.820],
        [1.410],
        [1.989],
        [2.000],
        [1.998]], device='cuda:0')
b after update for 1 param tensor([[112.885],
        [118.742],
        [118.956],
        [105.975],
        [ 84.328],
        [106.189],
        [111.029],
        [ 95.577],
        [111.033],
        [109.863],
        [ 81.059],
        [117.796],
        [132.919],
        [106.578],
        [102.656],
        [116.521],
        [102.542],
        [121.799],
        [122.118],
        [122.081]], device='cuda:0')
clipping threshold 1.2179991983518468
||w||^2 3.600248528527254
exp ma of ||w||^2 2.5396969071615945
||w|| 1.8974320879881983
exp ma of ||w|| 1.5338164891780488
||w||^2 5.363192242802068
exp ma of ||w||^2 2.4618659724133454
||w|| 2.3158566973804895
exp ma of ||w|| 1.503996817287153
||w||^2 1.4849319019151157
exp ma of ||w||^2 2.4971421024232825
||w|| 1.2185778193923915
exp ma of ||w|| 1.5153188985718806
||w||^2 0.9385587862035668
exp ma of ||w||^2 2.1173258508576844
||w|| 0.9687924371110495
exp ma of ||w|| 1.4042593091695514
||w||^2 4.123477700076362
exp ma of ||w||^2 2.3378706492906973
||w|| 2.030634802241989
exp ma of ||w|| 1.4746229070828165
||w||^2 1.8722293011591742
exp ma of ||w||^2 2.5574190334866294
||w|| 1.3682943035616184
exp ma of ||w|| 1.5393515070116428
||w||^2 1.351246734302494
exp ma of ||w||^2 2.542922734831222
||w|| 1.1624313890731333
exp ma of ||w|| 1.5315057884250636
cuda
Objective function 45.88 = squared loss an data 31.48 + 0.5*rho*h**2 7.430418 + alpha*h 5.170321 + L2reg 1.55 + L1reg 0.25 ; SHD = 94 ; DAG False
Proportion of microbatches that were clipped  0.7744475693049417
iteration 2 in inner loop, alpha 4.241269844477493 rho 10.0 h 1.2190503132020751
4420
cuda
Objective function 112.75 = squared loss an data 31.48 + 0.5*rho*h**2 74.304183 + alpha*h 5.170321 + L2reg 1.55 + L1reg 0.25 ; SHD = 94 ; DAG False
||w||^2 15653613.533786962
exp ma of ||w||^2 7681430613.037899
||w|| 3956.4647772711137
exp ma of ||w|| 28112.720441067235
||w||^2 3.844378985584955
exp ma of ||w||^2 49.28544972538286
||w|| 1.9607087967326904
exp ma of ||w|| 2.1017705356589667
||w||^2 2.133969549778687
exp ma of ||w||^2 3.8176638854286007
||w|| 1.4608112642565045
exp ma of ||w|| 1.8816903003684982
||w||^2 12.202461996788557
exp ma of ||w||^2 3.92857829229304
||w|| 3.4932022553508917
exp ma of ||w|| 1.9001485031017178
||w||^2 4.9369243085666135
exp ma of ||w||^2 3.6780382857225744
||w|| 2.22191905985943
exp ma of ||w|| 1.8416765229307785
||w||^2 2.312645204409941
exp ma of ||w||^2 3.6862180597175813
||w|| 1.520738374741014
exp ma of ||w|| 1.8678012262212946
||w||^2 5.651567792074813
exp ma of ||w||^2 3.87926151023316
||w|| 2.3773026294678625
exp ma of ||w|| 1.9094001185873717
||w||^2 2.021848981014653
exp ma of ||w||^2 3.618841602547996
||w|| 1.4219173608246904
exp ma of ||w|| 1.8377864673881663
cuda
Objective function 49.18 = squared loss an data 34.80 + 0.5*rho*h**2 10.490754 + alpha*h 1.942738 + L2reg 1.72 + L1reg 0.23 ; SHD = 90 ; DAG True
Proportion of microbatches that were clipped  0.7767407888329817
iteration 3 in inner loop, alpha 4.241269844477493 rho 100.0 h 0.45805576360036326
iteration 2 in outer loop, alpha = 50.04684620451382, rho = 100.0, h = 0.45805576360036326
cuda
4420
cuda
Objective function 70.17 = squared loss an data 34.80 + 0.5*rho*h**2 10.490754 + alpha*h 22.924246 + L2reg 1.72 + L1reg 0.23 ; SHD = 90 ; DAG True
||w||^2 2471176994.3408065
exp ma of ||w||^2 69266556566.17305
||w|| 49710.934353930694
exp ma of ||w|| 175861.89657566807
||w||^2 8557.689765523282
exp ma of ||w||^2 691444529.2549837
||w|| 92.50778218897739
exp ma of ||w|| 3191.148420862596
||w||^2 2.433995260993356
exp ma of ||w||^2 1068674.546417548
||w|| 1.5601266810721994
exp ma of ||w|| 8.649415632293302
||w||^2 8.208954707904837
exp ma of ||w||^2 60941.207111179894
||w|| 2.865127345844306
exp ma of ||w|| 2.5947161832573524
||w||^2 0.9889186227064886
exp ma of ||w||^2 4.028938817249838
||w|| 0.9944438760968306
exp ma of ||w|| 1.9260888529003979
||w||^2 7.240047773786028
exp ma of ||w||^2 4.026430216354334
||w|| 2.690733686893972
exp ma of ||w|| 1.9462267587464508
||w||^2 1.5592061049544492
exp ma of ||w||^2 3.819542919394673
||w|| 1.2486817468652487
exp ma of ||w|| 1.8980212930488054
||w||^2 1.6263500039243826
exp ma of ||w||^2 3.5253619722910257
||w|| 1.2752842835714642
exp ma of ||w|| 1.8232157441757806
||w||^2 6.002504239132552
exp ma of ||w||^2 3.757124241596817
||w|| 2.4500008651289393
exp ma of ||w|| 1.880438956290874
||w||^2 0.9163694084736866
exp ma of ||w||^2 3.623290739974448
||w|| 0.9572718571407428
exp ma of ||w|| 1.8467325154382672
||w||^2 6.155276541172323
exp ma of ||w||^2 3.834034271962684
||w|| 2.4809829788155184
exp ma of ||w|| 1.900429531838317
||w||^2 3.341854235205634
exp ma of ||w||^2 3.896260066066144
||w|| 1.828073914043312
exp ma of ||w|| 1.9257726032445557
||w||^2 7.409866132942702
exp ma of ||w||^2 3.8444123956504024
||w|| 2.7221069290060416
exp ma of ||w|| 1.9049787701290637
||w||^2 3.475070149887357
exp ma of ||w||^2 3.7994927781251038
||w|| 1.8641540038010156
exp ma of ||w|| 1.8773311862651016
||w||^2 3.6542163271894186
exp ma of ||w||^2 3.5554793114169376
||w|| 1.9116004622277687
exp ma of ||w|| 1.8150288361146387
cuda
Objective function 54.77 = squared loss an data 33.80 + 0.5*rho*h**2 4.261063 + alpha*h 14.610016 + L2reg 1.88 + L1reg 0.22 ; SHD = 87 ; DAG True
Proportion of microbatches that were clipped  0.7752872633112154
iteration 1 in inner loop, alpha 50.04684620451382 rho 100.0 h 0.29192681289937283
4420
cuda
Objective function 93.11 = squared loss an data 33.80 + 0.5*rho*h**2 42.610632 + alpha*h 14.610016 + L2reg 1.88 + L1reg 0.22 ; SHD = 87 ; DAG True
||w||^2 13.27932575858455
exp ma of ||w||^2 1420485.9737726399
||w|| 3.644080920970959
exp ma of ||w|| 8.861448991705247
||w||^2 5.403452838877854
exp ma of ||w||^2 13009.849107992035
||w|| 2.32453282163919
exp ma of ||w|| 2.4541601171286116
||w||^2 2.002657805560969
exp ma of ||w||^2 4.630306163140201
||w|| 1.4151529265634046
exp ma of ||w|| 2.089123877912422
||w||^2 2.5114285451628784
exp ma of ||w||^2 5.000135485929596
||w|| 1.5847487325007956
exp ma of ||w|| 2.1671888047576324
||w||^2 4.09410332657636
exp ma of ||w||^2 4.676428478697039
||w|| 2.0233890695010586
exp ma of ||w|| 2.1190061321847122
||w||^2 3.1308615468794336
exp ma of ||w||^2 4.6034053696136406
||w|| 1.7694240720865742
exp ma of ||w|| 2.0898843757130474
cuda
Objective function 53.75 = squared loss an data 35.01 + 0.5*rho*h**2 9.548047 + alpha*h 6.915904 + L2reg 2.05 + L1reg 0.22 ; SHD = 88 ; DAG True
Proportion of microbatches that were clipped  0.7808796627694266
iteration 2 in inner loop, alpha 50.04684620451382 rho 1000.0 h 0.1381886160588337
4420
cuda
Objective function 139.68 = squared loss an data 35.01 + 0.5*rho*h**2 95.480468 + alpha*h 6.915904 + L2reg 2.05 + L1reg 0.22 ; SHD = 88 ; DAG True
||w||^2 3455816818124.623
exp ma of ||w||^2 3592356259673.7324
||w|| 1858982.7374466453
exp ma of ||w|| 1191472.1099931186
||w||^2 3026370758.070801
exp ma of ||w||^2 358302902322.72034
||w|| 55012.460025623295
exp ma of ||w|| 290047.42805310246
||w||^2 2051.5616862097086
exp ma of ||w||^2 1258692565.0704267
||w|| 45.29416834659522
exp ma of ||w|| 1653.3982290108245
||w||^2 6.767193539310473
exp ma of ||w||^2 355915.80847663694
||w|| 2.6013830051167925
exp ma of ||w|| 3.699823704603272
||w||^2 4.5498905879693625
exp ma of ||w||^2 5.854806938411673
||w|| 2.1330472540404166
exp ma of ||w|| 2.3191989919473484
||w||^2 2.837520123380142
exp ma of ||w||^2 5.5898057674222414
||w|| 1.6844940259259285
exp ma of ||w|| 2.2925968185641237
||w||^2 5.46998100357302
exp ma of ||w||^2 5.60216365066712
||w|| 2.338799051558945
exp ma of ||w|| 2.3026768665256956
||w||^2 6.164990055732449
exp ma of ||w||^2 5.132025433091784
||w|| 2.4829398010689765
exp ma of ||w|| 2.2185783071195524
||w||^2 3.9711749521871784
exp ma of ||w||^2 5.101927813606753
||w|| 1.9927807085043698
exp ma of ||w|| 2.2114317201852467
||w||^2 5.554692129785854
exp ma of ||w||^2 5.411829260406262
||w|| 2.356839436573025
exp ma of ||w|| 2.2677851487037044
||w||^2 4.217669136293633
exp ma of ||w||^2 5.399576404312905
||w|| 2.0536964567076685
exp ma of ||w|| 2.264530658510827
||w||^2 6.428823976557904
exp ma of ||w||^2 5.1855422230919785
||w|| 2.5355125668309957
exp ma of ||w|| 2.2276313753902
cuda
Objective function 49.84 = squared loss an data 34.23 + 0.5*rho*h**2 10.871561 + alpha*h 2.333660 + L2reg 2.19 + L1reg 0.22 ; SHD = 87 ; DAG True
Proportion of microbatches that were clipped  0.7810032697982295
iteration 3 in inner loop, alpha 50.04684620451382 rho 10000.0 h 0.046629520716880535
iteration 3 in outer loop, alpha = 516.3420533733191, rho = 10000.0, h = 0.046629520716880535
cuda
4420
cuda
Objective function 71.58 = squared loss an data 34.23 + 0.5*rho*h**2 10.871561 + alpha*h 24.076782 + L2reg 2.19 + L1reg 0.22 ; SHD = 87 ; DAG True
||w||^2 10.298725870848639
exp ma of ||w||^2 168589.96745686143
||w|| 3.209162799056576
exp ma of ||w|| 3.8646120989148502
||w||^2 13.96992738392891
exp ma of ||w||^2 1061.642765972485
||w|| 3.7376366040492632
exp ma of ||w|| 2.8436692778683375
||w||^2 6.139875095739933
exp ma of ||w||^2 9.479759552855207
||w|| 2.477877134916082
exp ma of ||w|| 2.5129165105805154
||w||^2 7.036505494297436
exp ma of ||w||^2 5.199912372715393
||w|| 2.652641229849494
exp ma of ||w|| 2.240170309887167
||w||^2 3.6889654779205494
exp ma of ||w||^2 5.003204831785273
||w|| 1.9206679770123074
exp ma of ||w|| 2.1986371199309316
||w||^2 4.685025063749518
exp ma of ||w||^2 5.830473884117138
||w|| 2.1644918719527495
exp ma of ||w|| 2.3752084856705618
||w||^2 2.932644498077146
exp ma of ||w||^2 5.4837281405679255
||w|| 1.712496568778211
exp ma of ||w|| 2.2917261605714505
||w||^2 4.263372038080438
exp ma of ||w||^2 5.488923317786343
||w|| 2.0647934613613144
exp ma of ||w|| 2.296131747785702
||w||^2 4.220992510393166
exp ma of ||w||^2 5.65485114283465
||w|| 2.054505417465032
exp ma of ||w|| 2.331277815886099
||w||^2 5.844274962934315
exp ma of ||w||^2 5.229935047066254
||w|| 2.4174935290366992
exp ma of ||w|| 2.2494220451792843
||w||^2 4.819902872505326
exp ma of ||w||^2 5.526387682788641
||w|| 2.1954277197178063
exp ma of ||w|| 2.314693300063656
||w||^2 3.253616527181568
exp ma of ||w||^2 5.5812389501758215
||w|| 1.8037784030145076
exp ma of ||w|| 2.3218050953403697
cuda
Objective function 56.37 = squared loss an data 33.39 + 0.5*rho*h**2 4.673714 + alpha*h 15.786417 + L2reg 2.31 + L1reg 0.21 ; SHD = 86 ; DAG True
Proportion of microbatches that were clipped  0.7805732484076433
iteration 1 in inner loop, alpha 516.3420533733191 rho 10000.0 h 0.030573564799521336
4420
cuda
Objective function 98.43 = squared loss an data 33.39 + 0.5*rho*h**2 46.737143 + alpha*h 15.786417 + L2reg 2.31 + L1reg 0.21 ; SHD = 86 ; DAG True
||w||^2 274.2848931907014
exp ma of ||w||^2 3530694376.600139
||w|| 16.561548635037166
exp ma of ||w|| 534.932298157794
||w||^2 23.391898439874254
exp ma of ||w||^2 8629.976188209279
||w|| 4.8365171807690555
exp ma of ||w|| 5.033443224287886
||w||^2 13.743843029272634
exp ma of ||w||^2 113.02633848991665
||w|| 3.707268944826182
exp ma of ||w|| 3.8155794740061197
||w||^2 3.669211455656854
exp ma of ||w||^2 6.417571871725378
||w|| 1.915518586612214
exp ma of ||w|| 2.4769477217671625
||w||^2 12.889886027128416
exp ma of ||w||^2 5.813746430274816
||w|| 3.590248741679108
exp ma of ||w|| 2.369378298956122
||w||^2 5.663630543019115
exp ma of ||w||^2 5.781356687985909
||w|| 2.3798383438837005
exp ma of ||w|| 2.3550087577179872
||w||^2 4.1570916581786115
exp ma of ||w||^2 6.286148056394681
||w|| 2.0388947148341456
exp ma of ||w|| 2.471888607523662
||w||^2 10.484005803101704
exp ma of ||w||^2 6.446270267353468
||w|| 3.2379014504925414
exp ma of ||w|| 2.498306783108587
||w||^2 7.036229068336779
exp ma of ||w||^2 7.149667154058871
||w|| 2.6525891254276037
exp ma of ||w|| 2.638176715882342
||w||^2 4.4830281408294015
exp ma of ||w||^2 6.839758914570395
||w|| 2.1173162590480907
exp ma of ||w|| 2.5830230355246804
||w||^2 8.429305981097427
exp ma of ||w||^2 7.303123783913581
||w|| 2.9033267093280126
exp ma of ||w|| 2.67106634758053
cuda
Objective function 54.17 = squared loss an data 32.49 + 0.5*rho*h**2 11.271745 + alpha*h 7.752613 + L2reg 2.44 + L1reg 0.21 ; SHD = 81 ; DAG True
Proportion of microbatches that were clipped  0.7844682048396173
iteration 2 in inner loop, alpha 516.3420533733191 rho 100000.0 h 0.015014489932205777
iteration 4 in outer loop, alpha = 15530.831985579096, rho = 1000000.0, h = 0.015014489932205777
Threshold 0.3
[[0.008 0.128 0.01  0.145 0.056 0.122 0.071 0.01  0.201 0.039 0.16  0.046
  0.039 0.073 0.435 0.08  0.027 0.015 0.38  0.021]
 [0.068 0.006 0.016 0.117 0.032 0.33  0.159 0.008 0.818 0.215 0.055 0.035
  0.062 0.059 0.537 0.123 0.012 0.005 0.184 0.012]
 [0.829 0.404 0.012 0.512 0.259 0.673 0.822 0.104 1.201 1.001 0.186 0.229
  0.484 0.585 0.643 0.374 0.208 0.081 2.885 0.573]
 [0.034 0.071 0.014 0.01  0.01  0.134 0.114 0.015 0.131 0.509 0.063 0.043
  0.034 0.078 0.265 0.083 0.056 0.012 0.124 0.008]
 [0.172 0.132 0.044 0.744 0.008 0.322 0.175 0.014 0.937 0.325 0.622 0.24
  0.093 0.124 0.303 0.135 0.103 0.044 0.323 0.164]
 [0.08  0.037 0.014 0.039 0.025 0.009 0.106 0.016 0.169 0.161 0.039 0.017
  0.028 0.058 0.055 0.033 0.023 0.007 0.375 0.023]
 [0.095 0.059 0.012 0.078 0.04  0.052 0.008 0.002 0.193 0.081 0.061 0.049
  0.011 0.043 0.057 0.04  0.036 0.012 0.161 0.02 ]
 [0.668 0.738 0.055 0.539 0.44  0.57  3.14  0.009 0.826 0.655 0.781 0.167
  0.164 0.536 1.294 0.974 0.396 0.185 0.709 0.183]
 [0.036 0.007 0.006 0.053 0.006 0.05  0.05  0.005 0.005 0.14  0.025 0.012
  0.012 0.02  0.109 0.036 0.011 0.006 0.154 0.007]
 [0.076 0.026 0.009 0.014 0.018 0.052 0.083 0.011 0.059 0.009 0.034 0.011
  0.006 0.076 0.132 0.057 0.03  0.007 0.181 0.008]
 [0.05  0.108 0.032 0.149 0.011 0.196 0.123 0.016 0.289 0.167 0.007 0.035
  0.013 0.083 0.1   0.025 0.059 0.012 0.089 0.023]
 [0.187 0.243 0.04  0.218 0.032 0.524 0.19  0.029 0.635 0.665 0.215 0.006
  0.159 0.338 0.328 0.183 0.218 0.037 0.559 0.09 ]
 [0.218 0.076 0.018 0.188 0.087 0.248 0.529 0.037 0.476 1.029 0.508 0.053
  0.008 0.328 0.385 0.249 0.138 0.024 0.356 0.182]
 [0.174 0.127 0.01  0.102 0.041 0.124 0.192 0.014 0.294 0.101 0.12  0.035
  0.031 0.007 0.09  0.156 0.067 0.014 0.645 0.021]
 [0.024 0.018 0.012 0.029 0.015 0.13  0.109 0.006 0.084 0.064 0.066 0.03
  0.022 0.061 0.011 0.059 0.013 0.007 0.109 0.018]
 [0.1   0.062 0.02  0.098 0.068 0.263 0.269 0.01  0.236 0.156 0.306 0.036
  0.025 0.074 0.172 0.017 0.091 0.021 0.268 0.021]
 [0.304 0.757 0.039 0.134 0.066 0.293 0.241 0.018 0.31  0.263 0.145 0.066
  0.065 0.114 0.722 0.079 0.012 0.004 0.441 0.058]
 [0.394 1.173 0.104 0.391 0.26  0.846 0.443 0.046 1.037 0.595 0.577 0.231
  0.275 0.628 0.754 0.441 1.807 0.008 0.733 0.226]
 [0.025 0.035 0.002 0.05  0.015 0.022 0.056 0.008 0.052 0.037 0.086 0.013
  0.02  0.014 0.072 0.022 0.016 0.009 0.008 0.026]
 [0.282 0.603 0.011 1.054 0.038 0.486 0.43  0.05  0.527 0.695 0.407 0.103
  0.063 0.422 0.411 0.365 0.1   0.042 0.252 0.005]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.435 0.    0.    0.    0.38  0.   ]
 [0.    0.    0.    0.    0.    0.33  0.    0.    0.818 0.    0.    0.
  0.    0.    0.537 0.    0.    0.    0.    0.   ]
 [0.829 0.404 0.    0.512 0.    0.673 0.822 0.    1.201 1.001 0.    0.
  0.484 0.585 0.643 0.374 0.    0.    2.885 0.573]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.509 0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.744 0.    0.322 0.    0.    0.937 0.325 0.622 0.
  0.    0.    0.303 0.    0.    0.    0.323 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.375 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.668 0.738 0.    0.539 0.44  0.57  3.14  0.    0.826 0.655 0.781 0.
  0.    0.536 1.294 0.974 0.396 0.    0.709 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.524 0.    0.    0.635 0.665 0.    0.
  0.    0.338 0.328 0.    0.    0.    0.559 0.   ]
 [0.    0.    0.    0.    0.    0.    0.529 0.    0.476 1.029 0.508 0.
  0.    0.328 0.385 0.    0.    0.    0.356 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.645 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.306 0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.304 0.757 0.    0.    0.    0.    0.    0.    0.31  0.    0.    0.
  0.    0.    0.722 0.    0.    0.    0.441 0.   ]
 [0.394 1.173 0.    0.391 0.    0.846 0.443 0.    1.037 0.595 0.577 0.
  0.    0.628 0.754 0.441 1.807 0.    0.733 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.603 0.    1.054 0.    0.486 0.43  0.    0.527 0.695 0.407 0.
  0.    0.422 0.411 0.365 0.    0.    0.    0.   ]]
{'fdr': 0.7619047619047619, 'tpr': 0.5, 'fpr': 0.4266666666666667, 'f1': 0.32258064516129037, 'shd': 81, 'npred': 84, 'ntrue': 40}
[1.279e-01 9.709e-03 1.446e-01 5.606e-02 1.215e-01 7.079e-02 9.854e-03
 2.010e-01 3.852e-02 1.605e-01 4.617e-02 3.910e-02 7.327e-02 4.355e-01
 8.024e-02 2.698e-02 1.500e-02 3.804e-01 2.067e-02 6.787e-02 1.553e-02
 1.168e-01 3.215e-02 3.302e-01 1.590e-01 8.434e-03 8.178e-01 2.154e-01
 5.538e-02 3.523e-02 6.232e-02 5.913e-02 5.372e-01 1.230e-01 1.160e-02
 5.210e-03 1.843e-01 1.169e-02 8.288e-01 4.044e-01 5.120e-01 2.591e-01
 6.732e-01 8.225e-01 1.038e-01 1.201e+00 1.001e+00 1.859e-01 2.293e-01
 4.836e-01 5.847e-01 6.427e-01 3.737e-01 2.080e-01 8.095e-02 2.885e+00
 5.725e-01 3.391e-02 7.095e-02 1.375e-02 9.870e-03 1.338e-01 1.143e-01
 1.538e-02 1.313e-01 5.089e-01 6.327e-02 4.349e-02 3.399e-02 7.802e-02
 2.652e-01 8.262e-02 5.552e-02 1.195e-02 1.243e-01 7.802e-03 1.719e-01
 1.317e-01 4.449e-02 7.439e-01 3.219e-01 1.750e-01 1.430e-02 9.375e-01
 3.246e-01 6.222e-01 2.398e-01 9.311e-02 1.241e-01 3.035e-01 1.350e-01
 1.035e-01 4.431e-02 3.226e-01 1.638e-01 7.995e-02 3.703e-02 1.360e-02
 3.851e-02 2.542e-02 1.058e-01 1.572e-02 1.694e-01 1.611e-01 3.922e-02
 1.737e-02 2.828e-02 5.817e-02 5.454e-02 3.322e-02 2.336e-02 6.773e-03
 3.753e-01 2.262e-02 9.457e-02 5.854e-02 1.242e-02 7.768e-02 3.972e-02
 5.210e-02 2.034e-03 1.934e-01 8.069e-02 6.128e-02 4.860e-02 1.111e-02
 4.344e-02 5.741e-02 3.987e-02 3.623e-02 1.151e-02 1.606e-01 1.969e-02
 6.681e-01 7.384e-01 5.549e-02 5.386e-01 4.395e-01 5.701e-01 3.140e+00
 8.257e-01 6.546e-01 7.812e-01 1.665e-01 1.639e-01 5.355e-01 1.294e+00
 9.738e-01 3.961e-01 1.851e-01 7.091e-01 1.827e-01 3.579e-02 7.137e-03
 6.460e-03 5.302e-02 6.164e-03 5.008e-02 5.014e-02 5.005e-03 1.398e-01
 2.492e-02 1.248e-02 1.236e-02 1.957e-02 1.092e-01 3.593e-02 1.131e-02
 6.078e-03 1.544e-01 6.578e-03 7.620e-02 2.609e-02 8.950e-03 1.379e-02
 1.762e-02 5.213e-02 8.292e-02 1.094e-02 5.939e-02 3.405e-02 1.096e-02
 6.382e-03 7.640e-02 1.318e-01 5.742e-02 2.991e-02 6.502e-03 1.808e-01
 8.330e-03 4.968e-02 1.085e-01 3.188e-02 1.487e-01 1.123e-02 1.958e-01
 1.228e-01 1.605e-02 2.887e-01 1.670e-01 3.489e-02 1.346e-02 8.288e-02
 1.000e-01 2.486e-02 5.892e-02 1.184e-02 8.898e-02 2.345e-02 1.870e-01
 2.431e-01 4.006e-02 2.184e-01 3.162e-02 5.244e-01 1.899e-01 2.908e-02
 6.352e-01 6.651e-01 2.147e-01 1.590e-01 3.383e-01 3.279e-01 1.828e-01
 2.180e-01 3.661e-02 5.592e-01 8.959e-02 2.183e-01 7.561e-02 1.774e-02
 1.883e-01 8.702e-02 2.477e-01 5.287e-01 3.750e-02 4.762e-01 1.029e+00
 5.084e-01 5.253e-02 3.279e-01 3.847e-01 2.492e-01 1.380e-01 2.428e-02
 3.555e-01 1.820e-01 1.739e-01 1.269e-01 1.038e-02 1.019e-01 4.065e-02
 1.236e-01 1.923e-01 1.437e-02 2.935e-01 1.008e-01 1.197e-01 3.452e-02
 3.132e-02 8.997e-02 1.558e-01 6.739e-02 1.435e-02 6.452e-01 2.050e-02
 2.386e-02 1.809e-02 1.230e-02 2.925e-02 1.469e-02 1.297e-01 1.094e-01
 6.208e-03 8.356e-02 6.416e-02 6.550e-02 3.038e-02 2.219e-02 6.142e-02
 5.935e-02 1.274e-02 6.509e-03 1.091e-01 1.821e-02 1.004e-01 6.229e-02
 2.046e-02 9.813e-02 6.769e-02 2.631e-01 2.690e-01 9.553e-03 2.364e-01
 1.560e-01 3.057e-01 3.564e-02 2.528e-02 7.374e-02 1.718e-01 9.090e-02
 2.118e-02 2.681e-01 2.078e-02 3.037e-01 7.574e-01 3.850e-02 1.342e-01
 6.578e-02 2.933e-01 2.414e-01 1.826e-02 3.101e-01 2.626e-01 1.449e-01
 6.633e-02 6.542e-02 1.143e-01 7.223e-01 7.876e-02 3.928e-03 4.415e-01
 5.750e-02 3.943e-01 1.173e+00 1.042e-01 3.907e-01 2.599e-01 8.461e-01
 4.427e-01 4.625e-02 1.037e+00 5.947e-01 5.765e-01 2.315e-01 2.750e-01
 6.285e-01 7.540e-01 4.414e-01 1.807e+00 7.329e-01 2.256e-01 2.473e-02
 3.527e-02 2.389e-03 4.962e-02 1.523e-02 2.197e-02 5.642e-02 7.705e-03
 5.201e-02 3.689e-02 8.587e-02 1.297e-02 2.040e-02 1.396e-02 7.157e-02
 2.217e-02 1.619e-02 9.203e-03 2.584e-02 2.822e-01 6.030e-01 1.128e-02
 1.054e+00 3.837e-02 4.860e-01 4.304e-01 4.982e-02 5.274e-01 6.946e-01
 4.071e-01 1.026e-01 6.302e-02 4.223e-01 4.108e-01 3.653e-01 1.005e-01
 4.229e-02 2.524e-01]
[[0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.7146323529411766, 0.3858912147294449)
Iterations 2250
Achieves (3.524517146579602, 1e-05)-DP
