samples  5000  graph  30 60 ER mim  minibatch size  50  noise  0.6  minibatches per NN training  250 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 2.144444827137683
iteration 1 in outer loop, alpha = 2.144444827137683, rho = 1.0, h = 2.144444827137683
cuda
iteration 1 in inner loop,alpha 2.144444827137683 rho 1.0 h 1.3256466874605835
iteration 2 in inner loop,alpha 2.144444827137683 rho 10.0 h 0.5131010328032026
iteration 2 in outer loop, alpha = 7.275455155169709, rho = 10.0, h = 0.5131010328032026
cuda
iteration 1 in inner loop,alpha 7.275455155169709 rho 10.0 h 0.28442514981965417
iteration 2 in inner loop,alpha 7.275455155169709 rho 100.0 h 0.09687583592673477
iteration 3 in outer loop, alpha = 16.963038747843186, rho = 100.0, h = 0.09687583592673477
cuda
iteration 1 in inner loop,alpha 16.963038747843186 rho 100.0 h 0.05565872169768937
iteration 2 in inner loop,alpha 16.963038747843186 rho 1000.0 h 0.017246591836673986
iteration 4 in outer loop, alpha = 34.20963058451717, rho = 1000.0, h = 0.017246591836673986
cuda
iteration 1 in inner loop,alpha 34.20963058451717 rho 1000.0 h 0.007536379858688491
iteration 2 in inner loop,alpha 34.20963058451717 rho 10000.0 h 0.0024562545468960195
iteration 5 in outer loop, alpha = 58.77217605347737, rho = 10000.0, h = 0.0024562545468960195
cuda
iteration 1 in inner loop,alpha 58.77217605347737 rho 10000.0 h 0.0010792499674714406
iteration 2 in inner loop,alpha 58.77217605347737 rho 100000.0 h 0.00042229828057926966
iteration 6 in outer loop, alpha = 101.00200411140433, rho = 100000.0, h = 0.00042229828057926966
cuda
iteration 1 in inner loop,alpha 101.00200411140433 rho 100000.0 h 0.00022015692463384084
iteration 7 in outer loop, alpha = 321.1589287452452, rho = 1000000.0, h = 0.00022015692463384084
Threshold 0.3
[[0.    0.    0.101 0.045 0.058 0.001 0.112 0.022 0.059 0.349 0.004 0.06
  0.001 0.006 0.002 0.028 0.009 0.049 0.055 0.88  0.041 0.001 0.149 0.019
  0.006 0.035 0.02  0.017 0.024 0.022]
 [0.    0.    0.016 0.004 0.011 0.684 1.881 0.087 0.113 0.002 0.007 0.034
  0.006 0.005 0.005 0.062 0.002 0.074 0.027 0.052 0.005 0.007 0.102 0.055
  0.002 0.014 0.002 0.081 0.085 0.032]
 [0.    0.    0.004 0.008 0.11  0.    0.068 0.05  0.001 0.    0.    0.
  0.    0.    0.    0.004 0.    0.014 0.058 0.124 0.001 0.    0.009 0.021
  0.    0.    0.019 0.013 0.022 0.008]
 [0.    0.    0.006 0.002 0.02  0.002 0.019 0.    0.    0.    0.    0.001
  0.    0.    0.    0.001 0.    0.    0.001 0.051 0.    0.    0.001 0.001
  0.    0.    0.    0.    0.059 0.   ]
 [0.    0.    0.002 0.006 0.003 0.004 0.011 0.012 0.001 0.    0.    0.
  0.    0.    0.    0.001 0.    0.001 0.001 0.159 0.    0.    0.006 0.001
  0.    0.    0.001 0.009 0.012 0.001]
 [0.    0.    0.05  0.042 0.014 0.003 0.049 0.046 0.083 0.    0.    0.065
  0.    0.    0.    0.002 0.    0.006 0.004 0.834 0.001 0.    0.032 0.009
  0.    0.001 0.011 0.004 0.003 0.001]
 [0.    0.    0.011 0.029 0.027 0.    0.003 0.021 0.005 0.    0.    0.001
  0.    0.    0.    0.017 0.    0.011 0.007 0.095 0.    0.    0.09  0.045
  0.    0.001 0.004 0.01  0.021 0.002]
 [0.    0.    0.009 1.484 0.009 0.013 0.027 0.003 0.    0.    0.    0.001
  0.    0.    0.    0.002 0.    0.    0.001 0.008 0.001 0.    0.005 0.
  0.    0.    0.001 0.    0.041 0.002]
 [0.    0.    0.052 0.008 0.042 0.005 0.043 0.059 0.003 0.001 0.    0.061
  0.    0.    0.    0.102 0.    0.045 0.757 1.093 0.    0.001 1.828 0.076
  0.    0.003 0.053 0.001 0.057 0.009]
 [0.    0.001 0.127 0.141 0.031 1.138 0.055 0.644 0.091 0.    0.001 2.485
  0.001 0.004 0.    0.27  0.007 0.183 0.025 0.097 0.009 0.    0.064 0.003
  0.    0.012 0.615 0.021 0.015 0.026]
 [0.001 0.001 0.027 0.188 0.033 0.015 0.09  0.079 0.9   0.014 0.    0.038
  0.005 0.001 0.017 0.028 0.004 0.055 0.064 0.103 0.052 0.009 0.031 0.068
  0.008 0.038 0.095 4.129 0.041 0.013]
 [0.    0.001 4.293 0.009 0.03  0.01  0.019 0.056 0.012 0.    0.    0.002
  0.    0.    0.    0.135 0.    0.09  0.033 0.151 0.002 0.    0.009 0.068
  0.    0.    0.441 0.024 0.028 0.012]
 [0.003 0.001 0.003 0.053 0.047 0.009 1.88  0.013 1.184 0.021 0.    0.05
  0.    0.001 0.009 0.125 0.001 0.098 0.002 0.001 0.025 0.023 0.071 0.385
  0.001 0.038 0.475 0.038 0.021 3.059]
 [0.001 0.    0.082 0.001 1.232 0.043 0.022 0.129 0.063 0.001 0.006 0.069
  0.006 0.    0.001 0.117 0.006 0.927 0.034 1.343 0.02  0.007 0.045 0.038
  0.007 0.005 0.142 0.068 0.008 0.004]
 [0.003 0.001 0.032 0.058 0.061 0.059 0.04  0.103 0.05  0.011 0.001 1.755
  0.    0.001 0.    0.012 0.001 0.188 0.023 0.007 0.015 0.008 0.119 0.763
  0.001 3.17  0.004 0.013 0.122 0.057]
 [0.    0.    0.049 0.008 0.072 0.029 0.019 0.059 0.011 0.    0.    0.004
  0.    0.    0.    0.004 0.    0.095 0.01  0.027 0.003 0.001 0.463 0.012
  0.    0.005 0.812 0.005 0.008 0.073]
 [0.    0.004 2.543 0.094 0.088 0.018 0.034 0.012 0.46  0.    0.001 0.003
  0.002 0.    0.004 0.013 0.    0.121 0.001 0.034 2.861 0.404 0.129 0.014
  0.004 0.004 0.049 0.051 0.073 0.042]
 [0.    0.    0.014 0.06  1.538 0.085 0.013 1.122 0.001 0.    0.    0.
  0.    0.    0.    0.003 0.    0.003 0.002 0.092 0.002 0.    0.013 0.001
  0.    0.001 0.003 0.011 0.206 0.001]
 [0.    0.    0.007 0.026 0.023 0.008 0.005 0.036 0.001 0.    0.    0.
  0.    0.    0.    0.001 0.    0.141 0.002 0.011 0.    0.    0.018 0.001
  0.    0.    0.01  0.006 0.035 0.001]
 [0.    0.    0.004 0.003 0.001 0.001 0.007 0.    0.001 0.    0.    0.
  0.    0.    0.    0.02  0.    0.001 0.01  0.003 0.    0.    0.072 0.009
  0.    0.    0.006 0.003 0.009 0.001]
 [0.    0.    0.036 0.007 0.006 0.843 0.014 0.032 1.731 0.001 0.    0.063
  0.001 0.001 0.001 0.019 0.    0.075 0.024 0.082 0.002 0.001 0.002 0.032
  0.    0.019 0.009 0.012 2.129 0.037]
 [0.    0.001 0.044 1.344 1.128 0.022 0.052 0.12  0.24  0.006 0.001 0.038
  0.001 0.    0.003 0.062 0.    0.7   0.07  0.07  0.331 0.001 0.105 0.204
  0.    0.03  0.249 0.051 1.581 2.038]
 [0.    0.    0.001 0.12  0.059 0.002 0.002 0.106 0.    0.    0.    0.002
  0.    0.    0.    0.004 0.    0.008 0.027 0.    0.    0.    0.003 0.
  0.    0.    0.178 0.    0.005 0.   ]
 [0.    0.    0.004 0.62  0.005 0.022 0.011 0.085 0.009 0.    0.    0.004
  0.    0.    0.    0.025 0.    0.128 1.185 0.024 0.004 0.    2.459 0.003
  0.    0.    0.394 0.004 0.179 0.   ]
 [0.001 0.003 0.059 0.078 0.02  0.1   1.496 0.026 0.01  0.035 0.    0.018
  0.007 0.    0.004 0.089 0.001 0.057 0.06  0.059 0.032 0.068 1.773 0.038
  0.    0.035 0.084 0.061 0.009 0.053]
 [0.001 0.    0.047 0.062 0.179 0.043 0.007 2.528 0.039 0.001 0.    0.303
  0.    0.004 0.    0.164 0.    1.17  0.072 0.036 0.003 0.    0.171 1.574
  0.001 0.002 0.223 0.03  2.219 0.069]
 [0.    0.    0.039 0.013 0.183 0.017 0.031 0.066 0.002 0.    0.    0.002
  0.    0.    0.    0.002 0.    0.64  0.056 0.029 0.001 0.001 0.01  0.002
  0.    0.    0.004 0.009 0.041 0.002]
 [0.001 0.    0.036 0.089 0.    0.034 0.029 1.365 0.167 0.001 0.    0.007
  0.001 0.    0.    0.02  0.    0.034 0.039 0.054 0.044 0.005 0.012 0.02
  0.    0.014 0.001 0.003 0.024 0.014]
 [0.    0.    0.036 0.003 0.053 0.112 0.016 0.006 0.013 0.    0.    0.002
  0.    0.    0.    0.019 0.    0.002 0.008 0.059 0.    0.    0.049 0.001
  0.    0.    0.    0.    0.002 0.002]
 [0.001 0.    0.029 0.079 0.062 0.62  0.201 0.046 0.037 0.001 0.    0.017
  0.    0.001 0.    0.001 0.    0.191 1.031 0.039 0.007 0.    0.045 0.401
  0.    0.    0.043 0.016 0.069 0.002]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.349 0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.88  0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.684 1.881 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.834 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    1.484 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.757 1.093 0.    0.    1.828 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    1.138 0.    0.644 0.    0.    0.    2.485
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.615 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.9   0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    4.129 0.    0.   ]
 [0.    0.    4.293 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.441 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    1.88  0.    1.184 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.385
  0.    0.    0.475 0.    0.    3.059]
 [0.    0.    0.    0.    1.232 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.927 0.    1.343 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.755
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.763
  0.    3.17  0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.463 0.
  0.    0.    0.812 0.    0.    0.   ]
 [0.    0.    2.543 0.    0.    0.    0.    0.    0.46  0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    2.861 0.404 0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    1.538 0.    0.    1.122 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.843 0.    0.    1.731 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    2.129 0.   ]
 [0.    0.    0.    1.344 1.128 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.7   0.    0.    0.331 0.    0.    0.
  0.    0.    0.    0.    1.581 2.038]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.62  0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    1.185 0.    0.    0.    2.459 0.
  0.    0.    0.394 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    1.496 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.773 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    2.528 0.    0.    0.    0.303
  0.    0.    0.    0.    0.    1.17  0.    0.    0.    0.    0.    1.574
  0.    0.    0.    0.    2.219 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.64  0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    1.365 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.62  0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    1.031 0.    0.    0.    0.    0.401
  0.    0.    0.    0.    0.    0.   ]]
{'fdr': 0.11475409836065574, 'tpr': 0.9, 'fpr': 0.018666666666666668, 'f1': 0.8925619834710743, 'shd': 9, 'npred': 61, 'ntrue': 60}
[3.593e-04 1.005e-01 4.531e-02 5.814e-02 1.055e-03 1.120e-01 2.185e-02
 5.903e-02 3.487e-01 4.094e-03 6.045e-02 5.049e-04 6.173e-03 1.870e-03
 2.841e-02 8.746e-03 4.948e-02 5.539e-02 8.796e-01 4.091e-02 8.347e-04
 1.489e-01 1.946e-02 6.335e-03 3.510e-02 1.972e-02 1.699e-02 2.386e-02
 2.201e-02 4.465e-04 1.602e-02 3.810e-03 1.122e-02 6.837e-01 1.881e+00
 8.654e-02 1.126e-01 1.614e-03 7.468e-03 3.365e-02 6.251e-03 4.707e-03
 4.804e-03 6.157e-02 1.747e-03 7.374e-02 2.685e-02 5.171e-02 4.834e-03
 6.567e-03 1.020e-01 5.526e-02 2.017e-03 1.426e-02 2.029e-03 8.118e-02
 8.506e-02 3.178e-02 2.438e-05 1.293e-04 8.322e-03 1.095e-01 2.110e-04
 6.844e-02 4.962e-02 1.022e-03 3.060e-05 4.902e-05 5.911e-05 3.807e-05
 1.629e-04 3.205e-06 4.337e-03 1.453e-05 1.446e-02 5.835e-02 1.241e-01
 7.137e-04 2.336e-04 8.912e-03 2.057e-02 5.716e-05 3.900e-05 1.881e-02
 1.338e-02 2.224e-02 7.721e-03 2.045e-04 1.705e-04 6.036e-03 2.043e-02
 2.343e-03 1.907e-02 4.490e-04 3.092e-04 7.936e-05 7.314e-06 7.065e-04
 4.969e-05 9.461e-05 1.016e-06 1.348e-03 7.371e-05 6.831e-05 8.709e-04
 5.117e-02 2.499e-04 1.092e-04 1.079e-03 1.064e-03 1.224e-04 1.923e-05
 7.883e-05 5.839e-05 5.914e-02 4.290e-04 1.267e-04 9.767e-05 2.464e-03
 5.744e-03 3.590e-03 1.143e-02 1.202e-02 1.230e-03 2.609e-05 6.321e-05
 2.717e-04 6.010e-05 1.742e-05 3.491e-05 5.142e-04 3.725e-05 6.618e-04
 9.015e-04 1.589e-01 2.201e-04 8.727e-05 5.928e-03 1.088e-03 1.351e-04
 1.558e-04 1.018e-03 9.265e-03 1.182e-02 1.135e-03 5.993e-06 1.051e-05
 4.978e-02 4.209e-02 1.439e-02 4.899e-02 4.564e-02 8.293e-02 1.333e-04
 5.175e-05 6.451e-02 1.277e-05 3.434e-04 1.071e-04 1.774e-03 2.074e-05
 6.255e-03 3.519e-03 8.338e-01 6.193e-04 1.351e-04 3.244e-02 8.581e-03
 1.553e-04 5.636e-04 1.130e-02 3.546e-03 3.186e-03 1.166e-03 1.166e-04
 2.163e-05 1.057e-02 2.923e-02 2.710e-02 4.667e-04 2.067e-02 4.926e-03
 1.356e-04 1.119e-04 5.362e-04 1.930e-05 3.896e-04 1.126e-04 1.669e-02
 1.338e-04 1.062e-02 7.002e-03 9.463e-02 1.867e-04 8.266e-05 9.002e-02
 4.512e-02 1.619e-05 5.746e-04 4.029e-03 9.514e-03 2.083e-02 2.117e-03
 1.166e-04 1.569e-04 9.276e-03 1.484e+00 8.681e-03 1.311e-02 2.682e-02
 4.757e-04 9.958e-05 3.888e-06 1.175e-03 9.750e-05 5.805e-06 1.357e-06
 2.223e-03 4.253e-05 3.484e-04 7.838e-04 8.413e-03 6.559e-04 2.036e-04
 4.786e-03 4.812e-04 1.615e-04 9.821e-05 7.777e-04 3.214e-04 4.142e-02
 1.829e-03 3.059e-04 1.425e-04 5.152e-02 7.983e-03 4.239e-02 5.470e-03
 4.319e-02 5.851e-02 8.495e-04 6.527e-06 6.052e-02 5.011e-06 9.368e-05
 7.425e-05 1.015e-01 1.853e-06 4.538e-02 7.565e-01 1.093e+00 2.559e-04
 5.679e-04 1.828e+00 7.600e-02 1.541e-04 2.714e-03 5.265e-02 1.415e-03
 5.693e-02 8.676e-03 5.470e-05 1.246e-03 1.268e-01 1.407e-01 3.127e-02
 1.138e+00 5.508e-02 6.442e-01 9.140e-02 1.206e-03 2.485e+00 7.042e-04
 4.274e-03 1.350e-04 2.697e-01 6.737e-03 1.831e-01 2.455e-02 9.656e-02
 8.637e-03 2.877e-04 6.353e-02 2.891e-03 4.063e-04 1.195e-02 6.154e-01
 2.065e-02 1.466e-02 2.553e-02 5.473e-04 7.677e-04 2.680e-02 1.875e-01
 3.268e-02 1.518e-02 9.031e-02 7.904e-02 9.005e-01 1.392e-02 3.793e-02
 4.757e-03 5.130e-04 1.722e-02 2.831e-02 4.086e-03 5.456e-02 6.429e-02
 1.026e-01 5.150e-02 8.927e-03 3.109e-02 6.849e-02 8.168e-03 3.814e-02
 9.502e-02 4.129e+00 4.088e-02 1.257e-02 2.280e-04 5.691e-04 4.293e+00
 8.965e-03 3.013e-02 1.033e-02 1.937e-02 5.596e-02 1.223e-02 5.619e-05
 5.944e-05 1.055e-04 2.156e-04 2.860e-05 1.346e-01 1.608e-04 9.021e-02
 3.291e-02 1.508e-01 1.742e-03 4.096e-04 8.883e-03 6.806e-02 1.659e-04
 2.382e-04 4.411e-01 2.362e-02 2.795e-02 1.228e-02 3.333e-03 6.577e-04
 2.854e-03 5.316e-02 4.728e-02 9.106e-03 1.880e+00 1.269e-02 1.184e+00
 2.078e-02 1.510e-04 5.033e-02 7.744e-04 8.572e-03 1.246e-01 9.021e-04
 9.776e-02 2.399e-03 7.788e-04 2.472e-02 2.253e-02 7.127e-02 3.849e-01
 9.105e-04 3.762e-02 4.746e-01 3.756e-02 2.099e-02 3.059e+00 5.306e-04
 3.115e-04 8.230e-02 7.308e-04 1.232e+00 4.344e-02 2.153e-02 1.288e-01
 6.329e-02 1.225e-03 6.338e-03 6.910e-02 6.046e-03 1.050e-03 1.173e-01
 6.149e-03 9.274e-01 3.394e-02 1.343e+00 2.009e-02 6.518e-03 4.491e-02
 3.831e-02 6.817e-03 4.623e-03 1.419e-01 6.799e-02 8.063e-03 4.376e-03
 3.494e-03 8.201e-04 3.189e-02 5.751e-02 6.060e-02 5.912e-02 3.968e-02
 1.029e-01 5.043e-02 1.129e-02 6.576e-04 1.755e+00 3.987e-04 5.054e-04
 1.219e-02 1.150e-03 1.885e-01 2.280e-02 6.785e-03 1.546e-02 8.129e-03
 1.188e-01 7.628e-01 1.246e-03 3.170e+00 3.542e-03 1.331e-02 1.221e-01
 5.697e-02 2.947e-04 4.124e-04 4.870e-02 7.554e-03 7.182e-02 2.944e-02
 1.873e-02 5.946e-02 1.107e-02 4.545e-04 8.966e-05 4.048e-03 9.324e-05
 1.427e-04 5.405e-05 2.019e-04 9.534e-02 9.693e-03 2.726e-02 2.747e-03
 1.274e-03 4.625e-01 1.229e-02 1.411e-04 5.345e-03 8.117e-01 4.547e-03
 8.009e-03 7.337e-02 3.823e-04 3.962e-03 2.543e+00 9.365e-02 8.843e-02
 1.826e-02 3.380e-02 1.228e-02 4.595e-01 3.443e-04 7.914e-04 2.637e-03
 2.182e-03 3.695e-04 3.665e-03 1.270e-02 1.210e-01 1.170e-03 3.443e-02
 2.861e+00 4.038e-01 1.293e-01 1.379e-02 3.640e-03 3.534e-03 4.864e-02
 5.068e-02 7.262e-02 4.209e-02 8.612e-05 1.693e-04 1.389e-02 5.969e-02
 1.538e+00 8.505e-02 1.312e-02 1.122e+00 1.166e-03 5.769e-06 4.424e-05
 2.802e-04 5.498e-05 1.146e-05 1.870e-05 2.805e-03 8.278e-05 2.342e-03
 9.172e-02 1.952e-03 3.686e-04 1.336e-02 6.944e-04 1.339e-04 5.625e-04
 2.972e-03 1.066e-02 2.059e-01 1.334e-03 8.052e-05 2.144e-04 6.706e-03
 2.618e-02 2.258e-02 8.002e-03 5.037e-03 3.586e-02 9.890e-04 1.259e-04
 1.504e-05 1.860e-04 2.858e-05 2.191e-04 2.452e-05 8.579e-04 2.721e-05
 1.408e-01 1.126e-02 1.877e-04 6.044e-05 1.807e-02 6.644e-04 9.615e-05
 1.694e-04 1.048e-02 5.959e-03 3.505e-02 5.484e-04 1.302e-05 2.191e-05
 4.228e-03 3.447e-03 7.283e-04 9.342e-04 6.559e-03 4.887e-04 6.846e-04
 4.327e-05 8.098e-06 4.828e-04 8.504e-06 1.855e-05 1.078e-04 2.040e-02
 2.521e-05 9.854e-04 1.044e-02 1.459e-04 1.345e-04 7.217e-02 9.213e-03
 1.488e-04 4.194e-04 5.577e-03 2.726e-03 8.513e-03 9.381e-04 4.100e-04
 4.502e-04 3.636e-02 6.743e-03 6.245e-03 8.428e-01 1.402e-02 3.179e-02
 1.731e+00 8.323e-04 1.650e-04 6.329e-02 9.370e-04 5.595e-04 5.423e-04
 1.855e-02 9.046e-06 7.534e-02 2.448e-02 8.215e-02 1.476e-03 1.902e-03
 3.194e-02 4.449e-04 1.943e-02 8.569e-03 1.152e-02 2.129e+00 3.668e-02
 4.143e-04 9.847e-04 4.406e-02 1.344e+00 1.128e+00 2.225e-02 5.200e-02
 1.203e-01 2.400e-01 5.707e-03 7.807e-04 3.790e-02 8.639e-04 3.063e-04
 3.430e-03 6.199e-02 6.204e-05 6.995e-01 6.969e-02 6.964e-02 3.309e-01
 1.051e-01 2.044e-01 2.925e-04 3.032e-02 2.491e-01 5.100e-02 1.581e+00
 2.038e+00 8.896e-05 1.131e-04 1.251e-03 1.197e-01 5.913e-02 1.797e-03
 1.717e-03 1.057e-01 1.984e-04 2.281e-04 1.148e-05 1.826e-03 3.584e-05
 2.069e-04 2.073e-06 4.303e-03 1.777e-06 8.363e-03 2.695e-02 4.300e-04
 6.088e-05 3.871e-05 2.178e-04 1.827e-05 4.283e-05 1.784e-01 3.763e-04
 5.111e-03 5.517e-05 1.663e-04 1.151e-04 3.981e-03 6.198e-01 4.718e-03
 2.243e-02 1.131e-02 8.458e-02 8.962e-03 2.460e-04 1.361e-04 3.781e-03
 1.222e-05 8.876e-05 5.862e-06 2.479e-02 7.829e-05 1.278e-01 1.185e+00
 2.431e-02 3.972e-03 1.335e-04 2.459e+00 6.174e-05 3.232e-04 3.941e-01
 3.906e-03 1.789e-01 3.985e-04 1.220e-03 3.280e-03 5.851e-02 7.792e-02
 1.971e-02 9.977e-02 1.496e+00 2.553e-02 9.732e-03 3.450e-02 4.604e-04
 1.779e-02 7.288e-03 3.519e-04 3.956e-03 8.908e-02 7.130e-04 5.706e-02
 5.977e-02 5.862e-02 3.215e-02 6.835e-02 1.773e+00 3.846e-02 3.547e-02
 8.419e-02 6.115e-02 9.095e-03 5.323e-02 5.211e-04 4.945e-04 4.743e-02
 6.207e-02 1.794e-01 4.313e-02 7.087e-03 2.528e+00 3.912e-02 1.014e-03
 2.624e-04 3.031e-01 2.788e-04 4.291e-03 9.827e-06 1.639e-01 4.862e-04
 1.170e+00 7.180e-02 3.587e-02 3.259e-03 3.267e-04 1.712e-01 1.574e+00
 8.177e-04 2.225e-01 2.953e-02 2.219e+00 6.941e-02 7.932e-05 2.044e-04
 3.881e-02 1.301e-02 1.833e-01 1.659e-02 3.088e-02 6.628e-02 1.556e-03
 1.833e-04 1.218e-04 2.018e-03 1.497e-05 1.510e-04 6.925e-06 2.027e-03
 7.356e-05 6.396e-01 5.583e-02 2.878e-02 5.263e-04 8.016e-04 1.018e-02
 2.479e-03 6.928e-05 3.116e-04 8.864e-03 4.085e-02 1.704e-03 6.260e-04
 2.006e-04 3.584e-02 8.854e-02 2.006e-04 3.444e-02 2.930e-02 1.365e+00
 1.667e-01 6.308e-04 5.142e-07 6.633e-03 9.505e-04 3.405e-04 1.619e-04
 1.982e-02 1.613e-04 3.402e-02 3.948e-02 5.424e-02 4.393e-02 4.562e-03
 1.181e-02 1.958e-02 3.455e-04 1.402e-02 6.718e-04 2.354e-02 1.376e-02
 1.237e-04 1.193e-04 3.626e-02 2.625e-03 5.265e-02 1.115e-01 1.622e-02
 5.904e-03 1.286e-02 1.140e-04 7.553e-05 1.832e-03 1.987e-04 2.169e-04
 1.987e-06 1.854e-02 1.656e-06 2.006e-03 8.259e-03 5.873e-02 1.649e-04
 9.438e-05 4.931e-02 1.240e-03 1.385e-04 1.457e-04 2.030e-04 1.596e-04
 1.716e-03 5.998e-04 4.137e-04 2.913e-02 7.940e-02 6.205e-02 6.198e-01
 2.012e-01 4.618e-02 3.654e-02 1.238e-03 2.735e-04 1.741e-02 4.483e-06
 6.446e-04 1.564e-04 1.078e-03 1.234e-04 1.909e-01 1.031e+00 3.851e-02
 7.117e-03 9.017e-05 4.536e-02 4.007e-01 9.472e-05 3.818e-04 4.322e-02
 1.595e-02 6.879e-02]
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 1. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]]
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.9562962962962962, 0.9229807680614648)
cuda
9630
cuda
Objective function 291.21 = squared loss an data 35.20 + 0.5*rho*h**2 254.631624 + alpha*h 0.000000 + L2reg 0.55 + L1reg 0.82 ; SHD = 416 ; DAG False
||w||^2 5937624.999394784
exp ma of ||w||^2 32126865129.234226
||w|| 2436.724235401861
exp ma of ||w|| 48855.72134357291
||w||^2 0.02878687386072702
exp ma of ||w||^2 0.03841512698259331
||w|| 0.16966694981854014
exp ma of ||w|| 0.19198145279370604
||w||^2 0.027594613135284534
exp ma of ||w||^2 0.04906660175373764
||w|| 0.166116263909602
exp ma of ||w|| 0.21838985285247384
||w||^2 0.048468921654582386
exp ma of ||w||^2 0.04882658424329826
||w|| 0.2201565843997912
exp ma of ||w|| 0.2167143329619955
||w||^2 0.045933132333867685
exp ma of ||w||^2 0.049608182209933946
||w|| 0.21432016315285804
exp ma of ||w|| 0.21951195304702284
||w||^2 0.029194664760098417
exp ma of ||w||^2 0.04807600896859644
||w|| 0.17086446312823042
exp ma of ||w|| 0.2151789037883318
||w||^2 0.07572554360332123
exp ma of ||w||^2 0.04880624130860962
||w|| 0.27518274583142244
exp ma of ||w|| 0.217235524372063
||w||^2 0.03948230392981945
exp ma of ||w||^2 0.05148192280698719
||w|| 0.19870154486017327
exp ma of ||w|| 0.22364242931974485
||w||^2 0.045208495226093263
exp ma of ||w||^2 0.05195851542108617
||w|| 0.21262289440719517
exp ma of ||w|| 0.22397377151720588
||w||^2 0.02230360247551616
exp ma of ||w||^2 0.05181552852197222
||w|| 0.14934390672376346
exp ma of ||w|| 0.22352946522176315
||w||^2 0.049385063302842556
exp ma of ||w||^2 0.05167752431966228
||w|| 0.2222275034797506
exp ma of ||w|| 0.22314671288092092
||w||^2 0.08750008187301982
exp ma of ||w||^2 0.04885451449143392
||w|| 0.29580412754561053
exp ma of ||w|| 0.217820763737788
cuda
Objective function 27.62 = squared loss an data 25.56 + 0.5*rho*h**2 1.282229 + alpha*h 0.000000 + L2reg 0.35 + L1reg 0.44 ; SHD = 65 ; DAG False
Proportion of microbatches that were clipped  0.7563378007427741
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 1.6013923243897032
iteration 1 in outer loop, alpha = 1.6013923243897032, rho = 1.0, h = 1.6013923243897032
cuda
9630
cuda
Objective function 30.19 = squared loss an data 25.56 + 0.5*rho*h**2 1.282229 + alpha*h 2.564457 + L2reg 0.35 + L1reg 0.44 ; SHD = 65 ; DAG False
||w||^2 274013.7207941485
exp ma of ||w||^2 32800572.924473047
||w|| 523.4631990829427
exp ma of ||w|| 2402.04584371566
||w||^2 0.07419944979713868
exp ma of ||w||^2 60976.64319748696
||w|| 0.2723957595065288
exp ma of ||w|| 6.851375305534088
||w||^2 0.04536892033807581
exp ma of ||w||^2 20595.164958491016
||w|| 0.21299981300009588
exp ma of ||w|| 2.4624326337673654
||w||^2 0.047642178439412625
exp ma of ||w||^2 0.0462066670478182
||w|| 0.21827088316908563
exp ma of ||w|| 0.21189655504005542
||w||^2 0.036477101435646864
exp ma of ||w||^2 0.04515576320768621
||w|| 0.19098979406148084
exp ma of ||w|| 0.20882354787462212
||w||^2 0.058638309269170616
exp ma of ||w||^2 0.047241873721859964
||w|| 0.24215348287639932
exp ma of ||w|| 0.21349622700329726
||w||^2 0.026264416269651956
exp ma of ||w||^2 0.04403550523636191
||w|| 0.16206300092757742
exp ma of ||w|| 0.20552962184988996
||w||^2 0.04732669579314339
exp ma of ||w||^2 0.056731310984946784
||w|| 0.2175469967458604
exp ma of ||w|| 0.23379318897820223
cuda
Objective function 27.74 = squared loss an data 24.56 + 0.5*rho*h**2 0.585230 + alpha*h 1.732510 + L2reg 0.45 + L1reg 0.41 ; SHD = 60 ; DAG False
Proportion of microbatches that were clipped  0.7542545395326113
iteration 1 in inner loop, alpha 1.6013923243897032 rho 1.0 h 1.0818775841592156
9630
cuda
Objective function 33.01 = squared loss an data 24.56 + 0.5*rho*h**2 5.852296 + alpha*h 1.732510 + L2reg 0.45 + L1reg 0.41 ; SHD = 60 ; DAG False
||w||^2 27712.069090387497
exp ma of ||w||^2 27416141.456298735
||w|| 166.4694238903574
exp ma of ||w|| 1721.01837906132
||w||^2 0.03222283110136958
exp ma of ||w||^2 0.04485431275304701
||w|| 0.1795071895534259
exp ma of ||w|| 0.20608200873363144
||w||^2 0.05441500148543409
exp ma of ||w||^2 0.05890211491976093
||w|| 0.23327023274613093
exp ma of ||w|| 0.2376607660851116
||w||^2 0.06290317417177958
exp ma of ||w||^2 0.057617851968740544
||w|| 0.25080505212570897
exp ma of ||w|| 0.2348673217692067
||w||^2 0.04094490724896164
exp ma of ||w||^2 0.05887247827091627
||w|| 0.20234847972980088
exp ma of ||w|| 0.23782213631842
||w||^2 0.11218665626268425
exp ma of ||w||^2 0.053415549720831144
||w|| 0.33494276565210995
exp ma of ||w|| 0.22609868944738334
||w||^2 0.04474155863122606
exp ma of ||w||^2 0.05430860283025913
||w|| 0.21152200507565652
exp ma of ||w|| 0.22821249395850216
||w||^2 0.04862839032147769
exp ma of ||w||^2 0.058245215083260866
||w|| 0.22051845800630315
exp ma of ||w|| 0.2364022997118725
||w||^2 0.04893916820684372
exp ma of ||w||^2 0.05622253654227321
||w|| 0.22122198852474798
exp ma of ||w|| 0.2316214166608305
||w||^2 0.026301225572322194
exp ma of ||w||^2 0.05846876485784042
||w|| 0.16217652595959192
exp ma of ||w|| 0.2362159791122466
||w||^2 0.06511511396232325
exp ma of ||w||^2 0.06528432145176935
||w|| 0.25517663286892717
exp ma of ||w|| 0.25028781761971175
||w||^2 0.04119935242501748
exp ma of ||w||^2 0.06587357019404408
||w|| 0.2029762361091009
exp ma of ||w|| 0.2500855020541947
||w||^2 0.07631993092824364
exp ma of ||w||^2 0.06274639399607435
||w|| 0.2762606213853933
exp ma of ||w|| 0.244659327829598
cuda
Objective function 28.12 = squared loss an data 25.42 + 0.5*rho*h**2 1.070630 + alpha*h 0.741024 + L2reg 0.52 + L1reg 0.36 ; SHD = 61 ; DAG True
Proportion of microbatches that were clipped  0.7584820710725197
iteration 2 in inner loop, alpha 1.6013923243897032 rho 10.0 h 0.46273755033594455
9630
cuda
Objective function 37.75 = squared loss an data 25.42 + 0.5*rho*h**2 10.706302 + alpha*h 0.741024 + L2reg 0.52 + L1reg 0.36 ; SHD = 61 ; DAG True
||w||^2 20209381597.709663
exp ma of ||w||^2 5844400775.370318
||w|| 142159.70454988172
exp ma of ||w|| 40519.70282004241
||w||^2 3.096785985277956
exp ma of ||w||^2 735187.209745327
||w|| 1.7597687306228498
exp ma of ||w|| 37.19818380783016
||w||^2 1.3721167972180761
exp ma of ||w||^2 720557.0094908149
||w|| 1.1713738930068724
exp ma of ||w|| 36.480322929568786
||w||^2 0.0955325766830287
exp ma of ||w||^2 2807.4522895229147
||w|| 0.30908344614849353
exp ma of ||w|| 0.4642360528968631
||w||^2 0.06944805951183865
exp ma of ||w||^2 140.53272763585662
||w|| 0.26352999736621757
exp ma of ||w|| 0.25445811272823726
||w||^2 0.030774804959691843
exp ma of ||w||^2 0.1134229423940082
||w|| 0.17542749202930494
exp ma of ||w|| 0.21523997852070847
||w||^2 0.0855203113749933
exp ma of ||w||^2 0.05836063776614016
||w|| 0.2924385600002047
exp ma of ||w|| 0.23452101897592556
||w||^2 0.14524788995125543
exp ma of ||w||^2 0.06488374188192536
||w|| 0.3811140117487881
exp ma of ||w|| 0.2488640714743548
||w||^2 0.08710308668666458
exp ma of ||w||^2 0.06608217398281586
||w|| 0.29513232064052997
exp ma of ||w|| 0.2513914792355366
||w||^2 0.04900392022209733
exp ma of ||w||^2 0.06389509020524174
||w|| 0.22136829091380122
exp ma of ||w|| 0.2467821902528972
||w||^2 0.04403677158674327
exp ma of ||w||^2 0.06813505019834312
||w|| 0.20984940215960413
exp ma of ||w|| 0.25398900961653176
||w||^2 0.032823550440709455
exp ma of ||w||^2 0.06198147903664202
||w|| 0.181172708873907
exp ma of ||w|| 0.24318118051518317
||w||^2 0.03747868400601386
exp ma of ||w||^2 0.06351507248759024
||w|| 0.1935941218271202
exp ma of ||w|| 0.24642212004138472
||w||^2 0.05635716875497437
exp ma of ||w||^2 0.06189815877890735
||w|| 0.23739664857569992
exp ma of ||w|| 0.24289221973774883
||w||^2 0.09189357381900305
exp ma of ||w||^2 0.06389495267862783
||w|| 0.3031395286316238
exp ma of ||w|| 0.24653605789877145
||w||^2 0.03441587656722091
exp ma of ||w||^2 0.06445024414924719
||w|| 0.18551516532947085
exp ma of ||w|| 0.24775523519280543
||w||^2 0.056207549687659744
exp ma of ||w||^2 0.06745347648080438
||w|| 0.23708131450550832
exp ma of ||w|| 0.25297963012328273
cuda
Objective function 28.58 = squared loss an data 26.30 + 0.5*rho*h**2 1.139324 + alpha*h 0.241733 + L2reg 0.58 + L1reg 0.32 ; SHD = 50 ; DAG True
Proportion of microbatches that were clipped  0.7567633438947112
iteration 3 in inner loop, alpha 1.6013923243897032 rho 100.0 h 0.15095193929904482
iteration 2 in outer loop, alpha = 16.696586254294186, rho = 100.0, h = 0.15095193929904482
cuda
9630
cuda
Objective function 30.86 = squared loss an data 26.30 + 0.5*rho*h**2 1.139324 + alpha*h 2.520382 + L2reg 0.58 + L1reg 0.32 ; SHD = 50 ; DAG True
||w||^2 1550940801.394027
exp ma of ||w||^2 3265027713.731558
||w|| 39381.9857472173
exp ma of ||w|| 48793.054676992484
||w||^2 9897759.987028051
exp ma of ||w||^2 228447360.60020086
||w|| 3146.070562944838
exp ma of ||w|| 8392.5323365576
||w||^2 79673.13157764381
exp ma of ||w||^2 45847275.27354263
||w|| 282.2642938411513
exp ma of ||w|| 2201.8024049236124
||w||^2 0.20086613888363886
exp ma of ||w||^2 83281.69724799768
||w|| 0.4481809220433628
exp ma of ||w|| 5.572211074924763
||w||^2 0.0218104810589307
exp ma of ||w||^2 9.024584309467159
||w|| 0.1476837196813877
exp ma of ||w|| 0.2237999026242953
v before min max tensor([[-4.636,  3.748,  7.792,  ..., -0.107, -2.759, -4.513],
        [ 0.159, -3.390,  1.223,  ..., -0.068, -6.357, -5.186],
        [22.520, -4.823, -5.282,  ..., -4.292, -4.011,  1.627],
        ...,
        [-4.593,  0.428, -7.199,  ..., -2.631, -4.482, -1.517],
        [-2.794, -4.952, -4.207,  ..., -2.703, -4.478, -4.266],
        [ 0.843, -6.201, -4.795,  ...,  2.609, 15.605,  7.255]],
       device='cuda:0')
v tensor([[1.000e-12, 3.748e+00, 7.792e+00,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.592e-01, 1.000e-12, 1.223e+00,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.627e+00],
        ...,
        [1.000e-12, 4.276e-01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [8.433e-01, 1.000e-12, 1.000e-12,  ..., 2.609e+00, 1.000e+01,
         7.255e+00]], device='cuda:0')
v before min max tensor([ 2.384e+00, -6.417e+00, -2.332e+00, -3.953e+00, -5.421e-01,  1.429e+00,
        -5.515e+00, -3.755e+00,  4.942e+00, -7.210e+00, -5.319e+00, -4.599e+00,
        -4.529e+00,  3.778e+00,  6.084e+00, -5.512e+00,  2.446e+00, -3.794e+00,
        -4.459e+00, -5.902e+00,  1.690e+00, -3.917e+00,  8.815e+00,  3.481e+00,
        -5.249e+00, -2.787e+00,  1.004e+01, -2.744e+00,  8.528e+00,  4.173e+00,
        -1.622e+00,  2.316e+01,  3.544e+00, -7.357e-01, -4.724e+00, -5.168e+00,
         1.026e+01, -4.645e+00,  2.542e+00, -5.158e+00, -1.536e+00,  2.074e+00,
        -3.086e+00, -1.417e+00, -1.876e-01, -3.450e+00, -3.036e+00, -1.060e+00,
        -3.628e+00, -3.486e+00,  6.661e+00,  1.949e+01, -2.810e+00, -5.387e+00,
        -2.230e+00, -3.761e+00, -4.557e+00,  3.287e+00,  1.488e+01, -1.866e+00,
        -4.404e+00,  4.663e+00, -4.027e+00, -6.157e+00, -9.883e-01, -9.819e-01,
        -2.029e+00,  1.399e+01,  7.514e-01, -3.016e+00, -5.050e+00,  3.129e-01,
        -1.842e+00, -4.696e+00,  6.710e-01, -1.669e+00,  1.332e+00, -5.804e+00,
        -3.245e+00,  8.346e+00, -6.958e-01, -3.705e+00, -5.284e+00, -2.915e+00,
        -5.060e+00, -4.541e+00,  5.945e+00,  6.726e+00,  6.748e+00, -3.750e+00,
        -3.521e+00, -4.881e+00, -5.228e+00, -3.057e+00,  5.506e+00, -5.114e+00,
        -3.077e+00, -2.248e+00,  4.101e-01, -5.873e+00, -1.925e+00, -4.926e+00,
         1.438e+01, -6.170e+00, -5.296e+00, -3.460e+00, -4.892e+00, -1.159e+00,
        -4.855e+00, -3.249e+00, -4.666e+00,  4.370e-01, -5.351e-01, -5.195e+00,
        -4.773e+00,  2.024e+00, -4.245e+00,  2.349e+01, -3.343e+00, -5.758e+00,
        -3.517e+00, -2.957e+00, -3.968e-01,  4.005e-01, -4.553e+00, -5.431e+00,
        -2.545e+00, -1.615e+00, -3.267e+00, -7.281e-01,  1.100e+01, -2.385e+00,
        -2.721e+00,  4.548e-02,  3.979e+00, -4.073e+00, -5.980e+00,  3.702e-01,
         3.688e+00,  5.217e+00, -5.240e+00, -3.392e+00,  1.804e+01,  1.552e+01,
        -1.839e-01,  4.159e-01, -6.231e+00,  3.541e+00, -2.584e+00, -4.240e+00,
        -8.827e-01, -1.846e+00, -4.971e+00, -3.990e+00,  4.056e+00, -1.870e-01,
        -6.718e-01, -4.018e+00,  1.223e+01,  4.825e+00, -2.879e+00, -4.881e+00,
         1.135e+01, -3.225e+00, -4.115e+00, -4.653e+00, -5.288e+00, -8.309e+00,
        -7.909e-01,  9.844e+00, -4.712e+00,  7.775e-01,  1.616e+01, -6.790e+00,
        -4.248e+00, -5.589e+00,  6.589e-01,  1.069e+00, -3.912e+00, -3.843e+00,
        -5.220e+00,  6.108e+00, -3.184e+00,  2.798e-01, -4.619e+00,  7.986e+00,
        -4.986e+00,  8.840e+00, -6.564e+00, -3.232e+00, -4.385e-01,  1.277e+00,
         2.439e+01, -4.007e+00, -3.868e+00, -1.768e+00, -6.118e+00,  6.713e-01,
        -6.668e+00, -5.541e+00, -2.927e+00,  5.756e+00, -6.480e+00, -4.803e+00,
         3.214e-01, -4.965e+00, -1.005e+00,  3.041e+00, -5.556e+00, -3.837e+00,
         9.711e-01,  1.137e+00, -4.848e+00, -4.461e+00, -3.537e+00, -5.561e+00,
        -4.824e+00, -2.565e+00, -4.803e+00,  3.863e-01,  9.419e-02, -4.046e+00,
        -5.668e+00,  1.374e+00, -4.497e+00, -2.715e+00,  3.420e+00, -4.191e+00,
         8.065e-01, -2.579e+00,  8.406e+00, -5.362e+00, -6.284e-01, -3.970e-01,
        -2.045e+00,  6.383e+00, -3.444e+00, -5.182e+00,  1.506e+01, -7.918e-01,
        -6.216e+00,  8.698e+00, -5.660e+00, -9.226e-01, -2.288e+00, -3.010e+00,
        -4.361e+00,  7.018e-01, -2.650e+00, -1.232e+00, -2.311e+00, -3.668e+00,
        -1.697e+00,  2.504e+01, -9.746e-02,  2.982e+00, -3.549e+00, -2.255e+00,
         4.233e-03, -5.794e+00, -5.298e+00, -4.162e+00, -6.865e+00, -5.984e+00,
        -5.993e+00, -4.783e+00,  4.074e+00,  1.135e+00, -4.722e+00, -4.980e+00,
        -2.874e+00, -4.973e+00,  2.643e+01, -4.170e+00, -3.720e+00, -2.550e+00,
        -5.552e+00, -4.704e+00,  6.548e+00,  1.131e+00,  5.750e+00, -5.271e+00,
        -4.426e+00, -1.021e+00, -2.943e+00, -5.746e+00, -3.481e+00,  3.242e+01,
        -7.815e-01, -2.607e-01,  9.530e+00, -3.602e+00, -8.326e-01, -5.526e+00,
        -5.532e+00, -8.085e-01, -4.713e-01, -6.436e+00, -1.980e+00, -4.528e+00],
       device='cuda:0')
v tensor([2.384e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.429e+00,
        1.000e-12, 1.000e-12, 4.942e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 3.778e+00, 6.084e+00, 1.000e-12, 2.446e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.690e+00, 1.000e-12, 8.815e+00, 3.481e+00,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 8.528e+00, 4.173e+00,
        1.000e-12, 1.000e+01, 3.544e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 2.542e+00, 1.000e-12, 1.000e-12, 2.074e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 6.661e+00, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 3.287e+00, 1.000e+01, 1.000e-12,
        1.000e-12, 4.663e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 7.514e-01, 1.000e-12, 1.000e-12, 3.129e-01,
        1.000e-12, 1.000e-12, 6.710e-01, 1.000e-12, 1.332e+00, 1.000e-12,
        1.000e-12, 8.346e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 5.945e+00, 6.726e+00, 6.748e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.506e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 4.101e-01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 4.370e-01, 1.000e-12, 1.000e-12,
        1.000e-12, 2.024e+00, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 4.005e-01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 4.548e-02, 3.979e+00, 1.000e-12, 1.000e-12, 3.702e-01,
        3.688e+00, 5.217e+00, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 4.159e-01, 1.000e-12, 3.541e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 4.056e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 4.825e+00, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 9.844e+00, 1.000e-12, 7.775e-01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 6.589e-01, 1.069e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 6.108e+00, 1.000e-12, 2.798e-01, 1.000e-12, 7.986e+00,
        1.000e-12, 8.840e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.277e+00,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 6.713e-01,
        1.000e-12, 1.000e-12, 1.000e-12, 5.756e+00, 1.000e-12, 1.000e-12,
        3.214e-01, 1.000e-12, 1.000e-12, 3.041e+00, 1.000e-12, 1.000e-12,
        9.711e-01, 1.137e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 3.863e-01, 9.419e-02, 1.000e-12,
        1.000e-12, 1.374e+00, 1.000e-12, 1.000e-12, 3.420e+00, 1.000e-12,
        8.065e-01, 1.000e-12, 8.406e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 6.383e+00, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 8.698e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 7.018e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 2.982e+00, 1.000e-12, 1.000e-12,
        4.233e-03, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 4.074e+00, 1.135e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 6.548e+00, 1.131e+00, 5.750e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 9.530e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-2.325],
         [-4.826],
         [10.748],
         [-4.868],
         [-3.635],
         [-2.857],
         [ 4.290],
         [ 6.031],
         [-4.073],
         [ 0.661]],

        [[ 1.983],
         [-3.506],
         [-3.996],
         [-4.876],
         [-1.587],
         [-4.305],
         [10.380],
         [-4.985],
         [ 4.699],
         [11.069]],

        [[ 1.949],
         [-3.240],
         [-6.789],
         [-3.167],
         [10.883],
         [ 4.638],
         [-4.966],
         [-5.368],
         [-0.515],
         [ 4.780]],

        [[-4.963],
         [ 0.194],
         [ 7.840],
         [-4.476],
         [ 1.308],
         [-3.650],
         [-1.106],
         [10.966],
         [-3.946],
         [-3.542]],

        [[ 3.427],
         [-2.623],
         [19.217],
         [-3.695],
         [17.774],
         [-2.789],
         [-5.147],
         [10.905],
         [ 5.552],
         [16.261]],

        [[-2.608],
         [14.222],
         [-4.377],
         [ 2.011],
         [-4.454],
         [ 7.037],
         [-4.086],
         [-6.451],
         [ 3.038],
         [-3.385]],

        [[-5.791],
         [-4.383],
         [-3.429],
         [-4.990],
         [-4.695],
         [ 5.156],
         [-4.117],
         [-4.317],
         [-3.379],
         [-1.114]],

        [[-5.921],
         [-5.501],
         [-5.685],
         [-5.190],
         [ 3.318],
         [-3.350],
         [-6.386],
         [ 6.522],
         [-4.672],
         [-6.324]],

        [[-5.605],
         [ 4.796],
         [ 5.311],
         [-5.007],
         [ 9.301],
         [ 7.875],
         [-1.691],
         [-4.579],
         [-4.898],
         [-4.533]],

        [[-2.391],
         [ 1.829],
         [-4.533],
         [-0.789],
         [-3.896],
         [ 2.893],
         [-6.151],
         [-1.095],
         [-4.465],
         [-6.400]],

        [[-5.775],
         [-1.269],
         [-2.735],
         [-3.525],
         [-4.766],
         [ 7.661],
         [-4.648],
         [-3.553],
         [-5.991],
         [10.526]],

        [[ 8.352],
         [-4.620],
         [-7.137],
         [ 9.491],
         [56.259],
         [10.054],
         [ 2.099],
         [ 5.553],
         [-4.512],
         [59.338]],

        [[-3.860],
         [-2.159],
         [-6.250],
         [ 3.356],
         [-4.696],
         [ 9.348],
         [-5.967],
         [ 2.351],
         [ 1.446],
         [-3.237]],

        [[-1.373],
         [31.115],
         [ 2.132],
         [-5.410],
         [-4.440],
         [ 3.122],
         [-7.050],
         [-2.323],
         [-5.107],
         [ 0.265]],

        [[-1.419],
         [-5.369],
         [-6.101],
         [-3.823],
         [-0.560],
         [28.872],
         [-1.512],
         [-4.837],
         [-4.431],
         [ 8.929]],

        [[-5.470],
         [-3.086],
         [ 6.141],
         [30.243],
         [-5.450],
         [-2.393],
         [-5.532],
         [-0.565],
         [-6.140],
         [ 0.291]],

        [[-2.999],
         [-4.496],
         [-3.914],
         [-2.371],
         [ 0.366],
         [ 3.850],
         [-6.673],
         [-3.123],
         [-2.791],
         [ 6.726]],

        [[-2.992],
         [15.593],
         [ 7.991],
         [-5.375],
         [-5.332],
         [-4.030],
         [ 1.924],
         [-4.100],
         [ 7.923],
         [-5.773]],

        [[-2.549],
         [-1.832],
         [-1.451],
         [ 8.153],
         [-5.387],
         [-5.790],
         [-1.995],
         [-3.785],
         [-1.797],
         [-0.867]],

        [[-5.095],
         [ 0.706],
         [-4.515],
         [-5.862],
         [-1.946],
         [-0.303],
         [-6.474],
         [13.087],
         [ 5.296],
         [-6.347]],

        [[ 7.046],
         [-0.363],
         [-5.074],
         [-0.385],
         [-3.645],
         [-5.464],
         [ 2.099],
         [-4.633],
         [ 0.683],
         [-1.558]],

        [[ 3.502],
         [-6.089],
         [-6.678],
         [-4.808],
         [ 6.125],
         [-0.537],
         [ 5.640],
         [-2.330],
         [-2.338],
         [-3.694]],

        [[-5.620],
         [ 6.474],
         [-5.200],
         [16.935],
         [-3.649],
         [ 6.617],
         [14.605],
         [-4.759],
         [ 4.190],
         [-5.447]],

        [[-5.698],
         [-3.682],
         [-3.242],
         [-5.079],
         [20.436],
         [-5.375],
         [17.254],
         [-4.663],
         [ 2.512],
         [-4.447]],

        [[-3.130],
         [-3.473],
         [42.083],
         [-5.312],
         [ 3.296],
         [-0.877],
         [-3.940],
         [22.119],
         [-4.510],
         [12.750]],

        [[-6.999],
         [-3.837],
         [-2.857],
         [-4.737],
         [-3.351],
         [-3.572],
         [-2.416],
         [-5.291],
         [-0.653],
         [-0.809]],

        [[-5.447],
         [-0.420],
         [-3.495],
         [-5.710],
         [38.785],
         [-3.969],
         [50.004],
         [-0.532],
         [ 1.679],
         [-2.630]],

        [[ 0.367],
         [-3.642],
         [-1.185],
         [-5.976],
         [32.441],
         [-6.834],
         [-2.068],
         [-6.052],
         [-3.689],
         [ 4.965]],

        [[ 1.651],
         [-2.497],
         [ 7.861],
         [ 8.123],
         [ 2.226],
         [-3.318],
         [12.914],
         [ 9.552],
         [10.239],
         [-3.409]],

        [[-4.926],
         [-1.171],
         [28.668],
         [-4.730],
         [-5.510],
         [-3.623],
         [-3.579],
         [ 3.434],
         [ 0.229],
         [-3.286]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.290e+00],
         [6.031e+00],
         [1.000e-12],
         [6.614e-01]],

        [[1.983e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [4.699e+00],
         [1.000e+01]],

        [[1.949e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [4.638e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.780e+00]],

        [[1.000e-12],
         [1.940e-01],
         [7.840e+00],
         [1.000e-12],
         [1.308e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[3.427e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [5.552e+00],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [2.011e+00],
         [1.000e-12],
         [7.037e+00],
         [1.000e-12],
         [1.000e-12],
         [3.038e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.156e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.318e+00],
         [1.000e-12],
         [1.000e-12],
         [6.522e+00],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [4.796e+00],
         [5.311e+00],
         [1.000e-12],
         [9.301e+00],
         [7.875e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.829e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.893e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.661e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[8.352e+00],
         [1.000e-12],
         [1.000e-12],
         [9.491e+00],
         [1.000e+01],
         [1.000e+01],
         [2.099e+00],
         [5.553e+00],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.356e+00],
         [1.000e-12],
         [9.348e+00],
         [1.000e-12],
         [2.351e+00],
         [1.446e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [2.132e+00],
         [1.000e-12],
         [1.000e-12],
         [3.122e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.651e-01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [8.929e+00]],

        [[1.000e-12],
         [1.000e-12],
         [6.141e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.912e-01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.663e-01],
         [3.850e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.726e+00]],

        [[1.000e-12],
         [1.000e+01],
         [7.991e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.924e+00],
         [1.000e-12],
         [7.923e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [8.153e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [7.059e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [5.296e+00],
         [1.000e-12]],

        [[7.046e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.099e+00],
         [1.000e-12],
         [6.830e-01],
         [1.000e-12]],

        [[3.502e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.125e+00],
         [1.000e-12],
         [5.640e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [6.474e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [6.617e+00],
         [1.000e+01],
         [1.000e-12],
         [4.190e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [2.512e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [3.296e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.679e+00],
         [1.000e-12]],

        [[3.674e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.965e+00]],

        [[1.651e+00],
         [1.000e-12],
         [7.861e+00],
         [8.123e+00],
         [2.226e+00],
         [1.000e-12],
         [1.000e+01],
         [9.552e+00],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.434e+00],
         [2.288e-01],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[-6.432],
        [39.867],
        [-5.724],
        [-4.687],
        [13.576],
        [-1.119],
        [ 4.900],
        [-5.130],
        [ 7.083],
        [-4.508],
        [-5.281],
        [-5.960],
        [-6.422],
        [-5.985],
        [-6.159],
        [-2.626],
        [-4.424],
        [-5.209],
        [13.725],
        [-1.749],
        [-0.490],
        [-2.117],
        [ 1.934],
        [-2.196],
        [-2.660],
        [-2.547],
        [ 3.726],
        [10.155],
        [-5.174],
        [-0.094]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [4.900e+00],
        [1.000e-12],
        [7.083e+00],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.934e+00],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [3.726e+00],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-0.002, -0.008,  0.017,  ..., -0.010, -0.019,  0.078],
        [ 0.035,  0.035,  0.041,  ..., -0.051,  0.038, -0.066],
        [-0.000, -0.049, -0.033,  ..., -0.029, -0.007, -0.008],
        ...,
        [-0.034, -0.019,  0.003,  ...,  0.000, -0.021,  0.012],
        [-0.020,  0.024, -0.007,  ...,  0.007,  0.240, -0.035],
        [ 0.065,  0.097, -0.101,  ...,  0.114, -0.167,  0.014]],
       device='cuda:0')
s after update for 1 param tensor([[2.224, 1.648, 1.725,  ..., 1.382, 1.250, 1.201],
        [2.109, 1.242, 1.208,  ..., 2.009, 1.677, 1.436],
        [2.226, 1.464, 1.480,  ..., 1.351, 1.065, 1.488],
        ...,
        [1.289, 1.897, 2.037,  ..., 1.202, 1.232, 2.364],
        [1.115, 1.306, 1.235,  ..., 0.741, 1.272, 1.681],
        [1.678, 1.733, 1.657,  ..., 1.715, 1.428, 1.843]], device='cuda:0')
b after update for 1 param tensor([[182.103, 156.728, 160.366,  ..., 143.541, 136.486, 133.824],
        [177.330, 136.093, 134.203,  ..., 173.051, 158.105, 146.301],
        [182.169, 147.753, 148.538,  ..., 141.894, 126.017, 148.948],
        ...,
        [138.642, 168.164, 174.275,  ..., 133.867, 135.538, 187.726],
        [128.903, 139.545, 135.688,  ..., 105.126, 137.717, 158.302],
        [158.149, 160.731, 157.158,  ..., 159.900, 145.898, 165.753]],
       device='cuda:0')
clipping threshold 0.18020771138435734
a after update for 1 param tensor([ 7.018e-02, -1.662e-02, -1.828e-02,  6.905e-03,  9.730e-02,  4.452e-02,
        -1.533e-02, -2.066e-01,  1.580e-02,  5.517e-03, -1.676e-01,  1.678e-02,
        -5.606e-02, -9.654e-03,  1.450e-02,  1.162e-01,  6.456e-02,  2.631e-02,
        -1.813e-02,  1.518e-01, -9.351e-04,  2.454e-02, -1.143e-02, -8.252e-03,
        -1.030e-01, -4.453e-03,  6.351e-02, -1.044e-02, -2.413e-02,  1.237e-01,
        -5.450e-02,  4.973e-02,  1.313e-02,  1.043e-02, -1.386e-01, -1.118e-01,
         6.055e-02, -7.684e-02, -1.171e-01,  2.144e-02,  5.743e-03, -3.229e-02,
         1.148e-01,  2.914e-04, -1.071e-02,  6.677e-04, -4.114e-02, -1.693e-02,
         8.530e-02,  1.824e-02, -5.909e-02,  5.567e-02,  4.437e-02, -1.057e-01,
        -2.257e-02,  3.300e-02, -5.802e-02,  5.467e-02,  1.665e-02, -7.946e-02,
         1.242e-02, -1.521e-01, -1.266e-02, -6.966e-03, -3.730e-02,  6.878e-03,
         1.143e-01,  5.431e-02, -2.763e-02,  3.369e-03, -2.770e-02,  2.048e-02,
        -7.010e-02,  2.290e-02, -8.159e-02,  1.178e-01,  3.785e-02,  2.960e-02,
        -1.642e-01,  8.108e-03, -7.416e-02, -1.860e-01,  1.007e-01, -5.010e-02,
        -1.693e-02,  8.159e-03, -9.503e-02, -5.922e-03,  5.739e-02, -1.058e-01,
         1.093e-01,  4.086e-02, -1.953e-02,  2.894e-02, -3.480e-03, -5.972e-02,
         1.131e-02, -1.226e-01,  1.432e-02, -2.010e-02,  2.555e-02,  2.732e-02,
        -8.330e-02, -5.606e-03,  1.092e-01, -1.094e-01, -7.552e-02, -1.265e-03,
         6.585e-02,  4.507e-02,  2.113e-02,  3.841e-02,  6.371e-02, -4.378e-03,
         9.527e-03,  7.422e-02, -6.313e-02,  1.058e-02, -8.711e-02,  6.373e-03,
         3.119e-02, -4.282e-02,  4.409e-02, -2.219e-02,  1.152e-02,  1.383e-01,
         8.195e-03, -3.540e-02, -1.137e-01, -6.664e-03, -1.386e-02,  7.777e-02,
        -1.983e-01, -4.725e-03, -3.367e-02, -3.898e-02,  1.702e-02,  2.843e-03,
         3.484e-02,  1.749e-02,  4.878e-02,  2.952e-02,  6.628e-02,  3.219e-02,
        -7.318e-02, -5.144e-02, -1.037e-01,  7.716e-02,  1.193e-01,  1.194e-02,
        -9.415e-03, -5.137e-02,  7.209e-02, -8.934e-02,  1.632e-01,  6.994e-02,
         1.710e-01, -2.551e-02,  4.624e-02, -6.157e-02,  4.349e-03, -4.896e-02,
         3.047e-01,  7.799e-02,  4.277e-03, -7.035e-02,  1.941e-02, -8.677e-02,
         1.244e-01,  1.632e-02, -5.962e-02,  4.339e-02,  3.653e-02,  3.500e-02,
         6.210e-02,  4.258e-03,  3.399e-02, -1.288e-01, -3.164e-03, -1.170e-02,
        -1.771e-01, -2.051e-02,  6.357e-03,  5.758e-02,  1.066e-01,  8.028e-02,
         1.862e-03,  1.328e-01, -7.831e-02, -1.021e-01, -1.485e-01,  5.087e-02,
         1.097e-01,  1.563e-01, -2.074e-02, -2.393e-02,  1.724e-02, -6.752e-02,
         3.209e-02, -1.457e-01,  2.734e-02,  2.629e-02, -9.703e-02, -1.346e-01,
         1.478e-01,  9.620e-03, -9.275e-03, -4.206e-02,  4.083e-02,  1.602e-02,
         4.454e-03, -1.104e-01,  4.009e-02, -3.003e-02,  2.040e-02,  5.042e-02,
         7.191e-02,  7.017e-03, -9.745e-02, -4.347e-02,  5.994e-03,  4.023e-02,
         2.433e-01, -8.445e-02,  1.296e-01, -7.419e-02, -6.668e-02,  3.850e-02,
        -2.467e-02, -4.118e-02,  4.245e-02, -2.313e-02, -9.463e-02,  3.794e-02,
        -5.338e-02, -1.122e-01,  3.572e-02,  3.860e-02, -2.239e-02,  2.644e-02,
         1.159e-01,  3.346e-02,  6.145e-02, -1.003e-01, -1.307e-01, -2.305e-03,
        -6.134e-03,  4.011e-02, -1.598e-02, -1.019e-01,  1.213e-02,  1.167e-02,
         5.764e-02,  1.814e-01, -5.915e-03,  4.157e-04, -1.017e-01, -6.930e-02,
        -1.638e-02, -1.575e-01,  5.438e-02, -2.536e-02,  2.681e-02,  1.674e-02,
        -2.002e-02,  1.027e-02, -2.939e-02, -1.421e-01,  3.044e-02, -4.698e-02,
        -1.352e-02, -4.798e-02,  1.384e-01, -6.758e-02, -3.857e-02,  1.424e-01,
         8.511e-03, -2.661e-02, -1.262e-01,  1.048e-01, -2.885e-02, -1.106e-01,
        -5.005e-02,  1.137e-01, -4.872e-02, -9.579e-02, -5.820e-02,  1.503e-01,
        -1.423e-01,  2.250e-01, -1.370e-02, -1.437e-02,  2.644e-02,  6.534e-02,
        -6.137e-02, -1.918e-01,  1.820e-01,  5.223e-03, -5.416e-02, -2.703e-02],
       device='cuda:0')
s after update for 1 param tensor([1.259, 1.765, 1.182, 1.082, 0.544, 1.269, 1.600, 1.432, 1.644, 1.909,
        1.469, 1.283, 1.232, 1.383, 1.945, 1.472, 1.173, 1.438, 1.576, 1.662,
        1.693, 1.232, 1.441, 1.444, 1.519, 1.865, 1.932, 1.234, 1.337, 1.693,
        1.232, 1.830, 0.727, 0.198, 1.344, 1.910, 1.832, 1.446, 1.787, 1.696,
        0.560, 1.187, 1.402, 1.289, 0.745, 1.420, 0.801, 1.165, 1.035, 1.452,
        1.720, 1.570, 1.161, 1.654, 1.756, 1.248, 1.235, 1.594, 1.523, 1.072,
        1.682, 1.271, 1.489, 1.694, 1.008, 1.391, 1.528, 1.880, 1.541, 1.137,
        1.843, 1.186, 1.207, 1.503, 1.635, 1.468, 1.268, 1.532, 1.237, 1.210,
        1.603, 1.164, 1.810, 0.854, 1.378, 1.341, 1.269, 1.639, 1.462, 1.456,
        1.032, 1.503, 1.394, 0.828, 1.612, 1.351, 1.367, 1.195, 1.634, 1.589,
        0.815, 1.500, 1.743, 1.678, 1.442, 1.380, 1.302, 0.898, 1.370, 1.120,
        2.010, 1.539, 1.454, 1.403, 1.373, 0.975, 1.121, 1.425, 1.117, 1.880,
        1.509, 1.300, 1.590, 1.031, 1.235, 1.556, 0.911, 1.268, 1.516, 1.345,
        2.403, 1.342, 1.596, 0.974, 1.390, 1.138, 1.760, 1.370, 1.789, 0.982,
        1.383, 1.363, 1.600, 1.449, 1.847, 1.428, 1.717, 1.604, 1.073, 1.120,
        1.408, 1.273, 1.901, 1.070, 1.088, 1.313, 1.236, 1.310, 1.682, 1.667,
        0.959, 1.316, 2.028, 1.841, 1.251, 1.628, 1.395, 2.221, 1.314, 1.395,
        1.313, 0.755, 1.547, 1.856, 1.459, 1.484, 1.733, 1.571, 1.278, 1.022,
        1.444, 1.306, 0.973, 1.136, 1.708, 1.836, 1.903, 1.599, 1.735, 1.725,
        1.200, 1.153, 2.154, 1.092, 1.129, 1.328, 1.698, 1.261, 1.763, 1.820,
        1.406, 1.804, 1.783, 1.344, 1.013, 1.362, 0.712, 1.615, 1.492, 1.013,
        1.193, 1.304, 1.297, 1.177, 1.181, 1.497, 1.797, 1.548, 1.280, 1.117,
        1.954, 1.217, 1.583, 1.464, 1.205, 1.101, 1.248, 1.211, 1.307, 1.080,
        1.859, 1.466, 1.413, 1.292, 1.156, 1.884, 1.335, 1.585, 1.711, 1.428,
        1.745, 1.936, 1.580, 0.737, 1.532, 1.139, 1.499, 0.966, 0.737, 1.432,
        1.257, 1.013, 1.376, 1.692, 1.179, 1.405, 1.457, 1.787, 1.350, 1.528,
        1.464, 1.175, 1.917, 1.578, 1.689, 1.294, 1.347, 1.840, 1.396, 1.443,
        1.168, 1.396, 1.618, 1.120, 1.211, 1.231, 1.719, 1.252, 1.704, 1.208,
        1.525, 1.392, 1.633, 0.920, 1.259, 1.556, 1.162, 1.823, 1.217, 1.379,
        1.646, 1.351, 1.079, 1.681, 1.772, 1.415, 1.317, 1.798, 0.840, 1.842],
       device='cuda:0')
b after update for 1 param tensor([137.026, 162.206, 132.747, 127.026,  90.050, 137.526, 154.433, 146.129,
        156.552, 168.702, 148.009, 138.299, 135.528, 143.597, 170.267, 148.128,
        132.241, 146.400, 153.295, 157.418, 158.861, 135.546, 146.560, 146.711,
        150.474, 166.749, 169.696, 135.652, 141.156, 158.881, 135.527, 165.151,
        104.140,  54.384, 141.577, 168.763, 165.253, 146.842, 163.219, 159.004,
         91.391, 133.052, 144.561, 138.633, 105.383, 145.488, 109.284, 131.814,
        124.229, 147.122, 160.138, 152.980, 131.589, 157.041, 161.795, 136.398,
        135.696, 154.149, 150.674, 126.440, 158.354, 137.658, 148.996, 158.915,
        122.593, 143.997, 150.906, 167.411, 151.581, 130.184, 165.748, 132.959,
        134.124, 149.676, 156.110, 147.958, 137.482, 151.147, 135.791, 134.321,
        154.604, 131.735, 164.249, 112.854, 143.344, 141.401, 137.530, 156.320,
        147.643, 147.331, 124.047, 149.688, 144.168, 111.126, 155.021, 141.912,
        142.740, 133.483, 156.065, 153.908, 110.219, 149.550, 161.203, 158.149,
        146.597, 143.427, 139.300, 115.680, 142.909, 129.218, 173.111, 151.474,
        147.208, 144.625, 143.092, 120.572, 129.266, 145.762, 129.025, 167.427,
        150.002, 139.207, 153.946, 123.957, 135.713, 152.327, 116.532, 137.483,
        150.327, 141.594, 189.264, 141.460, 154.271, 120.510, 143.953, 130.268,
        161.987, 142.932, 163.312, 121.020, 143.572, 142.545, 154.467, 146.968,
        165.949, 145.884, 159.986, 154.628, 126.495, 129.194, 144.866, 137.754,
        168.337, 126.289, 127.381, 139.922, 135.757, 139.761, 158.337, 157.640,
        119.566, 140.064, 173.859, 165.683, 136.579, 155.798, 144.212, 181.958,
        139.978, 144.197, 139.896, 106.108, 151.862, 166.353, 147.502, 148.734,
        160.713, 153.031, 138.040, 123.421, 146.705, 139.517, 120.428, 130.124,
        159.574, 165.431, 168.442, 154.403, 160.851, 160.381, 133.730, 131.101,
        179.197, 127.591, 129.745, 140.693, 159.095, 137.120, 162.124, 164.738,
        144.760, 164.008, 163.022, 141.528, 122.917, 142.520, 102.994, 155.171,
        149.141, 122.900, 133.375, 139.430, 139.055, 132.451, 132.701, 149.406,
        163.675, 151.908, 138.157, 129.051, 170.678, 134.696, 153.599, 147.720,
        134.008, 128.094, 136.419, 134.345, 139.569, 126.876, 166.492, 147.818,
        145.154, 138.785, 131.273, 167.575, 141.077, 153.739, 159.690, 145.918,
        161.273, 169.906, 153.499, 104.839, 151.123, 130.331, 149.506, 120.002,
        104.825, 146.135, 136.874, 122.892, 143.247, 158.812, 132.564, 144.711,
        147.377, 163.224, 141.877, 150.953, 147.754, 132.330, 169.052, 153.398,
        158.667, 138.899, 141.689, 165.603, 144.248, 146.671, 131.939, 144.242,
        155.318, 129.209, 134.383, 135.468, 160.101, 136.599, 159.373, 134.177,
        150.806, 144.037, 156.049, 117.098, 137.023, 152.309, 131.636, 164.877,
        134.678, 143.406, 156.655, 141.899, 126.854, 158.295, 162.554, 145.265,
        140.113, 163.738, 111.929, 165.714], device='cuda:0')
clipping threshold 0.18020771138435734
a after update for 1 param tensor([[[ 0.043],
         [-0.102],
         [-0.114],
         [ 0.018],
         [-0.070],
         [ 0.097],
         [-0.052],
         [-0.023],
         [-0.013],
         [ 0.086]],

        [[-0.085],
         [ 0.123],
         [-0.081],
         [-0.006],
         [ 0.057],
         [ 0.146],
         [ 0.080],
         [-0.038],
         [-0.021],
         [-0.081]],

        [[-0.008],
         [-0.110],
         [ 0.016],
         [-0.086],
         [ 0.051],
         [ 0.012],
         [-0.070],
         [-0.018],
         [ 0.121],
         [-0.056]],

        [[ 0.050],
         [ 0.001],
         [ 0.026],
         [ 0.029],
         [ 0.041],
         [ 0.053],
         [ 0.017],
         [ 0.023],
         [ 0.012],
         [-0.055]],

        [[-0.007],
         [ 0.009],
         [-0.093],
         [-0.033],
         [-0.011],
         [-0.094],
         [ 0.027],
         [-0.011],
         [ 0.015],
         [ 0.078]],

        [[ 0.084],
         [-0.049],
         [-0.036],
         [-0.110],
         [-0.041],
         [-0.103],
         [-0.030],
         [ 0.083],
         [-0.029],
         [ 0.072]],

        [[ 0.020],
         [ 0.017],
         [-0.065],
         [-0.008],
         [-0.098],
         [ 0.103],
         [ 0.032],
         [ 0.025],
         [-0.155],
         [-0.053]],

        [[ 0.107],
         [-0.019],
         [ 0.079],
         [ 0.093],
         [-0.104],
         [ 0.090],
         [-0.104],
         [ 0.015],
         [-0.015],
         [-0.004]],

        [[-0.014],
         [-0.011],
         [-0.011],
         [-0.008],
         [ 0.087],
         [-0.033],
         [-0.084],
         [ 0.204],
         [ 0.036],
         [-0.035]],

        [[-0.041],
         [-0.150],
         [ 0.092],
         [-0.014],
         [ 0.055],
         [ 0.057],
         [ 0.082],
         [ 0.063],
         [-0.020],
         [-0.063]],

        [[ 0.057],
         [-0.009],
         [ 0.070],
         [ 0.040],
         [-0.083],
         [-0.069],
         [ 0.128],
         [-0.061],
         [-0.060],
         [-0.074]],

        [[ 0.062],
         [ 0.091],
         [-0.036],
         [ 0.090],
         [-0.003],
         [ 0.045],
         [ 0.030],
         [-0.039],
         [ 0.053],
         [-0.018]],

        [[ 0.022],
         [ 0.087],
         [ 0.065],
         [ 0.049],
         [ 0.055],
         [-0.049],
         [-0.040],
         [ 0.128],
         [-0.071],
         [ 0.079]],

        [[-0.035],
         [ 0.030],
         [ 0.120],
         [ 0.118],
         [-0.091],
         [-0.091],
         [ 0.134],
         [ 0.003],
         [ 0.003],
         [-0.046]],

        [[ 0.098],
         [-0.011],
         [-0.014],
         [ 0.006],
         [ 0.003],
         [ 0.112],
         [-0.074],
         [-0.025],
         [ 0.139],
         [ 0.088]],

        [[-0.003],
         [-0.178],
         [ 0.070],
         [ 0.181],
         [ 0.040],
         [-0.011],
         [-0.117],
         [ 0.132],
         [ 0.052],
         [-0.012]],

        [[-0.260],
         [ 0.139],
         [-0.028],
         [ 0.057],
         [ 0.017],
         [ 0.020],
         [ 0.117],
         [-0.072],
         [ 0.044],
         [ 0.054]],

        [[-0.033],
         [-0.072],
         [-0.025],
         [-0.050],
         [ 0.104],
         [ 0.069],
         [-0.005],
         [-0.035],
         [ 0.014],
         [ 0.005]],

        [[-0.037],
         [-0.080],
         [ 0.021],
         [ 0.028],
         [ 0.017],
         [-0.113],
         [ 0.082],
         [-0.041],
         [ 0.031],
         [ 0.079]],

        [[ 0.152],
         [-0.025],
         [-0.052],
         [-0.110],
         [-0.042],
         [-0.021],
         [ 0.054],
         [ 0.018],
         [-0.009],
         [-0.004]],

        [[-0.122],
         [-0.098],
         [ 0.001],
         [ 0.045],
         [ 0.115],
         [-0.040],
         [-0.104],
         [-0.027],
         [-0.085],
         [-0.024]],

        [[ 0.033],
         [ 0.075],
         [ 0.090],
         [-0.031],
         [-0.118],
         [-0.201],
         [ 0.029],
         [ 0.031],
         [-0.004],
         [-0.028]],

        [[ 0.043],
         [ 0.093],
         [ 0.063],
         [ 0.068],
         [ 0.030],
         [-0.010],
         [ 0.101],
         [ 0.008],
         [-0.171],
         [ 0.002]],

        [[ 0.021],
         [-0.019],
         [ 0.009],
         [ 0.023],
         [ 0.010],
         [ 0.015],
         [ 0.023],
         [-0.084],
         [-0.007],
         [ 0.042]],

        [[-0.043],
         [ 0.029],
         [ 0.147],
         [-0.027],
         [-0.038],
         [-0.046],
         [ 0.047],
         [ 0.005],
         [ 0.054],
         [ 0.018]],

        [[ 0.034],
         [-0.092],
         [-0.055],
         [ 0.098],
         [ 0.002],
         [ 0.088],
         [ 0.045],
         [-0.029],
         [ 0.102],
         [ 0.048]],

        [[ 0.008],
         [ 0.107],
         [-0.006],
         [ 0.008],
         [-0.020],
         [-0.160],
         [ 0.076],
         [ 0.116],
         [-0.191],
         [-0.002]],

        [[ 0.088],
         [ 0.098],
         [-0.008],
         [ 0.098],
         [-0.047],
         [-0.015],
         [ 0.018],
         [ 0.080],
         [ 0.015],
         [-0.011]],

        [[ 0.039],
         [ 0.141],
         [-0.009],
         [-0.062],
         [-0.078],
         [ 0.020],
         [ 0.012],
         [ 0.048],
         [-0.026],
         [ 0.055]],

        [[ 0.045],
         [-0.072],
         [-0.040],
         [-0.024],
         [-0.020],
         [ 0.007],
         [-0.065],
         [ 0.130],
         [ 0.086],
         [-0.089]]], device='cuda:0')
s after update for 1 param tensor([[[1.136],
         [1.284],
         [1.850],
         [1.345],
         [1.031],
         [1.081],
         [1.890],
         [1.080],
         [1.269],
         [1.106]],

        [[2.075],
         [1.155],
         [1.310],
         [1.528],
         [0.926],
         [1.294],
         [2.060],
         [1.435],
         [1.127],
         [2.017]],

        [[1.068],
         [1.431],
         [1.800],
         [0.839],
         [1.398],
         [1.437],
         [1.382],
         [1.417],
         [1.042],
         [1.832]],

        [[1.423],
         [1.555],
         [2.172],
         [1.253],
         [1.676],
         [1.308],
         [0.768],
         [2.341],
         [1.555],
         [1.321]],

        [[1.693],
         [1.401],
         [1.620],
         [1.709],
         [1.440],
         [1.007],
         [1.403],
         [1.542],
         [1.805],
         [1.396]],

        [[1.832],
         [1.790],
         [1.172],
         [1.425],
         [1.582],
         [1.272],
         [1.541],
         [1.825],
         [1.568],
         [1.621]],

        [[1.602],
         [1.315],
         [1.085],
         [1.448],
         [1.259],
         [1.338],
         [1.442],
         [1.253],
         [1.074],
         [1.707]],

        [[1.571],
         [1.563],
         [1.505],
         [1.564],
         [1.975],
         [1.010],
         [1.870],
         [1.857],
         [1.499],
         [1.740]],

        [[1.500],
         [1.066],
         [1.720],
         [1.421],
         [1.731],
         [1.192],
         [1.222],
         [1.457],
         [1.479],
         [1.627]],

        [[0.716],
         [2.189],
         [1.426],
         [1.235],
         [1.272],
         [1.735],
         [2.152],
         [1.740],
         [1.605],
         [1.778]],

        [[1.533],
         [1.114],
         [1.221],
         [1.181],
         [1.297],
         [2.172],
         [1.633],
         [1.602],
         [1.606],
         [1.880]],

        [[1.687],
         [1.238],
         [1.947],
         [1.778],
         [1.978],
         [1.544],
         [1.437],
         [1.952],
         [1.619],
         [1.540]],

        [[1.076],
         [1.199],
         [2.011],
         [1.916],
         [1.365],
         [1.443],
         [1.574],
         [1.552],
         [1.560],
         [1.295]],

        [[1.067],
         [1.793],
         [1.681],
         [1.662],
         [1.529],
         [1.156],
         [1.871],
         [1.103],
         [1.487],
         [1.404]],

        [[1.419],
         [1.600],
         [1.661],
         [1.400],
         [1.048],
         [1.681],
         [0.918],
         [1.533],
         [1.588],
         [2.038]],

        [[1.730],
         [1.173],
         [1.235],
         [1.921],
         [1.607],
         [1.306],
         [1.500],
         [1.339],
         [1.624],
         [1.172]],

        [[0.944],
         [1.277],
         [1.688],
         [1.446],
         [1.211],
         [1.462],
         [1.817],
         [1.247],
         [1.649],
         [1.683]],

        [[1.335],
         [2.019],
         [1.617],
         [1.419],
         [1.410],
         [1.084],
         [1.137],
         [1.100],
         [1.660],
         [1.727]],

        [[0.754],
         [1.763],
         [1.104],
         [1.316],
         [1.578],
         [2.066],
         [0.968],
         [1.010],
         [1.876],
         [1.581]],

        [[1.535],
         [0.884],
         [1.207],
         [1.688],
         [1.352],
         [1.197],
         [1.732],
         [1.476],
         [1.532],
         [1.722]],

        [[1.555],
         [1.652],
         [1.557],
         [1.336],
         [2.021],
         [1.458],
         [1.724],
         [1.688],
         [0.885],
         [1.804]],

        [[1.513],
         [1.762],
         [1.893],
         [1.268],
         [1.804],
         [1.804],
         [2.306],
         [1.691],
         [0.746],
         [1.699]],

        [[1.716],
         [1.610],
         [1.509],
         [1.988],
         [1.160],
         [1.760],
         [1.770],
         [1.357],
         [1.302],
         [1.692]],

        [[1.515],
         [1.190],
         [1.795],
         [1.869],
         [1.582],
         [1.432],
         [1.812],
         [1.234],
         [1.308],
         [1.173]],

        [[1.174],
         [0.947],
         [1.851],
         [1.563],
         [1.021],
         [1.250],
         [1.052],
         [2.068],
         [1.450],
         [1.860]],

        [[1.847],
         [1.471],
         [0.954],
         [1.580],
         [0.978],
         [1.164],
         [0.639],
         [1.816],
         [1.397],
         [1.395]],

        [[1.594],
         [1.087],
         [1.558],
         [1.535],
         [1.857],
         [1.223],
         [2.202],
         [1.586],
         [1.607],
         [1.087]],

        [[1.260],
         [1.626],
         [1.158],
         [1.599],
         [1.839],
         [1.901],
         [1.312],
         [1.619],
         [1.388],
         [1.041]],

        [[0.808],
         [1.220],
         [1.405],
         [1.409],
         [1.642],
         [1.559],
         [1.202],
         [1.542],
         [2.019],
         [1.127]],

        [[1.488],
         [1.368],
         [2.049],
         [1.251],
         [1.492],
         [1.215],
         [1.707],
         [1.368],
         [1.232],
         [1.543]]], device='cuda:0')
b after update for 1 param tensor([[[130.140],
         [138.336],
         [166.090],
         [141.589],
         [124.004],
         [126.945],
         [167.847],
         [126.886],
         [137.544],
         [128.410]],

        [[175.903],
         [131.247],
         [139.755],
         [150.948],
         [117.497],
         [138.898],
         [175.252],
         [146.280],
         [129.646],
         [173.424]],

        [[126.178],
         [146.049],
         [163.792],
         [111.809],
         [144.374],
         [146.389],
         [143.527],
         [145.324],
         [124.627],
         [165.251]],

        [[145.651],
         [152.282],
         [179.958],
         [136.685],
         [158.092],
         [139.626],
         [107.004],
         [186.829],
         [152.254],
         [140.317]],

        [[158.859],
         [144.527],
         [155.409],
         [159.597],
         [146.502],
         [122.557],
         [144.615],
         [151.602],
         [164.036],
         [144.285]],

        [[165.277],
         [163.372],
         [132.210],
         [145.755],
         [153.577],
         [137.693],
         [151.573],
         [164.937],
         [152.871],
         [155.451]],

        [[154.561],
         [140.019],
         [127.172],
         [146.946],
         [137.005],
         [141.234],
         [146.637],
         [136.698],
         [126.557],
         [159.513]],

        [[153.015],
         [152.659],
         [149.793],
         [152.683],
         [171.580],
         [122.679],
         [166.985],
         [166.407],
         [149.497],
         [161.060]],

        [[149.532],
         [126.043],
         [160.118],
         [145.534],
         [160.640],
         [133.316],
         [134.991],
         [147.370],
         [148.511],
         [155.749]],

        [[103.347],
         [180.649],
         [145.796],
         [135.702],
         [137.718],
         [160.844],
         [179.131],
         [161.083],
         [154.668],
         [162.827]],

        [[151.178],
         [128.844],
         [134.941],
         [132.697],
         [139.043],
         [179.938],
         [156.030],
         [154.546],
         [154.757],
         [167.432]],

        [[158.596],
         [135.830],
         [170.352],
         [162.808],
         [171.740],
         [151.703],
         [146.392],
         [170.596],
         [155.352],
         [151.535]],

        [[126.653],
         [133.674],
         [173.134],
         [168.998],
         [142.636],
         [146.691],
         [153.195],
         [152.109],
         [152.511],
         [138.943]],

        [[126.142],
         [163.491],
         [158.297],
         [157.403],
         [150.974],
         [131.269],
         [167.032],
         [128.229],
         [148.908],
         [144.688]],

        [[145.447],
         [154.465],
         [157.373],
         [144.475],
         [125.012],
         [158.325],
         [116.998],
         [151.201],
         [153.869],
         [174.300]],

        [[160.579],
         [132.264],
         [135.698],
         [169.217],
         [154.769],
         [139.520],
         [149.517],
         [141.277],
         [155.579],
         [132.165]],

        [[118.658],
         [137.960],
         [158.626],
         [146.837],
         [134.360],
         [147.622],
         [164.579],
         [136.346],
         [156.785],
         [158.382]],

        [[141.079],
         [173.511],
         [155.276],
         [145.435],
         [144.982],
         [127.133],
         [130.178],
         [128.066],
         [157.308],
         [160.438]],

        [[106.001],
         [162.110],
         [128.293],
         [140.084],
         [153.363],
         [175.500],
         [120.155],
         [122.684],
         [167.258],
         [153.513]],

        [[151.299],
         [114.773],
         [134.154],
         [158.617],
         [141.948],
         [133.568],
         [160.697],
         [148.330],
         [151.132],
         [160.208]],

        [[152.278],
         [156.944],
         [152.348],
         [141.130],
         [173.596],
         [147.429],
         [160.324],
         [158.651],
         [114.866],
         [164.015]],

        [[150.168],
         [162.093],
         [168.010],
         [137.516],
         [163.976],
         [163.985],
         [185.410],
         [158.778],
         [105.452],
         [159.152]],

        [[159.925],
         [154.938],
         [149.991],
         [172.166],
         [131.526],
         [161.999],
         [162.428],
         [142.232],
         [139.336],
         [158.835]],

        [[150.276],
         [133.209],
         [163.566],
         [166.921],
         [153.584],
         [146.108],
         [164.348],
         [135.630],
         [139.660],
         [132.253]],

        [[132.280],
         [118.810],
         [166.138],
         [152.642],
         [123.375],
         [136.513],
         [125.244],
         [175.597],
         [147.052],
         [166.499]],

        [[165.958],
         [148.104],
         [119.235],
         [153.454],
         [120.728],
         [131.730],
         [ 97.617],
         [164.531],
         [144.323],
         [144.198]],

        [[154.164],
         [127.298],
         [152.392],
         [151.281],
         [166.382],
         [135.026],
         [181.204],
         [153.778],
         [154.772],
         [127.282]],

        [[137.071],
         [155.708],
         [131.412],
         [154.420],
         [165.561],
         [168.331],
         [139.830],
         [155.355],
         [143.846],
         [124.553]],

        [[109.753],
         [134.846],
         [144.752],
         [144.924],
         [156.477],
         [152.443],
         [133.843],
         [151.607],
         [173.483],
         [129.641]],

        [[148.944],
         [142.836],
         [174.769],
         [136.580],
         [149.123],
         [134.609],
         [159.507],
         [142.793],
         [135.510],
         [151.648]]], device='cuda:0')
clipping threshold 0.18020771138435734
a after update for 1 param tensor([[ 0.078],
        [-0.205],
        [ 0.016],
        [ 0.011],
        [ 0.028],
        [-0.030],
        [-0.021],
        [-0.006],
        [ 0.084],
        [-0.091],
        [ 0.014],
        [ 0.108],
        [ 0.031],
        [ 0.002],
        [-0.023],
        [ 0.002],
        [ 0.020],
        [ 0.074],
        [ 0.041],
        [-0.036],
        [ 0.150],
        [ 0.108],
        [-0.047],
        [-0.062],
        [-0.016],
        [ 0.080],
        [ 0.029],
        [-0.005],
        [ 0.067],
        [ 0.043]], device='cuda:0')
s after update for 1 param tensor([[1.699],
        [2.169],
        [1.530],
        [1.435],
        [1.681],
        [1.690],
        [1.549],
        [1.371],
        [1.794],
        [1.476],
        [1.979],
        [1.945],
        [1.999],
        [1.947],
        [1.637],
        [1.357],
        [1.314],
        [1.609],
        [1.822],
        [1.915],
        [1.373],
        [1.437],
        [1.471],
        [1.211],
        [1.289],
        [1.563],
        [1.518],
        [1.668],
        [1.407],
        [0.913]], device='cuda:0')
b after update for 1 param tensor([[159.157],
        [179.828],
        [151.021],
        [146.288],
        [158.287],
        [158.742],
        [151.977],
        [142.954],
        [163.557],
        [148.364],
        [171.748],
        [170.279],
        [172.627],
        [170.388],
        [156.204],
        [142.244],
        [139.977],
        [154.856],
        [164.800],
        [168.950],
        [143.063],
        [146.360],
        [148.074],
        [134.356],
        [138.612],
        [152.626],
        [150.428],
        [157.714],
        [144.845],
        [116.664]], device='cuda:0')
clipping threshold 0.18020771138435734
||w||^2 0.0436148220953295
exp ma of ||w||^2 0.059612481801351785
||w|| 0.20884161964352196
exp ma of ||w|| 0.2388558653788113
||w||^2 0.08361456290607813
exp ma of ||w||^2 0.06864313739224669
||w|| 0.2891618282313178
exp ma of ||w|| 0.2558501589649429
||w||^2 0.09933173506789565
exp ma of ||w||^2 0.07138804746829773
||w|| 0.31516937520624627
exp ma of ||w|| 0.2617802883189968
||w||^2 0.05793062638289936
exp ma of ||w||^2 0.06682604619873579
||w|| 0.240687819348839
exp ma of ||w|| 0.25319769389124025
||w||^2 0.039809489369825965
exp ma of ||w||^2 0.060936452338312165
||w|| 0.19952315497161216
exp ma of ||w|| 0.2414764274821536
||w||^2 0.0835086484800695
exp ma of ||w||^2 0.0714191618112612
||w|| 0.2889786297982422
exp ma of ||w|| 0.2609604660791151
||w||^2 0.027669441390075728
exp ma of ||w||^2 0.07473639473004538
||w|| 0.16634133999122325
exp ma of ||w|| 0.267599598047198
||w||^2 0.09200174711474239
exp ma of ||w||^2 0.07595822884793424
||w|| 0.3033178977817537
exp ma of ||w|| 0.26910283262770873
||w||^2 0.0699977034975344
exp ma of ||w||^2 0.06941317766426024
||w|| 0.26457079108914194
exp ma of ||w|| 0.25655529266174326
||w||^2 0.07933269358443956
exp ma of ||w||^2 0.06827225073242245
||w|| 0.28166059998593973
exp ma of ||w|| 0.25583195706498957
cuda
Objective function 29.45 = squared loss an data 26.39 + 0.5*rho*h**2 0.479271 + alpha*h 1.634682 + L2reg 0.64 + L1reg 0.31 ; SHD = 55 ; DAG True
Proportion of microbatches that were clipped  0.7568332524664403
iteration 1 in inner loop, alpha 16.696586254294186 rho 100.0 h 0.09790513759502417
9630
cuda
Objective function 33.76 = squared loss an data 26.39 + 0.5*rho*h**2 4.792708 + alpha*h 1.634682 + L2reg 0.64 + L1reg 0.31 ; SHD = 55 ; DAG True
||w||^2 27913024.877407152
exp ma of ||w||^2 1515467445.0103576
||w|| 5283.277853511696
exp ma of ||w|| 27051.259375471578
||w||^2 1861.743360309727
exp ma of ||w||^2 12924380.562611133
||w|| 43.14792417150247
exp ma of ||w|| 504.2934854007966
||w||^2 0.09162660199150566
exp ma of ||w||^2 0.05904319895649785
||w|| 0.3026988635451175
exp ma of ||w|| 0.23834569792616725
||w||^2 0.06626760633588766
exp ma of ||w||^2 0.05887360721102837
||w|| 0.2574249528229298
exp ma of ||w|| 0.2382556247399948
||w||^2 0.053895954525036906
exp ma of ||w||^2 0.06157674383746248
||w|| 0.23215502261428012
exp ma of ||w|| 0.2430509044680626
||w||^2 0.05748656797304229
exp ma of ||w||^2 0.06669369856426102
||w|| 0.23976356681748437
exp ma of ||w|| 0.2526416283990014
||w||^2 0.06876864936877225
exp ma of ||w||^2 0.06589199792272721
||w|| 0.26223777258200665
exp ma of ||w|| 0.2517901186350502
||w||^2 0.0400464152775647
exp ma of ||w||^2 0.06710838984891712
||w|| 0.20011600455127196
exp ma of ||w|| 0.2529110038342887
||w||^2 0.04451749983145832
exp ma of ||w||^2 0.06204982052155811
||w|| 0.2109917055987233
exp ma of ||w|| 0.24342842676389928
||w||^2 0.05954073019504744
exp ma of ||w||^2 0.06257019726357717
||w|| 0.24400969283011573
exp ma of ||w|| 0.2450746501167607
||w||^2 0.0370457999760179
exp ma of ||w||^2 0.06349979165118148
||w|| 0.19247285516669072
exp ma of ||w|| 0.24538793973803333
||w||^2 0.03706857515940226
exp ma of ||w||^2 0.06450109137914144
||w|| 0.192532010739519
exp ma of ||w|| 0.2477561882392981
||w||^2 0.05597884991967089
exp ma of ||w||^2 0.06436657008618617
||w|| 0.23659849940282987
exp ma of ||w|| 0.2484775842118384
||w||^2 0.05405091047821692
exp ma of ||w||^2 0.06545723118861493
||w|| 0.23248851687388114
exp ma of ||w|| 0.2501466286873015
cuda
Objective function 29.27 = squared loss an data 26.66 + 0.5*rho*h**2 0.916728 + alpha*h 0.714929 + L2reg 0.69 + L1reg 0.29 ; SHD = 56 ; DAG True
Proportion of microbatches that were clipped  0.7608124253285543
iteration 2 in inner loop, alpha 16.696586254294186 rho 1000.0 h 0.04281886854823114
9630
cuda
Objective function 37.52 = squared loss an data 26.66 + 0.5*rho*h**2 9.167278 + alpha*h 0.714929 + L2reg 0.69 + L1reg 0.29 ; SHD = 56 ; DAG True
||w||^2 2211314805.095424
exp ma of ||w||^2 31389238468.14478
||w|| 47024.61913822826
exp ma of ||w|| 131838.4289727634
||w||^2 1354048.8624835236
exp ma of ||w||^2 1031135087.1102147
||w|| 1163.6360524165293
exp ma of ||w|| 8303.02884207929
||w||^2 0.04210423065316847
exp ma of ||w||^2 3.759100405556871
||w|| 0.20519315449880016
exp ma of ||w|| 0.24803076565065837
||w||^2 0.07585800790649097
exp ma of ||w||^2 1.260221561467427
||w|| 0.27542332491365173
exp ma of ||w|| 0.2442223206634193
||w||^2 0.03004044308541611
exp ma of ||w||^2 0.6481494489716014
||w|| 0.1733217905671878
exp ma of ||w|| 0.24347360533082343
||w||^2 0.032970037932903096
exp ma of ||w||^2 0.06860181193436095
||w|| 0.1815765346428417
exp ma of ||w|| 0.25520430831035723
||w||^2 0.04164131510464261
exp ma of ||w||^2 0.06602836765112831
||w|| 0.2040620373921681
exp ma of ||w|| 0.25133138427548807
||w||^2 0.10616835834490725
exp ma of ||w||^2 0.07147346064318032
||w|| 0.32583486361177993
exp ma of ||w|| 0.2620773091853889
||w||^2 0.046510224444203205
exp ma of ||w||^2 0.0666126053166875
||w|| 0.2156622925877475
exp ma of ||w|| 0.25260136070763956
||w||^2 0.0677357449421183
exp ma of ||w||^2 0.0714845967836224
||w|| 0.2602609170469479
exp ma of ||w|| 0.2619769951136474
||w||^2 0.13677093928699388
exp ma of ||w||^2 0.07134667970362037
||w|| 0.36982555250684596
exp ma of ||w|| 0.2620862466274838
||w||^2 0.05005877340601914
exp ma of ||w||^2 0.07056499757688027
||w|| 0.22373818048339256
exp ma of ||w|| 0.2605472977617089
v before min max tensor([[ 4.784, -2.392,  0.135,  ..., -3.956, -2.141,  0.121],
        [38.639,  3.211, -0.908,  ..., -4.047, -6.743, -2.711],
        [-4.942,  3.607, -3.934,  ..., 75.687, -6.714, -5.616],
        ...,
        [10.471, -6.899, -6.435,  ..., -7.024, -5.192, -6.461],
        [-6.743, 16.478, -7.712,  ...,  9.596, -5.506,  4.239],
        [ 2.557,  6.412, -7.257,  ..., -3.506,  0.959, -7.436]],
       device='cuda:0')
v tensor([[4.784e+00, 1.000e-12, 1.346e-01,  ..., 1.000e-12, 1.000e-12,
         1.208e-01],
        [1.000e+01, 3.211e+00, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 3.607e+00, 1.000e-12,  ..., 1.000e+01, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 9.596e+00, 1.000e-12,
         4.239e+00],
        [2.557e+00, 6.412e+00, 1.000e-12,  ..., 1.000e-12, 9.593e-01,
         1.000e-12]], device='cuda:0')
v before min max tensor([-2.259e-01,  1.031e+00, -7.841e+00, -7.962e+00, -7.755e-01,  4.099e-03,
         2.640e+00, -5.902e+00, -6.919e+00,  9.853e+00,  6.760e+00,  3.656e+00,
        -2.592e+00, -3.205e+00, -6.855e+00,  1.333e+01, -4.981e+00, -4.755e+00,
         3.929e+00,  1.567e+01,  2.681e+00, -4.825e+00, -1.285e+00, -5.786e+00,
         5.793e+00,  2.100e+00, -8.243e+00, -1.328e+00,  1.732e+00, -5.833e+00,
         4.492e+00, -1.769e+00, -1.936e+00, -5.114e+00,  5.683e+00, -1.545e+00,
        -3.227e+00, -4.450e+00, -4.215e+00,  7.703e+00, -3.100e+00,  1.255e+00,
        -3.918e+00, -2.970e+00,  8.232e+00,  5.581e+00,  3.061e+01, -4.682e+00,
         4.042e+01, -1.920e+00, -2.507e+00,  3.168e+00, -4.696e+00, -7.597e+00,
         3.435e+00, -3.243e+00,  3.961e+00, -6.760e+00, -6.253e+00, -5.620e+00,
        -4.323e+00, -6.269e+00, -2.332e+00, -1.227e+00, -5.304e+00, -5.765e+00,
         2.675e+00, -2.726e+00,  1.378e+01, -2.716e+00,  1.204e+01, -6.926e+00,
        -4.845e+00, -4.019e+00, -4.430e+00, -2.805e+00,  6.392e+00, -5.860e+00,
        -6.805e+00, -4.757e+00, -5.288e+00, -5.583e+00, -6.758e+00,  8.352e+00,
        -4.538e+00, -5.465e+00, -2.113e+00,  2.753e+00, -5.419e+00, -1.363e+00,
        -1.880e+00,  2.824e+00, -7.552e-01, -2.907e+00,  8.217e-01, -5.680e+00,
        -4.477e+00, -5.875e+00, -3.770e+00, -3.022e+00, -3.330e-01,  2.798e+01,
        -2.979e+00,  1.259e+00, -3.427e+00, -5.794e+00, -7.634e+00, -2.048e+00,
        -7.264e+00,  3.204e+00, -5.031e+00, -2.612e+00, -1.542e+00,  6.556e+00,
        -2.351e+00,  1.000e+01,  7.194e+00,  2.954e+00, -5.262e+00, -5.097e+00,
        -2.123e+00,  7.717e+00, -5.966e+00, -6.863e+00, -4.912e+00, -1.064e+00,
        -4.119e+00, -3.748e+00,  1.970e+01, -3.526e+00,  3.690e+00,  1.023e+01,
        -6.225e+00, -2.436e+00,  3.608e+00, -3.972e+00, -5.969e+00, -1.915e+00,
        -2.245e+00, -5.525e+00, -4.474e+00, -2.249e+00, -4.027e+00,  4.108e+00,
        -2.358e+00, -4.060e+00, -3.314e+00, -8.151e+00, -1.365e+00, -6.276e+00,
        -5.944e+00, -1.432e+00,  2.802e+01, -5.717e+00, -4.859e+00,  7.822e-01,
         5.928e+00, -6.959e+00,  2.645e+00, -4.937e+00, -1.229e+00, -5.282e+00,
        -1.640e+00, -3.425e+00, -2.821e+00, -5.155e+00, -2.559e+00, -5.323e+00,
        -5.927e+00, -3.331e+00,  3.098e+01, -6.676e+00,  7.249e+00, -3.535e+00,
        -2.997e+00, -3.873e+00, -2.626e+00, -3.877e+00,  5.257e-01, -5.001e+00,
        -5.103e+00,  1.705e+00, -5.835e+00, -4.901e+00, -4.932e+00, -3.223e+00,
        -2.322e+00, -3.613e+00, -4.163e+00, -5.117e+00,  1.229e+01, -2.991e+00,
         1.807e+01, -6.590e+00,  6.779e-01,  1.099e-01, -5.484e+00,  8.841e+00,
        -1.535e+00, -4.048e+00, -5.125e+00,  6.832e-02, -7.616e+00,  4.736e-01,
         1.919e+00, -3.046e+00, -4.616e+00,  1.688e+01,  4.547e+00, -5.504e+00,
        -4.809e+00, -4.419e+00, -4.067e+00,  8.947e-01,  6.675e-01, -2.713e+00,
        -6.925e+00, -7.643e-01, -4.019e+00,  3.343e+00,  1.440e+01, -5.102e+00,
        -5.663e+00, -1.563e+00,  2.024e+01,  4.292e+00, -4.965e+00, -2.568e+00,
        -5.736e+00, -3.950e+00, -5.442e+00, -5.851e+00, -2.218e+00,  9.507e+00,
         2.649e+00, -4.324e+00,  1.225e+01, -6.051e+00, -6.842e+00,  2.115e+01,
         1.714e+01,  1.017e+01, -4.037e+00, -6.586e+00, -1.160e+00, -1.666e-01,
        -7.593e+00, -2.356e+00, -6.213e+00, -6.908e+00,  2.590e+00, -5.286e+00,
        -4.605e-01, -5.202e+00, -6.552e+00, -5.984e+00, -5.432e+00,  7.598e+00,
        -5.792e+00, -3.982e+00,  5.084e-01, -2.247e+00,  5.345e+00, -4.606e+00,
        -4.220e+00, -5.338e+00, -3.184e+00, -3.444e+00,  6.041e+00, -3.389e+00,
        -3.665e+00, -2.654e+00, -3.435e+00,  6.688e+00, -4.311e+00,  6.417e+00,
        -5.829e+00, -3.856e+00, -2.364e+00, -6.165e+00,  1.163e+00, -3.870e+00,
        -6.532e+00, -5.531e+00, -4.198e-02,  1.862e+00,  6.067e-01, -2.703e+00,
        -5.005e+00,  6.847e+00, -6.176e+00, -5.240e+00, -8.022e-02,  1.665e+01,
        -5.809e+00, -3.652e+00, -3.734e+00,  8.737e-02,  4.003e+00, -2.054e+00],
       device='cuda:0')
v tensor([1.000e-12, 1.031e+00, 1.000e-12, 1.000e-12, 1.000e-12, 4.099e-03,
        2.640e+00, 1.000e-12, 1.000e-12, 9.853e+00, 6.760e+00, 3.656e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        3.929e+00, 1.000e+01, 2.681e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        5.793e+00, 2.100e+00, 1.000e-12, 1.000e-12, 1.732e+00, 1.000e-12,
        4.492e+00, 1.000e-12, 1.000e-12, 1.000e-12, 5.683e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 7.703e+00, 1.000e-12, 1.255e+00,
        1.000e-12, 1.000e-12, 8.232e+00, 5.581e+00, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 3.168e+00, 1.000e-12, 1.000e-12,
        3.435e+00, 1.000e-12, 3.961e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        2.675e+00, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 6.392e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 8.352e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 2.753e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 2.824e+00, 1.000e-12, 1.000e-12, 8.217e-01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.259e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 3.204e+00, 1.000e-12, 1.000e-12, 1.000e-12, 6.556e+00,
        1.000e-12, 1.000e+01, 7.194e+00, 2.954e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 7.717e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 3.690e+00, 1.000e+01,
        1.000e-12, 1.000e-12, 3.608e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 4.108e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 7.822e-01,
        5.928e+00, 1.000e-12, 2.645e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 7.249e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.257e-01, 1.000e-12,
        1.000e-12, 1.705e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 6.779e-01, 1.099e-01, 1.000e-12, 8.841e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 6.832e-02, 1.000e-12, 4.736e-01,
        1.919e+00, 1.000e-12, 1.000e-12, 1.000e+01, 4.547e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 8.947e-01, 6.675e-01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 3.343e+00, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 4.292e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 9.507e+00,
        2.649e+00, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.590e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 7.598e+00,
        1.000e-12, 1.000e-12, 5.084e-01, 1.000e-12, 5.345e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 6.041e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 6.688e+00, 1.000e-12, 6.417e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.163e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.862e+00, 6.067e-01, 1.000e-12,
        1.000e-12, 6.847e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 8.737e-02, 4.003e+00, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-5.411],
         [-2.892],
         [-5.030],
         [-1.062],
         [ 4.851],
         [13.513],
         [-5.825],
         [-3.968],
         [-5.720],
         [ 7.047]],

        [[-5.646],
         [-2.884],
         [ 7.524],
         [-4.679],
         [-1.798],
         [ 5.130],
         [24.716],
         [-6.702],
         [-8.498],
         [-5.101]],

        [[ 4.418],
         [-2.328],
         [-6.092],
         [-5.246],
         [-6.676],
         [20.569],
         [-5.092],
         [ 1.798],
         [-2.648],
         [10.867]],

        [[ 0.211],
         [-5.173],
         [-4.798],
         [-4.482],
         [ 3.494],
         [-3.983],
         [ 7.999],
         [ 3.883],
         [-5.119],
         [-4.314]],

        [[-2.703],
         [-4.563],
         [ 5.723],
         [-4.467],
         [-1.992],
         [-4.792],
         [-7.066],
         [ 0.186],
         [-6.835],
         [-2.870]],

        [[66.270],
         [-2.808],
         [25.516],
         [-5.448],
         [-7.569],
         [23.539],
         [-6.155],
         [-1.633],
         [13.180],
         [-3.989]],

        [[ 8.477],
         [-6.231],
         [-3.007],
         [62.042],
         [16.281],
         [-4.816],
         [-2.743],
         [-0.714],
         [ 0.234],
         [-4.646]],

        [[-2.517],
         [-1.510],
         [-4.314],
         [-5.052],
         [-4.383],
         [ 0.788],
         [-5.163],
         [ 0.328],
         [-6.156],
         [ 2.429]],

        [[18.369],
         [ 1.786],
         [-5.487],
         [-6.821],
         [ 1.728],
         [-7.585],
         [-7.478],
         [-5.065],
         [-4.475],
         [16.088]],

        [[ 4.576],
         [ 2.854],
         [-6.544],
         [-0.400],
         [-5.089],
         [-3.969],
         [-6.091],
         [-5.107],
         [-3.136],
         [62.361]],

        [[-7.650],
         [-5.201],
         [-7.315],
         [-1.624],
         [-6.045],
         [-6.277],
         [ 0.069],
         [-5.250],
         [ 2.567],
         [10.480]],

        [[20.279],
         [-5.900],
         [-4.458],
         [-3.681],
         [-3.471],
         [-6.358],
         [13.966],
         [-6.452],
         [17.253],
         [ 2.352]],

        [[-2.859],
         [-3.946],
         [ 0.092],
         [-0.920],
         [-1.503],
         [ 0.090],
         [-1.852],
         [ 9.392],
         [-7.042],
         [10.663]],

        [[-3.453],
         [-1.671],
         [-4.375],
         [-6.577],
         [-4.502],
         [ 2.454],
         [10.002],
         [-3.181],
         [-0.441],
         [-3.933]],

        [[-1.663],
         [-5.551],
         [ 5.622],
         [ 1.620],
         [ 0.321],
         [-7.853],
         [-4.526],
         [ 1.678],
         [-7.340],
         [14.193]],

        [[-5.542],
         [ 8.861],
         [-3.510],
         [-6.219],
         [ 0.888],
         [-6.708],
         [-2.950],
         [-3.557],
         [23.269],
         [-2.362]],

        [[-4.441],
         [-4.326],
         [-3.578],
         [-4.434],
         [-7.668],
         [-5.480],
         [ 3.920],
         [-7.648],
         [11.084],
         [26.253]],

        [[-5.379],
         [-1.960],
         [ 5.662],
         [-0.500],
         [-3.612],
         [-8.137],
         [-7.662],
         [-4.581],
         [ 8.559],
         [ 6.410]],

        [[-3.693],
         [-3.425],
         [-5.791],
         [ 3.375],
         [-0.629],
         [ 3.209],
         [-3.976],
         [ 0.467],
         [-6.335],
         [-5.915]],

        [[-4.700],
         [ 7.129],
         [-5.057],
         [-8.823],
         [-1.918],
         [-3.303],
         [-4.120],
         [-2.331],
         [-4.160],
         [-2.142]],

        [[ 3.655],
         [-4.344],
         [ 6.093],
         [16.927],
         [ 1.883],
         [-6.964],
         [21.496],
         [-4.637],
         [-2.006],
         [11.358]],

        [[-3.575],
         [16.260],
         [-7.995],
         [-6.218],
         [-5.661],
         [ 1.982],
         [-1.059],
         [-0.920],
         [15.985],
         [-6.146]],

        [[ 1.681],
         [-0.976],
         [-5.084],
         [-1.711],
         [-4.503],
         [-5.964],
         [-6.479],
         [-3.197],
         [ 3.287],
         [-0.262]],

        [[-4.702],
         [-1.259],
         [-4.122],
         [13.650],
         [12.874],
         [-5.145],
         [-3.632],
         [-6.605],
         [-3.046],
         [ 5.040]],

        [[-3.689],
         [-7.883],
         [-2.193],
         [17.443],
         [ 6.843],
         [-2.821],
         [-7.560],
         [-5.408],
         [ 4.677],
         [-1.761]],

        [[-6.235],
         [-6.095],
         [ 0.618],
         [ 0.231],
         [-3.423],
         [-6.093],
         [-3.145],
         [53.342],
         [-2.647],
         [12.615]],

        [[-5.350],
         [-4.791],
         [ 5.931],
         [-1.598],
         [-6.209],
         [-1.130],
         [-5.901],
         [-0.171],
         [-9.151],
         [-0.909]],

        [[ 1.985],
         [-2.694],
         [-3.347],
         [-3.157],
         [22.130],
         [27.057],
         [-1.440],
         [ 1.158],
         [-0.959],
         [-1.915]],

        [[-7.508],
         [-3.456],
         [ 7.219],
         [ 3.207],
         [34.589],
         [-8.196],
         [10.917],
         [ 5.911],
         [-5.170],
         [-0.855]],

        [[26.144],
         [14.877],
         [-3.623],
         [-5.046],
         [-0.494],
         [ 0.759],
         [21.592],
         [-3.489],
         [-5.114],
         [-3.734]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.851e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.047e+00]],

        [[1.000e-12],
         [1.000e-12],
         [7.524e+00],
         [1.000e-12],
         [1.000e-12],
         [5.130e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[4.418e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.798e+00],
         [1.000e-12],
         [1.000e+01]],

        [[2.111e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.494e+00],
         [1.000e-12],
         [7.999e+00],
         [3.883e+00],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [5.723e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.857e-01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[8.477e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.339e-01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.884e-01],
         [1.000e-12],
         [3.282e-01],
         [1.000e-12],
         [2.429e+00]],

        [[1.000e+01],
         [1.786e+00],
         [1.000e-12],
         [1.000e-12],
         [1.728e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[4.576e+00],
         [2.854e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.859e-02],
         [1.000e-12],
         [2.567e+00],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [2.352e+00]],

        [[1.000e-12],
         [1.000e-12],
         [9.154e-02],
         [1.000e-12],
         [1.000e-12],
         [8.983e-02],
         [1.000e-12],
         [9.392e+00],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.454e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [5.622e+00],
         [1.620e+00],
         [3.213e-01],
         [1.000e-12],
         [1.000e-12],
         [1.678e+00],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [8.861e+00],
         [1.000e-12],
         [1.000e-12],
         [8.880e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.920e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [5.662e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [8.559e+00],
         [6.410e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.375e+00],
         [1.000e-12],
         [3.209e+00],
         [1.000e-12],
         [4.668e-01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [7.129e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[3.655e+00],
         [1.000e-12],
         [6.093e+00],
         [1.000e+01],
         [1.883e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.982e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.681e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.287e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.040e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [6.843e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.677e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [6.183e-01],
         [2.309e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [5.931e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.985e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.158e+00],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [7.219e+00],
         [3.207e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [5.911e+00],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.594e-01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[-1.043],
        [ 6.037],
        [-5.328],
        [ 4.911],
        [69.111],
        [-5.006],
        [-4.557],
        [-5.969],
        [-6.237],
        [ 6.445],
        [-1.035],
        [ 3.047],
        [-7.001],
        [-5.169],
        [-6.170],
        [-4.407],
        [-5.630],
        [-1.441],
        [-5.156],
        [-0.239],
        [-5.220],
        [-4.373],
        [-6.056],
        [-6.495],
        [-3.128],
        [-3.749],
        [-4.867],
        [-1.168],
        [-2.975],
        [-5.673]], device='cuda:0')
v tensor([[1.000e-12],
        [6.037e+00],
        [1.000e-12],
        [4.911e+00],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [6.445e+00],
        [1.000e-12],
        [3.047e+00],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-0.005, -0.009,  0.008,  ..., -0.034,  0.013, -0.014],
        [ 0.008,  0.035,  0.014,  ..., -0.028, -0.001,  0.010],
        [ 0.003, -0.041,  0.012,  ..., -0.033, -0.003,  0.016],
        ...,
        [ 0.008,  0.011, -0.014,  ...,  0.058, -0.004,  0.000],
        [ 0.005,  0.005,  0.017,  ...,  0.014, -0.005, -0.002],
        [-0.003,  0.011,  0.004,  ...,  0.056,  0.008, -0.011]],
       device='cuda:0')
s after update for 1 param tensor([[1.117, 0.575, 1.298,  ..., 1.770, 0.897, 1.226],
        [2.196, 1.054, 1.081,  ..., 1.408, 1.612, 0.600],
        [1.377, 0.984, 1.023,  ..., 2.168, 1.466, 1.311],
        ...,
        [1.385, 1.603, 1.413,  ..., 1.776, 1.276, 1.424],
        [1.475, 1.406, 1.720,  ..., 1.433, 1.336, 1.268],
        [1.486, 1.388, 1.687,  ..., 1.644, 1.094, 1.693]], device='cuda:0')
b after update for 1 param tensor([[123.094,  88.295, 132.702,  ..., 154.979, 110.328, 128.985],
        [172.612, 119.570, 121.116,  ..., 138.217, 147.863,  90.242],
        [136.653, 115.545, 117.820,  ..., 171.504, 141.024, 133.386],
        ...,
        [137.059, 147.454, 138.473,  ..., 155.208, 131.576, 138.974],
        [141.455, 138.096, 152.771,  ..., 139.440, 134.650, 131.162],
        [141.968, 137.223, 151.300,  ..., 149.327, 121.850, 151.569]],
       device='cuda:0')
clipping threshold 0.2093895742663162
a after update for 1 param tensor([-0.010,  0.043, -0.007,  0.019, -0.028,  0.003, -0.008,  0.029,  0.006,
        -0.011,  0.008,  0.014, -0.048,  0.056,  0.021,  0.010, -0.003, -0.006,
         0.057,  0.003,  0.009,  0.002,  0.079,  0.043,  0.045, -0.023, -0.037,
        -0.005,  0.004,  0.034, -0.048,  0.040, -0.032, -0.004,  0.028, -0.010,
         0.006, -0.041, -0.038,  0.000, -0.019, -0.036, -0.024, -0.054,  0.005,
         0.024,  0.043, -0.008, -0.033,  0.017, -0.012,  0.059, -0.008, -0.005,
        -0.038,  0.044, -0.053,  0.015,  0.005, -0.005, -0.019,  0.006,  0.024,
        -0.040, -0.081,  0.078,  0.009, -0.011,  0.059, -0.006,  0.006, -0.044,
         0.025,  0.017, -0.006,  0.010, -0.002,  0.006, -0.046, -0.004, -0.012,
         0.021, -0.016,  0.034, -0.034, -0.020,  0.027, -0.007, -0.043, -0.057,
         0.008,  0.025, -0.007, -0.012, -0.013, -0.018,  0.002, -0.019, -0.007,
         0.028, -0.002,  0.096, -0.008, -0.044, -0.002,  0.016, -0.020,  0.018,
         0.006, -0.037,  0.016,  0.018, -0.082, -0.049, -0.027,  0.030,  0.041,
        -0.026,  0.019, -0.043, -0.025, -0.022, -0.012, -0.025,  0.014,  0.058,
         0.000,  0.030, -0.016, -0.012,  0.003,  0.004, -0.034,  0.037,  0.009,
        -0.026,  0.002,  0.032,  0.012, -0.019, -0.008, -0.005, -0.028,  0.024,
        -0.010, -0.024,  0.005, -0.024, -0.021,  0.014,  0.015, -0.009,  0.031,
        -0.005,  0.012,  0.004,  0.011, -0.011, -0.046, -0.042, -0.008,  0.005,
         0.017,  0.026,  0.001, -0.009, -0.022, -0.012, -0.015,  0.015, -0.001,
         0.004, -0.009, -0.030, -0.007,  0.034,  0.010, -0.009,  0.008,  0.027,
         0.009, -0.006,  0.010,  0.003, -0.017, -0.008, -0.009,  0.060, -0.027,
         0.030,  0.012,  0.028,  0.012, -0.019, -0.007,  0.038,  0.033,  0.028,
         0.025,  0.026,  0.019, -0.020,  0.032, -0.018,  0.062,  0.056,  0.038,
        -0.014, -0.027, -0.002,  0.013,  0.013,  0.044, -0.030,  0.048,  0.012,
        -0.041, -0.021,  0.023, -0.050, -0.033, -0.015,  0.028, -0.009, -0.006,
         0.019,  0.008,  0.020,  0.007,  0.046, -0.001, -0.038, -0.048,  0.011,
        -0.017, -0.040,  0.009, -0.014, -0.008,  0.020,  0.026,  0.007, -0.006,
         0.041, -0.040,  0.008,  0.013,  0.029, -0.063,  0.016, -0.022,  0.001,
         0.069, -0.002, -0.015,  0.010, -0.001,  0.034,  0.043, -0.023,  0.006,
        -0.023, -0.001, -0.009, -0.037, -0.044, -0.029,  0.026, -0.002, -0.025,
         0.019, -0.013, -0.059, -0.013,  0.008, -0.016, -0.007,  0.017, -0.004,
        -0.059,  0.016, -0.017, -0.014, -0.010,  0.020, -0.012,  0.026,  0.050,
         0.003, -0.039,  0.022, -0.046, -0.075,  0.004,  0.008,  0.034, -0.044,
         0.010,  0.064,  0.029], device='cuda:0')
s after update for 1 param tensor([1.098, 1.245, 1.708, 1.736, 1.081, 1.372, 1.669, 1.295, 1.567, 1.971,
        2.011, 1.110, 1.119, 0.770, 1.638, 1.418, 1.093, 1.820, 1.539, 1.544,
        1.674, 1.149, 1.264, 1.334, 1.218, 1.495, 1.951, 1.050, 1.176, 1.549,
        1.097, 0.887, 0.507, 1.134, 1.448, 1.786, 0.787, 1.284, 0.957, 1.806,
        1.501, 0.846, 1.592, 0.767, 1.986, 1.293, 1.509, 1.832, 1.792, 1.336,
        1.633, 1.116, 1.517, 1.918, 1.480, 1.354, 1.447, 1.501, 1.482, 1.232,
        1.266, 1.478, 0.784, 1.290, 1.218, 1.329, 1.342, 0.608, 1.565, 1.401,
        1.408, 1.517, 1.192, 1.634, 1.306, 0.739, 1.651, 1.291, 1.483, 1.685,
        1.181, 1.337, 1.547, 1.855, 1.194, 1.447, 1.363, 1.303, 1.229, 1.067,
        1.536, 1.435, 0.852, 0.952, 1.117, 1.241, 1.116, 1.448, 1.374, 1.201,
        1.302, 1.861, 0.668, 1.070, 0.825, 1.485, 1.664, 1.389, 1.590, 1.957,
        1.560, 1.173, 0.939, 2.003, 1.128, 1.787, 1.841, 0.978, 1.349, 1.404,
        0.652, 1.625, 1.342, 1.496, 1.071, 0.642, 1.324, 1.242, 1.843, 1.062,
        1.285, 2.005, 1.359, 1.358, 1.165, 0.962, 1.383, 0.734, 0.490, 1.206,
        1.862, 0.989, 1.288, 1.335, 1.805, 1.739, 0.957, 1.790, 0.692, 1.413,
        1.663, 0.816, 1.840, 1.337, 1.073, 0.977, 1.478, 1.691, 1.226, 1.082,
        1.038, 1.263, 0.895, 0.924, 0.615, 1.616, 1.229, 1.205, 1.346, 0.902,
        1.616, 1.637, 1.193, 0.772, 0.833, 1.283, 0.932, 0.928, 0.599, 1.288,
        1.141, 1.132, 1.719, 1.070, 1.338, 0.771, 1.111, 0.944, 1.131, 1.244,
        1.525, 1.288, 2.097, 1.713, 0.997, 1.574, 1.198, 1.405, 1.010, 1.326,
        1.574, 1.282, 1.792, 1.088, 1.341, 1.299, 1.482, 1.407, 1.329, 1.199,
        1.198, 1.907, 1.670, 1.505, 0.552, 1.134, 1.541, 0.430, 0.916, 1.460,
        1.907, 1.879, 1.947, 0.852, 1.760, 1.425, 1.227, 1.241, 1.290, 1.226,
        1.351, 1.451, 0.704, 1.283, 1.727, 1.040, 1.648, 1.456, 1.775, 1.800,
        1.689, 1.882, 0.881, 1.447, 1.397, 1.121, 1.655, 0.907, 1.359, 1.537,
        1.041, 1.297, 1.226, 1.228, 1.507, 1.367, 1.274, 1.462, 1.262, 1.028,
        0.894, 0.496, 1.497, 1.436, 0.963, 1.226, 1.177, 0.833, 1.886, 0.824,
        0.884, 1.412, 1.073, 1.310, 1.047, 1.508, 1.376, 0.994, 1.158, 1.555,
        0.783, 0.929, 1.534, 1.207, 1.900, 0.629, 1.118, 1.070, 1.481, 1.480,
        1.347, 1.148, 1.215, 1.802, 1.267, 0.977, 1.399, 0.847, 0.980, 1.140],
       device='cuda:0')
b after update for 1 param tensor([122.029, 129.961, 152.235, 153.456, 121.117, 136.411, 150.474, 132.551,
        145.805, 163.537, 165.163, 122.694, 123.188, 102.190, 149.067, 138.693,
        121.786, 157.114, 144.502, 144.722, 150.681, 124.845, 130.935, 134.548,
        128.548, 142.427, 162.676, 119.373, 126.284, 144.978, 121.983, 109.725,
         82.914, 124.030, 140.168, 155.675, 103.324, 131.968, 113.960, 156.516,
        142.695, 107.141, 146.957, 102.000, 164.141, 132.448, 143.086, 157.665,
        155.899, 134.604, 148.852, 123.070, 143.475, 161.324, 141.711, 135.507,
        140.121, 142.696, 141.800, 129.289, 131.052, 141.580, 103.147, 132.270,
        128.565, 134.268, 134.927,  90.789, 145.708, 137.863, 138.193, 143.437,
        127.173, 148.889, 133.115, 100.134, 149.672, 132.335, 141.841, 151.213,
        126.553, 134.676, 144.882, 158.624, 127.246, 140.120, 135.958, 132.934,
        129.108, 120.304, 144.343, 139.521, 107.531, 113.664, 123.098, 129.739,
        123.047, 140.147, 136.548, 127.620, 132.877, 158.907,  95.185, 120.496,
        105.765, 141.955, 150.235, 137.283, 146.863, 162.918, 145.489, 126.142,
        112.870, 164.825, 123.678, 155.688, 158.035, 115.191, 135.303, 137.991,
         94.058, 148.467, 134.919, 142.473, 120.555,  93.342, 133.999, 129.796,
        158.102, 120.005, 132.043, 164.910, 135.761, 135.706, 125.729, 114.256,
        136.968,  99.793,  81.504, 127.902, 158.933, 115.805, 132.164, 134.591,
        156.466, 153.596, 113.916, 155.827,  96.917, 138.460, 150.179, 105.217,
        157.993, 134.665, 120.659, 115.129, 141.607, 151.439, 128.991, 121.170,
        118.685, 130.872, 110.214, 111.964,  91.352, 148.055, 129.130, 127.836,
        135.152, 110.628, 148.069, 149.030, 127.232, 102.316, 106.296, 131.925,
        112.454, 112.190,  90.121, 132.201, 124.405, 123.908, 152.722, 120.460,
        134.748, 102.301, 122.785, 113.146, 123.856, 129.905, 143.830, 132.179,
        168.672, 152.428, 116.284, 146.104, 127.485, 138.038, 117.047, 134.111,
        146.130, 131.875, 155.938, 121.502, 134.855, 132.771, 141.774, 138.148,
        134.274, 127.546, 127.501, 160.858, 150.515, 142.899,  86.522, 124.015,
        144.584,  76.400, 111.466, 140.711, 160.829, 159.643, 162.531, 107.507,
        154.527, 139.048, 129.031, 129.741, 132.276, 128.954, 135.400, 140.304,
         97.748, 131.950, 153.077, 118.791, 149.539, 140.559, 155.184, 156.282,
        151.393, 159.768, 109.342, 140.127, 137.682, 123.301, 149.853, 110.951,
        135.757, 144.386, 118.842, 132.660, 128.972, 129.086, 142.987, 136.181,
        131.469, 140.845, 130.852, 118.106, 110.125,  82.041, 142.530, 139.576,
        114.275, 128.977, 126.347, 106.302, 159.967, 105.733, 109.524, 138.408,
        120.635, 133.291, 119.199, 143.044, 136.649, 116.108, 125.320, 145.259,
        103.058, 112.253, 144.237, 127.965, 160.558,  92.349, 123.143, 120.507,
        141.733, 141.679, 135.192, 124.801, 128.392, 156.350, 131.083, 115.127,
        137.784, 107.189, 115.292, 124.362], device='cuda:0')
clipping threshold 0.2093895742663162
a after update for 1 param tensor([[[-5.675e-03],
         [ 4.875e-02],
         [ 9.147e-03],
         [-2.674e-02],
         [ 3.426e-03],
         [-8.184e-03],
         [-4.683e-02],
         [-3.507e-03],
         [ 5.561e-03],
         [ 2.837e-02]],

        [[-1.631e-02],
         [-5.727e-02],
         [ 6.733e-02],
         [-3.296e-02],
         [ 1.473e-02],
         [-1.202e-02],
         [ 1.410e-02],
         [-3.917e-02],
         [-3.630e-02],
         [ 3.349e-02]],

        [[-1.918e-02],
         [ 1.182e-02],
         [ 3.282e-02],
         [ 2.977e-02],
         [ 1.946e-02],
         [ 9.182e-03],
         [ 1.702e-03],
         [-8.807e-04],
         [-2.351e-02],
         [ 8.853e-03]],

        [[ 2.448e-04],
         [-4.067e-02],
         [-6.196e-02],
         [ 4.011e-02],
         [-2.016e-03],
         [ 5.419e-02],
         [-2.203e-02],
         [ 1.291e-02],
         [ 3.250e-02],
         [ 2.475e-03]],

        [[-5.945e-03],
         [-6.482e-02],
         [ 2.896e-03],
         [ 3.458e-03],
         [ 1.882e-02],
         [ 4.469e-02],
         [-2.133e-02],
         [ 1.820e-03],
         [ 3.090e-02],
         [ 1.806e-02]],

        [[-8.356e-03],
         [-1.997e-02],
         [ 2.736e-03],
         [ 2.334e-03],
         [-8.457e-03],
         [-3.147e-02],
         [ 7.512e-03],
         [ 4.374e-04],
         [ 1.843e-02],
         [-2.377e-03]],

        [[-2.849e-02],
         [-3.570e-03],
         [-4.087e-02],
         [-1.786e-02],
         [ 2.755e-02],
         [ 2.250e-02],
         [ 2.189e-02],
         [-1.124e-02],
         [-4.636e-02],
         [ 1.756e-02]],

        [[-2.152e-03],
         [ 3.397e-02],
         [-2.181e-03],
         [-4.640e-03],
         [ 9.118e-03],
         [-2.533e-02],
         [-2.208e-02],
         [ 1.385e-02],
         [-2.740e-02],
         [ 1.833e-02]],

        [[-3.103e-02],
         [ 3.303e-02],
         [-5.095e-02],
         [ 9.619e-04],
         [ 8.877e-03],
         [ 1.001e-01],
         [-1.821e-03],
         [ 1.561e-02],
         [-3.550e-02],
         [-3.880e-02]],

        [[-5.488e-03],
         [ 7.956e-03],
         [-8.715e-03],
         [ 4.520e-03],
         [-1.070e-02],
         [-3.425e-02],
         [-2.484e-02],
         [-2.816e-03],
         [ 1.199e-02],
         [ 6.025e-02]],

        [[ 7.765e-03],
         [-3.784e-02],
         [ 6.238e-02],
         [-3.210e-02],
         [-9.546e-04],
         [ 2.070e-02],
         [ 4.689e-02],
         [ 8.762e-03],
         [ 5.478e-03],
         [ 2.612e-02]],

        [[-3.263e-02],
         [-1.277e-02],
         [-7.255e-05],
         [-9.620e-04],
         [-2.006e-02],
         [-3.277e-02],
         [-1.055e-02],
         [ 3.712e-02],
         [ 5.892e-02],
         [-3.959e-02]],

        [[-1.103e-02],
         [ 3.505e-02],
         [-4.780e-03],
         [ 3.318e-02],
         [ 2.104e-02],
         [-3.250e-02],
         [-1.992e-02],
         [ 2.060e-02],
         [ 4.562e-02],
         [ 7.138e-03]],

        [[ 3.393e-02],
         [ 4.255e-02],
         [-2.218e-02],
         [-3.476e-03],
         [ 1.615e-02],
         [ 1.438e-02],
         [ 1.864e-02],
         [ 2.099e-02],
         [ 1.098e-05],
         [-3.264e-02]],

        [[-1.753e-02],
         [ 7.544e-03],
         [-3.236e-02],
         [-2.151e-02],
         [-2.088e-02],
         [ 1.138e-02],
         [ 2.262e-02],
         [ 5.979e-02],
         [-7.620e-03],
         [-3.225e-02]],

        [[ 4.230e-02],
         [-1.135e-02],
         [-2.375e-03],
         [ 3.425e-02],
         [-3.986e-02],
         [ 2.708e-02],
         [-2.928e-02],
         [ 3.630e-02],
         [ 4.223e-03],
         [ 7.579e-03]],

        [[ 8.798e-02],
         [-2.155e-02],
         [-7.928e-03],
         [-3.617e-03],
         [ 3.124e-02],
         [ 4.171e-02],
         [-1.328e-02],
         [-8.571e-03],
         [-4.587e-02],
         [-4.922e-03]],

        [[-1.511e-02],
         [-5.299e-03],
         [-2.279e-02],
         [-4.551e-02],
         [-8.153e-03],
         [ 4.724e-02],
         [ 4.238e-02],
         [-3.020e-02],
         [ 3.731e-02],
         [-4.899e-02]],

        [[-2.471e-03],
         [-6.803e-03],
         [-2.649e-02],
         [-1.703e-02],
         [-4.381e-03],
         [ 1.941e-02],
         [ 5.919e-02],
         [-7.351e-03],
         [-1.201e-03],
         [ 4.136e-02]],

        [[ 1.508e-02],
         [ 3.145e-02],
         [-7.905e-03],
         [ 4.880e-02],
         [-9.476e-03],
         [ 1.572e-02],
         [ 1.292e-05],
         [-1.485e-02],
         [-3.683e-02],
         [ 2.744e-02]],

        [[-1.773e-02],
         [ 1.986e-02],
         [ 3.088e-02],
         [-1.661e-02],
         [ 2.785e-03],
         [ 1.668e-02],
         [-2.785e-02],
         [-1.482e-02],
         [ 6.391e-03],
         [ 1.926e-02]],

        [[-6.306e-02],
         [ 9.437e-03],
         [ 3.463e-02],
         [-3.652e-02],
         [ 9.023e-03],
         [-1.992e-02],
         [-7.107e-03],
         [-6.761e-03],
         [ 7.358e-03],
         [-5.622e-02]],

        [[-2.124e-02],
         [ 6.923e-02],
         [ 8.026e-03],
         [ 4.989e-03],
         [-1.997e-03],
         [-3.845e-02],
         [-1.794e-02],
         [-4.685e-02],
         [ 4.168e-02],
         [ 3.442e-03]],

        [[ 4.167e-02],
         [ 4.070e-02],
         [ 1.468e-02],
         [ 5.707e-02],
         [-3.090e-02],
         [-3.920e-02],
         [-1.945e-02],
         [-3.780e-02],
         [-4.971e-02],
         [ 5.251e-02]],

        [[-1.118e-02],
         [-2.294e-04],
         [ 2.580e-02],
         [ 2.588e-02],
         [ 2.650e-02],
         [-1.134e-04],
         [-3.527e-02],
         [-3.188e-02],
         [ 5.180e-03],
         [ 1.666e-03]],

        [[-9.094e-03],
         [ 8.602e-03],
         [-5.618e-02],
         [ 1.824e-04],
         [ 2.415e-02],
         [-3.623e-02],
         [ 1.639e-02],
         [-1.492e-02],
         [ 1.406e-02],
         [ 2.204e-02]],

        [[ 5.783e-03],
         [ 1.826e-02],
         [-1.339e-02],
         [-7.386e-02],
         [-2.536e-02],
         [-5.840e-03],
         [ 2.620e-03],
         [-3.244e-02],
         [-4.294e-02],
         [ 3.576e-02]],

        [[ 1.502e-02],
         [ 2.823e-03],
         [-6.028e-02],
         [ 4.884e-02],
         [ 4.751e-03],
         [-2.810e-02],
         [-4.018e-02],
         [ 8.135e-02],
         [-1.480e-02],
         [ 9.580e-02]],

        [[-2.443e-02],
         [ 8.919e-04],
         [-2.440e-02],
         [-2.223e-02],
         [-1.375e-03],
         [-2.445e-02],
         [-2.000e-02],
         [ 1.371e-02],
         [ 1.409e-02],
         [ 1.004e-02]],

        [[ 1.116e-03],
         [-3.942e-02],
         [ 5.572e-03],
         [ 2.024e-02],
         [ 2.778e-02],
         [-7.144e-02],
         [ 6.042e-02],
         [-9.759e-03],
         [ 1.214e-02],
         [ 5.165e-03]]], device='cuda:0')
s after update for 1 param tensor([[[1.322],
         [0.835],
         [1.112],
         [1.502],
         [1.017],
         [1.991],
         [1.278],
         [1.297],
         [1.413],
         [1.677]],

        [[1.319],
         [1.744],
         [1.534],
         [1.131],
         [1.119],
         [1.397],
         [1.751],
         [1.460],
         [1.856],
         [1.433]],

        [[1.316],
         [0.573],
         [1.507],
         [1.613],
         [1.469],
         [1.514],
         [1.132],
         [1.682],
         [0.877],
         [1.587]],

        [[1.381],
         [1.341],
         [1.191],
         [0.979],
         [1.625],
         [0.970],
         [1.120],
         [1.482],
         [1.218],
         [1.076]],

        [[1.085],
         [1.065],
         [1.375],
         [1.258],
         [1.039],
         [1.313],
         [1.543],
         [0.902],
         [1.589],
         [1.177]],

        [[1.843],
         [0.683],
         [1.839],
         [1.306],
         [1.680],
         [2.023],
         [1.696],
         [1.384],
         [1.740],
         [1.857]],

        [[1.666],
         [1.406],
         [1.528],
         [2.037],
         [1.667],
         [1.057],
         [1.624],
         [0.990],
         [0.973],
         [1.013]],

        [[0.704],
         [0.942],
         [1.285],
         [1.258],
         [1.325],
         [1.250],
         [1.125],
         [1.293],
         [1.369],
         [1.285]],

        [[1.907],
         [1.334],
         [1.290],
         [1.639],
         [1.527],
         [1.662],
         [1.678],
         [1.516],
         [1.264],
         [1.654]],

        [[1.206],
         [1.562],
         [1.464],
         [0.671],
         [1.512],
         [1.174],
         [1.397],
         [1.331],
         [1.398],
         [1.955]],

        [[1.921],
         [1.178],
         [1.711],
         [0.693],
         [1.393],
         [1.395],
         [1.430],
         [1.632],
         [1.983],
         [1.567]],

        [[1.775],
         [1.296],
         [1.424],
         [0.899],
         [1.272],
         [1.465],
         [1.219],
         [1.474],
         [1.710],
         [1.177]],

        [[0.626],
         [1.150],
         [1.563],
         [1.168],
         [1.497],
         [0.586],
         [0.953],
         [1.671],
         [1.902],
         [1.693]],

        [[0.752],
         [1.023],
         [0.990],
         [1.501],
         [1.439],
         [1.822],
         [1.652],
         [0.731],
         [1.784],
         [1.319]],

        [[1.438],
         [1.265],
         [2.009],
         [1.259],
         [0.680],
         [1.872],
         [1.067],
         [0.786],
         [1.827],
         [1.329]],

        [[1.586],
         [1.664],
         [0.952],
         [1.472],
         [0.874],
         [1.496],
         [1.141],
         [0.777],
         [1.624],
         [0.924]],

        [[0.984],
         [1.583],
         [1.211],
         [1.007],
         [1.804],
         [1.530],
         [1.174],
         [1.742],
         [2.244],
         [1.707]],

        [[1.360],
         [1.517],
         [1.065],
         [1.608],
         [0.948],
         [1.800],
         [1.675],
         [1.479],
         [1.370],
         [1.807]],

        [[1.014],
         [1.502],
         [1.587],
         [1.881],
         [1.301],
         [1.329],
         [0.926],
         [0.933],
         [1.421],
         [1.309]],

        [[1.247],
         [1.373],
         [1.386],
         [1.922],
         [1.584],
         [1.156],
         [1.803],
         [0.784],
         [0.948],
         [0.887]],

        [[1.387],
         [1.211],
         [1.604],
         [1.358],
         [1.823],
         [1.530],
         [1.581],
         [1.045],
         [1.036],
         [1.945]],

        [[1.156],
         [1.738],
         [1.867],
         [1.416],
         [1.268],
         [1.207],
         [1.265],
         [0.906],
         [1.290],
         [1.611]],

        [[1.011],
         [1.494],
         [1.108],
         [1.193],
         [1.081],
         [1.560],
         [1.457],
         [0.718],
         [1.299],
         [1.730]],

        [[1.109],
         [1.435],
         [0.901],
         [1.716],
         [1.888],
         [1.703],
         [0.829],
         [1.770],
         [0.987],
         [1.202]],

        [[1.566],
         [1.718],
         [0.804],
         [1.413],
         [1.876],
         [0.721],
         [1.864],
         [1.287],
         [0.983],
         [0.832]],

        [[1.376],
         [1.783],
         [0.827],
         [1.011],
         [0.950],
         [1.376],
         [0.770],
         [1.649],
         [1.024],
         [1.947]],

        [[1.667],
         [1.326],
         [1.187],
         [1.914],
         [1.585],
         [0.761],
         [1.336],
         [1.088],
         [1.999],
         [1.390]],

        [[1.097],
         [1.491],
         [1.721],
         [1.575],
         [1.617],
         [2.168],
         [1.177],
         [1.724],
         [1.098],
         [1.707]],

        [[1.675],
         [1.139],
         [1.655],
         [1.450],
         [2.099],
         [1.793],
         [1.587],
         [1.005],
         [1.536],
         [1.064]],

        [[1.658],
         [2.042],
         [1.360],
         [1.146],
         [1.235],
         [1.180],
         [1.225],
         [1.829],
         [1.411],
         [1.103]]], device='cuda:0')
b after update for 1 param tensor([[[133.936],
         [106.413],
         [122.805],
         [142.762],
         [117.435],
         [164.339],
         [131.678],
         [132.653],
         [138.433],
         [150.841]],

        [[133.761],
         [153.797],
         [144.254],
         [123.850],
         [123.233],
         [137.687],
         [154.145],
         [140.745],
         [158.692],
         [139.442]],

        [[133.629],
         [ 88.182],
         [142.968],
         [147.931],
         [141.177],
         [143.334],
         [123.908],
         [151.064],
         [109.079],
         [146.747]],

        [[136.887],
         [134.894],
         [127.116],
         [115.230],
         [148.453],
         [114.698],
         [123.248],
         [141.788],
         [128.531],
         [120.823]],

        [[121.344],
         [120.173],
         [136.601],
         [130.642],
         [118.716],
         [133.475],
         [144.671],
         [110.634],
         [146.843],
         [126.343]],

        [[158.138],
         [ 96.287],
         [157.942],
         [133.105],
         [150.985],
         [165.655],
         [151.679],
         [137.016],
         [153.625],
         [158.739]],

        [[150.343],
         [138.096],
         [143.981],
         [166.232],
         [150.393],
         [119.746],
         [148.438],
         [115.890],
         [114.906],
         [117.220]],

        [[ 97.699],
         [113.051],
         [132.055],
         [130.631],
         [134.093],
         [130.226],
         [123.558],
         [132.457],
         [136.295],
         [132.050]],

        [[160.842],
         [134.541],
         [132.281],
         [149.094],
         [143.946],
         [150.174],
         [150.887],
         [143.419],
         [130.935],
         [149.800]],

        [[127.906],
         [145.556],
         [140.906],
         [ 95.413],
         [143.219],
         [126.226],
         [137.685],
         [134.349],
         [137.695],
         [162.863]],

        [[161.439],
         [126.410],
         [152.345],
         [ 96.932],
         [137.468],
         [137.555],
         [139.266],
         [148.783],
         [164.032],
         [145.797]],

        [[155.161],
         [132.588],
         [139.009],
         [110.445],
         [131.386],
         [140.970],
         [128.601],
         [141.394],
         [152.293],
         [126.355]],

        [[ 92.126],
         [124.894],
         [145.623],
         [125.899],
         [142.529],
         [ 89.179],
         [113.684],
         [150.583],
         [160.634],
         [151.563]],

        [[101.023],
         [117.795],
         [115.862],
         [142.680],
         [139.712],
         [157.238],
         [149.700],
         [ 99.613],
         [155.553],
         [133.756]],

        [[139.691],
         [131.001],
         [165.076],
         [130.680],
         [ 96.017],
         [159.356],
         [120.328],
         [103.241],
         [157.441],
         [134.297]],

        [[146.690],
         [150.232],
         [113.623],
         [141.312],
         [108.914],
         [142.479],
         [124.400],
         [102.650],
         [148.416],
         [111.962]],

        [[115.530],
         [146.555],
         [128.187],
         [116.881],
         [156.454],
         [144.078],
         [126.211],
         [153.709],
         [174.485],
         [152.185]],

        [[135.828],
         [143.478],
         [120.215],
         [147.693],
         [113.376],
         [156.254],
         [150.743],
         [141.671],
         [136.304],
         [156.572]],

        [[117.282],
         [142.762],
         [146.751],
         [159.727],
         [132.865],
         [134.266],
         [112.108],
         [112.515],
         [138.856],
         [133.275]],

        [[130.082],
         [136.499],
         [137.141],
         [161.488],
         [146.574],
         [125.252],
         [156.375],
         [103.105],
         [113.430],
         [109.693]],

        [[137.195],
         [128.152],
         [147.503],
         [135.720],
         [157.240],
         [144.047],
         [146.467],
         [119.054],
         [118.574],
         [162.421]],

        [[125.252],
         [153.557],
         [159.128],
         [138.587],
         [131.160],
         [127.967],
         [131.002],
         [110.854],
         [132.305],
         [147.834]],

        [[117.100],
         [142.357],
         [122.620],
         [127.195],
         [121.080],
         [145.478],
         [140.604],
         [ 98.713],
         [132.726],
         [153.207]],

        [[122.634],
         [139.522],
         [110.569],
         [152.582],
         [160.035],
         [152.007],
         [106.054],
         [154.939],
         [115.688],
         [127.695]],

        [[145.753],
         [152.669],
         [104.409],
         [138.453],
         [159.531],
         [ 98.868],
         [158.999],
         [132.138],
         [115.501],
         [106.220]],

        [[136.614],
         [155.541],
         [105.906],
         [117.110],
         [113.512],
         [136.640],
         [102.220],
         [149.553],
         [117.869],
         [162.504]],

        [[150.373],
         [134.132],
         [126.911],
         [161.140],
         [146.659],
         [101.589],
         [134.608],
         [121.483],
         [164.663],
         [137.338]],

        [[121.983],
         [142.213],
         [152.790],
         [146.183],
         [148.110],
         [171.489],
         [126.357],
         [152.935],
         [122.043],
         [152.155]],

        [[150.733],
         [124.318],
         [149.850],
         [140.247],
         [168.729],
         [155.942],
         [146.713],
         [116.786],
         [144.353],
         [120.151]],

        [[149.954],
         [166.432],
         [135.843],
         [124.706],
         [129.421],
         [126.514],
         [128.887],
         [157.502],
         [138.331],
         [122.308]]], device='cuda:0')
clipping threshold 0.2093895742663162
a after update for 1 param tensor([[-0.022],
        [-0.032],
        [-0.029],
        [-0.021],
        [ 0.001],
        [ 0.030],
        [ 0.017],
        [-0.020],
        [-0.021],
        [-0.005],
        [-0.059],
        [ 0.012],
        [-0.010],
        [-0.010],
        [-0.019],
        [-0.020],
        [-0.086],
        [-0.015],
        [-0.003],
        [ 0.009],
        [ 0.007],
        [ 0.053],
        [ 0.006],
        [-0.013],
        [-0.012],
        [ 0.027],
        [-0.012],
        [ 0.000],
        [ 0.050],
        [-0.030]], device='cuda:0')
s after update for 1 param tensor([[1.430],
        [1.596],
        [1.470],
        [1.724],
        [2.219],
        [1.643],
        [1.796],
        [1.493],
        [1.462],
        [1.416],
        [0.819],
        [1.306],
        [1.620],
        [1.405],
        [1.409],
        [1.546],
        [1.235],
        [1.385],
        [1.478],
        [1.331],
        [1.797],
        [0.953],
        [1.559],
        [1.425],
        [1.793],
        [0.907],
        [1.552],
        [1.351],
        [1.398],
        [1.680]], device='cuda:0')
b after update for 1 param tensor([[139.292],
        [147.124],
        [141.208],
        [152.950],
        [173.508],
        [149.287],
        [156.076],
        [142.327],
        [140.831],
        [138.606],
        [105.410],
        [133.110],
        [148.256],
        [138.035],
        [138.271],
        [144.832],
        [129.440],
        [137.083],
        [141.605],
        [134.359],
        [156.113],
        [113.690],
        [145.446],
        [139.031],
        [155.940],
        [110.917],
        [145.107],
        [135.393],
        [137.738],
        [150.950]], device='cuda:0')
clipping threshold 0.2093895742663162
cuda
Objective function 29.24 = squared loss an data 26.75 + 0.5*rho*h**2 1.214698 + alpha*h 0.260242 + L2reg 0.74 + L1reg 0.27 ; SHD = 64 ; DAG True
Proportion of microbatches that were clipped  0.7611035802567578
iteration 3 in inner loop, alpha 16.696586254294186 rho 10000.0 h 0.015586517694607949
iteration 3 in outer loop, alpha = 172.56176320037366, rho = 10000.0, h = 0.015586517694607949
cuda
9630
cuda
Objective function 31.67 = squared loss an data 26.75 + 0.5*rho*h**2 1.214698 + alpha*h 2.689637 + L2reg 0.74 + L1reg 0.27 ; SHD = 64 ; DAG True
||w||^2 18480697987.270905
exp ma of ||w||^2 4592211239.23363
||w|| 135943.73095980156
exp ma of ||w|| 32836.85984989948
||w||^2 0.06708234873757438
exp ma of ||w||^2 29.608598042573185
||w|| 0.2590026037274034
exp ma of ||w|| 0.3144063904083622
||w||^2 0.057890194632458224
exp ma of ||w||^2 0.0613898357388535
||w|| 0.24060381258919863
exp ma of ||w|| 0.24275568425521987
||w||^2 0.039108810389997216
exp ma of ||w||^2 0.06423516447843185
||w|| 0.19775947610670194
exp ma of ||w|| 0.2487843298810629
||w||^2 0.05310278386323136
exp ma of ||w||^2 0.06851872957784587
||w|| 0.23044041282559655
exp ma of ||w|| 0.2567091105235242
||w||^2 0.060768451242993106
exp ma of ||w||^2 0.06909161132034239
||w|| 0.24651257826527453
exp ma of ||w|| 0.2571124386169859
||w||^2 0.04950845262309066
exp ma of ||w||^2 0.06698666278015554
||w|| 0.22250494965975623
exp ma of ||w|| 0.25393075265239967
||w||^2 0.0953715549415456
exp ma of ||w||^2 0.0715885618445927
||w|| 0.3088228536581216
exp ma of ||w|| 0.26267083772683947
||w||^2 0.05071043467394334
exp ma of ||w||^2 0.07232141727030694
||w|| 0.22518977479882016
exp ma of ||w|| 0.26387985875675046
||w||^2 0.05180190452785628
exp ma of ||w||^2 0.06727876874061439
||w|| 0.22760031750385648
exp ma of ||w|| 0.25455207079574826
||w||^2 0.08126462389216389
exp ma of ||w||^2 0.07401006934860188
||w|| 0.2850695071244273
exp ma of ||w|| 0.26743064114858894
cuda
Objective function 29.89 = squared loss an data 26.71 + 0.5*rho*h**2 0.474254 + alpha*h 1.680602 + L2reg 0.76 + L1reg 0.26 ; SHD = 67 ; DAG True
Proportion of microbatches that were clipped  0.7629300071502344
iteration 1 in inner loop, alpha 172.56176320037366 rho 10000.0 h 0.00973913475889887
9630
cuda
Objective function 34.16 = squared loss an data 26.71 + 0.5*rho*h**2 4.742537 + alpha*h 1.680602 + L2reg 0.76 + L1reg 0.26 ; SHD = 67 ; DAG True
||w||^2 0.7696058910294813
exp ma of ||w||^2 14220.648947028116
||w|| 0.8772718455698219
exp ma of ||w|| 0.9437238969248638
||w||^2 0.09862898149660304
exp ma of ||w||^2 13.187434403734857
||w|| 0.3140525139154327
exp ma of ||w|| 0.390150290501483
||w||^2 0.04120264475654933
exp ma of ||w||^2 0.06140988551114733
||w|| 0.20298434608744914
exp ma of ||w|| 0.24368132856115915
||w||^2 0.02977377063501698
exp ma of ||w||^2 0.0598529475998974
||w|| 0.1725507769759875
exp ma of ||w|| 0.24056880704049421
||w||^2 0.061431670147068865
exp ma of ||w||^2 0.059427454509370745
||w|| 0.2478541307847599
exp ma of ||w|| 0.2398167289719475
v before min max tensor([[17.412, 23.822, -0.427,  ..., -4.702,  2.209, -3.731],
        [96.937, -7.024,  8.592,  ..., -5.935, -2.360,  5.183],
        [16.449,  0.766, -4.549,  ..., -2.179,  9.117,  2.472],
        ...,
        [-0.232, 39.954, 11.592,  ..., -4.851, -3.739, -3.428],
        [-5.600, -3.716, -6.694,  ..., -1.801, 25.300, 28.950],
        [21.215, -6.017, 71.448,  ..., 22.894, -4.011, -8.304]],
       device='cuda:0')
v tensor([[1.000e+01, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 2.209e+00,
         1.000e-12],
        [1.000e+01, 1.000e-12, 8.592e+00,  ..., 1.000e-12, 1.000e-12,
         5.183e+00],
        [1.000e+01, 7.661e-01, 1.000e-12,  ..., 1.000e-12, 9.117e+00,
         2.472e+00],
        ...,
        [1.000e-12, 1.000e+01, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         1.000e+01],
        [1.000e+01, 1.000e-12, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([  3.586,  -3.107,   2.347,  -1.041,   7.211,  -5.945,  -4.490,  -5.886,
         -4.348,  17.786,   1.149,  -4.787,  15.190,  -6.331,  14.226,   4.889,
         -1.983,  -3.056,  15.422,  -1.488,  -1.173,  -1.978,  -2.637,  -2.204,
         -2.972,  -5.815,  -3.798,  11.798,   3.050,   0.420,  94.291,  -2.257,
         -0.939,   7.482,  -2.423,   3.031,  43.667,  -8.384,  -3.176,  67.951,
         -1.432,  38.054,  -8.181,  -3.546,  -1.606,  -5.012,  21.242,   3.892,
          3.603,  -2.713,  -0.943,  -5.831,  -7.226,  -6.479,  -6.815,  -5.143,
          2.208,  25.925,  23.310,  -7.507,  -1.635,  30.488,  13.695,  -3.163,
         -6.306,  -6.766,   5.106,  -6.363,  -4.499,  -6.674,  -2.122,  -1.644,
         -2.998,  -5.600,  35.512,  -5.291,  19.555,  -3.151,  -4.221,  -2.969,
         -4.880,  -6.580,  -0.662,   3.736,  43.321,  12.717,  71.071,   3.309,
         -3.206,  -4.003,  -5.660,  -5.919,  -3.880,  -6.062,  -2.639,  -5.206,
         17.964,  -6.176, 117.269,  -4.737,  -5.568,  -5.858,  25.618,   2.517,
         -2.663,   0.725,   5.279,  -6.354,   9.984,  -3.074,  -0.264,  29.255,
         -5.234,   1.673,   1.936,  -6.228,   1.363,  -3.798,  -5.324,  -4.367,
         58.692,   2.149,  14.500,  19.764,  -2.758,  -4.789,  -5.011,  -2.250,
         -2.670,  -6.980,  -4.613,   6.972,  -7.499,  -4.297,  44.482,   4.624,
         -6.903,  -5.958,  -4.823,   1.015,   6.945,  -4.392,  -4.322,  -6.014,
          7.261,  -6.568,   6.847,  -5.482,  -3.490,  -4.974,  -0.828,  -4.535,
         -4.117,  14.822,   2.159,  -1.080,   4.572,  -4.909,  -4.109,  -6.679,
         -4.519,  -3.901,  12.837,  -2.235,   7.118,  -5.130,  -5.652,   1.779,
          9.097,  -0.798,   1.855,  -5.907,  10.968,  -5.499,  -6.086,   6.041,
         -5.458,  13.470,  -4.799,  -4.233,  -4.489,  10.699,   0.665,  -3.891,
         -6.203,  21.722,  -4.517,  -3.157,   0.247,  18.751,  -1.448,  -6.403,
         -4.375,  -6.143,  -5.829,  90.238,  -6.615,  -4.190,  -3.332,  15.807,
          2.773,  -2.153,   8.977,   4.089,  34.763,  -6.741,   8.452,  -3.403,
         -0.975,  31.250,   5.001,   1.774,  28.431,  12.780,  -3.805,  37.356,
         -7.753,  -5.518,  -1.398,  23.073,  11.494,   1.950,  -5.850,  -2.643,
         58.407,  46.447,  -6.191,  -6.122,  22.330,  -4.689,  18.481,  -1.317,
         -2.012,  -2.552,   4.796,   7.660,  -2.310,  -2.614,  14.216,   6.176,
         -6.815,  -6.426,  -2.757,  58.362,  12.158,   1.195,  -0.790,   1.110,
         -3.661,   3.397,  -3.490,   7.261,  -3.804,  -3.186,  -0.577,   8.424,
         -6.080,  -1.002,  -2.576,  -7.836,  10.650,  -0.411,   5.832,  -5.696,
         19.918,  -3.878,  22.703,  -7.924,   0.900,   2.233,  -5.424,  -5.723,
         12.707,   3.453,   3.394,  14.714,  -5.917,  13.114,  -2.074,  -4.918,
         -2.728,  15.830,  26.727,  55.416,  -1.845,  -7.011,  15.993,  -5.140,
         -2.652,  -5.531,  -4.061,  -6.634,  -4.317,  -6.715,  -4.016,  -2.052,
         -2.526,  -5.850,   6.018,  -3.633], device='cuda:0')
v tensor([3.586e+00, 1.000e-12, 2.347e+00, 1.000e-12, 7.211e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.149e+00, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 4.889e+00, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 3.050e+00, 4.199e-01,
        1.000e+01, 1.000e-12, 1.000e-12, 7.482e+00, 1.000e-12, 3.031e+00,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 3.892e+00,
        3.603e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 2.208e+00, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        5.106e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.736e+00,
        1.000e+01, 1.000e+01, 1.000e+01, 3.309e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 2.517e+00, 1.000e-12, 7.250e-01, 5.279e+00, 1.000e-12,
        9.984e+00, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.673e+00,
        1.936e+00, 1.000e-12, 1.363e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 2.149e+00, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 6.972e+00,
        1.000e-12, 1.000e-12, 1.000e+01, 4.624e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.015e+00, 6.945e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        7.261e+00, 1.000e-12, 6.847e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 2.159e+00, 1.000e-12,
        4.572e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 7.118e+00, 1.000e-12, 1.000e-12, 1.779e+00,
        9.097e+00, 1.000e-12, 1.855e+00, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 6.041e+00, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 6.652e-01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 2.473e-01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 2.773e+00, 1.000e-12, 8.977e+00, 4.089e+00,
        1.000e+01, 1.000e-12, 8.452e+00, 1.000e-12, 1.000e-12, 1.000e+01,
        5.001e+00, 1.774e+00, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.950e+00,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        4.796e+00, 7.660e+00, 1.000e-12, 1.000e-12, 1.000e+01, 6.176e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.195e+00,
        1.000e-12, 1.110e+00, 1.000e-12, 3.397e+00, 1.000e-12, 7.261e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 8.424e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 5.832e+00, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 9.002e-01, 2.233e+00,
        1.000e-12, 1.000e-12, 1.000e+01, 3.453e+00, 3.394e+00, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 6.018e+00, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-4.980e+00],
         [ 7.177e+00],
         [ 2.716e+01],
         [ 3.789e+00],
         [-7.657e+00],
         [-3.282e+00],
         [-2.057e+00],
         [ 4.222e+00],
         [-3.730e-01],
         [ 3.677e-01]],

        [[ 2.579e+00],
         [ 6.782e+00],
         [-3.565e+00],
         [-4.990e-01],
         [ 1.437e+00],
         [ 6.638e-01],
         [ 1.071e+01],
         [ 5.243e+01],
         [ 2.511e+01],
         [-3.093e-02]],

        [[ 3.187e+00],
         [-3.965e+00],
         [ 1.293e+00],
         [ 1.760e+01],
         [ 1.067e+01],
         [ 1.389e+01],
         [-6.209e+00],
         [-3.995e+00],
         [ 2.682e+00],
         [ 4.498e+00]],

        [[-4.213e+00],
         [-6.998e+00],
         [ 2.938e+01],
         [ 2.374e+01],
         [-4.331e+00],
         [-5.487e+00],
         [-4.765e+00],
         [ 8.928e+00],
         [-5.100e+00],
         [-2.986e+00]],

        [[ 3.431e+01],
         [-3.624e+00],
         [ 1.019e+01],
         [-6.584e+00],
         [-5.997e+00],
         [-6.296e+00],
         [-9.908e-01],
         [-6.768e+00],
         [-5.562e+00],
         [ 9.167e+00]],

        [[ 5.213e+01],
         [ 9.138e+00],
         [-4.066e+00],
         [ 1.355e+01],
         [-1.923e+00],
         [ 1.761e+01],
         [ 1.708e+00],
         [-1.734e+00],
         [ 3.309e+00],
         [ 1.800e+01]],

        [[-4.345e+00],
         [-1.166e+00],
         [-4.760e+00],
         [-6.672e+00],
         [ 4.186e+00],
         [-2.690e+00],
         [-4.419e+00],
         [ 8.681e+00],
         [ 4.003e+01],
         [ 8.281e-01]],

        [[ 1.200e+01],
         [ 1.838e+01],
         [-2.222e+00],
         [ 2.555e+01],
         [ 1.411e+00],
         [-9.438e-01],
         [-6.085e+00],
         [-3.307e+00],
         [-6.467e+00],
         [ 2.911e+00]],

        [[-1.303e+00],
         [-1.103e+00],
         [-5.328e+00],
         [-2.610e+00],
         [ 2.403e+00],
         [-5.326e+00],
         [-1.879e+00],
         [-3.707e+00],
         [-5.109e+00],
         [-4.273e+00]],

        [[-1.046e+00],
         [-6.549e+00],
         [ 5.184e+01],
         [ 4.611e+00],
         [ 1.279e+01],
         [ 7.641e+01],
         [-4.762e+00],
         [ 6.348e+01],
         [ 1.745e+00],
         [ 3.077e+01]],

        [[ 1.271e+01],
         [ 1.824e+01],
         [-6.250e+00],
         [ 1.490e+01],
         [-6.217e+00],
         [-6.299e+00],
         [ 1.484e+01],
         [-5.000e-01],
         [-2.589e-01],
         [-5.388e+00]],

        [[-2.942e+00],
         [-3.087e+00],
         [-4.140e+00],
         [ 6.346e+00],
         [ 9.310e+00],
         [-1.913e+00],
         [-6.038e+00],
         [-2.658e+00],
         [ 1.011e+01],
         [ 1.734e+00]],

        [[ 2.137e+01],
         [ 2.911e+00],
         [ 1.206e+01],
         [-5.008e+00],
         [ 1.731e+00],
         [ 5.477e+00],
         [-5.288e+00],
         [-1.596e+00],
         [ 1.058e+01],
         [ 3.693e+00]],

        [[-4.748e+00],
         [ 8.722e+00],
         [ 4.476e+00],
         [-3.055e+00],
         [-5.740e+00],
         [-8.278e-01],
         [-1.321e+00],
         [ 7.174e+00],
         [ 1.252e+01],
         [ 1.401e+01]],

        [[-6.252e+00],
         [-6.502e+00],
         [-4.192e+00],
         [-2.830e-01],
         [ 4.035e+01],
         [ 3.945e+01],
         [-3.874e+00],
         [-3.721e+00],
         [ 1.563e+01],
         [ 1.570e+01]],

        [[-4.220e+00],
         [ 2.169e+01],
         [ 3.328e+01],
         [-4.832e+00],
         [ 1.754e+01],
         [-4.161e+00],
         [ 3.098e+01],
         [-5.461e+00],
         [-7.196e+00],
         [ 4.545e+01]],

        [[ 1.881e+01],
         [ 6.876e+00],
         [-3.254e+00],
         [-7.702e+00],
         [-7.650e+00],
         [ 3.414e+01],
         [-4.882e+00],
         [-2.260e-01],
         [-1.561e+00],
         [-2.591e+00]],

        [[ 2.881e+00],
         [ 2.221e+01],
         [ 5.281e+00],
         [-2.301e+00],
         [ 4.037e-01],
         [-4.537e+00],
         [ 3.380e+00],
         [ 1.157e+00],
         [ 4.392e+00],
         [-8.042e+00]],

        [[-2.714e+00],
         [-4.400e+00],
         [ 2.192e+00],
         [ 3.584e+01],
         [-6.976e+00],
         [ 1.417e+01],
         [-2.655e+00],
         [ 2.327e+01],
         [-3.888e+00],
         [-6.661e+00]],

        [[ 4.242e+00],
         [-2.327e+00],
         [-9.248e-01],
         [-4.718e+00],
         [-2.422e+00],
         [-1.095e-01],
         [-4.564e+00],
         [-5.296e+00],
         [ 6.886e+00],
         [ 1.891e+01]],

        [[-7.348e+00],
         [-2.735e+00],
         [-3.550e+00],
         [-8.455e+00],
         [-5.751e+00],
         [-4.888e+00],
         [-5.679e+00],
         [-4.612e+00],
         [-2.195e+00],
         [ 1.795e+01]],

        [[ 7.022e+00],
         [-6.574e+00],
         [ 1.197e+01],
         [-6.280e+00],
         [ 2.946e-01],
         [ 4.327e+00],
         [ 1.266e+01],
         [-5.989e+00],
         [-4.782e+00],
         [ 1.844e+01]],

        [[-2.559e+00],
         [-3.216e+00],
         [-6.869e+00],
         [-6.059e+00],
         [-1.430e+00],
         [-1.630e+00],
         [ 1.114e+01],
         [ 5.512e+00],
         [-8.231e+00],
         [ 9.130e-01]],

        [[-3.727e+00],
         [ 4.354e+00],
         [-2.237e+00],
         [ 1.796e+00],
         [-3.395e+00],
         [-1.164e+00],
         [-6.097e+00],
         [ 1.641e+01],
         [ 5.063e+00],
         [ 1.809e+00]],

        [[-4.468e+00],
         [-2.905e+00],
         [ 1.230e+00],
         [-3.197e+00],
         [-5.246e+00],
         [ 1.775e+01],
         [-1.659e+00],
         [-6.748e+00],
         [-5.048e+00],
         [ 1.775e+00]],

        [[-3.788e+00],
         [-7.363e+00],
         [-6.147e+00],
         [ 3.912e+00],
         [-6.905e+00],
         [-6.739e+00],
         [-2.057e+00],
         [ 5.642e+00],
         [-2.530e+00],
         [ 1.161e+01]],

        [[-3.774e+00],
         [-8.491e-01],
         [ 3.990e+00],
         [ 1.823e+01],
         [ 1.055e+00],
         [-1.169e+00],
         [ 3.346e+01],
         [-7.083e+00],
         [ 3.388e+01],
         [-1.300e+00]],

        [[-5.238e+00],
         [-6.891e+00],
         [ 1.246e+00],
         [-4.335e+00],
         [-5.828e+00],
         [ 2.956e+01],
         [ 1.868e+01],
         [-1.339e+00],
         [-6.054e+00],
         [ 1.162e+01]],

        [[ 1.320e+01],
         [-2.353e+00],
         [-7.097e+00],
         [-3.464e-01],
         [-5.941e+00],
         [-6.799e+00],
         [ 1.304e+00],
         [-7.195e+00],
         [ 1.031e+01],
         [ 4.354e+00]],

        [[ 1.829e+01],
         [ 8.043e+00],
         [ 9.646e+00],
         [ 1.497e+01],
         [ 2.124e+00],
         [ 4.785e+00],
         [-1.939e+00],
         [ 1.044e+01],
         [-1.441e+00],
         [ 1.604e+00]]], device='cuda:0')
v tensor([[[1.000e-12],
         [7.177e+00],
         [1.000e+01],
         [3.789e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.222e+00],
         [1.000e-12],
         [3.677e-01]],

        [[2.579e+00],
         [6.782e+00],
         [1.000e-12],
         [1.000e-12],
         [1.437e+00],
         [6.638e-01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[3.187e+00],
         [1.000e-12],
         [1.293e+00],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [2.682e+00],
         [4.498e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [8.928e+00],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [9.167e+00]],

        [[1.000e+01],
         [9.138e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.708e+00],
         [1.000e-12],
         [3.309e+00],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.186e+00],
         [1.000e-12],
         [1.000e-12],
         [8.681e+00],
         [1.000e+01],
         [8.281e-01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.411e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.911e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.403e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [4.611e+00],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.745e+00],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.346e+00],
         [9.310e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.734e+00]],

        [[1.000e+01],
         [2.911e+00],
         [1.000e+01],
         [1.000e-12],
         [1.731e+00],
         [5.477e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [3.693e+00]],

        [[1.000e-12],
         [8.722e+00],
         [4.476e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.174e+00],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [6.876e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[2.881e+00],
         [1.000e+01],
         [5.281e+00],
         [1.000e-12],
         [4.037e-01],
         [1.000e-12],
         [3.380e+00],
         [1.157e+00],
         [4.392e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [2.192e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[4.242e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.886e+00],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[7.022e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [2.946e-01],
         [4.327e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [5.512e+00],
         [1.000e-12],
         [9.130e-01]],

        [[1.000e-12],
         [4.354e+00],
         [1.000e-12],
         [1.796e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [5.063e+00],
         [1.809e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.230e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.775e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.912e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.642e+00],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [3.990e+00],
         [1.000e+01],
         [1.055e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.246e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.304e+00],
         [1.000e-12],
         [1.000e+01],
         [4.354e+00]],

        [[1.000e+01],
         [8.043e+00],
         [9.646e+00],
         [1.000e+01],
         [2.124e+00],
         [4.785e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.604e+00]]], device='cuda:0')
v before min max tensor([[-0.728],
        [-1.680],
        [-3.545],
        [ 4.917],
        [36.252],
        [-6.376],
        [-6.424],
        [ 9.437],
        [ 3.717],
        [-3.269],
        [ 1.169],
        [18.212],
        [-3.818],
        [-5.988],
        [-2.330],
        [33.414],
        [-6.721],
        [-3.139],
        [15.091],
        [-5.389],
        [37.118],
        [ 6.788],
        [ 5.790],
        [ 3.873],
        [39.105],
        [-1.597],
        [-2.357],
        [-0.950],
        [ 2.585],
        [-3.958]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [4.917e+00],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [9.437e+00],
        [3.717e+00],
        [1.000e-12],
        [1.169e+00],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [6.788e+00],
        [5.790e+00],
        [3.873e+00],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [2.585e+00],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-9.002e-03,  2.155e-01,  4.698e-02,  ..., -7.543e-02,  1.510e-02,
         -2.807e-02],
        [-9.480e-03, -2.456e-02, -4.935e-03,  ..., -1.611e-02,  2.146e-02,
         -6.496e-02],
        [-1.565e-02,  4.263e-03,  8.770e-03,  ...,  2.294e-02, -5.723e-02,
          5.547e-02],
        ...,
        [-1.106e-01,  3.762e-02,  1.889e-02,  ...,  1.262e-01,  7.705e-02,
         -7.905e-04],
        [-7.871e-02,  6.850e-02, -2.682e-03,  ..., -2.126e-01,  1.529e-02,
          1.468e-02],
        [-1.220e-02, -7.860e-03,  1.971e-04,  ..., -2.634e-02,  7.147e-03,
         -4.498e-04]], device='cuda:0')
s after update for 1 param tensor([[2.439, 1.720, 1.996,  ..., 1.275, 1.199, 1.081],
        [1.971, 1.741, 1.619,  ..., 1.514, 0.653, 1.265],
        [2.830, 1.272, 1.146,  ..., 0.748, 1.278, 1.554],
        ...,
        [1.525, 1.726, 1.639,  ..., 1.643, 1.356, 1.306],
        [1.347, 1.190, 1.911,  ..., 1.623, 1.860, 2.604],
        [1.737, 1.440, 1.694,  ..., 1.647, 1.276, 2.173]], device='cuda:0')
b after update for 1 param tensor([[191.419, 160.746, 173.148,  ..., 138.411, 134.177, 127.454],
        [172.044, 161.724, 155.952,  ..., 150.803,  99.050, 137.839],
        [206.176, 138.238, 131.225,  ..., 105.983, 138.565, 152.802],
        ...,
        [151.357, 161.020, 156.884,  ..., 157.077, 142.741, 140.073],
        [142.266, 133.713, 169.433,  ..., 156.122, 167.167, 197.787],
        [161.523, 147.075, 159.525,  ..., 157.286, 138.428, 180.674]],
       device='cuda:0')
clipping threshold 0.191500346170177
a after update for 1 param tensor([-1.660e-01,  1.088e-01,  9.182e-02, -1.476e-01, -8.978e-02,  3.346e-02,
         4.882e-02, -1.161e-01, -7.007e-02,  5.711e-02, -2.200e-01,  6.427e-02,
         4.303e-02,  4.788e-02, -3.038e-02,  6.979e-03, -2.907e-01, -1.166e-02,
         2.244e-01, -9.514e-03,  4.786e-02,  7.372e-02, -8.628e-02, -5.629e-02,
        -7.662e-02, -5.072e-02, -9.456e-02,  1.335e-01, -1.092e-01,  7.835e-02,
         3.624e-02,  8.469e-02, -3.850e-02,  2.065e-02, -3.055e-02, -2.726e-01,
        -2.736e-02,  1.116e-02, -1.631e-02,  9.360e-03,  3.131e-02,  5.271e-02,
         1.882e-03,  1.089e-01,  4.294e-02, -6.812e-02,  1.371e-01,  2.720e-01,
         1.735e-02, -3.468e-02,  2.015e-02,  3.631e-02, -4.344e-02, -7.251e-02,
         5.749e-02,  1.850e-02, -1.179e-01, -2.626e-02,  6.412e-02,  3.212e-02,
         1.539e-02, -1.037e-01,  8.856e-02,  1.114e-01,  5.211e-02, -4.373e-02,
         2.375e-03,  6.518e-02,  5.365e-02, -2.269e-03, -8.718e-02,  1.307e-01,
         2.008e-01,  1.130e-01, -2.372e-02,  1.920e-02,  6.659e-02,  6.831e-02,
        -2.206e-02,  7.546e-02,  1.165e-01, -1.013e-01, -1.073e-03, -1.142e-01,
        -1.006e-01,  4.282e-02, -9.823e-02, -9.308e-02, -2.209e-03,  1.682e-01,
         1.112e-01, -4.352e-02, -9.405e-03, -1.382e-01,  9.468e-02, -1.705e-01,
         1.378e-02,  5.678e-02, -8.532e-02,  1.318e-01,  3.211e-02, -1.350e-02,
        -5.005e-03,  6.880e-02, -3.030e-01,  8.239e-04, -1.185e-01, -5.425e-02,
         6.865e-02, -8.039e-02, -1.860e-02,  6.346e-03,  7.689e-02, -1.111e-01,
         1.309e-01,  1.396e-01, -1.350e-01,  1.499e-01,  2.486e-02,  5.591e-02,
         1.351e-01, -1.728e-01,  1.118e-01, -3.814e-02,  2.092e-01,  9.424e-02,
        -3.211e-02,  8.835e-02, -1.744e-01, -5.292e-02, -4.152e-01,  6.474e-02,
        -1.145e-01,  3.084e-02, -6.544e-02, -8.510e-02,  1.976e-01, -7.873e-02,
         5.149e-02,  1.564e-01,  1.033e-02,  2.239e-02, -2.515e-02, -5.607e-02,
         1.049e-01, -7.658e-03,  1.340e-01, -1.752e-02,  1.174e-01,  2.709e-01,
        -7.211e-02,  2.874e-02, -7.995e-02, -9.246e-02, -1.045e-01, -6.153e-02,
        -1.292e-01,  1.914e-03, -3.506e-02,  5.215e-02, -7.879e-02,  7.957e-02,
         8.314e-02,  7.711e-02,  2.932e-03, -3.932e-02,  1.924e-01,  3.835e-02,
         1.177e-01, -6.317e-02, -3.386e-02,  5.804e-02,  2.391e-02,  8.275e-02,
        -3.173e-02, -1.820e-01,  5.435e-03,  1.848e-01, -8.366e-02,  5.105e-03,
         1.128e-01,  1.571e-01,  1.446e-02, -6.950e-02, -9.471e-02, -6.439e-02,
        -2.056e-02, -4.150e-03,  1.139e-01,  2.763e-02, -8.326e-02,  5.551e-03,
        -3.154e-02, -2.374e-01,  2.499e-02,  2.146e-01,  1.167e-01,  1.043e-01,
         9.141e-02, -1.667e-01, -6.256e-02,  3.479e-02, -8.034e-02, -1.102e-01,
         8.830e-02, -1.689e-01,  1.135e-01,  4.776e-02,  5.845e-02,  7.777e-02,
        -7.125e-03, -7.184e-02,  5.496e-02, -2.491e-02,  1.169e-02,  3.600e-02,
        -4.032e-02,  2.192e-02, -2.374e-02, -3.342e-02, -4.503e-02,  2.688e-02,
         5.020e-02, -5.059e-02,  2.704e-01,  1.330e-01, -3.322e-02, -4.944e-02,
         1.300e-01, -1.766e-01, -1.542e-01,  5.160e-02, -1.288e-01, -6.184e-02,
        -1.169e-01,  1.152e-01, -7.990e-02,  1.399e-01,  1.473e-01, -5.270e-02,
         3.331e-04, -1.580e-01,  8.568e-02, -6.604e-02, -3.079e-03,  5.989e-02,
         2.363e-02, -2.332e-02, -1.026e-01, -9.483e-02,  7.109e-03,  6.950e-02,
         6.632e-02, -4.444e-02, -2.586e-01,  1.384e-01, -1.911e-01, -1.211e-01,
        -1.595e-01,  8.986e-02,  4.698e-02, -5.669e-02, -1.671e-02, -6.061e-02,
         3.297e-03, -9.928e-04, -4.966e-04,  3.718e-02, -9.790e-02, -2.372e-01,
         1.693e-01, -2.198e-02,  9.949e-02,  1.073e-02, -6.099e-02, -2.110e-02,
         7.228e-02, -1.820e-02, -7.649e-02, -1.017e-01, -3.671e-03, -2.284e-01,
        -2.073e-01,  1.480e-01,  1.745e-03,  2.365e-02,  8.147e-02, -7.226e-02,
         1.153e-01,  9.928e-02, -1.207e-01, -1.026e-01,  1.624e-01, -1.255e-02,
        -4.998e-02,  5.929e-02, -1.079e-02,  5.839e-02,  4.504e-02, -2.757e-03],
       device='cuda:0')
s after update for 1 param tensor([1.530, 1.394, 1.498, 1.810, 1.457, 1.614, 1.391, 1.860, 2.059, 1.885,
        1.063, 1.147, 1.556, 1.650, 1.640, 1.679, 1.456, 1.228, 1.777, 0.811,
        1.259, 1.516, 1.935, 1.208, 1.253, 1.461, 1.104, 1.552, 1.355, 1.283,
        2.130, 1.322, 1.235, 1.328, 1.193, 1.567, 1.639, 2.007, 1.272, 1.784,
        1.515, 1.615, 2.002, 1.395, 1.095, 1.210, 1.616, 1.036, 1.572, 1.448,
        1.144, 1.579, 1.869, 1.565, 1.686, 1.571, 1.435, 1.910, 1.925, 1.801,
        1.079, 1.716, 1.541, 1.114, 1.512, 1.634, 1.389, 1.723, 1.096, 1.640,
        0.677, 1.981, 1.263, 1.336, 1.817, 1.266, 2.236, 1.078, 1.249, 0.743,
        1.302, 1.571, 1.169, 1.450, 1.923, 1.636, 2.086, 1.753, 1.204, 1.003,
        1.541, 1.546, 1.525, 1.552, 0.965, 1.504, 1.766, 1.506, 2.409, 1.447,
        1.342, 1.451, 1.704, 1.194, 1.974, 1.259, 1.504, 1.519, 2.497, 1.363,
        1.009, 1.521, 1.250, 1.395, 1.524, 1.487, 1.284, 1.538, 1.278, 1.280,
        2.087, 1.467, 1.775, 1.461, 1.719, 1.148, 1.431, 1.375, 1.744, 1.705,
        2.031, 1.435, 1.789, 1.093, 1.621, 1.575, 1.804, 1.542, 1.374, 1.547,
        1.232, 1.149, 1.127, 1.476, 1.787, 1.579, 1.915, 1.311, 1.829, 1.489,
        1.151, 1.650, 1.118, 1.788, 1.251, 1.340, 1.589, 1.870, 1.601, 1.594,
        1.259, 1.330, 1.577, 1.472, 1.157, 1.584, 1.356, 1.573, 1.124, 1.368,
        1.684, 1.498, 1.148, 1.668, 1.453, 1.187, 1.302, 1.775, 1.204, 1.524,
        1.125, 1.748, 1.498, 0.979, 1.481, 1.924, 1.663, 1.909, 1.128, 1.516,
        1.334, 1.674, 1.401, 1.466, 1.466, 1.526, 1.594, 1.238, 1.049, 1.821,
        1.795, 1.069, 1.642, 1.696, 1.608, 1.811, 1.166, 1.014, 1.707, 1.854,
        1.325, 1.880, 1.608, 1.467, 1.411, 1.790, 1.909, 1.386, 1.659, 1.668,
        1.791, 1.834, 1.396, 1.485, 1.707, 1.901, 1.478, 1.483, 1.481, 1.213,
        1.912, 0.900, 1.649, 1.184, 1.389, 1.789, 1.235, 1.696, 1.587, 1.772,
        1.631, 1.701, 0.840, 1.502, 1.742, 1.608, 1.801, 1.090, 1.131, 1.448,
        1.055, 1.585, 1.142, 0.808, 1.517, 2.008, 1.713, 1.831, 1.236, 1.879,
        1.645, 1.403, 2.121, 2.051, 1.709, 0.933, 1.984, 2.011, 1.174, 1.908,
        1.341, 1.400, 1.298, 1.337, 1.366, 1.892, 1.466, 1.857, 0.781, 1.194,
        1.578, 1.826, 1.561, 2.243, 1.067, 1.696, 1.757, 1.791, 1.001, 1.330,
        1.158, 1.668, 1.040, 1.672, 1.382, 1.107, 1.097, 1.815, 1.681, 1.587],
       device='cuda:0')
b after update for 1 param tensor([151.591, 144.710, 150.001, 164.905, 147.959, 155.718, 144.561, 167.154,
        175.870, 168.280, 126.345, 131.238, 152.875, 157.437, 156.931, 158.826,
        147.904, 135.795, 163.375, 110.382, 137.522, 150.882, 170.475, 134.700,
        137.195, 148.160, 128.790, 152.699, 142.639, 138.809, 178.853, 140.895,
        136.175, 141.222, 133.888, 153.429, 156.899, 173.644, 138.232, 163.714,
        150.852, 155.766, 173.395, 144.747, 128.248, 134.801, 155.815, 124.753,
        153.646, 147.503, 131.060, 154.015, 167.538, 153.307, 159.131, 153.630,
        146.802, 169.391, 170.044, 164.469, 127.324, 160.548, 152.146, 129.367,
        150.701, 156.644, 144.458, 160.882, 128.329, 156.971, 100.876, 172.482,
        137.726, 141.670, 165.219, 137.881, 183.254, 127.235, 136.987, 105.643,
        139.841, 153.609, 132.534, 147.570, 169.938, 156.762, 177.027, 162.265,
        134.505, 122.722, 152.149, 152.371, 151.342, 152.687, 120.403, 150.327,
        162.854, 150.421, 190.225, 147.403, 141.961, 147.616, 159.988, 133.922,
        172.183, 137.517, 150.295, 151.045, 193.664, 143.083, 123.092, 151.142,
        137.002, 144.768, 151.291, 149.429, 138.867, 151.990, 138.544, 138.650,
        177.059, 148.435, 163.301, 148.139, 160.702, 131.330, 146.622, 143.715,
        161.870, 160.034, 174.648, 146.823, 163.934, 128.147, 156.063, 153.822,
        164.595, 152.183, 143.649, 152.418, 136.014, 131.385, 130.109, 148.909,
        163.854, 154.003, 169.590, 140.302, 165.727, 149.544, 131.491, 157.438,
        129.609, 163.876, 137.084, 141.898, 154.506, 167.600, 155.054, 154.753,
        137.541, 141.367, 153.891, 148.701, 131.815, 154.247, 142.721, 153.703,
        129.913, 143.363, 159.035, 150.010, 131.295, 158.304, 147.711, 133.531,
        139.860, 163.295, 134.486, 151.289, 130.004, 162.059, 150.004, 121.281,
        149.126, 170.016, 158.049, 169.329, 130.167, 150.887, 141.544, 158.585,
        145.058, 148.400, 148.409, 151.389, 154.713, 136.356, 125.525, 165.378,
        164.217, 126.729, 157.068, 159.611, 155.417, 164.909, 132.343, 123.421,
        160.124, 166.885, 141.093, 168.054, 155.399, 148.463, 145.604, 163.958,
        169.341, 144.264, 157.870, 158.272, 164.040, 165.954, 144.797, 149.372,
        160.130, 168.979, 149.004, 149.264, 149.158, 134.966, 169.464, 116.245,
        157.375, 133.366, 144.457, 163.947, 136.212, 159.599, 154.410, 163.129,
        156.497, 159.856, 112.349, 150.192, 161.760, 155.413, 164.482, 127.944,
        130.340, 147.468, 125.900, 154.312, 130.973, 110.184, 150.961, 173.666,
        160.389, 165.816, 136.268, 167.980, 157.188, 145.169, 178.496, 175.525,
        160.229, 118.397, 172.613, 173.792, 132.805, 169.280, 141.946, 144.993,
        139.613, 141.734, 143.266, 168.590, 148.377, 167.007, 108.326, 133.913,
        153.963, 165.631, 153.115, 183.559, 126.607, 159.606, 162.447, 164.035,
        122.621, 141.343, 131.881, 158.285, 124.979, 158.452, 144.101, 128.944,
        128.380, 165.096, 158.889, 154.397], device='cuda:0')
clipping threshold 0.191500346170177
a after update for 1 param tensor([[[ 2.568e-02],
         [ 1.101e-01],
         [-3.103e-02],
         [ 4.319e-02],
         [-9.354e-02],
         [ 7.582e-03],
         [-8.057e-02],
         [ 1.756e-02],
         [ 7.945e-02],
         [ 3.662e-02]],

        [[-1.378e-02],
         [ 6.616e-02],
         [ 9.886e-02],
         [-5.592e-02],
         [ 1.134e-01],
         [ 1.817e-02],
         [ 2.362e-02],
         [-8.230e-03],
         [-1.650e-01],
         [-2.719e-02]],

        [[ 8.498e-03],
         [-1.005e-02],
         [-2.912e-01],
         [ 4.496e-02],
         [-6.210e-03],
         [ 7.875e-02],
         [ 8.486e-02],
         [ 1.578e-01],
         [-2.658e-03],
         [-4.196e-03]],

        [[-6.187e-02],
         [-1.640e-02],
         [-4.032e-02],
         [ 1.300e-01],
         [-1.325e-01],
         [-7.951e-02],
         [ 8.243e-02],
         [-1.301e-01],
         [ 3.009e-02],
         [ 1.098e-01]],

        [[-1.212e-01],
         [ 1.710e-02],
         [ 8.678e-02],
         [-4.119e-02],
         [ 3.467e-02],
         [-7.764e-02],
         [-6.151e-02],
         [ 1.504e-01],
         [-8.765e-02],
         [ 1.341e-01]],

        [[-1.612e-01],
         [-2.686e-01],
         [-1.458e-01],
         [ 1.378e-01],
         [ 1.272e-02],
         [ 9.360e-02],
         [-2.032e-02],
         [-2.112e-02],
         [-8.134e-02],
         [ 9.369e-04]],

        [[-7.981e-02],
         [ 1.597e-02],
         [-9.584e-02],
         [ 2.490e-03],
         [ 3.679e-02],
         [ 5.105e-02],
         [ 4.633e-02],
         [-2.446e-01],
         [ 9.956e-02],
         [ 1.104e-01]],

        [[ 1.297e-02],
         [ 8.651e-02],
         [ 1.306e-01],
         [-1.648e-01],
         [ 1.847e-02],
         [-1.370e-01],
         [ 1.397e-02],
         [ 9.162e-02],
         [ 6.247e-02],
         [ 6.220e-02]],

        [[-1.246e-01],
         [ 1.505e-01],
         [ 1.303e-03],
         [ 1.429e-01],
         [-9.185e-02],
         [ 1.296e-01],
         [ 3.456e-02],
         [ 2.302e-02],
         [-1.505e-01],
         [-3.403e-02]],

        [[-8.393e-02],
         [-3.400e-02],
         [-5.878e-02],
         [ 6.986e-02],
         [ 8.933e-02],
         [ 6.735e-02],
         [ 2.337e-02],
         [-1.659e-01],
         [-5.288e-02],
         [-8.586e-02]],

        [[ 1.255e-02],
         [ 2.345e-01],
         [-2.196e-01],
         [-8.866e-02],
         [ 1.224e-01],
         [ 6.172e-02],
         [ 3.442e-02],
         [ 2.331e-03],
         [-1.607e-01],
         [-1.225e-01]],

        [[-1.482e-01],
         [-6.533e-02],
         [ 1.326e-01],
         [ 7.651e-02],
         [ 4.054e-02],
         [-8.756e-02],
         [ 5.202e-02],
         [ 1.020e-01],
         [-1.862e-01],
         [ 6.549e-02]],

        [[ 7.472e-02],
         [-6.606e-02],
         [-5.936e-02],
         [ 1.614e-01],
         [-4.713e-02],
         [-5.873e-02],
         [-8.503e-02],
         [ 2.119e-01],
         [-6.145e-03],
         [ 8.386e-02]],

        [[-2.347e-01],
         [ 2.049e-01],
         [ 9.116e-02],
         [-8.620e-02],
         [-1.075e-02],
         [-7.515e-03],
         [ 2.837e-02],
         [-7.616e-02],
         [-1.493e-01],
         [-8.571e-02]],

        [[-9.119e-02],
         [ 1.192e-01],
         [ 6.829e-02],
         [ 1.003e-01],
         [ 6.210e-02],
         [ 6.048e-02],
         [-2.308e-02],
         [ 5.786e-02],
         [ 1.178e-01],
         [-2.572e-02]],

        [[ 1.122e-01],
         [ 3.471e-02],
         [-1.798e-02],
         [-1.972e-02],
         [ 1.107e-02],
         [-1.023e-01],
         [-2.029e-01],
         [-8.677e-02],
         [ 6.284e-02],
         [-4.443e-02]],

        [[ 1.514e-01],
         [ 3.792e-02],
         [-7.854e-03],
         [-8.578e-02],
         [ 1.177e-01],
         [ 1.681e-02],
         [ 1.255e-01],
         [ 3.558e-02],
         [-7.195e-02],
         [ 1.588e-02]],

        [[ 8.973e-02],
         [-3.629e-02],
         [ 6.264e-02],
         [-8.887e-02],
         [-5.795e-02],
         [ 2.346e-02],
         [-1.117e-01],
         [ 4.459e-02],
         [-6.060e-02],
         [ 1.055e-01]],

        [[-2.639e-02],
         [-1.851e-01],
         [ 1.258e-01],
         [-8.164e-02],
         [ 6.231e-02],
         [ 4.165e-02],
         [ 5.475e-04],
         [ 4.086e-02],
         [-9.971e-02],
         [-1.759e-01]],

        [[-1.593e-01],
         [ 2.042e-02],
         [ 2.081e-02],
         [-9.012e-02],
         [ 8.855e-03],
         [ 1.245e-01],
         [-8.266e-02],
         [-1.124e-01],
         [ 1.017e-01],
         [-1.075e-01]],

        [[ 1.896e-01],
         [ 7.884e-02],
         [ 9.801e-02],
         [-1.165e-01],
         [ 1.967e-02],
         [-1.023e-02],
         [-8.029e-02],
         [ 3.267e-02],
         [ 6.488e-02],
         [-9.691e-03]],

        [[ 1.818e-01],
         [-3.317e-02],
         [ 3.228e-02],
         [ 6.696e-02],
         [-9.148e-02],
         [-9.368e-02],
         [-2.932e-02],
         [-8.013e-02],
         [-4.450e-02],
         [-8.315e-02]],

        [[-1.499e-01],
         [-2.242e-01],
         [-2.026e-01],
         [-1.179e-01],
         [ 3.369e-05],
         [ 8.974e-02],
         [ 1.673e-01],
         [ 9.333e-02],
         [ 4.121e-02],
         [ 7.208e-02]],

        [[-1.181e-01],
         [-4.918e-02],
         [-7.179e-02],
         [ 1.117e-03],
         [ 2.628e-02],
         [-2.325e-01],
         [ 1.399e-01],
         [ 4.118e-03],
         [-7.760e-02],
         [ 2.756e-01]],

        [[ 3.432e-02],
         [-3.635e-03],
         [ 2.540e-02],
         [ 1.222e-01],
         [ 7.688e-02],
         [ 9.823e-02],
         [-2.480e-02],
         [ 6.266e-02],
         [-9.891e-02],
         [-3.390e-02]],

        [[ 1.843e-01],
         [-6.198e-02],
         [-6.122e-02],
         [ 1.929e-01],
         [ 5.870e-02],
         [-1.005e-01],
         [ 1.008e-01],
         [-5.097e-02],
         [-1.337e-02],
         [ 4.982e-02]],

        [[ 3.530e-02],
         [ 1.870e-01],
         [-4.039e-02],
         [-6.561e-02],
         [-9.703e-02],
         [ 1.318e-02],
         [-2.248e-02],
         [ 5.830e-02],
         [-1.940e-01],
         [-1.836e-02]],

        [[-1.791e-02],
         [-5.200e-03],
         [-4.582e-01],
         [ 5.830e-02],
         [-3.435e-02],
         [ 1.716e-01],
         [-4.520e-02],
         [ 6.885e-02],
         [-3.804e-02],
         [ 9.314e-02]],

        [[-7.951e-02],
         [ 1.008e-03],
         [-1.644e-01],
         [ 2.156e-02],
         [ 1.761e-01],
         [-1.028e-01],
         [ 1.137e-01],
         [ 1.621e-02],
         [-2.131e-01],
         [ 2.703e-02]],

        [[-1.250e-02],
         [-1.066e-01],
         [ 1.412e-01],
         [ 9.604e-02],
         [-9.423e-02],
         [-8.201e-02],
         [ 4.172e-02],
         [-1.308e-01],
         [-5.275e-02],
         [ 1.255e-01]]], device='cuda:0')
s after update for 1 param tensor([[[1.288],
         [1.461],
         [1.929],
         [1.067],
         [1.860],
         [1.420],
         [1.105],
         [1.341],
         [1.193],
         [1.483]],

        [[1.461],
         [1.941],
         [1.359],
         [1.250],
         [1.567],
         [1.367],
         [1.684],
         [1.857],
         [1.786],
         [1.620]],

        [[1.078],
         [1.735],
         [1.558],
         [2.226],
         [1.917],
         [1.552],
         [1.482],
         [1.004],
         [1.032],
         [1.910]],

        [[1.098],
         [1.695],
         [2.096],
         [1.606],
         [1.263],
         [1.551],
         [1.384],
         [1.720],
         [1.411],
         [1.320]],

        [[1.973],
         [1.365],
         [1.742],
         [1.712],
         [1.674],
         [1.526],
         [1.093],
         [1.764],
         [1.556],
         [1.600]],

        [[1.930],
         [1.847],
         [1.443],
         [1.481],
         [1.510],
         [1.377],
         [1.098],
         [1.663],
         [1.813],
         [1.812]],

        [[1.411],
         [0.999],
         [1.136],
         [1.593],
         [1.616],
         [1.774],
         [1.068],
         [1.134],
         [1.823],
         [1.861]],

        [[1.957],
         [1.956],
         [0.943],
         [1.640],
         [1.130],
         [1.478],
         [1.541],
         [1.045],
         [1.548],
         [1.695]],

        [[1.328],
         [1.644],
         [1.287],
         [1.571],
         [1.716],
         [1.409],
         [1.203],
         [1.240],
         [1.239],
         [1.553]],

        [[1.374],
         [1.570],
         [1.535],
         [1.336],
         [1.788],
         [1.620],
         [1.445],
         [1.647],
         [1.938],
         [1.544]],

        [[1.896],
         [1.910],
         [1.733],
         [1.965],
         [1.676],
         [1.688],
         [1.583],
         [1.126],
         [1.074],
         [1.378]],

        [[1.776],
         [1.028],
         [1.410],
         [1.554],
         [1.670],
         [1.133],
         [1.842],
         [1.731],
         [1.898],
         [1.597]],

        [[1.851],
         [0.860],
         [1.905],
         [1.396],
         [1.368],
         [1.711],
         [1.311],
         [1.260],
         [2.097],
         [1.490]],

        [[1.509],
         [1.802],
         [1.069],
         [1.551],
         [1.402],
         [1.373],
         [1.473],
         [1.686],
         [1.901],
         [1.988]],

        [[1.493],
         [1.600],
         [1.076],
         [1.415],
         [1.895],
         [1.995],
         [1.361],
         [1.526],
         [1.353],
         [2.001]],

        [[1.708],
         [2.358],
         [1.983],
         [1.314],
         [1.687],
         [1.173],
         [1.787],
         [1.663],
         [1.878],
         [1.770]],

        [[1.894],
         [1.713],
         [1.022],
         [2.030],
         [1.837],
         [2.277],
         [1.398],
         [1.241],
         [1.470],
         [1.507]],

        [[1.655],
         [1.725],
         [1.335],
         [1.016],
         [1.407],
         [1.198],
         [1.264],
         [0.906],
         [1.252],
         [1.965]],

        [[1.056],
         [1.155],
         [1.637],
         [1.649],
         [1.707],
         [1.935],
         [1.328],
         [1.650],
         [1.085],
         [1.666]],

        [[2.232],
         [1.676],
         [1.939],
         [1.580],
         [1.656],
         [1.787],
         [1.947],
         [1.350],
         [1.411],
         [1.959]],

        [[1.772],
         [1.238],
         [0.880],
         [2.095],
         [1.415],
         [1.289],
         [1.444],
         [1.310],
         [1.529],
         [1.449]],

        [[1.824],
         [1.587],
         [1.679],
         [1.529],
         [1.374],
         [1.722],
         [1.824],
         [1.480],
         [1.493],
         [1.565]],

        [[0.646],
         [1.229],
         [1.653],
         [1.504],
         [1.107],
         [1.397],
         [1.506],
         [1.231],
         [2.014],
         [1.658]],

        [[0.927],
         [1.648],
         [0.995],
         [1.702],
         [1.384],
         [0.944],
         [1.520],
         [1.877],
         [0.890],
         [1.369]],

        [[1.197],
         [1.461],
         [1.571],
         [1.373],
         [1.349],
         [1.843],
         [1.810],
         [1.689],
         [1.205],
         [1.160]],

        [[1.406],
         [1.839],
         [1.667],
         [1.679],
         [1.653],
         [1.632],
         [0.574],
         [1.483],
         [1.178],
         [1.641]],

        [[1.144],
         [1.648],
         [1.598],
         [2.110],
         [1.311],
         [1.349],
         [1.602],
         [1.836],
         [1.864],
         [1.581]],

        [[1.390],
         [1.662],
         [1.573],
         [1.446],
         [1.516],
         [1.761],
         [1.653],
         [1.375],
         [1.742],
         [1.233]],

        [[1.598],
         [1.154],
         [1.773],
         [1.201],
         [1.630],
         [1.652],
         [1.084],
         [1.749],
         [2.286],
         [1.306]],

        [[1.694],
         [1.869],
         [1.448],
         [1.913],
         [1.549],
         [1.174],
         [1.288],
         [2.069],
         [1.524],
         [0.643]]], device='cuda:0')
b after update for 1 param tensor([[[139.065],
         [148.124],
         [170.219],
         [126.624],
         [167.163],
         [146.031],
         [128.818],
         [141.949],
         [133.872],
         [149.225]],

        [[148.159],
         [170.735],
         [142.862],
         [137.018],
         [153.417],
         [143.307],
         [159.041],
         [167.014],
         [163.809],
         [155.980]],

        [[127.225],
         [161.449],
         [152.953],
         [182.863],
         [169.680],
         [152.703],
         [149.181],
         [122.824],
         [124.492],
         [169.386]],

        [[128.406],
         [159.556],
         [177.441],
         [155.333],
         [137.744],
         [152.614],
         [144.161],
         [160.736],
         [145.570],
         [140.817]],

        [[172.170],
         [143.185],
         [161.748],
         [160.345],
         [158.587],
         [151.377],
         [128.123],
         [162.783],
         [152.866],
         [155.035]],

        [[170.280],
         [166.558],
         [147.198],
         [149.170],
         [150.597],
         [143.809],
         [128.435],
         [158.046],
         [165.028],
         [164.970]],

        [[145.601],
         [122.473],
         [130.646],
         [154.697],
         [155.799],
         [163.244],
         [126.643],
         [130.515],
         [165.471],
         [167.176]],

        [[171.449],
         [171.402],
         [119.024],
         [156.937],
         [130.281],
         [149.000],
         [152.159],
         [125.284],
         [152.467],
         [159.550]],

        [[141.231],
         [157.131],
         [139.059],
         [153.623],
         [160.543],
         [145.471],
         [134.441],
         [136.471],
         [136.437],
         [152.720]],

        [[143.655],
         [153.544],
         [151.847],
         [141.677],
         [163.875],
         [156.012],
         [147.320],
         [157.271],
         [170.622],
         [152.275]],

        [[168.775],
         [169.389],
         [161.344],
         [171.783],
         [158.686],
         [159.233],
         [154.182],
         [130.024],
         [127.031],
         [143.857]],

        [[163.338],
         [124.234],
         [145.526],
         [152.793],
         [158.375],
         [130.475],
         [166.357],
         [161.224],
         [168.846],
         [154.875]],

        [[166.759],
         [113.634],
         [169.169],
         [144.825],
         [143.365],
         [160.333],
         [140.334],
         [137.591],
         [177.489],
         [149.597]],

        [[150.548],
         [164.531],
         [126.705],
         [152.625],
         [145.132],
         [143.625],
         [148.761],
         [159.155],
         [168.974],
         [172.801]],

        [[149.769],
         [155.026],
         [127.110],
         [145.803],
         [168.691],
         [173.102],
         [142.978],
         [151.382],
         [142.566],
         [173.377]],

        [[160.163],
         [188.211],
         [172.570],
         [140.470],
         [159.172],
         [132.742],
         [163.820],
         [158.046],
         [167.972],
         [163.037]],

        [[168.690],
         [160.411],
         [123.899],
         [174.613],
         [166.128],
         [184.927],
         [144.900],
         [136.524],
         [148.582],
         [150.445]],

        [[157.671],
         [160.967],
         [141.599],
         [123.513],
         [145.351],
         [134.131],
         [137.808],
         [116.628],
         [137.132],
         [171.807]],

        [[125.954],
         [131.701],
         [156.794],
         [157.392],
         [160.143],
         [170.490],
         [141.233],
         [157.428],
         [127.660],
         [158.167]],

        [[183.088],
         [158.649],
         [170.646],
         [154.060],
         [157.731],
         [163.853],
         [171.024],
         [142.414],
         [145.563],
         [171.532]],

        [[163.160],
         [136.361],
         [114.976],
         [177.408],
         [145.803],
         [139.121],
         [147.256],
         [140.279],
         [151.536],
         [147.534]],

        [[165.510],
         [154.392],
         [158.795],
         [151.552],
         [143.681],
         [160.822],
         [165.533],
         [149.112],
         [149.777],
         [153.327]],

        [[ 98.468],
         [135.887],
         [157.556],
         [150.280],
         [128.962],
         [144.854],
         [150.388],
         [135.953],
         [173.943],
         [157.823]],

        [[118.016],
         [157.326],
         [122.257],
         [159.874],
         [144.190],
         [119.102],
         [151.089],
         [167.908],
         [115.644],
         [143.422]],

        [[134.091],
         [148.162],
         [153.595],
         [143.596],
         [142.361],
         [166.368],
         [164.875],
         [159.280],
         [134.563],
         [132.027]],

        [[145.335],
         [166.185],
         [158.237],
         [158.784],
         [157.581],
         [156.564],
         [ 92.884],
         [149.259],
         [133.025],
         [156.980]],

        [[131.104],
         [157.324],
         [154.911],
         [178.031],
         [140.328],
         [142.373],
         [155.121],
         [166.060],
         [167.319],
         [154.123]],

        [[144.479],
         [158.001],
         [153.734],
         [147.360],
         [150.908],
         [162.636],
         [157.596],
         [143.726],
         [161.745],
         [136.090]],

        [[154.923],
         [131.646],
         [163.211],
         [134.288],
         [156.487],
         [157.533],
         [127.605],
         [162.079],
         [185.293],
         [140.040]],

        [[159.499],
         [167.571],
         [147.499],
         [169.527],
         [152.535],
         [132.776],
         [139.083],
         [176.286],
         [151.285],
         [ 98.293]]], device='cuda:0')
clipping threshold 0.191500346170177
a after update for 1 param tensor([[-0.085],
        [-0.131],
        [ 0.004],
        [ 0.008],
        [-0.046],
        [-0.180],
        [-0.044],
        [-0.107],
        [-0.163],
        [ 0.048],
        [ 0.040],
        [-0.057],
        [ 0.113],
        [ 0.068],
        [-0.118],
        [ 0.005],
        [-0.105],
        [-0.050],
        [-0.075],
        [-0.014],
        [-0.150],
        [-0.039],
        [ 0.023],
        [-0.005],
        [ 0.132],
        [-0.012],
        [ 0.101],
        [-0.131],
        [-0.053],
        [-0.132]], device='cuda:0')
s after update for 1 param tensor([[1.641],
        [1.624],
        [1.009],
        [1.987],
        [1.717],
        [1.545],
        [1.539],
        [2.075],
        [2.075],
        [0.888],
        [1.700],
        [1.475],
        [1.043],
        [1.571],
        [1.316],
        [1.754],
        [1.996],
        [1.135],
        [1.847],
        [1.570],
        [1.601],
        [1.405],
        [1.114],
        [2.166],
        [2.039],
        [1.387],
        [1.880],
        [1.038],
        [1.125],
        [1.601]], device='cuda:0')
b after update for 1 param tensor([[157.003],
        [156.201],
        [123.118],
        [172.746],
        [160.575],
        [152.333],
        [152.038],
        [176.543],
        [176.531],
        [115.465],
        [159.801],
        [148.836],
        [125.138],
        [153.620],
        [140.610],
        [162.304],
        [173.161],
        [130.587],
        [166.565],
        [153.542],
        [155.073],
        [145.246],
        [129.341],
        [180.362],
        [174.990],
        [144.335],
        [168.023],
        [124.851],
        [129.992],
        [155.060]], device='cuda:0')
clipping threshold 0.191500346170177
||w||^2 0.12816086082947747
exp ma of ||w||^2 0.08208122389989833
||w|| 0.35799561565678073
exp ma of ||w|| 0.28138126519094225
||w||^2 0.07499433236527932
exp ma of ||w||^2 0.07274706265438652
||w|| 0.2738509309191395
exp ma of ||w|| 0.2628958519485259
||w||^2 0.10699803874458783
exp ma of ||w||^2 0.07673694111449439
||w|| 0.32710554679581305
exp ma of ||w|| 0.27059742891444866
||w||^2 0.057648420402798606
exp ma of ||w||^2 0.07736152245789221
||w|| 0.2401008546482053
exp ma of ||w|| 0.2724735024204645
||w||^2 0.06305796863466225
exp ma of ||w||^2 0.07160455448083827
||w|| 0.25111345769325516
exp ma of ||w|| 0.26203986390268963
||w||^2 0.0783674773351458
exp ma of ||w||^2 0.07075356672341462
||w|| 0.2799419177885759
exp ma of ||w|| 0.26007738789746027
||w||^2 0.059896745219109995
exp ma of ||w||^2 0.07094981228317149
||w|| 0.24473811558298392
exp ma of ||w|| 0.26174186285942563
||w||^2 0.0713427803164834
exp ma of ||w||^2 0.07371729957501669
||w|| 0.2671006932160293
exp ma of ||w|| 0.26717840487256556
cuda
Objective function 28.84 = squared loss an data 26.86 + 0.5*rho*h**2 0.459779 + alpha*h 0.523280 + L2reg 0.76 + L1reg 0.24 ; SHD = 66 ; DAG True
Proportion of microbatches that were clipped  0.7576000641694073
iteration 2 in inner loop, alpha 172.56176320037366 rho 100000.0 h 0.0030324226538667176
iteration 4 in outer loop, alpha = 475.8040285870454, rho = 100000.0, h = 0.0030324226538667176
cuda
9630
cuda
Objective function 29.76 = squared loss an data 26.86 + 0.5*rho*h**2 0.459779 + alpha*h 1.442839 + L2reg 0.76 + L1reg 0.24 ; SHD = 66 ; DAG True
||w||^2 797817083.6587585
exp ma of ||w||^2 1443004627678.7324
||w|| 28245.656013956526
exp ma of ||w|| 516690.7530240604
||w||^2 6581691.871256662
exp ma of ||w||^2 367955673987.6596
||w|| 2565.4808265229076
exp ma of ||w|| 139676.01309774595
||w||^2 3510.2385823406667
exp ma of ||w||^2 17864731709.780674
||w|| 59.24726645458562
exp ma of ||w|| 7060.480200482166
||w||^2 0.08662702861681877
exp ma of ||w||^2 0.0679202985081558
||w|| 0.29432469929793315
exp ma of ||w|| 0.25697217968236025
||w||^2 0.04231537309400821
exp ma of ||w||^2 0.06884584846635365
||w|| 0.20570700788745191
exp ma of ||w|| 0.25786253883775584
v before min max tensor([[-2.132, -3.995, -4.474,  ..., 47.338, -5.629, -1.338],
        [-9.146, 36.912, -7.798,  ...,  3.777, -6.256, -7.024],
        [-4.065, -2.742, -7.371,  ..., -6.366, 12.248,  5.773],
        ...,
        [ 0.965,  9.083, -6.470,  ..., -4.577,  4.101, -2.537],
        [-5.491, -5.409, -3.580,  ..., -4.286,  1.113, 42.146],
        [ 5.333, -4.328, -6.442,  ..., -6.031, -6.522, 13.749]],
       device='cuda:0')
v tensor([[1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e+01, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 3.777e+00, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         5.773e+00],
        ...,
        [9.649e-01, 9.083e+00, 1.000e-12,  ..., 1.000e-12, 4.101e+00,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.113e+00,
         1.000e+01],
        [5.333e+00, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e+01]], device='cuda:0')
v before min max tensor([-5.552e+00,  3.362e+00, -8.077e+00, -3.021e+00, -4.955e+00, -6.623e+00,
        -8.357e+00, -3.619e+00, -9.857e-01, -3.246e-01, -3.507e+00,  3.371e+01,
         4.523e-01, -3.042e+00, -2.843e+00, -5.893e+00, -5.536e+00, -2.845e+00,
        -5.400e+00,  1.963e+01, -2.911e+00, -3.521e+00,  2.024e+01, -2.351e-01,
         4.164e+00, -7.962e+00, -4.177e+00,  2.258e+00, -6.419e+00, -4.818e+00,
        -4.372e+00,  2.224e-01,  1.971e-01, -6.175e+00, -5.734e+00, -2.472e+00,
         1.975e+00, -2.229e+00, -5.311e+00, -7.941e-01, -5.160e+00,  7.952e+00,
        -6.308e+00,  2.432e+01, -4.052e+00, -7.115e-01, -5.241e+00,  5.770e+00,
         7.718e+01, -3.546e+00,  6.526e+00, -3.791e+00,  2.795e-01,  4.170e+01,
        -5.904e+00,  1.887e-01, -5.567e+00, -5.277e+00, -4.452e-02,  7.705e+00,
        -1.390e+00, -1.672e+00,  1.993e+01, -1.969e+00, -3.378e+00,  1.159e+01,
        -3.543e+00, -4.600e+00, -2.513e+00,  4.051e+00,  5.609e-01,  1.079e+00,
        -3.273e+00, -2.057e+00, -6.192e+00, -5.571e+00, -3.558e+00, -6.953e+00,
         8.749e+00,  2.993e+01, -4.243e+00,  1.083e+01,  4.965e-01, -4.137e+00,
        -3.455e+00,  1.080e+00, -2.415e+00,  7.798e+00,  1.776e+01, -7.881e+00,
        -6.001e+00,  2.156e+01, -4.068e+00,  2.068e+01, -3.396e+00, -3.351e+00,
        -6.805e+00, -2.355e+00,  1.604e+01, -2.730e+00, -7.087e+00, -5.100e+00,
        -6.006e+00, -1.391e+00, -1.012e+01, -4.889e+00, -6.402e+00,  3.585e+00,
        -2.680e+00,  1.423e+01, -1.925e+00, -7.013e+00, -5.223e+00, -7.348e-01,
        -2.368e+00, -7.764e+00, -5.638e+00,  1.405e+01, -2.522e+00, -7.921e+00,
         1.443e+01, -1.334e+00,  4.620e-01,  3.022e+01, -8.694e-01,  6.591e-01,
         8.663e+00,  4.711e+00, -4.270e+00, -4.517e+00, -1.458e+00, -5.361e+00,
        -1.819e+00,  4.863e+00,  1.111e+01, -6.372e+00,  4.564e+00, -4.213e+00,
        -7.964e+00,  2.591e+01, -7.772e-01,  3.097e+00, -4.696e+00, -5.024e+00,
        -9.499e+00,  6.411e+01, -2.707e+00, -2.122e+00,  7.925e+00, -4.810e+00,
         8.513e-01, -6.889e+00, -6.094e+00, -3.912e+00, -6.381e+00,  1.494e+01,
        -2.663e+00,  1.267e+01, -3.421e+00, -5.299e+00, -8.374e+00, -4.312e+00,
        -7.355e+00, -8.918e+00, -2.533e+00, -6.176e+00,  2.373e+00, -3.033e+00,
        -6.580e+00, -4.296e+00, -1.088e+01, -1.148e+00, -4.883e+00, -2.810e+00,
         3.162e+01, -6.622e+00,  4.540e+00,  1.827e+01, -3.435e+00, -4.153e+00,
        -3.563e+00, -4.174e+00, -2.359e+00, -2.054e+00,  1.115e+01, -5.018e+00,
         6.523e+00, -7.337e+00,  2.082e+01, -2.597e+00, -1.096e+00, -3.498e+00,
         4.503e+00,  3.585e+00, -1.736e+00, -2.072e-01, -4.618e+00, -5.516e+00,
        -7.737e+00, -2.914e+00,  9.249e+00, -5.854e+00, -4.444e+00,  1.181e+01,
         4.234e+00,  3.239e+00, -3.919e-01, -6.617e+00, -6.503e+00, -5.218e+00,
        -5.914e+00,  3.059e+00, -5.163e+00, -3.899e+00, -7.744e+00,  2.196e+00,
         7.133e+00, -2.613e+00, -6.652e+00, -7.706e+00, -4.893e+00, -3.759e+00,
        -5.297e+00, -3.819e+00,  2.953e+00,  2.795e+00, -9.071e+00, -3.815e+00,
         1.687e+01, -2.309e+00,  9.723e+00, -3.679e+00, -5.013e+00,  2.273e+00,
        -3.209e+00, -9.636e+00,  9.260e+00, -5.595e+00, -6.956e+00, -4.811e+00,
        -3.408e+00,  2.667e+01, -2.770e+00, -8.097e+00, -3.225e+00,  9.366e+00,
         5.592e+00, -9.916e-01, -7.444e+00, -4.146e+00, -5.870e+00, -2.024e+00,
         1.775e+01, -2.583e+00, -2.137e+00, -4.963e+00,  2.130e+01, -4.950e+00,
         3.539e+00, -3.864e+00, -2.552e+00,  1.016e+01, -3.750e+00, -8.083e+00,
        -7.315e+00, -5.201e+00,  1.162e+00, -7.110e+00,  2.862e+00, -1.883e+00,
        -6.603e+00,  5.055e+00, -3.283e+00,  1.841e+01, -8.041e+00, -7.613e+00,
        -5.378e+00,  3.620e+00, -2.984e+00, -5.048e+00, -1.655e-01,  1.541e+01,
         4.274e+01,  1.614e+01,  6.993e+00,  2.066e+01, -4.719e+00, -3.412e+00,
        -7.116e+00,  4.563e+00, -5.761e-01, -5.702e+00, -6.159e-01, -6.331e+00,
        -8.464e+00,  1.825e-02, -8.845e+00, -7.088e+00, -5.723e+00, -3.299e+00],
       device='cuda:0')
v tensor([1.000e-12, 3.362e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        4.523e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        4.164e+00, 1.000e-12, 1.000e-12, 2.258e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 2.224e-01, 1.971e-01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.975e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 7.952e+00,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 5.770e+00,
        1.000e+01, 1.000e-12, 6.526e+00, 1.000e-12, 2.795e-01, 1.000e+01,
        1.000e-12, 1.887e-01, 1.000e-12, 1.000e-12, 1.000e-12, 7.705e+00,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 4.051e+00, 5.609e-01, 1.079e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        8.749e+00, 1.000e+01, 1.000e-12, 1.000e+01, 4.965e-01, 1.000e-12,
        1.000e-12, 1.080e+00, 1.000e-12, 7.798e+00, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.585e+00,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 4.620e-01, 1.000e+01, 1.000e-12, 6.591e-01,
        8.663e+00, 4.711e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 4.863e+00, 1.000e+01, 1.000e-12, 4.564e+00, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 3.097e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 7.925e+00, 1.000e-12,
        8.513e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.373e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 4.540e+00, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        6.523e+00, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        4.503e+00, 3.585e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 9.249e+00, 1.000e-12, 1.000e-12, 1.000e+01,
        4.234e+00, 3.239e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 3.059e+00, 1.000e-12, 1.000e-12, 1.000e-12, 2.196e+00,
        7.133e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 2.953e+00, 2.795e+00, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 9.723e+00, 1.000e-12, 1.000e-12, 2.273e+00,
        1.000e-12, 1.000e-12, 9.260e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 9.366e+00,
        5.592e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        3.539e+00, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.162e+00, 1.000e-12, 2.862e+00, 1.000e-12,
        1.000e-12, 5.055e+00, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 3.620e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 6.993e+00, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 4.563e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.825e-02, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[ -1.554],
         [ -1.632],
         [ -3.083],
         [  6.508],
         [ -6.596],
         [ -3.111],
         [ 18.640],
         [ -3.962],
         [ -1.122],
         [ -1.970]],

        [[ -1.318],
         [  2.156],
         [ -4.574],
         [ -3.514],
         [ -5.555],
         [  9.011],
         [ -7.717],
         [ -4.915],
         [ -2.130],
         [ 13.249]],

        [[  6.731],
         [ -5.209],
         [ -8.024],
         [ -4.775],
         [ -5.906],
         [  0.709],
         [ -7.873],
         [ -9.095],
         [ -5.972],
         [ -9.162]],

        [[ -1.693],
         [  5.782],
         [ -3.482],
         [ -1.300],
         [ -0.625],
         [ -9.143],
         [ -2.056],
         [  0.514],
         [ -5.799],
         [ 14.938]],

        [[ -3.122],
         [ 67.422],
         [ -6.188],
         [ 17.453],
         [ -5.070],
         [  4.292],
         [ -5.211],
         [  0.592],
         [ 24.750],
         [ -3.198]],

        [[  9.880],
         [ -4.950],
         [ -7.170],
         [  8.942],
         [ 27.483],
         [ -8.351],
         [ 11.935],
         [ -4.869],
         [ -3.083],
         [ -6.884]],

        [[ 13.947],
         [  0.168],
         [ -2.385],
         [  3.117],
         [ 26.627],
         [  2.447],
         [ -2.725],
         [ 24.335],
         [ -6.624],
         [ -6.035]],

        [[ -7.289],
         [ 43.215],
         [ -6.933],
         [ -5.953],
         [ -3.873],
         [ 11.978],
         [ 48.243],
         [102.469],
         [ -3.726],
         [  0.766]],

        [[ -5.692],
         [  0.285],
         [ -6.078],
         [ -7.412],
         [  1.536],
         [ -4.984],
         [ 11.253],
         [ -0.177],
         [  9.620],
         [ -4.883]],

        [[  5.502],
         [  0.234],
         [ -9.631],
         [ -0.217],
         [ -4.396],
         [ -6.956],
         [ -7.180],
         [ -6.590],
         [ -4.054],
         [ -1.829]],

        [[ -5.542],
         [ -6.545],
         [ -4.987],
         [ -3.026],
         [ -2.740],
         [ 19.843],
         [ -1.056],
         [ -5.750],
         [ -1.592],
         [  0.199]],

        [[ 28.734],
         [ -1.229],
         [  1.382],
         [ -4.126],
         [ -6.075],
         [ -1.246],
         [ -9.626],
         [ -4.757],
         [ -5.617],
         [  8.768]],

        [[-10.269],
         [ -7.436],
         [ -3.515],
         [  9.061],
         [ -1.782],
         [ -7.612],
         [ 50.670],
         [ -0.599],
         [ -3.761],
         [ 31.367]],

        [[ -5.975],
         [ 28.762],
         [  5.164],
         [ -4.585],
         [ -4.767],
         [ -7.131],
         [ 15.405],
         [ -9.188],
         [ 14.782],
         [ -4.181]],

        [[ -7.024],
         [ 18.755],
         [  4.953],
         [ -3.857],
         [ -9.220],
         [  2.395],
         [ -7.336],
         [ -7.999],
         [ -3.671],
         [ -4.243]],

        [[ -6.139],
         [  0.185],
         [ -5.658],
         [ 12.633],
         [  0.654],
         [  0.319],
         [ 22.342],
         [ -3.784],
         [ -0.435],
         [  3.545]],

        [[ -6.534],
         [ 27.726],
         [ -5.755],
         [ -5.727],
         [ -4.532],
         [ -5.199],
         [  0.173],
         [ -2.359],
         [ 54.562],
         [ -4.502]],

        [[ -6.580],
         [ -2.610],
         [ -3.457],
         [  1.955],
         [  0.500],
         [ -1.209],
         [ -5.839],
         [  0.812],
         [  1.564],
         [ -4.187]],

        [[  2.081],
         [ -8.227],
         [ -1.739],
         [ -5.844],
         [ -5.198],
         [  1.209],
         [ 11.288],
         [ -4.632],
         [ -8.153],
         [ -4.761]],

        [[ -6.275],
         [  3.061],
         [ -4.419],
         [  7.555],
         [ -6.872],
         [ 10.610],
         [  3.170],
         [ -4.621],
         [ -1.921],
         [ 12.449]],

        [[ -5.563],
         [ 11.780],
         [  7.109],
         [ -6.018],
         [ 31.714],
         [ -5.153],
         [ -6.565],
         [ -4.859],
         [ -7.532],
         [ -4.519]],

        [[ -2.734],
         [ 12.141],
         [ -5.750],
         [ -0.362],
         [  1.368],
         [ -4.751],
         [ -5.591],
         [ -4.658],
         [ -4.721],
         [ -5.339]],

        [[ -7.361],
         [ -5.762],
         [  1.135],
         [  0.243],
         [ -6.790],
         [ -5.740],
         [ -4.519],
         [ -6.457],
         [  9.375],
         [ -1.342]],

        [[ 31.692],
         [ -5.691],
         [ -2.826],
         [ -3.843],
         [ 10.431],
         [ -5.682],
         [ -1.294],
         [ -8.267],
         [ -1.761],
         [ -0.449]],

        [[ -2.082],
         [  0.583],
         [ -4.805],
         [ -7.164],
         [ -6.622],
         [  1.545],
         [ -4.128],
         [ -3.396],
         [ 26.286],
         [ -0.793]],

        [[  2.939],
         [ -4.048],
         [ -3.110],
         [  0.707],
         [ -4.617],
         [ -7.701],
         [  6.068],
         [ -6.735],
         [  1.061],
         [ -5.896]],

        [[  3.182],
         [ -5.074],
         [ -1.367],
         [ -4.727],
         [ -5.714],
         [ 23.764],
         [ -7.223],
         [ -3.039],
         [ -8.428],
         [ -3.152]],

        [[ -6.043],
         [  1.823],
         [ -0.511],
         [ -6.621],
         [ -5.495],
         [ -8.778],
         [ -5.364],
         [ -5.082],
         [ -6.638],
         [ -7.853]],

        [[ -2.595],
         [ -8.251],
         [ -3.718],
         [ -7.767],
         [ -5.408],
         [  3.712],
         [ -9.666],
         [ 12.885],
         [ 30.057],
         [ -6.390]],

        [[  3.116],
         [ -7.540],
         [  7.479],
         [  1.961],
         [  2.794],
         [ -9.104],
         [ -7.855],
         [  4.362],
         [ -8.452],
         [ 39.334]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.508e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [2.156e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [9.011e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[6.731e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.086e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [5.782e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.141e-01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [4.292e+00],
         [1.000e-12],
         [5.918e-01],
         [1.000e+01],
         [1.000e-12]],

        [[9.880e+00],
         [1.000e-12],
         [1.000e-12],
         [8.942e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.677e-01],
         [1.000e-12],
         [3.117e+00],
         [1.000e+01],
         [2.447e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [7.663e-01]],

        [[1.000e-12],
         [2.851e-01],
         [1.000e-12],
         [1.000e-12],
         [1.536e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [9.620e+00],
         [1.000e-12]],

        [[5.502e+00],
         [2.343e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.988e-01]],

        [[1.000e+01],
         [1.000e-12],
         [1.382e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [8.768e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [9.061e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [5.164e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [4.953e+00],
         [1.000e-12],
         [1.000e-12],
         [2.395e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.851e-01],
         [1.000e-12],
         [1.000e+01],
         [6.536e-01],
         [3.194e-01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [3.545e+00]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.726e-01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.955e+00],
         [5.002e-01],
         [1.000e-12],
         [1.000e-12],
         [8.118e-01],
         [1.564e+00],
         [1.000e-12]],

        [[2.081e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.209e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [3.061e+00],
         [1.000e-12],
         [7.555e+00],
         [1.000e-12],
         [1.000e+01],
         [3.170e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [7.109e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.368e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.135e+00],
         [2.430e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [9.375e+00],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [5.830e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.545e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[2.939e+00],
         [1.000e-12],
         [1.000e-12],
         [7.067e-01],
         [1.000e-12],
         [1.000e-12],
         [6.068e+00],
         [1.000e-12],
         [1.061e+00],
         [1.000e-12]],

        [[3.182e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.823e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.712e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[3.116e+00],
         [1.000e-12],
         [7.479e+00],
         [1.961e+00],
         [2.794e+00],
         [1.000e-12],
         [1.000e-12],
         [4.362e+00],
         [1.000e-12],
         [1.000e+01]]], device='cuda:0')
v before min max tensor([[ 1.947],
        [-2.547],
        [42.040],
        [ 8.999],
        [-4.575],
        [ 1.728],
        [-3.767],
        [-0.443],
        [-5.411],
        [ 7.626],
        [-8.151],
        [-5.878],
        [-6.717],
        [-3.066],
        [-4.101],
        [12.314],
        [ 5.334],
        [-6.916],
        [-5.717],
        [24.729],
        [ 3.712],
        [17.487],
        [-3.475],
        [30.904],
        [-5.966],
        [ 1.407],
        [ 0.745],
        [-6.511],
        [-7.511],
        [-5.173]], device='cuda:0')
v tensor([[1.947e+00],
        [1.000e-12],
        [1.000e+01],
        [8.999e+00],
        [1.000e-12],
        [1.728e+00],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [7.626e+00],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [5.334e+00],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [3.712e+00],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.407e+00],
        [7.447e-01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-0.010, -0.022, -0.014,  ..., -0.020,  0.029, -0.008],
        [ 0.016,  0.053, -0.041,  ...,  0.017,  0.025, -0.050],
        [ 0.016,  0.019, -0.035,  ...,  0.029, -0.017, -0.077],
        ...,
        [-0.013, -0.076,  0.019,  ..., -0.123,  0.051, -0.002],
        [-0.010, -0.033,  0.045,  ..., -0.011,  0.030, -0.001],
        [ 0.018,  0.044, -0.012,  ..., -0.042,  0.033,  0.023]],
       device='cuda:0')
s after update for 1 param tensor([[2.422, 0.906, 0.952,  ..., 1.946, 1.330, 1.668],
        [1.892, 1.926, 1.631,  ..., 1.179, 1.388, 1.427],
        [2.154, 1.259, 1.486,  ..., 1.280, 1.659, 1.628],
        ...,
        [1.467, 1.613, 1.315,  ..., 0.917, 1.534, 1.942],
        [1.239, 1.551, 1.485,  ..., 0.978, 1.550, 2.355],
        [1.726, 1.037, 1.286,  ..., 1.251, 1.344, 2.280]], device='cuda:0')
b after update for 1 param tensor([[183.785, 112.429, 115.213,  ..., 164.730, 136.206, 152.490],
        [162.419, 163.859, 150.804,  ..., 128.197, 139.132, 141.065],
        [173.321, 132.508, 143.964,  ..., 133.623, 152.082, 150.652],
        ...,
        [143.043, 149.980, 135.427,  ..., 113.062, 146.235, 164.540],
        [131.424, 147.070, 143.901,  ..., 116.780, 147.001, 181.218],
        [155.129, 120.243, 133.912,  ..., 132.090, 136.874, 178.293]],
       device='cuda:0')
clipping threshold 0.2160525932205314
a after update for 1 param tensor([ 0.145, -0.117, -0.037, -0.045,  0.081, -0.023, -0.063,  0.030,  0.033,
        -0.086, -0.071,  0.003, -0.139, -0.013, -0.140, -0.096, -0.063, -0.063,
        -0.080, -0.054, -0.116, -0.112,  0.015, -0.066,  0.029, -0.190,  0.035,
         0.066, -0.154,  0.042,  0.019,  0.050, -0.166, -0.037,  0.076,  0.036,
         0.124,  0.022,  0.116,  0.070, -0.008,  0.074,  0.012, -0.134, -0.065,
        -0.070, -0.019, -0.105,  0.049,  0.176, -0.150, -0.046, -0.008,  0.012,
        -0.019, -0.051,  0.103,  0.076, -0.141,  0.019, -0.102, -0.061,  0.007,
        -0.042,  0.020,  0.224, -0.014, -0.174, -0.123,  0.041,  0.025,  0.131,
        -0.104,  0.050, -0.040,  0.087, -0.018, -0.125, -0.085,  0.022, -0.020,
        -0.182,  0.033,  0.187,  0.052,  0.071, -0.052, -0.011,  0.041, -0.011,
         0.008,  0.111, -0.002,  0.110, -0.005, -0.230, -0.020, -0.088,  0.041,
         0.004, -0.010,  0.011,  0.037, -0.148, -0.016,  0.110,  0.005,  0.063,
         0.035, -0.181,  0.121,  0.066, -0.214, -0.031,  0.025,  0.029,  0.102,
        -0.071,  0.011,  0.027, -0.147,  0.044,  0.053, -0.003, -0.028,  0.050,
         0.039, -0.006,  0.016, -0.068,  0.066, -0.226, -0.171,  0.007,  0.068,
         0.064, -0.092, -0.007,  0.014, -0.102, -0.076, -0.011, -0.138,  0.022,
        -0.081,  0.002, -0.014, -0.189, -0.090,  0.034,  0.111, -0.006,  0.112,
        -0.017,  0.092, -0.040, -0.154,  0.065,  0.011,  0.071, -0.027, -0.008,
        -0.023, -0.078,  0.093, -0.092,  0.116, -0.087,  0.056, -0.051,  0.222,
        -0.004,  0.084, -0.096, -0.029, -0.050,  0.024,  0.006,  0.094, -0.092,
         0.018,  0.106, -0.085, -0.055, -0.034, -0.055, -0.066,  0.125, -0.034,
         0.017, -0.106,  0.043,  0.025,  0.034,  0.044,  0.029, -0.126,  0.022,
         0.131, -0.167,  0.082,  0.056, -0.050,  0.028, -0.006,  0.161, -0.020,
         0.165, -0.019, -0.080, -0.099,  0.032,  0.077,  0.090,  0.011,  0.041,
         0.129, -0.087,  0.057, -0.094,  0.116,  0.049, -0.237, -0.053,  0.065,
         0.025,  0.015,  0.024,  0.191,  0.031,  0.087,  0.107, -0.038, -0.065,
         0.113, -0.064, -0.073,  0.165,  0.019, -0.059, -0.061,  0.120,  0.049,
        -0.127, -0.059, -0.024,  0.029, -0.111,  0.130,  0.005,  0.052, -0.007,
        -0.095,  0.031,  0.080, -0.187, -0.067,  0.206, -0.032,  0.026,  0.210,
         0.115, -0.076,  0.081,  0.017, -0.025, -0.007,  0.053,  0.079, -0.042,
         0.003, -0.098, -0.054, -0.198, -0.070, -0.180,  0.193,  0.136,  0.040,
         0.014, -0.054, -0.042, -0.075, -0.025,  0.078,  0.028, -0.084, -0.021,
        -0.059,  0.035,  0.001,  0.035,  0.145,  0.065,  0.049, -0.083,  0.099,
        -0.036, -0.117,  0.125], device='cuda:0')
s after update for 1 param tensor([1.204, 0.853, 1.981, 1.442, 1.072, 1.426, 1.686, 0.815, 0.906, 0.822,
        1.167, 1.439, 1.626, 1.250, 2.080, 1.239, 1.108, 1.536, 1.556, 1.676,
        1.472, 1.428, 1.247, 1.076, 1.510, 1.648, 1.180, 1.134, 1.663, 0.978,
        1.394, 1.150, 1.576, 1.259, 1.153, 1.045, 1.561, 0.477, 1.396, 1.397,
        1.249, 1.628, 1.262, 1.855, 1.355, 1.689, 1.114, 1.513, 1.935, 1.130,
        1.618, 1.525, 1.357, 1.598, 1.187, 1.441, 1.387, 1.526, 1.436, 1.675,
        1.708, 1.252, 1.431, 1.581, 1.154, 1.709, 1.981, 1.195, 1.078, 0.953,
        1.333, 1.269, 1.243, 1.947, 1.689, 1.118, 0.714, 1.403, 1.531, 1.909,
        0.987, 1.873, 0.969, 1.327, 0.931, 1.380, 1.587, 1.548, 1.789, 1.595,
        1.295, 1.648, 1.028, 1.584, 1.273, 0.804, 1.562, 1.096, 1.819, 0.739,
        1.438, 1.035, 1.198, 1.263, 2.095, 1.184, 1.341, 1.534, 0.833, 1.695,
        1.319, 1.411, 1.167, 1.459, 1.331, 1.739, 1.711, 1.572, 1.386, 1.745,
        1.830, 1.638, 1.599, 1.756, 1.442, 1.470, 2.146, 1.642, 1.211, 0.979,
        1.859, 1.074, 0.759, 0.973, 1.665, 1.349, 1.452, 0.848, 1.678, 1.675,
        1.023, 0.941, 1.592, 1.003, 1.897, 1.713, 0.686, 1.177, 1.189, 0.962,
        1.420, 1.467, 1.277, 1.550, 1.402, 1.502, 1.436, 2.035, 1.170, 1.063,
        1.737, 1.024, 1.840, 1.883, 0.852, 1.270, 1.002, 0.757, 1.331, 0.892,
        2.176, 0.697, 0.990, 1.134, 1.822, 1.428, 1.893, 1.622, 0.690, 0.924,
        0.744, 1.697, 1.487, 1.501, 1.548, 1.112, 1.588, 1.477, 2.140, 1.725,
        1.494, 0.840, 1.264, 1.169, 1.463, 1.058, 1.236, 1.277, 1.591, 1.392,
        1.304, 1.486, 0.894, 1.671, 1.163, 1.281, 1.279, 1.366, 1.626, 1.066,
        1.856, 1.281, 1.247, 1.029, 1.548, 1.527, 1.911, 0.562, 1.327, 1.541,
        1.514, 0.810, 1.811, 0.765, 1.965, 0.792, 1.819, 1.073, 1.730, 1.499,
        1.888, 1.775, 1.016, 1.595, 1.421, 1.940, 1.864, 1.116, 1.449, 0.974,
        1.581, 1.306, 0.924, 1.616, 1.006, 1.547, 1.455, 0.799, 1.583, 0.831,
        1.181, 1.453, 1.531, 1.001, 1.516, 1.283, 1.513, 1.410, 1.550, 1.616,
        1.733, 1.828, 1.462, 1.662, 1.463, 1.248, 1.008, 1.632, 1.093, 0.570,
        1.566, 1.198, 1.856, 1.698, 1.619, 1.598, 1.586, 1.265, 1.633, 1.300,
        1.150, 2.076, 1.882, 1.977, 1.414, 2.052, 0.945, 0.758, 1.428, 1.277,
        0.892, 1.249, 1.223, 1.289, 1.689, 1.082, 1.764, 1.706, 1.299, 1.250],
       device='cuda:0')
b after update for 1 param tensor([129.586, 109.038, 166.207, 141.791, 122.253, 141.007, 153.307, 106.611,
        112.414, 107.042, 127.580, 141.633, 150.566, 132.019, 170.311, 131.427,
        124.290, 146.337, 147.280, 152.853, 143.259, 141.134, 131.844, 122.487,
        145.104, 151.594, 128.268, 125.774, 152.298, 116.764, 139.421, 126.619,
        148.236, 132.514, 126.800, 120.740, 147.546,  81.593, 139.532, 139.548,
        131.946, 150.674, 132.646, 160.835, 137.461, 153.478, 124.639, 145.240,
        164.267, 125.533, 150.203, 145.811, 137.566, 149.257, 128.663, 141.727,
        139.072, 145.877, 141.499, 152.822, 154.347, 132.111, 141.258, 148.492,
        126.852, 154.379, 166.182, 129.079, 122.590, 115.268, 136.315, 133.031,
        131.648, 164.764, 153.476, 124.858,  99.785, 139.882, 146.119, 163.135,
        117.336, 161.614, 116.245, 136.034, 113.964, 138.699, 148.775, 146.903,
        157.925, 149.127, 134.384, 151.601, 119.707, 148.637, 133.236, 105.858,
        147.565, 123.616, 159.279, 101.496, 141.602, 120.108, 129.228, 132.686,
        170.899, 128.516, 136.764, 146.251, 107.794, 153.746, 135.627, 140.273,
        127.582, 142.628, 136.224, 155.706, 154.469, 148.043, 139.035, 155.977,
        159.754, 151.125, 149.311, 156.470, 141.819, 143.169, 172.995, 151.302,
        129.958, 116.844, 161.009, 122.395, 102.868, 116.469, 152.373, 137.171,
        142.288, 108.715, 152.955, 152.843, 119.414, 114.540, 148.987, 118.276,
        162.654, 154.546,  97.791, 128.096, 128.771, 115.797, 140.692, 143.006,
        133.443, 146.994, 139.805, 144.708, 141.522, 168.459, 127.745, 121.750,
        155.636, 119.514, 160.189, 162.027, 109.004, 133.077, 118.215, 102.739,
        136.248, 111.495, 174.206,  98.556, 117.477, 125.751, 159.381, 141.107,
        162.476, 150.382,  98.067, 113.500, 101.847, 153.840, 143.985, 144.687,
        146.931, 124.545, 148.805, 143.516, 172.747, 155.108, 144.344, 108.233,
        132.784, 127.660, 142.820, 121.482, 131.272, 133.445, 148.940, 139.315,
        134.849, 143.942, 111.635, 152.639, 127.357, 133.652, 133.554, 138.024,
        150.570, 121.944, 160.863, 133.659, 131.879, 119.793, 146.933, 145.901,
        163.248,  88.549, 136.030, 146.564, 145.279, 106.287, 158.920, 103.295,
        165.543, 105.080, 159.259, 122.309, 155.316, 144.565, 162.263, 157.313,
        119.046, 149.127, 140.762, 164.471, 161.224, 124.772, 142.143, 116.538,
        148.475, 134.945, 113.509, 150.130, 118.440, 146.878, 142.457, 105.553,
        148.563, 107.632, 128.316, 142.358, 146.126, 118.153, 145.403, 133.738,
        145.240, 140.235, 147.037, 150.105, 155.468, 159.659, 142.786, 152.221,
        142.832, 131.899, 118.577, 150.853, 123.460,  89.174, 147.769, 129.262,
        160.882, 153.855, 150.258, 149.285, 148.724, 132.809, 150.888, 134.634,
        126.623, 170.125, 161.997, 166.023, 140.409, 169.157, 114.764, 102.779,
        141.102, 133.433, 111.532, 131.964, 130.608, 134.070, 153.459, 122.854,
        156.822, 154.230, 134.602, 132.016], device='cuda:0')
clipping threshold 0.2160525932205314
a after update for 1 param tensor([[[-0.056],
         [ 0.125],
         [ 0.045],
         [ 0.106],
         [-0.012],
         [-0.015],
         [ 0.079],
         [-0.086],
         [ 0.053],
         [-0.052]],

        [[-0.068],
         [-0.006],
         [ 0.122],
         [ 0.036],
         [ 0.016],
         [ 0.020],
         [ 0.022],
         [-0.018],
         [-0.056],
         [ 0.002]],

        [[ 0.041],
         [ 0.138],
         [-0.043],
         [-0.035],
         [-0.080],
         [-0.041],
         [-0.076],
         [ 0.041],
         [ 0.073],
         [ 0.091]],

        [[-0.165],
         [ 0.206],
         [ 0.075],
         [ 0.091],
         [-0.066],
         [ 0.203],
         [-0.083],
         [-0.197],
         [ 0.104],
         [ 0.116]],

        [[ 0.034],
         [-0.018],
         [-0.013],
         [ 0.030],
         [-0.110],
         [-0.008],
         [-0.033],
         [ 0.104],
         [ 0.009],
         [ 0.091]],

        [[-0.051],
         [ 0.041],
         [ 0.074],
         [-0.015],
         [-0.075],
         [-0.077],
         [ 0.007],
         [ 0.064],
         [-0.097],
         [ 0.067]],

        [[-0.082],
         [-0.054],
         [ 0.082],
         [-0.059],
         [ 0.093],
         [ 0.054],
         [-0.149],
         [ 0.074],
         [ 0.124],
         [-0.072]],

        [[-0.009],
         [-0.035],
         [-0.008],
         [ 0.044],
         [ 0.083],
         [ 0.030],
         [-0.034],
         [-0.153],
         [ 0.038],
         [ 0.041]],

        [[-0.043],
         [ 0.048],
         [ 0.060],
         [-0.091],
         [-0.031],
         [ 0.024],
         [-0.109],
         [-0.156],
         [ 0.062],
         [-0.087]],

        [[ 0.059],
         [ 0.042],
         [ 0.062],
         [-0.031],
         [ 0.029],
         [ 0.050],
         [-0.051],
         [-0.016],
         [-0.004],
         [ 0.000]],

        [[-0.063],
         [-0.099],
         [ 0.009],
         [-0.068],
         [-0.006],
         [ 0.065],
         [ 0.034],
         [ 0.018],
         [ 0.011],
         [ 0.027]],

        [[ 0.040],
         [ 0.053],
         [ 0.062],
         [ 0.115],
         [ 0.104],
         [-0.255],
         [-0.096],
         [-0.009],
         [ 0.101],
         [ 0.048]],

        [[-0.048],
         [ 0.072],
         [-0.061],
         [-0.128],
         [ 0.055],
         [ 0.029],
         [-0.024],
         [-0.001],
         [ 0.026],
         [-0.148]],

        [[-0.184],
         [-0.013],
         [-0.060],
         [ 0.052],
         [ 0.085],
         [-0.001],
         [ 0.018],
         [ 0.102],
         [-0.108],
         [-0.094]],

        [[-0.102],
         [-0.007],
         [-0.098],
         [ 0.107],
         [ 0.078],
         [ 0.008],
         [ 0.146],
         [-0.056],
         [ 0.053],
         [-0.070]],

        [[ 0.105],
         [ 0.104],
         [ 0.023],
         [ 0.004],
         [ 0.031],
         [-0.055],
         [-0.040],
         [ 0.084],
         [-0.107],
         [-0.043]],

        [[-0.113],
         [-0.194],
         [-0.028],
         [ 0.021],
         [-0.038],
         [-0.166],
         [ 0.050],
         [ 0.083],
         [ 0.050],
         [-0.023]],

        [[-0.019],
         [-0.141],
         [ 0.017],
         [ 0.047],
         [ 0.068],
         [ 0.064],
         [-0.128],
         [-0.012],
         [ 0.017],
         [ 0.102]],

        [[ 0.008],
         [-0.033],
         [ 0.097],
         [-0.040],
         [-0.101],
         [-0.099],
         [ 0.085],
         [ 0.055],
         [-0.005],
         [ 0.036]],

        [[ 0.110],
         [-0.054],
         [-0.033],
         [-0.047],
         [-0.027],
         [-0.139],
         [-0.050],
         [-0.089],
         [ 0.002],
         [-0.087]],

        [[ 0.019],
         [ 0.108],
         [-0.135],
         [-0.056],
         [-0.016],
         [-0.027],
         [-0.028],
         [ 0.125],
         [ 0.109],
         [-0.165]],

        [[-0.125],
         [ 0.007],
         [ 0.033],
         [-0.020],
         [-0.079],
         [ 0.038],
         [ 0.046],
         [-0.010],
         [-0.040],
         [ 0.032]],

        [[-0.098],
         [-0.009],
         [ 0.035],
         [-0.040],
         [ 0.125],
         [-0.056],
         [ 0.001],
         [-0.042],
         [-0.001],
         [ 0.049]],

        [[ 0.029],
         [-0.053],
         [ 0.051],
         [-0.075],
         [ 0.086],
         [-0.151],
         [ 0.081],
         [ 0.075],
         [ 0.038],
         [ 0.132]],

        [[ 0.129],
         [-0.087],
         [ 0.071],
         [-0.105],
         [ 0.066],
         [-0.096],
         [-0.096],
         [ 0.005],
         [-0.091],
         [-0.136]],

        [[ 0.017],
         [ 0.032],
         [-0.001],
         [-0.081],
         [-0.074],
         [ 0.102],
         [-0.008],
         [ 0.026],
         [-0.100],
         [ 0.109]],

        [[-0.030],
         [-0.079],
         [-0.067],
         [ 0.061],
         [ 0.062],
         [ 0.019],
         [ 0.013],
         [-0.045],
         [-0.085],
         [-0.075]],

        [[ 0.045],
         [ 0.011],
         [ 0.040],
         [-0.031],
         [-0.022],
         [ 0.237],
         [ 0.082],
         [ 0.005],
         [-0.076],
         [-0.032]],

        [[ 0.008],
         [-0.233],
         [-0.002],
         [-0.068],
         [ 0.014],
         [-0.042],
         [ 0.006],
         [ 0.177],
         [ 0.145],
         [ 0.129]],

        [[-0.120],
         [ 0.054],
         [ 0.082],
         [ 0.081],
         [-0.049],
         [ 0.041],
         [-0.053],
         [ 0.083],
         [ 0.071],
         [-0.023]]], device='cuda:0')
s after update for 1 param tensor([[[0.600],
         [0.686],
         [1.347],
         [1.464],
         [1.349],
         [1.505],
         [1.822],
         [1.170],
         [1.445],
         [0.780]],

        [[0.787],
         [1.005],
         [0.989],
         [0.703],
         [1.588],
         [1.382],
         [1.539],
         [1.496],
         [1.300],
         [1.855]],

        [[1.284],
         [1.579],
         [1.602],
         [1.813],
         [1.248],
         [1.091],
         [1.588],
         [1.853],
         [1.233],
         [1.831]],

        [[0.929],
         [1.563],
         [1.129],
         [1.553],
         [1.133],
         [1.832],
         [1.390],
         [1.429],
         [1.499],
         [2.118]],

        [[1.358],
         [1.517],
         [1.423],
         [1.823],
         [1.121],
         [1.926],
         [1.110],
         [1.279],
         [1.827],
         [1.462]],

        [[1.608],
         [1.321],
         [1.719],
         [1.544],
         [1.714],
         [1.665],
         [1.659],
         [0.976],
         [1.097],
         [1.388]],

        [[1.566],
         [0.914],
         [0.773],
         [1.449],
         [1.573],
         [1.174],
         [1.378],
         [1.491],
         [1.506],
         [1.251]],

        [[1.519],
         [1.985],
         [1.594],
         [2.005],
         [0.800],
         [2.107],
         [1.833],
         [2.220],
         [1.242],
         [0.968]],

        [[1.505],
         [0.822],
         [1.358],
         [1.561],
         [1.026],
         [1.104],
         [1.753],
         [1.431],
         [1.692],
         [1.003]],

        [[1.708],
         [0.818],
         [1.921],
         [1.444],
         [0.995],
         [1.538],
         [1.535],
         [1.322],
         [1.299],
         [1.605]],

        [[1.391],
         [1.665],
         [0.998],
         [1.118],
         [1.210],
         [1.340],
         [1.209],
         [1.395],
         [1.335],
         [1.589]],

        [[2.235],
         [1.071],
         [0.906],
         [1.108],
         [1.371],
         [1.324],
         [1.989],
         [0.963],
         [1.153],
         [1.510]],

        [[2.051],
         [1.483],
         [1.435],
         [1.779],
         [1.739],
         [1.537],
         [1.638],
         [1.407],
         [1.362],
         [1.527]],

        [[1.201],
         [1.596],
         [1.329],
         [1.621],
         [0.951],
         [1.422],
         [1.666],
         [1.898],
         [1.648],
         [1.590]],

        [[1.657],
         [2.157],
         [1.868],
         [0.886],
         [1.969],
         [1.538],
         [1.502],
         [1.663],
         [1.008],
         [1.361]],

        [[1.235],
         [1.263],
         [1.201],
         [1.262],
         [1.593],
         [1.292],
         [1.421],
         [1.808],
         [0.531],
         [1.251]],

        [[1.303],
         [1.636],
         [1.148],
         [1.150],
         [0.993],
         [1.970],
         [0.911],
         [0.599],
         [2.450],
         [0.930]],

        [[1.565],
         [1.633],
         [1.457],
         [1.494],
         [0.625],
         [0.923],
         [1.173],
         [1.437],
         [1.653],
         [1.430]],

        [[1.359],
         [1.640],
         [1.467],
         [1.472],
         [1.450],
         [1.166],
         [1.994],
         [1.132],
         [1.724],
         [1.136]],

        [[1.254],
         [1.383],
         [0.958],
         [1.554],
         [1.386],
         [1.760],
         [1.467],
         [0.930],
         [1.486],
         [2.038]],

        [[1.753],
         [1.866],
         [1.519],
         [1.243],
         [2.014],
         [1.219],
         [1.321],
         [1.331],
         [1.509],
         [1.031]],

        [[1.853],
         [1.550],
         [1.147],
         [1.343],
         [1.334],
         [1.754],
         [1.217],
         [1.320],
         [1.034],
         [1.254]],

        [[1.472],
         [1.460],
         [1.426],
         [1.784],
         [1.637],
         [1.223],
         [1.554],
         [1.289],
         [2.143],
         [1.914]],

        [[1.794],
         [1.139],
         [1.370],
         [1.388],
         [1.957],
         [1.323],
         [1.461],
         [1.649],
         [1.614],
         [0.971]],

        [[1.627],
         [1.407],
         [1.105],
         [1.631],
         [1.579],
         [1.121],
         [1.480],
         [1.208],
         [1.657],
         [1.693]],

        [[1.542],
         [0.859],
         [1.780],
         [1.848],
         [1.692],
         [1.539],
         [1.834],
         [1.552],
         [1.321],
         [1.322]],

        [[1.379],
         [1.430],
         [0.987],
         [1.109],
         [1.446],
         [2.255],
         [1.814],
         [1.139],
         [1.713],
         [1.100]],

        [[1.232],
         [1.261],
         [0.859],
         [1.666],
         [1.104],
         [1.750],
         [1.072],
         [1.221],
         [1.333],
         [1.707]],

        [[0.630],
         [1.672],
         [0.854],
         [1.635],
         [1.354],
         [1.308],
         [1.928],
         [2.030],
         [1.874],
         [1.408]],

        [[1.430],
         [1.508],
         [1.407],
         [1.194],
         [1.749],
         [1.860],
         [1.574],
         [1.561],
         [1.738],
         [1.988]]], device='cuda:0')
b after update for 1 param tensor([[[ 91.433],
         [ 97.782],
         [137.049],
         [142.873],
         [137.156],
         [144.877],
         [159.375],
         [127.754],
         [141.939],
         [104.303]],

        [[104.735],
         [118.392],
         [117.432],
         [ 99.025],
         [148.813],
         [138.829],
         [146.480],
         [144.447],
         [134.664],
         [160.836]],

        [[133.817],
         [148.369],
         [149.463],
         [158.997],
         [131.907],
         [123.352],
         [148.814],
         [160.751],
         [131.136],
         [159.770]],

        [[113.790],
         [147.609],
         [125.461],
         [147.177],
         [125.700],
         [159.833],
         [139.226],
         [141.180],
         [144.591],
         [171.837]],

        [[137.634],
         [145.445],
         [140.861],
         [159.417],
         [125.041],
         [163.886],
         [124.390],
         [133.557],
         [159.621],
         [142.769]],

        [[149.758],
         [135.734],
         [154.827],
         [146.739],
         [154.589],
         [152.382],
         [152.101],
         [116.671],
         [123.659],
         [139.126]],

        [[147.761],
         [112.885],
         [103.820],
         [142.133],
         [148.100],
         [127.966],
         [138.614],
         [144.188],
         [144.912],
         [132.068]],

        [[145.532],
         [166.365],
         [149.082],
         [167.203],
         [105.591],
         [171.424],
         [159.892],
         [175.957],
         [131.581],
         [116.195]],

        [[144.874],
         [107.070],
         [137.631],
         [147.544],
         [119.589],
         [124.087],
         [156.333],
         [141.259],
         [153.598],
         [118.237]],

        [[154.327],
         [106.822],
         [163.667],
         [141.917],
         [117.792],
         [146.465],
         [146.309],
         [135.796],
         [134.591],
         [149.621]],

        [[139.271],
         [152.363],
         [117.941],
         [124.859],
         [129.901],
         [136.688],
         [129.848],
         [139.494],
         [136.464],
         [148.875]],

        [[176.525],
         [122.223],
         [112.396],
         [124.308],
         [138.261],
         [135.885],
         [166.531],
         [115.866],
         [126.804],
         [145.099]],

        [[169.126],
         [143.806],
         [141.443],
         [157.498],
         [155.730],
         [146.399],
         [151.144],
         [140.069],
         [137.794],
         [145.902]],

        [[129.383],
         [149.158],
         [136.156],
         [150.342],
         [115.180],
         [140.807],
         [152.439],
         [162.691],
         [151.584],
         [148.905]],

        [[152.016],
         [173.414],
         [161.396],
         [111.135],
         [165.696],
         [146.424],
         [144.744],
         [152.285],
         [118.579],
         [137.736]],

        [[131.215],
         [132.732],
         [129.417],
         [132.645],
         [149.030],
         [134.224],
         [140.742],
         [158.792],
         [ 86.069],
         [132.068]],

        [[134.793],
         [151.022],
         [126.516],
         [126.612],
         [117.660],
         [165.739],
         [112.728],
         [ 91.375],
         [184.832],
         [113.895]],

        [[147.725],
         [150.921],
         [142.529],
         [144.340],
         [ 93.334],
         [113.454],
         [127.909],
         [141.542],
         [151.828],
         [141.215]],

        [[137.676],
         [151.244],
         [143.036],
         [143.272],
         [142.209],
         [127.515],
         [166.742],
         [125.617],
         [155.041],
         [125.881]],

        [[132.233],
         [138.849],
         [115.599],
         [147.194],
         [139.001],
         [156.670],
         [143.019],
         [113.884],
         [143.949],
         [168.594]],

        [[156.339],
         [161.315],
         [145.523],
         [131.627],
         [167.574],
         [130.387],
         [135.699],
         [136.238],
         [145.077],
         [119.879]],

        [[160.756],
         [147.014],
         [126.451],
         [136.866],
         [136.368],
         [156.397],
         [130.264],
         [135.649],
         [120.081],
         [132.258]],

        [[143.287],
         [142.673],
         [140.988],
         [157.740],
         [151.096],
         [130.603],
         [147.197],
         [134.046],
         [172.855],
         [163.356]],

        [[158.161],
         [126.014],
         [138.222],
         [139.104],
         [165.174],
         [135.846],
         [142.712],
         [151.617],
         [150.030],
         [116.336]],

        [[150.627],
         [140.074],
         [124.121],
         [150.812],
         [148.396],
         [125.032],
         [143.681],
         [129.796],
         [152.001],
         [153.658]],

        [[146.645],
         [109.469],
         [157.525],
         [160.538],
         [153.588],
         [146.491],
         [159.900],
         [147.132],
         [135.703],
         [135.798]],

        [[138.687],
         [141.218],
         [117.321],
         [124.338],
         [141.978],
         [177.339],
         [159.064],
         [125.998],
         [154.561],
         [123.872]],

        [[131.063],
         [132.603],
         [109.419],
         [152.416],
         [124.078],
         [156.227],
         [122.284],
         [130.499],
         [136.351],
         [154.301]],

        [[ 93.744],
         [152.680],
         [109.129],
         [151.015],
         [137.400],
         [135.034],
         [163.948],
         [168.259],
         [161.641],
         [140.123]],

        [[141.197],
         [145.019],
         [140.092],
         [129.030],
         [156.161],
         [161.034],
         [148.141],
         [147.546],
         [155.668],
         [166.481]]], device='cuda:0')
clipping threshold 0.2160525932205314
a after update for 1 param tensor([[-0.123],
        [-0.046],
        [ 0.055],
        [ 0.209],
        [-0.025],
        [ 0.070],
        [ 0.072],
        [ 0.022],
        [ 0.017],
        [-0.075],
        [ 0.001],
        [-0.125],
        [ 0.025],
        [-0.047],
        [-0.122],
        [ 0.027],
        [ 0.025],
        [-0.064],
        [-0.010],
        [-0.032],
        [-0.004],
        [-0.018],
        [-0.019],
        [-0.056],
        [ 0.048],
        [-0.002],
        [ 0.042],
        [ 0.014],
        [ 0.039],
        [-0.012]], device='cuda:0')
s after update for 1 param tensor([[1.373],
        [1.168],
        [1.656],
        [1.565],
        [1.316],
        [1.556],
        [1.375],
        [1.112],
        [1.704],
        [1.831],
        [1.631],
        [1.227],
        [1.370],
        [1.438],
        [1.233],
        [1.902],
        [1.299],
        [1.540],
        [1.370],
        [2.184],
        [1.294],
        [1.263],
        [1.560],
        [1.895],
        [1.771],
        [1.414],
        [1.811],
        [1.495],
        [1.664],
        [1.213]], device='cuda:0')
b after update for 1 param tensor([[138.386],
        [127.592],
        [151.954],
        [147.705],
        [135.476],
        [147.318],
        [138.454],
        [124.516],
        [154.142],
        [159.795],
        [150.818],
        [130.827],
        [138.193],
        [141.613],
        [131.101],
        [162.869],
        [134.565],
        [146.528],
        [138.232],
        [174.529],
        [134.324],
        [132.725],
        [147.499],
        [162.569],
        [157.131],
        [140.422],
        [158.916],
        [144.393],
        [152.332],
        [130.047]], device='cuda:0')
clipping threshold 0.2160525932205314
||w||^2 0.09037644151642696
exp ma of ||w||^2 0.07080678528311707
||w|| 0.30062674783928817
exp ma of ||w|| 0.2607883020057393
||w||^2 0.06261101082026102
exp ma of ||w||^2 0.07086933011842438
||w|| 0.25022192314076125
exp ma of ||w|| 0.26091057338767903
||w||^2 0.06278611425882218
exp ma of ||w||^2 0.07582106787337524
||w|| 0.25057157512140554
exp ma of ||w|| 0.26956766843249047
||w||^2 0.07862169668011808
exp ma of ||w||^2 0.0704702048681163
||w|| 0.28039560745510633
exp ma of ||w|| 0.2601205225590379
||w||^2 0.0801107720522287
exp ma of ||w||^2 0.06932469263287085
||w|| 0.2830384639094636
exp ma of ||w|| 0.2585329727640646
||w||^2 0.03574209344028416
exp ma of ||w||^2 0.07073304532962175
||w|| 0.18905579451655047
exp ma of ||w|| 0.260025376504226
||w||^2 0.06685670639898511
exp ma of ||w||^2 0.07280814432865695
||w|| 0.25856663821727877
exp ma of ||w|| 0.26566271895260024
||w||^2 0.03714574336316863
exp ma of ||w||^2 0.07237909027975542
||w|| 0.19273231011734548
exp ma of ||w|| 0.26390866964732385
||w||^2 0.0382195813216712
exp ma of ||w||^2 0.07713521314234821
||w|| 0.19549828981776593
exp ma of ||w|| 0.27278067317514637
cuda
Objective function 29.34 = squared loss an data 26.89 + 0.5*rho*h**2 0.292598 + alpha*h 1.151008 + L2reg 0.77 + L1reg 0.23 ; SHD = 52 ; DAG True
Proportion of microbatches that were clipped  0.7612395632626846
iteration 1 in inner loop, alpha 475.8040285870454 rho 100000.0 h 0.002419080582559019
iteration 5 in outer loop, alpha = 2894.8846111460643, rho = 1000000.0, h = 0.002419080582559019
Threshold 0.3
[[0.002 0.088 0.095 0.117 0.057 0.19  0.121 0.037 0.084 0.021 0.071 0.025
  0.13  0.012 0.033 0.073 0.074 0.173 0.101 0.264 0.013 0.008 0.09  0.027
  0.015 0.014 0.197 0.026 0.078 0.011]
 [0.024 0.002 0.178 0.205 0.052 0.249 0.29  0.101 0.091 0.017 0.094 0.009
  0.063 0.013 0.071 0.032 0.144 0.118 0.186 0.174 0.013 0.009 0.141 0.061
  0.017 0.009 0.219 0.013 0.321 0.129]
 [0.021 0.013 0.003 0.022 0.011 0.018 0.009 0.004 0.015 0.006 0.024 0.001
  0.016 0.011 0.014 0.012 0.004 0.04  0.02  0.027 0.007 0.005 0.043 0.007
  0.006 0.003 0.046 0.009 0.024 0.015]
 [0.019 0.008 0.107 0.002 0.029 0.049 0.039 0.003 0.01  0.012 0.011 0.01
  0.019 0.015 0.02  0.012 0.013 0.127 0.085 0.042 0.006 0.003 0.019 0.007
  0.013 0.003 0.082 0.006 0.064 0.012]
 [0.044 0.03  0.254 0.092 0.002 0.066 0.05  0.029 0.156 0.014 0.063 0.016
  0.074 0.011 0.132 0.039 0.094 0.544 0.217 0.144 0.039 0.008 0.181 0.042
  0.024 0.019 0.219 0.017 0.125 0.088]
 [0.013 0.011 0.086 0.051 0.038 0.002 0.148 0.011 0.126 0.002 0.027 0.004
  0.008 0.014 0.023 0.02  0.016 0.164 0.118 0.333 0.008 0.011 0.193 0.018
  0.018 0.008 0.192 0.01  0.159 0.025]
 [0.011 0.009 0.206 0.067 0.048 0.02  0.002 0.014 0.053 0.007 0.058 0.013
  0.006 0.016 0.013 0.015 0.022 0.044 0.031 0.038 0.006 0.008 0.063 0.008
  0.002 0.009 0.135 0.019 0.098 0.006]
 [0.073 0.015 0.631 0.649 0.081 0.194 0.164 0.002 0.031 0.021 0.065 0.014
  0.018 0.032 0.12  0.063 0.067 0.275 0.151 0.101 0.015 0.009 0.185 0.015
  0.041 0.005 0.171 0.008 0.078 0.07 ]
 [0.02  0.022 0.199 0.136 0.019 0.019 0.066 0.042 0.003 0.008 0.026 0.009
  0.009 0.015 0.032 0.006 0.045 0.074 0.235 0.021 0.003 0.009 0.235 0.027
  0.008 0.009 0.054 0.021 0.153 0.031]
 [0.086 0.177 0.183 0.297 0.184 0.829 0.284 0.092 0.296 0.002 0.121 0.151
  0.073 0.19  0.208 0.068 0.163 0.238 0.309 0.289 0.103 0.048 0.25  0.186
  0.085 0.031 0.546 0.052 0.202 0.106]
 [0.027 0.02  0.103 0.178 0.029 0.073 0.048 0.038 0.082 0.009 0.001 0.013
  0.025 0.007 0.05  0.016 0.014 0.04  0.128 0.175 0.007 0.016 0.088 0.018
  0.032 0.005 0.071 0.002 0.193 0.05 ]
 [0.089 0.265 1.081 0.13  0.148 0.282 0.136 0.091 0.167 0.01  0.157 0.002
  0.241 0.032 0.098 0.083 0.192 0.306 0.198 0.131 0.094 0.015 0.12  0.102
  0.037 0.019 0.538 0.054 0.153 0.139]
 [0.03  0.035 0.141 0.12  0.032 0.223 0.32  0.123 0.311 0.027 0.089 0.006
  0.003 0.011 0.063 0.018 0.027 0.199 0.149 0.163 0.016 0.011 0.099 0.089
  0.021 0.015 0.24  0.014 0.115 0.029]
 [0.182 0.196 0.235 0.138 0.146 0.123 0.128 0.057 0.156 0.013 0.286 0.052
  0.12  0.002 0.257 0.087 0.059 0.747 0.263 0.633 0.05  0.009 0.213 0.116
  0.08  0.011 0.25  0.046 0.109 0.127]
 [0.049 0.033 0.143 0.133 0.02  0.136 0.1   0.022 0.079 0.009 0.04  0.021
  0.043 0.011 0.002 0.044 0.027 0.192 0.175 0.06  0.02  0.008 0.151 0.014
  0.019 0.003 0.137 0.023 0.102 0.028]
 [0.036 0.076 0.182 0.163 0.065 0.161 0.186 0.033 0.243 0.036 0.118 0.03
  0.107 0.021 0.047 0.002 0.092 0.122 0.132 0.167 0.012 0.022 0.437 0.027
  0.015 0.024 0.555 0.046 0.286 0.057]
 [0.042 0.012 0.451 0.148 0.027 0.091 0.122 0.036 0.042 0.013 0.098 0.009
  0.073 0.028 0.09  0.019 0.002 0.116 0.246 0.133 0.005 0.011 0.205 0.023
  0.014 0.016 0.116 0.019 0.099 0.079]
 [0.017 0.02  0.056 0.016 0.004 0.014 0.051 0.008 0.034 0.011 0.052 0.006
  0.011 0.002 0.01  0.018 0.022 0.002 0.097 0.078 0.007 0.003 0.057 0.023
  0.017 0.002 0.236 0.007 0.093 0.015]
 [0.019 0.005 0.121 0.036 0.015 0.017 0.067 0.01  0.009 0.005 0.016 0.014
  0.013 0.005 0.014 0.008 0.011 0.017 0.002 0.055 0.004 0.003 0.019 0.003
  0.012 0.005 0.029 0.007 0.036 0.006]
 [0.007 0.016 0.089 0.036 0.016 0.007 0.057 0.012 0.131 0.005 0.013 0.018
  0.008 0.003 0.042 0.014 0.017 0.048 0.048 0.002 0.01  0.005 0.138 0.01
  0.019 0.013 0.031 0.003 0.103 0.021]
 [0.136 0.204 0.305 0.35  0.049 0.379 0.23  0.132 0.624 0.029 0.279 0.024
  0.101 0.051 0.176 0.15  0.354 0.268 0.488 0.225 0.002 0.022 0.191 0.178
  0.07  0.013 0.164 0.079 0.67  0.135]
 [0.308 0.264 0.258 0.79  0.367 0.168 0.223 0.181 0.282 0.034 0.255 0.146
  0.208 0.229 0.233 0.151 0.276 0.473 0.314 0.449 0.087 0.002 0.226 0.075
  0.1   0.056 0.409 0.025 0.421 0.506]
 [0.018 0.015 0.037 0.145 0.008 0.012 0.052 0.01  0.01  0.007 0.025 0.013
  0.016 0.007 0.011 0.005 0.013 0.032 0.119 0.015 0.007 0.008 0.002 0.003
  0.008 0.004 0.209 0.005 0.045 0.037]
 [0.069 0.034 0.21  0.234 0.06  0.163 0.194 0.087 0.115 0.011 0.114 0.019
  0.025 0.021 0.15  0.07  0.1   0.087 0.628 0.173 0.008 0.023 0.721 0.002
  0.02  0.003 0.366 0.03  0.189 0.067]
 [0.162 0.127 0.386 0.231 0.119 0.096 0.899 0.056 0.341 0.026 0.133 0.049
  0.16  0.032 0.118 0.081 0.108 0.141 0.169 0.106 0.023 0.017 0.342 0.1
  0.002 0.042 0.224 0.079 0.165 0.115]
 [0.142 0.198 0.396 0.431 0.098 0.229 0.232 0.642 0.195 0.044 0.398 0.116
  0.165 0.186 0.824 0.094 0.163 0.84  0.332 0.22  0.128 0.031 0.442 0.682
  0.056 0.002 0.287 0.067 0.542 0.154]
 [0.012 0.009 0.044 0.033 0.008 0.014 0.021 0.016 0.032 0.002 0.038 0.002
  0.007 0.005 0.013 0.003 0.023 0.012 0.063 0.05  0.009 0.004 0.012 0.006
  0.008 0.005 0.002 0.004 0.018 0.01 ]
 [0.127 0.183 0.242 0.293 0.12  0.151 0.122 0.272 0.095 0.068 0.757 0.053
  0.122 0.079 0.111 0.064 0.141 0.194 0.198 0.338 0.027 0.081 0.342 0.074
  0.018 0.04  0.492 0.002 0.082 0.135]
 [0.029 0.007 0.092 0.031 0.018 0.023 0.023 0.021 0.015 0.011 0.014 0.014
  0.019 0.014 0.016 0.006 0.022 0.025 0.042 0.019 0.003 0.006 0.058 0.014
  0.018 0.004 0.095 0.019 0.002 0.036]
 [0.169 0.026 0.201 0.139 0.033 0.127 0.285 0.03  0.055 0.013 0.034 0.015
  0.065 0.017 0.1   0.029 0.031 0.158 0.39  0.102 0.02  0.003 0.067 0.042
  0.013 0.011 0.292 0.014 0.056 0.002]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.321 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.544 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.333 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.631 0.649 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.829 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.309 0.    0.    0.    0.    0.
  0.    0.    0.546 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    1.081 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.306 0.    0.    0.    0.    0.    0.
  0.    0.    0.538 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.32  0.    0.311 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.747 0.    0.633 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.437 0.
  0.    0.    0.555 0.    0.    0.   ]
 [0.    0.    0.451 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.305 0.35  0.    0.379 0.    0.    0.624 0.    0.    0.
  0.    0.    0.    0.    0.354 0.    0.488 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.67  0.   ]
 [0.308 0.    0.    0.79  0.367 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.473 0.314 0.449 0.    0.    0.    0.
  0.    0.    0.409 0.    0.421 0.506]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.628 0.    0.    0.    0.721 0.
  0.    0.    0.366 0.    0.    0.   ]
 [0.    0.    0.386 0.    0.    0.    0.899 0.    0.341 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.342 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.396 0.431 0.    0.    0.    0.642 0.    0.    0.398 0.
  0.    0.    0.824 0.    0.    0.84  0.332 0.    0.    0.    0.442 0.682
  0.    0.    0.    0.    0.542 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.757 0.
  0.    0.    0.    0.    0.    0.    0.    0.338 0.    0.    0.342 0.
  0.    0.    0.492 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.39  0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]]
{'fdr': 0.48214285714285715, 'tpr': 0.48333333333333334, 'fpr': 0.072, 'f1': 0.5, 'shd': 52, 'npred': 56, 'ntrue': 60}
[0.088 0.095 0.117 0.057 0.19  0.121 0.037 0.084 0.021 0.071 0.025 0.13
 0.012 0.033 0.073 0.074 0.173 0.101 0.264 0.013 0.008 0.09  0.027 0.015
 0.014 0.197 0.026 0.078 0.011 0.024 0.178 0.205 0.052 0.249 0.29  0.101
 0.091 0.017 0.094 0.009 0.063 0.013 0.071 0.032 0.144 0.118 0.186 0.174
 0.013 0.009 0.141 0.061 0.017 0.009 0.219 0.013 0.321 0.129 0.021 0.013
 0.022 0.011 0.018 0.009 0.004 0.015 0.006 0.024 0.001 0.016 0.011 0.014
 0.012 0.004 0.04  0.02  0.027 0.007 0.005 0.043 0.007 0.006 0.003 0.046
 0.009 0.024 0.015 0.019 0.008 0.107 0.029 0.049 0.039 0.003 0.01  0.012
 0.011 0.01  0.019 0.015 0.02  0.012 0.013 0.127 0.085 0.042 0.006 0.003
 0.019 0.007 0.013 0.003 0.082 0.006 0.064 0.012 0.044 0.03  0.254 0.092
 0.066 0.05  0.029 0.156 0.014 0.063 0.016 0.074 0.011 0.132 0.039 0.094
 0.544 0.217 0.144 0.039 0.008 0.181 0.042 0.024 0.019 0.219 0.017 0.125
 0.088 0.013 0.011 0.086 0.051 0.038 0.148 0.011 0.126 0.002 0.027 0.004
 0.008 0.014 0.023 0.02  0.016 0.164 0.118 0.333 0.008 0.011 0.193 0.018
 0.018 0.008 0.192 0.01  0.159 0.025 0.011 0.009 0.206 0.067 0.048 0.02
 0.014 0.053 0.007 0.058 0.013 0.006 0.016 0.013 0.015 0.022 0.044 0.031
 0.038 0.006 0.008 0.063 0.008 0.002 0.009 0.135 0.019 0.098 0.006 0.073
 0.015 0.631 0.649 0.081 0.194 0.164 0.031 0.021 0.065 0.014 0.018 0.032
 0.12  0.063 0.067 0.275 0.151 0.101 0.015 0.009 0.185 0.015 0.041 0.005
 0.171 0.008 0.078 0.07  0.02  0.022 0.199 0.136 0.019 0.019 0.066 0.042
 0.008 0.026 0.009 0.009 0.015 0.032 0.006 0.045 0.074 0.235 0.021 0.003
 0.009 0.235 0.027 0.008 0.009 0.054 0.021 0.153 0.031 0.086 0.177 0.183
 0.297 0.184 0.829 0.284 0.092 0.296 0.121 0.151 0.073 0.19  0.208 0.068
 0.163 0.238 0.309 0.289 0.103 0.048 0.25  0.186 0.085 0.031 0.546 0.052
 0.202 0.106 0.027 0.02  0.103 0.178 0.029 0.073 0.048 0.038 0.082 0.009
 0.013 0.025 0.007 0.05  0.016 0.014 0.04  0.128 0.175 0.007 0.016 0.088
 0.018 0.032 0.005 0.071 0.002 0.193 0.05  0.089 0.265 1.081 0.13  0.148
 0.282 0.136 0.091 0.167 0.01  0.157 0.241 0.032 0.098 0.083 0.192 0.306
 0.198 0.131 0.094 0.015 0.12  0.102 0.037 0.019 0.538 0.054 0.153 0.139
 0.03  0.035 0.141 0.12  0.032 0.223 0.32  0.123 0.311 0.027 0.089 0.006
 0.011 0.063 0.018 0.027 0.199 0.149 0.163 0.016 0.011 0.099 0.089 0.021
 0.015 0.24  0.014 0.115 0.029 0.182 0.196 0.235 0.138 0.146 0.123 0.128
 0.057 0.156 0.013 0.286 0.052 0.12  0.257 0.087 0.059 0.747 0.263 0.633
 0.05  0.009 0.213 0.116 0.08  0.011 0.25  0.046 0.109 0.127 0.049 0.033
 0.143 0.133 0.02  0.136 0.1   0.022 0.079 0.009 0.04  0.021 0.043 0.011
 0.044 0.027 0.192 0.175 0.06  0.02  0.008 0.151 0.014 0.019 0.003 0.137
 0.023 0.102 0.028 0.036 0.076 0.182 0.163 0.065 0.161 0.186 0.033 0.243
 0.036 0.118 0.03  0.107 0.021 0.047 0.092 0.122 0.132 0.167 0.012 0.022
 0.437 0.027 0.015 0.024 0.555 0.046 0.286 0.057 0.042 0.012 0.451 0.148
 0.027 0.091 0.122 0.036 0.042 0.013 0.098 0.009 0.073 0.028 0.09  0.019
 0.116 0.246 0.133 0.005 0.011 0.205 0.023 0.014 0.016 0.116 0.019 0.099
 0.079 0.017 0.02  0.056 0.016 0.004 0.014 0.051 0.008 0.034 0.011 0.052
 0.006 0.011 0.002 0.01  0.018 0.022 0.097 0.078 0.007 0.003 0.057 0.023
 0.017 0.002 0.236 0.007 0.093 0.015 0.019 0.005 0.121 0.036 0.015 0.017
 0.067 0.01  0.009 0.005 0.016 0.014 0.013 0.005 0.014 0.008 0.011 0.017
 0.055 0.004 0.003 0.019 0.003 0.012 0.005 0.029 0.007 0.036 0.006 0.007
 0.016 0.089 0.036 0.016 0.007 0.057 0.012 0.131 0.005 0.013 0.018 0.008
 0.003 0.042 0.014 0.017 0.048 0.048 0.01  0.005 0.138 0.01  0.019 0.013
 0.031 0.003 0.103 0.021 0.136 0.204 0.305 0.35  0.049 0.379 0.23  0.132
 0.624 0.029 0.279 0.024 0.101 0.051 0.176 0.15  0.354 0.268 0.488 0.225
 0.022 0.191 0.178 0.07  0.013 0.164 0.079 0.67  0.135 0.308 0.264 0.258
 0.79  0.367 0.168 0.223 0.181 0.282 0.034 0.255 0.146 0.208 0.229 0.233
 0.151 0.276 0.473 0.314 0.449 0.087 0.226 0.075 0.1   0.056 0.409 0.025
 0.421 0.506 0.018 0.015 0.037 0.145 0.008 0.012 0.052 0.01  0.01  0.007
 0.025 0.013 0.016 0.007 0.011 0.005 0.013 0.032 0.119 0.015 0.007 0.008
 0.003 0.008 0.004 0.209 0.005 0.045 0.037 0.069 0.034 0.21  0.234 0.06
 0.163 0.194 0.087 0.115 0.011 0.114 0.019 0.025 0.021 0.15  0.07  0.1
 0.087 0.628 0.173 0.008 0.023 0.721 0.02  0.003 0.366 0.03  0.189 0.067
 0.162 0.127 0.386 0.231 0.119 0.096 0.899 0.056 0.341 0.026 0.133 0.049
 0.16  0.032 0.118 0.081 0.108 0.141 0.169 0.106 0.023 0.017 0.342 0.1
 0.042 0.224 0.079 0.165 0.115 0.142 0.198 0.396 0.431 0.098 0.229 0.232
 0.642 0.195 0.044 0.398 0.116 0.165 0.186 0.824 0.094 0.163 0.84  0.332
 0.22  0.128 0.031 0.442 0.682 0.056 0.287 0.067 0.542 0.154 0.012 0.009
 0.044 0.033 0.008 0.014 0.021 0.016 0.032 0.002 0.038 0.002 0.007 0.005
 0.013 0.003 0.023 0.012 0.063 0.05  0.009 0.004 0.012 0.006 0.008 0.005
 0.004 0.018 0.01  0.127 0.183 0.242 0.293 0.12  0.151 0.122 0.272 0.095
 0.068 0.757 0.053 0.122 0.079 0.111 0.064 0.141 0.194 0.198 0.338 0.027
 0.081 0.342 0.074 0.018 0.04  0.492 0.082 0.135 0.029 0.007 0.092 0.031
 0.018 0.023 0.023 0.021 0.015 0.011 0.014 0.014 0.019 0.014 0.016 0.006
 0.022 0.025 0.042 0.019 0.003 0.006 0.058 0.014 0.018 0.004 0.095 0.019
 0.036 0.169 0.026 0.201 0.139 0.033 0.127 0.285 0.03  0.055 0.013 0.034
 0.015 0.065 0.017 0.1   0.029 0.031 0.158 0.39  0.102 0.02  0.003 0.067
 0.042 0.013 0.011 0.292 0.014 0.056]
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 1. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]]
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.7724074074074073, 0.4828149281173054)
Iterations 2500
Achieves (13.610683049707138, 1e-05)-DP
