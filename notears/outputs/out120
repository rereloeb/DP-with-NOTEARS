samples  5000  graph  30 60 ER mim  minibatch size  50  noise  0.6  minibatches per NN training  250 quantile adaptive clipping
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 2.144444827137683
iteration 1 in outer loop, alpha = 2.144444827137683, rho = 1.0, h = 2.144444827137683
cuda
iteration 1 in inner loop,alpha 2.144444827137683 rho 1.0 h 1.3256466874605835
iteration 2 in inner loop,alpha 2.144444827137683 rho 10.0 h 0.5131010328032026
iteration 2 in outer loop, alpha = 7.275455155169709, rho = 10.0, h = 0.5131010328032026
cuda
iteration 1 in inner loop,alpha 7.275455155169709 rho 10.0 h 0.28442514981965417
iteration 2 in inner loop,alpha 7.275455155169709 rho 100.0 h 0.09687583592673477
iteration 3 in outer loop, alpha = 16.963038747843186, rho = 100.0, h = 0.09687583592673477
cuda
iteration 1 in inner loop,alpha 16.963038747843186 rho 100.0 h 0.05565872169768937
iteration 2 in inner loop,alpha 16.963038747843186 rho 1000.0 h 0.017246591836673986
iteration 4 in outer loop, alpha = 34.20963058451717, rho = 1000.0, h = 0.017246591836673986
cuda
iteration 1 in inner loop,alpha 34.20963058451717 rho 1000.0 h 0.007536379858688491
iteration 2 in inner loop,alpha 34.20963058451717 rho 10000.0 h 0.0024562545468960195
iteration 5 in outer loop, alpha = 58.77217605347737, rho = 10000.0, h = 0.0024562545468960195
cuda
iteration 1 in inner loop,alpha 58.77217605347737 rho 10000.0 h 0.0010792499674714406
iteration 2 in inner loop,alpha 58.77217605347737 rho 100000.0 h 0.00042229828057926966
iteration 6 in outer loop, alpha = 101.00200411140433, rho = 100000.0, h = 0.00042229828057926966
cuda
iteration 1 in inner loop,alpha 101.00200411140433 rho 100000.0 h 0.00022015692463384084
iteration 7 in outer loop, alpha = 321.1589287452452, rho = 1000000.0, h = 0.00022015692463384084
Threshold 0.3
[[0.    0.    0.101 0.045 0.058 0.001 0.112 0.022 0.059 0.349 0.004 0.06
  0.001 0.006 0.002 0.028 0.009 0.049 0.055 0.88  0.041 0.001 0.149 0.019
  0.006 0.035 0.02  0.017 0.024 0.022]
 [0.    0.    0.016 0.004 0.011 0.684 1.881 0.087 0.113 0.002 0.007 0.034
  0.006 0.005 0.005 0.062 0.002 0.074 0.027 0.052 0.005 0.007 0.102 0.055
  0.002 0.014 0.002 0.081 0.085 0.032]
 [0.    0.    0.004 0.008 0.11  0.    0.068 0.05  0.001 0.    0.    0.
  0.    0.    0.    0.004 0.    0.014 0.058 0.124 0.001 0.    0.009 0.021
  0.    0.    0.019 0.013 0.022 0.008]
 [0.    0.    0.006 0.002 0.02  0.002 0.019 0.    0.    0.    0.    0.001
  0.    0.    0.    0.001 0.    0.    0.001 0.051 0.    0.    0.001 0.001
  0.    0.    0.    0.    0.059 0.   ]
 [0.    0.    0.002 0.006 0.003 0.004 0.011 0.012 0.001 0.    0.    0.
  0.    0.    0.    0.001 0.    0.001 0.001 0.159 0.    0.    0.006 0.001
  0.    0.    0.001 0.009 0.012 0.001]
 [0.    0.    0.05  0.042 0.014 0.003 0.049 0.046 0.083 0.    0.    0.065
  0.    0.    0.    0.002 0.    0.006 0.004 0.834 0.001 0.    0.032 0.009
  0.    0.001 0.011 0.004 0.003 0.001]
 [0.    0.    0.011 0.029 0.027 0.    0.003 0.021 0.005 0.    0.    0.001
  0.    0.    0.    0.017 0.    0.011 0.007 0.095 0.    0.    0.09  0.045
  0.    0.001 0.004 0.01  0.021 0.002]
 [0.    0.    0.009 1.484 0.009 0.013 0.027 0.003 0.    0.    0.    0.001
  0.    0.    0.    0.002 0.    0.    0.001 0.008 0.001 0.    0.005 0.
  0.    0.    0.001 0.    0.041 0.002]
 [0.    0.    0.052 0.008 0.042 0.005 0.043 0.059 0.003 0.001 0.    0.061
  0.    0.    0.    0.102 0.    0.045 0.757 1.093 0.    0.001 1.828 0.076
  0.    0.003 0.053 0.001 0.057 0.009]
 [0.    0.001 0.127 0.141 0.031 1.138 0.055 0.644 0.091 0.    0.001 2.485
  0.001 0.004 0.    0.27  0.007 0.183 0.025 0.097 0.009 0.    0.064 0.003
  0.    0.012 0.615 0.021 0.015 0.026]
 [0.001 0.001 0.027 0.188 0.033 0.015 0.09  0.079 0.9   0.014 0.    0.038
  0.005 0.001 0.017 0.028 0.004 0.055 0.064 0.103 0.052 0.009 0.031 0.068
  0.008 0.038 0.095 4.129 0.041 0.013]
 [0.    0.001 4.293 0.009 0.03  0.01  0.019 0.056 0.012 0.    0.    0.002
  0.    0.    0.    0.135 0.    0.09  0.033 0.151 0.002 0.    0.009 0.068
  0.    0.    0.441 0.024 0.028 0.012]
 [0.003 0.001 0.003 0.053 0.047 0.009 1.88  0.013 1.184 0.021 0.    0.05
  0.    0.001 0.009 0.125 0.001 0.098 0.002 0.001 0.025 0.023 0.071 0.385
  0.001 0.038 0.475 0.038 0.021 3.059]
 [0.001 0.    0.082 0.001 1.232 0.043 0.022 0.129 0.063 0.001 0.006 0.069
  0.006 0.    0.001 0.117 0.006 0.927 0.034 1.343 0.02  0.007 0.045 0.038
  0.007 0.005 0.142 0.068 0.008 0.004]
 [0.003 0.001 0.032 0.058 0.061 0.059 0.04  0.103 0.05  0.011 0.001 1.755
  0.    0.001 0.    0.012 0.001 0.188 0.023 0.007 0.015 0.008 0.119 0.763
  0.001 3.17  0.004 0.013 0.122 0.057]
 [0.    0.    0.049 0.008 0.072 0.029 0.019 0.059 0.011 0.    0.    0.004
  0.    0.    0.    0.004 0.    0.095 0.01  0.027 0.003 0.001 0.463 0.012
  0.    0.005 0.812 0.005 0.008 0.073]
 [0.    0.004 2.543 0.094 0.088 0.018 0.034 0.012 0.46  0.    0.001 0.003
  0.002 0.    0.004 0.013 0.    0.121 0.001 0.034 2.861 0.404 0.129 0.014
  0.004 0.004 0.049 0.051 0.073 0.042]
 [0.    0.    0.014 0.06  1.538 0.085 0.013 1.122 0.001 0.    0.    0.
  0.    0.    0.    0.003 0.    0.003 0.002 0.092 0.002 0.    0.013 0.001
  0.    0.001 0.003 0.011 0.206 0.001]
 [0.    0.    0.007 0.026 0.023 0.008 0.005 0.036 0.001 0.    0.    0.
  0.    0.    0.    0.001 0.    0.141 0.002 0.011 0.    0.    0.018 0.001
  0.    0.    0.01  0.006 0.035 0.001]
 [0.    0.    0.004 0.003 0.001 0.001 0.007 0.    0.001 0.    0.    0.
  0.    0.    0.    0.02  0.    0.001 0.01  0.003 0.    0.    0.072 0.009
  0.    0.    0.006 0.003 0.009 0.001]
 [0.    0.    0.036 0.007 0.006 0.843 0.014 0.032 1.731 0.001 0.    0.063
  0.001 0.001 0.001 0.019 0.    0.075 0.024 0.082 0.002 0.001 0.002 0.032
  0.    0.019 0.009 0.012 2.129 0.037]
 [0.    0.001 0.044 1.344 1.128 0.022 0.052 0.12  0.24  0.006 0.001 0.038
  0.001 0.    0.003 0.062 0.    0.7   0.07  0.07  0.331 0.001 0.105 0.204
  0.    0.03  0.249 0.051 1.581 2.038]
 [0.    0.    0.001 0.12  0.059 0.002 0.002 0.106 0.    0.    0.    0.002
  0.    0.    0.    0.004 0.    0.008 0.027 0.    0.    0.    0.003 0.
  0.    0.    0.178 0.    0.005 0.   ]
 [0.    0.    0.004 0.62  0.005 0.022 0.011 0.085 0.009 0.    0.    0.004
  0.    0.    0.    0.025 0.    0.128 1.185 0.024 0.004 0.    2.459 0.003
  0.    0.    0.394 0.004 0.179 0.   ]
 [0.001 0.003 0.059 0.078 0.02  0.1   1.496 0.026 0.01  0.035 0.    0.018
  0.007 0.    0.004 0.089 0.001 0.057 0.06  0.059 0.032 0.068 1.773 0.038
  0.    0.035 0.084 0.061 0.009 0.053]
 [0.001 0.    0.047 0.062 0.179 0.043 0.007 2.528 0.039 0.001 0.    0.303
  0.    0.004 0.    0.164 0.    1.17  0.072 0.036 0.003 0.    0.171 1.574
  0.001 0.002 0.223 0.03  2.219 0.069]
 [0.    0.    0.039 0.013 0.183 0.017 0.031 0.066 0.002 0.    0.    0.002
  0.    0.    0.    0.002 0.    0.64  0.056 0.029 0.001 0.001 0.01  0.002
  0.    0.    0.004 0.009 0.041 0.002]
 [0.001 0.    0.036 0.089 0.    0.034 0.029 1.365 0.167 0.001 0.    0.007
  0.001 0.    0.    0.02  0.    0.034 0.039 0.054 0.044 0.005 0.012 0.02
  0.    0.014 0.001 0.003 0.024 0.014]
 [0.    0.    0.036 0.003 0.053 0.112 0.016 0.006 0.013 0.    0.    0.002
  0.    0.    0.    0.019 0.    0.002 0.008 0.059 0.    0.    0.049 0.001
  0.    0.    0.    0.    0.002 0.002]
 [0.001 0.    0.029 0.079 0.062 0.62  0.201 0.046 0.037 0.001 0.    0.017
  0.    0.001 0.    0.001 0.    0.191 1.031 0.039 0.007 0.    0.045 0.401
  0.    0.    0.043 0.016 0.069 0.002]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.349 0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.88  0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.684 1.881 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.834 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    1.484 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.757 1.093 0.    0.    1.828 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    1.138 0.    0.644 0.    0.    0.    2.485
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.615 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.9   0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    4.129 0.    0.   ]
 [0.    0.    4.293 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.441 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    1.88  0.    1.184 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.385
  0.    0.    0.475 0.    0.    3.059]
 [0.    0.    0.    0.    1.232 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.927 0.    1.343 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.755
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.763
  0.    3.17  0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.463 0.
  0.    0.    0.812 0.    0.    0.   ]
 [0.    0.    2.543 0.    0.    0.    0.    0.    0.46  0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    2.861 0.404 0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    1.538 0.    0.    1.122 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.843 0.    0.    1.731 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    2.129 0.   ]
 [0.    0.    0.    1.344 1.128 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.7   0.    0.    0.331 0.    0.    0.
  0.    0.    0.    0.    1.581 2.038]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.62  0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    1.185 0.    0.    0.    2.459 0.
  0.    0.    0.394 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    1.496 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.773 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    2.528 0.    0.    0.    0.303
  0.    0.    0.    0.    0.    1.17  0.    0.    0.    0.    0.    1.574
  0.    0.    0.    0.    2.219 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.64  0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    1.365 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.62  0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    1.031 0.    0.    0.    0.    0.401
  0.    0.    0.    0.    0.    0.   ]]
{'fdr': 0.11475409836065574, 'tpr': 0.9, 'fpr': 0.018666666666666668, 'f1': 0.8925619834710743, 'shd': 9, 'npred': 61, 'ntrue': 60}
[3.593e-04 1.005e-01 4.531e-02 5.814e-02 1.055e-03 1.120e-01 2.185e-02
 5.903e-02 3.487e-01 4.094e-03 6.045e-02 5.049e-04 6.173e-03 1.870e-03
 2.841e-02 8.746e-03 4.948e-02 5.539e-02 8.796e-01 4.091e-02 8.347e-04
 1.489e-01 1.946e-02 6.335e-03 3.510e-02 1.972e-02 1.699e-02 2.386e-02
 2.201e-02 4.465e-04 1.602e-02 3.810e-03 1.122e-02 6.837e-01 1.881e+00
 8.654e-02 1.126e-01 1.614e-03 7.468e-03 3.365e-02 6.251e-03 4.707e-03
 4.804e-03 6.157e-02 1.747e-03 7.374e-02 2.685e-02 5.171e-02 4.834e-03
 6.567e-03 1.020e-01 5.526e-02 2.017e-03 1.426e-02 2.029e-03 8.118e-02
 8.506e-02 3.178e-02 2.438e-05 1.293e-04 8.322e-03 1.095e-01 2.110e-04
 6.844e-02 4.962e-02 1.022e-03 3.060e-05 4.902e-05 5.911e-05 3.807e-05
 1.629e-04 3.205e-06 4.337e-03 1.453e-05 1.446e-02 5.835e-02 1.241e-01
 7.137e-04 2.336e-04 8.912e-03 2.057e-02 5.716e-05 3.900e-05 1.881e-02
 1.338e-02 2.224e-02 7.721e-03 2.045e-04 1.705e-04 6.036e-03 2.043e-02
 2.343e-03 1.907e-02 4.490e-04 3.092e-04 7.936e-05 7.314e-06 7.065e-04
 4.969e-05 9.461e-05 1.016e-06 1.348e-03 7.371e-05 6.831e-05 8.709e-04
 5.117e-02 2.499e-04 1.092e-04 1.079e-03 1.064e-03 1.224e-04 1.923e-05
 7.883e-05 5.839e-05 5.914e-02 4.290e-04 1.267e-04 9.767e-05 2.464e-03
 5.744e-03 3.590e-03 1.143e-02 1.202e-02 1.230e-03 2.609e-05 6.321e-05
 2.717e-04 6.010e-05 1.742e-05 3.491e-05 5.142e-04 3.725e-05 6.618e-04
 9.015e-04 1.589e-01 2.201e-04 8.727e-05 5.928e-03 1.088e-03 1.351e-04
 1.558e-04 1.018e-03 9.265e-03 1.182e-02 1.135e-03 5.993e-06 1.051e-05
 4.978e-02 4.209e-02 1.439e-02 4.899e-02 4.564e-02 8.293e-02 1.333e-04
 5.175e-05 6.451e-02 1.277e-05 3.434e-04 1.071e-04 1.774e-03 2.074e-05
 6.255e-03 3.519e-03 8.338e-01 6.193e-04 1.351e-04 3.244e-02 8.581e-03
 1.553e-04 5.636e-04 1.130e-02 3.546e-03 3.186e-03 1.166e-03 1.166e-04
 2.163e-05 1.057e-02 2.923e-02 2.710e-02 4.667e-04 2.067e-02 4.926e-03
 1.356e-04 1.119e-04 5.362e-04 1.930e-05 3.896e-04 1.126e-04 1.669e-02
 1.338e-04 1.062e-02 7.002e-03 9.463e-02 1.867e-04 8.266e-05 9.002e-02
 4.512e-02 1.619e-05 5.746e-04 4.029e-03 9.514e-03 2.083e-02 2.117e-03
 1.166e-04 1.569e-04 9.276e-03 1.484e+00 8.681e-03 1.311e-02 2.682e-02
 4.757e-04 9.958e-05 3.888e-06 1.175e-03 9.750e-05 5.805e-06 1.357e-06
 2.223e-03 4.253e-05 3.484e-04 7.838e-04 8.413e-03 6.559e-04 2.036e-04
 4.786e-03 4.812e-04 1.615e-04 9.821e-05 7.777e-04 3.214e-04 4.142e-02
 1.829e-03 3.059e-04 1.425e-04 5.152e-02 7.983e-03 4.239e-02 5.470e-03
 4.319e-02 5.851e-02 8.495e-04 6.527e-06 6.052e-02 5.011e-06 9.368e-05
 7.425e-05 1.015e-01 1.853e-06 4.538e-02 7.565e-01 1.093e+00 2.559e-04
 5.679e-04 1.828e+00 7.600e-02 1.541e-04 2.714e-03 5.265e-02 1.415e-03
 5.693e-02 8.676e-03 5.470e-05 1.246e-03 1.268e-01 1.407e-01 3.127e-02
 1.138e+00 5.508e-02 6.442e-01 9.140e-02 1.206e-03 2.485e+00 7.042e-04
 4.274e-03 1.350e-04 2.697e-01 6.737e-03 1.831e-01 2.455e-02 9.656e-02
 8.637e-03 2.877e-04 6.353e-02 2.891e-03 4.063e-04 1.195e-02 6.154e-01
 2.065e-02 1.466e-02 2.553e-02 5.473e-04 7.677e-04 2.680e-02 1.875e-01
 3.268e-02 1.518e-02 9.031e-02 7.904e-02 9.005e-01 1.392e-02 3.793e-02
 4.757e-03 5.130e-04 1.722e-02 2.831e-02 4.086e-03 5.456e-02 6.429e-02
 1.026e-01 5.150e-02 8.927e-03 3.109e-02 6.849e-02 8.168e-03 3.814e-02
 9.502e-02 4.129e+00 4.088e-02 1.257e-02 2.280e-04 5.691e-04 4.293e+00
 8.965e-03 3.013e-02 1.033e-02 1.937e-02 5.596e-02 1.223e-02 5.619e-05
 5.944e-05 1.055e-04 2.156e-04 2.860e-05 1.346e-01 1.608e-04 9.021e-02
 3.291e-02 1.508e-01 1.742e-03 4.096e-04 8.883e-03 6.806e-02 1.659e-04
 2.382e-04 4.411e-01 2.362e-02 2.795e-02 1.228e-02 3.333e-03 6.577e-04
 2.854e-03 5.316e-02 4.728e-02 9.106e-03 1.880e+00 1.269e-02 1.184e+00
 2.078e-02 1.510e-04 5.033e-02 7.744e-04 8.572e-03 1.246e-01 9.021e-04
 9.776e-02 2.399e-03 7.788e-04 2.472e-02 2.253e-02 7.127e-02 3.849e-01
 9.105e-04 3.762e-02 4.746e-01 3.756e-02 2.099e-02 3.059e+00 5.306e-04
 3.115e-04 8.230e-02 7.308e-04 1.232e+00 4.344e-02 2.153e-02 1.288e-01
 6.329e-02 1.225e-03 6.338e-03 6.910e-02 6.046e-03 1.050e-03 1.173e-01
 6.149e-03 9.274e-01 3.394e-02 1.343e+00 2.009e-02 6.518e-03 4.491e-02
 3.831e-02 6.817e-03 4.623e-03 1.419e-01 6.799e-02 8.063e-03 4.376e-03
 3.494e-03 8.201e-04 3.189e-02 5.751e-02 6.060e-02 5.912e-02 3.968e-02
 1.029e-01 5.043e-02 1.129e-02 6.576e-04 1.755e+00 3.987e-04 5.054e-04
 1.219e-02 1.150e-03 1.885e-01 2.280e-02 6.785e-03 1.546e-02 8.129e-03
 1.188e-01 7.628e-01 1.246e-03 3.170e+00 3.542e-03 1.331e-02 1.221e-01
 5.697e-02 2.947e-04 4.124e-04 4.870e-02 7.554e-03 7.182e-02 2.944e-02
 1.873e-02 5.946e-02 1.107e-02 4.545e-04 8.966e-05 4.048e-03 9.324e-05
 1.427e-04 5.405e-05 2.019e-04 9.534e-02 9.693e-03 2.726e-02 2.747e-03
 1.274e-03 4.625e-01 1.229e-02 1.411e-04 5.345e-03 8.117e-01 4.547e-03
 8.009e-03 7.337e-02 3.823e-04 3.962e-03 2.543e+00 9.365e-02 8.843e-02
 1.826e-02 3.380e-02 1.228e-02 4.595e-01 3.443e-04 7.914e-04 2.637e-03
 2.182e-03 3.695e-04 3.665e-03 1.270e-02 1.210e-01 1.170e-03 3.443e-02
 2.861e+00 4.038e-01 1.293e-01 1.379e-02 3.640e-03 3.534e-03 4.864e-02
 5.068e-02 7.262e-02 4.209e-02 8.612e-05 1.693e-04 1.389e-02 5.969e-02
 1.538e+00 8.505e-02 1.312e-02 1.122e+00 1.166e-03 5.769e-06 4.424e-05
 2.802e-04 5.498e-05 1.146e-05 1.870e-05 2.805e-03 8.278e-05 2.342e-03
 9.172e-02 1.952e-03 3.686e-04 1.336e-02 6.944e-04 1.339e-04 5.625e-04
 2.972e-03 1.066e-02 2.059e-01 1.334e-03 8.052e-05 2.144e-04 6.706e-03
 2.618e-02 2.258e-02 8.002e-03 5.037e-03 3.586e-02 9.890e-04 1.259e-04
 1.504e-05 1.860e-04 2.858e-05 2.191e-04 2.452e-05 8.579e-04 2.721e-05
 1.408e-01 1.126e-02 1.877e-04 6.044e-05 1.807e-02 6.644e-04 9.615e-05
 1.694e-04 1.048e-02 5.959e-03 3.505e-02 5.484e-04 1.302e-05 2.191e-05
 4.228e-03 3.447e-03 7.283e-04 9.342e-04 6.559e-03 4.887e-04 6.846e-04
 4.327e-05 8.098e-06 4.828e-04 8.504e-06 1.855e-05 1.078e-04 2.040e-02
 2.521e-05 9.854e-04 1.044e-02 1.459e-04 1.345e-04 7.217e-02 9.213e-03
 1.488e-04 4.194e-04 5.577e-03 2.726e-03 8.513e-03 9.381e-04 4.100e-04
 4.502e-04 3.636e-02 6.743e-03 6.245e-03 8.428e-01 1.402e-02 3.179e-02
 1.731e+00 8.323e-04 1.650e-04 6.329e-02 9.370e-04 5.595e-04 5.423e-04
 1.855e-02 9.046e-06 7.534e-02 2.448e-02 8.215e-02 1.476e-03 1.902e-03
 3.194e-02 4.449e-04 1.943e-02 8.569e-03 1.152e-02 2.129e+00 3.668e-02
 4.143e-04 9.847e-04 4.406e-02 1.344e+00 1.128e+00 2.225e-02 5.200e-02
 1.203e-01 2.400e-01 5.707e-03 7.807e-04 3.790e-02 8.639e-04 3.063e-04
 3.430e-03 6.199e-02 6.204e-05 6.995e-01 6.969e-02 6.964e-02 3.309e-01
 1.051e-01 2.044e-01 2.925e-04 3.032e-02 2.491e-01 5.100e-02 1.581e+00
 2.038e+00 8.896e-05 1.131e-04 1.251e-03 1.197e-01 5.913e-02 1.797e-03
 1.717e-03 1.057e-01 1.984e-04 2.281e-04 1.148e-05 1.826e-03 3.584e-05
 2.069e-04 2.073e-06 4.303e-03 1.777e-06 8.363e-03 2.695e-02 4.300e-04
 6.088e-05 3.871e-05 2.178e-04 1.827e-05 4.283e-05 1.784e-01 3.763e-04
 5.111e-03 5.517e-05 1.663e-04 1.151e-04 3.981e-03 6.198e-01 4.718e-03
 2.243e-02 1.131e-02 8.458e-02 8.962e-03 2.460e-04 1.361e-04 3.781e-03
 1.222e-05 8.876e-05 5.862e-06 2.479e-02 7.829e-05 1.278e-01 1.185e+00
 2.431e-02 3.972e-03 1.335e-04 2.459e+00 6.174e-05 3.232e-04 3.941e-01
 3.906e-03 1.789e-01 3.985e-04 1.220e-03 3.280e-03 5.851e-02 7.792e-02
 1.971e-02 9.977e-02 1.496e+00 2.553e-02 9.732e-03 3.450e-02 4.604e-04
 1.779e-02 7.288e-03 3.519e-04 3.956e-03 8.908e-02 7.130e-04 5.706e-02
 5.977e-02 5.862e-02 3.215e-02 6.835e-02 1.773e+00 3.846e-02 3.547e-02
 8.419e-02 6.115e-02 9.095e-03 5.323e-02 5.211e-04 4.945e-04 4.743e-02
 6.207e-02 1.794e-01 4.313e-02 7.087e-03 2.528e+00 3.912e-02 1.014e-03
 2.624e-04 3.031e-01 2.788e-04 4.291e-03 9.827e-06 1.639e-01 4.862e-04
 1.170e+00 7.180e-02 3.587e-02 3.259e-03 3.267e-04 1.712e-01 1.574e+00
 8.177e-04 2.225e-01 2.953e-02 2.219e+00 6.941e-02 7.932e-05 2.044e-04
 3.881e-02 1.301e-02 1.833e-01 1.659e-02 3.088e-02 6.628e-02 1.556e-03
 1.833e-04 1.218e-04 2.018e-03 1.497e-05 1.510e-04 6.925e-06 2.027e-03
 7.356e-05 6.396e-01 5.583e-02 2.878e-02 5.263e-04 8.016e-04 1.018e-02
 2.479e-03 6.928e-05 3.116e-04 8.864e-03 4.085e-02 1.704e-03 6.260e-04
 2.006e-04 3.584e-02 8.854e-02 2.006e-04 3.444e-02 2.930e-02 1.365e+00
 1.667e-01 6.308e-04 5.142e-07 6.633e-03 9.505e-04 3.405e-04 1.619e-04
 1.982e-02 1.613e-04 3.402e-02 3.948e-02 5.424e-02 4.393e-02 4.562e-03
 1.181e-02 1.958e-02 3.455e-04 1.402e-02 6.718e-04 2.354e-02 1.376e-02
 1.237e-04 1.193e-04 3.626e-02 2.625e-03 5.265e-02 1.115e-01 1.622e-02
 5.904e-03 1.286e-02 1.140e-04 7.553e-05 1.832e-03 1.987e-04 2.169e-04
 1.987e-06 1.854e-02 1.656e-06 2.006e-03 8.259e-03 5.873e-02 1.649e-04
 9.438e-05 4.931e-02 1.240e-03 1.385e-04 1.457e-04 2.030e-04 1.596e-04
 1.716e-03 5.998e-04 4.137e-04 2.913e-02 7.940e-02 6.205e-02 6.198e-01
 2.012e-01 4.618e-02 3.654e-02 1.238e-03 2.735e-04 1.741e-02 4.483e-06
 6.446e-04 1.564e-04 1.078e-03 1.234e-04 1.909e-01 1.031e+00 3.851e-02
 7.117e-03 9.017e-05 4.536e-02 4.007e-01 9.472e-05 3.818e-04 4.322e-02
 1.595e-02 6.879e-02]
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 1. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]]
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.9562962962962962, 0.9229807680614648)
cuda
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cuda
Objective function 291.21 = squared loss an data 35.20 + 0.5*rho*h**2 254.631624 + alpha*h 0.000000 + L2reg 0.55 + L1reg 0.82 ; SHD = 416 ; DAG False
total norm for a microbatch 21.175331720601303 clip 1.8511579101054196
total norm for a microbatch 16.21057658250904 clip 16.6785491829798
total norm for a microbatch 14.394965133407739 clip 16.936082100140045
total norm for a microbatch 19.752563435748907 clip 17.002195770544084
total norm for a microbatch 20.348947403104358 clip 18.905444807696025
total norm for a microbatch 15.550336018142282 clip 17.704530907082596
total norm for a microbatch 26.431367596560875 clip 18.001155083284225
total norm for a microbatch 20.020290720727658 clip 18.766102376470766
total norm for a microbatch 21.428942560598216 clip 20.151860829874224
total norm for a microbatch 16.909136361584984 clip 19.52084487641292
total norm for a microbatch 26.800050926324783 clip 20.544842015896762
total norm for a microbatch 36.74971061017746 clip 21.242387999178113
cuda
Objective function 26.52 = squared loss an data 22.97 + 0.5*rho*h**2 2.425658 + alpha*h 0.000000 + L2reg 0.64 + L1reg 0.49 ; SHD = 78 ; DAG False
Proportion of microbatches that were clipped  0.8035685451316001
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 2.202570457992195
iteration 1 in outer loop, alpha = 2.202570457992195, rho = 1.0, h = 2.202570457992195
cuda
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cuda
Objective function 31.37 = squared loss an data 22.97 + 0.5*rho*h**2 2.425658 + alpha*h 4.851317 + L2reg 0.64 + L1reg 0.49 ; SHD = 78 ; DAG False
total norm for a microbatch 29.003927762556557 clip 2.9274048785051345
total norm for a microbatch 25.520553029816394 clip 9.827362307325945
total norm for a microbatch 37.100048766515734 clip 12.751562309647179
total norm for a microbatch 31.80335851473564 clip 23.48053675415908
total norm for a microbatch 24.823720338894688 clip 24.365266128598652
total norm for a microbatch 31.736518024226125 clip 23.09021130886225
total norm for a microbatch 20.772655290473516 clip 22.634073906784877
total norm for a microbatch 28.296359017863992 clip 24.095953961814544
cuda
Objective function 27.91 = squared loss an data 22.20 + 0.5*rho*h**2 1.081884 + alpha*h 3.239927 + L2reg 0.93 + L1reg 0.46 ; SHD = 75 ; DAG False
Proportion of microbatches that were clipped  0.8039247618272127
iteration 1 in inner loop, alpha 2.202570457992195 rho 1.0 h 1.4709754550585075
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cuda
Objective function 37.65 = squared loss an data 22.20 + 0.5*rho*h**2 10.818844 + alpha*h 3.239927 + L2reg 0.93 + L1reg 0.46 ; SHD = 75 ; DAG False
total norm for a microbatch 30.595119610846407 clip 3.259756890234208
total norm for a microbatch 29.43753389266003 clip 28.002622355708464
total norm for a microbatch 33.44278330470985 clip 30.340444901986825
total norm for a microbatch 39.10246166759216 clip 28.794923264996154
total norm for a microbatch 30.127460126015627 clip 31.235071011572288
total norm for a microbatch 59.14677166401899 clip 28.224212392751134
total norm for a microbatch 32.800602136873586 clip 28.7551299020825
total norm for a microbatch 31.429653750877964 clip 27.712928891594984
total norm for a microbatch 34.10017879025357 clip 28.455563858610084
total norm for a microbatch 23.596573114648425 clip 29.247053770656088
total norm for a microbatch 34.0684136045629 clip 29.645500338619406
total norm for a microbatch 26.096367107406422 clip 29.056957692786195
total norm for a microbatch 40.10441842356635 clip 29.630273289755547
cuda
Objective function 28.68 = squared loss an data 23.55 + 0.5*rho*h**2 2.153250 + alpha*h 1.445413 + L2reg 1.11 + L1reg 0.42 ; SHD = 94 ; DAG True
Proportion of microbatches that were clipped  0.8091333011738222
iteration 2 in inner loop, alpha 2.202570457992195 rho 10.0 h 0.6562392277721365
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cuda
Objective function 48.06 = squared loss an data 23.55 + 0.5*rho*h**2 21.532496 + alpha*h 1.445413 + L2reg 1.11 + L1reg 0.42 ; SHD = 94 ; DAG True
total norm for a microbatch 70.12139525208327 clip 1.0
total norm for a microbatch 42.09081600549226 clip 6.895783329617075
total norm for a microbatch 32.23542945010058 clip 6.895783329617075
total norm for a microbatch 45.38885885458332 clip 18.477762008719147
total norm for a microbatch 48.94907061910585 clip 29.828100571602377
total norm for a microbatch 32.40487030133412 clip 33.75886088148439
total norm for a microbatch 48.97210318883314 clip 34.66390999057132
total norm for a microbatch 60.80969093893972 clip 31.472394844860112
total norm for a microbatch 47.14033362473125 clip 30.87784426282143
total norm for a microbatch 34.10541331373803 clip 30.442201006861083
total norm for a microbatch 29.926538271987848 clip 31.461310598809714
total norm for a microbatch 27.57632861912455 clip 31.979957483322007
total norm for a microbatch 30.371522202803252 clip 32.20739045141626
total norm for a microbatch 37.23802792585844 clip 31.516072913778395
total norm for a microbatch 45.315294842878096 clip 31.353527640487663
total norm for a microbatch 29.607838493092963 clip 31.513339308239598
total norm for a microbatch 32.70230202536139 clip 31.508022347672917
cuda
Objective function 29.58 = squared loss an data 25.05 + 0.5*rho*h**2 2.490051 + alpha*h 0.491529 + L2reg 1.18 + L1reg 0.37 ; SHD = 91 ; DAG True
Proportion of microbatches that were clipped  0.8088390608497847
iteration 3 in inner loop, alpha 2.202570457992195 rho 100.0 h 0.22316142908173475
iteration 2 in outer loop, alpha = 24.51871336616567, rho = 100.0, h = 0.22316142908173475
cuda
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cuda
Objective function 34.56 = squared loss an data 25.05 + 0.5*rho*h**2 2.490051 + alpha*h 5.471631 + L2reg 1.18 + L1reg 0.37 ; SHD = 91 ; DAG True
total norm for a microbatch 43.25377959502954 clip 1.2929899128129856
total norm for a microbatch 50.023839514303646 clip 2.2065959255337204
total norm for a microbatch 34.064008548433335 clip 2.883073826190332
total norm for a microbatch 45.93877740203303 clip 9.253742714706249
total norm for a microbatch 25.972081220501096 clip 33.703709365585894
total norm for a microbatch 40.30395998805976 clip 34.83977492846432
total norm for a microbatch 48.03988118728254 clip 35.05256919536501
total norm for a microbatch 51.92040764477515 clip 33.55350378172198
total norm for a microbatch 37.7239718215409 clip 35.459963962983466
total norm for a microbatch 29.33190566813774 clip 34.15477435316981
total norm for a microbatch 49.250600110948305 clip 34.80290208072275
total norm for a microbatch 25.518834352064527 clip 34.4645089928981
total norm for a microbatch 45.53647320069665 clip 35.80830799375767
total norm for a microbatch 36.629784480101605 clip 32.87133418331528
total norm for a microbatch 42.42366621580785 clip 34.410202919607535
cuda
Objective function 31.61 = squared loss an data 25.41 + 0.5*rho*h**2 1.045421 + alpha*h 3.545343 + L2reg 1.24 + L1reg 0.36 ; SHD = 98 ; DAG True
Proportion of microbatches that were clipped  0.8072941937570759
iteration 1 in inner loop, alpha 24.51871336616567 rho 100.0 h 0.14459742599581205
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cuda
Objective function 41.02 = squared loss an data 25.41 + 0.5*rho*h**2 10.454208 + alpha*h 3.545343 + L2reg 1.24 + L1reg 0.36 ; SHD = 98 ; DAG True
total norm for a microbatch 31.20877573615604 clip 1.6994152444932447
total norm for a microbatch 48.94391937816497 clip 3.737997185022944
total norm for a microbatch 57.89788455985012 clip 38.05197578681986
total norm for a microbatch 46.62900347740701 clip 38.05197578681986
total norm for a microbatch 40.938211507229745 clip 39.07842693624758
total norm for a microbatch 44.76454416105439 clip 39.980772516136106
total norm for a microbatch 49.309140835289305 clip 39.87214111609057
total norm for a microbatch 39.383499118998564 clip 40.60370348032053
total norm for a microbatch 38.39640049258112 clip 36.40896373410313
total norm for a microbatch 41.31782300507082 clip 36.37604020799686
total norm for a microbatch 34.2222642268862 clip 36.3290848187318
total norm for a microbatch 36.453624717300535 clip 36.3290848187318
total norm for a microbatch 41.60751740447663 clip 35.88195030541796
total norm for a microbatch 43.23798323225297 clip 35.79288578967339
cuda
Objective function 31.18 = squared loss an data 25.89 + 0.5*rho*h**2 2.039779 + alpha*h 1.566045 + L2reg 1.33 + L1reg 0.36 ; SHD = 115 ; DAG True
Proportion of microbatches that were clipped  0.8134607726005576
iteration 2 in inner loop, alpha 24.51871336616567 rho 1000.0 h 0.06387141205532743
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cuda
Objective function 49.54 = squared loss an data 25.89 + 0.5*rho*h**2 20.397786 + alpha*h 1.566045 + L2reg 1.33 + L1reg 0.36 ; SHD = 115 ; DAG True
total norm for a microbatch 192.1074282383521 clip 1.3285360296189497
total norm for a microbatch 66.92442732957298 clip 2.342497264749504
total norm for a microbatch 63.27596249512122 clip 59.7012949032081
total norm for a microbatch 84.24148438076335 clip 77.64796488184263
total norm for a microbatch 72.3423597381579 clip 75.2451306580968
total norm for a microbatch 47.48233839303119 clip 50.14845632354544
total norm for a microbatch 44.39588425778182 clip 43.45245255447177
total norm for a microbatch 59.90917913569282 clip 40.48804417795525
total norm for a microbatch 40.23963787678426 clip 41.26438989751369
total norm for a microbatch 49.64713453248055 clip 42.132294969030674
total norm for a microbatch 64.68638163836037 clip 40.25458121278845
total norm for a microbatch 44.95283420711614 clip 40.25458121278845
cuda
Objective function 30.84 = squared loss an data 26.14 + 0.5*rho*h**2 2.464373 + alpha*h 0.544335 + L2reg 1.35 + L1reg 0.35 ; SHD = 125 ; DAG True
Proportion of microbatches that were clipped  0.8145283470217686
iteration 3 in inner loop, alpha 24.51871336616567 rho 10000.0 h 0.022200780919099827
iteration 3 in outer loop, alpha = 246.52652255716396, rho = 10000.0, h = 0.022200780919099827
cuda
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cuda
Objective function 35.77 = squared loss an data 26.14 + 0.5*rho*h**2 2.464373 + alpha*h 5.473081 + L2reg 1.35 + L1reg 0.35 ; SHD = 125 ; DAG True
total norm for a microbatch 70.0312652961482 clip 1.0
total norm for a microbatch 88.77362632549826 clip 64.33751086047766
total norm for a microbatch 88.73022351205717 clip 78.80418128601256
total norm for a microbatch 69.92728525490631 clip 62.86018388792527
total norm for a microbatch 52.92921599463904 clip 45.917808578878855
total norm for a microbatch 47.1667506465638 clip 44.45343583232555
total norm for a microbatch 48.394655418964184 clip 44.44814961835411
total norm for a microbatch 57.05105656148903 clip 47.30571697098622
total norm for a microbatch 48.61224284397515 clip 47.45987918341704
total norm for a microbatch 46.564865021955015 clip 45.30275477246598
total norm for a microbatch 60.22236143512235 clip 47.525395666052674
cuda
Objective function 32.47 = squared loss an data 26.25 + 0.5*rho*h**2 1.003229 + alpha*h 3.492036 + L2reg 1.37 + L1reg 0.36 ; SHD = 141 ; DAG True
Proportion of microbatches that were clipped  0.8148089298482561
iteration 1 in inner loop, alpha 246.52652255716396 rho 10000.0 h 0.014164948609018069
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cuda
Objective function 41.50 = squared loss an data 26.25 + 0.5*rho*h**2 10.032288 + alpha*h 3.492036 + L2reg 1.37 + L1reg 0.36 ; SHD = 141 ; DAG True
total norm for a microbatch 333.8976014936365 clip 35.839554808996
total norm for a microbatch 469.13525673763604 clip 125.24951506921897
total norm for a microbatch 1004.7897775865542 clip 691.366931898554
total norm for a microbatch 1174.2580035678145 clip 762.3772653342855
total norm for a microbatch 1174.601225895525 clip 762.3772653342855
total norm for a microbatch 1029.9597040826081 clip 913.8694031884606
total norm for a microbatch 462.8476485754125 clip 487.09732860424
total norm for a microbatch 50.96841754183986 clip 42.715512642582254
total norm for a microbatch 38.242080797483254 clip 35.58503621409141
total norm for a microbatch 37.60441056909863 clip 35.31607229603343
total norm for a microbatch 44.502184051136176 clip 33.9107678325669
total norm for a microbatch 37.959296235306084 clip 36.51989580433874
total norm for a microbatch 40.013165149393465 clip 35.5652335004213
cuda
Objective function 29.97 = squared loss an data 27.70 + 0.5*rho*h**2 0.092441 + alpha*h 0.335206 + L2reg 1.48 + L1reg 0.36 ; SHD = 162 ; DAG True
Proportion of microbatches that were clipped  0.8111013074516724
iteration 2 in inner loop, alpha 246.52652255716396 rho 100000.0 h 0.001359715527712524
iteration 4 in outer loop, alpha = 382.49807532841635, rho = 100000.0, h = 0.001359715527712524
cuda
noise_multiplier  0.6  noise_multiplier_b  2.5  noise_multiplier_delta  0.6043672230190352
cuda
Objective function 30.16 = squared loss an data 27.70 + 0.5*rho*h**2 0.092441 + alpha*h 0.520089 + L2reg 1.48 + L1reg 0.36 ; SHD = 162 ; DAG True
total norm for a microbatch 2583.556217550431 clip 1.5800104281720568
total norm for a microbatch 1524.8721692713518 clip 2.0639977664832068
total norm for a microbatch 643.3327382774497 clip 3.2480238231413754
total norm for a microbatch 999.3444132384287 clip 1102.0409157606516
total norm for a microbatch 1993.3500204995657 clip 1774.4191414170798
total norm for a microbatch 2253.4052536222543 clip 1637.9713976710393
total norm for a microbatch 1616.3028455886897 clip 1482.7757434035377
total norm for a microbatch 1682.966744601487 clip 1782.691856649897
total norm for a microbatch 982.3402535012583 clip 735.3244659211143
total norm for a microbatch 581.7516984168025 clip 501.76138846378643
total norm for a microbatch 533.9018413568713 clip 545.2675406326165
total norm for a microbatch 71.81390549547777 clip 68.09756112964489
total norm for a microbatch 32.5664976555394 clip 36.16677763006839
total norm for a microbatch 29.15992068443448 clip 37.03456767390887
cuda
Objective function 31.42 = squared loss an data 29.01 + 0.5*rho*h**2 0.046125 + alpha*h 0.367378 + L2reg 1.61 + L1reg 0.39 ; SHD = 176 ; DAG True
Proportion of microbatches that were clipped  0.8090077071290944
iteration 1 in inner loop, alpha 382.49807532841635 rho 100000.0 h 0.0009604694086888799
iteration 5 in outer loop, alpha = 1342.967484017296, rho = 1000000.0, h = 0.0009604694086888799
Threshold 0.3
[[0.001 0.015 0.169 0.486 0.358 0.292 0.54  0.006 0.217 0.018 0.003 0.019
  0.003 0.003 0.002 0.024 0.004 0.078 0.094 0.188 0.004 0.003 0.111 0.105
  0.016 0.012 0.18  0.182 0.227 0.185]
 [0.127 0.001 0.483 0.812 0.323 0.318 0.708 0.082 0.359 0.06  0.004 0.022
  0.002 0.005 0.002 0.02  0.012 0.172 0.192 0.484 0.007 0.003 0.296 0.15
  0.107 0.273 0.146 0.435 0.464 0.177]
 [0.005 0.003 0.002 0.233 0.049 0.03  0.054 0.001 0.017 0.002 0.001 0.001
  0.001 0.001 0.001 0.001 0.002 0.005 0.004 0.048 0.002 0.002 0.065 0.002
  0.002 0.002 0.002 0.152 0.015 0.062]
 [0.002 0.001 0.004 0.002 0.013 0.075 0.019 0.001 0.022 0.002 0.    0.002
  0.001 0.001 0.001 0.003 0.001 0.003 0.003 0.046 0.002 0.001 0.009 0.002
  0.005 0.002 0.005 0.031 0.012 0.009]
 [0.003 0.003 0.038 0.113 0.002 0.071 0.091 0.003 0.045 0.003 0.002 0.003
  0.002 0.001 0.001 0.003 0.001 0.009 0.007 0.034 0.002 0.001 0.038 0.001
  0.005 0.005 0.015 0.078 0.007 0.113]
 [0.003 0.003 0.071 0.023 0.035 0.001 0.24  0.003 0.035 0.001 0.001 0.003
  0.001 0.002 0.001 0.002 0.002 0.013 0.005 0.109 0.001 0.001 0.04  0.007
  0.009 0.006 0.01  0.116 0.027 0.15 ]
 [0.002 0.001 0.031 0.091 0.019 0.006 0.001 0.002 0.004 0.001 0.001 0.002
  0.001 0.001 0.001 0.001 0.001 0.004 0.01  0.005 0.001 0.001 0.007 0.001
  0.002 0.008 0.002 0.004 0.07  0.007]
 [0.19  0.021 0.355 0.928 0.243 0.256 0.532 0.003 0.23  0.008 0.002 0.002
  0.009 0.005 0.002 0.055 0.007 0.074 0.118 0.149 0.005 0.005 0.248 0.036
  0.053 0.076 0.095 0.506 0.247 0.392]
 [0.007 0.002 0.118 0.098 0.055 0.06  0.217 0.005 0.001 0.002 0.001 0.003
  0.001 0.001 0.001 0.003 0.001 0.005 0.01  0.094 0.001 0.002 0.038 0.004
  0.002 0.001 0.008 0.119 0.076 0.144]
 [0.088 0.054 0.453 0.531 0.331 0.875 0.736 0.174 0.56  0.    0.006 0.034
  0.005 0.005 0.003 0.051 0.032 0.064 0.119 0.444 0.008 0.002 0.233 0.154
  0.101 0.129 0.413 0.496 0.522 0.301]
 [0.277 0.262 1.066 0.893 0.434 0.916 1.22  0.541 0.676 0.243 0.001 0.416
  0.098 0.03  0.008 0.122 0.054 0.376 0.549 0.494 0.117 0.008 0.531 0.108
  0.383 0.247 0.428 2.073 0.263 0.526]
 [0.075 0.052 1.178 0.387 0.347 0.377 0.367 0.369 0.368 0.065 0.003 0.001
  0.026 0.01  0.004 0.081 0.01  0.086 0.308 0.736 0.024 0.012 0.277 0.202
  0.06  0.236 0.21  0.554 0.201 0.209]
 [0.342 0.38  0.987 0.699 0.697 1.    0.905 0.128 0.628 0.2   0.02  0.084
  0.001 0.023 0.02  0.118 0.202 0.295 0.493 0.442 0.226 0.004 0.709 0.154
  0.145 0.38  0.226 1.15  0.641 1.137]
 [0.423 0.233 0.713 0.829 0.729 0.247 1.165 0.199 0.84  0.198 0.082 0.12
  0.094 0.001 0.013 0.245 0.205 0.183 0.408 0.443 0.274 0.019 0.645 0.272
  0.334 0.273 0.541 0.563 0.666 0.724]
 [0.419 0.327 0.909 0.806 1.054 0.509 0.733 0.352 0.654 0.205 0.187 0.342
  0.093 0.156 0.001 0.427 0.264 0.334 0.733 0.599 0.202 0.062 0.43  1.001
  0.493 0.736 0.521 1.268 0.719 0.866]
 [0.087 0.076 0.619 0.303 0.356 0.582 0.646 0.045 0.254 0.052 0.009 0.029
  0.008 0.005 0.003 0.001 0.03  0.122 0.286 0.962 0.005 0.005 0.677 0.12
  0.138 0.074 0.508 0.837 0.236 0.381]
 [0.34  0.124 0.386 0.635 0.87  0.566 1.158 0.21  0.632 0.059 0.043 0.107
  0.007 0.005 0.002 0.059 0.001 0.244 0.26  0.376 0.006 0.038 0.383 0.386
  0.089 0.297 0.342 0.543 0.56  0.591]
 [0.032 0.007 0.179 0.372 0.306 0.105 0.321 0.029 0.229 0.022 0.003 0.017
  0.004 0.005 0.003 0.012 0.003 0.002 0.057 0.55  0.002 0.001 0.239 0.015
  0.069 0.082 0.047 0.407 0.05  0.25 ]
 [0.023 0.006 0.282 0.327 0.169 0.259 0.106 0.01  0.213 0.01  0.002 0.003
  0.002 0.003 0.001 0.004 0.005 0.025 0.002 0.129 0.003 0.001 0.088 0.034
  0.013 0.005 0.036 0.266 0.125 0.124]
 [0.004 0.002 0.053 0.054 0.073 0.024 0.202 0.009 0.032 0.002 0.001 0.001
  0.002 0.002 0.001 0.001 0.002 0.002 0.011 0.002 0.001 0.001 0.042 0.004
  0.004 0.003 0.01  0.06  0.006 0.069]
 [0.292 0.142 0.466 0.454 0.56  0.889 0.843 0.198 0.907 0.19  0.011 0.09
  0.004 0.005 0.005 0.199 0.17  0.34  0.322 0.899 0.001 0.006 0.471 0.222
  0.117 0.215 0.209 0.541 0.172 0.74 ]
 [0.229 0.329 0.512 0.884 0.659 0.777 1.09  0.345 0.457 0.37  0.148 0.108
  0.233 0.118 0.035 0.229 0.059 0.676 0.801 0.528 0.188 0.001 0.99  0.209
  0.394 0.481 0.34  1.065 0.717 1.021]
 [0.008 0.004 0.028 0.163 0.05  0.052 0.142 0.004 0.072 0.004 0.001 0.002
  0.001 0.001 0.001 0.002 0.002 0.003 0.021 0.059 0.002 0.001 0.002 0.006
  0.002 0.008 0.006 0.005 0.011 0.064]
 [0.015 0.01  0.391 0.567 0.683 0.198 0.74  0.073 0.267 0.007 0.009 0.007
  0.005 0.005 0.001 0.01  0.004 0.13  0.097 0.313 0.004 0.006 0.451 0.002
  0.151 0.146 0.307 0.386 0.282 0.357]
 [0.116 0.012 0.495 0.213 0.222 0.134 0.429 0.057 0.354 0.012 0.003 0.025
  0.008 0.003 0.002 0.011 0.015 0.027 0.11  0.261 0.012 0.003 0.423 0.008
  0.001 0.069 0.115 0.28  0.156 0.207]
 [0.122 0.004 0.436 0.381 0.21  0.224 0.125 0.067 0.415 0.01  0.003 0.004
  0.002 0.003 0.002 0.021 0.002 0.034 0.356 0.381 0.005 0.002 0.219 0.021
  0.035 0.002 0.123 0.284 0.512 0.217]
 [0.009 0.008 0.472 0.233 0.145 0.137 0.307 0.016 0.204 0.002 0.002 0.007
  0.003 0.001 0.001 0.003 0.003 0.067 0.071 0.139 0.004 0.003 0.209 0.004
  0.01  0.009 0.002 0.118 0.083 0.194]
 [0.004 0.002 0.012 0.071 0.025 0.013 0.188 0.003 0.016 0.002 0.    0.001
  0.001 0.001 0.    0.001 0.002 0.004 0.003 0.019 0.001 0.    0.13  0.003
  0.004 0.003 0.011 0.001 0.012 0.067]
 [0.006 0.002 0.101 0.101 0.192 0.071 0.023 0.007 0.042 0.001 0.003 0.006
  0.001 0.002 0.001 0.004 0.001 0.039 0.014 0.173 0.006 0.001 0.099 0.004
  0.007 0.003 0.013 0.102 0.002 0.029]
 [0.004 0.003 0.04  0.148 0.01  0.009 0.185 0.003 0.01  0.002 0.002 0.004
  0.001 0.001 0.001 0.003 0.002 0.01  0.023 0.038 0.001 0.001 0.044 0.004
  0.006 0.005 0.009 0.032 0.081 0.001]]
[[0.    0.    0.    0.486 0.358 0.    0.54  0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.483 0.812 0.323 0.318 0.708 0.    0.359 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.484 0.    0.    0.    0.
  0.    0.    0.    0.435 0.464 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.355 0.928 0.    0.    0.532 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.506 0.    0.392]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.453 0.531 0.331 0.875 0.736 0.    0.56  0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.444 0.    0.    0.    0.
  0.    0.    0.413 0.496 0.522 0.301]
 [0.    0.    1.066 0.893 0.434 0.916 1.22  0.541 0.676 0.    0.    0.416
  0.    0.    0.    0.    0.    0.376 0.549 0.494 0.    0.    0.531 0.
  0.383 0.    0.428 2.073 0.    0.526]
 [0.    0.    1.178 0.387 0.347 0.377 0.367 0.369 0.368 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.308 0.736 0.    0.    0.    0.
  0.    0.    0.    0.554 0.    0.   ]
 [0.342 0.38  0.987 0.699 0.697 1.    0.905 0.    0.628 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.493 0.442 0.    0.    0.709 0.
  0.    0.38  0.    1.15  0.641 1.137]
 [0.423 0.    0.713 0.829 0.729 0.    1.165 0.    0.84  0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.408 0.443 0.    0.    0.645 0.
  0.334 0.    0.541 0.563 0.666 0.724]
 [0.419 0.327 0.909 0.806 1.054 0.509 0.733 0.352 0.654 0.    0.    0.342
  0.    0.    0.    0.427 0.    0.334 0.733 0.599 0.    0.    0.43  1.001
  0.493 0.736 0.521 1.268 0.719 0.866]
 [0.    0.    0.619 0.303 0.356 0.582 0.646 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.962 0.    0.    0.677 0.
  0.    0.    0.508 0.837 0.    0.381]
 [0.34  0.    0.386 0.635 0.87  0.566 1.158 0.    0.632 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.376 0.    0.    0.383 0.386
  0.    0.    0.342 0.543 0.56  0.591]
 [0.    0.    0.    0.372 0.306 0.    0.321 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.55  0.    0.    0.    0.
  0.    0.    0.    0.407 0.    0.   ]
 [0.    0.    0.    0.327 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.466 0.454 0.56  0.889 0.843 0.    0.907 0.    0.    0.
  0.    0.    0.    0.    0.    0.34  0.322 0.899 0.    0.    0.471 0.
  0.    0.    0.    0.541 0.    0.74 ]
 [0.    0.329 0.512 0.884 0.659 0.777 1.09  0.345 0.457 0.37  0.    0.
  0.    0.    0.    0.    0.    0.676 0.801 0.528 0.    0.    0.99  0.
  0.394 0.481 0.34  1.065 0.717 1.021]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.391 0.567 0.683 0.    0.74  0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.313 0.    0.    0.451 0.
  0.    0.    0.307 0.386 0.    0.357]
 [0.    0.    0.495 0.    0.    0.    0.429 0.    0.354 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.423 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.436 0.381 0.    0.    0.    0.    0.415 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.356 0.381 0.    0.    0.    0.
  0.    0.    0.    0.    0.512 0.   ]
 [0.    0.    0.472 0.    0.    0.    0.307 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]]
{'fdr': 0.8181818181818182, 'tpr': 0.5666666666666667, 'fpr': 0.408, 'f1': 0.2753036437246963, 'shd': 176, 'npred': 187, 'ntrue': 60}
[1.483e-02 1.686e-01 4.861e-01 3.578e-01 2.920e-01 5.398e-01 6.491e-03
 2.175e-01 1.792e-02 2.809e-03 1.877e-02 3.407e-03 3.267e-03 2.310e-03
 2.441e-02 4.343e-03 7.759e-02 9.448e-02 1.880e-01 3.532e-03 2.639e-03
 1.105e-01 1.051e-01 1.600e-02 1.242e-02 1.804e-01 1.821e-01 2.271e-01
 1.850e-01 1.267e-01 4.835e-01 8.123e-01 3.226e-01 3.178e-01 7.085e-01
 8.173e-02 3.594e-01 6.034e-02 3.683e-03 2.238e-02 2.040e-03 5.024e-03
 2.194e-03 2.038e-02 1.249e-02 1.723e-01 1.920e-01 4.838e-01 7.460e-03
 2.605e-03 2.960e-01 1.500e-01 1.071e-01 2.735e-01 1.456e-01 4.350e-01
 4.645e-01 1.770e-01 5.020e-03 2.583e-03 2.328e-01 4.891e-02 3.031e-02
 5.421e-02 1.441e-03 1.718e-02 2.114e-03 6.436e-04 7.544e-04 8.737e-04
 7.938e-04 7.000e-04 9.680e-04 1.678e-03 5.410e-03 3.857e-03 4.819e-02
 2.222e-03 1.501e-03 6.534e-02 1.950e-03 2.416e-03 2.133e-03 2.231e-03
 1.521e-01 1.495e-02 6.237e-02 2.100e-03 1.034e-03 3.853e-03 1.281e-02
 7.549e-02 1.890e-02 1.332e-03 2.246e-02 1.752e-03 4.152e-04 2.334e-03
 8.098e-04 8.543e-04 1.141e-03 3.028e-03 1.476e-03 2.669e-03 3.380e-03
 4.554e-02 1.730e-03 1.047e-03 9.123e-03 2.099e-03 4.776e-03 2.255e-03
 5.327e-03 3.053e-02 1.222e-02 9.387e-03 3.266e-03 3.066e-03 3.760e-02
 1.133e-01 7.135e-02 9.143e-02 3.313e-03 4.451e-02 2.935e-03 1.916e-03
 3.002e-03 1.508e-03 1.281e-03 6.729e-04 3.125e-03 1.054e-03 9.157e-03
 6.949e-03 3.374e-02 1.930e-03 8.835e-04 3.798e-02 1.316e-03 4.879e-03
 4.564e-03 1.476e-02 7.816e-02 6.559e-03 1.134e-01 2.692e-03 3.360e-03
 7.098e-02 2.328e-02 3.458e-02 2.395e-01 3.365e-03 3.472e-02 8.259e-04
 7.988e-04 3.128e-03 5.145e-04 2.172e-03 1.162e-03 2.085e-03 1.821e-03
 1.328e-02 5.431e-03 1.090e-01 1.173e-03 7.836e-04 3.974e-02 6.672e-03
 8.592e-03 5.597e-03 1.013e-02 1.156e-01 2.728e-02 1.498e-01 1.876e-03
 1.479e-03 3.127e-02 9.057e-02 1.865e-02 5.623e-03 1.793e-03 4.387e-03
 1.124e-03 5.486e-04 1.978e-03 6.487e-04 5.237e-04 7.313e-04 1.320e-03
 7.586e-04 3.772e-03 9.616e-03 4.816e-03 7.721e-04 8.163e-04 7.107e-03
 5.406e-04 2.396e-03 8.396e-03 2.182e-03 4.248e-03 6.974e-02 7.336e-03
 1.900e-01 2.128e-02 3.546e-01 9.281e-01 2.426e-01 2.561e-01 5.325e-01
 2.297e-01 7.796e-03 1.601e-03 2.453e-03 9.442e-03 5.010e-03 2.182e-03
 5.527e-02 6.581e-03 7.351e-02 1.179e-01 1.491e-01 4.717e-03 4.593e-03
 2.482e-01 3.632e-02 5.306e-02 7.593e-02 9.538e-02 5.058e-01 2.473e-01
 3.919e-01 6.978e-03 2.099e-03 1.179e-01 9.783e-02 5.514e-02 5.983e-02
 2.167e-01 5.442e-03 2.235e-03 1.499e-03 2.762e-03 1.352e-03 1.025e-03
 9.920e-04 3.398e-03 1.008e-03 5.136e-03 1.017e-02 9.438e-02 1.023e-03
 2.159e-03 3.775e-02 3.977e-03 2.412e-03 1.452e-03 7.671e-03 1.190e-01
 7.638e-02 1.439e-01 8.829e-02 5.420e-02 4.532e-01 5.310e-01 3.314e-01
 8.755e-01 7.362e-01 1.741e-01 5.603e-01 5.554e-03 3.416e-02 4.806e-03
 4.981e-03 3.363e-03 5.108e-02 3.231e-02 6.351e-02 1.189e-01 4.442e-01
 7.542e-03 2.149e-03 2.333e-01 1.543e-01 1.012e-01 1.292e-01 4.132e-01
 4.959e-01 5.219e-01 3.007e-01 2.766e-01 2.624e-01 1.066e+00 8.933e-01
 4.342e-01 9.160e-01 1.220e+00 5.412e-01 6.762e-01 2.435e-01 4.158e-01
 9.807e-02 2.989e-02 7.711e-03 1.221e-01 5.395e-02 3.764e-01 5.486e-01
 4.940e-01 1.171e-01 7.582e-03 5.309e-01 1.082e-01 3.831e-01 2.474e-01
 4.278e-01 2.073e+00 2.625e-01 5.257e-01 7.468e-02 5.198e-02 1.178e+00
 3.874e-01 3.472e-01 3.772e-01 3.674e-01 3.688e-01 3.685e-01 6.550e-02
 3.355e-03 2.553e-02 1.006e-02 3.855e-03 8.077e-02 1.026e-02 8.632e-02
 3.083e-01 7.364e-01 2.403e-02 1.231e-02 2.774e-01 2.021e-01 6.021e-02
 2.364e-01 2.100e-01 5.544e-01 2.005e-01 2.094e-01 3.416e-01 3.799e-01
 9.869e-01 6.994e-01 6.970e-01 1.000e+00 9.046e-01 1.283e-01 6.281e-01
 2.000e-01 1.955e-02 8.369e-02 2.269e-02 1.990e-02 1.176e-01 2.021e-01
 2.948e-01 4.928e-01 4.415e-01 2.256e-01 4.263e-03 7.087e-01 1.537e-01
 1.449e-01 3.803e-01 2.259e-01 1.150e+00 6.410e-01 1.137e+00 4.231e-01
 2.327e-01 7.131e-01 8.291e-01 7.291e-01 2.466e-01 1.165e+00 1.985e-01
 8.403e-01 1.977e-01 8.245e-02 1.205e-01 9.364e-02 1.272e-02 2.449e-01
 2.053e-01 1.830e-01 4.084e-01 4.427e-01 2.738e-01 1.948e-02 6.453e-01
 2.724e-01 3.344e-01 2.733e-01 5.414e-01 5.630e-01 6.658e-01 7.241e-01
 4.187e-01 3.266e-01 9.094e-01 8.062e-01 1.054e+00 5.091e-01 7.330e-01
 3.520e-01 6.537e-01 2.046e-01 1.870e-01 3.418e-01 9.257e-02 1.559e-01
 4.269e-01 2.642e-01 3.337e-01 7.326e-01 5.993e-01 2.019e-01 6.240e-02
 4.302e-01 1.001e+00 4.933e-01 7.365e-01 5.214e-01 1.268e+00 7.193e-01
 8.664e-01 8.708e-02 7.629e-02 6.194e-01 3.033e-01 3.559e-01 5.822e-01
 6.462e-01 4.495e-02 2.543e-01 5.219e-02 9.141e-03 2.886e-02 7.754e-03
 4.946e-03 3.220e-03 3.021e-02 1.225e-01 2.857e-01 9.624e-01 5.480e-03
 5.336e-03 6.771e-01 1.201e-01 1.381e-01 7.417e-02 5.077e-01 8.370e-01
 2.364e-01 3.810e-01 3.402e-01 1.236e-01 3.857e-01 6.352e-01 8.704e-01
 5.659e-01 1.158e+00 2.103e-01 6.323e-01 5.920e-02 4.294e-02 1.067e-01
 7.378e-03 5.247e-03 2.408e-03 5.923e-02 2.435e-01 2.595e-01 3.756e-01
 5.690e-03 3.816e-02 3.826e-01 3.858e-01 8.931e-02 2.971e-01 3.417e-01
 5.433e-01 5.595e-01 5.912e-01 3.190e-02 6.811e-03 1.788e-01 3.717e-01
 3.058e-01 1.050e-01 3.210e-01 2.853e-02 2.288e-01 2.232e-02 2.651e-03
 1.718e-02 3.863e-03 5.237e-03 2.903e-03 1.173e-02 2.659e-03 5.671e-02
 5.499e-01 2.157e-03 1.333e-03 2.387e-01 1.518e-02 6.915e-02 8.240e-02
 4.702e-02 4.074e-01 4.992e-02 2.500e-01 2.294e-02 5.687e-03 2.824e-01
 3.265e-01 1.693e-01 2.595e-01 1.056e-01 1.024e-02 2.130e-01 9.627e-03
 1.584e-03 3.476e-03 2.494e-03 3.349e-03 1.044e-03 4.054e-03 4.507e-03
 2.525e-02 1.285e-01 3.109e-03 6.255e-04 8.834e-02 3.381e-02 1.256e-02
 4.579e-03 3.555e-02 2.660e-01 1.252e-01 1.241e-01 4.188e-03 1.954e-03
 5.310e-02 5.443e-02 7.347e-02 2.371e-02 2.018e-01 8.530e-03 3.173e-02
 1.816e-03 1.354e-03 7.623e-04 1.953e-03 2.039e-03 1.149e-03 9.498e-04
 1.821e-03 2.064e-03 1.133e-02 8.375e-04 1.092e-03 4.198e-02 3.602e-03
 3.948e-03 3.086e-03 9.811e-03 6.025e-02 5.515e-03 6.943e-02 2.916e-01
 1.422e-01 4.663e-01 4.535e-01 5.603e-01 8.888e-01 8.432e-01 1.976e-01
 9.066e-01 1.899e-01 1.077e-02 8.959e-02 3.942e-03 4.526e-03 5.100e-03
 1.987e-01 1.701e-01 3.398e-01 3.223e-01 8.990e-01 6.079e-03 4.706e-01
 2.224e-01 1.165e-01 2.154e-01 2.090e-01 5.413e-01 1.719e-01 7.398e-01
 2.289e-01 3.290e-01 5.117e-01 8.839e-01 6.588e-01 7.768e-01 1.090e+00
 3.454e-01 4.570e-01 3.695e-01 1.476e-01 1.084e-01 2.327e-01 1.184e-01
 3.513e-02 2.291e-01 5.877e-02 6.763e-01 8.013e-01 5.277e-01 1.882e-01
 9.900e-01 2.088e-01 3.943e-01 4.808e-01 3.397e-01 1.065e+00 7.167e-01
 1.021e+00 7.579e-03 4.117e-03 2.770e-02 1.631e-01 4.971e-02 5.163e-02
 1.418e-01 3.844e-03 7.154e-02 3.961e-03 9.701e-04 2.263e-03 1.393e-03
 8.686e-04 1.403e-03 1.801e-03 2.247e-03 2.767e-03 2.055e-02 5.929e-02
 1.917e-03 8.506e-04 5.521e-03 2.365e-03 7.549e-03 5.782e-03 4.674e-03
 1.148e-02 6.405e-02 1.473e-02 1.003e-02 3.911e-01 5.669e-01 6.830e-01
 1.976e-01 7.405e-01 7.316e-02 2.671e-01 6.790e-03 8.572e-03 7.003e-03
 5.302e-03 5.316e-03 8.336e-04 1.012e-02 3.790e-03 1.296e-01 9.684e-02
 3.127e-01 4.435e-03 5.583e-03 4.514e-01 1.506e-01 1.460e-01 3.070e-01
 3.863e-01 2.816e-01 3.573e-01 1.159e-01 1.248e-02 4.949e-01 2.132e-01
 2.219e-01 1.343e-01 4.292e-01 5.724e-02 3.539e-01 1.187e-02 2.914e-03
 2.514e-02 8.358e-03 3.155e-03 1.796e-03 1.131e-02 1.493e-02 2.656e-02
 1.098e-01 2.613e-01 1.246e-02 2.507e-03 4.234e-01 8.000e-03 6.888e-02
 1.150e-01 2.799e-01 1.563e-01 2.069e-01 1.218e-01 3.820e-03 4.358e-01
 3.806e-01 2.104e-01 2.238e-01 1.246e-01 6.673e-02 4.152e-01 1.045e-02
 3.360e-03 3.751e-03 2.008e-03 3.122e-03 1.927e-03 2.126e-02 2.130e-03
 3.375e-02 3.561e-01 3.812e-01 4.521e-03 1.822e-03 2.194e-01 2.134e-02
 3.489e-02 1.233e-01 2.843e-01 5.124e-01 2.173e-01 9.023e-03 8.021e-03
 4.724e-01 2.327e-01 1.447e-01 1.375e-01 3.074e-01 1.569e-02 2.041e-01
 1.781e-03 2.401e-03 6.943e-03 3.095e-03 1.491e-03 1.118e-03 3.180e-03
 2.925e-03 6.691e-02 7.075e-02 1.391e-01 3.873e-03 2.794e-03 2.086e-01
 4.464e-03 1.019e-02 9.490e-03 1.184e-01 8.335e-02 1.941e-01 4.422e-03
 2.004e-03 1.205e-02 7.087e-02 2.464e-02 1.317e-02 1.875e-01 3.058e-03
 1.608e-02 1.606e-03 3.041e-04 1.423e-03 5.764e-04 1.100e-03 4.785e-04
 6.635e-04 1.954e-03 3.621e-03 3.427e-03 1.946e-02 1.468e-03 3.605e-04
 1.297e-01 3.096e-03 3.908e-03 3.389e-03 1.068e-02 1.213e-02 6.719e-02
 6.005e-03 2.281e-03 1.011e-01 1.012e-01 1.916e-01 7.070e-02 2.303e-02
 6.896e-03 4.228e-02 9.588e-04 2.711e-03 6.315e-03 8.341e-04 1.875e-03
 1.309e-03 3.714e-03 1.446e-03 3.864e-02 1.422e-02 1.731e-01 5.666e-03
 1.023e-03 9.897e-02 3.521e-03 7.486e-03 2.755e-03 1.291e-02 1.018e-01
 2.893e-02 4.269e-03 3.357e-03 3.999e-02 1.478e-01 9.527e-03 8.987e-03
 1.845e-01 3.171e-03 9.810e-03 2.432e-03 1.759e-03 4.218e-03 9.707e-04
 1.120e-03 6.244e-04 2.757e-03 1.777e-03 9.922e-03 2.252e-02 3.841e-02
 1.076e-03 6.447e-04 4.408e-02 3.523e-03 5.780e-03 5.294e-03 9.030e-03
 3.204e-02 8.075e-02]
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 1. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]]
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.7512345679012346, 0.22140042168293547)
Iterations 2500
Achieves (13.610683049707138, 1e-05)-DP
