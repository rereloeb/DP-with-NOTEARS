samples  5000  graph  20 60 ER mim  minibatch size  50  noise  1.0  minibatches per NN training  250 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.894755422218715
iteration 1 in outer loop, alpha = 1.894755422218715, rho = 1.0, h = 1.894755422218715
cuda
iteration 1 in inner loop,alpha 1.894755422218715 rho 1.0 h 1.1837267518041905
iteration 2 in inner loop,alpha 1.894755422218715 rho 10.0 h 0.4591942400387481
iteration 2 in outer loop, alpha = 6.486697822606196, rho = 10.0, h = 0.4591942400387481
cuda
iteration 1 in inner loop,alpha 6.486697822606196 rho 10.0 h 0.25438138894107
iteration 2 in inner loop,alpha 6.486697822606196 rho 100.0 h 0.09198602423245106
iteration 3 in outer loop, alpha = 15.685300245851302, rho = 100.0, h = 0.09198602423245106
cuda
iteration 1 in inner loop,alpha 15.685300245851302 rho 100.0 h 0.05359112023960222
iteration 2 in inner loop,alpha 15.685300245851302 rho 1000.0 h 0.01996759308255136
iteration 4 in outer loop, alpha = 35.65289332840266, rho = 1000.0, h = 0.01996759308255136
cuda
iteration 1 in inner loop,alpha 35.65289332840266 rho 1000.0 h 0.01076752019967131
iteration 2 in inner loop,alpha 35.65289332840266 rho 10000.0 h 0.003504612785590666
iteration 5 in outer loop, alpha = 70.69902118430932, rho = 10000.0, h = 0.003504612785590666
cuda
iteration 1 in inner loop,alpha 70.69902118430932 rho 10000.0 h 0.0014524928098538226
iteration 2 in inner loop,alpha 70.69902118430932 rho 100000.0 h 0.0005777446095223127
iteration 6 in outer loop, alpha = 128.47348213654058, rho = 100000.0, h = 0.0005777446095223127
cuda
iteration 1 in inner loop,alpha 128.47348213654058 rho 100000.0 h 0.00035764464758258896
iteration 7 in outer loop, alpha = 486.11812971912957, rho = 1000000.0, h = 0.00035764464758258896
Threshold 0.3
[[0.    0.032 0.014 0.022 0.153 0.181 0.068 0.    0.027 0.045 0.461 0.734
  1.07  0.    0.086 0.002 0.102 2.588 0.504 0.014]
 [0.    0.001 0.    0.108 0.083 0.462 0.13  0.    0.005 0.061 0.112 0.
  0.    0.    0.073 0.143 0.025 0.    0.081 0.798]
 [0.    0.407 0.002 0.076 0.541 0.095 0.073 0.001 1.453 0.793 0.109 0.005
  0.005 0.    0.03  0.215 0.095 0.027 0.137 0.112]
 [0.    0.002 0.    0.002 0.03  0.014 0.011 0.    0.001 0.016 0.122 0.
  0.    0.    0.068 0.002 0.496 0.    0.004 0.028]
 [0.    0.003 0.    0.021 0.002 0.009 0.004 0.    0.    0.053 0.152 0.
  0.    0.    0.039 0.12  0.004 0.    0.001 0.008]
 [0.    0.002 0.004 0.012 0.03  0.005 0.01  0.    0.021 0.02  0.053 0.
  0.003 0.    1.193 0.068 0.007 0.    0.281 0.045]
 [0.    0.005 0.003 0.003 0.291 0.24  0.003 0.    0.004 0.16  0.411 0.001
  0.004 0.    0.089 0.063 0.001 0.    0.006 0.133]
 [0.001 0.06  0.002 0.664 0.053 0.056 0.174 0.    0.362 0.073 0.05  2.228
  1.356 0.016 0.108 0.018 0.002 2.25  0.047 0.032]
 [0.    0.032 0.    1.09  1.38  0.019 0.112 0.    0.003 0.373 1.175 0.
  0.001 0.    0.417 0.138 0.066 0.    0.006 0.016]
 [0.    0.003 0.001 0.001 0.005 0.207 0.013 0.    0.005 0.004 1.108 0.001
  0.002 0.    0.101 0.007 0.008 0.    0.007 0.662]
 [0.    0.002 0.    0.004 0.    0.012 0.003 0.    0.    0.001 0.002 0.
  0.    0.    0.012 0.004 0.003 0.    0.003 0.748]
 [0.    2.175 0.001 1.361 1.293 0.062 0.569 0.    1.033 0.068 0.97  0.001
  0.001 0.001 0.002 0.901 0.267 0.    0.067 0.129]
 [0.    0.032 0.003 0.117 0.075 0.111 0.342 0.    0.001 0.594 0.043 0.573
  0.003 0.    1.597 0.159 0.2   0.    0.004 0.037]
 [0.001 1.075 4.144 0.051 0.039 0.159 0.066 0.001 0.826 0.185 0.035 0.03
  0.049 0.    0.054 0.674 0.002 0.083 0.689 1.195]
 [0.    0.001 0.    0.001 0.019 0.001 0.002 0.    0.002 0.004 0.01  0.
  0.    0.    0.002 0.011 0.001 0.    0.001 0.002]
 [0.    0.001 0.002 0.027 0.005 0.015 0.008 0.    0.004 0.289 0.047 0.
  0.    0.    0.038 0.003 0.006 0.    0.001 0.09 ]
 [0.    0.004 0.001 0.002 0.077 0.002 0.919 0.    0.    0.004 0.104 0.001
  0.003 0.    0.555 0.007 0.002 0.    0.002 0.052]
 [0.    0.021 0.007 0.096 0.046 0.048 0.067 0.    0.111 0.047 0.116 0.993
  1.998 0.001 0.001 0.073 0.021 0.002 0.027 1.25 ]
 [0.    0.001 0.009 0.059 0.777 0.017 0.029 0.    0.418 0.197 0.161 0.001
  0.006 0.    0.695 1.038 0.001 0.006 0.004 0.066]
 [0.    0.    0.    0.006 0.001 0.017 0.001 0.    0.001 0.001 0.001 0.
  0.    0.    0.053 0.001 0.001 0.    0.002 0.002]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.461 0.734
  1.07  0.    0.    0.    0.    2.588 0.504 0.   ]
 [0.    0.    0.    0.    0.    0.462 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.798]
 [0.    0.407 0.    0.    0.541 0.    0.    0.    1.453 0.793 0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.496 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    1.193 0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.411 0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.664 0.    0.    0.    0.    0.362 0.    0.    2.228
  1.356 0.    0.    0.    0.    2.25  0.    0.   ]
 [0.    0.    0.    1.09  1.38  0.    0.    0.    0.    0.373 1.175 0.
  0.    0.    0.417 0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.108 0.
  0.    0.    0.    0.    0.    0.    0.    0.662]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.748]
 [0.    2.175 0.    1.361 1.293 0.    0.569 0.    1.033 0.    0.97  0.
  0.    0.    0.    0.901 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.342 0.    0.    0.594 0.    0.573
  0.    0.    1.597 0.    0.    0.    0.    0.   ]
 [0.    1.075 4.144 0.    0.    0.    0.    0.    0.826 0.    0.    0.
  0.    0.    0.    0.674 0.    0.    0.689 1.195]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.919 0.    0.    0.    0.    0.
  0.    0.    0.555 0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.993
  1.998 0.    0.    0.    0.    0.    0.    1.25 ]
 [0.    0.    0.    0.    0.777 0.    0.    0.    0.418 0.    0.    0.
  0.    0.    0.695 1.038 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]]
{'fdr': 0.1320754716981132, 'tpr': 0.7666666666666667, 'fpr': 0.05384615384615385, 'f1': 0.8141592920353983, 'shd': 16, 'npred': 53, 'ntrue': 60}
[3.196e-02 1.351e-02 2.213e-02 1.530e-01 1.811e-01 6.797e-02 1.673e-04
 2.711e-02 4.481e-02 4.605e-01 7.344e-01 1.070e+00 2.098e-04 8.557e-02
 1.880e-03 1.019e-01 2.588e+00 5.043e-01 1.396e-02 2.020e-06 9.849e-05
 1.084e-01 8.310e-02 4.620e-01 1.299e-01 2.573e-06 5.372e-03 6.053e-02
 1.120e-01 8.573e-05 1.196e-04 1.985e-05 7.348e-02 1.431e-01 2.502e-02
 3.011e-05 8.087e-02 7.977e-01 2.732e-04 4.069e-01 7.618e-02 5.414e-01
 9.474e-02 7.323e-02 1.397e-03 1.453e+00 7.931e-01 1.086e-01 4.632e-03
 4.619e-03 1.352e-05 2.991e-02 2.149e-01 9.498e-02 2.663e-02 1.375e-01
 1.121e-01 1.998e-05 2.128e-03 5.939e-05 3.036e-02 1.422e-02 1.107e-02
 1.219e-06 6.951e-04 1.607e-02 1.218e-01 1.653e-04 3.795e-04 4.790e-06
 6.790e-02 2.292e-03 4.958e-01 3.879e-05 3.742e-03 2.784e-02 4.990e-06
 3.499e-03 1.535e-04 2.102e-02 9.137e-03 4.326e-03 2.113e-06 4.413e-04
 5.349e-02 1.522e-01 1.534e-04 2.534e-04 2.267e-06 3.899e-02 1.198e-01
 3.827e-03 7.495e-05 6.720e-04 8.319e-03 1.759e-05 1.731e-03 3.626e-03
 1.249e-02 3.044e-02 1.009e-02 4.396e-05 2.111e-02 2.046e-02 5.258e-02
 3.362e-04 2.891e-03 6.199e-05 1.193e+00 6.782e-02 7.451e-03 3.462e-04
 2.813e-01 4.539e-02 1.992e-05 4.807e-03 2.922e-03 2.541e-03 2.912e-01
 2.404e-01 1.198e-05 3.597e-03 1.604e-01 4.106e-01 9.770e-04 3.793e-03
 7.940e-05 8.912e-02 6.338e-02 1.244e-03 8.196e-05 6.216e-03 1.332e-01
 5.168e-04 6.030e-02 2.446e-03 6.642e-01 5.291e-02 5.585e-02 1.739e-01
 3.624e-01 7.261e-02 4.982e-02 2.228e+00 1.356e+00 1.629e-02 1.079e-01
 1.833e-02 2.143e-03 2.250e+00 4.686e-02 3.166e-02 1.543e-05 3.205e-02
 2.460e-04 1.090e+00 1.380e+00 1.896e-02 1.117e-01 1.333e-05 3.730e-01
 1.175e+00 2.695e-04 5.975e-04 1.252e-05 4.174e-01 1.380e-01 6.579e-02
 1.227e-04 5.831e-03 1.559e-02 1.364e-05 2.638e-03 6.227e-04 1.416e-03
 4.859e-03 2.071e-01 1.308e-02 3.151e-05 4.707e-03 1.108e+00 9.406e-04
 1.663e-03 7.562e-06 1.013e-01 7.488e-03 8.182e-03 1.410e-04 7.119e-03
 6.620e-01 1.846e-05 2.268e-03 1.845e-04 3.802e-03 4.427e-04 1.216e-02
 3.301e-03 3.272e-06 4.719e-04 7.776e-04 1.523e-04 1.024e-04 4.400e-06
 1.193e-02 4.270e-03 3.015e-03 9.790e-05 2.810e-03 7.476e-01 2.830e-06
 2.175e+00 1.416e-03 1.361e+00 1.293e+00 6.181e-02 5.688e-01 5.472e-06
 1.033e+00 6.771e-02 9.703e-01 1.160e-03 5.616e-04 1.717e-03 9.007e-01
 2.672e-01 1.427e-04 6.692e-02 1.291e-01 5.359e-06 3.179e-02 3.219e-03
 1.174e-01 7.508e-02 1.106e-01 3.416e-01 3.823e-06 1.121e-03 5.935e-01
 4.292e-02 5.733e-01 4.318e-05 1.597e+00 1.589e-01 2.001e-01 8.041e-05
 3.998e-03 3.724e-02 8.174e-04 1.075e+00 4.144e+00 5.129e-02 3.912e-02
 1.592e-01 6.579e-02 1.424e-03 8.258e-01 1.854e-01 3.540e-02 3.037e-02
 4.868e-02 5.377e-02 6.737e-01 1.705e-03 8.261e-02 6.891e-01 1.195e+00
 2.607e-06 7.961e-04 2.550e-04 5.729e-04 1.852e-02 8.101e-04 1.544e-03
 1.968e-06 1.558e-03 3.930e-03 9.803e-03 2.448e-04 4.157e-04 3.393e-05
 1.105e-02 8.824e-04 3.502e-05 1.249e-03 2.150e-03 1.214e-05 6.871e-04
 1.819e-03 2.655e-02 4.559e-03 1.513e-02 7.764e-03 9.337e-06 3.991e-03
 2.891e-01 4.699e-02 4.603e-04 4.226e-04 3.012e-05 3.824e-02 5.765e-03
 7.035e-05 1.480e-03 8.988e-02 2.647e-05 4.450e-03 7.196e-04 2.236e-03
 7.666e-02 1.992e-03 9.191e-01 4.004e-05 3.818e-04 4.198e-03 1.040e-01
 6.247e-04 3.041e-03 1.567e-05 5.549e-01 7.296e-03 3.421e-05 2.335e-03
 5.248e-02 2.688e-06 2.094e-02 7.399e-03 9.565e-02 4.626e-02 4.769e-02
 6.700e-02 1.224e-05 1.106e-01 4.699e-02 1.157e-01 9.927e-01 1.998e+00
 9.796e-04 8.386e-04 7.340e-02 2.074e-02 2.684e-02 1.250e+00 8.648e-05
 1.290e-03 8.653e-03 5.931e-02 7.767e-01 1.704e-02 2.863e-02 1.684e-04
 4.178e-01 1.966e-01 1.614e-01 5.292e-04 6.060e-03 1.266e-04 6.954e-01
 1.038e+00 5.632e-04 6.216e-03 6.620e-02 2.589e-06 3.168e-04 7.321e-05
 6.025e-03 1.226e-03 1.746e-02 1.185e-03 2.205e-06 6.447e-04 5.642e-04
 7.022e-04 2.103e-05 4.708e-04 1.200e-05 5.349e-02 6.860e-04 1.213e-03
 3.113e-04 1.867e-03]
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0.]
 [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.
 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1.
 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.9068229166666667, 0.8280908540583602)
cuda
4420
cuda
Objective function 242.67 = squared loss an data 26.66 + 0.5*rho*h**2 215.201283 + alpha*h 0.000000 + L2reg 0.37 + L1reg 0.45 ; SHD = 207 ; DAG False
v before min max tensor([[-5.570e-02,  2.727e-03, -1.173e-02,  ..., -1.582e-03,  2.723e-02,
         -1.269e-03],
        [-6.590e-02, -7.287e-03, -1.150e-01,  ..., -8.444e-03, -3.015e-03,
         -4.687e-03],
        [-2.495e-02,  3.373e-03, -3.862e-02,  ..., -4.993e-03,  1.491e-04,
         -1.838e-03],
        ...,
        [ 5.597e-01, -1.557e-01, -7.731e-03,  ...,  9.486e-05,  9.259e-04,
         -2.939e-02],
        [-1.159e-02, -2.328e-02, -1.022e-03,  ..., -3.627e-03, -1.015e-03,
          2.730e-03],
        [ 6.576e-02, -2.707e-04, -1.181e-02,  ..., -9.349e-04,  1.709e-02,
         -5.934e-02]], device='cuda:0')
v tensor([[1.000e-12, 2.727e-03, 1.000e-12,  ..., 1.000e-12, 2.723e-02,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 3.373e-03, 1.000e-12,  ..., 1.000e-12, 1.491e-04,
         1.000e-12],
        ...,
        [5.597e-01, 1.000e-12, 1.000e-12,  ..., 9.486e-05, 9.259e-04,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         2.730e-03],
        [6.576e-02, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.709e-02,
         1.000e-12]], device='cuda:0')
v before min max tensor([-6.826e-04,  3.206e-02, -1.072e-04, -7.450e-04, -2.841e-04, -2.852e-01,
        -2.424e-03, -1.851e-03, -9.576e-03, -6.407e-03, -3.576e-04, -8.784e-04,
         7.922e-05, -3.901e-02, -1.340e-04, -3.589e-02,  5.476e-05, -2.421e-03,
         2.632e-03, -5.712e-05, -1.045e-03, -3.176e-02, -8.747e-04, -7.808e-06,
         5.146e-01, -6.848e-04, -2.610e-02, -5.683e-05,  3.923e-03, -7.779e-04,
        -2.739e-02, -6.110e-02, -8.501e-02, -1.010e-05,  9.601e-04, -2.030e-02,
        -6.287e-04, -9.209e-02, -7.770e-03, -1.595e-03, -5.816e-04, -4.045e-02,
        -9.403e-04, -3.218e-02, -7.002e-04,  2.621e-04,  3.917e-04, -1.883e-04,
        -1.010e-05,  4.481e-02, -9.385e-02,  3.098e-03, -1.584e-04, -1.425e-04,
        -3.354e-02,  5.933e-03, -4.460e-03, -1.972e-03, -6.388e-03, -3.490e-02,
        -2.556e-05, -5.149e-03,  6.751e-03, -2.274e-03, -1.938e-02, -3.547e-05,
         1.103e-03, -1.962e-01, -9.093e-02,  5.269e-05, -7.606e-03, -1.912e-02,
        -9.855e-06, -3.633e-04,  3.429e-03, -6.128e-04,  1.739e-03, -4.687e-04,
        -7.566e-03, -5.840e-05,  8.610e-04,  2.852e-02, -1.008e-05, -5.931e-03,
        -3.586e-01, -3.375e-03, -6.782e-04, -1.056e-03, -6.005e-06, -6.768e-03,
         1.770e-02,  2.101e-02, -6.349e-04,  9.370e-02, -7.625e-05, -8.210e-04,
        -9.327e-04, -5.081e-04, -8.165e-02,  1.030e-03,  2.635e-04,  1.495e-04,
        -1.752e-02, -4.685e-03, -3.025e-02, -3.347e-03,  3.545e-01, -5.289e-04,
        -4.285e-04, -1.578e-02, -2.119e-05,  1.514e-04,  1.510e-03, -5.017e-02,
        -1.050e-02, -2.535e-03, -7.964e-04,  1.352e-04, -4.351e-02,  2.758e-03,
        -6.942e-05,  1.444e-04, -2.660e-03,  3.851e-03, -1.259e-03, -7.796e-04,
         1.560e-03,  2.324e-02, -7.970e-03, -7.908e-02,  1.011e-01,  1.572e-01,
         1.711e-03, -3.313e-03,  5.825e-04, -1.276e-02, -1.237e-04,  1.566e-05,
         7.763e-04, -1.002e-03, -2.412e-05,  2.278e-06, -4.559e-06, -3.316e-04,
        -4.328e-06,  4.830e-04, -8.983e-06,  4.774e-01, -1.399e-01, -1.731e-03,
        -6.574e-03, -1.156e-02,  1.324e-03, -3.892e-01, -8.448e-02,  3.701e-03,
        -5.254e-02,  7.818e-04, -3.252e-03, -4.674e-05, -4.456e-02, -2.453e-04,
        -2.493e-02, -1.199e-05, -4.939e-02,  4.443e-03,  6.684e-02, -3.038e-04,
         5.328e-02,  5.895e-06, -2.693e-03, -3.315e-01, -2.472e-04, -2.137e-03,
        -6.963e-05,  5.771e-03, -3.103e-03, -2.727e-03, -1.577e-04, -1.648e-07,
        -1.604e-03, -1.164e-04, -2.236e-03, -1.010e-05, -7.566e-03,  2.361e-01,
        -5.725e-03,  1.070e-01,  1.491e-03, -7.161e-04, -2.535e-02, -4.022e-05,
        -1.730e-02, -2.614e-03, -5.064e-03, -8.647e-04,  1.173e-02, -1.658e-05,
         7.087e-03, -1.128e-02], device='cuda:0')
v tensor([1.000e-12, 3.206e-02, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        7.922e-05, 1.000e-12, 1.000e-12, 1.000e-12, 5.476e-05, 1.000e-12,
        2.632e-03, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        5.146e-01, 1.000e-12, 1.000e-12, 1.000e-12, 3.923e-03, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 9.601e-04, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 2.621e-04, 3.917e-04, 1.000e-12,
        1.000e-12, 4.481e-02, 1.000e-12, 3.098e-03, 1.000e-12, 1.000e-12,
        1.000e-12, 5.933e-03, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 6.751e-03, 1.000e-12, 1.000e-12, 1.000e-12,
        1.103e-03, 1.000e-12, 1.000e-12, 5.269e-05, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 3.429e-03, 1.000e-12, 1.739e-03, 1.000e-12,
        1.000e-12, 1.000e-12, 8.610e-04, 2.852e-02, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.770e-02, 2.101e-02, 1.000e-12, 9.370e-02, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.030e-03, 2.635e-04, 1.495e-04,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.545e-01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.514e-04, 1.510e-03, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.352e-04, 1.000e-12, 2.758e-03,
        1.000e-12, 1.444e-04, 1.000e-12, 3.851e-03, 1.000e-12, 1.000e-12,
        1.560e-03, 2.324e-02, 1.000e-12, 1.000e-12, 1.011e-01, 1.572e-01,
        1.711e-03, 1.000e-12, 5.825e-04, 1.000e-12, 1.000e-12, 1.566e-05,
        7.763e-04, 1.000e-12, 1.000e-12, 2.278e-06, 1.000e-12, 1.000e-12,
        1.000e-12, 4.830e-04, 1.000e-12, 4.774e-01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.324e-03, 1.000e-12, 1.000e-12, 3.701e-03,
        1.000e-12, 7.818e-04, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 4.443e-03, 6.684e-02, 1.000e-12,
        5.328e-02, 5.895e-06, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 5.771e-03, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.361e-01,
        1.000e-12, 1.070e-01, 1.491e-03, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.173e-02, 1.000e-12,
        7.087e-03, 1.000e-12], device='cuda:0')
v before min max tensor([[[ 2.604e-02],
         [-8.077e-02],
         [ 8.382e-04],
         [-4.127e-02],
         [-2.802e-01],
         [-2.412e-02],
         [-2.176e-02],
         [-9.851e-04],
         [ 6.850e-03],
         [ 1.164e-03]],

        [[-1.074e-03],
         [-1.271e-02],
         [ 1.455e-02],
         [-1.584e-03],
         [-1.295e-02],
         [ 1.173e-01],
         [-1.513e-02],
         [ 2.166e-02],
         [ 5.351e-03],
         [ 1.772e-01]],

        [[-5.992e-02],
         [ 8.511e-02],
         [-4.650e-03],
         [-1.302e-01],
         [ 1.012e-02],
         [-3.060e-02],
         [-2.713e-02],
         [-3.891e-03],
         [ 2.198e-02],
         [ 5.424e-03]],

        [[-2.882e-02],
         [-2.724e-03],
         [-1.764e-04],
         [-8.518e-03],
         [-1.378e-04],
         [-1.037e-02],
         [ 1.456e-04],
         [ 1.291e-02],
         [ 1.098e-02],
         [-4.050e-02]],

        [[-1.591e-02],
         [ 1.841e-03],
         [-6.270e-04],
         [-1.383e-02],
         [ 1.202e-01],
         [-7.128e-03],
         [ 3.235e-01],
         [ 3.059e-02],
         [-1.523e-03],
         [-6.908e-02]],

        [[ 1.245e-01],
         [-8.864e-04],
         [-1.768e-02],
         [-1.710e-02],
         [-8.631e-03],
         [-6.696e-02],
         [-1.926e-03],
         [-5.907e-03],
         [-3.564e-03],
         [-4.342e-03]],

        [[ 1.715e-02],
         [-3.178e-04],
         [-5.493e-03],
         [-2.613e-03],
         [-6.827e-02],
         [-2.554e-02],
         [-3.937e-01],
         [-1.248e-02],
         [ 1.391e-03],
         [-1.475e-01]],

        [[-6.127e-04],
         [ 4.203e-02],
         [-2.583e-02],
         [-1.588e-01],
         [-3.938e-02],
         [-7.812e-03],
         [ 7.366e-02],
         [ 1.946e-02],
         [-7.127e-03],
         [ 5.254e-04]],

        [[ 2.004e-03],
         [ 3.074e-03],
         [-2.089e-02],
         [ 6.004e-04],
         [-1.307e-02],
         [-1.946e-02],
         [ 1.015e-02],
         [ 1.322e-02],
         [-2.242e-02],
         [ 4.261e-03]],

        [[-4.984e-03],
         [-6.151e-03],
         [-5.209e-02],
         [-2.559e-02],
         [-1.112e-02],
         [ 6.098e-02],
         [-5.538e-03],
         [ 7.554e-04],
         [ 4.925e-03],
         [-1.334e-01]],

        [[-2.053e-04],
         [-1.622e-04],
         [-1.531e-02],
         [-7.190e-03],
         [-1.500e-04],
         [-2.628e-04],
         [-9.446e-03],
         [-1.102e-03],
         [ 8.459e-03],
         [ 3.444e-02]],

        [[ 1.501e-02],
         [ 1.480e-03],
         [-2.083e-02],
         [-8.524e-04],
         [-1.124e-02],
         [-4.833e-05],
         [-4.294e-03],
         [-1.394e-03],
         [-1.071e-03],
         [-2.796e-04]],

        [[-1.629e-01],
         [-1.967e-02],
         [ 9.763e-01],
         [-1.068e-01],
         [-9.936e-02],
         [ 1.341e-02],
         [ 8.178e-03],
         [-6.819e-02],
         [-7.394e-02],
         [ 3.274e-03]],

        [[-4.995e-03],
         [-2.722e-03],
         [-1.318e-01],
         [-1.416e-02],
         [ 1.040e-03],
         [-4.075e-03],
         [ 6.285e-04],
         [ 1.715e-02],
         [-7.490e-05],
         [-7.277e-04]],

        [[-3.124e-02],
         [-2.307e-02],
         [-4.298e-03],
         [-1.008e-02],
         [ 2.997e-03],
         [ 1.746e-02],
         [-1.257e-02],
         [ 5.427e-04],
         [-7.733e-04],
         [-6.075e-03]],

        [[-1.164e-02],
         [-1.325e-01],
         [-2.540e-03],
         [ 1.504e-03],
         [-2.227e-02],
         [ 2.017e-01],
         [-2.447e-03],
         [-1.313e-03],
         [ 9.829e-03],
         [-1.162e-03]],

        [[-7.850e-04],
         [-2.328e-03],
         [-3.103e-02],
         [ 3.642e-03],
         [-1.205e-02],
         [-7.931e-04],
         [-3.927e-03],
         [-7.415e-02],
         [-1.850e-04],
         [-5.106e-02]],

        [[-3.256e-02],
         [-3.403e-02],
         [-9.351e-02],
         [-1.926e-02],
         [-1.391e-01],
         [-1.224e-01],
         [-2.403e-02],
         [-1.255e-02],
         [ 9.847e-02],
         [ 1.490e-02]],

        [[-5.515e-02],
         [ 3.884e-02],
         [-1.830e-04],
         [ 1.403e-02],
         [ 5.650e-04],
         [-2.150e-02],
         [-1.595e-02],
         [-1.468e-02],
         [-3.378e-03],
         [ 1.380e-02]],

        [[ 5.942e-03],
         [-2.630e-02],
         [-1.993e-02],
         [-9.443e-04],
         [-3.412e-03],
         [ 1.884e-04],
         [ 3.621e-04],
         [-4.869e-04],
         [-7.823e-03],
         [-2.370e-04]]], device='cuda:0')
v tensor([[[2.604e-02],
         [1.000e-12],
         [8.382e-04],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.850e-03],
         [1.164e-03]],

        [[1.000e-12],
         [1.000e-12],
         [1.455e-02],
         [1.000e-12],
         [1.000e-12],
         [1.173e-01],
         [1.000e-12],
         [2.166e-02],
         [5.351e-03],
         [1.772e-01]],

        [[1.000e-12],
         [8.511e-02],
         [1.000e-12],
         [1.000e-12],
         [1.012e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.198e-02],
         [5.424e-03]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.456e-04],
         [1.291e-02],
         [1.098e-02],
         [1.000e-12]],

        [[1.000e-12],
         [1.841e-03],
         [1.000e-12],
         [1.000e-12],
         [1.202e-01],
         [1.000e-12],
         [3.235e-01],
         [3.059e-02],
         [1.000e-12],
         [1.000e-12]],

        [[1.245e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.715e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.391e-03],
         [1.000e-12]],

        [[1.000e-12],
         [4.203e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.366e-02],
         [1.946e-02],
         [1.000e-12],
         [5.254e-04]],

        [[2.004e-03],
         [3.074e-03],
         [1.000e-12],
         [6.004e-04],
         [1.000e-12],
         [1.000e-12],
         [1.015e-02],
         [1.322e-02],
         [1.000e-12],
         [4.261e-03]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.098e-02],
         [1.000e-12],
         [7.554e-04],
         [4.925e-03],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [8.459e-03],
         [3.444e-02]],

        [[1.501e-02],
         [1.480e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [9.763e-01],
         [1.000e-12],
         [1.000e-12],
         [1.341e-02],
         [8.178e-03],
         [1.000e-12],
         [1.000e-12],
         [3.274e-03]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.040e-03],
         [1.000e-12],
         [6.285e-04],
         [1.715e-02],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.997e-03],
         [1.746e-02],
         [1.000e-12],
         [5.427e-04],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.504e-03],
         [1.000e-12],
         [2.017e-01],
         [1.000e-12],
         [1.000e-12],
         [9.829e-03],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.642e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [9.847e-02],
         [1.490e-02]],

        [[1.000e-12],
         [3.884e-02],
         [1.000e-12],
         [1.403e-02],
         [5.650e-04],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.380e-02]],

        [[5.942e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.884e-04],
         [3.621e-04],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[ 0.011],
        [-0.062],
        [-0.009],
        [ 0.033],
        [-0.006],
        [ 0.014],
        [ 0.102],
        [-0.020],
        [ 0.000],
        [-0.006],
        [ 0.005],
        [-0.002],
        [-0.002],
        [-0.013],
        [-0.006],
        [-0.002],
        [-0.010],
        [-0.015],
        [-0.049],
        [ 0.012]], device='cuda:0')
v tensor([[1.104e-02],
        [1.000e-12],
        [1.000e-12],
        [3.317e-02],
        [1.000e-12],
        [1.383e-02],
        [1.023e-01],
        [1.000e-12],
        [2.529e-04],
        [1.000e-12],
        [5.390e-03],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.177e-02]], device='cuda:0')
a after update for 1 param tensor([[-2.048e-05, -1.096e-04, -6.230e-05,  ...,  1.440e-04,  1.352e-04,
         -1.436e-04],
        [-1.016e-04, -1.032e-04,  1.767e-04,  ..., -1.109e-04, -1.180e-05,
         -6.187e-05],
        [ 1.864e-04, -4.338e-05, -7.581e-05,  ...,  2.301e-05, -3.460e-04,
          1.105e-05],
        ...,
        [ 1.911e-03,  4.982e-06, -2.575e-04,  ..., -1.943e-05,  5.823e-05,
          3.302e-04],
        [-4.901e-05,  3.899e-05, -3.973e-05,  ..., -3.874e-04,  1.382e-04,
         -2.433e-04],
        [ 2.648e-04,  3.604e-05, -1.268e-05,  ..., -4.074e-05,  3.564e-04,
         -9.194e-04]], device='cuda:0')
s after update for 1 param tensor([[1.196e-02, 1.654e-02, 2.323e-03,  ..., 5.610e-04, 5.221e-02,
         1.613e-03],
        [1.210e-02, 1.654e-03, 3.446e-02,  ..., 2.342e-03, 1.256e-03,
         8.609e-04],
        [5.360e-03, 1.838e-02, 8.402e-03,  ..., 9.236e-04, 1.167e-02,
         3.710e-04],
        ...,
        [2.551e-01, 3.301e-02, 3.744e-03,  ..., 3.080e-03, 9.622e-03,
         7.164e-03],
        [3.704e-03, 4.342e-03, 2.765e-04,  ..., 8.375e-03, 1.091e-03,
         1.984e-02],
        [8.163e-02, 1.694e-04, 2.979e-03,  ..., 1.939e-04, 4.191e-02,
         5.033e-02]], device='cuda:0')
b after update for 1 param tensor([[0.968, 1.138, 0.426,  ..., 0.210, 2.022, 0.355],
        [0.974, 0.360, 1.643,  ..., 0.428, 0.314, 0.260],
        [0.648, 1.200, 0.811,  ..., 0.269, 0.956, 0.170],
        ...,
        [4.470, 1.608, 0.541,  ..., 0.491, 0.868, 0.749],
        [0.539, 0.583, 0.147,  ..., 0.810, 0.292, 1.246],
        [2.528, 0.115, 0.483,  ..., 0.123, 1.811, 1.985]], device='cuda:0')
clipping threshold 2.782537623814828
a after update for 1 param tensor([ 3.759e-05,  5.844e-04, -1.679e-05,  2.040e-05,  1.238e-05, -5.907e-05,
         9.483e-05,  8.456e-05, -4.687e-05,  3.256e-05, -7.841e-06, -1.960e-05,
         2.543e-05, -1.131e-04, -4.177e-05, -9.732e-05,  1.338e-05, -6.872e-05,
         8.835e-05, -9.166e-06, -3.858e-05, -7.576e-05, -7.580e-05, -2.873e-06,
        -1.607e-03, -5.263e-05,  6.605e-05, -1.971e-05, -1.765e-04, -3.457e-05,
         1.343e-04, -2.625e-04,  5.093e-04,  1.389e-06,  9.627e-05,  8.070e-06,
         2.048e-05,  8.638e-05,  1.355e-06,  5.247e-05, -7.131e-05,  3.936e-05,
        -2.232e-05, -1.888e-04, -4.031e-05,  3.697e-05, -2.198e-05,  7.325e-07,
         1.225e-06,  3.994e-04, -7.629e-04,  2.681e-04,  4.507e-06, -1.506e-05,
         1.095e-05,  1.402e-04, -8.624e-05,  6.894e-05, -5.197e-05, -2.478e-04,
        -2.490e-05,  1.708e-05, -8.805e-04, -4.377e-05, -2.343e-04,  1.376e-06,
         7.467e-05,  1.022e-04, -4.487e-04,  4.261e-05, -1.302e-05,  2.124e-04,
         8.810e-07, -9.278e-06,  8.706e-05,  1.182e-05,  1.243e-04, -1.633e-05,
        -6.897e-06,  7.436e-06,  4.321e-05,  5.288e-04,  2.196e-06,  6.630e-06,
        -6.494e-04,  9.805e-05,  1.304e-05,  3.797e-05, -2.410e-06,  8.046e-05,
        -2.125e-04, -2.699e-04, -4.156e-05, -5.008e-04,  1.540e-05, -2.498e-05,
         9.463e-06,  2.724e-05, -2.645e-04, -4.587e-05, -6.008e-05, -3.593e-05,
        -8.791e-05,  2.161e-05,  1.637e-04,  6.893e-05,  1.228e-03,  2.989e-05,
         6.567e-06,  3.504e-04, -1.789e-08, -1.800e-05, -1.310e-04,  1.085e-04,
        -3.942e-05,  5.138e-05,  3.870e-05, -7.000e-05, -1.494e-04, -8.729e-05,
        -3.879e-07,  1.763e-05, -4.339e-05,  1.153e-04,  1.282e-05, -2.743e-05,
         1.194e-04, -1.682e-04,  2.029e-04, -2.408e-05, -5.814e-04,  6.699e-04,
        -8.856e-05, -7.958e-05,  5.278e-05, -2.012e-05,  1.285e-05,  9.746e-06,
        -1.055e-04, -1.530e-04, -2.212e-06,  1.277e-05, -3.470e-08, -1.531e-05,
         5.806e-06, -5.452e-05, -1.207e-05, -1.514e-03,  1.534e-05, -5.938e-05,
        -5.414e-05, -4.054e-05,  1.751e-04,  7.925e-04, -4.781e-04, -1.096e-04,
        -7.340e-04,  1.644e-05, -1.504e-05,  3.187e-05,  5.531e-05, -1.803e-05,
         2.686e-04,  2.721e-05, -6.431e-05,  1.026e-04,  4.624e-04,  2.044e-05,
        -4.004e-04,  3.516e-06,  7.439e-05, -3.685e-04, -3.807e-06,  1.920e-05,
         6.463e-06,  9.916e-05, -6.388e-05,  6.603e-06,  2.561e-06, -4.020e-06,
         3.361e-05,  1.178e-04,  5.165e-05,  1.260e-06, -1.604e-05,  7.711e-04,
         1.659e-05,  4.563e-04, -5.716e-05, -9.654e-06, -1.880e-04,  2.626e-06,
         3.693e-05,  6.155e-05,  3.697e-04,  1.345e-05, -1.683e-04, -5.065e-05,
        -1.226e-04,  2.176e-05], device='cuda:0')
s after update for 1 param tensor([1.337e-04, 5.758e-02, 6.433e-05, 1.460e-04, 5.363e-05, 6.352e-02,
        5.431e-04, 9.579e-04, 2.237e-03, 1.181e-03, 6.697e-05, 3.413e-04,
        2.815e-03, 7.745e-03, 5.782e-05, 6.873e-03, 2.340e-03, 5.538e-04,
        1.629e-02, 3.910e-05, 5.627e-04, 9.671e-03, 8.911e-04, 3.947e-06,
        2.308e-01, 5.356e-04, 6.196e-03, 1.207e-04, 1.981e-02, 1.775e-04,
        5.272e-03, 1.366e-02, 2.717e-02, 1.882e-06, 9.822e-03, 4.157e-03,
        1.163e-04, 1.769e-02, 1.631e-03, 4.255e-04, 2.330e-04, 8.516e-03,
        1.726e-04, 1.059e-02, 1.460e-04, 5.119e-03, 6.259e-03, 3.489e-05,
        1.882e-06, 6.703e-02, 4.078e-02, 1.778e-02, 2.918e-05, 5.560e-05,
        7.185e-03, 2.436e-02, 1.677e-03, 6.843e-04, 1.221e-03, 7.877e-03,
        9.262e-05, 9.561e-04, 3.752e-02, 6.152e-04, 8.570e-03, 6.608e-06,
        1.051e-02, 3.731e-02, 2.278e-02, 2.334e-03, 1.817e-03, 3.786e-03,
        1.882e-06, 6.912e-05, 1.852e-02, 1.132e-04, 1.319e-02, 8.942e-05,
        1.694e-03, 1.593e-05, 9.281e-03, 5.485e-02, 1.882e-06, 1.181e-03,
        6.625e-02, 8.365e-04, 1.259e-04, 2.284e-04, 1.882e-06, 2.245e-03,
        4.207e-02, 4.589e-02, 1.488e-04, 9.733e-02, 2.455e-05, 1.523e-04,
        3.134e-04, 1.056e-04, 1.757e-02, 1.019e-02, 5.145e-03, 3.866e-03,
        5.206e-03, 8.871e-04, 6.434e-03, 1.044e-03, 1.901e-01, 1.585e-04,
        8.143e-05, 3.988e-03, 4.244e-06, 3.891e-03, 1.242e-02, 1.085e-02,
        1.984e-03, 2.234e-03, 1.476e-04, 3.682e-03, 1.157e-02, 1.661e-02,
        1.336e-05, 3.800e-03, 5.595e-04, 1.965e-02, 2.311e-04, 1.528e-04,
        1.252e-02, 4.860e-02, 2.615e-03, 1.604e-02, 1.018e-01, 1.255e-01,
        1.308e-02, 9.413e-04, 7.633e-03, 2.384e-03, 2.629e-05, 1.251e-03,
        8.813e-03, 1.151e-03, 2.156e-04, 4.783e-04, 1.882e-06, 1.196e-04,
        1.882e-06, 6.982e-03, 8.981e-06, 2.246e-01, 2.857e-02, 4.173e-04,
        1.461e-03, 2.755e-03, 1.159e-02, 8.599e-02, 2.579e-02, 1.925e-02,
        2.762e-02, 8.844e-03, 1.012e-03, 2.204e-05, 8.194e-03, 4.502e-05,
        9.483e-03, 6.618e-05, 1.400e-02, 2.108e-02, 8.243e-02, 5.985e-05,
        7.303e-02, 7.678e-04, 5.814e-03, 6.101e-02, 4.831e-05, 4.125e-04,
        2.384e-05, 2.403e-02, 5.985e-04, 5.704e-04, 3.023e-05, 1.882e-06,
        2.944e-04, 5.132e-04, 4.174e-04, 1.882e-06, 1.424e-03, 1.607e-01,
        1.110e-03, 1.150e-01, 1.221e-02, 1.631e-04, 1.338e-02, 7.404e-06,
        3.290e-03, 4.921e-04, 1.561e-02, 1.750e-04, 3.426e-02, 2.300e-04,
        2.663e-02, 2.227e-03], device='cuda:0')
b after update for 1 param tensor([0.102, 2.123, 0.071, 0.107, 0.065, 2.230, 0.206, 0.274, 0.419, 0.304,
        0.072, 0.163, 0.469, 0.779, 0.067, 0.734, 0.428, 0.208, 1.129, 0.055,
        0.210, 0.870, 0.264, 0.018, 4.251, 0.205, 0.697, 0.097, 1.245, 0.118,
        0.643, 1.034, 1.459, 0.012, 0.877, 0.571, 0.095, 1.177, 0.357, 0.183,
        0.135, 0.817, 0.116, 0.911, 0.107, 0.633, 0.700, 0.052, 0.012, 2.291,
        1.787, 1.180, 0.048, 0.066, 0.750, 1.381, 0.362, 0.231, 0.309, 0.785,
        0.085, 0.274, 1.714, 0.219, 0.819, 0.023, 0.907, 1.709, 1.336, 0.427,
        0.377, 0.545, 0.012, 0.074, 1.204, 0.094, 1.016, 0.084, 0.364, 0.035,
        0.852, 2.072, 0.012, 0.304, 2.278, 0.256, 0.099, 0.134, 0.012, 0.419,
        1.815, 1.896, 0.108, 2.761, 0.044, 0.109, 0.157, 0.091, 1.173, 0.893,
        0.635, 0.550, 0.638, 0.264, 0.710, 0.286, 3.858, 0.111, 0.080, 0.559,
        0.018, 0.552, 0.986, 0.922, 0.394, 0.418, 0.108, 0.537, 0.952, 1.140,
        0.032, 0.545, 0.209, 1.240, 0.135, 0.109, 0.990, 1.951, 0.452, 1.121,
        2.823, 3.135, 1.012, 0.271, 0.773, 0.432, 0.045, 0.313, 0.831, 0.300,
        0.130, 0.194, 0.012, 0.097, 0.012, 0.739, 0.027, 4.193, 1.496, 0.181,
        0.338, 0.464, 0.953, 2.595, 1.421, 1.228, 1.471, 0.832, 0.282, 0.042,
        0.801, 0.059, 0.862, 0.072, 1.047, 1.285, 2.541, 0.068, 2.391, 0.245,
        0.675, 2.186, 0.062, 0.180, 0.043, 1.372, 0.216, 0.211, 0.049, 0.012,
        0.152, 0.200, 0.181, 0.012, 0.334, 3.547, 0.295, 3.001, 0.978, 0.113,
        1.024, 0.024, 0.508, 0.196, 1.105, 0.117, 1.638, 0.134, 1.444, 0.418],
       device='cuda:0')
clipping threshold 2.782537623814828
a after update for 1 param tensor([[[ 3.749e-04],
         [-3.394e-05],
         [ 8.100e-05],
         [-2.601e-04],
         [-7.058e-04],
         [ 2.693e-04],
         [ 2.993e-04],
         [ 2.654e-04],
         [ 2.881e-04],
         [-9.178e-05]],

        [[ 1.376e-04],
         [-1.749e-04],
         [ 4.282e-04],
         [ 4.592e-06],
         [-1.496e-04],
         [ 5.878e-04],
         [ 2.228e-04],
         [-5.206e-04],
         [-2.623e-04],
         [ 5.841e-04]],

        [[-2.058e-04],
         [-3.288e-04],
         [-5.079e-05],
         [-3.807e-04],
         [ 3.554e-04],
         [-1.230e-04],
         [-1.455e-04],
         [-1.180e-04],
         [-3.902e-04],
         [-2.159e-04]],

        [[ 6.634e-06],
         [ 1.088e-05],
         [ 1.173e-05],
         [ 3.853e-06],
         [-8.170e-06],
         [-7.227e-05],
         [-2.826e-05],
         [ 2.003e-04],
         [ 1.847e-04],
         [ 6.714e-04]],

        [[ 3.429e-05],
         [-6.687e-05],
         [ 2.289e-05],
         [ 1.940e-04],
         [-7.127e-04],
         [ 1.785e-05],
         [ 8.542e-04],
         [-3.126e-04],
         [-3.451e-05],
         [ 7.222e-04]],

        [[ 6.318e-04],
         [-6.756e-05],
         [ 1.121e-04],
         [-1.061e-04],
         [ 2.445e-04],
         [ 1.667e-04],
         [-1.764e-05],
         [ 3.500e-04],
         [ 1.081e-04],
         [ 7.506e-05]],

        [[-2.307e-04],
         [ 1.075e-05],
         [ 1.571e-05],
         [-1.359e-05],
         [ 1.940e-04],
         [ 2.156e-04],
         [-6.838e-04],
         [ 1.476e-05],
         [-5.504e-05],
         [ 3.543e-04]],

        [[ 1.370e-05],
         [ 4.625e-04],
         [ 9.604e-05],
         [ 1.175e-04],
         [ 6.173e-05],
         [ 5.173e-05],
         [-5.739e-04],
         [ 2.780e-04],
         [ 5.080e-05],
         [ 5.740e-05]],

        [[-1.028e-04],
         [-1.696e-04],
         [ 1.000e-05],
         [ 9.585e-05],
         [-5.346e-05],
         [-1.247e-04],
         [-1.727e-04],
         [-3.081e-04],
         [ 3.820e-04],
         [-2.204e-04]],

        [[ 3.415e-05],
         [-1.232e-05],
         [ 2.010e-05],
         [-1.763e-04],
         [-1.695e-04],
         [ 3.095e-04],
         [ 9.644e-05],
         [-3.095e-05],
         [-1.877e-04],
         [-1.315e-04]],

        [[-6.772e-05],
         [ 4.499e-05],
         [-5.530e-05],
         [ 6.776e-05],
         [-1.763e-06],
         [-1.443e-05],
         [-4.797e-05],
         [ 5.035e-05],
         [ 1.848e-04],
         [ 4.237e-04]],

        [[-2.857e-04],
         [ 1.319e-04],
         [-2.120e-04],
         [-1.091e-05],
         [-2.731e-06],
         [-5.232e-06],
         [ 3.567e-05],
         [ 4.723e-06],
         [-1.941e-06],
         [-2.367e-05]],

        [[ 2.237e-04],
         [-2.666e-04],
         [ 1.760e-03],
         [-6.072e-05],
         [-6.479e-04],
         [ 1.727e-04],
         [ 1.899e-04],
         [ 1.104e-04],
         [ 2.702e-04],
         [ 1.081e-04]],

        [[ 2.831e-05],
         [ 4.404e-05],
         [ 2.785e-05],
         [ 4.121e-05],
         [-7.365e-05],
         [ 7.492e-05],
         [ 1.288e-04],
         [ 1.781e-04],
         [ 8.971e-05],
         [ 2.002e-05]],

        [[ 3.309e-04],
         [-1.288e-04],
         [-3.256e-05],
         [ 8.738e-05],
         [ 1.499e-04],
         [ 3.396e-04],
         [-1.502e-04],
         [ 2.903e-05],
         [ 1.173e-04],
         [ 3.905e-05]],

        [[ 2.501e-04],
         [ 4.759e-04],
         [-3.383e-04],
         [ 1.076e-04],
         [-1.759e-04],
         [ 9.837e-04],
         [-1.770e-05],
         [-3.025e-05],
         [-1.600e-04],
         [-1.964e-05]],

        [[-1.360e-06],
         [ 5.473e-05],
         [-3.506e-04],
         [ 7.849e-05],
         [ 4.592e-05],
         [ 4.987e-05],
         [-2.138e-05],
         [ 5.054e-04],
         [-1.056e-05],
         [-1.868e-04]],

        [[-1.968e-04],
         [-1.625e-04],
         [-3.660e-04],
         [ 1.657e-05],
         [-1.125e-04],
         [-1.697e-04],
         [-1.576e-07],
         [-9.694e-05],
         [ 4.710e-04],
         [ 7.763e-04]],

        [[ 8.671e-04],
         [-3.189e-04],
         [ 4.490e-05],
         [ 1.658e-04],
         [ 5.320e-05],
         [-1.519e-04],
         [ 1.313e-04],
         [ 2.640e-05],
         [-4.034e-05],
         [ 1.892e-04]],

        [[ 1.460e-04],
         [ 1.919e-04],
         [-4.418e-05],
         [ 1.577e-05],
         [-1.075e-04],
         [ 7.942e-06],
         [ 1.808e-05],
         [ 7.432e-06],
         [ 1.547e-04],
         [ 3.758e-06]]], device='cuda:0')
s after update for 1 param tensor([[[5.143e-02],
         [1.710e-02],
         [9.156e-03],
         [1.246e-02],
         [6.634e-02],
         [7.499e-03],
         [7.193e-03],
         [2.824e-03],
         [2.634e-02],
         [1.115e-02]],

        [[2.238e-03],
         [3.555e-03],
         [3.890e-02],
         [2.918e-04],
         [2.636e-03],
         [1.087e-01],
         [4.502e-03],
         [4.781e-02],
         [2.318e-02],
         [1.380e-01]],

        [[1.105e-02],
         [9.238e-02],
         [1.008e-03],
         [2.882e-02],
         [4.345e-02],
         [1.014e-02],
         [4.982e-03],
         [1.178e-03],
         [4.724e-02],
         [2.329e-02]],

        [[6.065e-03],
         [5.100e-04],
         [5.642e-05],
         [2.151e-03],
         [3.059e-05],
         [1.968e-03],
         [3.817e-03],
         [3.644e-02],
         [3.314e-02],
         [2.281e-02]],

        [[3.038e-03],
         [1.357e-02],
         [2.452e-04],
         [7.196e-03],
         [1.108e-01],
         [1.377e-03],
         [1.859e-01],
         [5.537e-02],
         [3.046e-04],
         [3.482e-02]],

        [[1.120e-01],
         [1.877e-04],
         [3.250e-03],
         [4.960e-03],
         [5.309e-03],
         [1.231e-02],
         [4.491e-04],
         [9.159e-03],
         [1.347e-03],
         [8.179e-04]],

        [[4.143e-02],
         [6.634e-05],
         [1.631e-03],
         [5.694e-04],
         [1.353e-02],
         [1.344e-02],
         [7.967e-02],
         [2.305e-03],
         [1.181e-02],
         [2.969e-02]],

        [[1.326e-04],
         [6.498e-02],
         [4.800e-03],
         [2.947e-02],
         [8.064e-03],
         [1.630e-03],
         [8.593e-02],
         [4.414e-02],
         [1.371e-03],
         [7.248e-03]],

        [[1.416e-02],
         [1.762e-02],
         [3.944e-03],
         [7.763e-03],
         [4.635e-03],
         [3.590e-03],
         [3.186e-02],
         [3.672e-02],
         [5.593e-03],
         [2.072e-02]],

        [[9.189e-04],
         [1.133e-03],
         [1.009e-02],
         [6.327e-03],
         [2.478e-03],
         [8.244e-02],
         [2.396e-03],
         [8.692e-03],
         [2.263e-02],
         [2.452e-02]],

        [[2.472e-04],
         [1.491e-04],
         [2.810e-03],
         [1.338e-03],
         [4.475e-05],
         [1.083e-04],
         [1.747e-03],
         [3.995e-04],
         [2.938e-02],
         [5.892e-02]],

        [[3.895e-02],
         [1.219e-02],
         [4.190e-03],
         [1.687e-04],
         [2.530e-03],
         [1.308e-05],
         [8.082e-04],
         [1.693e-03],
         [1.974e-04],
         [2.754e-04]],

        [[5.234e-02],
         [4.599e-03],
         [3.133e-01],
         [5.714e-02],
         [2.630e-02],
         [3.663e-02],
         [2.865e-02],
         [1.258e-02],
         [1.489e-02],
         [1.809e-02]],

        [[9.507e-04],
         [7.622e-04],
         [3.038e-02],
         [2.822e-03],
         [1.022e-02],
         [1.319e-03],
         [7.950e-03],
         [4.151e-02],
         [5.718e-04],
         [1.650e-04]],

        [[1.009e-02],
         [6.278e-03],
         [9.725e-04],
         [2.855e-03],
         [1.733e-02],
         [4.194e-02],
         [3.760e-03],
         [7.367e-03],
         [7.043e-04],
         [1.678e-03]],

        [[6.599e-03],
         [3.764e-02],
         [8.058e-03],
         [1.226e-02],
         [5.590e-03],
         [1.445e-01],
         [5.867e-04],
         [4.077e-04],
         [3.192e-02],
         [2.801e-04]],

        [[1.969e-04],
         [7.853e-04],
         [7.678e-03],
         [1.910e-02],
         [2.279e-03],
         [2.604e-04],
         [8.839e-04],
         [2.274e-02],
         [3.414e-05],
         [1.016e-02]],

        [[6.356e-03],
         [6.749e-03],
         [1.815e-02],
         [4.671e-03],
         [2.602e-02],
         [2.253e-02],
         [5.455e-03],
         [2.466e-03],
         [9.967e-02],
         [5.123e-02]],

        [[4.272e-02],
         [6.233e-02],
         [9.072e-05],
         [3.748e-02],
         [7.519e-03],
         [3.999e-03],
         [4.692e-03],
         [3.106e-03],
         [7.848e-04],
         [3.772e-02]],

        [[2.439e-02],
         [7.172e-03],
         [3.778e-03],
         [1.792e-04],
         [6.318e-04],
         [4.341e-03],
         [6.017e-03],
         [9.034e-05],
         [3.511e-03],
         [5.233e-05]]], device='cuda:0')
b after update for 1 param tensor([[[2.007],
         [1.157],
         [0.847],
         [0.988],
         [2.279],
         [0.766],
         [0.751],
         [0.470],
         [1.436],
         [0.934]],

        [[0.419],
         [0.528],
         [1.745],
         [0.151],
         [0.454],
         [2.917],
         [0.594],
         [1.935],
         [1.347],
         [3.287]],

        [[0.930],
         [2.690],
         [0.281],
         [1.502],
         [1.844],
         [0.891],
         [0.625],
         [0.304],
         [1.923],
         [1.351]],

        [[0.689],
         [0.200],
         [0.066],
         [0.410],
         [0.049],
         [0.393],
         [0.547],
         [1.689],
         [1.611],
         [1.336]],

        [[0.488],
         [1.031],
         [0.139],
         [0.751],
         [2.946],
         [0.328],
         [3.816],
         [2.082],
         [0.154],
         [1.651]],

        [[2.961],
         [0.121],
         [0.504],
         [0.623],
         [0.645],
         [0.982],
         [0.188],
         [0.847],
         [0.325],
         [0.253]],

        [[1.801],
         [0.072],
         [0.357],
         [0.211],
         [1.029],
         [1.026],
         [2.498],
         [0.425],
         [0.962],
         [1.525]],

        [[0.102],
         [2.256],
         [0.613],
         [1.519],
         [0.795],
         [0.357],
         [2.594],
         [1.859],
         [0.328],
         [0.753]],

        [[1.053],
         [1.175],
         [0.556],
         [0.780],
         [0.602],
         [0.530],
         [1.579],
         [1.696],
         [0.662],
         [1.274]],

        [[0.268],
         [0.298],
         [0.889],
         [0.704],
         [0.440],
         [2.541],
         [0.433],
         [0.825],
         [1.331],
         [1.386]],

        [[0.139],
         [0.108],
         [0.469],
         [0.324],
         [0.059],
         [0.092],
         [0.370],
         [0.177],
         [1.517],
         [2.148]],

        [[1.746],
         [0.977],
         [0.573],
         [0.115],
         [0.445],
         [0.032],
         [0.252],
         [0.364],
         [0.124],
         [0.147]],

        [[2.024],
         [0.600],
         [4.953],
         [2.115],
         [1.435],
         [1.694],
         [1.498],
         [0.993],
         [1.080],
         [1.190]],

        [[0.273],
         [0.244],
         [1.542],
         [0.470],
         [0.895],
         [0.321],
         [0.789],
         [1.803],
         [0.212],
         [0.114]],

        [[0.889],
         [0.701],
         [0.276],
         [0.473],
         [1.165],
         [1.812],
         [0.543],
         [0.760],
         [0.235],
         [0.363]],

        [[0.719],
         [1.717],
         [0.794],
         [0.980],
         [0.662],
         [3.364],
         [0.214],
         [0.179],
         [1.581],
         [0.148]],

        [[0.124],
         [0.248],
         [0.775],
         [1.223],
         [0.422],
         [0.143],
         [0.263],
         [1.334],
         [0.052],
         [0.892]],

        [[0.706],
         [0.727],
         [1.192],
         [0.605],
         [1.428],
         [1.328],
         [0.654],
         [0.439],
         [2.794],
         [2.003]],

        [[1.829],
         [2.209],
         [0.084],
         [1.713],
         [0.767],
         [0.560],
         [0.606],
         [0.493],
         [0.248],
         [1.719]],

        [[1.382],
         [0.749],
         [0.544],
         [0.118],
         [0.222],
         [0.583],
         [0.686],
         [0.084],
         [0.524],
         [0.064]]], device='cuda:0')
clipping threshold 2.782537623814828
a after update for 1 param tensor([[ 1.910e-04],
        [-8.095e-04],
        [-3.094e-05],
        [-6.462e-04],
        [-4.765e-04],
        [ 5.054e-04],
        [ 5.697e-04],
        [ 8.251e-05],
        [ 3.507e-05],
        [ 6.759e-05],
        [ 1.630e-04],
        [-3.921e-05],
        [ 1.970e-04],
        [-5.090e-05],
        [-2.037e-04],
        [ 2.040e-05],
        [-2.306e-04],
        [-1.194e-04],
        [ 1.271e-04],
        [ 1.013e-04]], device='cuda:0')
s after update for 1 param tensor([[0.033],
        [0.034],
        [0.002],
        [0.060],
        [0.014],
        [0.043],
        [0.102],
        [0.005],
        [0.005],
        [0.003],
        [0.023],
        [0.000],
        [0.003],
        [0.002],
        [0.002],
        [0.000],
        [0.003],
        [0.006],
        [0.009],
        [0.034]], device='cuda:0')
b after update for 1 param tensor([[1.613],
        [1.620],
        [0.407],
        [2.169],
        [1.055],
        [1.838],
        [2.820],
        [0.599],
        [0.637],
        [0.498],
        [1.351],
        [0.171],
        [0.443],
        [0.438],
        [0.418],
        [0.184],
        [0.456],
        [0.683],
        [0.842],
        [1.639]], device='cuda:0')
clipping threshold 2.782537623814828
||w||^2 0.04849335194660525
exp ma of ||w||^2 0.04372628008100543
||w|| 0.22021206131046783
exp ma of ||w|| 0.20529332702675115
||w||^2 0.04783629683441114
exp ma of ||w||^2 0.04257748272135866
||w|| 0.21871510426674043
exp ma of ||w|| 0.2030841622945446
||w||^2 0.026176283435660388
exp ma of ||w||^2 0.043518336365540325
||w|| 0.16179086326384562
exp ma of ||w|| 0.20450511889662634
||w||^2 0.04838593797874324
exp ma of ||w||^2 0.04422982674705435
||w|| 0.21996803853910968
exp ma of ||w|| 0.20598815105617085
||w||^2 0.04747808290096534
exp ma of ||w||^2 0.04523693721605989
||w|| 0.21789466010199823
exp ma of ||w|| 0.2080360683329824
||w||^2 0.040465111023016406
exp ma of ||w||^2 0.04419607023743784
||w|| 0.2011594169384481
exp ma of ||w|| 0.20657644185347676
||w||^2 0.06358087761135721
exp ma of ||w||^2 0.043117704680568386
||w|| 0.2521524888065894
exp ma of ||w|| 0.20294653688191963
v before min max tensor([[-3.338,  0.272, -1.807,  ..., -1.806, -1.199,  0.708],
        [-5.275,  2.311, -0.243,  ..., -0.988, -2.621, -2.153],
        [-2.226,  2.809, -3.143,  ..., -2.586, -3.778, -1.005],
        ...,
        [-1.897, -2.959, -2.293,  ..., -1.516, -1.142, -2.396],
        [-4.280, -2.717, -0.819,  ..., -0.462, -1.777,  0.990],
        [-1.555, -3.345,  2.197,  ..., 10.238, -2.702, -0.101]],
       device='cuda:0')
v tensor([[1.000e-12, 2.716e-01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         7.075e-01],
        [1.000e-12, 2.311e+00, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 2.809e+00, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         9.901e-01],
        [1.000e-12, 1.000e-12, 2.197e+00,  ..., 1.000e+01, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([-3.386e+00, -2.152e+00, -3.465e+00, -2.126e+00,  3.743e+00, -2.387e+00,
        -1.983e+00, -1.914e+00, -3.028e+00, -1.341e+00, -9.578e-01,  3.390e-01,
         8.256e-02, -2.665e+00, -1.656e+00, -3.651e+00, -3.326e+00,  2.339e+00,
        -7.123e-01,  3.155e+00, -2.426e+00,  3.667e+00,  9.756e+00,  1.079e+01,
        -2.849e+00, -2.610e-01, -1.876e+00,  1.936e-02, -4.708e+00, -4.806e+00,
        -1.235e+00, -3.321e+00, -3.833e+00, -3.750e+00, -3.685e+00, -2.716e+00,
        -3.991e+00, -4.042e+00, -2.779e+00, -2.456e+00,  3.772e+00, -1.571e+00,
         6.290e-01, -4.691e+00,  3.759e+00, -9.571e-01,  3.223e-01, -1.818e-01,
        -3.289e+00, -1.898e-01, -1.972e+00, -1.466e+00, -3.337e+00, -2.933e+00,
        -5.512e+00,  7.775e+00, -5.781e-01, -1.982e+00, -5.628e-01, -4.848e+00,
        -3.345e+00,  1.944e+01,  6.585e+00, -3.098e+00, -3.732e+00, -4.177e+00,
        -3.006e+00,  6.286e+00, -2.718e+00,  9.682e+00,  5.985e+00, -3.195e+00,
         1.648e+00, -1.769e+00, -2.793e+00,  8.702e+00, -1.091e+00, -7.362e-01,
         3.741e+00, -6.882e-01,  2.110e-01, -7.363e-01, -8.612e-01, -2.555e+00,
        -2.477e+00, -1.242e+00,  1.762e+00, -3.557e+00, -4.569e+00, -6.390e-01,
         7.838e+00,  3.385e+00, -2.957e+00, -4.047e+00, -8.548e-01, -1.390e+00,
         1.998e-01, -3.197e+00, -3.763e-03, -1.672e+00,  2.597e+00, -3.029e+00,
        -1.440e-01, -8.226e-01,  9.427e+00,  3.565e+00, -1.002e+00, -3.655e+00,
        -2.683e+00, -3.560e+00, -4.959e-01, -2.712e+00, -4.395e+00, -1.846e+00,
        -2.236e+00, -2.056e+00, -1.137e+00, -5.248e-01,  4.554e+00, -4.464e+00,
         5.281e+00, -4.884e-01, -2.395e+00, -2.867e+00, -5.013e+00, -3.399e+00,
        -3.362e+00, -3.285e+00, -3.369e+00, -3.117e+00, -1.791e+00, -4.627e+00,
         7.636e+00,  5.297e+00, -1.412e+00, -3.072e+00, -4.089e+00, -1.305e+00,
        -7.884e-01,  1.622e+00, -6.400e-01, -5.592e-01, -3.413e+00,  7.920e-01,
        -1.755e+00, -2.539e+00, -1.992e+00, -3.217e+00, -2.273e+00, -4.018e+00,
        -4.652e+00, -2.159e-01, -1.135e+00,  8.767e-02, -1.145e+00,  4.827e+00,
        -1.555e+00, -3.732e+00,  1.361e+01, -4.237e-01, -4.011e+00,  3.982e+00,
         3.084e-02, -2.208e-02,  5.759e+00, -4.452e-01, -1.317e+00, -6.251e-01,
         4.417e+00, -2.366e+00, -2.710e+00, -1.983e+00, -3.100e+00,  3.521e+00,
        -1.221e+00, -2.274e+00, -3.864e+00, -1.961e+00, -9.747e-01, -3.624e+00,
        -1.591e+00, -2.398e+00, -1.210e+00,  2.742e+00, -2.905e+00, -2.099e+00,
        -1.519e+00, -1.579e+00, -1.099e+00,  2.017e+01, -4.059e+00, -3.240e+00,
        -9.783e-02, -2.951e+00, -1.515e+00, -1.025e+00, -2.689e+00,  7.380e-01,
        -2.686e+00, -3.117e+00], device='cuda:0')
v tensor([1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.743e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.390e-01,
        8.256e-02, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.339e+00,
        1.000e-12, 3.155e+00, 1.000e-12, 3.667e+00, 9.756e+00, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.936e-02, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.772e+00, 1.000e-12,
        6.290e-01, 1.000e-12, 3.759e+00, 1.000e-12, 3.223e-01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 7.775e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 6.585e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 6.286e+00, 1.000e-12, 9.682e+00, 5.985e+00, 1.000e-12,
        1.648e+00, 1.000e-12, 1.000e-12, 8.702e+00, 1.000e-12, 1.000e-12,
        3.741e+00, 1.000e-12, 2.110e-01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.762e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        7.838e+00, 3.385e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.998e-01, 1.000e-12, 1.000e-12, 1.000e-12, 2.597e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 9.427e+00, 3.565e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 4.554e+00, 1.000e-12,
        5.281e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        7.636e+00, 5.297e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.622e+00, 1.000e-12, 1.000e-12, 1.000e-12, 7.920e-01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 8.767e-02, 1.000e-12, 4.827e+00,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 3.982e+00,
        3.084e-02, 1.000e-12, 5.759e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        4.417e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.521e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 2.742e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 7.380e-01,
        1.000e-12, 1.000e-12], device='cuda:0')
v before min max tensor([[[-2.892],
         [-3.208],
         [-3.628],
         [ 0.477],
         [-2.854],
         [10.300],
         [-3.440],
         [-3.312],
         [-2.482],
         [ 6.321]],

        [[-2.177],
         [-0.386],
         [-2.211],
         [-3.289],
         [-4.646],
         [-2.534],
         [10.022],
         [-3.614],
         [ 3.596],
         [-0.520]],

        [[-2.938],
         [34.701],
         [ 9.097],
         [-4.135],
         [-2.579],
         [-2.769],
         [-2.439],
         [-3.128],
         [ 3.336],
         [ 1.464]],

        [[-3.042],
         [ 1.987],
         [ 1.679],
         [-5.696],
         [-1.143],
         [-4.255],
         [-2.697],
         [-4.644],
         [-0.958],
         [-3.401]],

        [[-4.971],
         [-1.402],
         [ 4.660],
         [-4.339],
         [-2.920],
         [ 6.575],
         [-2.778],
         [ 1.088],
         [-1.426],
         [ 7.111]],

        [[-5.441],
         [ 6.968],
         [ 3.655],
         [-3.640],
         [-2.163],
         [-3.313],
         [ 3.322],
         [ 0.819],
         [ 4.394],
         [ 2.905]],

        [[ 2.119],
         [-2.355],
         [-1.994],
         [-2.224],
         [-3.070],
         [-5.177],
         [-1.810],
         [ 1.129],
         [ 0.290],
         [ 3.706]],

        [[10.391],
         [ 2.997],
         [-4.745],
         [ 0.618],
         [-3.063],
         [ 0.417],
         [ 8.828],
         [ 1.901],
         [-2.775],
         [ 0.246]],

        [[13.261],
         [ 9.999],
         [14.849],
         [-3.195],
         [-3.198],
         [-0.441],
         [-5.978],
         [22.278],
         [-0.862],
         [ 2.144]],

        [[-4.371],
         [ 4.425],
         [-3.529],
         [-2.438],
         [-2.355],
         [-2.231],
         [-2.267],
         [ 4.814],
         [ 1.492],
         [-3.225]],

        [[-2.012],
         [ 3.807],
         [-0.643],
         [-2.538],
         [-0.900],
         [-2.632],
         [ 1.255],
         [-2.430],
         [-3.418],
         [-2.413]],

        [[ 0.611],
         [-2.646],
         [ 1.679],
         [-2.096],
         [-2.465],
         [-2.045],
         [-6.071],
         [15.002],
         [-1.004],
         [-3.108]],

        [[-1.743],
         [-3.539],
         [ 5.807],
         [-3.951],
         [-3.751],
         [-0.679],
         [-0.239],
         [-2.479],
         [-3.852],
         [-4.079]],

        [[-2.992],
         [ 7.168],
         [-1.450],
         [-2.435],
         [ 0.901],
         [-1.205],
         [-1.612],
         [ 5.764],
         [ 0.105],
         [-2.221]],

        [[ 1.987],
         [ 4.577],
         [-4.013],
         [-2.549],
         [-2.920],
         [-4.827],
         [-2.165],
         [ 1.577],
         [-4.007],
         [-1.771]],

        [[-4.208],
         [-3.432],
         [-2.319],
         [-4.711],
         [-4.473],
         [-3.540],
         [ 6.176],
         [-2.769],
         [-2.911],
         [-2.619]],

        [[-1.641],
         [-3.208],
         [-1.201],
         [-2.240],
         [ 5.596],
         [-1.283],
         [10.623],
         [ 0.294],
         [-0.943],
         [12.018]],

        [[-0.339],
         [-1.643],
         [14.173],
         [-2.708],
         [ 1.077],
         [-2.598],
         [-3.950],
         [-2.165],
         [ 0.189],
         [-2.927]],

        [[ 1.660],
         [ 3.213],
         [-3.669],
         [-3.799],
         [-4.110],
         [-2.652],
         [-2.887],
         [-1.982],
         [-3.490],
         [ 1.880]],

        [[-1.650],
         [ 2.626],
         [-4.068],
         [-4.333],
         [ 0.271],
         [-1.586],
         [-3.572],
         [ 0.517],
         [ 4.255],
         [-1.968]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.769e-01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.321e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [3.596e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [9.097e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.336e+00],
         [1.464e+00]],

        [[1.000e-12],
         [1.987e+00],
         [1.679e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [4.660e+00],
         [1.000e-12],
         [1.000e-12],
         [6.575e+00],
         [1.000e-12],
         [1.088e+00],
         [1.000e-12],
         [7.111e+00]],

        [[1.000e-12],
         [6.968e+00],
         [3.655e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.322e+00],
         [8.194e-01],
         [4.394e+00],
         [2.905e+00]],

        [[2.119e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.129e+00],
         [2.902e-01],
         [3.706e+00]],

        [[1.000e+01],
         [2.997e+00],
         [1.000e-12],
         [6.175e-01],
         [1.000e-12],
         [4.172e-01],
         [8.828e+00],
         [1.901e+00],
         [1.000e-12],
         [2.457e-01]],

        [[1.000e+01],
         [9.999e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [2.144e+00]],

        [[1.000e-12],
         [4.425e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.814e+00],
         [1.492e+00],
         [1.000e-12]],

        [[1.000e-12],
         [3.807e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.255e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[6.114e-01],
         [1.000e-12],
         [1.679e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [5.807e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [7.168e+00],
         [1.000e-12],
         [1.000e-12],
         [9.013e-01],
         [1.000e-12],
         [1.000e-12],
         [5.764e+00],
         [1.047e-01],
         [1.000e-12]],

        [[1.987e+00],
         [4.577e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.577e+00],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.176e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.596e+00],
         [1.000e-12],
         [1.000e+01],
         [2.939e-01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.077e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.894e-01],
         [1.000e-12]],

        [[1.660e+00],
         [3.213e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.880e+00]],

        [[1.000e-12],
         [2.626e+00],
         [1.000e-12],
         [1.000e-12],
         [2.711e-01],
         [1.000e-12],
         [1.000e-12],
         [5.165e-01],
         [4.255e+00],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[15.635],
        [-4.915],
        [-3.372],
        [-3.442],
        [-2.231],
        [12.190],
        [-2.674],
        [-0.596],
        [-5.312],
        [-4.709],
        [ 6.656],
        [ 6.600],
        [-1.920],
        [-3.408],
        [-1.383],
        [-4.505],
        [-4.284],
        [-5.290],
        [11.588],
        [-2.045]], device='cuda:0')
v tensor([[1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [6.656e+00],
        [6.600e+00],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 8.294e-05, -1.272e-02, -1.345e-02,  ...,  1.719e-02,  1.295e-02,
         -6.920e-03],
        [-4.982e-02, -1.407e-02,  4.292e-02,  ...,  3.403e-02, -2.352e-02,
         -1.114e-02],
        [ 2.568e-02, -1.418e-02, -1.428e-02,  ..., -1.308e-02, -8.433e-02,
          5.227e-02],
        ...,
        [-3.322e-02,  2.860e-02, -1.105e-02,  ..., -1.810e-02, -1.807e-02,
          5.404e-02],
        [-2.508e-02, -5.522e-02,  3.370e-03,  ...,  5.205e-02, -1.508e-02,
         -1.869e-03],
        [ 2.262e-02, -1.202e-02,  2.060e-02,  ...,  4.524e-02, -1.851e-02,
          4.064e-02]], device='cuda:0')
s after update for 1 param tensor([[1.038, 0.798, 0.981,  ..., 0.573, 0.665, 0.621],
        [1.686, 1.163, 0.477,  ..., 0.478, 1.071, 0.734],
        [0.873, 1.420, 0.952,  ..., 1.002, 1.112, 1.292],
        ...,
        [0.620, 0.888, 1.057,  ..., 1.038, 0.474, 1.085],
        [1.359, 1.055, 1.340,  ..., 1.304, 0.710, 1.070],
        [0.976, 0.985, 0.847,  ..., 1.215, 0.841, 0.621]], device='cuda:0')
b after update for 1 param tensor([[69.039, 60.508, 67.101,  ..., 51.276, 55.234, 53.377],
        [87.979, 73.062, 46.772,  ..., 46.851, 70.116, 58.065],
        [63.305, 80.743, 66.097,  ..., 67.833, 71.458, 77.001],
        ...,
        [53.365, 63.833, 69.670,  ..., 69.027, 46.636, 70.572],
        [78.976, 69.605, 78.419,  ..., 77.378, 57.101, 70.068],
        [66.946, 67.256, 62.364,  ..., 74.679, 62.123, 53.394]],
       device='cuda:0')
clipping threshold 0.182971180234178
a after update for 1 param tensor([ 0.026, -0.039,  0.003,  0.008, -0.032,  0.009,  0.024, -0.006,  0.011,
         0.005, -0.007,  0.022, -0.005, -0.017, -0.000, -0.007, -0.002, -0.014,
         0.023,  0.053, -0.036,  0.021, -0.000,  0.049,  0.001,  0.046, -0.023,
         0.003,  0.037, -0.001,  0.014, -0.029, -0.043, -0.044, -0.017, -0.016,
         0.021, -0.036,  0.010, -0.030,  0.022, -0.062,  0.010, -0.043, -0.011,
        -0.022,  0.029, -0.006, -0.045, -0.015, -0.015, -0.009,  0.012, -0.010,
         0.061, -0.004,  0.012, -0.033,  0.052, -0.007, -0.003, -0.021,  0.049,
        -0.008,  0.005, -0.053, -0.002,  0.018, -0.018, -0.043, -0.041,  0.003,
        -0.011,  0.036, -0.010,  0.022, -0.024,  0.005,  0.067, -0.007, -0.019,
        -0.018, -0.009,  0.043,  0.009, -0.013, -0.003, -0.005,  0.023, -0.020,
         0.029,  0.001, -0.025,  0.040,  0.031, -0.028, -0.021,  0.009, -0.003,
        -0.008,  0.002,  0.003,  0.009,  0.018, -0.047, -0.011, -0.011, -0.043,
        -0.033,  0.008, -0.012,  0.003, -0.019, -0.017,  0.023, -0.044, -0.004,
        -0.005, -0.007, -0.009, -0.026,  0.010, -0.030, -0.000, -0.034, -0.014,
        -0.030,  0.040,  0.032,  0.001,  0.016,  0.000,  0.071,  0.021, -0.034,
        -0.066,  0.029,  0.013, -0.007,  0.029,  0.018,  0.015,  0.005, -0.008,
        -0.025, -0.015, -0.052,  0.004, -0.005,  0.018, -0.019,  0.012, -0.002,
        -0.022, -0.004, -0.015, -0.012,  0.024,  0.020,  0.031, -0.036,  0.021,
        -0.036, -0.012,  0.019,  0.038, -0.015,  0.007,  0.055, -0.006, -0.014,
        -0.034, -0.007, -0.014,  0.002, -0.002, -0.017,  0.024, -0.002, -0.002,
         0.005,  0.031, -0.049, -0.006, -0.008, -0.004,  0.011,  0.002,  0.005,
        -0.042,  0.036, -0.042,  0.050, -0.024,  0.015,  0.054,  0.008,  0.020,
        -0.050,  0.028], device='cuda:0')
s after update for 1 param tensor([1.114, 1.047, 1.170, 0.810, 0.964, 0.718, 0.822, 0.711, 0.946, 0.395,
        1.315, 0.468, 0.922, 0.943, 0.671, 1.086, 0.982, 0.932, 0.590, 1.218,
        1.625, 1.038, 1.752, 1.773, 0.840, 0.886, 1.146, 0.504, 1.389, 1.595,
        1.741, 1.083, 1.141, 1.457, 1.362, 0.802, 1.279, 1.243, 1.387, 0.922,
        0.918, 0.987, 0.972, 1.515, 1.233, 0.809, 1.236, 0.774, 0.999, 0.877,
        0.779, 0.529, 1.299, 1.042, 1.622, 1.485, 0.255, 0.586, 0.742, 1.663,
        1.020, 1.315, 1.353, 1.193, 1.292, 1.258, 1.152, 0.921, 0.801, 1.549,
        1.445, 0.982, 1.037, 0.892, 0.828, 1.256, 0.584, 0.264, 1.481, 0.270,
        1.026, 1.180, 0.859, 0.847, 0.943, 0.844, 1.319, 1.060, 1.378, 0.562,
        1.802, 1.630, 0.875, 1.394, 1.594, 0.417, 0.756, 0.966, 0.762, 0.962,
        1.249, 1.085, 0.694, 0.597, 1.207, 1.504, 0.552, 1.355, 0.841, 1.193,
        0.429, 0.861, 1.309, 0.589, 0.911, 0.618, 1.282, 0.739, 1.333, 1.328,
        1.318, 0.480, 1.024, 1.055, 1.598, 1.190, 1.182, 0.985, 1.294, 0.918,
        1.403, 1.463, 1.392, 1.592, 0.830, 0.905, 1.213, 0.548, 0.849, 1.058,
        0.700, 0.684, 1.005, 0.797, 1.317, 0.749, 1.340, 1.029, 0.806, 1.189,
        1.376, 0.766, 0.396, 0.484, 1.062, 1.331, 0.648, 1.222, 1.726, 1.625,
        1.182, 1.335, 1.429, 0.658, 1.526, 0.718, 1.228, 1.196, 1.364, 0.739,
        0.971, 0.629, 0.917, 1.371, 0.899, 0.684, 1.225, 1.153, 1.451, 1.131,
        0.552, 0.718, 0.979, 1.641, 1.159, 1.092, 0.544, 0.685, 0.402, 1.611,
        1.334, 1.360, 1.526, 0.911, 1.018, 0.683, 0.867, 1.036, 0.836, 0.936],
       device='cuda:0')
b after update for 1 param tensor([71.518, 69.332, 73.281, 60.976, 66.531, 57.427, 61.423, 57.124, 65.903,
        42.562, 77.690, 46.353, 65.044, 65.789, 55.516, 70.605, 67.126, 65.403,
        52.036, 74.769, 86.371, 69.027, 89.689, 90.210, 62.094, 63.764, 72.520,
        48.111, 79.846, 85.569, 89.407, 70.519, 72.386, 81.775, 79.058, 60.687,
        76.632, 75.537, 79.783, 65.059, 64.907, 67.312, 66.807, 83.394, 75.236,
        60.946, 75.328, 59.617, 67.706, 63.462, 59.810, 49.275, 77.211, 69.166,
        86.300, 82.555, 34.204, 51.858, 58.363, 87.365, 68.413, 77.685, 78.802,
        73.988, 77.008, 75.979, 72.721, 65.022, 60.622, 84.322, 81.452, 67.126,
        69.001, 63.994, 61.637, 75.937, 51.767, 34.782, 82.444, 35.200, 68.618,
        73.613, 62.781, 62.369, 65.791, 62.249, 77.818, 69.759, 79.520, 50.772,
        90.943, 86.497, 63.377, 79.997, 85.534, 43.776, 58.891, 66.586, 59.123,
        66.465, 75.731, 70.566, 56.453, 52.335, 74.446, 83.085, 50.350, 78.880,
        62.150, 73.990, 44.387, 62.881, 77.528, 52.005, 64.657, 53.250, 76.713,
        58.250, 78.234, 78.084, 77.779, 46.946, 68.569, 69.598, 85.641, 73.913,
        73.662, 67.243, 77.071, 64.921, 80.241, 81.940, 79.950, 85.474, 61.729,
        64.455, 74.633, 50.150, 62.422, 69.698, 56.686, 56.033, 67.925, 60.481,
        77.747, 58.648, 78.424, 68.723, 60.829, 73.872, 79.486, 59.312, 42.651,
        47.131, 69.831, 78.167, 54.546, 74.894, 89.000, 86.368, 73.666, 78.286,
        80.980, 54.953, 83.693, 57.405, 75.089, 74.108, 79.118, 58.238, 66.765,
        53.723, 64.885, 79.345, 64.230, 56.040, 74.975, 72.738, 81.620, 72.038,
        50.345, 57.426, 67.051, 86.793, 72.946, 70.797, 49.968, 56.079, 42.971,
        85.995, 78.251, 79.007, 83.704, 64.654, 68.351, 55.998, 63.094, 68.966,
        61.961, 65.544], device='cuda:0')
clipping threshold 0.182971180234178
a after update for 1 param tensor([[[ 2.961e-02],
         [ 1.220e-02],
         [-2.859e-02],
         [ 2.386e-02],
         [ 1.171e-01],
         [ 1.724e-02],
         [ 3.200e-02],
         [-3.992e-02],
         [ 7.767e-02],
         [ 3.568e-02]],

        [[-6.224e-02],
         [-8.255e-02],
         [-1.949e-02],
         [-7.886e-02],
         [ 9.617e-03],
         [ 1.899e-02],
         [-2.339e-02],
         [-4.422e-02],
         [-7.124e-03],
         [-3.755e-02]],

        [[-2.824e-03],
         [-5.897e-03],
         [ 6.162e-02],
         [-5.366e-02],
         [-4.872e-02],
         [ 1.038e-01],
         [-5.598e-02],
         [ 4.999e-03],
         [-4.821e-02],
         [-8.983e-02]],

        [[ 5.370e-03],
         [ 2.414e-02],
         [-4.891e-05],
         [ 3.492e-02],
         [-5.832e-02],
         [-4.893e-02],
         [ 6.202e-02],
         [-3.708e-02],
         [-9.325e-04],
         [ 1.967e-02]],

        [[-1.614e-03],
         [-2.641e-02],
         [ 1.465e-02],
         [-8.770e-02],
         [ 1.769e-02],
         [ 5.395e-03],
         [-3.991e-02],
         [ 4.378e-02],
         [-8.957e-02],
         [ 6.401e-02]],

        [[ 7.461e-02],
         [ 7.492e-02],
         [-4.266e-03],
         [ 4.598e-02],
         [-5.248e-02],
         [-1.513e-02],
         [-8.962e-02],
         [-2.693e-02],
         [-1.364e-02],
         [-2.552e-02]],

        [[-1.234e-02],
         [ 6.096e-03],
         [-1.116e-01],
         [ 4.239e-03],
         [-1.189e-02],
         [-7.924e-03],
         [ 6.113e-02],
         [-3.486e-02],
         [ 5.312e-02],
         [ 3.615e-02]],

        [[ 2.805e-02],
         [-1.152e-03],
         [ 3.041e-02],
         [ 3.605e-02],
         [ 2.983e-02],
         [-5.060e-03],
         [ 3.052e-03],
         [ 2.569e-02],
         [ 3.012e-03],
         [ 4.141e-02]],

        [[-3.056e-02],
         [ 8.227e-03],
         [-6.868e-02],
         [ 1.502e-02],
         [ 8.272e-02],
         [ 1.839e-02],
         [-1.598e-02],
         [-5.856e-02],
         [-5.449e-03],
         [-9.761e-03]],

        [[-1.292e-02],
         [ 5.820e-02],
         [-4.486e-02],
         [-6.255e-02],
         [ 5.999e-02],
         [-9.855e-02],
         [-2.701e-02],
         [ 5.197e-02],
         [-6.877e-02],
         [-7.326e-02]],

        [[ 3.370e-02],
         [ 8.374e-02],
         [-6.722e-02],
         [ 5.388e-03],
         [ 3.149e-02],
         [-7.295e-03],
         [-2.873e-02],
         [-4.109e-02],
         [-4.805e-02],
         [-5.433e-02]],

        [[ 9.370e-03],
         [-5.454e-02],
         [-6.848e-02],
         [-4.568e-02],
         [ 5.115e-02],
         [ 3.970e-02],
         [ 9.335e-02],
         [ 1.166e-02],
         [ 5.785e-02],
         [ 1.256e-02]],

        [[ 9.112e-02],
         [ 4.853e-02],
         [ 5.243e-02],
         [-7.408e-02],
         [ 2.570e-02],
         [ 3.504e-02],
         [-2.236e-03],
         [ 7.616e-02],
         [-4.185e-02],
         [ 5.029e-02]],

        [[-2.759e-02],
         [ 2.269e-02],
         [ 3.158e-02],
         [ 2.314e-02],
         [ 2.581e-02],
         [ 5.627e-02],
         [-3.779e-02],
         [-5.413e-02],
         [ 1.746e-02],
         [ 4.531e-02]],

        [[-6.856e-02],
         [-3.578e-02],
         [-1.520e-03],
         [ 3.166e-02],
         [ 1.426e-02],
         [ 5.290e-02],
         [-5.019e-04],
         [ 6.926e-02],
         [-1.001e-02],
         [-6.756e-03]],

        [[ 1.319e-02],
         [ 9.208e-02],
         [ 9.793e-03],
         [ 8.883e-04],
         [ 2.749e-02],
         [-4.497e-02],
         [-1.148e-02],
         [ 3.697e-02],
         [ 2.366e-02],
         [-4.842e-02]],

        [[ 2.012e-02],
         [ 6.044e-02],
         [ 2.327e-02],
         [-4.274e-02],
         [ 3.397e-02],
         [-2.062e-02],
         [-7.762e-02],
         [-6.584e-03],
         [-1.816e-02],
         [ 1.811e-02]],

        [[-1.186e-01],
         [-6.076e-02],
         [-5.881e-02],
         [ 1.926e-02],
         [-8.652e-02],
         [-3.030e-02],
         [ 2.153e-02],
         [ 4.204e-02],
         [-5.726e-02],
         [ 6.147e-02]],

        [[ 1.197e-01],
         [ 3.274e-02],
         [-8.880e-02],
         [ 8.662e-02],
         [-2.650e-02],
         [ 1.386e-02],
         [-6.001e-02],
         [-3.569e-02],
         [-1.449e-03],
         [ 5.275e-02]],

        [[-8.454e-03],
         [ 2.569e-02],
         [-7.299e-04],
         [-8.502e-03],
         [ 2.555e-03],
         [-2.751e-02],
         [ 6.965e-03],
         [ 3.728e-02],
         [ 5.215e-02],
         [ 5.872e-02]]], device='cuda:0')
s after update for 1 param tensor([[[0.900],
         [0.993],
         [1.391],
         [1.105],
         [0.903],
         [1.538],
         [1.577],
         [0.986],
         [0.811],
         [1.057]],

        [[1.000],
         [0.888],
         [0.847],
         [1.639],
         [1.370],
         [0.832],
         [1.650],
         [1.422],
         [1.157],
         [1.078]],

        [[1.143],
         [1.951],
         [2.149],
         [1.643],
         [1.451],
         [1.051],
         [1.268],
         [1.048],
         [1.369],
         [0.878]],

        [[1.181],
         [1.383],
         [1.167],
         [1.711],
         [1.287],
         [1.265],
         [1.056],
         [1.504],
         [1.197],
         [1.110]],

        [[1.478],
         [0.917],
         [1.319],
         [1.558],
         [1.031],
         [1.542],
         [1.132],
         [1.261],
         [0.957],
         [1.558]],

        [[1.604],
         [1.280],
         [1.259],
         [1.103],
         [0.654],
         [1.231],
         [1.144],
         [1.587],
         [1.567],
         [0.820]],

        [[1.256],
         [0.706],
         [0.934],
         [0.908],
         [1.034],
         [1.774],
         [0.535],
         [1.458],
         [0.554],
         [1.578]],

        [[1.458],
         [1.205],
         [1.471],
         [1.448],
         [0.902],
         [0.709],
         [1.355],
         [1.038],
         [0.817],
         [0.565]],

        [[2.001],
         [1.693],
         [1.905],
         [0.991],
         [1.227],
         [1.231],
         [1.966],
         [1.393],
         [1.101],
         [1.311]],

        [[1.417],
         [1.431],
         [1.061],
         [0.751],
         [0.701],
         [1.045],
         [0.744],
         [1.680],
         [1.541],
         [0.989]],

        [[0.593],
         [1.541],
         [1.078],
         [0.749],
         [0.863],
         [1.038],
         [0.804],
         [1.099],
         [1.054],
         [1.143]],

        [[1.056],
         [1.255],
         [1.316],
         [0.804],
         [1.411],
         [0.602],
         [2.186],
         [1.375],
         [0.839],
         [1.239]],

        [[0.759],
         [1.060],
         [1.328],
         [1.724],
         [1.422],
         [0.622],
         [1.082],
         [0.907],
         [1.137],
         [1.430]],

        [[1.023],
         [1.389],
         [1.094],
         [0.757],
         [1.216],
         [0.968],
         [0.522],
         [1.287],
         [0.595],
         [0.941]],

        [[1.665],
         [1.510],
         [1.182],
         [1.386],
         [1.108],
         [1.493],
         [1.499],
         [1.385],
         [1.230],
         [0.927]],

        [[1.293],
         [1.465],
         [1.424],
         [1.617],
         [1.385],
         [1.043],
         [1.581],
         [0.828],
         [1.282],
         [0.843]],

        [[0.495],
         [1.055],
         [0.707],
         [0.774],
         [1.216],
         [1.663],
         [1.246],
         [0.838],
         [1.263],
         [1.537]],

        [[1.376],
         [1.554],
         [1.520],
         [1.608],
         [1.731],
         [1.272],
         [1.211],
         [0.680],
         [0.859],
         [1.145]],

        [[1.541],
         [1.056],
         [1.085],
         [1.163],
         [1.212],
         [1.105],
         [1.049],
         [0.803],
         [1.127],
         [1.245]],

        [[1.117],
         [1.052],
         [1.228],
         [1.277],
         [1.336],
         [0.568],
         [1.064],
         [1.403],
         [1.384],
         [0.934]]], device='cuda:0')
b after update for 1 param tensor([[[ 64.292],
         [ 67.531],
         [ 79.896],
         [ 71.205],
         [ 64.374],
         [ 84.033],
         [ 85.091],
         [ 67.277],
         [ 61.000],
         [ 69.665]],

        [[ 67.768],
         [ 63.838],
         [ 62.369],
         [ 86.750],
         [ 79.305],
         [ 61.791],
         [ 87.029],
         [ 80.806],
         [ 72.868],
         [ 70.357]],

        [[ 72.425],
         [ 94.642],
         [ 99.319],
         [ 86.835],
         [ 81.609],
         [ 69.472],
         [ 76.292],
         [ 69.348],
         [ 79.279],
         [ 63.479]],

        [[ 73.631],
         [ 79.678],
         [ 73.188],
         [ 88.622],
         [ 76.862],
         [ 76.190],
         [ 69.634],
         [ 83.089],
         [ 74.111],
         [ 71.372]],

        [[ 82.360],
         [ 64.872],
         [ 77.807],
         [ 84.575],
         [ 68.810],
         [ 84.133],
         [ 72.097],
         [ 76.094],
         [ 66.272],
         [ 84.565]],

        [[ 85.796],
         [ 76.653],
         [ 76.025],
         [ 71.144],
         [ 54.811],
         [ 75.165],
         [ 72.478],
         [ 85.346],
         [ 84.816],
         [ 61.339]],

        [[ 75.932],
         [ 56.922],
         [ 65.488],
         [ 64.551],
         [ 68.900],
         [ 90.237],
         [ 49.556],
         [ 81.797],
         [ 50.411],
         [ 85.116]],

        [[ 81.797],
         [ 74.381],
         [ 82.160],
         [ 81.533],
         [ 64.336],
         [ 57.069],
         [ 78.854],
         [ 69.041],
         [ 61.236],
         [ 50.929]],

        [[ 95.830],
         [ 88.159],
         [ 93.501],
         [ 67.436],
         [ 75.047],
         [ 75.161],
         [ 95.009],
         [ 79.950],
         [ 71.078],
         [ 77.580]],

        [[ 80.664],
         [ 81.046],
         [ 69.778],
         [ 58.732],
         [ 56.709],
         [ 69.256],
         [ 58.443],
         [ 87.830],
         [ 84.103],
         [ 67.381]],

        [[ 52.169],
         [ 84.099],
         [ 70.358],
         [ 58.621],
         [ 62.949],
         [ 69.032],
         [ 60.763],
         [ 71.027],
         [ 69.544],
         [ 72.429]],

        [[ 69.623],
         [ 75.895],
         [ 77.726],
         [ 60.761],
         [ 80.470],
         [ 52.571],
         [100.169],
         [ 79.455],
         [ 62.069],
         [ 75.415]],

        [[ 59.027],
         [ 69.771],
         [ 78.086],
         [ 88.958],
         [ 80.788],
         [ 53.443],
         [ 70.468],
         [ 64.541],
         [ 72.257],
         [ 81.026]],

        [[ 68.538],
         [ 79.849],
         [ 70.855],
         [ 58.959],
         [ 74.719],
         [ 66.665],
         [ 48.945],
         [ 76.856],
         [ 52.282],
         [ 65.740]],

        [[ 87.411],
         [ 83.247],
         [ 73.670],
         [ 79.776],
         [ 71.310],
         [ 82.774],
         [ 82.962],
         [ 79.731],
         [ 75.156],
         [ 65.237]],

        [[ 77.028],
         [ 82.007],
         [ 80.851],
         [ 86.155],
         [ 79.724],
         [ 69.199],
         [ 85.190],
         [ 61.648],
         [ 76.716],
         [ 62.192]],

        [[ 47.690],
         [ 69.597],
         [ 56.969],
         [ 59.592],
         [ 74.717],
         [ 87.378],
         [ 75.614],
         [ 62.032],
         [ 76.145],
         [ 83.987]],

        [[ 79.470],
         [ 84.465],
         [ 83.527],
         [ 85.910],
         [ 89.131],
         [ 76.416],
         [ 74.551],
         [ 55.883],
         [ 62.799],
         [ 72.507]],

        [[ 84.105],
         [ 69.627],
         [ 70.588],
         [ 73.081],
         [ 74.584],
         [ 71.208],
         [ 69.395],
         [ 60.720],
         [ 71.925],
         [ 75.583]],

        [[ 71.614],
         [ 69.495],
         [ 75.090],
         [ 76.566],
         [ 78.314],
         [ 51.055],
         [ 69.875],
         [ 80.262],
         [ 79.694],
         [ 65.483]]], device='cuda:0')
clipping threshold 0.182971180234178
a after update for 1 param tensor([[ 0.023],
        [-0.044],
        [-0.052],
        [ 0.002],
        [ 0.032],
        [ 0.011],
        [-0.001],
        [-0.040],
        [-0.012],
        [ 0.022],
        [-0.005],
        [-0.013],
        [ 0.024],
        [ 0.033],
        [-0.004],
        [-0.000],
        [-0.027],
        [ 0.033],
        [ 0.100],
        [-0.052]], device='cuda:0')
s after update for 1 param tensor([[1.379],
        [1.487],
        [1.047],
        [1.313],
        [1.550],
        [1.653],
        [1.256],
        [0.773],
        [1.704],
        [1.448],
        [1.358],
        [1.410],
        [0.960],
        [1.213],
        [1.268],
        [1.330],
        [1.472],
        [1.561],
        [2.188],
        [0.914]], device='cuda:0')
b after update for 1 param tensor([[ 79.550],
        [ 82.622],
        [ 69.332],
        [ 77.628],
        [ 84.358],
        [ 87.108],
        [ 75.942],
        [ 59.582],
        [ 88.435],
        [ 81.532],
        [ 78.940],
        [ 80.464],
        [ 66.374],
        [ 74.633],
        [ 76.305],
        [ 78.150],
        [ 82.201],
        [ 84.645],
        [100.217],
        [ 64.768]], device='cuda:0')
clipping threshold 0.182971180234178
||w||^2 0.05703447162806617
exp ma of ||w||^2 0.052029603553060376
||w|| 0.23881890969532998
exp ma of ||w|| 0.22369482437162047
||w||^2 0.046754906585089934
exp ma of ||w||^2 0.04894669035261143
||w|| 0.216228829218238
exp ma of ||w|| 0.21632409722073756
||w||^2 0.07897058292052087
exp ma of ||w||^2 0.04716913019042846
||w|| 0.2810170509426801
exp ma of ||w|| 0.21161828629728532
||w||^2 0.02132508775058176
exp ma of ||w||^2 0.04554174428198209
||w|| 0.1460311191170627
exp ma of ||w|| 0.2081151426560369
||w||^2 0.05761224852679264
exp ma of ||w||^2 0.049856144377125454
||w|| 0.24002551640771996
exp ma of ||w|| 0.21683058088552654
cuda
Objective function 20.24 = squared loss an data 18.74 + 0.5*rho*h**2 1.023693 + alpha*h 0.000000 + L2reg 0.24 + L1reg 0.24 ; SHD = 63 ; DAG False
Proportion of microbatches that were clipped  0.7563398481666936
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 1.4308692450452583
iteration 1 in outer loop, alpha = 1.4308692450452583, rho = 1.0, h = 1.4308692450452583
cuda
4420
cuda
Objective function 22.29 = squared loss an data 18.74 + 0.5*rho*h**2 1.023693 + alpha*h 2.047387 + L2reg 0.24 + L1reg 0.24 ; SHD = 63 ; DAG False
||w||^2 520431088.08909607
exp ma of ||w||^2 2491936197.4473257
||w|| 22812.958775421834
exp ma of ||w|| 38972.22350625415
||w||^2 54.71587914680595
exp ma of ||w||^2 1578165.5848435012
||w|| 7.397018260542957
exp ma of ||w|| 116.67921364918024
||w||^2 0.05583399173558056
exp ma of ||w||^2 33947.672046483836
||w|| 0.23629217451193885
exp ma of ||w|| 3.0726384476617654
||w||^2 0.054005835827007825
exp ma of ||w||^2 0.04940537627648588
||w|| 0.23239155713366144
exp ma of ||w|| 0.21802475280488576
||w||^2 0.03710031690240205
exp ma of ||w||^2 0.044002486895525834
||w|| 0.19261442547847255
exp ma of ||w|| 0.2047983547052355
||w||^2 0.03524037438497533
exp ma of ||w||^2 0.05281425692322603
||w|| 0.1877241976543656
exp ma of ||w|| 0.22452079115665935
||w||^2 0.04788259683200124
exp ma of ||w||^2 0.051460641341701904
||w|| 0.21882092411833298
exp ma of ||w|| 0.22143647059212093
||w||^2 0.022712994645266233
exp ma of ||w||^2 0.051219517940703
||w|| 0.15070830980827246
exp ma of ||w|| 0.22032487034294157
||w||^2 0.01953565398764816
exp ma of ||w||^2 0.05058440059097198
||w|| 0.1397700038908498
exp ma of ||w|| 0.21962928083236963
||w||^2 0.0953176693318191
exp ma of ||w||^2 0.046753615295232365
||w|| 0.3087355977722995
exp ma of ||w|| 0.2111203186711902
||w||^2 0.036472935694637096
exp ma of ||w||^2 0.05643865601952419
||w|| 0.19097888808618899
exp ma of ||w|| 0.2298368608971282
||w||^2 0.04352838278533531
exp ma of ||w||^2 0.05640518949851371
||w|| 0.20863456757051385
exp ma of ||w|| 0.23212501944939823
cuda
Objective function 19.71 = squared loss an data 17.43 + 0.5*rho*h**2 0.424020 + alpha*h 1.317675 + L2reg 0.33 + L1reg 0.22 ; SHD = 50 ; DAG False
Proportion of microbatches that were clipped  0.7520963933892372
iteration 1 in inner loop, alpha 1.4308692450452583 rho 1.0 h 0.9208913029077088
4420
cuda
Objective function 23.53 = squared loss an data 17.43 + 0.5*rho*h**2 4.240204 + alpha*h 1.317675 + L2reg 0.33 + L1reg 0.22 ; SHD = 50 ; DAG False
||w||^2 5.32311054089761
exp ma of ||w||^2 446697.8563675629
||w|| 2.307186715655586
exp ma of ||w|| 31.72403519480133
||w||^2 0.044339433031691924
exp ma of ||w||^2 0.07964583206456488
||w|| 0.21056930695543433
exp ma of ||w|| 0.21500602731047747
v before min max tensor([[-5.845, -5.736,  0.080,  ..., -2.565, -5.451, 28.046],
        [-1.895, -1.409, 75.498,  ...,  5.849, 20.927, -7.915],
        [10.729, -0.828,  5.825,  ...,  5.254, -1.770, 12.232],
        ...,
        [-3.755, -5.538, -3.475,  ..., -1.276, -7.422, -6.159],
        [-0.243, -6.362, -4.037,  ..., -4.082, -2.373,  2.507],
        [-2.057, -0.661, -5.222,  ...,  1.718, -5.852, -5.714]],
       device='cuda:0')
v tensor([[1.000e-12, 1.000e-12, 8.030e-02,  ..., 1.000e-12, 1.000e-12,
         1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 5.849e+00, 1.000e+01,
         1.000e-12],
        [1.000e+01, 1.000e-12, 5.825e+00,  ..., 5.254e+00, 1.000e-12,
         1.000e+01],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         2.507e+00],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.718e+00, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([-4.349e+00,  3.042e+00, -3.358e-01, -7.832e+00, -4.642e+00, -4.125e+00,
         1.020e+01, -3.589e+00,  4.991e-02,  2.230e+00,  5.144e+00, -4.975e+00,
        -3.562e+00, -3.044e+00, -3.836e+00,  2.424e-02,  3.376e+01, -6.548e+00,
         2.497e+01, -1.801e-01, -5.554e-01,  4.924e+00,  1.671e+00, -2.872e+00,
         7.667e+00, -6.203e-02, -7.098e+00, -4.866e+00,  1.191e+01,  8.603e-01,
        -5.018e+00, -6.243e+00,  1.285e+00, -1.294e+00, -3.742e+00, -4.177e+00,
        -7.552e+00,  5.551e+00, -4.437e+00, -5.160e+00,  2.458e+01, -4.247e+00,
        -7.144e+00, -3.181e+00, -6.989e+00, -7.058e+00, -1.602e+00, -1.096e+00,
         2.038e+01, -4.912e+00, -3.181e+00,  3.344e+00,  7.380e-01, -4.773e+00,
        -5.159e+00,  8.965e-01, -3.983e+00, -6.334e+00,  7.022e+00,  3.171e+00,
         1.495e+00, -5.602e+00, -5.505e+00, -8.379e+00, -1.022e+00, -6.072e+00,
        -3.292e+00,  9.190e+00,  3.397e+00,  3.795e+00, -7.675e+00, -4.281e+00,
        -3.361e+00,  4.741e+00, -5.421e+00, -4.120e+00,  4.522e+00, -8.188e+00,
         1.046e+01,  3.385e+00, -5.548e+00, -7.835e+00,  1.656e+01, -7.181e-01,
        -4.187e+00, -1.983e+00, -4.700e+00,  1.230e+01,  1.877e+01,  2.163e+01,
         7.877e+01,  9.103e+00,  2.377e+01, -4.615e+00,  5.490e+00,  1.031e+01,
        -8.517e+00, -2.398e+00,  9.231e+00, -3.342e+00, -8.228e+00, -8.544e+00,
        -1.683e+00,  2.979e+01, -6.088e+00, -7.951e+00,  1.135e+01, -1.298e+00,
         9.464e-01,  8.205e+00, -7.896e+00, -7.154e+00, -3.701e+00, -1.464e-01,
         5.403e+00, -3.379e+00, -6.239e+00, -7.018e+00, -7.920e+00,  2.609e+01,
        -4.229e+00, -7.071e+00,  1.971e+00,  2.676e+01, -6.489e+00, -2.909e+00,
        -6.357e+00,  8.491e+00, -5.652e+00,  4.980e+00, -7.206e+00, -6.846e+00,
         6.378e+00, -4.619e+00, -5.592e+00,  5.476e+00, -6.778e+00, -7.088e+00,
        -4.861e+00, -4.868e+00, -3.600e+00,  6.588e+00, -7.198e+00, -1.993e+00,
        -3.031e+00, -3.982e+00, -6.179e+00,  7.612e+00, -4.149e+00, -5.605e+00,
        -5.525e+00, -5.883e+00, -1.071e+00, -4.362e+00, -2.347e+00, -1.273e+00,
        -2.007e+00, -9.097e+00,  2.883e+01, -4.847e+00, -6.106e+00, -4.346e-01,
        -1.417e+00, -5.559e+00, -6.482e+00, -6.136e+00, -4.261e+00, -1.070e+00,
         4.841e+00, -8.801e+00, -6.175e+00,  6.428e+00, -5.029e+00, -1.007e+00,
        -4.318e+00, -6.302e+00, -2.589e+00, -2.984e+00, -7.533e+00, -4.855e+00,
        -8.310e+00, -6.124e+00, -6.792e+00,  2.057e+01, -6.930e+00, -7.011e+00,
        -1.367e+00, -2.897e+00, -4.502e+00, -6.065e+00, -6.168e+00, -3.725e+00,
        -5.456e+00,  8.195e+00, -8.724e+00, -4.199e+00, -4.824e+00, -5.576e+00,
        -1.785e+00, -2.193e+00], device='cuda:0')
v tensor([1.000e-12, 3.042e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 4.991e-02, 2.230e+00, 5.144e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 2.424e-02, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 4.924e+00, 1.671e+00, 1.000e-12,
        7.667e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 8.603e-01,
        1.000e-12, 1.000e-12, 1.285e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 5.551e+00, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 3.344e+00, 7.380e-01, 1.000e-12,
        1.000e-12, 8.965e-01, 1.000e-12, 1.000e-12, 7.022e+00, 3.171e+00,
        1.495e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 9.190e+00, 3.397e+00, 3.795e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 4.741e+00, 1.000e-12, 1.000e-12, 4.522e+00, 1.000e-12,
        1.000e+01, 3.385e+00, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e+01, 9.103e+00, 1.000e+01, 1.000e-12, 5.490e+00, 1.000e+01,
        1.000e-12, 1.000e-12, 9.231e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        9.464e-01, 8.205e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        5.403e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.971e+00, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 8.491e+00, 1.000e-12, 4.980e+00, 1.000e-12, 1.000e-12,
        6.378e+00, 1.000e-12, 1.000e-12, 5.476e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 6.588e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 7.612e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        4.841e+00, 1.000e-12, 1.000e-12, 6.428e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 8.195e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12], device='cuda:0')
v before min max tensor([[[ 2.179e+00],
         [-2.589e+00],
         [-1.540e+00],
         [-9.809e-01],
         [-2.574e+00],
         [ 4.452e+00],
         [-9.515e+00],
         [-1.012e+00],
         [ 9.485e-01],
         [-2.729e+00]],

        [[ 3.920e+00],
         [-5.580e+00],
         [-7.305e+00],
         [ 1.066e+01],
         [-2.112e+00],
         [-5.962e-01],
         [-1.180e-01],
         [ 2.534e+01],
         [-3.858e+00],
         [ 3.014e+00]],

        [[-1.358e-01],
         [-4.560e+00],
         [-3.808e+00],
         [ 6.348e+00],
         [-3.589e+00],
         [-3.232e+00],
         [ 1.315e+00],
         [-8.120e+00],
         [ 1.231e+01],
         [-5.694e+00]],

        [[-4.986e+00],
         [-2.616e-01],
         [-6.465e+00],
         [-7.867e+00],
         [-4.329e+00],
         [ 5.683e+01],
         [-5.360e+00],
         [ 1.227e+00],
         [-7.638e+00],
         [-5.509e+00]],

        [[ 6.662e+00],
         [-5.500e+00],
         [-2.846e+00],
         [-7.948e+00],
         [ 3.099e+00],
         [ 6.969e+00],
         [ 7.466e+00],
         [-1.294e+00],
         [ 7.057e+01],
         [ 2.006e+00]],

        [[-7.548e+00],
         [-2.205e+00],
         [ 1.102e+00],
         [ 2.625e+00],
         [ 4.983e+00],
         [-5.625e+00],
         [ 7.954e+00],
         [ 2.072e+01],
         [-6.021e+00],
         [-6.302e+00]],

        [[-1.074e+00],
         [ 1.731e+00],
         [-2.549e+00],
         [-3.903e+00],
         [-3.722e+00],
         [ 1.654e+00],
         [-5.333e+00],
         [-5.586e+00],
         [ 5.012e+00],
         [-3.833e+00]],

        [[ 1.297e+00],
         [-1.551e+00],
         [-6.578e+00],
         [-6.110e+00],
         [-2.196e-01],
         [ 1.807e+01],
         [-2.835e+00],
         [-8.272e+00],
         [-1.315e+00],
         [ 1.530e+01]],

        [[-4.637e+00],
         [-2.851e+00],
         [ 3.839e+00],
         [-6.750e+00],
         [ 1.037e+00],
         [ 6.960e+00],
         [ 2.142e+01],
         [-7.475e+00],
         [-4.866e+00],
         [ 7.541e+00]],

        [[-5.189e+00],
         [-3.259e+00],
         [-7.069e+00],
         [-7.649e+00],
         [ 6.479e+00],
         [ 6.158e-02],
         [ 6.834e+00],
         [-2.815e+00],
         [-5.601e+00],
         [ 1.383e+00]],

        [[-4.912e+00],
         [ 6.983e+00],
         [ 3.924e+01],
         [-3.287e+00],
         [-6.763e+00],
         [ 5.503e+00],
         [-6.382e+00],
         [-4.729e+00],
         [-7.512e+00],
         [ 6.010e+00]],

        [[-5.468e+00],
         [ 8.207e+00],
         [-3.282e+00],
         [-6.195e+00],
         [ 6.149e+00],
         [-4.453e+00],
         [-4.449e+00],
         [-2.536e+00],
         [-3.663e+00],
         [-6.114e+00]],

        [[-1.245e+00],
         [-1.333e-01],
         [-3.863e+00],
         [-5.634e+00],
         [-9.101e+00],
         [ 6.876e-01],
         [-1.432e+00],
         [-3.738e-01],
         [ 6.869e+00],
         [ 7.598e-01]],

        [[-6.610e+00],
         [-6.113e+00],
         [-5.862e-01],
         [-8.582e+00],
         [ 3.784e+00],
         [-4.456e+00],
         [-6.627e+00],
         [-1.930e+00],
         [-8.861e-01],
         [-6.914e+00]],

        [[-5.777e+00],
         [ 1.410e+01],
         [-5.035e+00],
         [-5.345e+00],
         [ 1.785e-01],
         [-5.227e+00],
         [-5.356e+00],
         [ 5.570e+01],
         [ 1.649e+01],
         [-2.959e+00]],

        [[-4.724e+00],
         [-7.035e+00],
         [-5.338e+00],
         [ 7.773e+00],
         [-1.464e+00],
         [ 1.392e+01],
         [ 3.145e+01],
         [-7.156e+00],
         [-6.406e+00],
         [ 2.616e+00]],

        [[-3.979e+00],
         [-5.125e+00],
         [-1.262e-01],
         [ 2.247e+00],
         [-6.152e+00],
         [ 2.803e+00],
         [-3.766e+00],
         [-6.513e+00],
         [-7.594e-01],
         [-5.815e-01]],

        [[ 1.230e+01],
         [-7.068e+00],
         [-4.264e+00],
         [ 9.436e+00],
         [-8.478e+00],
         [-8.541e+00],
         [-5.342e+00],
         [-6.178e+00],
         [-6.525e+00],
         [ 3.828e+00]],

        [[-5.721e+00],
         [ 5.350e+00],
         [ 6.196e+00],
         [-7.303e+00],
         [-7.351e+00],
         [ 2.439e+00],
         [ 4.285e+00],
         [-4.580e-01],
         [-7.213e+00],
         [-6.220e+00]],

        [[-8.129e+00],
         [ 8.068e+00],
         [-9.193e+00],
         [-9.245e+00],
         [-4.175e+00],
         [-6.284e+00],
         [ 2.043e+01],
         [-3.343e+00],
         [-3.711e+00],
         [-4.601e+00]]], device='cuda:0')
v tensor([[[2.179e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.452e+00],
         [1.000e-12],
         [1.000e-12],
         [9.485e-01],
         [1.000e-12]],

        [[3.920e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [3.014e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.348e+00],
         [1.000e-12],
         [1.000e-12],
         [1.315e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.227e+00],
         [1.000e-12],
         [1.000e-12]],

        [[6.662e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.099e+00],
         [6.969e+00],
         [7.466e+00],
         [1.000e-12],
         [1.000e+01],
         [2.006e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.102e+00],
         [2.625e+00],
         [4.983e+00],
         [1.000e-12],
         [7.954e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.731e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.654e+00],
         [1.000e-12],
         [1.000e-12],
         [5.012e+00],
         [1.000e-12]],

        [[1.297e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [3.839e+00],
         [1.000e-12],
         [1.037e+00],
         [6.960e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [7.541e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.479e+00],
         [6.158e-02],
         [6.834e+00],
         [1.000e-12],
         [1.000e-12],
         [1.383e+00]],

        [[1.000e-12],
         [6.983e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [5.503e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.010e+00]],

        [[1.000e-12],
         [8.207e+00],
         [1.000e-12],
         [1.000e-12],
         [6.149e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.876e-01],
         [1.000e-12],
         [1.000e-12],
         [6.869e+00],
         [7.598e-01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.784e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.785e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.773e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [2.616e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.247e+00],
         [1.000e-12],
         [2.803e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [9.436e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.828e+00]],

        [[1.000e-12],
         [5.350e+00],
         [6.196e+00],
         [1.000e-12],
         [1.000e-12],
         [2.439e+00],
         [4.285e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [8.068e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[ 1.294],
        [-8.737],
        [-3.473],
        [-1.742],
        [18.245],
        [13.100],
        [-1.184],
        [-3.425],
        [-0.426],
        [-8.709],
        [ 0.810],
        [26.486],
        [ 4.598],
        [-6.178],
        [47.047],
        [-8.715],
        [11.854],
        [-3.953],
        [-3.732],
        [-7.426]], device='cuda:0')
v tensor([[1.294e+00],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [8.096e-01],
        [1.000e+01],
        [4.598e+00],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 0.033, -0.030, -0.166,  ..., -0.073,  0.024, -0.041],
        [-0.089, -0.053, -0.005,  ...,  0.189,  0.015,  0.025],
        [-0.007, -0.012,  0.041,  ..., -0.060,  0.060, -0.269],
        ...,
        [-0.003, -0.115,  0.009,  ...,  0.030, -0.093,  0.030],
        [ 0.007,  0.003,  0.116,  ...,  0.043,  0.022, -0.122],
        [ 0.024, -0.048, -0.065,  ...,  0.100,  0.106,  0.047]],
       device='cuda:0')
s after update for 1 param tensor([[1.233, 1.411, 1.801,  ..., 1.126, 1.115, 1.558],
        [1.856, 1.164, 2.010,  ..., 1.667, 1.657, 1.930],
        [1.389, 1.553, 1.553,  ..., 1.747, 0.891, 1.827],
        ...,
        [1.111, 1.417, 1.831,  ..., 0.917, 1.521, 1.760],
        [1.134, 1.341, 1.231,  ..., 1.612, 1.167, 1.894],
        [1.733, 1.729, 1.148,  ..., 1.467, 1.314, 1.201]], device='cuda:0')
b after update for 1 param tensor([[ 89.807,  96.042, 108.513,  ...,  85.819,  85.404, 100.941],
        [110.153,  87.231, 114.658,  ..., 104.404, 104.099, 112.336],
        [ 95.290, 100.768, 100.761,  ..., 106.884,  76.330, 109.292],
        ...,
        [ 85.243,  96.247, 109.424,  ...,  77.416,  99.734, 107.275],
        [ 86.120,  93.626,  89.703,  ..., 102.656,  87.351, 111.297],
        [106.439, 106.315,  86.624,  ...,  97.935,  92.702,  88.616]],
       device='cuda:0')
clipping threshold 0.18459897298868314
a after update for 1 param tensor([-2.392e-02, -6.369e-02, -2.644e-02,  2.263e-03,  6.052e-03, -2.481e-02,
         7.610e-02,  7.926e-02,  7.844e-02,  9.600e-02, -1.091e-01,  5.497e-02,
         1.334e-01, -5.004e-02,  1.308e-01,  5.987e-02,  5.035e-02,  1.227e-01,
        -1.079e-01, -9.139e-03, -7.217e-02,  5.243e-02, -4.876e-02,  2.498e-01,
        -4.344e-02,  8.936e-02, -1.239e-01, -4.094e-03, -1.211e-02,  1.470e-01,
         8.101e-02, -2.017e-02, -2.732e-02,  2.250e-02,  9.130e-02, -7.917e-02,
        -6.213e-02,  1.074e-02, -3.822e-02, -4.966e-02,  6.420e-02,  1.129e-01,
        -7.862e-02, -1.030e-01,  4.747e-03, -4.980e-02,  7.083e-03,  9.463e-02,
        -6.505e-02, -2.743e-02,  9.335e-02,  9.506e-02,  2.791e-02, -4.463e-02,
         3.842e-02,  8.637e-02,  2.355e-01, -2.315e-02,  2.865e-02, -3.213e-02,
        -2.011e-03, -1.784e-02, -1.958e-01, -1.864e-01,  8.679e-02, -1.830e-02,
         1.389e-01, -2.632e-02, -3.717e-02,  9.295e-02, -3.160e-02, -6.156e-02,
        -8.301e-02, -1.139e-01,  6.797e-02, -6.684e-03,  1.302e-01,  2.230e-01,
         2.010e-02,  4.184e-02,  4.628e-02, -3.083e-02, -7.677e-02,  3.882e-02,
        -8.770e-02,  5.955e-02, -1.497e-02, -1.881e-01,  2.841e-02, -2.243e-02,
         2.998e-02,  1.316e-02, -1.532e-01,  2.302e-02,  1.739e-02, -2.050e-02,
        -2.435e-01, -1.418e-01, -7.919e-03, -8.011e-02, -9.468e-03,  1.327e-01,
         1.493e-01,  9.134e-02, -1.377e-02, -2.046e-02,  1.040e-01, -8.622e-03,
        -7.658e-02,  5.606e-02, -1.281e-01, -6.848e-03, -1.645e-01, -4.098e-03,
        -1.018e-02,  7.154e-02,  2.207e-01,  1.190e-02, -1.457e-02, -9.694e-02,
         1.095e-01,  1.838e-01, -2.978e-04,  1.010e-03, -4.178e-02, -3.023e-01,
         2.063e-01,  3.871e-02,  3.216e-02, -3.277e-02,  2.751e-03, -3.995e-02,
        -2.820e-02, -1.742e-02, -1.439e-03, -2.056e-01,  5.896e-02, -1.216e-01,
         2.989e-01,  5.699e-03, -3.047e-02, -2.760e-02,  2.823e-02, -4.635e-02,
        -1.406e-01, -5.999e-03,  4.516e-02, -6.790e-02, -5.603e-02,  2.500e-02,
         7.122e-02,  1.121e-01, -2.030e-01,  4.178e-02, -2.961e-02, -3.229e-02,
        -3.854e-02, -1.964e-01,  7.761e-02,  1.152e-02,  1.702e-01,  1.762e-01,
         2.286e-01,  1.103e-02, -3.042e-03,  5.840e-02,  3.675e-02,  1.653e-01,
         3.705e-02,  4.211e-02, -1.212e-01,  5.133e-02, -1.068e-02, -1.784e-02,
         2.045e-02,  8.451e-02, -3.648e-02,  1.575e-01, -4.104e-02, -4.907e-03,
         9.942e-02,  9.074e-03,  8.564e-02,  9.824e-02,  3.805e-02,  3.546e-02,
        -1.413e-01,  6.920e-03, -2.087e-01, -1.211e-01, -1.378e-02,  6.809e-02,
         8.706e-02, -1.084e-01, -6.735e-02,  4.230e-02,  6.756e-02,  3.141e-02,
        -9.926e-03,  6.660e-02], device='cuda:0')
s after update for 1 param tensor([1.205, 1.099, 0.712, 1.603, 1.105, 1.534, 1.625, 1.529, 0.939, 1.139,
        1.062, 1.113, 1.401, 1.475, 1.172, 1.539, 1.703, 1.391, 1.708, 0.815,
        1.101, 1.420, 1.550, 1.518, 1.804, 1.486, 1.545, 1.487, 1.512, 1.421,
        1.294, 1.503, 1.771, 1.553, 1.535, 0.865, 1.622, 1.364, 1.174, 1.139,
        1.648, 1.362, 1.468, 1.459, 1.581, 1.444, 1.893, 1.366, 1.882, 1.837,
        1.064, 1.175, 1.010, 1.175, 1.530, 0.634, 1.331, 1.444, 1.887, 1.553,
        1.625, 1.239, 1.505, 1.721, 1.076, 1.391, 0.683, 1.448, 1.818, 1.175,
        1.575, 1.390, 1.237, 1.786, 1.375, 1.755, 1.665, 1.720, 1.776, 1.612,
        1.372, 1.653, 1.891, 1.327, 1.279, 1.081, 1.153, 1.935, 1.962, 1.795,
        1.691, 1.559, 1.735, 1.075, 1.522, 1.622, 1.744, 1.569, 2.093, 1.037,
        1.683, 1.755, 1.441, 1.701, 1.490, 1.697, 1.910, 1.407, 1.267, 1.434,
        1.711, 1.485, 0.878, 0.635, 1.703, 0.865, 1.309, 1.523, 1.962, 1.917,
        1.094, 1.466, 1.470, 2.084, 1.339, 1.768, 1.303, 1.713, 1.544, 1.813,
        1.480, 1.402, 1.707, 1.383, 1.143, 1.879, 1.824, 1.530, 1.370, 1.735,
        1.429, 1.408, 1.474, 1.229, 1.282, 0.814, 1.319, 1.831, 0.848, 1.249,
        1.175, 1.279, 1.080, 1.114, 1.387, 1.102, 1.121, 1.942, 1.904, 1.246,
        1.556, 1.278, 1.787, 1.258, 1.725, 1.370, 1.096, 1.446, 1.341, 1.824,
        1.388, 1.317, 1.096, 1.427, 1.220, 1.691, 0.861, 1.467, 1.600, 1.339,
        1.698, 1.684, 1.401, 1.645, 1.528, 1.458, 1.312, 1.408, 0.961, 1.240,
        1.263, 1.395, 1.133, 1.993, 1.783, 1.859, 1.604, 1.327, 0.828, 1.218],
       device='cuda:0')
b after update for 1 param tensor([ 88.771,  84.773,  68.257, 102.368,  84.994, 100.150, 103.069, 100.004,
         78.352,  86.304,  83.332,  85.299,  95.726,  98.206,  87.548, 100.311,
        105.538,  95.358, 105.686,  72.980,  84.866,  96.351, 100.673,  99.616,
        108.625,  98.588, 100.501,  98.591,  99.428,  96.400,  91.980,  99.142,
        107.623, 100.786, 100.172,  75.186, 102.995,  94.433,  87.610,  86.314,
        103.801,  94.383,  97.967,  97.662, 101.672,  97.186, 111.272,  94.514,
        110.938, 109.601,  83.406,  87.655,  81.280,  87.645, 100.015,  64.382,
         93.289,  97.177, 111.068, 100.773, 103.078,  90.017,  99.198, 106.078,
         83.877,  95.382,  66.820,  97.309, 109.020,  87.663, 101.468,  95.325,
         89.938, 108.052,  94.829, 107.123, 104.332, 106.057, 107.760, 102.655,
         94.716, 103.965, 111.207,  93.150,  91.443,  84.070,  86.815, 112.477,
        113.263, 108.332, 105.157, 100.954, 106.514,  83.833,  99.750, 102.994,
        106.800, 101.282, 116.981,  82.344, 104.891, 107.127,  97.054, 105.456,
         98.703, 105.327, 111.748,  95.903,  91.011,  96.843, 105.759,  98.535,
         75.770,  64.423, 105.529,  75.218,  92.519,  99.796, 113.275, 111.966,
         84.568,  97.919,  98.041, 116.738,  93.555, 107.522,  92.320, 105.822,
        100.493, 108.882,  98.369,  95.749, 105.654,  95.101,  86.448, 110.841,
        109.202, 100.008,  94.649, 106.502,  96.665,  95.965,  98.178,  89.635,
         91.548,  72.940,  92.869, 109.424,  74.448,  90.364,  87.643,  91.468,
         84.055,  85.338,  95.226,  84.871,  85.635, 112.697, 111.590,  90.254,
        100.870,  91.407, 108.103,  90.711, 106.220,  94.653,  84.644,  97.250,
         93.655, 109.197,  95.254,  92.787,  84.643,  96.611,  89.327, 105.141,
         75.043,  97.940, 102.273,  93.573, 105.374, 104.938,  95.699, 103.714,
         99.966,  97.646,  92.623,  95.946,  79.279,  90.029,  90.869,  95.516,
         86.064, 114.154, 107.975, 110.240, 102.401,  93.142,  73.564,  89.252],
       device='cuda:0')
clipping threshold 0.18459897298868314
a after update for 1 param tensor([[[-0.032],
         [-0.059],
         [-0.045],
         [ 0.356],
         [-0.079],
         [-0.013],
         [ 0.178],
         [-0.046],
         [ 0.017],
         [-0.108]],

        [[ 0.049],
         [-0.085],
         [-0.073],
         [-0.175],
         [ 0.071],
         [ 0.015],
         [ 0.015],
         [ 0.059],
         [ 0.022],
         [ 0.098]],

        [[ 0.031],
         [-0.011],
         [-0.006],
         [-0.097],
         [-0.158],
         [ 0.057],
         [ 0.002],
         [-0.034],
         [ 0.036],
         [ 0.045]],

        [[ 0.011],
         [-0.039],
         [-0.045],
         [-0.047],
         [-0.089],
         [-0.005],
         [ 0.034],
         [ 0.011],
         [-0.100],
         [-0.081]],

        [[-0.132],
         [ 0.188],
         [-0.059],
         [ 0.057],
         [-0.028],
         [ 0.026],
         [-0.029],
         [ 0.017],
         [ 0.112],
         [ 0.032]],

        [[ 0.083],
         [-0.031],
         [-0.007],
         [-0.085],
         [-0.304],
         [ 0.064],
         [-0.025],
         [-0.141],
         [ 0.118],
         [ 0.005]],

        [[-0.099],
         [-0.214],
         [ 0.076],
         [-0.041],
         [-0.017],
         [ 0.047],
         [ 0.012],
         [-0.142],
         [ 0.152],
         [-0.075]],

        [[ 0.075],
         [-0.136],
         [ 0.044],
         [-0.008],
         [ 0.087],
         [ 0.069],
         [ 0.091],
         [ 0.062],
         [-0.186],
         [-0.119]],

        [[-0.054],
         [ 0.200],
         [ 0.016],
         [-0.043],
         [ 0.070],
         [-0.072],
         [ 0.218],
         [-0.141],
         [-0.030],
         [ 0.044]],

        [[-0.051],
         [-0.016],
         [ 0.045],
         [ 0.073],
         [ 0.021],
         [-0.050],
         [ 0.071],
         [ 0.066],
         [-0.123],
         [-0.008]],

        [[-0.049],
         [-0.010],
         [-0.160],
         [-0.296],
         [-0.030],
         [ 0.254],
         [-0.005],
         [ 0.157],
         [ 0.140],
         [-0.077]],

        [[-0.042],
         [-0.089],
         [ 0.024],
         [ 0.001],
         [ 0.055],
         [ 0.069],
         [-0.285],
         [ 0.203],
         [-0.074],
         [ 0.004]],

        [[-0.060],
         [ 0.068],
         [-0.126],
         [ 0.095],
         [ 0.084],
         [-0.148],
         [-0.065],
         [-0.017],
         [ 0.299],
         [-0.202]],

        [[-0.038],
         [-0.081],
         [ 0.027],
         [-0.286],
         [-0.036],
         [ 0.198],
         [-0.023],
         [-0.144],
         [ 0.091],
         [-0.060]],

        [[ 0.024],
         [ 0.002],
         [ 0.002],
         [-0.029],
         [ 0.033],
         [-0.057],
         [-0.071],
         [ 0.020],
         [ 0.025],
         [ 0.258]],

        [[ 0.046],
         [ 0.053],
         [-0.003],
         [ 0.074],
         [-0.031],
         [-0.102],
         [ 0.094],
         [ 0.010],
         [-0.111],
         [ 0.082]],

        [[-0.011],
         [-0.040],
         [-0.090],
         [ 0.010],
         [-0.080],
         [-0.072],
         [ 0.005],
         [-0.008],
         [ 0.045],
         [-0.123]],

        [[ 0.117],
         [ 0.152],
         [-0.117],
         [-0.021],
         [ 0.171],
         [ 0.007],
         [ 0.147],
         [ 0.171],
         [-0.082],
         [ 0.128]],

        [[ 0.081],
         [-0.081],
         [-0.030],
         [-0.077],
         [ 0.009],
         [ 0.264],
         [ 0.026],
         [ 0.043],
         [ 0.053],
         [-0.069]],

        [[-0.020],
         [ 0.042],
         [-0.054],
         [-0.020],
         [ 0.164],
         [-0.010],
         [-0.036],
         [-0.024],
         [ 0.085],
         [ 0.048]]], device='cuda:0')
s after update for 1 param tensor([[[1.373],
         [1.354],
         [1.753],
         [1.588],
         [1.289],
         [1.680],
         [1.969],
         [1.783],
         [1.361],
         [1.268]],

        [[1.218],
         [1.742],
         [1.500],
         [1.956],
         [1.220],
         [1.144],
         [1.376],
         [1.324],
         [1.438],
         [2.181]],

        [[1.648],
         [1.130],
         [1.773],
         [1.568],
         [0.923],
         [1.486],
         [1.226],
         [1.679],
         [1.801],
         [1.526]],

        [[1.113],
         [0.744],
         [1.471],
         [1.682],
         [0.903],
         [2.020],
         [1.286],
         [1.139],
         [1.573],
         [1.282]],

        [[1.989],
         [1.739],
         [1.149],
         [1.635],
         [1.317],
         [1.761],
         [1.319],
         [1.493],
         [2.023],
         [1.520]],

        [[1.570],
         [0.676],
         [1.515],
         [1.384],
         [1.880],
         [1.350],
         [1.256],
         [1.637],
         [1.324],
         [1.325]],

        [[1.048],
         [1.237],
         [0.871],
         [0.809],
         [1.277],
         [1.662],
         [1.383],
         [1.490],
         [1.604],
         [1.181]],

        [[1.951],
         [1.400],
         [1.484],
         [1.423],
         [1.411],
         [1.604],
         [1.272],
         [1.724],
         [1.089],
         [1.594]],

        [[1.015],
         [1.766],
         [1.493],
         [1.383],
         [1.976],
         [1.618],
         [1.709],
         [1.976],
         [0.996],
         [1.867]],

        [[1.089],
         [1.180],
         [1.446],
         [1.570],
         [1.187],
         [1.345],
         [1.656],
         [0.991],
         [1.286],
         [1.197]],

        [[1.903],
         [1.064],
         [2.053],
         [1.928],
         [1.404],
         [1.857],
         [1.304],
         [1.540],
         [1.584],
         [1.570]],

        [[1.330],
         [1.761],
         [1.779],
         [1.275],
         [1.801],
         [1.334],
         [1.225],
         [1.593],
         [1.595],
         [1.251]],

        [[1.539],
         [1.419],
         [1.575],
         [1.154],
         [1.892],
         [1.067],
         [0.932],
         [1.801],
         [2.092],
         [1.817]],

        [[1.431],
         [1.655],
         [1.678],
         [1.863],
         [1.500],
         [1.215],
         [1.488],
         [1.382],
         [1.631],
         [1.417]],

        [[1.213],
         [1.352],
         [1.331],
         [1.516],
         [1.487],
         [1.160],
         [1.179],
         [1.671],
         [2.156],
         [1.937]],

        [[1.523],
         [1.680],
         [1.388],
         [1.615],
         [1.343],
         [1.589],
         [1.864],
         [1.470],
         [1.334],
         [1.107]],

        [[0.813],
         [1.641],
         [1.723],
         [1.162],
         [1.821],
         [1.081],
         [0.877],
         [1.354],
         [1.367],
         [1.095]],

        [[1.891],
         [1.473],
         [1.467],
         [1.782],
         [1.754],
         [1.755],
         [1.210],
         [1.660],
         [1.501],
         [1.568]],

        [[1.524],
         [1.913],
         [1.952],
         [1.538],
         [1.505],
         [1.745],
         [1.162],
         [1.647],
         [1.501],
         [1.748]],

        [[1.694],
         [1.479],
         [1.980],
         [2.165],
         [1.886],
         [1.339],
         [1.829],
         [1.205],
         [0.940],
         [0.945]]], device='cuda:0')
b after update for 1 param tensor([[[ 94.767],
         [ 94.090],
         [107.069],
         [101.915],
         [ 91.819],
         [104.811],
         [113.456],
         [107.962],
         [ 94.346],
         [ 91.058]],

        [[ 89.256],
         [106.717],
         [ 99.036],
         [113.080],
         [ 89.310],
         [ 86.474],
         [ 94.866],
         [ 93.030],
         [ 96.965],
         [119.426]],

        [[103.822],
         [ 85.968],
         [107.684],
         [101.262],
         [ 77.692],
         [ 98.562],
         [ 89.521],
         [104.766],
         [108.521],
         [ 99.891]],

        [[ 85.298],
         [ 69.769],
         [ 98.085],
         [104.888],
         [ 76.854],
         [114.933],
         [ 91.701],
         [ 86.288],
         [101.424],
         [ 91.546]],

        [[114.051],
         [106.644],
         [ 86.681],
         [103.386],
         [ 92.800],
         [107.320],
         [ 92.856],
         [ 98.811],
         [115.006],
         [ 99.690]],

        [[101.333],
         [ 66.503],
         [ 99.520],
         [ 95.124],
         [110.881],
         [ 93.943],
         [ 90.636],
         [103.468],
         [ 93.029],
         [ 93.078]],

        [[ 82.765],
         [ 89.936],
         [ 75.464],
         [ 72.723],
         [ 91.397],
         [104.240],
         [ 95.084],
         [ 98.707],
         [102.429],
         [ 87.862]],

        [[112.939],
         [ 95.667],
         [ 98.521],
         [ 96.475],
         [ 96.065],
         [102.417],
         [ 91.202],
         [106.161],
         [ 84.388],
         [102.103]],

        [[ 81.471],
         [107.464],
         [ 98.813],
         [ 95.080],
         [113.666],
         [102.874],
         [105.711],
         [113.662],
         [ 80.688],
         [110.503]],

        [[ 84.393],
         [ 87.829],
         [ 97.241],
         [101.316],
         [ 88.100],
         [ 93.792],
         [104.070],
         [ 80.485],
         [ 91.690],
         [ 88.467]],

        [[111.545],
         [ 83.410],
         [115.870],
         [112.278],
         [ 95.822],
         [110.196],
         [ 92.344],
         [100.351],
         [101.763],
         [101.309]],

        [[ 93.254],
         [107.323],
         [107.854],
         [ 91.314],
         [108.510],
         [ 93.388],
         [ 89.501],
         [102.063],
         [102.130],
         [ 90.452]],

        [[100.321],
         [ 96.310],
         [101.485],
         [ 86.862],
         [111.240],
         [ 83.511],
         [ 78.077],
         [108.507],
         [116.945],
         [108.993]],

        [[ 96.740],
         [104.024],
         [104.748],
         [110.376],
         [ 99.035],
         [ 89.151],
         [ 98.633],
         [ 95.049],
         [103.265],
         [ 96.244]],

        [[ 89.047],
         [ 94.022],
         [ 93.293],
         [ 99.549],
         [ 98.592],
         [ 87.109],
         [ 87.812],
         [104.530],
         [118.740],
         [112.539]],

        [[ 99.779],
         [104.818],
         [ 95.253],
         [102.776],
         [ 93.703],
         [101.944],
         [110.399],
         [ 98.048],
         [ 93.412],
         [ 85.091]],

        [[ 72.917],
         [103.573],
         [106.144],
         [ 87.157],
         [109.136],
         [ 84.071],
         [ 75.721],
         [ 94.102],
         [ 94.531],
         [ 84.621]],

        [[111.197],
         [ 98.127],
         [ 97.946],
         [107.946],
         [107.101],
         [107.124],
         [ 88.964],
         [104.192],
         [ 99.069],
         [101.255]],

        [[ 99.841],
         [111.841],
         [112.977],
         [100.285],
         [ 99.212],
         [106.812],
         [ 87.183],
         [103.776],
         [ 99.067],
         [106.921]],

        [[105.254],
         [ 98.339],
         [113.799],
         [118.973],
         [111.044],
         [ 93.569],
         [109.351],
         [ 88.782],
         [ 78.415],
         [ 78.599]]], device='cuda:0')
clipping threshold 0.18459897298868314
a after update for 1 param tensor([[ 0.017],
        [-0.028],
        [-0.014],
        [-0.087],
        [ 0.036],
        [-0.081],
        [ 0.015],
        [ 0.042],
        [-0.106],
        [-0.120],
        [-0.073],
        [ 0.151],
        [ 0.173],
        [-0.023],
        [-0.174],
        [-0.175],
        [-0.019],
        [-0.051],
        [-0.111],
        [ 0.017]], device='cuda:0')
s after update for 1 param tensor([[1.583],
        [1.812],
        [0.928],
        [1.501],
        [1.509],
        [1.819],
        [1.461],
        [1.483],
        [1.374],
        [1.791],
        [1.535],
        [1.779],
        [1.653],
        [1.324],
        [2.097],
        [2.038],
        [1.985],
        [1.340],
        [1.425],
        [1.526]], device='cuda:0')
b after update for 1 param tensor([[101.746],
        [108.843],
        [ 77.915],
        [ 99.086],
        [ 99.334],
        [109.068],
        [ 97.730],
        [ 98.462],
        [ 94.801],
        [108.206],
        [100.198],
        [107.849],
        [103.971],
        [ 93.035],
        [117.095],
        [115.453],
        [113.937],
        [ 93.609],
        [ 96.532],
        [ 99.877]], device='cuda:0')
clipping threshold 0.18459897298868314
||w||^2 0.07057258916491545
exp ma of ||w||^2 0.05171598462607521
||w|| 0.26565501908474354
exp ma of ||w|| 0.22080508230181498
||w||^2 0.04661539793884061
exp ma of ||w||^2 0.06035484590231751
||w|| 0.21590599329069263
exp ma of ||w|| 0.23926031990276414
v before min max tensor([[-2.996,  1.732,  9.019,  ..., 20.631,  4.545, -4.359],
        [-4.546,  7.021, -6.877,  ..., -2.793, -3.440, -6.396],
        [-4.101, -6.637, 30.896,  ..., -6.292, -2.459,  3.707],
        ...,
        [-5.633, -0.636, -4.281,  ..., -6.832, -0.316, -7.582],
        [ 4.625, -1.510, -2.762,  ..., -0.874, -3.299, -3.180],
        [11.742, -5.701, -1.455,  ..., -3.572, -7.527,  4.360]],
       device='cuda:0')
v tensor([[1.000e-12, 1.732e+00, 9.019e+00,  ..., 1.000e+01, 4.545e+00,
         1.000e-12],
        [1.000e-12, 7.021e+00, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         3.707e+00],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [4.625e+00, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         4.360e+00]], device='cuda:0')
v before min max tensor([ 5.146e+00, -5.003e+00, -5.626e+00, -4.131e+00, -6.188e+00,  3.621e+00,
        -4.986e+00, -5.883e+00,  7.767e+00, -7.107e+00, -4.974e+00, -6.243e+00,
         3.676e+00, -2.066e+00, -5.644e+00, -7.709e+00, -4.499e+00, -6.058e+00,
        -7.264e+00,  5.680e+00,  2.248e+01, -2.915e+00, -5.184e+00,  7.305e+00,
        -2.583e+00, -3.981e+00,  5.555e+00, -5.672e+00,  1.337e+02, -6.381e+00,
        -5.527e+00, -1.664e+00,  2.113e+01, -7.196e+00, -2.427e+00, -5.374e+00,
        -3.852e+00, -4.925e+00, -3.117e+00, -5.325e+00, -9.822e+00, -6.106e+00,
        -5.176e+00, -4.063e+00, -2.542e+00, -7.937e+00, -6.265e+00, -5.997e+00,
         3.704e+00,  8.608e-01,  1.180e+00, -7.513e+00,  3.303e+01, -3.045e+00,
        -6.190e+00, -3.384e+00,  6.801e+00, -6.791e+00, -5.509e+00, -1.885e+00,
        -2.735e+00,  1.590e+00, -5.307e+00,  1.689e+01, -4.396e+00, -6.557e+00,
        -4.160e+00,  1.058e+01,  5.991e-01, -3.349e+00, -5.767e+00, -3.864e+00,
        -5.989e+00,  5.636e+00, -4.098e+00, -4.581e+00,  1.814e+01, -1.184e+00,
         6.189e+00,  2.810e+00,  1.933e+00, -7.359e+00, -1.656e+00, -4.259e+00,
        -6.040e+00, -4.385e+00,  6.617e+00, -6.380e+00, -7.215e+00, -6.426e+00,
        -5.524e+00, -1.824e+00, -5.423e+00,  4.125e+00,  1.337e+01, -3.741e+00,
         4.435e+00,  1.562e+01, -3.398e+00, -3.137e+00, -7.494e+00, -4.485e+00,
        -7.717e+00,  1.602e+01, -4.875e+00,  1.519e-01, -4.753e+00, -6.246e-01,
        -6.225e+00, -3.708e+00,  7.282e-01, -2.952e+00, -2.957e+00,  1.620e+01,
        -4.859e+00,  8.250e+00,  1.843e+00,  4.749e+00, -6.750e+00, -6.274e+00,
        -5.049e+00,  8.206e+00,  1.034e+01, -5.380e+00,  2.202e+01,  1.814e+01,
        -4.693e+00, -3.200e+00, -5.514e+00,  1.686e+00, -2.132e+00,  3.081e+00,
         7.484e+00, -5.379e+00, -1.300e-01, -3.157e+00, -6.934e+00, -2.046e+00,
         1.112e+01, -5.849e+00, -5.808e+00, -4.179e+00,  4.934e+00, -5.906e+00,
        -6.425e+00,  3.687e+00, -7.249e+00,  1.814e+00, -4.756e+00, -6.291e+00,
        -1.749e+00, -2.945e+00,  3.395e+00,  2.918e+01, -3.637e+00,  9.743e+00,
        -2.968e+00, -2.903e+00, -5.383e+00, -2.747e+00, -4.868e+00, -5.002e+00,
         4.698e-01, -4.517e+00,  3.326e-01, -4.418e+00, -4.139e+00,  5.739e+00,
        -2.490e+00, -5.797e+00, -5.167e+00, -3.723e+00,  2.703e+00, -2.912e+00,
        -2.338e+00,  1.985e+00, -5.902e+00, -3.763e+00, -2.225e+00,  3.665e+00,
         7.204e+00, -3.514e+00, -6.809e+00,  2.064e+00, -8.275e+00,  8.338e+00,
        -2.432e+00,  4.032e+01, -7.105e+00, -5.752e+00, -4.589e+00, -3.830e+00,
         1.097e+00, -6.126e+00, -6.039e+00, -6.666e+00, -5.505e+00, -7.401e+00,
        -7.500e+00, -1.103e+00], device='cuda:0')
v tensor([5.146e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.621e+00,
        1.000e-12, 1.000e-12, 7.767e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        3.676e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 5.680e+00, 1.000e+01, 1.000e-12, 1.000e-12, 7.305e+00,
        1.000e-12, 1.000e-12, 5.555e+00, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        3.704e+00, 8.608e-01, 1.180e+00, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 6.801e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.590e+00, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 5.991e-01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 5.636e+00, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        6.189e+00, 2.810e+00, 1.933e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 6.617e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 4.125e+00, 1.000e+01, 1.000e-12,
        4.435e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.519e-01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 7.282e-01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 8.250e+00, 1.843e+00, 4.749e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 8.206e+00, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.686e+00, 1.000e-12, 3.081e+00,
        7.484e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 4.934e+00, 1.000e-12,
        1.000e-12, 3.687e+00, 1.000e-12, 1.814e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 3.395e+00, 1.000e+01, 1.000e-12, 9.743e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        4.698e-01, 1.000e-12, 3.326e-01, 1.000e-12, 1.000e-12, 5.739e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.703e+00, 1.000e-12,
        1.000e-12, 1.985e+00, 1.000e-12, 1.000e-12, 1.000e-12, 3.665e+00,
        7.204e+00, 1.000e-12, 1.000e-12, 2.064e+00, 1.000e-12, 8.338e+00,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.097e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12], device='cuda:0')
v before min max tensor([[[-4.930e+00],
         [-4.167e+00],
         [ 3.154e+00],
         [-6.516e+00],
         [-6.671e-01],
         [-3.719e+00],
         [-7.503e+00],
         [-3.763e+00],
         [ 5.249e-02],
         [ 5.080e+00]],

        [[ 1.103e+00],
         [ 8.410e+00],
         [-2.194e+00],
         [-3.140e+00],
         [ 1.390e+01],
         [ 2.134e+01],
         [-7.903e+00],
         [-4.313e+00],
         [-5.559e+00],
         [ 9.285e+00]],

        [[ 1.813e+00],
         [-5.371e+00],
         [-8.475e+00],
         [ 8.511e-01],
         [-5.821e-01],
         [-8.039e+00],
         [ 7.491e-01],
         [ 8.673e+00],
         [-3.571e+00],
         [-4.846e-01]],

        [[-5.146e+00],
         [ 1.828e+00],
         [ 1.993e+00],
         [ 4.221e+00],
         [-7.134e+00],
         [-2.926e+00],
         [-5.504e+00],
         [-4.977e+00],
         [ 2.466e+01],
         [-5.097e+00]],

        [[-9.532e+00],
         [-6.751e+00],
         [-6.694e+00],
         [ 3.145e+00],
         [-3.252e+00],
         [ 3.455e+00],
         [-5.682e+00],
         [-2.525e+00],
         [-3.607e+00],
         [-4.232e+00]],

        [[-2.432e+00],
         [ 5.245e+00],
         [-2.841e+00],
         [ 6.096e+00],
         [-7.423e+00],
         [-1.239e+00],
         [-2.003e+00],
         [ 2.348e+01],
         [ 1.419e+01],
         [-3.956e+00]],

        [[ 3.387e+00],
         [-6.800e+00],
         [-1.632e+00],
         [ 1.686e+01],
         [-5.424e+00],
         [-5.152e+00],
         [-7.401e+00],
         [ 1.876e+01],
         [-3.176e-01],
         [-9.519e-01]],

        [[ 8.021e+00],
         [ 5.522e+00],
         [ 1.920e+01],
         [-7.906e+00],
         [-5.163e+00],
         [ 1.187e+01],
         [ 1.079e+01],
         [ 8.759e+00],
         [ 2.240e+01],
         [-7.991e+00]],

        [[-6.987e+00],
         [-5.618e+00],
         [ 1.733e+01],
         [-3.989e+00],
         [ 2.739e+01],
         [-3.109e+00],
         [-6.860e+00],
         [-5.570e+00],
         [-2.134e+00],
         [-5.827e+00]],

        [[-5.423e+00],
         [-7.187e+00],
         [-4.302e+00],
         [-1.262e+00],
         [-1.126e-01],
         [-3.924e+00],
         [-6.961e-01],
         [-6.680e+00],
         [-2.726e+00],
         [-3.103e+00]],

        [[-4.977e+00],
         [-6.795e-01],
         [ 2.137e+00],
         [-1.138e+00],
         [-4.750e+00],
         [ 4.006e+00],
         [-1.362e+00],
         [-3.870e+00],
         [ 1.750e+00],
         [-3.529e+00]],

        [[-6.750e+00],
         [-4.700e+00],
         [-1.687e+00],
         [ 1.139e+01],
         [-2.761e+00],
         [ 7.617e+00],
         [-8.580e+00],
         [-3.013e+00],
         [ 5.128e-01],
         [-1.307e+00]],

        [[ 5.139e+00],
         [-3.334e+00],
         [ 5.642e+00],
         [-6.627e+00],
         [ 9.272e+00],
         [-2.867e+00],
         [-1.802e+00],
         [-2.317e+00],
         [-6.306e+00],
         [-5.154e+00]],

        [[ 5.800e-01],
         [ 9.636e+00],
         [-7.532e+00],
         [-4.517e+00],
         [ 2.528e+01],
         [-7.695e+00],
         [-5.940e+00],
         [ 6.734e+00],
         [-5.043e+00],
         [ 2.238e+01]],

        [[-4.396e+00],
         [-3.477e+00],
         [-4.485e+00],
         [-3.637e+00],
         [-6.809e+00],
         [-7.246e-02],
         [-3.027e+00],
         [ 1.780e+00],
         [ 5.516e+00],
         [-8.373e+00]],

        [[-3.864e+00],
         [ 5.781e-03],
         [-2.158e-01],
         [-6.787e+00],
         [-1.541e+00],
         [-4.708e+00],
         [-3.305e+00],
         [-5.586e+00],
         [-6.815e+00],
         [ 1.447e+01]],

        [[-5.554e+00],
         [-6.246e+00],
         [-6.022e+00],
         [-7.762e+00],
         [ 3.288e+00],
         [-4.265e+00],
         [-7.081e+00],
         [-3.099e+00],
         [ 1.270e+01],
         [ 3.421e+00]],

        [[-5.474e+00],
         [-4.129e+00],
         [-6.252e+00],
         [-6.231e+00],
         [-2.210e+00],
         [ 1.879e+01],
         [-3.896e+00],
         [-5.543e+00],
         [-4.817e+00],
         [-4.747e+00]],

        [[-6.511e+00],
         [ 1.562e+01],
         [ 7.795e-01],
         [-1.244e+00],
         [-3.428e+00],
         [-2.854e+00],
         [ 8.524e+00],
         [-4.314e+00],
         [ 4.945e+00],
         [-2.103e+00]],

        [[-1.664e+00],
         [-5.655e+00],
         [-4.412e+00],
         [-7.066e+00],
         [ 2.128e+01],
         [ 4.801e+00],
         [-3.400e+00],
         [-3.345e+00],
         [-4.569e+00],
         [-5.382e+00]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [3.154e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.249e-02],
         [5.080e+00]],

        [[1.103e+00],
         [8.410e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [9.285e+00]],

        [[1.813e+00],
         [1.000e-12],
         [1.000e-12],
         [8.511e-01],
         [1.000e-12],
         [1.000e-12],
         [7.491e-01],
         [8.673e+00],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.828e+00],
         [1.993e+00],
         [4.221e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.145e+00],
         [1.000e-12],
         [3.455e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [5.245e+00],
         [1.000e-12],
         [6.096e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[3.387e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[8.021e+00],
         [5.522e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [8.759e+00],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [2.137e+00],
         [1.000e-12],
         [1.000e-12],
         [4.006e+00],
         [1.000e-12],
         [1.000e-12],
         [1.750e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [7.617e+00],
         [1.000e-12],
         [1.000e-12],
         [5.128e-01],
         [1.000e-12]],

        [[5.139e+00],
         [1.000e-12],
         [5.642e+00],
         [1.000e-12],
         [9.272e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[5.800e-01],
         [9.636e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [6.734e+00],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.780e+00],
         [5.516e+00],
         [1.000e-12]],

        [[1.000e-12],
         [5.781e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.288e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [3.421e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [7.795e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [8.524e+00],
         [1.000e-12],
         [4.945e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [4.801e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[-1.588],
        [ 8.161],
        [26.933],
        [-4.958],
        [-7.830],
        [-3.328],
        [ 4.223],
        [-0.845],
        [-5.209],
        [ 6.260],
        [-0.310],
        [-0.384],
        [13.430],
        [-5.675],
        [-3.440],
        [-4.554],
        [-6.361],
        [-8.606],
        [ 5.481],
        [-7.018]], device='cuda:0')
v tensor([[1.000e-12],
        [8.161e+00],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [4.223e+00],
        [1.000e-12],
        [1.000e-12],
        [6.260e+00],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [5.481e+00],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 0.034, -0.045, -0.146,  ..., -0.051,  0.027, -0.044],
        [-0.083, -0.049, -0.030,  ...,  0.127,  0.030,  0.026],
        [-0.002, -0.044,  0.019,  ..., -0.062,  0.059, -0.246],
        ...,
        [-0.023, -0.105,  0.002,  ...,  0.026, -0.068,  0.009],
        [-0.002, -0.002,  0.119,  ...,  0.000,  0.014, -0.065],
        [ 0.011, -0.032, -0.042,  ...,  0.091,  0.034,  0.012]],
       device='cuda:0')
s after update for 1 param tensor([[1.342, 0.880, 1.382,  ..., 1.439, 0.939, 1.042],
        [1.254, 1.006, 1.706,  ..., 1.925, 1.196, 1.719],
        [1.577, 1.546, 1.750,  ..., 1.244, 0.740, 1.476],
        ...,
        [1.100, 0.998, 1.089,  ..., 1.338, 0.672, 1.581],
        [1.327, 0.602, 1.357,  ..., 1.236, 0.888, 1.633],
        [1.862, 1.637, 1.349,  ..., 0.864, 1.559, 1.266]], device='cuda:0')
b after update for 1 param tensor([[ 87.888,  71.169,  89.170,  ...,  91.018,  73.497,  77.445],
        [ 84.971,  76.076,  99.090,  ..., 105.268,  82.960,  99.461],
        [ 95.274,  94.342, 100.362,  ...,  84.605,  65.276,  92.176],
        ...,
        [ 79.566,  75.797,  79.181,  ...,  87.746,  62.203,  95.380],
        [ 87.378,  58.839,  88.373,  ...,  84.328,  71.507,  96.955],
        [103.527,  97.075,  88.126,  ...,  70.519,  94.713,  85.372]],
       device='cuda:0')
clipping threshold 0.20133391334234418
a after update for 1 param tensor([-0.016, -0.048, -0.022, -0.006,  0.024, -0.040,  0.068,  0.063,  0.057,
         0.072, -0.088,  0.042,  0.128, -0.060,  0.093,  0.061,  0.041,  0.109,
        -0.090, -0.023, -0.051,  0.038, -0.055,  0.204, -0.011,  0.097, -0.099,
         0.011, -0.002,  0.101,  0.049, -0.032, -0.010,  0.011,  0.052, -0.072,
        -0.048,  0.006, -0.042, -0.032,  0.036,  0.098, -0.056, -0.085,  0.023,
        -0.048,  0.017,  0.108, -0.070, -0.031,  0.070,  0.057,  0.028, -0.049,
         0.018,  0.065,  0.205,  0.009,  0.006, -0.042, -0.022, -0.008, -0.170,
        -0.150,  0.077, -0.035,  0.104, -0.011, -0.023,  0.077,  0.000, -0.067,
        -0.067, -0.085,  0.042, -0.028,  0.089,  0.182, -0.019,  0.043,  0.059,
        -0.035, -0.054,  0.039, -0.094,  0.024,  0.005, -0.120,  0.022, -0.032,
         0.014,  0.010, -0.136,  0.023, -0.018, -0.003, -0.193, -0.104,  0.003,
        -0.091, -0.028,  0.118,  0.089,  0.068,  0.008, -0.019,  0.061,  0.007,
        -0.048,  0.060, -0.106, -0.015, -0.133, -0.025,  0.006,  0.058,  0.179,
         0.009,  0.011, -0.081,  0.071,  0.136, -0.003,  0.009, -0.022, -0.225,
         0.203,  0.019,  0.016, -0.053, -0.002, -0.017, -0.041, -0.010,  0.011,
        -0.166,  0.029, -0.117,  0.251,  0.003, -0.001, -0.040,  0.030, -0.009,
        -0.078, -0.001,  0.011, -0.054, -0.040,  0.026,  0.048,  0.093, -0.184,
         0.009, -0.045, -0.023, -0.036, -0.173,  0.070,  0.032,  0.146,  0.138,
         0.206,  0.002, -0.014,  0.032,  0.024,  0.117,  0.037,  0.043, -0.112,
         0.056, -0.009, -0.012,  0.019,  0.069, -0.040,  0.141, -0.066, -0.013,
         0.100,  0.041,  0.054,  0.086,  0.035,  0.025, -0.090, -0.005, -0.157,
        -0.116, -0.026,  0.092,  0.096, -0.099, -0.076,  0.019,  0.077,  0.019,
        -0.006,  0.057], device='cuda:0')
s after update for 1 param tensor([1.491, 1.386, 1.099, 0.931, 1.208, 1.022, 1.142, 1.709, 1.543, 1.398,
        1.014, 1.219, 1.833, 1.236, 1.105, 1.604, 1.847, 1.478, 1.610, 1.314,
        1.454, 1.169, 1.036, 2.203, 1.035, 1.292, 1.471, 1.119, 1.832, 1.339,
        1.080, 0.995, 1.680, 1.570, 1.608, 1.059, 0.766, 1.014, 1.601, 1.141,
        1.929, 1.252, 1.021, 0.826, 0.916, 1.580, 1.320, 1.171, 1.187, 1.308,
        1.118, 1.583, 1.598, 1.171, 1.211, 1.112, 1.808, 1.327, 1.075, 0.665,
        1.290, 1.102, 1.239, 1.549, 1.485, 1.373, 1.005, 1.796, 0.844, 1.308,
        1.314, 1.546, 1.235, 1.519, 1.297, 0.902, 1.336, 1.546, 1.898, 1.550,
        1.286, 1.679, 1.530, 1.178, 1.409, 1.152, 1.776, 1.296, 1.502, 1.358,
        1.082, 0.829, 1.522, 1.503, 1.738, 1.148, 1.822, 1.595, 1.459, 1.129,
        1.711, 1.221, 1.590, 1.519, 1.547, 0.732, 1.395, 1.230, 1.228, 1.333,
        0.836, 1.146, 1.343, 1.750, 1.035, 1.267, 1.567, 1.980, 1.365, 1.263,
        1.198, 1.477, 1.350, 1.152, 1.599, 2.142, 0.920, 1.512, 1.081, 1.170,
        0.697, 1.341, 1.318, 1.697, 1.363, 1.377, 1.356, 1.821, 2.009, 1.354,
        1.536, 0.873, 1.118, 1.641, 1.773, 1.583, 1.605, 1.503, 0.990, 1.435,
        1.215, 0.880, 1.520, 1.670, 1.482, 1.297, 0.580, 0.968, 1.598, 1.228,
        1.353, 1.283, 1.368, 1.017, 0.684, 1.079, 0.877, 1.628, 1.439, 1.219,
        1.200, 0.834, 0.988, 0.792, 0.873, 1.288, 1.298, 1.260, 1.018, 1.184,
        1.534, 1.847, 1.334, 1.779, 1.640, 1.643, 1.013, 1.788, 1.539, 1.123,
        0.987, 1.366, 0.553, 1.220, 1.227, 1.302, 1.103, 1.447, 1.521, 0.629],
       device='cuda:0')
b after update for 1 param tensor([ 92.633,  89.325,  79.540,  73.213,  83.390,  76.697,  81.064,  99.184,
         94.226,  89.714,  76.398,  83.745, 102.707,  84.355,  79.762,  96.070,
        103.091,  92.226,  96.260,  86.964,  91.474,  82.010,  77.224, 112.609,
         77.173,  86.227,  92.005,  80.257, 102.674,  87.803,  78.827,  75.659,
         98.322,  95.051,  96.194,  78.081,  66.417,  76.408,  95.979,  81.048,
        105.374,  84.869,  76.665,  68.968,  72.606,  95.358,  87.155,  82.090,
         82.651,  86.753,  80.229,  95.436,  95.907,  82.109,  83.501,  79.992,
        102.015,  87.390,  78.674,  61.846,  86.180,  79.638,  84.438,  94.433,
         92.438,  88.891,  76.055, 101.665,  69.694,  86.780,  86.976,  94.335,
         84.321,  93.491,  86.403,  72.038,  87.682,  94.318, 104.518,  94.455,
         86.015,  98.291,  93.838,  82.334,  90.064,  81.430, 101.098,  86.369,
         92.974,  88.400,  78.931,  69.081,  93.589,  93.020, 100.025,  81.268,
        102.404,  95.819,  91.638,  80.625,  99.248,  83.816,  95.672,  93.504,
         94.374,  64.914,  89.610,  84.129,  84.082,  87.595,  69.370,  81.212,
         87.903, 100.362,  77.190,  85.386,  94.969, 106.763,  88.643,  85.266,
         83.026,  92.205,  88.139,  81.429,  95.945, 111.038,  72.758,  93.282,
         78.890,  82.042,  63.341,  87.865,  87.093,  98.836,  88.584,  89.013,
         88.340, 102.372, 107.533,  88.277,  94.010,  70.871,  80.223,  97.176,
        101.006,  95.463,  96.104,  93.017,  75.465,  90.864,  83.615,  71.182,
         93.533,  98.030,  92.359,  86.404,  57.752,  74.646,  95.904,  84.059,
         88.232,  85.926,  88.724,  76.489,  62.763,  78.812,  71.058,  96.793,
         91.015,  83.771,  83.107,  69.276,  75.398,  67.532,  70.870,  86.098,
         86.429,  85.171,  76.560,  82.533,  93.972, 103.092,  87.624, 101.175,
         97.150,  97.236,  76.342, 101.434,  94.114,  80.395,  75.371,  88.665,
         56.414,  83.807,  84.039,  86.552,  79.675,  91.267,  93.566,  60.175],
       device='cuda:0')
clipping threshold 0.20133391334234418
a after update for 1 param tensor([[[-0.037],
         [-0.039],
         [-0.024],
         [ 0.310],
         [-0.072],
         [-0.011],
         [ 0.150],
         [-0.039],
         [ 0.038],
         [-0.064]],

        [[ 0.035],
         [-0.065],
         [-0.064],
         [-0.158],
         [ 0.053],
         [-0.014],
         [ 0.024],
         [ 0.045],
         [ 0.011],
         [ 0.081]],

        [[ 0.032],
         [-0.007],
         [ 0.012],
         [-0.098],
         [-0.147],
         [ 0.080],
         [ 0.004],
         [-0.010],
         [ 0.045],
         [ 0.039]],

        [[ 0.023],
         [-0.001],
         [-0.033],
         [-0.047],
         [-0.079],
         [ 0.006],
         [-0.013],
         [-0.005],
         [-0.083],
         [-0.065]],

        [[-0.099],
         [ 0.155],
         [-0.072],
         [ 0.010],
         [-0.022],
         [ 0.050],
         [-0.037],
         [-0.003],
         [ 0.077],
         [ 0.030]],

        [[ 0.074],
         [-0.016],
         [ 0.005],
         [-0.053],
         [-0.252],
         [ 0.092],
         [-0.017],
         [-0.086],
         [ 0.105],
         [-0.013]],

        [[-0.082],
         [-0.158],
         [ 0.082],
         [-0.019],
         [-0.009],
         [ 0.051],
         [ 0.028],
         [-0.097],
         [ 0.111],
         [-0.052]],

        [[ 0.069],
         [-0.128],
         [ 0.041],
         [ 0.009],
         [ 0.062],
         [ 0.053],
         [ 0.102],
         [ 0.053],
         [-0.133],
         [-0.101]],

        [[-0.025],
         [ 0.175],
         [ 0.011],
         [-0.035],
         [ 0.051],
         [-0.034],
         [ 0.196],
         [-0.109],
         [-0.015],
         [ 0.016]],

        [[-0.044],
         [-0.007],
         [ 0.037],
         [ 0.057],
         [ 0.030],
         [-0.033],
         [ 0.053],
         [ 0.080],
         [-0.113],
         [-0.014]],

        [[-0.041],
         [-0.001],
         [-0.148],
         [-0.269],
         [-0.033],
         [ 0.192],
         [-0.001],
         [ 0.102],
         [ 0.077],
         [-0.062]],

        [[-0.071],
         [-0.063],
         [ 0.003],
         [-0.015],
         [ 0.047],
         [ 0.077],
         [-0.230],
         [ 0.181],
         [-0.056],
         [ 0.001]],

        [[-0.032],
         [ 0.044],
         [-0.088],
         [ 0.083],
         [ 0.070],
         [-0.131],
         [-0.070],
         [ 0.006],
         [ 0.272],
         [-0.166]],

        [[-0.034],
         [-0.059],
         [ 0.039],
         [-0.217],
         [-0.030],
         [ 0.142],
         [-0.002],
         [-0.124],
         [ 0.075],
         [-0.032]],

        [[ 0.023],
         [ 0.001],
         [-0.001],
         [-0.020],
         [ 0.036],
         [-0.044],
         [-0.059],
         [ 0.007],
         [ 0.008],
         [ 0.205]],

        [[ 0.034],
         [ 0.056],
         [-0.003],
         [ 0.056],
         [-0.034],
         [-0.077],
         [ 0.073],
         [ 0.009],
         [-0.084],
         [ 0.064]],

        [[-0.002],
         [-0.024],
         [-0.069],
         [-0.001],
         [-0.044],
         [-0.035],
         [-0.010],
         [ 0.010],
         [ 0.014],
         [-0.109]],

        [[ 0.100],
         [ 0.144],
         [-0.102],
         [ 0.035],
         [ 0.127],
         [-0.029],
         [ 0.132],
         [ 0.146],
         [-0.061],
         [ 0.111]],

        [[ 0.078],
         [-0.037],
         [-0.011],
         [-0.059],
         [ 0.021],
         [ 0.216],
         [ 0.025],
         [ 0.026],
         [ 0.079],
         [-0.033]],

        [[-0.013],
         [ 0.007],
         [-0.045],
         [-0.009],
         [ 0.112],
         [-0.016],
         [-0.028],
         [-0.018],
         [ 0.036],
         [ 0.046]]], device='cuda:0')
s after update for 1 param tensor([[[0.973],
         [0.814],
         [1.613],
         [1.359],
         [0.519],
         [0.742],
         [1.467],
         [1.332],
         [1.001],
         [1.584]],

        [[0.954],
         [1.427],
         [0.447],
         [1.374],
         [1.291],
         [2.032],
         [1.733],
         [1.014],
         [1.345],
         [1.326]],

        [[1.096],
         [1.089],
         [1.798],
         [1.038],
         [1.150],
         [1.570],
         [1.320],
         [1.639],
         [1.123],
         [1.011]],

        [[1.227],
         [1.751],
         [1.385],
         [1.587],
         [1.396],
         [1.261],
         [1.856],
         [1.008],
         [2.124],
         [1.310]],

        [[1.901],
         [1.500],
         [1.338],
         [1.583],
         [0.664],
         [1.444],
         [1.504],
         [1.378],
         [1.466],
         [0.831]],

        [[1.219],
         [1.063],
         [1.467],
         [1.418],
         [1.609],
         [1.346],
         [0.854],
         [1.606],
         [1.688],
         [1.142]],

        [[1.568],
         [1.385],
         [1.225],
         [1.529],
         [1.064],
         [1.584],
         [1.548],
         [1.294],
         [1.287],
         [1.336]],

        [[1.618],
         [1.631],
         [1.804],
         [1.560],
         [1.026],
         [1.527],
         [1.412],
         [2.173],
         [1.621],
         [1.560]],

        [[1.395],
         [1.574],
         [1.700],
         [1.794],
         [1.526],
         [1.551],
         [1.468],
         [1.302],
         [1.004],
         [1.186]],

        [[1.226],
         [1.410],
         [0.879],
         [1.421],
         [1.206],
         [0.889],
         [0.763],
         [1.305],
         [0.912],
         [1.376]],

        [[1.836],
         [0.835],
         [1.357],
         [0.956],
         [1.150],
         [1.504],
         [1.331],
         [1.605],
         [1.174],
         [1.083]],

        [[1.425],
         [1.111],
         [1.178],
         [1.495],
         [0.725],
         [1.447],
         [2.017],
         [1.057],
         [0.972],
         [0.896]],

        [[1.283],
         [1.435],
         [1.184],
         [1.498],
         [1.898],
         [0.738],
         [0.925],
         [1.438],
         [1.238],
         [1.544]],

        [[0.654],
         [1.786],
         [1.732],
         [1.512],
         [1.676],
         [1.544],
         [1.322],
         [1.183],
         [1.594],
         [1.754]],

        [[0.871],
         [0.984],
         [0.928],
         [1.178],
         [1.384],
         [0.593],
         [1.449],
         [1.071],
         [1.881],
         [1.669]],

        [[1.201],
         [1.039],
         [0.794],
         [1.359],
         [1.177],
         [1.193],
         [1.457],
         [1.482],
         [1.360],
         [1.793]],

        [[1.146],
         [1.255],
         [1.609],
         [1.783],
         [1.610],
         [1.320],
         [1.478],
         [1.071],
         [1.589],
         [1.537]],

        [[1.307],
         [1.557],
         [1.235],
         [1.723],
         [1.798],
         [2.114],
         [1.328],
         [1.320],
         [0.981],
         [1.152]],

        [[1.272],
         [1.845],
         [1.559],
         [1.569],
         [1.184],
         [1.241],
         [1.555],
         [1.063],
         [1.215],
         [1.224]],

        [[1.312],
         [1.587],
         [1.247],
         [1.406],
         [1.762],
         [1.845],
         [1.264],
         [1.546],
         [1.052],
         [1.116]]], device='cuda:0')
b after update for 1 param tensor([[[ 74.832],
         [ 68.433],
         [ 96.345],
         [ 88.455],
         [ 54.679],
         [ 65.355],
         [ 91.889],
         [ 87.567],
         [ 75.886],
         [ 95.474]],

        [[ 74.094],
         [ 90.615],
         [ 50.696],
         [ 88.929],
         [ 86.209],
         [108.153],
         [ 99.857],
         [ 76.396],
         [ 87.982],
         [ 87.366]],

        [[ 79.411],
         [ 79.156],
         [101.725],
         [ 77.305],
         [ 81.354],
         [ 95.048],
         [ 87.177],
         [ 97.127],
         [ 80.387],
         [ 76.279]],

        [[ 84.021],
         [100.377],
         [ 89.293],
         [ 95.570],
         [ 89.634],
         [ 85.192],
         [103.341],
         [ 76.167],
         [110.551],
         [ 86.846]],

        [[104.609],
         [ 92.909],
         [ 87.738],
         [ 95.462],
         [ 61.797],
         [ 91.151],
         [ 93.044],
         [ 89.045],
         [ 91.850],
         [ 69.143]],

        [[ 83.750],
         [ 78.207],
         [ 91.876],
         [ 90.327],
         [ 96.236],
         [ 88.003],
         [ 70.116],
         [ 96.135],
         [ 98.556],
         [ 81.072]],

        [[ 95.005],
         [ 89.284],
         [ 83.970],
         [ 93.819],
         [ 78.245],
         [ 95.493],
         [ 94.394],
         [ 86.302],
         [ 86.051],
         [ 87.683]],

        [[ 96.493],
         [ 96.898],
         [101.905],
         [ 94.766],
         [ 76.843],
         [ 93.732],
         [ 90.152],
         [111.820],
         [ 96.575],
         [ 94.756]],

        [[ 89.600],
         [ 95.191],
         [ 98.922],
         [101.619],
         [ 93.718],
         [ 94.484],
         [ 91.909],
         [ 86.549],
         [ 76.015],
         [ 82.609]],

        [[ 83.990],
         [ 90.092],
         [ 71.131],
         [ 90.438],
         [ 83.308],
         [ 71.538],
         [ 66.269],
         [ 86.657],
         [ 72.435],
         [ 88.995]],

        [[102.802],
         [ 69.342],
         [ 88.373],
         [ 74.170],
         [ 81.343],
         [ 93.052],
         [ 87.522],
         [ 96.109],
         [ 82.201],
         [ 78.941]],

        [[ 90.569],
         [ 79.973],
         [ 82.328],
         [ 92.750],
         [ 64.608],
         [ 91.261],
         [107.742],
         [ 78.005],
         [ 74.786],
         [ 71.825]],

        [[ 85.920],
         [ 90.882],
         [ 82.537],
         [ 92.861],
         [104.516],
         [ 65.178],
         [ 72.966],
         [ 90.980],
         [ 84.406],
         [ 94.280]],

        [[ 61.351],
         [101.396],
         [ 99.849],
         [ 93.288],
         [ 98.223],
         [ 94.266],
         [ 87.238],
         [ 82.498],
         [ 95.774],
         [100.462]],

        [[ 70.811],
         [ 75.243],
         [ 73.087],
         [ 82.323],
         [ 89.237],
         [ 58.441],
         [ 91.308],
         [ 78.522],
         [104.046],
         [ 97.998]],

        [[ 83.152],
         [ 77.317],
         [ 67.580],
         [ 88.435],
         [ 82.308],
         [ 82.864],
         [ 91.568],
         [ 92.356],
         [ 88.473],
         [101.591]],

        [[ 81.197],
         [ 84.985],
         [ 96.218],
         [101.296],
         [ 96.251],
         [ 87.169],
         [ 92.238],
         [ 78.511],
         [ 95.622],
         [ 94.041]],

        [[ 86.732],
         [ 94.654],
         [ 84.305],
         [ 99.581],
         [101.720],
         [110.310],
         [ 87.424],
         [ 87.172],
         [ 75.131],
         [ 81.440]],

        [[ 85.573],
         [103.043],
         [ 94.719],
         [ 95.026],
         [ 82.550],
         [ 84.523],
         [ 94.605],
         [ 78.200],
         [ 83.606],
         [ 83.945]],

        [[ 86.908],
         [ 95.583],
         [ 84.724],
         [ 89.959],
         [100.696],
         [103.055],
         [ 85.303],
         [ 94.340],
         [ 77.796],
         [ 80.146]]], device='cuda:0')
clipping threshold 0.20133391334234418
a after update for 1 param tensor([[ 0.052],
        [-0.042],
        [-0.000],
        [-0.074],
        [-0.003],
        [-0.044],
        [ 0.031],
        [ 0.033],
        [-0.075],
        [-0.068],
        [-0.079],
        [ 0.092],
        [ 0.147],
        [ 0.009],
        [-0.132],
        [-0.138],
        [-0.044],
        [-0.044],
        [-0.096],
        [-0.021]], device='cuda:0')
s after update for 1 param tensor([[1.541],
        [1.715],
        [1.681],
        [1.206],
        [1.577],
        [1.349],
        [1.783],
        [0.635],
        [1.608],
        [1.763],
        [0.939],
        [1.666],
        [1.896],
        [1.340],
        [1.022],
        [1.621],
        [1.354],
        [1.696],
        [1.934],
        [1.581]], device='cuda:0')
b after update for 1 param tensor([[ 94.172],
        [ 99.355],
        [ 98.366],
        [ 83.323],
        [ 95.257],
        [ 88.104],
        [101.298],
        [ 60.439],
        [ 96.212],
        [100.724],
        [ 73.511],
        [ 97.916],
        [104.457],
        [ 87.830],
        [ 76.687],
        [ 96.602],
        [ 88.279],
        [ 98.810],
        [105.502],
        [ 95.394]], device='cuda:0')
clipping threshold 0.20133391334234418
||w||^2 0.025318634940826687
exp ma of ||w||^2 0.06182697229050894
||w|| 0.15911830485782172
exp ma of ||w|| 0.24141588575399492
||w||^2 0.04961942041095128
exp ma of ||w||^2 0.06070147019937021
||w|| 0.22275417035591338
exp ma of ||w|| 0.23962528029298044
||w||^2 0.06833308631841813
exp ma of ||w||^2 0.05823696227343147
||w|| 0.26140597988266856
exp ma of ||w|| 0.2350819619663812
||w||^2 0.07348973401161477
exp ma of ||w||^2 0.057430880232520666
||w|| 0.2710899002390439
exp ma of ||w|| 0.23334482223229341
||w||^2 0.08905392133594206
exp ma of ||w||^2 0.06213929599651374
||w|| 0.2984190364838377
exp ma of ||w|| 0.24215341454630598
||w||^2 0.059963636941697714
exp ma of ||w||^2 0.06019229976610833
||w|| 0.2448747372468171
exp ma of ||w|| 0.23859521349292614
||w||^2 0.04845964537666196
exp ma of ||w||^2 0.06241634776510532
||w|| 0.22013551593657477
exp ma of ||w|| 0.24298459193408112
cuda
Objective function 20.07 = squared loss an data 18.19 + 0.5*rho*h**2 0.764670 + alpha*h 0.559567 + L2reg 0.37 + L1reg 0.19 ; SHD = 54 ; DAG True
Proportion of microbatches that were clipped  0.755564483728405
iteration 2 in inner loop, alpha 1.4308692450452583 rho 10.0 h 0.3910677179089106
4420
cuda
Objective function 26.96 = squared loss an data 18.19 + 0.5*rho*h**2 7.646698 + alpha*h 0.559567 + L2reg 0.37 + L1reg 0.19 ; SHD = 54 ; DAG True
||w||^2 229424.69963029795
exp ma of ||w||^2 105796406.03674644
||w|| 478.98298469809754
exp ma of ||w|| 3206.775062572452
||w||^2 0.043069672243378224
exp ma of ||w||^2 0.6684385877198998
||w|| 0.20753234023490946
exp ma of ||w|| 0.22874983154587825
||w||^2 0.09338659654235788
exp ma of ||w||^2 0.06735260016093784
||w|| 0.3055922062853663
exp ma of ||w|| 0.25132428546944185
||w||^2 0.04198588638147116
exp ma of ||w||^2 0.05862856418255985
||w|| 0.20490457872256335
exp ma of ||w|| 0.2353854566416871
||w||^2 0.024201310339131313
exp ma of ||w||^2 0.06609670482815215
||w|| 0.15556770339351067
exp ma of ||w|| 0.24837421274775945
||w||^2 0.10889936883497009
exp ma of ||w||^2 0.07031593174408794
||w|| 0.32999904368796296
exp ma of ||w|| 0.2576135905117978
||w||^2 0.044737044484786
exp ma of ||w||^2 0.0679540838268375
||w|| 0.21151133417570323
exp ma of ||w|| 0.2529393977762801
||w||^2 0.108195887890506
exp ma of ||w||^2 0.0748580167404726
||w|| 0.32893143341813047
exp ma of ||w|| 0.2649658935723405
cuda
Objective function 20.63 = squared loss an data 19.15 + 0.5*rho*h**2 0.730197 + alpha*h 0.172916 + L2reg 0.41 + L1reg 0.16 ; SHD = 52 ; DAG True
Proportion of microbatches that were clipped  0.7567764973218634
iteration 3 in inner loop, alpha 1.4308692450452583 rho 100.0 h 0.12084673696470816
iteration 2 in outer loop, alpha = 13.515542941516074, rho = 100.0, h = 0.12084673696470816
cuda
4420
cuda
Objective function 22.09 = squared loss an data 19.15 + 0.5*rho*h**2 0.730197 + alpha*h 1.633309 + L2reg 0.41 + L1reg 0.16 ; SHD = 52 ; DAG True
||w||^2 14670214.437349828
exp ma of ||w||^2 830955317.7430136
||w|| 3830.1715937213344
exp ma of ||w|| 19586.63553049826
||w||^2 690.5568783137243
exp ma of ||w||^2 8382446.516149917
||w|| 26.278448932798987
exp ma of ||w|| 383.44838636052174
||w||^2 0.1163529165404878
exp ma of ||w||^2 12955.99846653877
||w|| 0.34110543317350983
exp ma of ||w|| 1.1355444348839079
||w||^2 0.11469108653187322
exp ma of ||w||^2 738.8590992686242
||w|| 0.33866072481448634
exp ma of ||w|| 0.3739814146727061
||w||^2 0.030968127999346486
exp ma of ||w||^2 0.06296382126808865
||w|| 0.1759776349407688
exp ma of ||w|| 0.24266154065989107
||w||^2 0.10146912653519605
exp ma of ||w||^2 0.06946163125529152
||w|| 0.3185421895686599
exp ma of ||w|| 0.2573149333637121
||w||^2 0.05345614750023595
exp ma of ||w||^2 0.0689781184547808
||w|| 0.23120585524643608
exp ma of ||w|| 0.2546127520905783
||w||^2 0.055655118238953555
exp ma of ||w||^2 0.065061549551182
||w|| 0.23591337019964248
exp ma of ||w|| 0.24884462278047353
||w||^2 0.057890981660965096
exp ma of ||w||^2 0.06759500948282784
||w|| 0.24060544811156104
exp ma of ||w|| 0.2533950492761184
||w||^2 0.022625264357015198
exp ma of ||w||^2 0.06961698210061219
||w|| 0.15041696831479884
exp ma of ||w|| 0.2569672390556546
||w||^2 0.042226657738936205
exp ma of ||w||^2 0.07080379760465265
||w|| 0.20549125951956254
exp ma of ||w|| 0.25703585991028854
||w||^2 0.09236793800965613
exp ma of ||w||^2 0.07582696605578244
||w|| 0.3039209403934782
exp ma of ||w|| 0.2682994318820442
||w||^2 0.1287639056280858
exp ma of ||w||^2 0.07912265942090464
||w|| 0.3588368788573518
exp ma of ||w|| 0.2719341176739503
||w||^2 0.07008451411816051
exp ma of ||w||^2 0.07303399517548115
||w|| 0.2647347995979382
exp ma of ||w|| 0.26224311638467596
||w||^2 0.03820172774411156
exp ma of ||w||^2 0.0652180775688165
||w|| 0.195452622760892
exp ma of ||w|| 0.24788473212687573
cuda
Objective function 21.34 = squared loss an data 19.28 + 0.5*rho*h**2 0.332774 + alpha*h 1.102613 + L2reg 0.46 + L1reg 0.16 ; SHD = 59 ; DAG True
Proportion of microbatches that were clipped  0.7553002103900307
iteration 1 in inner loop, alpha 13.515542941516074 rho 100.0 h 0.0815811357215992
4420
cuda
Objective function 24.33 = squared loss an data 19.28 + 0.5*rho*h**2 3.327741 + alpha*h 1.102613 + L2reg 0.46 + L1reg 0.16 ; SHD = 59 ; DAG True
||w||^2 0.22131018024995697
exp ma of ||w||^2 17384.838407010047
||w|| 0.47043615959017965
exp ma of ||w|| 1.2252998901374275
||w||^2 0.11309052243868145
exp ma of ||w||^2 159.26076884568573
||w|| 0.3362893433320203
exp ma of ||w|| 0.3388521760498352
||w||^2 0.10400859638956866
exp ma of ||w||^2 0.07488031519016045
||w|| 0.32250363779276764
exp ma of ||w|| 0.2670063548063095
||w||^2 0.0729293088728267
exp ma of ||w||^2 0.0789986615334639
||w|| 0.27005427023623735
exp ma of ||w|| 0.27288025013025113
||w||^2 0.07562309863643511
exp ma of ||w||^2 0.07891507821145158
||w|| 0.27499654295360715
exp ma of ||w|| 0.2740505986482086
||w||^2 0.09672115856186056
exp ma of ||w||^2 0.08351300971801265
||w|| 0.31100025492250094
exp ma of ||w|| 0.2799311388313283
cuda
Objective function 21.18 = squared loss an data 19.41 + 0.5*rho*h**2 0.622723 + alpha*h 0.476975 + L2reg 0.52 + L1reg 0.16 ; SHD = 64 ; DAG True
Proportion of microbatches that were clipped  0.7606776425674063
iteration 2 in inner loop, alpha 13.515542941516074 rho 1000.0 h 0.03529087030948119
4420
cuda
Objective function 26.79 = squared loss an data 19.41 + 0.5*rho*h**2 6.227228 + alpha*h 0.476975 + L2reg 0.52 + L1reg 0.16 ; SHD = 64 ; DAG True
||w||^2 123363641208.26375
exp ma of ||w||^2 44259451116.10336
||w|| 351231.60622054467
exp ma of ||w|| 134150.30545827432
||w||^2 62865566.868650906
exp ma of ||w||^2 7099157513.4059925
||w|| 7928.780919451042
exp ma of ||w|| 38684.740441477516
||w||^2 17.904646981513018
exp ma of ||w||^2 24885917.52835337
||w|| 4.231388304270008
exp ma of ||w|| 207.99322355627717
||w||^2 0.19589450642730302
exp ma of ||w||^2 7037.030415122676
||w|| 0.44259971354182215
exp ma of ||w|| 0.6459130725391596
||w||^2 0.06615054297457282
exp ma of ||w||^2 0.07418832751052398
||w|| 0.25719747855407293
exp ma of ||w|| 0.2575982140881908
||w||^2 0.07978628091312365
exp ma of ||w||^2 0.07482681587749056
||w|| 0.282464654272218
exp ma of ||w|| 0.26617968115569723
||w||^2 0.0790065604818599
exp ma of ||w||^2 0.07260592230687028
||w|| 0.2810810567823095
exp ma of ||w|| 0.26255443475237605
||w||^2 0.07966356483035511
exp ma of ||w||^2 0.07522334014043347
||w|| 0.28224734689692854
exp ma of ||w|| 0.2677721458625779
||w||^2 0.07360682247496442
exp ma of ||w||^2 0.07710405508079105
||w|| 0.2713057730218147
exp ma of ||w|| 0.2717244874256471
||w||^2 0.10677841325612128
exp ma of ||w||^2 0.08156596526132999
||w|| 0.32676966391652895
exp ma of ||w|| 0.2765712279818602
||w||^2 0.11442821286369254
exp ma of ||w||^2 0.08311326943158474
||w|| 0.33827239447476726
exp ma of ||w|| 0.28009099528923215
||w||^2 0.07694775638896484
exp ma of ||w||^2 0.0743311845663725
||w|| 0.2773945860844527
exp ma of ||w|| 0.26624228752555845
cuda
Objective function 21.24 = squared loss an data 19.70 + 0.5*rho*h**2 0.685929 + alpha*h 0.158303 + L2reg 0.55 + L1reg 0.15 ; SHD = 64 ; DAG True
Proportion of microbatches that were clipped  0.7606667198341176
iteration 3 in inner loop, alpha 13.515542941516074 rho 10000.0 h 0.011712634917124376
iteration 3 in outer loop, alpha = 130.64189211275982, rho = 10000.0, h = 0.011712634917124376
cuda
4420
cuda
Objective function 22.62 = squared loss an data 19.70 + 0.5*rho*h**2 0.685929 + alpha*h 1.530161 + L2reg 0.55 + L1reg 0.15 ; SHD = 64 ; DAG True
||w||^2 0.28476054962790387
exp ma of ||w||^2 4932.457124403276
||w|| 0.5336295996549516
exp ma of ||w|| 0.6777556790643355
||w||^2 0.11988530602087469
exp ma of ||w||^2 30.96938758612544
||w|| 0.3462445754389153
exp ma of ||w|| 0.38643408060166423
||w||^2 0.09720014602010815
exp ma of ||w||^2 0.17032024907028495
||w|| 0.3117693795421676
exp ma of ||w|| 0.28534837245490013
||w||^2 0.06960611902706308
exp ma of ||w||^2 0.06560190103765912
||w|| 0.26382971596668764
exp ma of ||w|| 0.25093065211357307
||w||^2 0.036869389839258346
exp ma of ||w||^2 0.07855986891684927
||w|| 0.19201403552672483
exp ma of ||w|| 0.2729648260011257
||w||^2 0.03347351514796241
exp ma of ||w||^2 0.08157325254794032
||w|| 0.18295768676927027
exp ma of ||w|| 0.27869679700778893
||w||^2 0.09792386470855838
exp ma of ||w||^2 0.08031992106245477
||w|| 0.3129278905891234
exp ma of ||w|| 0.27593906454740585
||w||^2 0.05050310807960132
exp ma of ||w||^2 0.07752744355342794
||w|| 0.22472896582239085
exp ma of ||w|| 0.2725186907202715
||w||^2 0.08630520408806928
exp ma of ||w||^2 0.07876171167869304
||w|| 0.2937774737587436
exp ma of ||w|| 0.27365022824309926
||w||^2 0.050263304942896575
exp ma of ||w||^2 0.0771221926194643
||w|| 0.22419479240806772
exp ma of ||w|| 0.27073674612860515
||w||^2 0.11343303410579263
exp ma of ||w||^2 0.08556933096984082
||w|| 0.33679820977225017
exp ma of ||w|| 0.28701170492967004
||w||^2 0.11080246499133495
exp ma of ||w||^2 0.08182269336752976
||w|| 0.3328700421956517
exp ma of ||w|| 0.27979198031175057
cuda
Objective function 21.74 = squared loss an data 19.71 + 0.5*rho*h**2 0.303089 + alpha*h 1.017144 + L2reg 0.57 + L1reg 0.15 ; SHD = 63 ; DAG True
Proportion of microbatches that were clipped  0.7593152866242038
iteration 1 in inner loop, alpha 130.64189211275982 rho 10000.0 h 0.007785740994567192
4420
cuda
Objective function 24.47 = squared loss an data 19.71 + 0.5*rho*h**2 3.030888 + alpha*h 1.017144 + L2reg 0.57 + L1reg 0.15 ; SHD = 63 ; DAG True
||w||^2 10.593580143956755
exp ma of ||w||^2 150217899.1482895
||w|| 3.254778048340125
exp ma of ||w|| 101.87561264137814
||w||^2 0.45829432031962125
exp ma of ||w||^2 366.7210864837725
||w|| 0.6769743867530154
exp ma of ||w|| 0.7880126102172232
||w||^2 0.15978852314090605
exp ma of ||w||^2 4.422661376228045
||w|| 0.39973556651980074
exp ma of ||w|| 0.485248490091374
||w||^2 0.09486277676101923
exp ma of ||w||^2 0.07687903996142847
||w|| 0.3079980142160323
exp ma of ||w|| 0.27118838067337137
||w||^2 0.15208502990114797
exp ma of ||w||^2 0.0912124010635054
||w|| 0.38998080709330807
exp ma of ||w|| 0.2937939574425053
||w||^2 0.2474185434379786
exp ma of ||w||^2 0.08955958786433525
||w|| 0.4974118448911109
exp ma of ||w|| 0.2904167638850699
||w||^2 0.05499550005955047
exp ma of ||w||^2 0.08545123256910046
||w|| 0.2345111938896531
exp ma of ||w|| 0.28625626057294484
||w||^2 0.11976951759133517
exp ma of ||w||^2 0.08775461390669856
||w|| 0.3460773289184589
exp ma of ||w|| 0.28928649373266624
||w||^2 0.0554285526866045
exp ma of ||w||^2 0.08855004545903158
||w|| 0.2354326924762245
exp ma of ||w|| 0.2898678749390905
||w||^2 0.0693520584723659
exp ma of ||w||^2 0.07985444104954655
||w|| 0.2633477899515504
exp ma of ||w|| 0.2766258308321264
||w||^2 0.07452890805370542
exp ma of ||w||^2 0.08653616565999377
||w|| 0.27299983160014113
exp ma of ||w|| 0.28813628355949256
cuda
Objective function 21.22 = squared loss an data 19.84 + 0.5*rho*h**2 0.313315 + alpha*h 0.327031 + L2reg 0.60 + L1reg 0.14 ; SHD = 58 ; DAG True
Proportion of microbatches that were clipped  0.7613956105796286
iteration 2 in inner loop, alpha 130.64189211275982 rho 100000.0 h 0.0025032591574642993
iteration 4 in outer loop, alpha = 380.96780785918975, rho = 100000.0, h = 0.0025032591574642993
cuda
4420
cuda
Objective function 21.85 = squared loss an data 19.84 + 0.5*rho*h**2 0.313315 + alpha*h 0.953661 + L2reg 0.60 + L1reg 0.14 ; SHD = 58 ; DAG True
||w||^2 4.366886054477556
exp ma of ||w||^2 3622142.0095504024
||w|| 2.0897095622304924
exp ma of ||w|| 3.9505066505066355
||w||^2 4.1222615683616
exp ma of ||w||^2 2547988.6703752447
||w|| 2.0303353339686527
exp ma of ||w|| 3.381103061952732
||w||^2 2.0015510245741037
exp ma of ||w||^2 369962.52766596817
||w|| 1.4147618260944503
exp ma of ||w|| 1.9277570060038418
||w||^2 2.6129399238685656
exp ma of ||w||^2 96223.67775358139
||w|| 1.6164590696545846
exp ma of ||w|| 1.6552417828217691
||w||^2 0.1451905269105165
exp ma of ||w||^2 0.1774866661030374
||w|| 0.3810387472561242
exp ma of ||w|| 0.41257272289604724
||w||^2 0.0900180343039936
exp ma of ||w||^2 0.11868666884451817
||w|| 0.30003005566775076
exp ma of ||w|| 0.34191441539398215
||w||^2 0.07245446157287974
exp ma of ||w||^2 0.08640817476482202
||w|| 0.2691736643375049
exp ma of ||w|| 0.2881740937753561
v before min max tensor([[ 7.665e+00, -4.377e+00, -8.901e+00,  ..., -8.740e+00, -1.400e+01,
          8.121e+01],
        [ 4.936e+00, -9.128e+00, -1.195e+01,  ..., -8.055e+00,  1.893e+01,
         -5.430e+00],
        [ 2.189e-02, -2.735e+00,  5.579e+00,  ...,  3.287e+00, -6.473e+00,
          5.257e+01],
        ...,
        [-9.863e+00, -9.677e+00, -7.489e+00,  ..., -1.081e+01,  7.036e-01,
         -1.053e+01],
        [ 3.951e+01,  1.693e+00, -9.176e+00,  ...,  3.412e+00, -1.183e+01,
         -1.335e+01],
        [-5.437e+00, -1.201e+01, -1.189e+01,  ...,  3.904e+00,  7.094e+00,
         -6.557e+00]], device='cuda:0')
v tensor([[7.665e+00, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e+01],
        [4.936e+00, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         1.000e-12],
        [2.189e-02, 1.000e-12, 5.579e+00,  ..., 3.287e+00, 1.000e-12,
         1.000e+01],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 7.036e-01,
         1.000e-12],
        [1.000e+01, 1.693e+00, 1.000e-12,  ..., 3.412e+00, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 3.904e+00, 7.094e+00,
         1.000e-12]], device='cuda:0')
v before min max tensor([ -8.177, -14.769,   5.837,  -9.070,  20.982,   2.608,  -9.103, -10.672,
        -10.320, -11.487,   2.986,  11.536,  -7.194,  17.334, 136.283,   7.967,
         -6.799, -12.478,  -2.176,  -6.835, -15.764,  12.857,   4.378, -13.584,
        -11.517,  -2.183, -10.338,  -7.322, -10.683,   5.702,  25.331,  -7.015,
         -8.372,  31.245,  -4.962,  -6.688, -12.182,   2.401, -13.892,  29.027,
         11.015,  -9.950,  32.551, -10.584,  -6.019,  14.096,  -0.766,  -8.990,
         -6.632, -14.304,  -3.534,  -0.623,  -8.414,  -1.554,  43.729, -14.094,
        -14.104,  -5.812,  -7.747,   1.355,  -2.499,  -8.067, -13.366, -14.016,
         -6.208, -14.906,  59.317,  -7.631, -11.555, -10.269,  22.148, -11.810,
         -4.145,  -7.981,  -8.460,  -5.488, -13.538, -13.046, -11.111,  12.072,
         -8.298,   0.276,  19.985, -14.816,  -8.032, -11.502,  -1.009, -10.611,
        -10.281,  -9.724, -12.949,  -8.108, -13.375,  -7.246,  28.311,   1.866,
         -6.053, -10.205,  -2.120,  -4.046,   2.736,  25.791,  -2.704, -11.242,
         -7.368, -12.210,  -3.039, -11.265,  -2.261,  -3.461, -15.406,  19.372,
         22.323, -15.257, -12.176,  -9.141,  -0.945, -12.651,  -9.908, -10.639,
         -7.084,  -2.381, -10.332, -14.754, -14.248,   3.115,  -8.703, -13.170,
          4.504,  -9.300, -12.453,   3.629, -13.801,  -2.162,  -5.079,  21.014,
         -3.653,  -5.579, -12.397, -14.162,   3.591,  -9.168, -13.418, -14.915,
         -7.600,   5.747,   1.531, -10.550,  49.655,  24.958,   5.315, -11.761,
        -11.698, -18.732,  33.603, -10.068,  -9.873,  -3.582,  11.302,  -5.292,
        -10.532, -12.095, -12.986,  -3.184,  -8.433,  29.711,   7.797,  -5.681,
         31.820,   2.242,  -0.223,  -7.395,   8.567,  -8.941,  -9.074,   8.035,
        -11.129,  -6.247,  74.452,   9.886,  -2.779,   6.140,  -3.544,   8.833,
         -2.752,  -5.738,  -9.441,  -1.148,  -7.081,  -7.414,  26.450,  -9.540,
         -3.868, -11.096,  -7.679,   5.635,  -7.033,  -4.031, -11.305,  -7.799],
       device='cuda:0')
v tensor([1.000e-12, 1.000e-12, 5.837e+00, 1.000e-12, 1.000e+01, 2.608e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.986e+00, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e+01, 7.967e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 4.378e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.702e+00,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 2.401e+00, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.355e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 2.762e-01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.866e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.736e+00, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.115e+00,
        1.000e-12, 1.000e-12, 4.504e+00, 1.000e-12, 1.000e-12, 3.629e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 3.591e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 5.747e+00, 1.531e+00, 1.000e-12, 1.000e+01, 1.000e+01,
        5.315e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 7.797e+00, 1.000e-12,
        1.000e+01, 2.242e+00, 1.000e-12, 1.000e-12, 8.567e+00, 1.000e-12,
        1.000e-12, 8.035e+00, 1.000e-12, 1.000e-12, 1.000e+01, 9.886e+00,
        1.000e-12, 6.140e+00, 1.000e-12, 8.833e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 5.635e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12], device='cuda:0')
v before min max tensor([[[ 1.854e+01],
         [ 2.562e+01],
         [-9.813e+00],
         [-1.158e+01],
         [ 1.712e+01],
         [-8.090e+00],
         [ 6.458e+00],
         [ 5.004e+00],
         [-5.839e+00],
         [-2.168e+00]],

        [[-6.605e+00],
         [-9.636e+00],
         [-4.312e+00],
         [-1.046e+01],
         [-7.027e+00],
         [-1.024e+01],
         [-1.091e+01],
         [-1.370e+01],
         [ 1.043e-01],
         [-4.915e+00]],

        [[-1.591e+01],
         [-1.330e+01],
         [-3.580e+00],
         [-4.159e+00],
         [-5.771e+00],
         [-8.300e+00],
         [-1.250e+01],
         [-7.111e+00],
         [ 3.608e+01],
         [ 1.684e+01]],

        [[ 1.163e+01],
         [ 3.143e+01],
         [-1.318e+01],
         [ 2.651e+01],
         [-1.106e+01],
         [-1.419e+01],
         [-9.477e+00],
         [ 5.958e+01],
         [-1.249e+01],
         [-1.396e+01]],

        [[-9.627e+00],
         [-7.869e+00],
         [-4.667e-01],
         [-1.472e+01],
         [ 5.385e+00],
         [-9.599e+00],
         [-1.080e+01],
         [-2.182e+00],
         [-8.554e+00],
         [ 5.866e+00]],

        [[ 1.036e+01],
         [-3.414e-01],
         [-8.258e+00],
         [ 4.181e+01],
         [-4.620e+00],
         [-1.036e+01],
         [ 1.583e+01],
         [ 7.695e+00],
         [ 5.138e+01],
         [ 9.540e+00]],

        [[ 3.813e+00],
         [ 7.276e+00],
         [-1.175e+01],
         [-3.681e+00],
         [ 2.843e+01],
         [-6.603e+00],
         [-1.212e+01],
         [-1.124e+01],
         [-3.777e+00],
         [-7.852e+00]],

        [[-7.627e+00],
         [-1.348e+01],
         [-9.531e+00],
         [-1.441e+01],
         [ 5.395e+00],
         [-1.505e+01],
         [-8.016e+00],
         [ 1.168e+01],
         [-6.948e+00],
         [-8.916e+00]],

        [[-1.170e+01],
         [ 3.253e+01],
         [ 9.069e+00],
         [-1.315e+01],
         [-1.303e+01],
         [-9.654e+00],
         [-1.398e+01],
         [-7.068e+00],
         [-1.136e+01],
         [-1.891e+00]],

        [[ 1.138e+01],
         [-8.988e+00],
         [-2.721e+00],
         [ 1.086e+02],
         [-1.230e+01],
         [-1.257e+01],
         [-1.450e+01],
         [-1.182e+01],
         [ 5.049e-01],
         [-1.371e+01]],

        [[-1.245e+01],
         [-1.425e+01],
         [-1.373e+01],
         [ 1.940e-01],
         [-4.898e+00],
         [-1.022e+01],
         [-8.372e+00],
         [-1.122e+01],
         [ 6.503e+00],
         [-1.026e+01]],

        [[-1.015e+01],
         [-2.356e+00],
         [-8.307e+00],
         [ 4.683e+01],
         [ 3.092e+00],
         [ 1.450e+01],
         [-1.098e+01],
         [-1.171e+00],
         [-1.033e+01],
         [-1.160e+01]],

        [[-7.076e+00],
         [ 5.777e+00],
         [-3.582e-01],
         [-1.292e+01],
         [-4.321e+00],
         [ 2.543e+01],
         [-1.153e+01],
         [ 1.969e+00],
         [-1.147e+01],
         [ 3.105e+01]],

        [[-9.859e+00],
         [-1.050e+01],
         [-4.377e+00],
         [-9.398e+00],
         [ 5.401e+00],
         [-4.758e+00],
         [-1.238e+01],
         [-1.108e+01],
         [-7.621e+00],
         [-1.122e+01]],

        [[-5.023e+00],
         [-1.104e+01],
         [-9.454e+00],
         [ 1.707e+01],
         [ 2.110e+01],
         [-1.024e+01],
         [-4.517e+00],
         [-4.712e+00],
         [-1.654e+01],
         [-1.146e+00]],

        [[-8.330e+00],
         [-5.482e+00],
         [-3.465e+00],
         [ 8.025e+00],
         [ 5.586e+01],
         [ 2.770e+00],
         [-8.949e+00],
         [-2.640e+00],
         [-1.098e+01],
         [-6.285e+00]],

        [[-8.329e+00],
         [-7.451e+00],
         [-4.485e+00],
         [ 3.669e+01],
         [-1.322e+01],
         [-1.034e+01],
         [ 1.246e+01],
         [-2.850e+00],
         [ 1.745e+00],
         [-1.102e+00]],

        [[-2.688e+00],
         [-1.062e+00],
         [-8.028e+00],
         [-6.983e+00],
         [ 2.179e+00],
         [ 6.193e+00],
         [-8.158e+00],
         [-1.325e+01],
         [-8.876e+00],
         [-8.034e+00]],

        [[-1.326e+01],
         [-3.469e+00],
         [ 6.717e+00],
         [ 3.050e+00],
         [-1.278e+01],
         [-1.409e+01],
         [-1.082e+01],
         [-1.104e+01],
         [-1.519e+00],
         [-1.112e+01]],

        [[-1.322e+00],
         [ 2.882e-01],
         [-1.384e+01],
         [-8.041e+00],
         [-5.872e+00],
         [ 3.995e+00],
         [-5.840e+00],
         [-1.039e+01],
         [-9.239e+00],
         [ 2.953e+01]]], device='cuda:0')
v tensor([[[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [6.458e+00],
         [5.004e+00],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.043e-01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.385e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.866e+00]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [7.695e+00],
         [1.000e+01],
         [9.540e+00]],

        [[3.813e+00],
         [7.276e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.395e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [9.069e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.049e-01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.940e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.503e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [3.092e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [5.777e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.969e+00],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.401e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [8.025e+00],
         [1.000e+01],
         [2.770e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.745e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.179e+00],
         [6.193e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [6.717e+00],
         [3.050e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [2.882e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.995e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]]], device='cuda:0')
v before min max tensor([[ 13.485],
        [-10.675],
        [-11.041],
        [ 43.931],
        [ -9.478],
        [ -5.999],
        [ -4.817],
        [-11.097],
        [ -8.249],
        [ -1.652],
        [-12.837],
        [-10.072],
        [ -7.389],
        [-17.970],
        [-11.783],
        [ -4.226],
        [ 12.040],
        [ -5.597],
        [-13.085],
        [ -9.856]], device='cuda:0')
v tensor([[1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 0.008,  0.001, -0.009,  ..., -0.008,  0.011, -0.084],
        [-0.029,  0.039, -0.016,  ...,  0.026,  0.014, -0.033],
        [ 0.005, -0.033,  0.023,  ..., -0.041,  0.021,  0.081],
        ...,
        [ 0.029,  0.007, -0.009,  ...,  0.004, -0.079, -0.001],
        [ 0.026, -0.015, -0.002,  ..., -0.010,  0.006, -0.005],
        [ 0.025, -0.017,  0.010,  ..., -0.021,  0.032, -0.012]],
       device='cuda:0')
s after update for 1 param tensor([[2.161, 2.042, 1.447,  ..., 1.159, 1.729, 1.861],
        [2.528, 1.131, 1.517,  ..., 1.440, 1.524, 0.901],
        [1.481, 1.340, 1.742,  ..., 1.594, 1.254, 1.503],
        ...,
        [1.327, 1.317, 1.206,  ..., 1.608, 1.250, 1.290],
        [1.705, 1.331, 1.534,  ..., 1.401, 1.455, 1.833],
        [1.505, 1.502, 1.611,  ..., 1.563, 2.031, 2.116]], device='cuda:0')
b after update for 1 param tensor([[122.558, 119.128, 100.287,  ...,  89.766, 109.619, 113.721],
        [132.569,  88.678, 102.687,  ..., 100.061, 102.923,  79.117],
        [101.460,  96.518, 110.029,  ..., 105.259,  93.378, 102.201],
        ...,
        [ 96.029,  95.676,  91.562,  ..., 105.720,  93.205,  94.698],
        [108.875,  96.193, 103.263,  ...,  98.680, 100.558, 112.862],
        [102.290, 102.189, 105.819,  ..., 104.223, 118.825, 121.274]],
       device='cuda:0')
clipping threshold 0.2313863363140035
a after update for 1 param tensor([ 0.189, -0.187, -0.057, -0.058, -0.002, -0.032, -0.101,  0.001,  0.045,
        -0.071, -0.138,  0.012, -0.118,  0.082, -0.084, -0.167, -0.091,  0.011,
        -0.096, -0.129, -0.128, -0.129, -0.039, -0.007,  0.062, -0.145,  0.047,
         0.079, -0.188,  0.079,  0.029,  0.052, -0.186,  0.002,  0.106,  0.178,
         0.199,  0.056,  0.126,  0.052,  0.040,  0.062, -0.032, -0.174, -0.033,
        -0.073, -0.038, -0.132,  0.019,  0.235, -0.272, -0.182,  0.010,  0.005,
        -0.018, -0.053,  0.134,  0.045, -0.193,  0.079, -0.124, -0.078, -0.018,
        -0.038,  0.001,  0.260,  0.012, -0.181, -0.106,  0.048,  0.045,  0.148,
        -0.174,  0.071, -0.068,  0.061, -0.028, -0.205, -0.079,  0.115, -0.007,
        -0.173, -0.006,  0.203,  0.071,  0.018, -0.097, -0.001,  0.015,  0.027,
         0.008,  0.126,  0.023,  0.212, -0.099, -0.321,  0.001, -0.095,  0.099,
        -0.004,  0.005,  0.058,  0.091, -0.194, -0.048,  0.099,  0.052,  0.074,
         0.071, -0.188,  0.106,  0.066, -0.167, -0.092,  0.027,  0.067,  0.104,
        -0.125,  0.073,  0.029, -0.108,  0.094,  0.089, -0.001, -0.079,  0.033,
         0.104,  0.049,  0.060, -0.090,  0.066, -0.267, -0.174,  0.038,  0.090,
         0.106, -0.140,  0.077,  0.144, -0.193, -0.089, -0.020, -0.212, -0.033,
        -0.099, -0.068,  0.030, -0.258, -0.134,  0.009,  0.146,  0.010,  0.109,
        -0.054,  0.160, -0.062, -0.134, -0.020,  0.055,  0.044, -0.092, -0.006,
        -0.027, -0.091,  0.162, -0.098,  0.129, -0.133,  0.100, -0.077,  0.220,
         0.024,  0.044, -0.105, -0.058, -0.091,  0.024,  0.122,  0.094, -0.112,
         0.089,  0.135, -0.098, -0.131,  0.028, -0.087, -0.119,  0.021, -0.047,
        -0.001, -0.118,  0.018,  0.016,  0.064,  0.113, -0.019, -0.119,  0.018,
         0.290, -0.218], device='cuda:0')
s after update for 1 param tensor([1.718, 1.879, 1.295, 1.119, 1.472, 1.091, 1.206, 1.295, 1.312, 1.474,
        1.593, 1.608, 1.088, 2.054, 2.110, 1.755, 0.912, 1.515, 1.559, 1.009,
        1.949, 2.496, 1.675, 1.676, 1.521, 1.381, 1.286, 1.350, 1.370, 1.414,
        1.621, 1.045, 1.609, 1.958, 1.282, 1.344, 1.529, 1.452, 1.925, 1.980,
        1.793, 1.960, 1.917, 1.989, 1.775, 1.922, 1.394, 1.351, 1.832, 1.773,
        1.093, 1.517, 1.530, 1.272, 1.813, 1.945, 1.711, 2.184, 0.965, 1.382,
        1.655, 1.367, 1.677, 1.739, 1.484, 1.930, 1.872, 1.551, 1.596, 1.245,
        2.193, 1.729, 1.172, 1.956, 1.800, 0.930, 1.670, 1.583, 1.424, 1.838,
        1.012, 1.524, 2.261, 1.843, 1.722, 1.567, 1.430, 1.586, 1.414, 2.079,
        1.935, 1.388, 1.623, 1.274, 1.503, 1.295, 1.630, 1.375, 1.408, 1.088,
        1.421, 1.646, 1.587, 1.370, 1.687, 1.742, 0.838, 1.463, 1.918, 1.929,
        1.903, 1.762, 1.719, 1.883, 1.683, 1.482, 1.464, 1.734, 1.256, 1.507,
        1.491, 0.710, 1.378, 1.796, 1.727, 1.502, 1.315, 1.753, 1.470, 1.710,
        1.808, 1.920, 1.753, 1.717, 1.160, 1.873, 1.848, 1.169, 1.633, 2.108,
        1.503, 1.139, 1.627, 1.811, 1.169, 1.611, 1.756, 1.477, 2.009, 1.597,
        1.713, 1.527, 1.868, 2.279, 2.066, 1.394, 1.526, 1.445, 2.137, 1.483,
        1.806, 1.586, 1.722, 0.897, 1.402, 1.567, 1.488, 1.778, 1.766, 1.173,
        0.883, 0.904, 2.008, 1.612, 1.830, 2.018, 1.543, 1.694, 1.675, 1.529,
        1.255, 1.091, 1.557, 1.502, 1.675, 1.562, 1.163, 1.292, 1.480, 0.969,
        1.559, 1.179, 1.386, 1.629, 1.444, 1.053, 1.704, 1.852, 1.518, 1.579],
       device='cuda:0')
b after update for 1 param tensor([109.277, 114.291,  94.885,  88.187, 101.160,  87.071,  91.542,  94.860,
         95.489, 101.215, 105.211, 105.727,  86.971, 119.495, 121.113, 110.436,
         79.625, 102.632, 104.104,  83.765, 116.390, 131.705, 107.913, 107.941,
        102.817,  97.963,  94.555,  96.875,  97.574,  99.140, 106.155,  85.240,
        105.743, 116.651,  94.404,  96.653, 103.083, 100.456, 115.677, 117.318,
        111.624, 116.714, 115.427, 117.580, 111.086, 115.582,  98.450,  96.906,
        112.858, 110.998,  87.146, 102.676, 103.139,  94.018, 112.248, 116.279,
        109.058, 123.223,  81.900,  97.994, 107.264,  97.489, 107.957, 109.958,
        101.574, 115.809, 114.077, 103.841, 105.332,  93.032, 123.471, 109.643,
         90.265, 116.589, 111.856,  80.394, 107.739, 104.901,  99.473, 113.038,
         83.853, 102.931, 125.352, 113.186, 109.419, 104.357,  99.704, 104.981,
         99.148, 120.218, 115.983,  98.220, 106.229,  94.087, 102.225,  94.878,
        106.435,  97.775,  98.937,  86.946,  99.391, 106.959, 105.031,  97.570,
        108.273, 110.034,  76.339, 100.832, 115.449, 115.788, 115.023, 110.670,
        109.321, 114.393, 108.168, 101.507, 100.880, 109.774,  93.428, 102.353,
        101.787,  70.226,  97.869, 111.724, 109.579, 102.162,  95.615, 110.386,
        101.092, 109.034, 112.115, 115.520, 110.395, 109.245,  89.803, 114.106,
        113.347,  90.126, 106.541, 121.036, 102.217,  88.989, 106.341, 112.197,
         90.148, 105.822, 110.493, 101.340, 118.167, 105.353, 109.103, 103.030,
        113.934, 125.866, 119.845,  98.447, 102.981, 100.232, 121.877, 101.525,
        112.031, 105.008, 109.391,  78.972,  98.711, 104.381, 101.698, 111.171,
        110.782,  90.313,  78.340,  79.260, 118.132, 105.848, 112.793, 118.423,
        103.579, 108.497, 107.891, 103.085,  93.394,  87.095, 104.017, 102.178,
        107.917, 104.187,  89.915,  94.772, 101.415,  82.079, 104.092,  90.512,
         98.148, 106.399, 100.189,  85.539, 108.836, 113.468, 102.709, 104.773],
       device='cuda:0')
clipping threshold 0.2313863363140035
a after update for 1 param tensor([[[-0.070],
         [ 0.101],
         [ 0.151],
         [ 0.111],
         [ 0.016],
         [ 0.001],
         [ 0.094],
         [-0.012],
         [ 0.083],
         [-0.043]],

        [[-0.105],
         [-0.058],
         [ 0.078],
         [-0.010],
         [-0.088],
         [ 0.051],
         [ 0.053],
         [-0.018],
         [-0.116],
         [ 0.075]],

        [[ 0.108],
         [ 0.218],
         [-0.026],
         [-0.109],
         [-0.226],
         [-0.059],
         [-0.073],
         [ 0.022],
         [ 0.117],
         [ 0.051]],

        [[-0.261],
         [ 0.165],
         [-0.016],
         [ 0.012],
         [-0.117],
         [ 0.169],
         [-0.107],
         [-0.241],
         [ 0.004],
         [ 0.061]],

        [[ 0.071],
         [-0.027],
         [-0.051],
         [-0.021],
         [-0.123],
         [-0.082],
         [-0.047],
         [ 0.093],
         [ 0.054],
         [ 0.083]],

        [[-0.069],
         [ 0.056],
         [ 0.124],
         [ 0.004],
         [-0.015],
         [-0.098],
         [-0.039],
         [ 0.115],
         [-0.125],
         [ 0.087]],

        [[-0.111],
         [-0.056],
         [ 0.059],
         [ 0.051],
         [ 0.110],
         [ 0.065],
         [-0.175],
         [ 0.021],
         [ 0.157],
         [-0.152]],

        [[-0.012],
         [-0.098],
         [-0.046],
         [ 0.114],
         [ 0.088],
         [-0.050],
         [-0.055],
         [-0.210],
         [-0.008],
         [ 0.058]],

        [[-0.050],
         [ 0.058],
         [ 0.135],
         [-0.085],
         [ 0.016],
         [ 0.028],
         [-0.026],
         [-0.150],
         [ 0.113],
         [-0.039]],

        [[ 0.020],
         [ 0.126],
         [ 0.035],
         [-0.011],
         [ 0.035],
         [ 0.074],
         [-0.047],
         [-0.005],
         [-0.003],
         [ 0.008]],

        [[-0.017],
         [-0.086],
         [-0.021],
         [-0.130],
         [-0.017],
         [ 0.066],
         [-0.055],
         [-0.011],
         [ 0.053],
         [ 0.045]],

        [[-0.020],
         [ 0.037],
         [ 0.140],
         [ 0.160],
         [ 0.172],
         [-0.184],
         [-0.100],
         [-0.064],
         [ 0.058],
         [ 0.121]],

        [[-0.024],
         [ 0.087],
         [-0.099],
         [-0.192],
         [ 0.185],
         [ 0.116],
         [-0.031],
         [-0.080],
         [ 0.067],
         [-0.183]],

        [[-0.170],
         [ 0.009],
         [-0.107],
         [ 0.111],
         [ 0.094],
         [-0.028],
         [ 0.013],
         [ 0.104],
         [-0.164],
         [-0.122]],

        [[-0.129],
         [-0.009],
         [-0.107],
         [ 0.086],
         [ 0.038],
         [ 0.030],
         [ 0.112],
         [-0.041],
         [ 0.069],
         [-0.107]],

        [[ 0.179],
         [ 0.131],
         [ 0.019],
         [-0.008],
         [ 0.065],
         [-0.077],
         [-0.038],
         [ 0.017],
         [-0.155],
         [-0.034]],

        [[-0.164],
         [-0.192],
         [-0.127],
         [ 0.057],
         [ 0.016],
         [-0.198],
         [ 0.046],
         [ 0.105],
         [ 0.069],
         [-0.021]],

        [[ 0.012],
         [-0.112],
         [ 0.019],
         [ 0.066],
         [ 0.061],
         [ 0.062],
         [-0.151],
         [-0.024],
         [-0.004],
         [ 0.131]],

        [[ 0.029],
         [-0.038],
         [ 0.114],
         [-0.123],
         [-0.103],
         [-0.074],
         [ 0.050],
         [ 0.014],
         [ 0.014],
         [ 0.007]],

        [[ 0.125],
         [-0.034],
         [-0.056],
         [-0.040],
         [-0.004],
         [-0.187],
         [-0.098],
         [-0.079],
         [ 0.047],
         [-0.046]]], device='cuda:0')
s after update for 1 param tensor([[[1.988],
         [1.930],
         [1.874],
         [1.409],
         [1.791],
         [1.655],
         [1.754],
         [1.848],
         [1.344],
         [1.305]],

        [[1.767],
         [1.686],
         [1.214],
         [1.295],
         [1.525],
         [1.410],
         [1.346],
         [1.737],
         [1.954],
         [1.424]],

        [[1.952],
         [2.034],
         [1.230],
         [1.280],
         [1.625],
         [1.547],
         [1.776],
         [1.068],
         [1.782],
         [1.864]],

        [[1.841],
         [1.997],
         [1.602],
         [1.660],
         [1.344],
         [1.877],
         [1.340],
         [2.036],
         [1.546],
         [1.711]],

        [[1.696],
         [1.155],
         [1.020],
         [1.787],
         [1.487],
         [1.183],
         [1.384],
         [1.998],
         [1.084],
         [1.753]],

        [[1.631],
         [1.015],
         [2.032],
         [1.712],
         [1.470],
         [1.286],
         [2.004],
         [1.575],
         [2.180],
         [2.092]],

        [[2.017],
         [1.694],
         [1.488],
         [1.292],
         [1.937],
         [1.473],
         [2.148],
         [2.108],
         [1.834],
         [1.389]],

        [[1.738],
         [1.949],
         [1.567],
         [1.750],
         [1.769],
         [1.945],
         [1.334],
         [1.755],
         [1.461],
         [1.320]],

        [[1.431],
         [1.638],
         [2.168],
         [1.703],
         [1.799],
         [1.285],
         [1.729],
         [1.459],
         [1.452],
         [1.008]],

        [[1.536],
         [1.270],
         [1.729],
         [1.561],
         [1.570],
         [1.654],
         [1.830],
         [1.509],
         [1.163],
         [1.689]],

        [[1.568],
         [1.733],
         [1.688],
         [1.531],
         [1.612],
         [1.323],
         [1.017],
         [1.436],
         [1.640],
         [1.407]],

        [[1.529],
         [1.300],
         [1.446],
         [1.939],
         [1.657],
         [1.780],
         [1.464],
         [1.685],
         [1.299],
         [1.406]],

        [[2.031],
         [1.760],
         [1.708],
         [1.631],
         [1.094],
         [1.979],
         [1.415],
         [1.902],
         [1.489],
         [1.932]],

        [[1.442],
         [1.277],
         [1.762],
         [1.371],
         [1.808],
         [1.373],
         [1.506],
         [1.457],
         [1.741],
         [1.419]],

        [[1.389],
         [1.535],
         [1.644],
         [1.927],
         [2.194],
         [1.365],
         [1.321],
         [0.984],
         [2.029],
         [1.202]],

        [[1.028],
         [1.137],
         [0.468],
         [1.621],
         [1.593],
         [1.336],
         [1.094],
         [1.587],
         [1.356],
         [1.896]],

        [[1.293],
         [1.211],
         [1.014],
         [1.543],
         [1.646],
         [1.408],
         [1.582],
         [1.484],
         [1.758],
         [1.442]],

        [[1.183],
         [1.414],
         [1.038],
         [1.750],
         [1.163],
         [1.586],
         [1.343],
         [1.619],
         [1.651],
         [0.994]],

        [[1.617],
         [1.535],
         [1.295],
         [2.054],
         [1.590],
         [1.766],
         [1.338],
         [1.338],
         [1.270],
         [1.441]],

        [[1.578],
         [0.855],
         [1.717],
         [1.220],
         [1.619],
         [1.533],
         [1.307],
         [1.347],
         [1.370],
         [2.301]]], device='cuda:0')
b after update for 1 param tensor([[[117.545],
         [115.834],
         [114.136],
         [ 98.968],
         [111.573],
         [107.262],
         [110.405],
         [113.339],
         [ 96.665],
         [ 95.233]],

        [[110.822],
         [108.270],
         [ 91.876],
         [ 94.891],
         [102.963],
         [ 99.007],
         [ 96.721],
         [109.882],
         [116.528],
         [ 99.494]],

        [[116.491],
         [118.911],
         [ 92.455],
         [ 94.319],
         [106.270],
         [103.694],
         [111.104],
         [ 86.157],
         [111.285],
         [113.840]],

        [[113.120],
         [117.816],
         [105.530],
         [107.413],
         [ 96.666],
         [114.217],
         [ 96.493],
         [118.973],
         [103.656],
         [109.069]],

        [[108.561],
         [ 89.603],
         [ 84.209],
         [111.450],
         [101.665],
         [ 90.665],
         [ 98.090],
         [117.860],
         [ 86.796],
         [110.382]],

        [[106.473],
         [ 83.977],
         [118.858],
         [109.096],
         [101.080],
         [ 94.543],
         [118.016],
         [104.620],
         [123.084],
         [120.600]],

        [[118.395],
         [108.510],
         [101.715],
         [ 94.770],
         [116.033],
         [101.181],
         [122.201],
         [121.061],
         [112.897],
         [ 98.247]],

        [[109.914],
         [116.399],
         [104.363],
         [110.298],
         [110.878],
         [116.284],
         [ 96.298],
         [110.448],
         [100.773],
         [ 95.794]],

        [[ 99.732],
         [106.713],
         [122.756],
         [108.795],
         [111.815],
         [ 94.493],
         [109.621],
         [100.691],
         [100.474],
         [ 83.712]],

        [[103.344],
         [ 93.943],
         [109.616],
         [104.181],
         [104.465],
         [107.213],
         [112.790],
         [102.404],
         [ 89.916],
         [108.344]],

        [[104.406],
         [109.766],
         [108.315],
         [103.153],
         [105.862],
         [ 95.893],
         [ 84.089],
         [ 99.898],
         [106.761],
         [ 98.910]],

        [[103.108],
         [ 95.044],
         [100.239],
         [116.082],
         [107.309],
         [111.241],
         [100.886],
         [108.230],
         [ 95.016],
         [ 98.863]],

        [[118.830],
         [110.616],
         [108.965],
         [106.471],
         [ 87.191],
         [117.278],
         [ 99.181],
         [114.993],
         [101.740],
         [115.880]],

        [[100.127],
         [ 94.212],
         [110.657],
         [ 97.629],
         [112.095],
         [ 97.699],
         [102.310],
         [100.646],
         [109.993],
         [ 99.315]],

        [[ 98.252],
         [103.301],
         [106.886],
         [115.722],
         [123.494],
         [ 97.407],
         [ 95.827],
         [ 82.691],
         [118.759],
         [ 91.389]],

        [[ 84.520],
         [ 88.892],
         [ 57.024],
         [106.148],
         [105.232],
         [ 96.361],
         [ 87.184],
         [105.019],
         [ 97.088],
         [114.790]],

        [[ 94.802],
         [ 91.733],
         [ 83.942],
         [103.565],
         [106.969],
         [ 98.944],
         [104.863],
         [101.561],
         [110.527],
         [100.102]],

        [[ 90.666],
         [ 99.128],
         [ 84.949],
         [110.305],
         [ 89.925],
         [104.994],
         [ 96.618],
         [106.068],
         [107.119],
         [ 83.106]],

        [[106.026],
         [103.293],
         [ 94.873],
         [119.478],
         [105.122],
         [110.797],
         [ 96.420],
         [ 96.449],
         [ 93.961],
         [100.079]],

        [[104.747],
         [ 77.108],
         [109.242],
         [ 92.089],
         [106.079],
         [103.237],
         [ 95.312],
         [ 96.760],
         [ 97.596],
         [126.476]]], device='cuda:0')
clipping threshold 0.2313863363140035
a after update for 1 param tensor([[-0.047],
        [-0.049],
        [ 0.078],
        [ 0.043],
        [-0.070],
        [ 0.062],
        [ 0.031],
        [ 0.005],
        [ 0.023],
        [-0.085],
        [ 0.069],
        [-0.144],
        [ 0.011],
        [-0.032],
        [-0.141],
        [ 0.120],
        [ 0.075],
        [-0.095],
        [-0.017],
        [ 0.027]], device='cuda:0')
s after update for 1 param tensor([[1.768],
        [1.336],
        [1.338],
        [2.419],
        [1.210],
        [1.370],
        [1.652],
        [1.470],
        [1.296],
        [1.657],
        [1.794],
        [1.236],
        [1.490],
        [2.253],
        [1.572],
        [1.475],
        [2.049],
        [1.040],
        [1.892],
        [1.704]], device='cuda:0')
b after update for 1 param tensor([[110.847],
        [ 96.371],
        [ 96.446],
        [129.664],
        [ 91.710],
        [ 97.567],
        [107.157],
        [101.089],
        [ 94.924],
        [107.317],
        [111.656],
        [ 92.695],
        [101.779],
        [125.155],
        [104.528],
        [101.272],
        [119.336],
        [ 85.005],
        [114.675],
        [108.824]], device='cuda:0')
clipping threshold 0.2313863363140035
||w||^2 0.06764338870637494
exp ma of ||w||^2 0.08695395647603023
||w|| 0.2600834264353939
exp ma of ||w|| 0.2884139952985063
||w||^2 0.10301107904126203
exp ma of ||w||^2 0.08770459854653145
||w|| 0.3209533907614344
exp ma of ||w|| 0.2893488143478523
||w||^2 0.1983304242743912
exp ma of ||w||^2 0.09804665764109256
||w|| 0.445343041120428
exp ma of ||w|| 0.30441736917935275
v before min max tensor([[ 15.660,   9.646,  20.835,  ...,   4.428,  -6.791,  -7.582],
        [ -4.889,   0.572,  59.158,  ...,  -9.060,   4.876,  18.605],
        [  6.501,  41.421, -10.946,  ...,  19.325,  -9.600, -14.631],
        ...,
        [ -3.838,  12.165,  40.051,  ...,  -9.737,  31.228, -16.323],
        [ -1.739,  29.638,  -9.808,  ..., -13.996,  -7.873, -12.363],
        [  0.321,   8.140,  -0.769,  ...,  -6.157,  18.371,  -8.613]],
       device='cuda:0')
v tensor([[1.000e+01, 9.646e+00, 1.000e+01,  ..., 4.428e+00, 1.000e-12,
         1.000e-12],
        [1.000e-12, 5.723e-01, 1.000e+01,  ..., 1.000e-12, 4.876e+00,
         1.000e+01],
        [6.501e+00, 1.000e+01, 1.000e-12,  ..., 1.000e+01, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e-12, 1.000e+01, 1.000e+01,  ..., 1.000e-12, 1.000e+01,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [3.206e-01, 8.140e+00, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         1.000e-12]], device='cuda:0')
v before min max tensor([-9.553e+00, -1.322e+01,  5.016e+00,  4.887e+01, -1.399e+01,  1.706e+01,
        -8.110e+00, -6.660e+00,  1.073e+02, -4.675e+00, -8.875e+00, -1.238e+01,
         1.608e+01, -2.341e+00,  6.767e+01, -1.327e+01, -1.208e+01,  3.077e+01,
        -9.227e+00, -1.235e+01,  4.278e+01, -1.169e+01,  2.216e+01, -1.614e+01,
        -1.276e+01,  6.515e+01,  1.531e+01,  1.026e+01, -1.310e+01,  9.675e+00,
        -1.294e+01, -1.079e+01, -8.720e+00, -3.473e+00, -8.874e+00, -1.417e+01,
        -9.867e+00, -5.042e+00, -8.522e+00, -1.005e+01, -9.602e+00,  1.728e+01,
         6.773e+00,  5.060e+00, -7.876e+00, -1.517e+01, -3.780e+00, -1.123e+01,
         1.200e+00,  4.072e+01, -1.372e+01, -1.304e+01,  5.019e+01, -1.231e+01,
        -1.246e+01, -6.566e+00,  7.441e+00,  5.456e+00, -9.595e+00, -4.643e-01,
         2.299e+01,  7.355e+00, -2.433e+00, -9.079e+00, -6.893e+00,  1.004e+02,
         3.203e+01, -1.238e+01, -2.580e+00,  3.703e-02, -3.494e+00, -3.066e+00,
         3.791e+01,  1.222e+01, -1.339e+01,  1.140e+01, -8.097e+00, -5.380e+00,
        -1.447e+01,  1.073e+02,  4.340e+00, -1.040e+01,  5.034e+00, -9.316e+00,
        -3.339e+00, -6.695e+00, -3.863e+00, -5.519e-02, -6.781e+00, -1.023e+01,
        -6.858e+00, -4.395e+00,  1.131e+02,  6.596e+01, -5.794e+00, -5.698e+00,
         6.132e+00,  6.834e+01, -6.532e+00, -1.362e+01, -2.000e+00,  3.927e+01,
         2.026e+01, -8.249e+00,  6.014e+00,  2.789e+00,  3.136e+01,  1.594e+01,
        -4.774e+00, -1.070e+01,  3.356e+00, -6.555e+00, -1.182e+01,  4.223e+01,
         1.315e+01, -3.690e+00, -1.295e+01, -2.499e+00, -4.542e-01,  8.195e+00,
         7.267e+00, -8.828e+00, -6.885e+00,  2.496e+01, -1.565e+01, -4.317e+00,
        -1.104e+01, -5.855e+00, -6.031e+00,  2.047e-01, -9.182e+00,  2.129e-01,
        -9.798e+00,  1.909e+00, -4.026e+00,  5.005e+01, -1.365e+01,  2.175e+01,
         3.451e+00, -9.796e+00, -1.176e+01, -6.924e+00,  2.677e+01, -6.981e+00,
        -1.866e+01,  1.605e+01, -1.020e+01,  7.575e+00, -1.168e+01,  1.985e+01,
        -9.175e+00,  4.278e+00, -4.686e+00,  8.553e+01, -1.160e+01,  8.467e+00,
         3.332e+01, -2.390e+00,  2.646e+00,  1.228e+01,  3.141e+01,  1.512e+01,
         5.111e+01, -9.370e+00, -1.401e+01, -1.115e+01,  3.901e+01, -1.104e+01,
        -9.164e+00,  5.696e+00, -8.492e+00,  5.744e-01, -6.990e+00, -9.428e+00,
        -9.138e+00,  1.150e+01, -7.856e+00,  3.612e+01, -4.857e+00, -1.193e+01,
        -1.204e+01, -1.132e+01, -7.601e+00,  2.185e+01, -1.123e+01,  6.038e+00,
        -3.445e-01, -8.586e+00,  5.629e-02, -7.562e+00, -1.306e+01, -5.225e+00,
        -9.377e+00,  6.867e+00,  4.489e+01,  3.590e+01,  1.559e+01,  3.035e+01,
        -5.047e+00, -1.169e+01], device='cuda:0')
v tensor([1.000e-12, 1.000e-12, 5.016e+00, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 9.675e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        6.773e+00, 5.060e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.200e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 7.441e+00, 5.456e+00, 1.000e-12, 1.000e-12,
        1.000e+01, 7.355e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 3.703e-02, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 4.340e+00, 1.000e-12, 5.034e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        6.132e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 6.014e+00, 2.789e+00, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 3.356e+00, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 8.195e+00,
        7.267e+00, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 2.047e-01, 1.000e-12, 2.129e-01,
        1.000e-12, 1.909e+00, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        3.451e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 7.575e+00, 1.000e-12, 1.000e+01,
        1.000e-12, 4.278e+00, 1.000e-12, 1.000e+01, 1.000e-12, 8.467e+00,
        1.000e+01, 1.000e-12, 2.646e+00, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 5.696e+00, 1.000e-12, 5.744e-01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 6.038e+00,
        1.000e-12, 1.000e-12, 5.629e-02, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 6.867e+00, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12], device='cuda:0')
v before min max tensor([[[ 1.166e+01],
         [ 1.217e+01],
         [-1.645e+00],
         [-1.207e+01],
         [ 1.423e+00],
         [-3.402e+00],
         [-1.004e+01],
         [ 6.906e+00],
         [ 5.295e+01],
         [-2.439e+00]],

        [[ 1.762e+01],
         [-3.896e+00],
         [ 4.771e+01],
         [ 3.806e+01],
         [-5.165e+00],
         [ 6.381e+00],
         [-1.275e+00],
         [ 1.461e+01],
         [-2.951e+00],
         [-1.642e+01]],

        [[-1.296e+01],
         [-1.278e+01],
         [ 1.822e+01],
         [-1.238e-02],
         [-1.345e+01],
         [ 8.763e+00],
         [-7.293e+00],
         [-1.036e+01],
         [-5.170e+00],
         [ 3.541e+01]],

        [[ 7.246e+01],
         [ 4.262e+01],
         [ 1.378e+01],
         [ 1.929e+01],
         [-9.414e+00],
         [-1.144e+01],
         [-1.211e+01],
         [ 5.018e+00],
         [ 8.771e+01],
         [ 8.258e+01]],

        [[ 3.547e+01],
         [-7.996e+00],
         [-8.644e+00],
         [-5.371e+00],
         [-2.791e+00],
         [ 1.470e+01],
         [-6.736e+00],
         [-1.618e+01],
         [-3.490e+00],
         [ 1.350e+01]],

        [[-3.469e+00],
         [-1.035e+01],
         [ 1.324e+01],
         [ 6.523e+01],
         [ 1.151e+02],
         [ 6.827e-01],
         [-1.542e+01],
         [-5.841e+00],
         [ 1.569e+01],
         [-1.606e+01]],

        [[-1.225e+01],
         [ 2.033e-01],
         [ 1.470e+00],
         [-1.078e+01],
         [ 1.758e+00],
         [-1.013e+01],
         [-4.487e+00],
         [ 3.702e+01],
         [-8.467e+00],
         [ 2.034e+00]],

        [[-1.213e+01],
         [-1.009e+01],
         [-1.071e+01],
         [-5.986e+00],
         [-8.787e+00],
         [-5.226e+00],
         [-4.895e+00],
         [ 9.660e+00],
         [ 2.565e+01],
         [-1.025e+01]],

        [[-3.724e+00],
         [-1.029e+01],
         [-6.335e+00],
         [-8.764e+00],
         [ 1.105e+01],
         [-8.796e+00],
         [-1.298e+01],
         [ 4.510e+00],
         [-1.159e+01],
         [-1.529e+01]],

        [[-8.308e+00],
         [ 1.163e+01],
         [-4.087e+00],
         [-9.861e+00],
         [-7.772e+00],
         [-1.005e+01],
         [-1.188e+01],
         [ 1.157e+01],
         [ 7.630e+00],
         [-6.315e+00]],

        [[-8.340e+00],
         [-1.162e+01],
         [-8.666e+00],
         [ 1.739e+00],
         [ 1.032e+02],
         [ 5.244e-01],
         [-7.196e-01],
         [-1.410e+01],
         [-4.381e+00],
         [-8.234e+00]],

        [[ 2.045e+01],
         [-5.027e+00],
         [-7.691e+00],
         [ 6.072e+00],
         [ 2.153e+01],
         [ 8.794e+00],
         [-9.050e+00],
         [ 4.156e+00],
         [ 3.510e+01],
         [-1.079e+01]],

        [[ 2.186e+01],
         [-1.242e+01],
         [ 6.388e+01],
         [-1.473e+01],
         [ 1.146e+00],
         [-9.678e+00],
         [ 3.997e+01],
         [-9.814e+00],
         [-1.496e+01],
         [ 1.553e+01]],

        [[-1.270e+01],
         [-1.110e+01],
         [ 2.197e+01],
         [ 2.356e+01],
         [ 4.982e+00],
         [ 1.416e+01],
         [ 1.952e+00],
         [-1.357e+01],
         [ 1.246e+01],
         [-4.708e+00]],

        [[-5.724e-01],
         [ 4.740e+01],
         [-6.420e+00],
         [ 2.172e+01],
         [-9.499e+00],
         [-2.657e+00],
         [-6.795e+00],
         [ 1.954e+01],
         [ 1.219e+01],
         [-1.434e+01]],

        [[-6.743e+00],
         [-1.254e+01],
         [-1.062e+01],
         [-1.533e+01],
         [ 1.902e+01],
         [ 1.957e+01],
         [ 9.191e+00],
         [-1.045e+00],
         [-8.408e+00],
         [ 4.562e+01]],

        [[-5.674e+00],
         [-1.291e+01],
         [-1.471e+01],
         [-7.739e+00],
         [ 1.153e+02],
         [ 3.309e+01],
         [-2.074e+00],
         [-3.617e+00],
         [ 2.555e+00],
         [ 2.722e+01]],

        [[-5.578e+00],
         [-4.326e-01],
         [ 1.220e+00],
         [-5.232e+00],
         [-1.057e+01],
         [-2.167e+00],
         [-1.126e+01],
         [ 2.319e+01],
         [-1.078e+00],
         [-3.878e+00]],

        [[-8.511e+00],
         [ 1.241e+02],
         [-8.866e+00],
         [-1.143e+01],
         [-1.312e+01],
         [ 7.787e+00],
         [ 9.861e-02],
         [-1.238e+01],
         [ 6.674e+00],
         [ 9.181e+01]],

        [[ 5.531e+00],
         [-1.078e+01],
         [-1.065e+01],
         [ 3.830e+00],
         [ 3.030e-01],
         [ 2.480e+00],
         [-6.405e+00],
         [-4.132e-01],
         [-1.119e+01],
         [-1.677e+01]]], device='cuda:0')
v tensor([[[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.423e+00],
         [1.000e-12],
         [1.000e-12],
         [6.906e+00],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [6.381e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [8.763e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.018e+00],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [6.827e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [2.033e-01],
         [1.470e+00],
         [1.000e-12],
         [1.758e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [2.034e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [9.660e+00],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [4.510e+00],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [7.630e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.739e+00],
         [1.000e+01],
         [5.244e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [6.072e+00],
         [1.000e+01],
         [8.794e+00],
         [1.000e-12],
         [4.156e+00],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.146e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [4.982e+00],
         [1.000e+01],
         [1.952e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [9.191e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [2.555e+00],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.220e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.787e+00],
         [9.861e-02],
         [1.000e-12],
         [6.674e+00],
         [1.000e+01]],

        [[5.531e+00],
         [1.000e-12],
         [1.000e-12],
         [3.830e+00],
         [3.030e-01],
         [2.480e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[  7.696],
        [-12.682],
        [ -5.236],
        [  2.707],
        [ 82.411],
        [ -9.118],
        [-12.379],
        [  7.845],
        [ 66.886],
        [ 11.792],
        [ -3.598],
        [ -4.668],
        [ 13.987],
        [ -8.222],
        [  9.049],
        [ 23.755],
        [-10.264],
        [ -7.686],
        [ 27.817],
        [ 27.502]], device='cuda:0')
v tensor([[7.696e+00],
        [1.000e-12],
        [1.000e-12],
        [2.707e+00],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [7.845e+00],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [9.049e+00],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01]], device='cuda:0')
a after update for 1 param tensor([[-0.000, -0.003,  0.011,  ..., -0.005, -0.013, -0.017],
        [ 0.004,  0.018, -0.030,  ...,  0.018,  0.002, -0.007],
        [ 0.001,  0.008,  0.025,  ..., -0.008,  0.021,  0.065],
        ...,
        [ 0.045, -0.001,  0.020,  ..., -0.024,  0.020, -0.010],
        [ 0.019,  0.006,  0.003,  ...,  0.013,  0.003, -0.013],
        [-0.010,  0.009, -0.005,  ..., -0.010,  0.009, -0.010]],
       device='cuda:0')
s after update for 1 param tensor([[1.727, 1.506, 1.780,  ..., 1.689, 1.228, 1.123],
        [1.238, 0.903, 1.929,  ..., 1.269, 1.491, 2.068],
        [1.844, 1.832, 1.408,  ..., 1.683, 1.104, 1.949],
        ...,
        [1.233, 1.736, 1.603,  ..., 1.900, 1.885, 2.066],
        [1.148, 1.938, 1.398,  ..., 1.581, 1.332, 1.414],
        [1.416, 1.992, 1.040,  ..., 1.676, 1.789, 1.525]], device='cuda:0')
b after update for 1 param tensor([[109.005, 101.785, 110.671,  ..., 107.813,  91.911,  87.913],
        [ 92.312,  78.806, 115.211,  ...,  93.437, 101.283, 119.297],
        [112.633, 112.278,  98.445,  ..., 107.610,  87.176, 115.806],
        ...,
        [ 92.097, 109.290, 105.041,  ..., 114.336, 113.903, 119.244],
        [ 88.873, 115.492,  98.070,  ..., 104.314,  95.732,  98.649],
        [ 98.702, 117.084,  84.581,  ..., 107.379, 110.942, 102.445]],
       device='cuda:0')
clipping threshold 0.24461095595775853
a after update for 1 param tensor([ 0.169, -0.166, -0.053, -0.070,  0.067, -0.015, -0.074, -0.002, -0.022,
        -0.060, -0.121,  0.040, -0.111,  0.088, -0.047, -0.090, -0.056, -0.001,
        -0.079, -0.073, -0.142, -0.046, -0.036,  0.003,  0.024, -0.024, -0.004,
         0.072, -0.129,  0.042,  0.008,  0.017, -0.139,  0.014,  0.061,  0.067,
         0.124,  0.020,  0.099,  0.092,  0.079,  0.032, -0.060, -0.139, -0.045,
         0.001, -0.004, -0.087,  0.004,  0.144, -0.167, -0.100, -0.014,  0.027,
        -0.081, -0.066,  0.063,  0.051, -0.145,  0.041, -0.032, -0.040, -0.003,
         0.041, -0.029,  0.157,  0.012, -0.116, -0.074,  0.015,  0.008,  0.116,
        -0.128,  0.055, -0.023,  0.066, -0.023, -0.152, -0.050,  0.085,  0.008,
        -0.104, -0.018,  0.124, -0.011,  0.040, -0.049,  0.029,  0.010, -0.001,
         0.007,  0.131,  0.031,  0.134, -0.032, -0.215, -0.001, -0.081,  0.101,
         0.022, -0.013,  0.014,  0.058, -0.131, -0.015,  0.050,  0.068,  0.091,
         0.050, -0.129,  0.063,  0.042, -0.132, -0.099,  0.045,  0.041,  0.054,
        -0.045,  0.060,  0.001, -0.058,  0.049,  0.060,  0.022, -0.040,  0.016,
         0.058,  0.017,  0.081, -0.048, -0.002, -0.208, -0.132,  0.030,  0.079,
         0.044, -0.106,  0.079,  0.114, -0.130, -0.056, -0.076, -0.203, -0.013,
        -0.134, -0.028,  0.012, -0.133, -0.067, -0.010,  0.023,  0.039,  0.055,
        -0.052,  0.148, -0.041, -0.132, -0.036,  0.006,  0.024, -0.055,  0.018,
        -0.046, -0.075,  0.101, -0.047,  0.070, -0.097,  0.066, -0.078,  0.180,
         0.018,  0.004, -0.094, -0.039, -0.072, -0.003,  0.133,  0.044, -0.057,
         0.068,  0.047, -0.064, -0.090,  0.030, -0.055, -0.114,  0.045, -0.030,
         0.012, -0.076,  0.006,  0.004,  0.066,  0.051, -0.029, -0.073,  0.001,
         0.206, -0.138], device='cuda:0')
s after update for 1 param tensor([1.747, 1.531, 1.420, 1.613, 1.612, 1.501, 0.934, 1.115, 2.060, 0.950,
        1.392, 1.431, 1.524, 1.343, 1.777, 1.495, 1.397, 1.862, 1.058, 1.446,
        1.856, 1.317, 1.744, 1.867, 1.445, 2.000, 1.483, 1.352, 1.478, 1.880,
        1.549, 1.451, 1.001, 1.809, 1.067, 1.661, 1.338, 0.952, 1.405, 1.179,
        1.328, 1.318, 1.681, 1.804, 1.180, 1.806, 0.598, 1.669, 0.819, 1.831,
        1.741, 1.538, 1.651, 1.564, 1.404, 1.105, 1.928, 1.769, 1.544, 1.338,
        2.030, 1.561, 1.066, 1.026, 1.829, 2.147, 1.770, 1.626, 1.237, 0.956,
        1.630, 1.205, 1.389, 1.812, 1.635, 1.742, 1.568, 1.117, 1.912, 1.553,
        1.503, 1.543, 1.937, 1.579, 1.753, 1.547, 1.427, 1.191, 0.764, 1.334,
        1.858, 1.471, 1.904, 1.457, 1.594, 1.468, 1.289, 1.526, 1.599, 1.654,
        1.608, 1.760, 1.953, 1.541, 1.630, 1.129, 1.889, 1.779, 1.121, 1.225,
        1.825, 0.951, 1.532, 1.687, 1.622, 1.427, 1.529, 0.956, 1.337, 2.028,
        1.434, 1.002, 0.804, 2.058, 2.095, 1.425, 1.248, 1.194, 1.596, 1.428,
        1.272, 1.059, 1.442, 1.449, 0.892, 1.527, 1.679, 1.474, 1.390, 1.593,
        1.355, 1.648, 1.804, 0.915, 2.103, 2.205, 1.490, 2.033, 1.501, 1.697,
        1.526, 1.507, 1.080, 1.800, 1.987, 1.543, 1.592, 1.612, 1.902, 1.349,
        2.036, 1.871, 1.720, 1.791, 1.583, 1.706, 2.289, 1.524, 1.306, 1.681,
        0.957, 1.022, 0.953, 1.363, 1.044, 1.706, 1.063, 1.978, 0.552, 1.664,
        1.465, 1.544, 1.383, 2.057, 1.704, 1.206, 1.483, 0.983, 1.359, 1.363,
        1.870, 1.930, 1.128, 1.367, 2.055, 1.437, 1.363, 1.819, 1.509, 1.678],
       device='cuda:0')
b after update for 1 param tensor([109.641, 102.654,  98.848, 105.348, 105.310, 101.623,  80.163,  87.585,
        119.047,  80.862,  97.870,  99.232, 102.390,  96.140, 110.569, 101.441,
         98.053, 113.201,  85.338,  99.754, 113.016,  95.211, 109.532, 113.349,
         99.719, 117.304, 101.007,  96.456, 100.844, 113.747, 103.227,  99.924,
         82.980, 111.561,  85.696, 106.921,  95.962,  80.942,  98.319,  90.085,
         95.597,  95.244, 107.559, 111.410,  90.098, 111.471,  64.173, 107.153,
         75.063, 112.256, 109.456, 102.860, 106.595, 103.737,  98.297,  87.214,
        115.179, 110.343, 103.089,  95.962, 118.183, 103.625,  85.650,  84.035,
        112.197, 121.560, 110.364, 105.773,  92.252,  81.111, 105.909,  91.047,
         97.762, 111.674, 106.053, 109.476, 103.881,  87.689, 114.697, 103.370,
        101.689, 103.053, 115.459, 104.225, 109.826, 103.181,  99.090,  90.539,
         72.522,  95.795, 113.068, 100.596, 114.464, 100.138, 104.725, 100.493,
         94.169, 102.479, 104.882, 106.680, 105.177, 110.037, 115.923, 102.980,
        105.908,  88.151, 114.003, 110.652,  87.838,  91.802, 112.048,  80.874,
        102.660, 107.752, 105.659,  99.082, 102.558,  81.090,  95.902, 118.131,
         99.321,  83.041,  74.377, 119.006, 120.055,  99.012,  92.670,  90.636,
        104.786,  99.132,  93.545,  85.368,  99.618,  99.866,  78.365, 102.517,
        107.502, 100.699,  97.814, 104.713,  96.569, 106.490, 111.401,  79.338,
        120.302, 123.164, 101.252, 118.279, 101.638, 108.076, 102.471, 101.826,
         86.222, 111.304, 116.925, 103.042, 104.656, 105.309, 114.406,  96.352,
        118.361, 113.469, 108.800, 111.000, 104.366, 108.337, 125.505, 102.402,
         94.799, 107.558,  81.152,  83.867,  80.999,  96.846,  84.760, 108.332,
         85.512, 116.650,  61.653, 107.009, 100.400, 103.069,  97.542, 118.983,
        108.268,  91.085, 101.001,  82.244,  96.698,  96.861, 113.435, 115.250,
         88.087,  96.994, 118.924,  99.454,  96.828, 111.891, 101.912, 107.439],
       device='cuda:0')
clipping threshold 0.24461095595775853
a after update for 1 param tensor([[[-0.032],
         [ 0.049],
         [ 0.090],
         [ 0.074],
         [ 0.004],
         [-0.028],
         [ 0.089],
         [-0.008],
         [ 0.059],
         [-0.046]],

        [[-0.060],
         [-0.062],
         [ 0.056],
         [-0.009],
         [-0.053],
         [ 0.041],
         [ 0.046],
         [ 0.006],
         [-0.104],
         [ 0.092]],

        [[ 0.075],
         [ 0.131],
         [-0.029],
         [-0.117],
         [-0.179],
         [-0.064],
         [-0.033],
         [ 0.048],
         [ 0.052],
         [-0.000]],

        [[-0.149],
         [ 0.122],
         [-0.040],
         [-0.033],
         [-0.077],
         [ 0.117],
         [-0.096],
         [-0.193],
         [ 0.027],
         [ 0.095]],

        [[ 0.041],
         [-0.027],
         [ 0.013],
         [-0.038],
         [-0.127],
         [-0.037],
         [-0.079],
         [ 0.079],
         [ 0.012],
         [ 0.007]],

        [[-0.100],
         [ 0.051],
         [ 0.057],
         [ 0.014],
         [-0.102],
         [-0.087],
         [-0.037],
         [ 0.105],
         [-0.107],
         [ 0.098]],

        [[-0.112],
         [-0.032],
         [ 0.054],
         [ 0.100],
         [ 0.092],
         [ 0.004],
         [-0.128],
         [-0.024],
         [ 0.085],
         [-0.059]],

        [[ 0.008],
         [-0.066],
         [-0.052],
         [ 0.071],
         [ 0.015],
         [-0.018],
         [-0.086],
         [-0.141],
         [ 0.012],
         [ 0.031]],

        [[-0.013],
         [-0.001],
         [ 0.089],
         [-0.089],
         [ 0.033],
         [-0.012],
         [-0.022],
         [-0.113],
         [ 0.169],
         [-0.022]],

        [[ 0.040],
         [ 0.135],
         [ 0.069],
         [ 0.047],
         [ 0.027],
         [ 0.053],
         [-0.007],
         [ 0.042],
         [ 0.043],
         [-0.034]],

        [[-0.008],
         [-0.048],
         [-0.039],
         [-0.067],
         [-0.056],
         [ 0.009],
         [ 0.004],
         [-0.008],
         [ 0.016],
         [-0.042]],

        [[-0.001],
         [ 0.019],
         [ 0.053],
         [ 0.123],
         [ 0.083],
         [-0.116],
         [-0.076],
         [-0.049],
         [ 0.058],
         [ 0.111]],

        [[-0.023],
         [ 0.037],
         [-0.049],
         [-0.139],
         [ 0.153],
         [ 0.119],
         [-0.037],
         [-0.040],
         [ 0.059],
         [-0.180]],

        [[-0.072],
         [-0.010],
         [-0.053],
         [ 0.096],
         [ 0.104],
         [-0.038],
         [-0.008],
         [ 0.021],
         [-0.092],
         [-0.042]],

        [[-0.099],
         [ 0.047],
         [-0.062],
         [ 0.051],
         [ 0.034],
         [ 0.003],
         [ 0.076],
         [-0.005],
         [ 0.027],
         [-0.068]],

        [[ 0.130],
         [ 0.106],
         [ 0.039],
         [-0.011],
         [ 0.078],
         [-0.013],
         [ 0.007],
         [ 0.008],
         [-0.057],
         [-0.055]],

        [[-0.051],
         [-0.161],
         [-0.113],
         [ 0.059],
         [ 0.018],
         [-0.155],
         [ 0.024],
         [ 0.092],
         [-0.001],
         [-0.013]],

        [[ 0.048],
         [-0.100],
         [-0.005],
         [ 0.020],
         [ 0.037],
         [ 0.024],
         [-0.078],
         [ 0.004],
         [ 0.037],
         [ 0.068]],

        [[ 0.033],
         [ 0.028],
         [ 0.106],
         [-0.114],
         [-0.031],
         [-0.087],
         [ 0.021],
         [ 0.035],
         [-0.031],
         [-0.002]],

        [[ 0.105],
         [-0.079],
         [-0.066],
         [-0.068],
         [-0.021],
         [-0.163],
         [-0.066],
         [-0.070],
         [ 0.090],
         [-0.084]]], device='cuda:0')
s after update for 1 param tensor([[[1.782],
         [1.369],
         [0.974],
         [1.382],
         [1.026],
         [1.417],
         [1.290],
         [1.649],
         [1.940],
         [1.796]],

        [[1.520],
         [0.944],
         [1.858],
         [1.548],
         [1.444],
         [1.806],
         [1.571],
         [1.534],
         [1.104],
         [2.040]],

        [[1.558],
         [1.665],
         [1.905],
         [1.533],
         [1.536],
         [1.781],
         [1.297],
         [1.677],
         [0.984],
         [2.441]],

        [[1.741],
         [1.572],
         [1.542],
         [1.447],
         [1.132],
         [1.361],
         [1.442],
         [2.008],
         [2.075],
         [2.346]],

        [[1.995],
         [0.984],
         [1.464],
         [1.030],
         [1.480],
         [1.625],
         [1.164],
         [1.890],
         [1.237],
         [1.711]],

        [[0.830],
         [1.217],
         [1.903],
         [1.450],
         [2.130],
         [1.151],
         [1.758],
         [1.365],
         [1.433],
         [1.837]],

        [[1.469],
         [0.973],
         [0.793],
         [1.713],
         [1.143],
         [1.150],
         [1.159],
         [2.152],
         [1.661],
         [1.411]],

        [[1.391],
         [1.307],
         [1.725],
         [1.450],
         [1.027],
         [0.852],
         [0.955],
         [1.784],
         [1.840],
         [1.179]],

        [[1.519],
         [1.172],
         [1.307],
         [1.086],
         [1.341],
         [1.720],
         [1.754],
         [1.556],
         [1.326],
         [1.739]],

        [[1.545],
         [1.785],
         [1.100],
         [1.264],
         [1.774],
         [1.969],
         [1.736],
         [2.001],
         [1.968],
         [1.086]],

        [[1.130],
         [1.343],
         [0.978],
         [1.302],
         [2.100],
         [1.369],
         [1.329],
         [1.785],
         [1.774],
         [1.776]],

        [[1.806],
         [1.365],
         [1.270],
         [1.414],
         [1.909],
         [1.795],
         [1.613],
         [1.494],
         [1.643],
         [1.567]],

        [[2.012],
         [1.485],
         [1.667],
         [1.660],
         [1.762],
         [1.309],
         [1.668],
         [1.361],
         [1.761],
         [1.756]],

        [[1.607],
         [1.737],
         [1.723],
         [1.790],
         [1.522],
         [1.691],
         [1.902],
         [1.921],
         [1.502],
         [1.576]],

        [[1.418],
         [2.186],
         [1.307],
         [2.200],
         [1.523],
         [1.102],
         [1.626],
         [1.903],
         [1.625],
         [1.641]],

        [[1.860],
         [1.419],
         [1.407],
         [1.776],
         [1.703],
         [1.481],
         [1.621],
         [0.754],
         [1.527],
         [2.199]],

        [[2.126],
         [1.602],
         [1.753],
         [0.880],
         [1.973],
         [1.916],
         [0.795],
         [1.222],
         [1.709],
         [2.223]],

        [[1.138],
         [1.647],
         [0.995],
         [1.252],
         [1.308],
         [1.219],
         [1.455],
         [1.704],
         [1.145],
         [1.656]],

        [[1.188],
         [1.571],
         [1.105],
         [1.655],
         [1.606],
         [1.608],
         [1.027],
         [1.731],
         [1.472],
         [2.290]],

        [[2.038],
         [1.215],
         [1.218],
         [1.224],
         [1.087],
         [1.795],
         [1.695],
         [1.099],
         [1.656],
         [2.027]]], device='cuda:0')
b after update for 1 param tensor([[[110.739],
         [ 97.059],
         [ 81.849],
         [ 97.534],
         [ 84.019],
         [ 98.756],
         [ 94.197],
         [106.517],
         [115.542],
         [111.169]],

        [[102.259],
         [ 80.609],
         [113.064],
         [103.213],
         [ 99.695],
         [111.472],
         [103.977],
         [102.739],
         [ 87.163],
         [118.493]],

        [[103.550],
         [107.046],
         [114.498],
         [102.695],
         [102.810],
         [110.715],
         [ 94.460],
         [107.437],
         [ 82.276],
         [129.613]],

        [[109.457],
         [103.995],
         [103.017],
         [ 99.778],
         [ 88.248],
         [ 96.771],
         [ 99.611],
         [117.537],
         [119.480],
         [127.065]],

        [[117.176],
         [ 82.297],
         [100.365],
         [ 84.207],
         [100.911],
         [105.743],
         [ 89.511],
         [114.028],
         [ 92.254],
         [108.496]],

        [[ 75.568],
         [ 91.495],
         [114.418],
         [ 99.881],
         [121.074],
         [ 88.995],
         [109.983],
         [ 96.933],
         [ 99.303],
         [112.437]],

        [[100.552],
         [ 81.824],
         [ 73.856],
         [108.562],
         [ 88.693],
         [ 88.970],
         [ 89.301],
         [121.693],
         [106.904],
         [ 98.527]],

        [[ 97.850],
         [ 94.842],
         [108.959],
         [ 99.871],
         [ 84.078],
         [ 76.550],
         [ 81.062],
         [110.787],
         [112.532],
         [ 90.082]],

        [[102.241],
         [ 89.784],
         [ 94.845],
         [ 86.461],
         [ 96.067],
         [108.798],
         [109.852],
         [103.476],
         [ 95.527],
         [109.380]],

        [[103.106],
         [110.833],
         [ 86.992],
         [ 93.250],
         [110.485],
         [116.389],
         [109.289],
         [117.345],
         [116.374],
         [ 86.456]],

        [[ 88.182],
         [ 96.115],
         [ 82.051],
         [ 94.639],
         [120.215],
         [ 97.043],
         [ 95.642],
         [110.830],
         [110.496],
         [110.539]],

        [[111.481],
         [ 96.918],
         [ 93.491],
         [ 98.646],
         [114.620],
         [111.151],
         [105.360],
         [101.390],
         [106.336],
         [103.850]],

        [[117.659],
         [101.087],
         [107.096],
         [106.882],
         [110.109],
         [ 94.918],
         [107.147],
         [ 96.791],
         [110.076],
         [109.933]],

        [[105.165],
         [109.338],
         [108.893],
         [110.967],
         [102.328],
         [107.873],
         [114.406],
         [114.980],
         [101.647],
         [104.145]],

        [[ 98.772],
         [122.652],
         [ 94.836],
         [123.026],
         [102.379],
         [ 87.088],
         [105.772],
         [114.441],
         [105.751],
         [106.265]],

        [[113.119],
         [ 98.807],
         [ 98.383],
         [110.536],
         [108.265],
         [100.942],
         [105.597],
         [ 72.044],
         [102.499],
         [123.013]],

        [[120.943],
         [105.002],
         [109.828],
         [ 77.803],
         [116.516],
         [114.818],
         [ 73.979],
         [ 91.709],
         [108.428],
         [123.684]],

        [[ 88.499],
         [106.470],
         [ 82.728],
         [ 92.814],
         [ 94.869],
         [ 91.585],
         [100.048],
         [108.282],
         [ 88.775],
         [106.759]],

        [[ 90.404],
         [103.976],
         [ 87.190],
         [106.714],
         [105.127],
         [105.176],
         [ 84.058],
         [109.151],
         [100.639],
         [125.529]],

        [[118.418],
         [ 91.429],
         [ 91.555],
         [ 91.785],
         [ 86.485],
         [111.148],
         [108.000],
         [ 86.965],
         [106.735],
         [118.102]]], device='cuda:0')
clipping threshold 0.24461095595775853
a after update for 1 param tensor([[ 0.009],
        [-0.053],
        [ 0.044],
        [ 0.022],
        [ 0.011],
        [ 0.004],
        [ 0.022],
        [ 0.016],
        [-0.019],
        [-0.040],
        [ 0.078],
        [-0.125],
        [ 0.008],
        [-0.083],
        [-0.139],
        [ 0.085],
        [ 0.042],
        [ 0.029],
        [ 0.000],
        [-0.014]], device='cuda:0')
s after update for 1 param tensor([[1.827],
        [1.610],
        [1.459],
        [1.043],
        [1.709],
        [1.231],
        [1.852],
        [2.037],
        [1.745],
        [1.751],
        [1.146],
        [0.762],
        [1.983],
        [1.619],
        [1.447],
        [1.757],
        [1.535],
        [1.452],
        [1.859],
        [1.591]], device='cuda:0')
b after update for 1 param tensor([[112.123],
        [105.240],
        [100.195],
        [ 84.700],
        [108.431],
        [ 92.047],
        [112.895],
        [118.397],
        [109.574],
        [109.757],
        [ 88.797],
        [ 72.431],
        [116.807],
        [105.536],
        [ 99.782],
        [109.950],
        [102.776],
        [ 99.957],
        [113.108],
        [104.624]], device='cuda:0')
clipping threshold 0.24461095595775853
||w||^2 0.09435537528202037
exp ma of ||w||^2 0.09132906971334404
||w|| 0.3071732007874716
exp ma of ||w|| 0.2964826299086497
cuda
Objective function 21.48 = squared loss an data 19.93 + 0.5*rho*h**2 0.154802 + alpha*h 0.670335 + L2reg 0.60 + L1reg 0.13 ; SHD = 54 ; DAG True
Proportion of microbatches that were clipped  0.7606659729448492
iteration 1 in inner loop, alpha 380.96780785918975 rho 100000.0 h 0.001759557181692628
iteration 5 in outer loop, alpha = 2140.5249895518177, rho = 1000000.0, h = 0.001759557181692628
Threshold 0.3
[[0.002 0.287 0.193 0.036 0.421 0.365 0.169 0.019 0.013 0.172 0.253 0.247
  0.25  0.037 0.403 0.211 0.042 0.198 0.245 0.065]
 [0.011 0.002 0.258 0.017 0.122 0.529 0.235 0.005 0.009 0.143 0.192 0.074
  0.09  0.025 0.023 0.099 0.062 0.289 0.037 0.019]
 [0.015 0.01  0.002 0.012 0.046 0.122 0.102 0.007 0.008 0.047 0.058 0.012
  0.165 0.002 0.023 0.075 0.021 0.012 0.037 0.03 ]
 [0.083 0.136 0.303 0.002 0.105 0.126 0.225 0.016 0.006 0.337 0.233 0.172
  0.293 0.049 0.09  0.228 0.033 0.169 0.078 0.028]
 [0.009 0.023 0.07  0.02  0.002 0.214 0.022 0.004 0.002 0.025 0.139 0.008
  0.083 0.013 0.018 0.018 0.006 0.015 0.02  0.018]
 [0.012 0.005 0.017 0.015 0.018 0.002 0.008 0.005 0.005 0.009 0.016 0.009
  0.012 0.013 0.006 0.008 0.007 0.009 0.004 0.005]
 [0.014 0.01  0.026 0.01  0.172 0.286 0.002 0.009 0.007 0.053 0.126 0.007
  0.035 0.01  0.028 0.044 0.002 0.068 0.059 0.013]
 [0.192 0.505 0.243 0.132 0.596 0.182 0.243 0.002 0.102 0.269 0.369 0.583
  0.772 0.083 0.579 0.243 0.073 1.426 0.233 0.236]
 [0.19  0.34  0.465 0.58  0.781 0.572 0.354 0.019 0.002 0.357 0.604 0.512
  0.192 0.334 0.359 0.265 0.201 0.499 0.679 0.269]
 [0.016 0.025 0.124 0.01  0.102 0.369 0.049 0.009 0.007 0.002 0.412 0.032
  0.232 0.01  0.075 0.299 0.034 0.076 0.008 0.011]
 [0.01  0.014 0.051 0.01  0.025 0.216 0.04  0.007 0.005 0.009 0.002 0.006
  0.016 0.016 0.01  0.01  0.013 0.029 0.01  0.006]
 [0.009 0.054 0.249 0.027 0.371 0.249 0.298 0.005 0.005 0.082 0.336 0.002
  0.398 0.022 0.045 0.471 0.065 0.281 0.061 0.119]
 [0.013 0.016 0.019 0.014 0.04  0.186 0.149 0.003 0.008 0.014 0.154 0.005
  0.002 0.009 0.007 0.017 0.008 0.078 0.02  0.022]
 [0.098 0.126 1.421 0.067 0.146 0.125 0.222 0.019 0.007 0.257 0.144 0.179
  0.2   0.001 0.29  0.415 0.12  0.185 0.254 0.234]
 [0.006 0.133 0.115 0.022 0.145 0.448 0.077 0.004 0.007 0.044 0.242 0.045
  0.554 0.009 0.002 0.125 0.022 0.065 0.013 0.082]
 [0.013 0.03  0.041 0.012 0.104 0.192 0.06  0.011 0.008 0.012 0.25  0.005
  0.142 0.007 0.017 0.002 0.01  0.131 0.01  0.023]
 [0.066 0.028 0.124 0.09  0.321 0.258 0.73  0.045 0.019 0.054 0.287 0.046
  0.254 0.022 0.133 0.296 0.002 0.096 0.106 0.105]
 [0.018 0.008 0.135 0.011 0.133 0.322 0.036 0.002 0.006 0.033 0.104 0.014
  0.045 0.019 0.025 0.025 0.017 0.002 0.013 0.008]
 [0.01  0.071 0.075 0.029 0.176 0.582 0.045 0.011 0.005 0.462 0.196 0.046
  0.114 0.016 0.149 0.375 0.013 0.194 0.003 0.045]
 [0.058 0.166 0.115 0.078 0.168 0.281 0.293 0.01  0.021 0.272 0.487 0.027
  0.14  0.011 0.028 0.17  0.024 0.285 0.034 0.002]]
[[0.    0.    0.    0.    0.421 0.365 0.    0.    0.    0.    0.    0.
  0.    0.    0.403 0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.529 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.303 0.    0.    0.    0.    0.    0.    0.337 0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.505 0.    0.    0.596 0.    0.    0.    0.    0.    0.369 0.583
  0.772 0.    0.579 0.    0.    1.426 0.    0.   ]
 [0.    0.34  0.465 0.58  0.781 0.572 0.354 0.    0.    0.357 0.604 0.512
  0.    0.334 0.359 0.    0.    0.499 0.679 0.   ]
 [0.    0.    0.    0.    0.    0.369 0.    0.    0.    0.    0.412 0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.371 0.    0.    0.    0.    0.    0.336 0.
  0.398 0.    0.    0.471 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    1.421 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.415 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.448 0.    0.    0.    0.    0.    0.
  0.554 0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.321 0.    0.73  0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.322 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.582 0.    0.    0.    0.462 0.    0.
  0.    0.    0.    0.375 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.487 0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]]
{'fdr': 0.5116279069767442, 'tpr': 0.35, 'fpr': 0.16923076923076924, 'f1': 0.4077669902912621, 'shd': 54, 'npred': 43, 'ntrue': 60}
[0.287 0.193 0.036 0.421 0.365 0.169 0.019 0.013 0.172 0.253 0.247 0.25
 0.037 0.403 0.211 0.042 0.198 0.245 0.065 0.011 0.258 0.017 0.122 0.529
 0.235 0.005 0.009 0.143 0.192 0.074 0.09  0.025 0.023 0.099 0.062 0.289
 0.037 0.019 0.015 0.01  0.012 0.046 0.122 0.102 0.007 0.008 0.047 0.058
 0.012 0.165 0.002 0.023 0.075 0.021 0.012 0.037 0.03  0.083 0.136 0.303
 0.105 0.126 0.225 0.016 0.006 0.337 0.233 0.172 0.293 0.049 0.09  0.228
 0.033 0.169 0.078 0.028 0.009 0.023 0.07  0.02  0.214 0.022 0.004 0.002
 0.025 0.139 0.008 0.083 0.013 0.018 0.018 0.006 0.015 0.02  0.018 0.012
 0.005 0.017 0.015 0.018 0.008 0.005 0.005 0.009 0.016 0.009 0.012 0.013
 0.006 0.008 0.007 0.009 0.004 0.005 0.014 0.01  0.026 0.01  0.172 0.286
 0.009 0.007 0.053 0.126 0.007 0.035 0.01  0.028 0.044 0.002 0.068 0.059
 0.013 0.192 0.505 0.243 0.132 0.596 0.182 0.243 0.102 0.269 0.369 0.583
 0.772 0.083 0.579 0.243 0.073 1.426 0.233 0.236 0.19  0.34  0.465 0.58
 0.781 0.572 0.354 0.019 0.357 0.604 0.512 0.192 0.334 0.359 0.265 0.201
 0.499 0.679 0.269 0.016 0.025 0.124 0.01  0.102 0.369 0.049 0.009 0.007
 0.412 0.032 0.232 0.01  0.075 0.299 0.034 0.076 0.008 0.011 0.01  0.014
 0.051 0.01  0.025 0.216 0.04  0.007 0.005 0.009 0.006 0.016 0.016 0.01
 0.01  0.013 0.029 0.01  0.006 0.009 0.054 0.249 0.027 0.371 0.249 0.298
 0.005 0.005 0.082 0.336 0.398 0.022 0.045 0.471 0.065 0.281 0.061 0.119
 0.013 0.016 0.019 0.014 0.04  0.186 0.149 0.003 0.008 0.014 0.154 0.005
 0.009 0.007 0.017 0.008 0.078 0.02  0.022 0.098 0.126 1.421 0.067 0.146
 0.125 0.222 0.019 0.007 0.257 0.144 0.179 0.2   0.29  0.415 0.12  0.185
 0.254 0.234 0.006 0.133 0.115 0.022 0.145 0.448 0.077 0.004 0.007 0.044
 0.242 0.045 0.554 0.009 0.125 0.022 0.065 0.013 0.082 0.013 0.03  0.041
 0.012 0.104 0.192 0.06  0.011 0.008 0.012 0.25  0.005 0.142 0.007 0.017
 0.01  0.131 0.01  0.023 0.066 0.028 0.124 0.09  0.321 0.258 0.73  0.045
 0.019 0.054 0.287 0.046 0.254 0.022 0.133 0.296 0.096 0.106 0.105 0.018
 0.008 0.135 0.011 0.133 0.322 0.036 0.002 0.006 0.033 0.104 0.014 0.045
 0.019 0.025 0.025 0.017 0.013 0.008 0.01  0.071 0.075 0.029 0.176 0.582
 0.045 0.011 0.005 0.462 0.196 0.046 0.114 0.016 0.149 0.375 0.013 0.194
 0.045 0.058 0.166 0.115 0.078 0.168 0.281 0.293 0.01  0.021 0.272 0.487
 0.027 0.14  0.011 0.028 0.17  0.024 0.285 0.034]
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0.]
 [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.
 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1.
 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.6943229166666667, 0.42826211642805295)
Iterations 2500
Achieves (3.6993101023104464, 1e-05)-DP
