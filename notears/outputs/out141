samples  5000  graph  30 90 ER mlp  minibatch size  50  noise  1.0  minibatches per NN training  250 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 2.115034010050131
iteration 1 in outer loop, alpha = 2.115034010050131, rho = 1.0, h = 2.115034010050131
cuda
iteration 1 in inner loop,alpha 2.115034010050131 rho 1.0 h 1.3374026753201562
iteration 2 in inner loop,alpha 2.115034010050131 rho 10.0 h 0.5764720350935555
iteration 3 in inner loop,alpha 2.115034010050131 rho 100.0 h 0.17913910773663844
iteration 2 in outer loop, alpha = 20.028944783713975, rho = 100.0, h = 0.17913910773663844
cuda
iteration 1 in inner loop,alpha 20.028944783713975 rho 100.0 h 0.09436179946636969
iteration 2 in inner loop,alpha 20.028944783713975 rho 1000.0 h 0.03470738214967639
iteration 3 in outer loop, alpha = 54.736326933390366, rho = 1000.0, h = 0.03470738214967639
cuda
iteration 1 in inner loop,alpha 54.736326933390366 rho 1000.0 h 0.017431511737619587
iteration 2 in inner loop,alpha 54.736326933390366 rho 10000.0 h 0.005915530266015878
iteration 4 in outer loop, alpha = 113.89162959354914, rho = 10000.0, h = 0.005915530266015878
cuda
iteration 1 in inner loop,alpha 113.89162959354914 rho 10000.0 h 0.0030144797901456855
iteration 2 in inner loop,alpha 113.89162959354914 rho 100000.0 h 0.0009541529215439937
iteration 5 in outer loop, alpha = 209.3069217479485, rho = 100000.0, h = 0.0009541529215439937
cuda
iteration 1 in inner loop,alpha 209.3069217479485 rho 100000.0 h 0.0004507255397783183
iteration 6 in outer loop, alpha = 660.0324615262668, rho = 1000000.0, h = 0.0004507255397783183
Threshold 0.3
[[0.005 0.001 0.001 1.917 0.    0.001 0.001 0.001 0.001 0.    0.    0.002
  0.    0.    0.    0.185 0.    0.    0.91  0.283 0.    0.    1.619 0.
  0.    0.    0.068 0.    0.113 0.   ]
 [1.001 0.003 0.359 0.489 0.    0.135 0.002 0.389 0.001 0.    0.    1.04
  0.    0.    0.001 1.589 0.001 0.001 0.926 0.335 0.001 0.001 0.064 0.001
  0.    0.001 0.447 0.    0.198 0.001]
 [0.337 0.001 0.003 0.327 0.001 0.115 0.    0.23  0.    0.    0.    0.282
  0.    0.    0.    0.22  0.    0.001 0.168 0.218 0.    0.    0.123 0.
  0.    0.    0.18  0.    0.194 0.   ]
 [0.    0.    0.    0.007 0.    0.    0.002 0.    0.    0.    0.    0.
  0.    0.    0.    1.705 0.    0.    0.821 1.105 0.    0.    0.233 0.
  0.    0.    0.034 0.    0.144 0.   ]
 [0.195 0.159 0.23  0.204 0.002 0.128 0.009 0.136 0.001 0.    0.    0.259
  0.    0.    0.001 0.25  0.    0.    0.108 0.249 0.    0.    0.098 0.
  0.    0.    0.048 0.    0.192 0.   ]
 [0.409 0.001 0.001 0.264 0.001 0.002 0.002 0.001 0.    0.    0.    0.001
  0.    0.    0.    0.145 0.    0.    0.802 1.206 0.    0.    0.076 0.
  0.    0.    0.041 0.    1.178 0.   ]
 [0.076 0.199 0.152 0.141 0.061 0.13  0.001 0.068 0.567 0.006 0.031 0.095
  0.    0.006 0.    0.153 0.    0.001 0.595 0.101 0.036 0.062 0.068 0.001
  0.    0.002 0.062 0.    0.048 0.001]
 [0.964 0.    0.005 0.377 0.001 1.933 0.003 0.003 0.001 0.    0.    0.002
  0.    0.    0.    0.196 0.    0.    0.147 1.204 0.    0.001 0.086 0.
  0.    0.    0.017 0.    0.192 0.001]
 [0.135 0.231 0.106 0.157 0.143 0.084 0.001 0.159 0.001 0.006 0.097 0.118
  0.    0.021 0.001 0.251 0.    0.001 0.094 1.115 0.124 0.171 0.083 0.011
  0.    0.005 0.497 0.    0.112 0.001]
 [0.162 0.103 0.173 1.606 0.054 0.317 0.022 2.543 0.016 0.003 0.428 0.576
  0.001 3.37  0.016 0.315 0.002 0.459 0.132 0.234 0.276 0.102 0.389 0.113
  0.    0.459 0.176 0.002 0.27  0.286]
 [0.992 0.109 0.117 1.979 0.142 0.172 0.033 0.216 0.004 0.001 0.001 0.239
  0.006 0.084 0.001 1.127 0.001 0.073 0.249 0.171 2.746 1.115 1.447 0.076
  0.001 0.286 0.117 0.001 0.093 0.077]
 [0.193 0.    0.002 0.255 0.001 0.112 0.002 0.295 0.001 0.    0.    0.003
  0.    0.    0.    0.2   0.    0.    0.157 0.338 0.    0.    1.335 0.001
  0.    0.    0.011 0.    0.142 0.   ]
 [1.023 0.819 0.071 0.216 0.008 1.694 0.612 0.084 0.174 0.028 0.059 0.234
  0.001 0.001 0.001 0.104 0.011 0.167 0.532 0.073 0.035 0.024 0.171 0.044
  0.003 3.146 0.111 0.005 1.039 0.463]
 [0.943 2.17  1.863 0.685 0.027 0.28  0.01  1.803 0.002 0.    0.005 1.857
  0.004 0.001 0.001 0.308 0.002 0.192 0.335 0.798 0.128 0.011 0.221 0.003
  0.    0.026 0.113 0.001 0.262 0.076]
 [0.144 0.066 1.61  0.144 0.086 0.146 0.401 0.075 0.002 0.001 0.004 0.073
  0.008 0.038 0.    1.393 0.017 0.062 0.074 0.772 0.028 0.016 0.121 0.012
  0.006 0.08  0.013 0.028 0.05  0.06 ]
 [0.    0.    0.    0.001 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.003 0.    0.    0.061 0.255 0.    0.    0.004 0.
  0.    0.    0.001 0.    0.067 0.   ]
 [0.141 0.041 1.395 0.165 0.018 0.084 0.681 0.121 0.044 0.021 0.005 0.147
  0.005 0.003 0.001 0.101 0.001 0.038 0.09  0.772 0.052 0.022 0.078 0.026
  0.011 0.016 0.445 0.005 0.156 1.957]
 [0.13  0.127 0.157 1.491 1.345 0.094 0.187 0.283 0.151 0.    0.001 0.315
  0.    0.    0.001 1.165 0.    0.001 0.14  0.252 0.026 0.003 0.175 0.
  0.    0.    0.069 0.    0.975 0.   ]
 [0.002 0.    0.    0.006 0.001 0.    0.001 0.    0.    0.    0.    0.001
  0.    0.    0.    0.029 0.    0.    0.008 0.032 0.    0.    0.009 0.
  0.    0.    0.026 0.    0.014 0.   ]
 [0.    0.    0.    0.001 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.022 0.003 0.    0.    0.005 0.
  0.    0.    0.002 0.    1.176 0.   ]
 [0.908 1.221 1.821 0.32  2.103 0.096 0.005 0.113 0.001 0.    0.    1.271
  0.001 0.001 0.001 0.621 0.002 0.009 0.132 0.994 0.002 0.001 0.16  0.001
  0.    0.006 0.131 0.001 0.125 0.004]
 [0.751 0.24  0.192 0.3   0.131 0.015 0.01  0.125 0.001 0.001 0.    0.263
  0.004 0.03  0.003 0.316 0.001 0.049 0.103 0.14  0.464 0.001 0.074 0.038
  0.    0.114 0.058 0.002 0.099 0.024]
 [0.    0.001 0.    0.002 0.001 0.    0.001 0.    0.001 0.    0.    0.001
  0.    0.    0.    0.147 0.    0.    0.118 0.108 0.    0.    0.004 0.
  0.    0.    0.003 0.    0.251 0.   ]
 [1.165 0.083 0.083 0.242 0.111 0.034 0.071 0.286 0.008 0.002 0.001 0.123
  0.    0.041 0.001 0.09  0.007 0.19  0.102 0.117 0.086 0.002 0.087 0.001
  0.    0.001 0.015 0.    0.172 0.094]
 [0.049 0.252 0.033 0.288 0.106 0.163 0.075 0.45  0.002 4.088 1.006 0.219
  0.013 0.342 0.001 0.035 0.014 0.177 0.076 0.082 0.12  0.022 0.193 0.001
  0.001 1.647 0.016 0.001 0.721 0.158]
 [0.46  0.356 0.202 0.227 0.091 1.912 0.083 0.135 0.047 0.001 0.    0.066
  0.    0.013 0.001 0.148 0.002 0.388 0.205 0.203 0.097 0.003 0.054 0.243
  0.001 0.001 0.569 0.014 1.215 1.879]
 [0.008 0.005 0.001 0.026 0.008 0.012 0.003 0.004 0.001 0.    0.    0.078
  0.    0.    0.001 0.251 0.    0.006 0.237 0.219 0.002 0.001 1.534 0.002
  0.    0.    0.005 0.001 1.147 0.001]
 [0.216 0.022 0.011 0.157 2.184 0.181 0.035 1.606 0.022 0.002 0.012 1.995
  0.002 0.038 0.002 0.138 0.023 1.016 0.138 0.321 0.006 0.038 0.106 1.481
  0.006 0.002 0.037 0.001 0.111 0.077]
 [0.    0.001 0.    0.    0.    0.    0.001 0.    0.    0.    0.    0.
  0.    0.    0.    0.001 0.    0.    0.06  0.    0.    0.    0.001 0.
  0.    0.    0.002 0.    0.003 0.   ]
 [0.205 0.074 1.803 0.135 0.105 0.101 0.059 0.087 0.052 0.    0.    0.12
  0.    0.001 0.001 0.172 0.    1.091 0.112 0.18  0.032 0.002 0.095 0.003
  0.    0.    0.712 0.001 0.346 0.001]]
[[0.    0.    0.    1.917 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.91  0.    0.    0.    1.619 0.
  0.    0.    0.    0.    0.    0.   ]
 [1.001 0.    0.359 0.489 0.    0.    0.    0.389 0.    0.    0.    1.04
  0.    0.    0.    1.589 0.    0.    0.926 0.335 0.    0.    0.    0.
  0.    0.    0.447 0.    0.    0.   ]
 [0.337 0.    0.    0.327 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    1.705 0.    0.    0.821 1.105 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.409 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.802 1.206 0.    0.    0.    0.
  0.    0.    0.    0.    1.178 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.567 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.595 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.964 0.    0.    0.377 0.    1.933 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    1.204 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    1.115 0.    0.    0.    0.
  0.    0.    0.497 0.    0.    0.   ]
 [0.    0.    0.    1.606 0.    0.317 0.    2.543 0.    0.    0.428 0.576
  0.    3.37  0.    0.315 0.    0.459 0.    0.    0.    0.    0.389 0.
  0.    0.459 0.    0.    0.    0.   ]
 [0.992 0.    0.    1.979 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    1.127 0.    0.    0.    0.    2.746 1.115 1.447 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.338 0.    0.    1.335 0.
  0.    0.    0.    0.    0.    0.   ]
 [1.023 0.819 0.    0.    0.    1.694 0.612 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.532 0.    0.    0.    0.    0.
  0.    3.146 0.    0.    1.039 0.463]
 [0.943 2.17  1.863 0.685 0.    0.    0.    1.803 0.    0.    0.    1.857
  0.    0.    0.    0.308 0.    0.    0.335 0.798 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    1.61  0.    0.    0.    0.401 0.    0.    0.    0.    0.
  0.    0.    0.    1.393 0.    0.    0.    0.772 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    1.395 0.    0.    0.    0.681 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.772 0.    0.    0.    0.
  0.    0.    0.445 0.    0.    1.957]
 [0.    0.    0.    1.491 1.345 0.    0.    0.    0.    0.    0.    0.315
  0.    0.    0.    1.165 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.975 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    1.176 0.   ]
 [0.908 1.221 1.821 0.32  2.103 0.    0.    0.    0.    0.    0.    1.271
  0.    0.    0.    0.621 0.    0.    0.    0.994 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.751 0.    0.    0.3   0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.316 0.    0.    0.    0.    0.464 0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [1.165 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.45  0.    4.088 1.006 0.
  0.    0.342 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    1.647 0.    0.    0.721 0.   ]
 [0.46  0.356 0.    0.    0.    1.912 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.388 0.    0.    0.    0.    0.    0.
  0.    0.    0.569 0.    1.215 1.879]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.534 0.
  0.    0.    0.    0.    1.147 0.   ]
 [0.    0.    0.    0.    2.184 0.    0.    1.606 0.    0.    0.    1.995
  0.    0.    0.    0.    0.    1.016 0.    0.321 0.    0.    0.    1.481
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    1.803 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    1.091 0.    0.    0.    0.    0.    0.
  0.    0.    0.712 0.    0.346 0.   ]]
{'fdr': 0.29914529914529914, 'tpr': 0.9111111111111111, 'fpr': 0.10144927536231885, 'f1': 0.7922705314009661, 'shd': 42, 'npred': 117, 'ntrue': 90}
[9.515e-04 8.746e-04 1.917e+00 4.083e-04 6.357e-04 6.301e-04 7.153e-04
 7.106e-04 2.622e-05 4.220e-05 1.692e-03 5.963e-05 2.433e-05 4.646e-05
 1.855e-01 1.122e-05 3.171e-04 9.096e-01 2.830e-01 4.975e-04 1.326e-04
 1.619e+00 2.867e-05 2.140e-05 3.623e-05 6.830e-02 1.904e-05 1.130e-01
 9.718e-05 1.001e+00 3.592e-01 4.893e-01 4.605e-04 1.350e-01 1.614e-03
 3.893e-01 1.116e-03 5.805e-06 3.242e-05 1.040e+00 3.734e-04 2.006e-05
 1.140e-03 1.589e+00 7.855e-04 1.182e-03 9.260e-01 3.351e-01 7.931e-04
 6.540e-04 6.435e-02 9.919e-04 4.173e-06 8.416e-04 4.467e-01 1.134e-05
 1.982e-01 9.004e-04 3.365e-01 1.290e-03 3.267e-01 6.617e-04 1.146e-01
 3.714e-04 2.305e-01 3.516e-04 1.194e-04 1.851e-05 2.824e-01 9.486e-06
 2.086e-04 1.360e-05 2.203e-01 9.575e-05 1.161e-03 1.684e-01 2.182e-01
 2.654e-04 1.447e-04 1.233e-01 2.494e-04 5.378e-05 1.106e-05 1.798e-01
 1.203e-05 1.938e-01 1.047e-04 1.368e-04 1.670e-04 1.201e-04 2.557e-04
 1.555e-04 2.018e-03 1.081e-04 4.359e-04 5.057e-05 1.531e-04 4.419e-04
 4.343e-05 8.668e-06 1.050e-04 1.705e+00 1.826e-05 1.169e-04 8.212e-01
 1.105e+00 8.779e-05 4.164e-05 2.326e-01 4.485e-05 6.831e-06 3.716e-05
 3.387e-02 3.191e-06 1.444e-01 4.058e-05 1.952e-01 1.588e-01 2.297e-01
 2.040e-01 1.277e-01 8.905e-03 1.363e-01 7.986e-04 2.680e-04 1.972e-05
 2.585e-01 5.469e-06 4.109e-04 5.258e-04 2.497e-01 4.811e-05 2.782e-04
 1.078e-01 2.491e-01 4.665e-04 2.667e-04 9.755e-02 3.563e-04 2.099e-05
 1.353e-04 4.820e-02 3.241e-05 1.918e-01 1.544e-04 4.089e-01 5.260e-04
 1.264e-03 2.640e-01 1.058e-03 1.610e-03 6.268e-04 2.368e-04 9.004e-06
 3.110e-05 8.495e-04 3.115e-05 7.413e-05 7.684e-05 1.453e-01 1.127e-04
 2.109e-04 8.024e-01 1.206e+00 5.536e-05 4.595e-04 7.606e-02 8.287e-05
 1.115e-05 8.833e-05 4.107e-02 5.666e-05 1.178e+00 2.115e-04 7.597e-02
 1.987e-01 1.516e-01 1.411e-01 6.053e-02 1.299e-01 6.824e-02 5.666e-01
 6.469e-03 3.099e-02 9.538e-02 4.414e-04 5.607e-03 2.596e-04 1.530e-01
 4.549e-04 5.713e-04 5.945e-01 1.006e-01 3.576e-02 6.201e-02 6.813e-02
 1.377e-03 2.203e-05 1.877e-03 6.211e-02 4.405e-04 4.774e-02 9.645e-04
 9.642e-01 4.782e-04 4.569e-03 3.774e-01 1.097e-03 1.933e+00 3.189e-03
 5.054e-04 7.930e-06 3.051e-05 2.339e-03 5.579e-06 1.145e-04 1.018e-04
 1.956e-01 8.790e-06 1.962e-04 1.472e-01 1.204e+00 6.922e-05 8.456e-04
 8.554e-02 9.033e-05 8.457e-06 2.438e-04 1.748e-02 8.687e-05 1.924e-01
 5.588e-04 1.350e-01 2.309e-01 1.058e-01 1.573e-01 1.434e-01 8.420e-02
 9.016e-04 1.588e-01 5.772e-03 9.674e-02 1.176e-01 3.837e-04 2.063e-02
 9.512e-04 2.509e-01 2.958e-05 1.215e-03 9.427e-02 1.115e+00 1.239e-01
 1.711e-01 8.300e-02 1.112e-02 2.983e-04 4.634e-03 4.974e-01 4.923e-04
 1.117e-01 8.098e-04 1.617e-01 1.032e-01 1.731e-01 1.606e+00 5.379e-02
 3.166e-01 2.174e-02 2.543e+00 1.566e-02 4.277e-01 5.756e-01 1.059e-03
 3.370e+00 1.554e-02 3.152e-01 1.652e-03 4.592e-01 1.322e-01 2.342e-01
 2.756e-01 1.015e-01 3.885e-01 1.127e-01 4.329e-04 4.585e-01 1.761e-01
 1.959e-03 2.696e-01 2.856e-01 9.917e-01 1.090e-01 1.167e-01 1.979e+00
 1.424e-01 1.719e-01 3.254e-02 2.159e-01 4.327e-03 9.576e-04 2.390e-01
 6.138e-03 8.409e-02 7.505e-04 1.127e+00 1.197e-03 7.335e-02 2.493e-01
 1.711e-01 2.746e+00 1.115e+00 1.447e+00 7.555e-02 1.184e-03 2.857e-01
 1.170e-01 7.951e-04 9.275e-02 7.670e-02 1.926e-01 1.643e-04 2.217e-03
 2.545e-01 5.019e-04 1.121e-01 2.094e-03 2.947e-01 6.051e-04 2.798e-05
 1.802e-05 3.316e-05 5.173e-05 7.113e-05 2.000e-01 6.942e-05 2.177e-04
 1.566e-01 3.381e-01 3.261e-04 5.879e-05 1.335e+00 1.142e-03 2.260e-05
 2.208e-04 1.108e-02 1.787e-04 1.418e-01 1.134e-04 1.023e+00 8.192e-01
 7.106e-02 2.160e-01 8.097e-03 1.694e+00 6.122e-01 8.413e-02 1.741e-01
 2.837e-02 5.923e-02 2.340e-01 6.330e-04 1.369e-03 1.045e-01 1.126e-02
 1.668e-01 5.316e-01 7.293e-02 3.543e-02 2.385e-02 1.714e-01 4.375e-02
 2.774e-03 3.146e+00 1.108e-01 4.578e-03 1.039e+00 4.629e-01 9.433e-01
 2.170e+00 1.863e+00 6.845e-01 2.670e-02 2.805e-01 1.037e-02 1.803e+00
 2.101e-03 2.350e-04 5.225e-03 1.857e+00 4.251e-03 1.162e-03 3.080e-01
 1.585e-03 1.916e-01 3.349e-01 7.979e-01 1.281e-01 1.109e-02 2.212e-01
 3.282e-03 7.329e-05 2.605e-02 1.125e-01 1.189e-03 2.617e-01 7.632e-02
 1.444e-01 6.569e-02 1.610e+00 1.442e-01 8.636e-02 1.463e-01 4.006e-01
 7.546e-02 1.776e-03 1.316e-03 4.493e-03 7.334e-02 8.195e-03 3.850e-02
 1.393e+00 1.661e-02 6.152e-02 7.373e-02 7.717e-01 2.833e-02 1.633e-02
 1.211e-01 1.232e-02 6.066e-03 7.971e-02 1.315e-02 2.809e-02 4.953e-02
 5.995e-02 1.930e-05 1.204e-04 1.293e-04 7.841e-04 1.184e-04 7.077e-05
 2.821e-04 7.042e-05 2.777e-05 2.154e-05 2.630e-05 3.191e-04 3.181e-05
 1.104e-05 1.465e-05 6.280e-05 4.095e-05 6.109e-02 2.548e-01 3.346e-05
 5.456e-05 4.124e-03 1.734e-05 1.673e-05 2.458e-05 1.085e-03 4.660e-06
 6.706e-02 4.002e-05 1.412e-01 4.067e-02 1.395e+00 1.650e-01 1.824e-02
 8.384e-02 6.810e-01 1.214e-01 4.433e-02 2.139e-02 4.826e-03 1.473e-01
 5.017e-03 2.655e-03 1.366e-03 1.009e-01 3.826e-02 8.960e-02 7.717e-01
 5.230e-02 2.158e-02 7.775e-02 2.556e-02 1.082e-02 1.609e-02 4.446e-01
 5.385e-03 1.558e-01 1.957e+00 1.297e-01 1.270e-01 1.567e-01 1.491e+00
 1.345e+00 9.401e-02 1.869e-01 2.827e-01 1.513e-01 6.914e-05 1.488e-03
 3.147e-01 3.091e-05 3.206e-04 1.293e-03 1.165e+00 2.685e-05 1.404e-01
 2.520e-01 2.552e-02 3.049e-03 1.751e-01 3.197e-04 8.400e-06 9.519e-05
 6.896e-02 1.456e-05 9.747e-01 1.658e-04 2.014e-03 2.114e-04 2.271e-04
 5.853e-03 1.012e-03 1.944e-04 8.914e-04 3.864e-04 4.449e-04 2.811e-05
 1.702e-04 1.245e-03 6.638e-05 2.520e-05 2.728e-05 2.942e-02 1.147e-04
 1.382e-04 3.182e-02 1.280e-04 1.529e-04 9.156e-03 1.085e-04 1.503e-05
 3.294e-05 2.570e-02 2.178e-05 1.354e-02 1.319e-04 4.288e-05 7.377e-05
 1.777e-04 7.205e-04 4.780e-05 1.461e-04 5.657e-05 2.151e-05 2.361e-05
 6.315e-06 2.471e-05 2.706e-04 8.620e-05 3.345e-05 4.813e-05 3.989e-04
 8.928e-05 1.918e-05 2.207e-02 5.996e-05 2.571e-05 5.322e-03 3.677e-05
 1.284e-05 1.168e-05 1.588e-03 9.995e-06 1.176e+00 1.195e-05 9.077e-01
 1.221e+00 1.821e+00 3.203e-01 2.103e+00 9.579e-02 5.051e-03 1.128e-01
 8.748e-04 6.088e-05 1.440e-05 1.271e+00 7.007e-04 1.271e-03 1.309e-03
 6.207e-01 1.832e-03 9.287e-03 1.322e-01 9.944e-01 5.434e-04 1.604e-01
 1.234e-03 1.820e-05 5.505e-03 1.306e-01 1.417e-03 1.247e-01 3.876e-03
 7.510e-01 2.395e-01 1.924e-01 3.003e-01 1.306e-01 1.501e-02 9.605e-03
 1.254e-01 1.294e-03 5.364e-04 8.036e-05 2.635e-01 3.864e-03 3.043e-02
 2.816e-03 3.164e-01 1.478e-03 4.905e-02 1.032e-01 1.398e-01 4.636e-01
 7.450e-02 3.830e-02 2.971e-04 1.139e-01 5.827e-02 1.555e-03 9.883e-02
 2.399e-02 8.764e-05 6.638e-04 4.228e-04 2.461e-03 7.385e-04 3.282e-04
 1.055e-03 5.287e-05 5.339e-04 2.100e-05 7.642e-05 1.107e-03 7.709e-05
 1.422e-05 8.874e-05 1.470e-01 3.323e-04 2.699e-04 1.181e-01 1.081e-01
 3.549e-04 2.629e-05 4.026e-05 3.747e-05 1.445e-04 3.262e-03 7.226e-05
 2.512e-01 3.915e-04 1.165e+00 8.312e-02 8.296e-02 2.422e-01 1.106e-01
 3.423e-02 7.085e-02 2.858e-01 7.815e-03 1.602e-03 1.318e-03 1.228e-01
 3.938e-05 4.127e-02 1.288e-03 9.006e-02 6.603e-03 1.903e-01 1.015e-01
 1.171e-01 8.576e-02 1.596e-03 8.703e-02 2.672e-05 5.383e-04 1.466e-02
 1.562e-04 1.715e-01 9.356e-02 4.907e-02 2.524e-01 3.261e-02 2.878e-01
 1.057e-01 1.631e-01 7.461e-02 4.503e-01 2.217e-03 4.088e+00 1.006e+00
 2.189e-01 1.262e-02 3.415e-01 8.347e-04 3.548e-02 1.386e-02 1.773e-01
 7.585e-02 8.216e-02 1.205e-01 2.239e-02 1.932e-01 1.162e-03 1.647e+00
 1.568e-02 8.366e-04 7.213e-01 1.583e-01 4.603e-01 3.555e-01 2.021e-01
 2.266e-01 9.072e-02 1.912e+00 8.288e-02 1.345e-01 4.698e-02 1.006e-03
 9.333e-05 6.557e-02 1.008e-05 1.275e-02 1.389e-03 1.482e-01 1.714e-03
 3.875e-01 2.050e-01 2.032e-01 9.659e-02 2.860e-03 5.373e-02 2.428e-01
 5.026e-04 5.692e-01 1.411e-02 1.215e+00 1.879e+00 7.859e-03 5.115e-03
 1.298e-03 2.597e-02 8.229e-03 1.199e-02 2.516e-03 3.759e-03 6.844e-04
 2.338e-05 5.030e-05 7.802e-02 9.505e-05 1.685e-04 7.174e-04 2.509e-01
 1.983e-04 5.750e-03 2.366e-01 2.188e-01 1.842e-03 5.544e-04 1.534e+00
 2.055e-03 5.128e-06 2.147e-04 1.052e-03 1.147e+00 5.947e-04 2.163e-01
 2.171e-02 1.118e-02 1.573e-01 2.184e+00 1.809e-01 3.509e-02 1.606e+00
 2.183e-02 1.520e-03 1.243e-02 1.995e+00 2.296e-03 3.770e-02 1.878e-03
 1.379e-01 2.272e-02 1.016e+00 1.380e-01 3.210e-01 6.459e-03 3.751e-02
 1.056e-01 1.481e+00 5.839e-03 1.819e-03 3.714e-02 1.112e-01 7.668e-02
 1.180e-04 6.172e-04 3.290e-04 1.699e-04 3.212e-04 6.580e-05 7.200e-04
 1.678e-05 9.593e-05 7.388e-06 2.155e-05 2.395e-04 1.255e-05 9.808e-06
 4.531e-06 7.543e-04 8.458e-05 5.542e-05 6.029e-02 2.153e-04 1.757e-04
 5.319e-05 1.418e-03 2.720e-05 2.590e-05 1.028e-04 2.125e-03 1.236e-05
 3.757e-05 2.049e-01 7.418e-02 1.803e+00 1.350e-01 1.049e-01 1.013e-01
 5.913e-02 8.716e-02 5.222e-02 1.464e-04 4.217e-04 1.202e-01 1.868e-05
 7.932e-04 1.116e-03 1.718e-01 9.509e-05 1.091e+00 1.120e-01 1.798e-01
 3.177e-02 1.508e-03 9.514e-02 2.573e-03 5.410e-05 1.172e-04 7.122e-01
 6.272e-04 3.461e-01]
[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 1. 0. 0. 1. 0.]
 [1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
  0. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 0. 1. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0.]
aucroc, aucpr (0.9791025641025641, 0.9364431161838167)
cuda
9630
cuda
Objective function 982.29 = squared loss an data 726.28 + 0.5*rho*h**2 254.631624 + alpha*h 0.000000 + L2reg 0.55 + L1reg 0.82 ; SHD = 415 ; DAG False
||w||^2 75396509.19719733
exp ma of ||w||^2 43351236446.99372
||w|| 8683.11632982061
exp ma of ||w|| 77932.28588638935
||w||^2 0.08699265551014033
exp ma of ||w||^2 0.10567484584795375
||w|| 0.29494517373596796
exp ma of ||w|| 0.31480067820171803
||w||^2 0.05176737183338691
exp ma of ||w||^2 0.10424021934832263
||w|| 0.22752444227683957
exp ma of ||w|| 0.3091829620827844
||w||^2 0.11516305723980916
exp ma of ||w||^2 0.1181022047254922
||w|| 0.3393568287802813
exp ma of ||w|| 0.33037954343030995
||w||^2 0.07718048401713187
exp ma of ||w||^2 0.1265733876653069
||w|| 0.277813757789516
exp ma of ||w|| 0.3430766223630414
||w||^2 0.29568532334662057
exp ma of ||w||^2 0.13869140010761613
||w|| 0.5437695498523437
exp ma of ||w|| 0.3578681496255689
||w||^2 0.1771992907016332
exp ma of ||w||^2 0.15681910548265193
||w|| 0.42095046110158046
exp ma of ||w|| 0.3792471605630725
||w||^2 0.06562849762220958
exp ma of ||w||^2 0.1636262317169496
||w|| 0.25618059571757107
exp ma of ||w|| 0.3895828391750541
||w||^2 0.30771273631776164
exp ma of ||w||^2 0.2269175338571671
||w|| 0.5547186100337375
exp ma of ||w|| 0.4552639640322643
||w||^2 0.13107710352515703
exp ma of ||w||^2 0.23364437843323377
||w|| 0.3620457202138385
exp ma of ||w|| 0.4618793312248784
||w||^2 0.1500898128605392
exp ma of ||w||^2 0.24738033146835428
||w|| 0.38741426517429534
exp ma of ||w|| 0.47550713279448636
||w||^2 0.14625470286041076
exp ma of ||w||^2 0.27008473859287957
||w|| 0.382432612182082
exp ma of ||w|| 0.4926251813786781
cuda
Objective function 73.50 = squared loss an data 62.54 + 0.5*rho*h**2 9.043305 + alpha*h 0.000000 + L2reg 1.34 + L1reg 0.58 ; SHD = 202 ; DAG False
Proportion of microbatches that were clipped  0.7648151138382044
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 4.252835407211819
iteration 1 in outer loop, alpha = 4.252835407211819, rho = 1.0, h = 4.252835407211819
cuda
9630
cuda
Objective function 91.59 = squared loss an data 62.54 + 0.5*rho*h**2 9.043305 + alpha*h 18.086609 + L2reg 1.34 + L1reg 0.58 ; SHD = 202 ; DAG False
||w||^2 70527.98099446089
exp ma of ||w||^2 476333860.862078
||w|| 265.5710469807673
exp ma of ||w|| 5300.0296410478695
||w||^2 1.1897752825045185
exp ma of ||w||^2 882358.4284478376
||w|| 1.0907682075053886
exp ma of ||w|| 14.077153070717399
||w||^2 1.1440084517435183
exp ma of ||w||^2 298021.0762055231
||w|| 1.069583307528459
exp ma of ||w|| 5.384873060740859
||w||^2 2.8780299547843544
exp ma of ||w||^2 0.7560777907372692
||w|| 1.6964757454158768
exp ma of ||w|| 0.835597203886805
||w||^2 0.560276790321524
exp ma of ||w||^2 0.5871583138756729
||w|| 0.7485163928208413
exp ma of ||w|| 0.7387597677846782
||w||^2 1.3997933772135747
exp ma of ||w||^2 0.5894377166906011
||w|| 1.1831286393345293
exp ma of ||w|| 0.7401856700199874
||w||^2 0.4180441609967058
exp ma of ||w||^2 0.5115144245534239
||w|| 0.6465633464686239
exp ma of ||w|| 0.694998591284691
||w||^2 0.3818305421722327
exp ma of ||w||^2 0.6521514592367936
||w|| 0.6179243822444885
exp ma of ||w|| 0.780360770034602
cuda
Objective function 71.77 = squared loss an data 47.34 + 0.5*rho*h**2 6.661442 + alpha*h 15.523073 + L2reg 1.68 + L1reg 0.57 ; SHD = 196 ; DAG False
Proportion of microbatches that were clipped  0.7673642211546291
iteration 1 in inner loop, alpha 4.252835407211819 rho 1.0 h 3.65005264726188
9630
cuda
Objective function 131.73 = squared loss an data 47.34 + 0.5*rho*h**2 66.614422 + alpha*h 15.523073 + L2reg 1.68 + L1reg 0.57 ; SHD = 196 ; DAG False
||w||^2 26069.411096678894
exp ma of ||w||^2 753475474.055728
||w|| 161.46024618053477
exp ma of ||w|| 4596.175161750269
||w||^2 1.9118938368988125
exp ma of ||w||^2 1.3112857437285794
||w|| 1.3827124924939431
exp ma of ||w|| 1.104893645389129
||w||^2 1.975091919258955
exp ma of ||w||^2 1.2172420801293637
||w|| 1.4053796352797188
exp ma of ||w|| 1.0678674211163433
||w||^2 5.49116840947934
exp ma of ||w||^2 1.2985100488895465
||w|| 2.3433242220143886
exp ma of ||w|| 1.0957799165725506
||w||^2 1.3857231589964618
exp ma of ||w||^2 1.19150599891529
||w|| 1.177167430315867
exp ma of ||w|| 1.0583086666156776
||w||^2 1.145954377153749
exp ma of ||w||^2 1.222889377608813
||w|| 1.0704925862208243
exp ma of ||w|| 1.0728141960276527
||w||^2 0.8859564193648801
exp ma of ||w||^2 1.1094347084542602
||w|| 0.9412525800043685
exp ma of ||w|| 1.026460396578047
||w||^2 0.9299322469124044
exp ma of ||w||^2 1.1514086547727604
||w|| 0.9643299471199701
exp ma of ||w|| 1.0452207989432876
||w||^2 0.9817555334407296
exp ma of ||w||^2 1.1086997217688581
||w|| 0.9908357752123859
exp ma of ||w|| 1.0221641751164867
||w||^2 1.164079492506762
exp ma of ||w||^2 1.2357242667079615
||w|| 1.0789251561191637
exp ma of ||w|| 1.076201183769684
||w||^2 3.1697306911075787
exp ma of ||w||^2 1.292917754296652
||w|| 1.7803737503983759
exp ma of ||w|| 1.1038571901760847
||w||^2 1.541518233861892
exp ma of ||w||^2 1.2912610263058237
||w|| 1.2415789277616998
exp ma of ||w|| 1.1015451916275032
||w||^2 0.8566706989183371
exp ma of ||w||^2 1.3295502219285051
||w|| 0.9255650700617094
exp ma of ||w|| 1.1204161057085573
cuda
Objective function 73.94 = squared loss an data 48.08 + 0.5*rho*h**2 15.891370 + alpha*h 7.581834 + L2reg 1.88 + L1reg 0.50 ; SHD = 157 ; DAG False
Proportion of microbatches that were clipped  0.773757838880849
iteration 2 in inner loop, alpha 4.252835407211819 rho 10.0 h 1.7827714421812786
9630
cuda
Objective function 216.96 = squared loss an data 48.08 + 0.5*rho*h**2 158.913701 + alpha*h 7.581834 + L2reg 1.88 + L1reg 0.50 ; SHD = 157 ; DAG False
||w||^2 1151786294816.7065
exp ma of ||w||^2 364378995865.2066
||w|| 1073213.0705580818
exp ma of ||w|| 319990.77266628906
||w||^2 18.7390021015157
exp ma of ||w||^2 32393362.982560422
||w|| 4.32885690471696
exp ma of ||w|| 131.70310343793855
||w||^2 32.16279188835927
exp ma of ||w||^2 31748735.585470628
||w|| 5.671224901937788
exp ma of ||w|| 129.1839338037439
||w||^2 1.8694244964603821
exp ma of ||w||^2 123699.27989799684
||w|| 1.3672689919911085
exp ma of ||w|| 2.404828457736998
||w||^2 2.0022281494607475
exp ma of ||w||^2 6191.9562840584285
||w|| 1.4150011128832187
exp ma of ||w|| 1.6280451075187479
||w||^2 0.7689697999818277
exp ma of ||w||^2 4.745593840298938
||w|| 0.8769092313243302
exp ma of ||w|| 1.3417759378472935
||w||^2 1.8339709758846776
exp ma of ||w||^2 1.9748459444208004
||w|| 1.3542418454193024
exp ma of ||w|| 1.3618544747917272
||w||^2 1.0386518228700452
exp ma of ||w||^2 1.8712320506981406
||w|| 1.0191426901420846
exp ma of ||w|| 1.328702557063155
||w||^2 1.3258445338642066
exp ma of ||w||^2 2.0997256008782372
||w|| 1.1514532269546196
exp ma of ||w|| 1.4076023890972718
||w||^2 0.8544834730778569
exp ma of ||w||^2 1.8265826302451296
||w|| 0.924382752477488
exp ma of ||w|| 1.316194108015624
||w||^2 2.0373899439675873
exp ma of ||w||^2 2.065898014571149
||w|| 1.4273716908946974
exp ma of ||w|| 1.3942816453730325
||w||^2 3.4861649501830394
exp ma of ||w||^2 1.9636113632566046
||w|| 1.8671274595439487
exp ma of ||w|| 1.3630774896018283
||w||^2 2.2261091630228966
exp ma of ||w||^2 1.9472496459453175
||w|| 1.4920151349845272
exp ma of ||w|| 1.3602401906000396
||w||^2 1.1448190408942993
exp ma of ||w||^2 1.812713841029747
||w|| 1.0699621679733817
exp ma of ||w|| 1.3167634842154545
||w||^2 1.3606734991744167
exp ma of ||w||^2 2.084426479544318
||w|| 1.1664791036166986
exp ma of ||w|| 1.4002285054511676
||w||^2 3.141477075669248
exp ma of ||w||^2 2.0285240635111013
||w|| 1.7724212466762093
exp ma of ||w|| 1.3910190293998723
||w||^2 1.0399114837496348
exp ma of ||w||^2 2.043788077937846
||w|| 1.019760503132787
exp ma of ||w|| 1.385756545201687
cuda
Objective function 80.05 = squared loss an data 52.26 + 0.5*rho*h**2 22.501425 + alpha*h 2.852979 + L2reg 2.01 + L1reg 0.43 ; SHD = 142 ; DAG False
Proportion of microbatches that were clipped  0.7740677553009992
iteration 3 in inner loop, alpha 4.252835407211819 rho 100.0 h 0.6708416419222161
iteration 2 in outer loop, alpha = 71.33699959943343, rho = 100.0, h = 0.6708416419222161
cuda
9630
cuda
Objective function 125.05 = squared loss an data 52.26 + 0.5*rho*h**2 22.501425 + alpha*h 47.855830 + L2reg 2.01 + L1reg 0.43 ; SHD = 142 ; DAG False
||w||^2 44788480374.55279
exp ma of ||w||^2 161566803862.05588
||w|| 211632.89057836164
exp ma of ||w|| 323389.6490475031
||w||^2 41930549.16199032
exp ma of ||w||^2 8743346440.324615
||w|| 6475.380233004879
exp ma of ||w|| 35093.000200306946
||w||^2 284616.2089976083
exp ma of ||w||^2 1735690488.6904142
||w|| 533.4943382994877
exp ma of ||w|| 7973.712356821172
||w||^2 5.77452486453022
exp ma of ||w||^2 3150738.0532296426
||w|| 2.403024108187477
exp ma of ||w|| 20.326142696540963
||w||^2 1.5650064534777668
exp ma of ||w||^2 342.2165138918647
||w|| 1.25100217964549
exp ma of ||w|| 1.6268624244479417
v before min max tensor([[-1164.464,   717.063,  1268.390,  ...,  -147.226,  -912.946,
          -569.938],
        [ -590.653,  -532.980,   223.475,  ...,  -556.108, -1191.533,
         -1020.071],
        [ -670.307, -1031.261,  -781.608,  ..., -1069.917,  -735.682,
            56.514],
        ...,
        [ -790.682,   652.175, -1316.308,  ...,  -827.876,  -752.763,
         -1314.428],
        [ -161.242,  -979.083,  -794.948,  ...,  -845.741,  -969.205,
           650.125],
        [ -611.249, -1145.304, -1088.317,  ...,  -312.371,  1319.163,
         -1251.459]], device='cuda:0')
v tensor([[1.000e-12, 1.000e+01, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e+01],
        ...,
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         1.000e-12]], device='cuda:0')
v before min max tensor([ 9.041e+02, -1.253e+03, -5.955e+02, -7.621e+02,  1.020e+02,  5.351e+01,
        -1.175e+03, -7.479e+01,  7.552e+02, -1.486e+03, -1.046e+03, -1.253e+03,
        -1.099e+03,  3.836e+02,  1.129e+03, -1.104e+03,  6.134e+02, -8.135e+02,
        -8.601e+02, -1.225e+03,  1.364e+02, -1.037e+03,  1.231e+03,  7.350e+02,
        -8.699e+02, -3.956e+02,  1.325e+03, -5.860e+02,  2.469e+03,  3.538e+01,
        -6.848e+02,  4.345e+03,  1.680e+03, -7.360e+02, -7.453e+02, -1.251e+03,
         1.185e+03, -6.398e+02, -3.649e+02, -1.138e+03, -6.057e+02,  4.867e+02,
        -3.270e+02, -4.934e+02, -4.709e+02, -9.097e+02, -8.071e+02, -2.873e+02,
        -7.262e+02, -7.940e+02,  1.018e+03,  5.025e+03, -7.302e+02, -7.904e+02,
        -6.027e+02, -8.057e+02, -1.218e+03,  2.379e+02,  3.730e+03, -3.680e+02,
        -7.778e+02,  1.479e+02, -8.966e+02, -1.257e+03, -2.983e+02, -3.254e+02,
        -7.188e+02,  3.380e+03, -2.813e+01, -6.520e+02, -5.916e+02, -1.517e+02,
        -8.218e+02, -4.573e+02,  4.958e+02, -8.098e+02, -8.543e+01, -1.318e+03,
        -2.589e+02,  2.222e+03, -6.614e+02, -9.513e+02, -7.119e+02, -7.682e+02,
        -9.979e+02, -1.018e+03,  5.904e+02,  1.272e+03,  1.531e+03, -8.875e+02,
        -1.023e+03, -9.388e+02, -1.080e+03, -9.503e+02,  9.750e+02, -8.839e+02,
        -7.771e+02, -6.232e+02, -9.734e+01, -1.027e+03, -3.140e+02, -1.074e+03,
         2.265e+03, -1.162e+03, -1.405e+03, -8.576e+02, -9.142e+02, -3.450e+02,
        -1.067e+03, -7.676e+02, -1.128e+03, -3.350e+02,  3.416e+02, -1.056e+03,
        -9.143e+02,  5.285e+02, -1.060e+03,  4.314e+03, -8.774e+02, -1.238e+03,
        -7.097e+02, -5.842e+02, -2.636e+02, -9.513e+01, -1.042e+03, -8.804e+02,
        -6.425e+02, -6.158e+02, -9.196e+02, -2.360e+02,  2.042e+03, -2.005e+02,
         2.003e+02,  4.270e+01,  8.564e+02, -8.440e+02, -1.241e+03,  7.728e-01,
         4.878e+02,  1.423e+03, -9.037e+02, -7.408e+02,  3.347e+03,  2.942e+03,
         3.409e+02, -8.685e+01, -1.045e+03,  7.125e+02, -8.505e+02, -1.021e+03,
        -3.517e+02, -7.388e+02, -1.057e+03, -8.459e+02,  1.458e+02,  1.940e+02,
        -5.889e+02, -9.335e+02,  1.701e+03,  7.896e+02, -6.510e+02, -1.021e+03,
         5.648e+01, -4.761e+02, -7.738e+02, -1.107e+03, -1.115e+03, -1.439e+03,
        -5.469e+02,  2.284e+03, -9.033e+02,  4.729e+02,  3.107e+03, -1.228e+03,
        -7.340e+02, -1.201e+03,  2.388e+02, -3.914e+02, -9.083e+02, -8.058e+02,
        -8.801e+02,  9.722e+02, -5.895e+02, -3.515e+02, -4.915e+02,  9.700e+02,
        -9.605e+02,  8.240e+02, -1.130e+03, -9.619e+02,  3.532e+02,  7.271e+02,
         3.376e+03, -8.417e+02, -8.922e+02, -5.410e+02, -1.525e+03,  3.061e+02,
        -1.328e+03, -7.091e+02, -7.858e+02,  1.150e+03, -1.379e+03, -8.026e+02,
        -5.675e+02, -1.019e+03, -2.475e+02,  1.751e+02, -1.120e+03, -9.179e+02,
         1.819e+01, -3.436e+02, -1.213e+03, -8.538e+02, -8.726e+02, -9.633e+02,
        -7.823e+02, -2.442e+02, -1.041e+03,  2.893e+02, -1.974e+02, -1.001e+03,
        -1.246e+03,  5.638e+02, -1.229e+03, -8.136e+02,  4.673e+02, -8.989e+02,
        -5.991e+01, -4.311e+02,  1.591e+03, -8.505e+02, -4.885e+02,  2.578e+01,
        -2.165e+02,  3.365e+02, -7.846e+02, -1.009e+03,  2.723e+03, -1.425e+02,
        -1.164e+03,  1.184e+03, -1.179e+03, -5.250e+02, -7.529e+02, -7.517e+02,
        -1.143e+03, -8.332e+00, -5.440e+02, -6.270e+02, -6.014e+02, -9.816e+02,
        -5.825e+02,  4.286e+03,  2.894e+02,  4.318e+01, -1.210e+03, -9.551e+02,
         1.434e+02, -9.611e+02, -1.075e+03, -8.916e+02, -1.402e+03, -1.191e+03,
        -1.141e+03, -9.088e+02,  3.946e+02, -6.291e+02, -1.071e+03, -1.102e+03,
        -5.214e+02, -1.066e+03,  4.249e+03, -8.839e+02, -1.032e+03, -8.466e+02,
        -1.153e+03, -9.274e+02,  5.893e+02,  9.772e+02,  1.117e+03, -1.069e+03,
        -1.009e+03, -4.623e+02, -6.490e+02, -1.197e+03, -6.120e+02,  7.054e+03,
         3.052e+02, -8.110e+02,  1.060e+03, -7.259e+02, -1.913e+02, -8.114e+02,
        -1.154e+03,  5.011e+02, -6.978e+02, -1.094e+03, -2.955e+02, -8.536e+02],
       device='cuda:0')
v tensor([1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 7.728e-01,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-7.681e+02],
         [-1.159e+03],
         [ 1.358e+03],
         [-9.862e+02],
         [-8.399e+02],
         [-2.983e+02],
         [ 5.935e+02],
         [ 9.992e+02],
         [-7.419e+02],
         [-2.892e+02]],

        [[ 1.930e+03],
         [-7.934e+02],
         [ 6.699e+00],
         [-1.318e+03],
         [-1.177e+02],
         [-8.794e+02],
         [ 1.322e+03],
         [-1.321e+03],
         [-4.073e+00],
         [ 2.070e+02]],

        [[ 5.790e+02],
         [-3.220e+02],
         [-1.314e+03],
         [-7.149e+02],
         [ 2.105e+03],
         [ 1.279e+03],
         [-8.875e+02],
         [-1.119e+03],
         [-5.651e+02],
         [ 2.100e+03]],

        [[-5.147e+02],
         [-2.605e+02],
         [ 5.417e+02],
         [-9.800e+02],
         [-9.737e+01],
         [-8.626e+02],
         [-4.545e+02],
         [ 1.598e+03],
         [-9.117e+02],
         [-7.681e+02]],

        [[-1.605e+02],
         [-2.093e+02],
         [ 1.872e+03],
         [-9.129e+02],
         [ 6.108e+03],
         [-1.096e+03],
         [-1.235e+03],
         [ 3.702e+03],
         [ 1.921e+02],
         [ 3.903e+03]],

        [[-4.069e+02],
         [ 1.656e+03],
         [-1.083e+03],
         [-4.647e+02],
         [-6.040e+02],
         [ 6.713e+02],
         [-1.102e+03],
         [-1.265e+03],
         [ 1.529e+02],
         [-7.073e+02]],

        [[-1.283e+03],
         [-5.735e+02],
         [-4.758e+02],
         [-9.482e+02],
         [-8.495e+02],
         [-6.207e+01],
         [-1.267e+03],
         [-9.054e+02],
         [-5.427e+02],
         [-3.794e+02]],

        [[-1.130e+03],
         [-1.110e+03],
         [-1.181e+03],
         [-1.445e+03],
         [ 2.488e+03],
         [-1.306e+03],
         [-1.281e+03],
         [ 4.025e+02],
         [-1.207e+03],
         [-1.320e+03]],

        [[-1.044e+03],
         [ 3.011e+02],
         [ 3.203e+02],
         [-1.275e+03],
         [ 1.928e+03],
         [ 8.118e+02],
         [-7.606e+02],
         [-9.458e+02],
         [-1.103e+03],
         [-5.558e+02]],

        [[-8.282e+02],
         [-8.174e+02],
         [-9.289e+02],
         [-6.103e+02],
         [-1.038e+03],
         [ 6.163e+02],
         [-1.210e+03],
         [-4.035e+01],
         [-6.660e+02],
         [-1.180e+03]],

        [[-1.118e+03],
         [-1.568e+02],
         [-8.532e+02],
         [-7.041e+02],
         [-1.039e+03],
         [ 8.175e+02],
         [-1.161e+03],
         [-8.627e+02],
         [-1.147e+03],
         [ 1.502e+03]],

        [[-1.914e+02],
         [-4.750e+02],
         [-1.176e+03],
         [ 4.035e+02],
         [ 6.159e+03],
         [ 4.157e+03],
         [-6.246e+02],
         [ 1.924e+01],
         [-8.863e+02],
         [ 1.017e+04]],

        [[-6.987e+02],
         [ 1.136e+02],
         [-8.432e+02],
         [ 9.567e+01],
         [-8.819e+02],
         [ 1.666e+03],
         [-1.155e+03],
         [-3.471e+02],
         [ 9.149e+01],
         [-1.167e+03]],

        [[ 9.581e+01],
         [ 4.763e+03],
         [ 1.014e+03],
         [-1.189e+03],
         [-1.127e+03],
         [-6.037e+01],
         [-1.211e+03],
         [-5.619e+02],
         [-9.061e+02],
         [-3.795e+02]],

        [[-8.140e+02],
         [-8.507e+02],
         [-1.273e+03],
         [-5.282e+02],
         [ 4.079e+02],
         [ 3.527e+03],
         [-8.727e+02],
         [-1.032e+03],
         [-1.204e+03],
         [ 1.502e+02]],

        [[-5.783e+02],
         [-6.474e+02],
         [ 2.962e+02],
         [ 2.514e+03],
         [-7.686e+02],
         [-8.359e+02],
         [-1.120e+03],
         [-8.721e+02],
         [-1.207e+03],
         [ 3.878e+02]],

        [[-1.030e+03],
         [-1.026e+03],
         [-6.895e+02],
         [-6.719e+02],
         [-2.736e+02],
         [ 8.705e+02],
         [-1.129e+03],
         [-3.230e+02],
         [-7.024e+02],
         [ 1.075e+03]],

        [[-6.169e+02],
         [ 2.573e+03],
         [ 1.517e+03],
         [-1.282e+03],
         [-1.076e+03],
         [-9.275e+02],
         [ 2.234e+02],
         [-9.329e+02],
         [ 1.903e+03],
         [-1.086e+03]],

        [[-5.469e+02],
         [ 2.867e+02],
         [-8.462e+02],
         [ 1.320e+03],
         [-9.846e+02],
         [-6.922e+02],
         [-5.972e+02],
         [-7.415e+02],
         [-2.809e+02],
         [ 2.123e+02]],

        [[-1.064e+03],
         [-7.441e+02],
         [-8.238e+02],
         [-4.875e+02],
         [-8.095e+02],
         [ 5.085e+02],
         [-1.159e+03],
         [ 2.139e+03],
         [ 2.785e+02],
         [-1.140e+03]],

        [[ 3.108e+02],
         [-8.306e+02],
         [-7.706e+02],
         [-3.046e+02],
         [-4.930e+02],
         [-1.099e+03],
         [-4.988e+02],
         [-1.077e+03],
         [ 1.045e+03],
         [ 2.689e+01]],

        [[-9.909e+01],
         [-6.695e+02],
         [-1.246e+03],
         [-1.143e+03],
         [ 1.158e+03],
         [ 1.841e+02],
         [ 6.623e+01],
         [-1.020e+03],
         [-3.673e+02],
         [-3.273e+02]],

        [[-9.426e+02],
         [ 8.048e+02],
         [-1.340e+03],
         [ 3.555e+03],
         [-7.827e+02],
         [ 1.412e+03],
         [ 1.627e+03],
         [-1.073e+03],
         [ 8.432e+01],
         [-1.091e+03]],

        [[-1.014e+03],
         [-7.302e+02],
         [-8.669e+02],
         [-1.034e+03],
         [ 3.468e+03],
         [-1.196e+03],
         [ 3.491e+03],
         [-7.521e+02],
         [ 2.426e+01],
         [-8.651e+02]],

        [[-5.007e+02],
         [-8.055e+02],
         [ 5.924e+03],
         [-9.099e+02],
         [ 1.025e+03],
         [-8.875e+01],
         [-1.041e+03],
         [ 4.285e+03],
         [-8.059e+02],
         [ 3.012e+03]],

        [[-1.261e+03],
         [-1.209e+03],
         [-8.346e+00],
         [-7.219e+02],
         [-4.971e+02],
         [-7.694e+02],
         [-8.898e+02],
         [-1.407e+03],
         [ 1.533e+02],
         [-7.973e+02]],

        [[-7.374e+02],
         [-4.649e+02],
         [-1.080e+03],
         [-8.201e+02],
         [ 1.070e+04],
         [-6.394e+01],
         [ 7.547e+03],
         [-1.477e+02],
         [-8.471e+02],
         [-1.180e+02]],

        [[ 4.073e+01],
         [-7.134e+02],
         [-4.061e+02],
         [-1.151e+03],
         [ 4.956e+03],
         [-1.254e+03],
         [-3.236e+02],
         [-1.220e+03],
         [-3.850e+02],
         [ 5.643e+02]],

        [[ 2.360e+02],
         [-1.517e+02],
         [ 1.037e+03],
         [ 2.552e+03],
         [ 1.130e+03],
         [-6.373e+02],
         [ 4.377e+03],
         [ 2.442e+03],
         [ 2.006e+03],
         [-7.490e+02]],

        [[-1.003e+03],
         [-4.610e+01],
         [ 3.629e+03],
         [-7.754e+02],
         [-1.011e+03],
         [-8.038e+02],
         [-9.743e+02],
         [-5.255e+02],
         [ 1.260e+03],
         [-1.835e+02]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [6.699e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[-1383.465],
        [ 1583.704],
        [-1383.892],
        [-1091.244],
        [  629.575],
        [ -756.580],
        [ -150.339],
        [ -336.038],
        [ 1651.433],
        [-1282.385],
        [ -969.778],
        [ 1044.096],
        [ -690.660],
        [-1310.399],
        [-1079.265],
        [-1170.137],
        [-1192.957],
        [ -683.374],
        [ 1477.573],
        [-1103.783],
        [ -264.648],
        [ 1139.939],
        [  337.671],
        [ -608.750],
        [ -702.650],
        [-1251.498],
        [ -445.600],
        [  612.858],
        [ -989.461],
        [ -914.742]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-0.021,  0.097, -0.154,  ..., -0.326, -0.089,  0.515],
        [-0.029,  0.064,  0.403,  ..., -0.080,  0.092, -0.390],
        [ 0.054, -0.118, -0.327,  ..., -0.079, -0.169, -0.057],
        ...,
        [-0.193,  0.172, -0.557,  ...,  0.153,  0.060,  0.131],
        [-0.289,  0.360, -0.108,  ..., -0.035,  1.367, -0.177],
        [ 0.078,  0.158, -0.342,  ...,  0.158, -0.754,  0.134]],
       device='cuda:0')
s after update for 1 param tensor([[1.798, 1.872, 2.111,  ..., 1.842, 1.664, 0.993],
        [1.293, 1.503, 1.898,  ..., 1.850, 1.828, 1.551],
        [1.286, 1.554, 1.504,  ..., 1.793, 1.098, 1.744],
        ...,
        [1.376, 2.102, 1.967,  ..., 1.526, 1.158, 2.009],
        [1.231, 1.504, 1.298,  ..., 1.283, 1.549, 1.852],
        [1.453, 1.766, 1.758,  ..., 1.969, 1.588, 2.233]], device='cuda:0')
b after update for 1 param tensor([[174.014, 177.526, 188.522,  ..., 176.129, 167.406, 129.323],
        [147.580, 159.069, 178.765,  ..., 176.499, 175.454, 161.601],
        [147.158, 161.743, 159.153,  ..., 173.781, 135.963, 171.344],
        ...,
        [152.226, 188.124, 181.986,  ..., 160.294, 139.657, 183.924],
        [143.997, 159.166, 147.828,  ..., 146.959, 161.500, 176.589],
        [156.414, 172.424, 172.048,  ..., 182.104, 163.505, 193.900]],
       device='cuda:0')
clipping threshold 1.3422601319208842
a after update for 1 param tensor([ 0.157, -0.037, -0.101,  0.074,  0.433,  0.170, -0.401, -0.737, -0.070,
         0.497, -0.460,  0.195, -0.375, -0.067,  0.400,  0.567,  0.468,  0.159,
        -0.492,  0.242,  0.229,  0.258, -0.580, -0.205, -0.184, -0.471,  0.243,
        -0.028, -0.062,  0.445, -0.032,  0.243,  0.177,  0.012, -0.646, -0.511,
         0.199,  0.119, -0.387,  0.184,  0.077, -0.400,  0.517, -0.140,  0.170,
         0.058, -0.209, -0.070,  0.303,  0.272, -0.463,  0.325,  0.398, -0.228,
        -0.176,  0.225, -0.225,  0.002,  0.226, -0.306, -0.467, -0.520, -0.190,
        -0.003, -0.144, -0.011,  0.384,  0.184, -0.246,  0.079,  0.239,  0.087,
        -0.195,  0.096, -0.437,  0.360,  0.020,  0.293, -0.958, -0.046, -0.234,
        -0.901,  0.165, -0.395, -0.127, -0.085, -0.354,  0.092,  0.469, -0.576,
         0.362,  0.264, -0.244,  0.178, -0.083, -0.046,  0.167, -0.535,  0.050,
        -0.153,  0.175,  0.015, -0.475, -0.127,  0.272, -0.764, -0.348, -0.093,
         0.075,  0.329,  0.130,  0.031,  0.205,  0.113, -0.181,  0.515, -0.111,
        -0.067, -0.228, -0.046,  0.207, -0.214,  0.197,  0.078, -0.060,  0.745,
         0.047, -0.205, -0.780, -0.115, -0.032,  0.271, -0.750, -0.048, -0.348,
        -0.284,  0.150,  0.078,  0.342,  0.123,  0.003,  0.134,  0.168,  0.126,
        -0.299, -0.063, -0.556,  0.613,  0.381,  0.139, -0.037, -0.131,  0.653,
        -0.021,  0.795,  0.324,  0.805, -0.088,  0.156, -0.257, -0.201, -0.361,
         0.861,  0.506, -0.038, -0.063, -0.015,  0.192,  0.493,  0.116,  0.043,
         0.349,  0.449, -0.131, -0.116,  0.005,  0.131, -0.502,  0.033, -0.092,
        -0.639, -0.020,  0.040,  0.148,  0.037,  0.207,  0.097,  0.297, -0.256,
        -0.194, -0.770, -0.143,  0.551,  0.490,  0.009, -0.047,  0.348, -0.344,
         0.096, -0.863, -0.114,  0.154, -0.590, -0.537,  0.573,  0.134, -0.038,
        -0.076,  0.283, -0.089, -0.165, -0.263,  0.263, -0.152,  0.314, -0.159,
         0.421, -0.539, -0.337, -0.357, -0.134,  0.125,  0.915, -0.621,  0.887,
        -0.271, -0.285,  0.367,  0.103, -0.203,  0.239,  0.386, -0.254,  0.113,
        -0.167, -0.228,  0.235,  0.062, -0.263,  0.189,  0.620, -0.029,  0.160,
        -0.570, -0.492, -0.168, -0.447,  0.288, -0.186, -0.240, -0.205, -0.155,
         0.348,  0.487,  0.274, -0.299, -0.128, -0.421, -0.087, -0.443,  0.082,
         0.078,  0.153, -0.207,  0.153,  0.158, -0.162, -0.331, -0.129,  0.087,
         0.035, -0.381,  0.856, -0.279, -0.152,  0.567, -0.079, -0.094, -0.853,
         0.331, -0.310, -0.387, -0.304,  0.535, -0.264, -0.742, -0.261,  1.269,
        -0.622,  0.763,  0.271, -0.140,  0.255,  0.040, -0.120, -0.725,  0.787,
        -0.411, -0.335, -0.284], device='cuda:0')
s after update for 1 param tensor([1.751, 1.964, 1.753, 1.180, 1.152, 2.041, 1.929, 1.677, 1.939, 2.218,
        1.584, 1.983, 1.657, 1.740, 2.166, 1.656, 1.456, 1.748, 1.585, 1.835,
        2.144, 1.736, 1.489, 2.030, 1.873, 2.087, 1.950, 1.483, 1.906, 2.200,
        1.543, 2.212, 1.574, 1.248, 1.629, 2.065, 1.941, 1.477, 1.805, 2.003,
        1.203, 1.655, 1.850, 1.870, 1.684, 2.099, 1.203, 1.302, 1.305, 1.810,
        1.837, 1.961, 1.742, 1.782, 1.888, 1.515, 1.826, 2.400, 2.108, 1.834,
        1.930, 1.733, 1.817, 1.903, 1.270, 1.662, 1.628, 2.210, 1.848, 1.555,
        1.800, 1.614, 1.464, 1.871, 2.191, 1.543, 1.421, 1.966, 1.480, 1.337,
        2.420, 1.434, 1.944, 1.168, 1.572, 1.578, 1.548, 1.754, 1.865, 1.454,
        1.525, 1.691, 1.626, 1.470, 1.899, 1.392, 1.873, 1.247, 1.820, 1.603,
        0.785, 1.944, 1.979, 1.785, 2.107, 1.531, 1.367, 1.478, 1.603, 1.378,
        2.114, 2.207, 1.946, 1.643, 1.536, 1.721, 1.718, 1.785, 1.340, 1.900,
        1.776, 1.875, 1.923, 1.184, 1.571, 1.722, 1.265, 1.937, 1.783, 1.526,
        2.504, 1.819, 2.029, 1.923, 1.753, 1.367, 2.101, 1.512, 2.061, 1.431,
        1.376, 1.494, 1.935, 1.603, 2.153, 1.384, 1.842, 1.895, 1.292, 1.528,
        1.806, 1.677, 2.258, 1.270, 1.508, 2.104, 1.319, 1.851, 1.752, 2.127,
        1.299, 1.591, 1.943, 2.077, 1.342, 1.831, 1.665, 2.175, 1.401, 1.757,
        1.348, 1.577, 1.690, 1.843, 1.794, 1.798, 2.175, 1.827, 1.704, 1.220,
        1.858, 1.681, 1.012, 1.561, 2.203, 2.005, 2.310, 1.767, 1.809, 1.798,
        2.028, 1.511, 2.169, 1.389, 1.474, 1.557, 2.365, 2.099, 1.988, 1.850,
        1.703, 2.016, 2.060, 1.671, 1.439, 1.599, 1.124, 1.956, 1.719, 1.408,
        1.629, 1.470, 1.842, 1.278, 1.743, 1.626, 2.178, 1.644, 1.593, 1.939,
        2.170, 1.591, 1.935, 2.093, 2.103, 1.418, 1.972, 1.442, 1.282, 1.310,
        1.968, 1.389, 1.632, 1.925, 1.309, 1.927, 1.863, 1.865, 1.833, 1.789,
        2.097, 2.046, 1.776, 1.126, 1.541, 1.637, 2.051, 1.256, 0.849, 1.562,
        1.493, 1.469, 1.716, 1.967, 1.577, 1.816, 1.931, 2.161, 1.741, 1.521,
        1.616, 1.381, 2.164, 1.779, 1.723, 1.412, 1.695, 1.741, 1.606, 1.682,
        1.360, 1.790, 1.785, 1.428, 1.717, 1.420, 1.855, 1.384, 1.887, 2.033,
        1.711, 1.656, 1.886, 0.990, 1.376, 1.795, 1.418, 1.996, 1.779, 1.629,
        1.751, 1.600, 1.503, 1.768, 1.856, 2.223, 1.526, 1.864, 0.970, 2.076],
       device='cuda:0')
b after update for 1 param tensor([171.706, 181.833, 171.822, 140.952, 139.267, 185.365, 180.216, 168.027,
        180.706, 193.256, 163.318, 182.753, 167.053, 171.177, 190.998, 166.989,
        156.607, 171.569, 163.347, 175.800, 190.024, 170.976, 158.338, 184.876,
        177.570, 187.485, 181.224, 158.041, 179.137, 192.456, 161.210, 193.003,
        162.818, 144.960, 165.633, 186.454, 180.789, 157.723, 174.346, 183.653,
        142.345, 166.929, 176.521, 177.435, 168.413, 188.024, 142.356, 148.095,
        148.252, 174.579, 175.866, 181.709, 171.270, 173.232, 178.310, 159.722,
        175.371, 201.022, 188.421, 175.751, 180.276, 170.844, 174.897, 179.030,
        146.226, 167.311, 165.572, 192.911, 176.412, 161.824, 174.106, 164.881,
        157.031, 177.480, 192.062, 161.208, 154.700, 181.949, 157.872, 150.070,
        201.856, 155.416, 180.929, 140.239, 162.700, 163.027, 161.472, 171.842,
        177.211, 156.454, 160.260, 168.743, 165.453, 157.320, 178.807, 153.074,
        177.612, 144.913, 175.052, 164.312, 115.003, 180.925, 182.564, 173.388,
        188.346, 160.540, 151.729, 157.758, 164.316, 152.353, 188.666, 192.762,
        181.004, 166.317, 160.807, 170.227, 170.110, 173.352, 150.218, 178.881,
        172.918, 177.690, 179.949, 141.207, 162.656, 170.264, 145.952, 180.602,
        173.265, 160.300, 205.355, 175.029, 184.842, 179.948, 171.814, 151.729,
        188.074, 159.579, 186.309, 155.233, 152.199, 158.592, 180.516, 164.315,
        190.416, 152.676, 176.121, 178.610, 147.475, 160.425, 174.390, 168.037,
        195.012, 146.251, 159.362, 188.216, 149.045, 176.556, 171.766, 189.250,
        147.896, 163.667, 180.888, 187.028, 150.328, 175.573, 167.465, 191.368,
        153.615, 172.029, 150.674, 162.947, 168.712, 176.187, 173.789, 174.001,
        191.397, 175.384, 169.381, 143.359, 176.865, 168.240, 130.532, 162.113,
        192.605, 183.745, 197.236, 172.516, 174.531, 173.982, 184.804, 159.527,
        191.126, 152.930, 157.522, 161.926, 199.551, 188.018, 182.967, 176.496,
        169.362, 184.238, 186.244, 167.764, 155.689, 164.107, 137.573, 181.490,
        170.135, 154.000, 165.597, 157.314, 176.132, 146.682, 171.314, 165.466,
        191.514, 166.381, 163.764, 180.697, 191.155, 163.683, 180.527, 187.728,
        188.181, 154.528, 182.232, 155.819, 146.948, 148.542, 182.042, 152.909,
        165.785, 180.031, 148.455, 180.122, 177.131, 177.220, 175.676, 173.564,
        187.921, 185.600, 172.911, 137.718, 161.070, 166.040, 185.857, 145.430,
        119.572, 162.192, 158.540, 157.268, 169.979, 181.974, 162.944, 174.856,
        180.306, 190.761, 171.214, 160.037, 164.983, 152.506, 190.888, 173.069,
        170.322, 154.222, 168.928, 171.234, 164.448, 168.299, 151.308, 173.631,
        173.392, 155.055, 170.045, 154.615, 176.731, 152.669, 178.243, 185.004,
        169.737, 166.997, 178.209, 129.136, 152.198, 173.861, 154.538, 183.339,
        173.084, 165.597, 171.708, 164.117, 159.096, 172.550, 176.765, 193.474,
        160.307, 177.170, 127.813, 186.984], device='cuda:0')
clipping threshold 1.3422601319208842
a after update for 1 param tensor([[[ 2.825e-01],
         [-5.402e-01],
         [-3.769e-01],
         [-2.061e-01],
         [-4.500e-01],
         [ 5.153e-01],
         [-2.644e-01],
         [-4.102e-02],
         [-7.262e-02],
         [ 2.937e-01]],

        [[-3.207e-01],
         [ 4.497e-01],
         [-2.935e-01],
         [-2.754e-01],
         [ 1.918e-01],
         [ 6.196e-01],
         [ 5.206e-01],
         [-2.307e-01],
         [-1.662e-01],
         [-1.519e-01]],

        [[-2.539e-01],
         [-4.421e-01],
         [-1.505e-02],
         [-6.994e-01],
         [ 4.514e-01],
         [ 1.284e-01],
         [-3.932e-01],
         [-3.468e-01],
         [ 5.620e-01],
         [-2.670e-01]],

        [[ 4.734e-01],
         [ 1.174e-01],
         [ 3.278e-01],
         [ 1.609e-01],
         [ 5.781e-01],
         [ 2.914e-01],
         [ 1.200e-01],
         [ 1.575e-01],
         [ 2.563e-01],
         [-2.328e-01]],

        [[ 3.584e-01],
         [ 1.621e-01],
         [-1.193e-03],
         [-7.625e-03],
         [ 8.885e-02],
         [-3.015e-01],
         [ 1.161e-01],
         [-8.026e-02],
         [ 2.647e-02],
         [ 6.056e-01]],

        [[ 3.994e-01],
         [-1.846e-01],
         [-6.549e-02],
         [-5.076e-01],
         [-9.931e-02],
         [-5.665e-01],
         [-2.846e-01],
         [ 5.428e-01],
         [-1.252e-01],
         [ 7.831e-01]],

        [[ 1.326e-01],
         [ 2.991e-01],
         [-4.108e-01],
         [-1.100e-01],
         [-4.160e-01],
         [ 4.677e-01],
         [ 2.251e-01],
         [ 4.926e-01],
         [-5.349e-01],
         [-3.140e-02]],

        [[ 1.775e-01],
         [-1.694e-02],
         [ 5.466e-01],
         [ 4.006e-01],
         [-4.607e-01],
         [ 5.838e-01],
         [-7.824e-01],
         [-2.969e-01],
         [-1.210e-01],
         [ 1.957e-01]],

        [[-1.135e-01],
         [ 2.585e-02],
         [-1.218e-01],
         [ 8.031e-02],
         [ 3.208e-01],
         [ 2.663e-01],
         [-1.109e-01],
         [ 8.273e-01],
         [ 4.179e-01],
         [ 3.850e-02]],

        [[-2.979e-01],
         [-3.817e-01],
         [ 5.028e-01],
         [ 3.180e-02],
         [ 3.136e-02],
         [ 1.325e-01],
         [ 1.500e-01],
         [ 1.427e-01],
         [-1.722e-02],
         [-2.759e-01]],

        [[ 6.068e-01],
         [-4.189e-04],
         [ 2.551e-01],
         [ 2.644e-01],
         [-2.778e-01],
         [-3.136e-01],
         [ 1.928e-01],
         [-3.070e-01],
         [-5.117e-01],
         [-2.869e-01]],

        [[ 5.959e-01],
         [ 7.300e-01],
         [ 2.694e-01],
         [ 5.375e-01],
         [-5.974e-02],
         [ 5.204e-01],
         [ 2.781e-01],
         [-2.087e-01],
         [ 1.776e-01],
         [ 3.539e-02]],

        [[ 2.209e-01],
         [ 4.752e-01],
         [ 1.733e-01],
         [ 3.619e-01],
         [ 3.030e-02],
         [-2.168e-01],
         [-2.131e-01],
         [ 3.809e-01],
         [-1.172e-01],
         [ 1.625e-01]],

        [[-2.479e-01],
         [ 3.252e-01],
         [ 6.794e-01],
         [ 2.565e-01],
         [-4.748e-01],
         [-5.988e-01],
         [ 5.005e-01],
         [ 9.942e-02],
         [-1.667e-01],
         [-3.594e-01]],

        [[ 5.692e-01],
         [ 1.544e-01],
         [ 1.915e-01],
         [ 4.580e-02],
         [ 2.567e-01],
         [ 6.259e-01],
         [-1.029e-01],
         [-1.346e-01],
         [ 5.326e-01],
         [ 2.104e-01]],

        [[ 4.514e-04],
         [-6.990e-01],
         [ 4.440e-01],
         [ 5.823e-01],
         [-1.428e-02],
         [ 7.334e-02],
         [-5.647e-01],
         [ 4.580e-01],
         [ 2.693e-01],
         [ 2.608e-02]],

        [[-1.033e+00],
         [ 3.896e-01],
         [-2.983e-01],
         [ 1.755e-01],
         [ 1.904e-01],
         [ 1.433e-01],
         [ 7.549e-01],
         [-8.645e-02],
         [ 1.105e-02],
         [ 6.810e-01]],

        [[ 3.580e-02],
         [ 1.586e-01],
         [-9.693e-02],
         [-3.705e-01],
         [ 4.581e-01],
         [ 4.334e-01],
         [ 2.952e-01],
         [-3.812e-02],
         [ 1.471e-01],
         [-6.691e-02]],

        [[-3.462e-03],
         [-5.716e-01],
         [ 2.349e-01],
         [ 1.886e-01],
         [ 1.367e-01],
         [-6.189e-01],
         [ 4.711e-01],
         [-4.628e-01],
         [ 2.643e-01],
         [ 4.376e-01]],

        [[ 8.634e-01],
         [ 2.118e-04],
         [-2.466e-01],
         [-6.118e-01],
         [-1.337e-01],
         [-3.137e-01],
         [ 1.753e-01],
         [-1.133e-01],
         [ 2.664e-04],
         [ 1.619e-01]],

        [[-4.638e-01],
         [-4.849e-01],
         [ 9.367e-02],
         [ 1.695e-01],
         [ 3.162e-01],
         [-2.080e-01],
         [-2.619e-01],
         [-3.093e-01],
         [-2.199e-01],
         [-1.062e-01]],

        [[ 1.255e-01],
         [ 6.309e-02],
         [ 2.872e-01],
         [-3.650e-02],
         [-4.910e-01],
         [-7.862e-01],
         [ 1.518e-01],
         [-3.522e-01],
         [ 2.550e-01],
         [-4.273e-02]],

        [[ 1.746e-01],
         [ 5.327e-01],
         [ 4.957e-01],
         [ 3.259e-01],
         [ 2.388e-01],
         [ 1.898e-01],
         [ 1.537e-01],
         [ 3.191e-01],
         [-5.767e-01],
         [ 1.726e-01]],

        [[ 7.566e-03],
         [-2.287e-01],
         [ 4.229e-02],
         [ 5.275e-02],
         [-2.012e-03],
         [-1.733e-01],
         [ 5.001e-01],
         [-2.173e-01],
         [-8.631e-02],
         [ 4.405e-01]],

        [[-3.805e-01],
         [ 2.275e-02],
         [ 4.144e-01],
         [-1.994e-01],
         [-8.385e-02],
         [-3.533e-01],
         [ 2.631e-01],
         [-8.390e-02],
         [ 2.832e-01],
         [ 1.240e-01]],

        [[-2.733e-01],
         [-5.841e-01],
         [-1.022e-01],
         [ 4.634e-01],
         [-2.520e-01],
         [ 2.376e-01],
         [ 2.841e-02],
         [-4.846e-01],
         [ 3.429e-01],
         [ 1.962e-01]],

        [[ 1.939e-01],
         [ 4.013e-01],
         [-9.460e-02],
         [ 1.799e-01],
         [-3.260e-01],
         [-9.718e-01],
         [ 4.205e-01],
         [ 1.923e-01],
         [-5.673e-01],
         [-1.338e-01]],

        [[ 2.783e-01],
         [ 5.251e-01],
         [ 7.648e-02],
         [ 2.858e-01],
         [ 1.938e-01],
         [-1.755e-02],
         [ 1.999e-01],
         [ 3.528e-01],
         [ 5.568e-03],
         [ 6.636e-02]],

        [[-1.032e-02],
         [ 4.223e-01],
         [-5.837e-02],
         [-3.953e-01],
         [-1.744e-01],
         [-6.125e-02],
         [-1.977e-01],
         [ 1.623e-01],
         [-4.121e-01],
         [ 3.766e-01]],

        [[ 1.913e-01],
         [-3.917e-01],
         [-3.328e-01],
         [-1.559e-02],
         [ 2.795e-01],
         [ 1.146e-01],
         [-1.548e-01],
         [ 6.891e-01],
         [ 8.201e-01],
         [-5.803e-01]]], device='cuda:0')
s after update for 1 param tensor([[[1.646],
         [1.733],
         [2.141],
         [1.479],
         [1.286],
         [1.332],
         [2.163],
         [1.261],
         [1.318],
         [0.972]],

        [[2.366],
         [1.382],
         [1.467],
         [1.965],
         [1.069],
         [1.594],
         [2.219],
         [1.977],
         [1.055],
         [1.978]],

        [[1.785],
         [1.508],
         [1.960],
         [1.066],
         [1.512],
         [1.702],
         [1.374],
         [1.673],
         [1.443],
         [2.253]],

        [[1.164],
         [1.637],
         [2.306],
         [1.515],
         [1.546],
         [1.651],
         [0.949],
         [2.398],
         [1.715],
         [1.223]],

        [[1.931],
         [1.505],
         [1.942],
         [1.480],
         [1.825],
         [1.635],
         [1.860],
         [1.761],
         [1.888],
         [1.911]],

        [[1.622],
         [1.789],
         [1.626],
         [2.088],
         [1.674],
         [1.602],
         [1.930],
         [1.968],
         [2.037],
         [1.742]],

        [[1.916],
         [1.319],
         [1.200],
         [1.897],
         [1.267],
         [1.303],
         [1.979],
         [1.656],
         [0.998],
         [1.723]],

        [[1.702],
         [1.739],
         [1.966],
         [2.165],
         [2.137],
         [1.959],
         [2.012],
         [2.064],
         [1.821],
         [2.091]],

        [[1.739],
         [1.503],
         [2.038],
         [1.952],
         [2.149],
         [1.408],
         [1.417],
         [1.465],
         [1.721],
         [1.637]],

        [[1.309],
         [2.085],
         [1.679],
         [1.451],
         [1.929],
         [2.302],
         [2.246],
         [1.865],
         [1.631],
         [1.762]],

        [[1.673],
         [1.378],
         [1.655],
         [1.352],
         [1.751],
         [2.286],
         [1.834],
         [1.610],
         [1.710],
         [2.076]],

        [[1.712],
         [1.552],
         [2.239],
         [1.750],
         [2.054],
         [1.735],
         [1.415],
         [2.205],
         [1.349],
         [1.898]],

        [[1.275],
         [1.864],
         [2.041],
         [2.181],
         [1.316],
         [1.701],
         [1.725],
         [1.394],
         [1.915],
         [1.836]],

        [[1.446],
         [1.838],
         [1.919],
         [1.806],
         [1.814],
         [1.475],
         [1.873],
         [1.483],
         [1.641],
         [1.505]],

        [[1.606],
         [1.732],
         [1.905],
         [1.553],
         [1.821],
         [1.922],
         [1.892],
         [1.597],
         [1.802],
         [2.119]],

        [[1.839],
         [1.278],
         [1.831],
         [2.107],
         [1.627],
         [1.858],
         [1.674],
         [1.616],
         [1.827],
         [1.645]],

        [[1.773],
         [1.530],
         [1.799],
         [1.481],
         [1.722],
         [1.930],
         [1.683],
         [1.472],
         [1.831],
         [1.768]],

        [[1.565],
         [2.102],
         [1.877],
         [1.926],
         [1.760],
         [1.562],
         [1.613],
         [1.402],
         [2.361],
         [1.762]],

        [[0.817],
         [2.149],
         [1.821],
         [1.614],
         [1.834],
         [2.220],
         [1.396],
         [1.275],
         [2.081],
         [2.035]],

        [[1.750],
         [1.572],
         [1.507],
         [1.706],
         [1.283],
         [1.868],
         [1.744],
         [1.649],
         [1.910],
         [1.701]],

        [[1.856],
         [1.987],
         [1.589],
         [1.759],
         [1.841],
         [1.667],
         [1.836],
         [1.776],
         [1.534],
         [2.250]],

        [[1.600],
         [1.976],
         [1.892],
         [1.764],
         [2.166],
         [2.170],
         [2.526],
         [1.762],
         [1.029],
         [2.210]],

        [[1.918],
         [2.139],
         [2.055],
         [2.117],
         [1.607],
         [2.010],
         [1.904],
         [1.831],
         [1.772],
         [1.971]],

        [[1.523],
         [1.172],
         [1.867],
         [1.918],
         [1.592],
         [1.784],
         [2.006],
         [1.198],
         [1.930],
         [1.339]],

        [[1.206],
         [1.208],
         [1.973],
         [1.552],
         [1.683],
         [1.727],
         [1.553],
         [2.392],
         [1.614],
         [2.165]],

        [[1.992],
         [1.803],
         [1.061],
         [1.651],
         [1.268],
         [1.799],
         [1.418],
         [2.167],
         [1.891],
         [1.790]],

        [[1.668],
         [1.165],
         [1.814],
         [1.595],
         [2.243],
         [1.255],
         [2.350],
         [1.913],
         [1.553],
         [1.606]],

        [[1.675],
         [1.602],
         [1.141],
         [1.719],
         [2.187],
         [1.871],
         [1.856],
         [1.846],
         [1.235],
         [1.480]],

        [[1.609],
         [1.246],
         [1.646],
         [1.761],
         [2.036],
         [1.762],
         [1.682],
         [2.010],
         [2.025],
         [1.244]],

        [[1.497],
         [1.529],
         [2.278],
         [1.358],
         [1.801],
         [1.201],
         [1.855],
         [1.983],
         [1.707],
         [2.088]]], device='cuda:0')
b after update for 1 param tensor([[[166.461],
         [170.838],
         [189.870],
         [157.813],
         [147.157],
         [149.744],
         [190.861],
         [145.739],
         [148.994],
         [127.907]],

        [[199.602],
         [152.574],
         [157.186],
         [181.911],
         [134.189],
         [163.813],
         [193.307],
         [182.478],
         [133.296],
         [182.503]],

        [[173.349],
         [159.349],
         [181.683],
         [134.009],
         [159.548],
         [169.290],
         [152.127],
         [167.839],
         [155.856],
         [194.776]],

        [[140.009],
         [166.033],
         [197.036],
         [159.732],
         [161.342],
         [166.747],
         [126.415],
         [200.935],
         [169.950],
         [143.498]],

        [[180.326],
         [159.198],
         [180.847],
         [157.859],
         [175.324],
         [165.907],
         [176.991],
         [172.207],
         [178.306],
         [179.394]],

        [[165.280],
         [173.553],
         [165.470],
         [187.495],
         [167.872],
         [164.236],
         [180.276],
         [182.057],
         [185.227],
         [171.281]],

        [[179.640],
         [149.030],
         [142.144],
         [178.744],
         [146.074],
         [148.102],
         [182.551],
         [167.014],
         [129.653],
         [170.339]],

        [[169.285],
         [171.124],
         [181.943],
         [190.936],
         [189.676],
         [181.630],
         [184.082],
         [186.441],
         [175.094],
         [187.655]],

        [[171.106],
         [159.080],
         [185.244],
         [181.296],
         [190.219],
         [153.981],
         [154.494],
         [157.086],
         [170.237],
         [166.030]],

        [[148.438],
         [187.380],
         [168.154],
         [156.318],
         [180.208],
         [196.873],
         [194.454],
         [177.235],
         [165.719],
         [172.259]],

        [[167.839],
         [152.328],
         [166.933],
         [150.875],
         [171.727],
         [196.180],
         [175.732],
         [164.643],
         [169.704],
         [186.953]],

        [[169.783],
         [161.651],
         [194.158],
         [171.680],
         [185.955],
         [170.906],
         [154.350],
         [192.708],
         [150.694],
         [178.761]],

        [[146.513],
         [177.187],
         [185.370],
         [191.632],
         [148.841],
         [169.243],
         [170.421],
         [153.201],
         [179.558],
         [175.808]],

        [[156.028],
         [175.947],
         [179.748],
         [174.402],
         [174.793],
         [157.583],
         [177.591],
         [158.027],
         [166.212],
         [159.172]],

        [[164.430],
         [170.758],
         [179.090],
         [161.732],
         [175.109],
         [179.903],
         [178.477],
         [163.972],
         [174.213],
         [188.912]],

        [[175.963],
         [146.709],
         [175.600],
         [188.343],
         [165.498],
         [176.869],
         [167.914],
         [164.969],
         [175.407],
         [166.429]],

        [[172.772],
         [160.516],
         [174.043],
         [157.926],
         [170.301],
         [180.262],
         [168.352],
         [157.414],
         [175.613],
         [172.551]],

        [[162.311],
         [188.129],
         [177.803],
         [180.089],
         [172.158],
         [162.181],
         [164.831],
         [153.654],
         [199.396],
         [172.273]],

        [[117.303],
         [190.224],
         [175.103],
         [164.881],
         [175.718],
         [193.358],
         [153.328],
         [146.507],
         [187.215],
         [185.099]],

        [[171.683],
         [162.693],
         [159.301],
         [169.481],
         [147.011],
         [177.340],
         [171.369],
         [166.630],
         [179.344],
         [169.251]],

        [[176.798],
         [182.908],
         [163.573],
         [172.108],
         [176.046],
         [167.554],
         [175.850],
         [172.943],
         [160.699],
         [194.662]],

        [[164.129],
         [182.432],
         [178.497],
         [172.346],
         [190.998],
         [191.145],
         [206.255],
         [172.271],
         [131.615],
         [192.904]],

        [[179.727],
         [189.769],
         [186.003],
         [188.817],
         [164.478],
         [183.976],
         [179.079],
         [175.596],
         [172.756],
         [182.158]],

        [[160.153],
         [140.474],
         [177.317],
         [179.698],
         [163.717],
         [173.322],
         [183.787],
         [142.047],
         [180.259],
         [150.169]],

        [[142.523],
         [142.613],
         [182.264],
         [161.672],
         [168.362],
         [170.545],
         [161.708],
         [200.690],
         [164.873],
         [190.950]],

        [[183.157],
         [174.219],
         [133.639],
         [166.721],
         [146.107],
         [174.049],
         [154.513],
         [191.027],
         [178.448],
         [173.633]],

        [[167.614],
         [140.076],
         [174.763],
         [163.861],
         [194.349],
         [145.362],
         [198.933],
         [179.460],
         [161.693],
         [164.435]],

        [[167.919],
         [164.247],
         [138.640],
         [170.117],
         [191.887],
         [177.502],
         [176.789],
         [176.323],
         [144.184],
         [157.847]],

        [[164.578],
         [144.821],
         [166.483],
         [172.191],
         [185.182],
         [172.251],
         [168.313],
         [183.992],
         [184.637],
         [144.754]],

        [[158.784],
         [160.448],
         [195.855],
         [151.198],
         [174.140],
         [142.205],
         [176.719],
         [182.751],
         [169.553],
         [187.524]]], device='cuda:0')
clipping threshold 1.3422601319208842
a after update for 1 param tensor([[ 2.191e-01],
        [-7.034e-01],
        [ 9.492e-03],
        [ 2.684e-01],
        [ 2.388e-01],
        [-1.466e-01],
        [-5.253e-02],
        [ 7.411e-02],
        [ 4.442e-01],
        [-6.072e-01],
        [ 6.387e-02],
        [ 7.701e-01],
        [ 1.941e-01],
        [ 1.976e-02],
        [-4.865e-02],
        [ 9.782e-02],
        [ 3.312e-04],
        [ 3.709e-01],
        [ 1.155e-01],
        [-2.027e-01],
        [ 9.410e-01],
        [ 6.356e-01],
        [-1.196e-01],
        [-4.935e-01],
        [ 8.081e-02],
        [ 1.190e-01],
        [-3.203e-01],
        [ 2.908e-01],
        [ 7.746e-02],
        [ 3.439e-01]], device='cuda:0')
s after update for 1 param tensor([[2.219],
        [1.948],
        [2.072],
        [1.628],
        [1.349],
        [1.903],
        [1.670],
        [1.388],
        [1.912],
        [1.920],
        [1.932],
        [2.010],
        [1.606],
        [2.147],
        [1.847],
        [1.864],
        [1.990],
        [1.591],
        [1.936],
        [1.827],
        [1.334],
        [1.779],
        [2.190],
        [1.689],
        [1.539],
        [1.982],
        [1.692],
        [1.868],
        [1.518],
        [1.403]], device='cuda:0')
b after update for 1 param tensor([[193.311],
        [181.120],
        [186.800],
        [165.549],
        [150.692],
        [179.013],
        [167.691],
        [152.872],
        [179.433],
        [179.826],
        [180.357],
        [183.977],
        [164.424],
        [190.135],
        [176.355],
        [177.143],
        [183.075],
        [163.704],
        [180.542],
        [175.388],
        [149.865],
        [173.093],
        [192.019],
        [168.646],
        [160.976],
        [182.684],
        [168.778],
        [177.368],
        [159.859],
        [153.722]], device='cuda:0')
clipping threshold 1.3422601319208842
||w||^2 2.579964578253587
exp ma of ||w||^2 2.422704336789886
||w|| 1.6062268140750195
exp ma of ||w|| 1.514378988931679
||w||^2 2.018123716728856
exp ma of ||w||^2 2.512301934219052
||w|| 1.420606812854583
exp ma of ||w|| 1.546471449931483
||w||^2 1.2863405011940112
exp ma of ||w||^2 2.4007490055960505
||w|| 1.1341695204836053
exp ma of ||w|| 1.5135252079437813
||w||^2 1.1244011944973966
exp ma of ||w||^2 2.385376508575948
||w|| 1.0603778545864662
exp ma of ||w|| 1.5044449496878844
||w||^2 1.0052905878053815
exp ma of ||w||^2 2.455928241464222
||w|| 1.0026418043376117
exp ma of ||w|| 1.5268592944490118
||w||^2 2.239591078013154
exp ma of ||w||^2 2.4439976831966685
||w|| 1.496526337226697
exp ma of ||w|| 1.5333473886555034
||w||^2 5.560980838434146
exp ma of ||w||^2 2.713265128419537
||w|| 2.358173199413933
exp ma of ||w|| 1.6078256059464597
||w||^2 2.4516047008766577
exp ma of ||w||^2 2.4970776062405657
||w|| 1.5657601032331414
exp ma of ||w|| 1.5390466765290685
||w||^2 2.955217664312355
exp ma of ||w||^2 2.6370174788109195
||w|| 1.7190746535018062
exp ma of ||w|| 1.5914461067945656
||w||^2 2.252776986021643
exp ma of ||w||^2 2.477085583687624
||w|| 1.5009253765666175
exp ma of ||w|| 1.5365287959607805
cuda
Objective function 100.75 = squared loss an data 52.96 + 0.5*rho*h**2 11.313502 + alpha*h 33.933478 + L2reg 2.12 + L1reg 0.42 ; SHD = 142 ; DAG True
Proportion of microbatches that were clipped  0.7751091703056768
iteration 1 in inner loop, alpha 71.33699959943343 rho 100.0 h 0.4756785139658888
9630
cuda
Objective function 202.57 = squared loss an data 52.96 + 0.5*rho*h**2 113.135024 + alpha*h 33.933478 + L2reg 2.12 + L1reg 0.42 ; SHD = 142 ; DAG True
||w||^2 1374085526.3269932
exp ma of ||w||^2 100007106509.13824
||w|| 37068.65962409476
exp ma of ||w|| 184011.41680438013
||w||^2 5568.7337313174585
exp ma of ||w||^2 813244920.0480856
||w|| 74.6239487786425
exp ma of ||w|| 2209.4939146722395
||w||^2 1.7168490781713495
exp ma of ||w||^2 2.989017226299029
||w|| 1.3102858765060965
exp ma of ||w|| 1.6958518208697453
||w||^2 2.5627384149542713
exp ma of ||w||^2 2.969936868759243
||w|| 1.600855525946758
exp ma of ||w|| 1.6924603308412114
||w||^2 4.398730013694557
exp ma of ||w||^2 3.0014444537683773
||w|| 2.097314953385532
exp ma of ||w|| 1.697881270938233
||w||^2 1.74306749429831
exp ma of ||w||^2 3.0512929350232447
||w|| 1.3202528145390602
exp ma of ||w|| 1.7102106902737026
||w||^2 1.5565751136163595
exp ma of ||w||^2 3.025652532123298
||w|| 1.2476277945029757
exp ma of ||w|| 1.7021618201704596
||w||^2 1.1110350661533497
exp ma of ||w||^2 2.941761037165531
||w|| 1.05405648148159
exp ma of ||w|| 1.6802605843498288
||w||^2 1.5145947165972962
exp ma of ||w||^2 2.777180064646473
||w|| 1.2306887163687235
exp ma of ||w|| 1.6293041453036488
||w||^2 3.0391288802530085
exp ma of ||w||^2 2.7905906478319835
||w|| 1.7433097487976739
exp ma of ||w|| 1.6380684508108478
||w||^2 3.316114916897533
exp ma of ||w||^2 2.9167655588326737
||w|| 1.8210202955754042
exp ma of ||w|| 1.672457056401237
||w||^2 2.2620994691783247
exp ma of ||w||^2 2.775540093141396
||w|| 1.5040277488059604
exp ma of ||w|| 1.6346225540724393
||w||^2 2.697786945586917
exp ma of ||w||^2 3.1005933831724417
||w|| 1.6424941234558244
exp ma of ||w|| 1.7249604310001796
||w||^2 4.369766290615448
exp ma of ||w||^2 3.131352593894695
||w|| 2.090398596109232
exp ma of ||w|| 1.7328227820901363
cuda
Objective function 96.83 = squared loss an data 53.36 + 0.5*rho*h**2 24.885805 + alpha*h 15.914965 + L2reg 2.29 + L1reg 0.38 ; SHD = 154 ; DAG True
Proportion of microbatches that were clipped  0.7796097172441259
iteration 2 in inner loop, alpha 71.33699959943343 rho 1000.0 h 0.22309551888464085
9630
cuda
Objective function 320.80 = squared loss an data 53.36 + 0.5*rho*h**2 248.858053 + alpha*h 15.914965 + L2reg 2.29 + L1reg 0.38 ; SHD = 154 ; DAG True
||w||^2 109028873677.73566
exp ma of ||w||^2 1779800869570.4966
||w|| 330195.2054130036
exp ma of ||w|| 942092.1071472671
||w||^2 18172578.78781376
exp ma of ||w||^2 57888120647.26346
||w|| 4262.930774457141
exp ma of ||w|| 52792.238788037255
||w||^2 5.033665686950833
exp ma of ||w||^2 213.27595764626193
||w|| 2.2435832248773018
exp ma of ||w|| 2.407292819229921
||w||^2 5.645022222952067
exp ma of ||w||^2 73.18667754209794
||w|| 2.375925550801638
exp ma of ||w|| 2.4052562636201116
||w||^2 7.4625608570599935
exp ma of ||w||^2 38.78321566282295
||w|| 2.73176881471694
exp ma of ||w|| 2.391752119151229
||w||^2 3.379763236192105
exp ma of ||w||^2 3.7948179290537962
||w|| 1.8384132386903944
exp ma of ||w|| 1.9077268119758481
||w||^2 3.120416592192306
exp ma of ||w||^2 3.7205459207581866
||w|| 1.7664700937724096
exp ma of ||w|| 1.9098734298413316
||w||^2 4.132792286550138
exp ma of ||w||^2 3.7703093556120497
||w|| 2.032927024403517
exp ma of ||w|| 1.9157320452181328
||w||^2 3.756111090141295
exp ma of ||w||^2 3.4693726130056577
||w|| 1.9380689074801483
exp ma of ||w|| 1.8370788743827604
||w||^2 3.3463379411312704
exp ma of ||w||^2 3.9970193389866084
||w|| 1.8292998499784747
exp ma of ||w|| 1.9714828677413587
||w||^2 3.7493314662258297
exp ma of ||w||^2 4.088746487785202
||w|| 1.9363190507315238
exp ma of ||w|| 1.992929903227122
||w||^2 2.9855777051205425
exp ma of ||w||^2 3.9499294122494875
||w|| 1.727882433824866
exp ma of ||w|| 1.9576448317004487
v before min max tensor([[ 3705.517,  -909.012,  1220.216,  ...,  -931.480,  -502.372,
           -38.431],
        [-1222.660,  1187.945,  -469.768,  ..., -1043.300, -2384.256,
         -1604.391],
        [-1698.042,  1938.237, -1142.716,  ..., 21864.584, -2071.854,
         -1872.632],
        ...,
        [ 4618.595, -1748.136, -1881.442,  ..., -1441.890, -1532.130,
         -1972.111],
        [-1905.819,  4693.584, -2130.337,  ...,  2406.748, -1808.497,
          2021.245],
        [  575.865,  2152.068, -2043.602,  ..., -1079.656,   458.011,
          1516.509]], device='cuda:0')
v tensor([[1.000e+01, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e+01, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e+01, 1.000e-12,
         1.000e+01],
        [1.000e+01, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         1.000e+01]], device='cuda:0')
v before min max tensor([  203.460,   780.332, -2215.642, -1910.170,  -209.116,  -170.911,
          783.527, -1993.238, -1885.039,  2339.161,  1936.492,  1292.083,
         -730.057, -1250.930, -2079.827,  4178.233, -1704.020, -1177.604,
          877.357,  4824.245,  1008.888, -1271.394,  -516.585, -2302.718,
         1984.834,  1684.315, -2046.667,  -285.710,   528.513, -1811.137,
         1799.095,  -584.635,  -757.916, -1634.534,  2058.068,  -292.337,
        -1389.282, -1358.358, -1364.439,  2837.967,  -690.650,   406.119,
         -934.851, -1124.581,  2257.970,  1519.454, 10487.118, -1194.021,
        11997.370,  -547.118,  -731.084,  1168.636, -1166.640, -1971.442,
          900.186, -1199.600,  1384.005, -2137.252, -1983.469, -2122.701,
        -1280.648, -1972.144,  -595.534,  -380.112, -1408.285, -1628.687,
          642.903, -1482.720,  4696.272,  -895.269,  4830.659, -2059.884,
        -1183.447, -1274.507, -1186.761, -1325.738,  2343.648, -1584.663,
        -1929.558, -1444.624, -1612.394, -2084.024, -1927.553,  2404.527,
        -1548.210, -1333.771,  -747.961,  1192.844, -1397.886,  -562.773,
         -484.519,   872.870,  -192.022,  -806.425,   306.738, -1776.535,
        -1125.316, -1737.401,  -997.610, -1014.833,    79.287,  8349.349,
        -1455.939,   517.805, -1085.410, -1835.054, -2202.543,  -902.260,
        -2094.847,   911.073, -1489.575,  -785.044,  -322.586,  1864.372,
         -481.916,  3264.154,  1974.211,  1206.219, -1576.761, -1435.292,
        -1304.605,  1823.254, -1889.888, -1863.497, -1786.056,  -495.522,
        -1001.283, -1033.462,  4944.503,  -950.152,  1120.759,  2951.132,
        -1857.496,  -924.612,  1581.523, -1590.638, -1768.181,  -908.695,
        -1077.156, -1803.793, -1352.632,  -767.101, -1120.292,  1196.702,
         -509.870, -1302.398,  -993.201, -2210.321, -1141.074, -2000.579,
        -1443.578,  -849.428,  9225.240, -1587.268, -1728.797,    45.688,
         2057.339, -2391.577,   505.664, -1922.677,   -94.137, -1553.528,
         -545.484, -1329.228, -1088.184, -1329.002,  -660.771, -2214.126,
        -1977.793, -1400.827, 10812.209, -2005.260,  3214.536, -1679.046,
        -1269.222, -1141.003,  -902.411, -1403.019,   544.738, -1309.731,
        -1944.346,   336.142, -1824.854, -1536.125, -1486.516, -1535.041,
         -870.642, -1161.539, -1497.109, -1749.407,  3823.353,  -924.151,
         5372.083, -1819.821,   290.466,    87.595, -1906.137,  2232.871,
         -648.953, -1181.382, -1471.187,   165.310, -2043.335,    28.475,
          776.509,  -731.054, -1284.865,  6007.429,  1335.407, -1399.286,
        -1352.789, -1389.619, -1198.641,   181.766,   137.166,  -569.206,
        -1687.721,  -435.214, -1363.958,   997.018,  3790.219, -1474.427,
        -1555.935,  -578.352,  5739.415,  1673.963, -1862.752,  -818.117,
        -1860.043, -1439.818, -1649.663, -1535.780, -1131.436,  3255.034,
          673.640, -1224.446,  4423.743, -1687.879, -1858.492,  6364.646,
         4834.104,  2670.699, -1608.209, -2134.397,  -525.112,   170.533,
        -2527.586,  -809.785, -2022.968, -2036.889,   873.436, -1732.826,
         -250.387, -1605.017, -1905.502, -1884.007, -1906.093,  1674.927,
        -1776.836, -1340.223,   329.172, -1465.608,  2825.047,  -798.269,
        -1347.511, -1416.215,   190.150,  -729.186,   780.351, -1434.548,
        -1707.333,  -936.671,  -981.982,  3101.649, -1639.787,  1437.217,
        -1788.846,  -962.453,  -662.450, -1816.704,   602.366, -1365.064,
        -1966.448, -1695.111,    69.672,  1202.831,   139.551,  -710.924,
        -1122.730,  2346.631, -2012.823, -1696.306,   169.070,  4590.853,
        -1773.568,  -900.347, -1059.925,  -123.168,  2622.579,  -539.561],
       device='cuda:0')
v tensor([1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-1457.537],
         [-1654.220],
         [-1326.775],
         [ -757.907],
         [  867.291],
         [ 2112.090],
         [-1355.716],
         [-1623.828],
         [-1763.572],
         [ 2881.158]],

        [[-1741.228],
         [ -829.762],
         [ 1968.537],
         [-1576.823],
         [ -657.652],
         [ 2480.470],
         [ 8631.470],
         [-2204.311],
         [-2100.324],
         [-1545.424]],

        [[  362.633],
         [-1371.494],
         [-1385.133],
         [-1673.811],
         [-1720.312],
         [ 6775.982],
         [-1461.533],
         [ -188.411],
         [ -666.324],
         [ 3795.109]],

        [[  -69.226],
         [-1494.526],
         [-1048.535],
         [-1302.273],
         [ 1543.871],
         [-1112.532],
         [ 4736.375],
         [ 1297.893],
         [-1795.082],
         [-1253.182]],

        [[ -860.895],
         [-1338.144],
         [ 1362.327],
         [-1775.051],
         [ -962.855],
         [-1660.686],
         [-1917.893],
         [  869.409],
         [-1685.170],
         [ -696.389]],

        [[18939.265],
         [-1133.744],
         [ 6721.682],
         [-1575.518],
         [-2083.199],
         [ 7095.126],
         [-1669.020],
         [ -256.366],
         [ 3311.837],
         [ -907.173]],

        [[ 1323.670],
         [-1785.723],
         [  -69.789],
         [15208.210],
         [ 3631.427],
         [-1401.297],
         [-1328.521],
         [ -540.209],
         [ 1076.372],
         [ -862.492]],

        [[ -732.514],
         [ -896.316],
         [-1420.286],
         [-1571.847],
         [ -797.456],
         [  557.945],
         [-1956.967],
         [  575.586],
         [-1655.687],
         [ 1025.166]],

        [[ 5098.651],
         [  243.469],
         [-1452.366],
         [-2184.595],
         [  344.142],
         [-2326.010],
         [-1818.643],
         [-1607.704],
         [-1439.104],
         [ 4556.739]],

        [[  964.296],
         [  241.233],
         [-1577.928],
         [ -586.370],
         [-1653.416],
         [ -829.878],
         [-1512.272],
         [-1451.810],
         [-1335.695],
         [18544.982]],

        [[-2252.898],
         [-1471.126],
         [-1646.312],
         [ -157.651],
         [-1743.698],
         [-1891.903],
         [ 1481.490],
         [ -805.314],
         [ 1432.240],
         [ 2454.418]],

        [[ 7431.091],
         [-1273.438],
         [-1266.880],
         [-1266.195],
         [ -899.292],
         [-2142.541],
         [ 5266.428],
         [-1879.788],
         [ 4886.836],
         [  697.423]],

        [[-1133.017],
         [ -343.829],
         [ 1594.611],
         [-1175.822],
         [ -951.688],
         [ -426.114],
         [-1165.256],
         [ 4206.937],
         [-1049.371],
         [ 1273.692]],

        [[-1644.395],
         [ -836.807],
         [-1585.901],
         [-1939.885],
         [-1470.068],
         [ 1069.131],
         [ 3117.695],
         [-1471.047],
         [ -316.630],
         [-1339.616]],

        [[ -233.982],
         [-1606.707],
         [ 1373.724],
         [  442.689],
         [  521.120],
         [-2277.045],
         [-1169.885],
         [  685.199],
         [-1696.039],
         [ 5631.159]],

        [[-1769.150],
         [ 4307.171],
         [ -334.933],
         [-1479.102],
         [ -493.795],
         [-1382.492],
         [-1691.571],
         [-1144.214],
         [ 6137.087],
         [  191.996]],

        [[-1294.578],
         [-1361.543],
         [-1417.240],
         [-1271.452],
         [-2004.622],
         [-1542.551],
         [  655.928],
         [-1991.474],
         [ 2174.932],
         [10068.363]],

        [[-1109.450],
         [ -134.937],
         [ 1846.853],
         [ -352.278],
         [-1060.121],
         [-2090.057],
         [-2482.440],
         [-1135.147],
         [ 2483.928],
         [  915.792]],

        [[-1217.871],
         [-1555.685],
         [-1653.598],
         [ 1559.057],
         [  493.911],
         [  285.237],
         [-1972.829],
         [ -352.596],
         [-1662.839],
         [-1767.023]],

        [[-1220.907],
         [ 1561.931],
         [-1727.412],
         [-2263.091],
         [ -757.689],
         [-1335.369],
         [ -796.919],
         [ -709.843],
         [ -837.290],
         [ -603.918]],

        [[  457.633],
         [-1275.333],
         [ 1069.828],
         [ 9869.764],
         [ 1551.842],
         [-1696.829],
         [ 4891.602],
         [-1094.851],
         [ -204.247],
         [ 2425.374]],

        [[-1648.297],
         [ 2287.248],
         [-1841.333],
         [-1408.687],
         [-2293.040],
         [ 2183.101],
         [  600.027],
         [ -981.773],
         [ 8469.991],
         [-1169.559]],

        [[ 1216.393],
         [ -691.838],
         [-1496.237],
         [ -790.809],
         [-1620.818],
         [-1643.984],
         [-1901.197],
         [ -922.395],
         [ 1976.465],
         [  469.230]],

        [[-1279.922],
         [ -760.205],
         [-1688.273],
         [ 3940.678],
         [ 4054.058],
         [-1615.466],
         [-1442.096],
         [-1913.863],
         [ -788.682],
         [ 1939.481]],

        [[ -355.209],
         [-1832.162],
         [ -844.601],
         [ 6646.565],
         [  740.157],
         [-1447.767],
         [-2243.428],
         [-1212.268],
         [ 5723.250],
         [  262.314]],

        [[-1748.632],
         [-2098.212],
         [ -292.221],
         [ -632.474],
         [-1904.821],
         [-1479.210],
         [-1561.986],
         [15619.375],
         [ -148.218],
         [ 4800.441]],

        [[-1879.063],
         [-1471.548],
         [ 6600.751],
         [ 2751.703],
         [-1687.417],
         [-1996.645],
         [-1199.901],
         [-1048.026],
         [-1898.377],
         [ 1873.895]],

        [[  518.902],
         [ -273.461],
         [-1197.515],
         [ -328.677],
         [ 7095.294],
         [ 6454.597],
         [ -962.332],
         [  248.867],
         [  339.538],
         [   40.951]],

        [[-1900.355],
         [ -924.748],
         [ 1987.584],
         [  757.052],
         [ 9432.383],
         [-2161.486],
         [ 2798.583],
         [ 1929.139],
         [-1445.071],
         [ -412.896]],

        [[ 6835.193],
         [ 5535.059],
         [ -894.677],
         [-2002.206],
         [ -835.684],
         [ 1273.415],
         [ 9483.731],
         [-1661.941],
         [ -901.095],
         [ -562.117]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[ 2013.386],
        [  940.393],
        [ -339.107],
        [ 2130.900],
        [16786.382],
        [ -840.940],
        [-1571.935],
        [-1615.853],
        [-1953.931],
        [  694.599],
        [ -983.931],
        [ 1059.528],
        [ -797.301],
        [-1521.103],
        [-2007.385],
        [  820.650],
        [-1408.089],
        [-1120.944],
        [-1986.513],
        [ -251.117],
        [ -298.981],
        [-1145.175],
        [-1880.042],
        [-2005.384],
        [ 1718.452],
        [-1338.038],
        [-1921.117],
        [  598.548],
        [ -611.462],
        [ -394.700]], device='cuda:0')
v tensor([[1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-0.054, -0.202, -0.029,  ..., -0.374,  0.129, -0.282],
        [-0.020,  0.596,  0.594,  ..., -0.535,  0.076,  0.296],
        [ 0.041, -0.539,  0.458,  ..., -0.376, -0.142,  0.428],
        ...,
        [ 0.047,  0.173, -0.216,  ...,  0.449, -0.054,  0.023],
        [ 0.324,  0.175,  0.312,  ..., -0.156, -0.076, -0.056],
        [-0.062,  0.138,  0.106,  ...,  0.532,  0.166, -0.225]],
       device='cuda:0')
s after update for 1 param tensor([[1.742, 0.940, 2.037,  ..., 1.880, 1.606, 1.710],
        [2.409, 1.866, 1.294,  ..., 1.517, 2.238, 1.470],
        [2.020, 1.753, 1.697,  ..., 2.464, 1.893, 1.872],
        ...,
        [1.843, 1.943, 1.720,  ..., 1.920, 1.579, 1.802],
        [1.812, 1.568, 1.946,  ..., 1.631, 1.722, 1.499],
        [2.237, 1.739, 1.924,  ..., 1.738, 1.807, 2.502]], device='cuda:0')
b after update for 1 param tensor([[174.476, 128.163, 188.642,  ..., 181.254, 167.502, 172.871],
        [205.173, 180.557, 150.347,  ..., 162.808, 197.738, 160.241],
        [187.857, 174.995, 172.192,  ..., 207.465, 181.850, 180.835],
        ...,
        [179.456, 184.272, 173.339,  ..., 183.131, 166.081, 177.415],
        [177.910, 165.491, 184.402,  ..., 168.803, 173.474, 161.815],
        [197.689, 174.288, 183.366,  ..., 174.243, 177.685, 209.063]],
       device='cuda:0')
clipping threshold 1.6895145338824729
a after update for 1 param tensor([-2.663e-01,  4.486e-01, -2.913e-01, -1.401e-01, -4.340e-01,  1.362e-01,
        -2.583e-01,  6.083e-01,  2.898e-01, -1.637e-01,  5.267e-02,  2.571e-01,
        -8.400e-01,  8.117e-01,  3.398e-01,  1.854e-01,  2.488e-03,  6.672e-02,
         6.149e-01,  2.953e-02, -2.602e-01,  1.696e-01,  1.140e+00,  8.328e-01,
         7.247e-01, -8.592e-02, -6.490e-01, -1.701e-01,  1.482e-01,  4.512e-01,
        -6.757e-01,  7.519e-01, -4.617e-01,  2.739e-02,  4.651e-01, -1.702e-01,
         2.308e-01, -8.493e-01, -6.172e-01,  3.097e-01, -2.641e-01, -4.393e-01,
        -5.430e-01, -6.790e-01,  1.250e-01,  3.385e-01,  6.225e-01, -4.856e-02,
        -6.903e-01,  1.038e-01, -2.602e-02,  8.047e-01, -1.670e-01,  1.057e-01,
        -6.668e-01,  3.838e-01, -4.412e-01,  3.849e-01,  1.315e-01,  3.384e-01,
        -4.907e-01,  3.198e-02, -3.818e-01, -5.280e-01, -1.166e+00,  1.143e+00,
        -4.758e-03, -1.666e-01,  7.278e-01, -5.374e-02, -3.237e-02, -6.479e-01,
         4.209e-01,  2.273e-01,  2.095e-01,  5.925e-01, -2.430e-02,  5.648e-01,
        -3.491e-01, -4.725e-02, -1.060e-01,  1.990e-01, -1.257e-01,  6.502e-01,
        -4.636e-01, -8.021e-01,  1.841e-01, -2.825e-01, -4.930e-01, -9.950e-01,
         1.605e-01,  4.459e-01,  3.366e-02,  3.237e-02, -3.083e-01, -2.428e-01,
         9.134e-02, -3.734e-01, -1.588e-01,  5.816e-01,  4.301e-02,  1.364e+00,
        -7.633e-02, -5.384e-01,  2.327e-01,  7.111e-06, -3.591e-01,  3.774e-01,
         3.120e-01, -5.667e-01,  3.091e-01,  2.607e-01, -8.714e-01, -4.847e-01,
        -3.983e-01,  2.837e-01,  5.343e-01, -2.483e-01,  3.681e-01, -2.375e-01,
        -4.394e-01, -7.551e-02, -2.230e-01, -3.208e-02,  6.423e-02,  1.101e+00,
         1.204e-01,  9.275e-02, -6.314e-03, -1.557e-01, -1.036e-01,  3.213e-02,
         6.390e-02,  5.490e-01,  1.076e-01, -5.108e-01, -7.575e-02,  7.315e-01,
         8.893e-03, -2.081e-01, -4.326e-01, -2.145e-01, -5.587e-01,  3.585e-01,
         2.575e-02, -1.316e-01,  4.496e-01, -2.107e-01,  1.502e-02,  3.861e-01,
         2.632e-01, -5.733e-02,  6.955e-01, -2.037e-01,  1.900e-01, -4.467e-02,
         2.033e-01, -1.969e-01, -7.879e-01, -6.095e-01,  6.811e-02,  9.402e-02,
         2.886e-01,  1.970e-01,  3.752e-02,  3.747e-02, -4.126e-01, -1.305e-01,
        -2.157e-02,  3.070e-01, -1.072e-01, -9.733e-02, -1.399e-01, -7.917e-01,
        -6.607e-02,  5.827e-01,  1.711e-01, -5.790e-02,  2.120e-01,  3.786e-01,
        -3.275e-02, -1.355e-01,  2.582e-01,  2.283e-01, -3.396e-01, -4.827e-01,
        -3.357e-01,  7.905e-01, -3.480e-01,  5.150e-01,  9.733e-02,  4.544e-01,
         2.180e-01, -3.722e-01, -3.204e-01,  6.083e-01,  5.944e-01,  5.164e-01,
         3.668e-01,  5.291e-01,  5.089e-01, -3.893e-01,  6.378e-01, -1.411e-01,
         9.910e-01,  7.687e-01,  4.650e-01, -2.802e-01, -8.124e-02,  2.117e-01,
         1.575e-01,  9.299e-01,  4.940e-01, -3.555e-01,  3.178e-01,  8.999e-02,
        -5.061e-01, -4.529e-01,  3.978e-01, -3.944e-01, -4.636e-01, -2.288e-01,
         5.778e-01, -1.102e-01,  2.073e-03,  3.684e-01,  4.117e-01,  2.339e-01,
         1.681e-01,  5.325e-01,  5.868e-02, -3.415e-01, -4.292e-01,  1.189e-01,
        -1.971e-01, -6.575e-01,  1.575e-01, -2.984e-01, -4.825e-02,  3.036e-01,
         7.072e-01,  4.215e-01,  1.730e-01,  4.531e-01, -6.579e-01,  3.212e-01,
         3.160e-01,  4.836e-01, -1.036e+00,  1.160e-01, -6.829e-01, -1.830e-01,
         1.025e+00,  1.712e-01, -1.567e-01,  4.734e-01,  3.230e-02,  8.049e-01,
         5.366e-01, -3.779e-01,  2.675e-02, -2.517e-01,  1.198e-02, -1.295e-01,
        -6.713e-01, -8.712e-01, -5.825e-01,  1.781e-01,  7.905e-02, -4.987e-01,
         2.991e-01, -6.743e-03, -9.038e-01, -2.195e-01,  6.691e-02, -6.139e-01,
         2.404e-01,  5.742e-02, -1.017e-01, -1.019e+00,  1.699e-01, -3.966e-01,
        -1.917e-01, -7.075e-02,  2.615e-01, -5.345e-01,  2.200e-01,  4.716e-01,
         3.133e-01, -7.854e-01,  4.635e-02, -8.501e-01, -1.179e+00, -1.140e-01,
        -3.132e-02,  4.636e-01, -7.223e-01,  2.743e-01,  9.414e-01,  5.349e-01],
       device='cuda:0')
s after update for 1 param tensor([1.884, 1.874, 2.028, 1.768, 1.388, 1.521, 2.306, 1.826, 1.767, 2.167,
        2.272, 1.644, 1.437, 1.365, 2.087, 1.639, 1.561, 1.952, 1.851, 1.770,
        2.110, 1.243, 1.755, 2.144, 1.956, 2.098, 2.118, 1.855, 1.741, 1.916,
        2.008, 1.261, 0.831, 1.523, 2.037, 2.202, 1.424, 1.603, 1.324, 2.165,
        1.674, 1.734, 1.820, 1.318, 2.365, 1.568, 1.870, 2.316, 2.108, 1.528,
        2.099, 1.801, 1.684, 2.120, 1.942, 2.169, 2.000, 1.992, 2.039, 1.955,
        1.482, 1.952, 1.195, 1.845, 1.530, 1.681, 2.072, 1.368, 2.115, 1.656,
        1.909, 1.884, 1.295, 1.758, 1.583, 1.492, 2.313, 1.497, 1.773, 1.984,
        1.515, 2.019, 1.827, 2.022, 1.827, 1.531, 1.692, 2.016, 1.319, 1.549,
        1.901, 2.061, 1.186, 1.203, 1.727, 1.623, 1.176, 1.775, 1.679, 1.812,
        2.159, 2.070, 1.422, 1.727, 1.157, 1.865, 2.015, 1.867, 1.930, 2.474,
        1.954, 1.378, 1.316, 2.392, 1.200, 2.252, 2.304, 1.587, 1.745, 1.594,
        1.633, 1.922, 1.756, 1.703, 1.632, 1.617, 1.431, 1.782, 1.988, 1.324,
        1.779, 2.187, 1.717, 2.010, 1.873, 1.605, 1.717, 1.524, 0.984, 1.648,
        2.160, 1.538, 1.574, 1.706, 2.073, 2.123, 1.311, 2.037, 1.689, 1.872,
        1.858, 1.631, 2.171, 1.667, 1.607, 1.813, 2.159, 2.260, 1.599, 1.758,
        1.377, 1.524, 1.270, 1.581, 0.994, 1.730, 1.502, 2.067, 1.872, 1.598,
        1.961, 1.935, 1.798, 1.553, 1.289, 1.856, 1.494, 1.429, 1.636, 1.355,
        1.816, 1.829, 2.293, 1.404, 1.723, 1.456, 1.370, 1.214, 1.887, 1.754,
        1.766, 1.634, 2.443, 1.997, 1.978, 2.324, 1.747, 1.521, 1.599, 1.681,
        1.801, 2.157, 1.997, 2.058, 2.011, 1.659, 1.784, 1.673, 1.933, 1.279,
        1.379, 2.032, 1.742, 1.847, 1.300, 1.324, 1.635, 0.765, 1.447, 2.230,
        2.064, 2.334, 2.079, 1.787, 1.979, 2.064, 1.857, 1.728, 1.763, 1.765,
        1.741, 1.678, 1.346, 1.543, 1.965, 1.240, 2.139, 1.690, 2.014, 2.071,
        2.037, 2.124, 1.470, 1.953, 1.975, 1.903, 2.309, 1.517, 1.857, 1.935,
        1.819, 1.768, 1.690, 1.775, 1.751, 2.014, 1.910, 1.720, 1.634, 1.599,
        1.789, 1.339, 2.010, 1.936, 1.419, 1.502, 1.801, 0.944, 2.325, 1.566,
        1.731, 1.732, 1.191, 2.095, 1.669, 1.653, 1.802, 1.133, 1.395, 1.904,
        1.700, 1.388, 1.915, 1.550, 2.452, 1.398, 1.779, 1.445, 1.498, 1.937,
        1.891, 1.560, 1.881, 2.038, 1.622, 1.195, 1.730, 1.483, 1.849, 1.385],
       device='cuda:0')
b after update for 1 param tensor([181.422, 180.964, 188.251, 175.738, 155.727, 162.996, 200.743, 178.617,
        175.721, 194.572, 199.237, 169.481, 158.444, 154.435, 190.959, 169.196,
        165.127, 184.680, 179.842, 175.844, 192.006, 147.360, 175.126, 193.558,
        184.849, 191.465, 192.372, 180.007, 174.416, 182.971, 187.323, 148.459,
        120.497, 163.114, 188.654, 196.123, 157.751, 167.362, 152.114, 194.471,
        171.013, 174.035, 178.298, 151.736, 203.285, 165.525, 180.769, 201.138,
        191.917, 163.366, 191.521, 177.371, 171.530, 192.449, 184.207, 194.649,
        186.932, 186.556, 188.750, 184.804, 160.895, 184.676, 144.469, 179.563,
        163.503, 171.378, 190.259, 154.624, 192.243, 170.075, 182.619, 181.431,
        150.402, 175.257, 166.286, 161.448, 201.026, 161.710, 176.019, 186.198,
        162.675, 187.813, 178.643, 187.956, 178.670, 163.575, 171.958, 187.666,
        151.780, 164.502, 182.264, 189.757, 143.960, 144.980, 173.706, 168.388,
        143.322, 176.082, 171.251, 177.944, 194.226, 190.157, 157.628, 173.728,
        142.153, 180.507, 187.610, 180.588, 183.611, 207.906, 184.755, 155.149,
        151.611, 204.430, 144.802, 198.352, 200.620, 166.537, 174.603, 166.886,
        168.907, 183.265, 175.155, 172.480, 168.856, 168.070, 158.143, 176.464,
        186.350, 152.081, 176.321, 195.469, 173.186, 187.406, 180.906, 167.443,
        173.194, 163.194, 131.120, 169.674, 194.242, 163.922, 165.814, 172.641,
        190.291, 192.576, 151.373, 188.644, 171.802, 180.857, 180.197, 168.825,
        194.748, 170.661, 167.557, 177.999, 194.231, 198.714, 167.121, 175.234,
        155.122, 163.154, 148.950, 166.184, 131.787, 173.879, 161.970, 190.015,
        180.864, 167.106, 185.120, 183.851, 177.259, 164.716, 150.041, 180.059,
        161.576, 158.026, 169.045, 153.841, 178.126, 178.744, 200.176, 156.596,
        173.496, 159.496, 154.708, 145.611, 181.557, 175.056, 175.639, 168.966,
        206.612, 186.780, 185.923, 201.499, 174.699, 163.024, 167.151, 171.386,
        177.409, 194.133, 186.797, 189.632, 187.426, 170.267, 176.546, 170.954,
        183.758, 149.515, 155.237, 188.414, 174.451, 179.631, 150.716, 152.069,
        168.996, 115.639, 158.993, 197.373, 189.909, 201.952, 190.609, 176.690,
        185.933, 189.904, 180.109, 173.762, 175.522, 175.601, 174.412, 171.208,
        153.354, 164.190, 185.270, 147.188, 193.311, 171.811, 187.595, 190.222,
        188.667, 192.653, 160.233, 184.704, 185.779, 182.359, 200.854, 162.815,
        180.141, 183.846, 178.264, 175.746, 171.818, 176.099, 174.916, 187.566,
        182.668, 173.370, 168.956, 167.134, 176.817, 152.944, 187.412, 183.914,
        157.472, 161.970, 177.403, 128.441, 201.567, 165.408, 173.881, 173.947,
        144.261, 191.331, 170.752, 169.925, 177.415, 140.702, 156.139, 182.384,
        172.337, 155.745, 182.933, 164.553, 206.996, 156.300, 176.284, 158.879,
        161.805, 183.976, 181.776, 165.081, 181.266, 188.691, 168.340, 144.517,
        173.843, 160.967, 179.728, 155.542], device='cuda:0')
clipping threshold 1.6895145338824729
a after update for 1 param tensor([[[ 6.172e-02],
         [ 7.865e-01],
         [-7.269e-02],
         [ 2.201e-01],
         [ 1.090e-01],
         [-6.087e-02],
         [-5.990e-01],
         [ 3.449e-02],
         [ 1.158e-01],
         [ 6.181e-01]],

        [[ 5.780e-02],
         [-6.723e-01],
         [ 1.268e+00],
         [-5.534e-01],
         [ 3.328e-01],
         [-1.236e-01],
         [ 1.512e-01],
         [-3.049e-01],
         [-6.547e-01],
         [ 5.561e-01]],

        [[-5.397e-01],
         [ 1.535e-01],
         [ 6.811e-01],
         [ 5.301e-01],
         [ 1.566e-01],
         [ 3.031e-01],
         [-8.990e-02],
         [ 1.087e-01],
         [-5.995e-01],
         [-2.010e-01]],

        [[ 1.047e-01],
         [-7.386e-01],
         [-6.629e-01],
         [ 7.784e-01],
         [-4.490e-02],
         [ 8.838e-01],
         [-3.596e-03],
         [ 2.987e-01],
         [ 5.256e-01],
         [ 2.871e-01]],

        [[ 5.484e-01],
         [-9.193e-01],
         [ 3.715e-01],
         [ 1.875e-01],
         [ 4.994e-01],
         [ 7.173e-01],
         [-1.881e-01],
         [-8.151e-02],
         [ 5.301e-01],
         [ 4.370e-01]],

        [[-1.893e-01],
         [-5.616e-01],
         [-1.577e-01],
         [-5.391e-02],
         [-4.050e-01],
         [-7.280e-01],
         [-2.859e-01],
         [-4.335e-01],
         [-1.991e-01],
         [-2.776e-01]],

        [[-4.269e-01],
         [ 2.081e-01],
         [-4.056e-01],
         [-4.514e-01],
         [ 6.994e-01],
         [ 2.765e-01],
         [ 5.095e-01],
         [-2.326e-01],
         [-3.462e-01],
         [ 1.572e-01]],

        [[-5.718e-03],
         [ 5.487e-01],
         [ 2.578e-01],
         [-5.400e-01],
         [ 2.633e-01],
         [-4.927e-01],
         [-2.714e-01],
         [ 4.177e-01],
         [-5.685e-01],
         [ 3.287e-01]],

        [[-3.166e-03],
         [ 3.691e-01],
         [-5.882e-01],
         [-8.863e-04],
         [ 4.304e-01],
         [ 1.442e+00],
         [ 1.924e-01],
         [ 4.645e-01],
         [-8.030e-02],
         [-1.489e-01]],

        [[ 5.214e-01],
         [ 7.640e-02],
         [ 3.408e-01],
         [ 3.780e-01],
         [ 4.125e-01],
         [-1.105e-01],
         [ 1.205e-02],
         [ 3.868e-01],
         [ 5.395e-01],
         [ 7.916e-01]],

        [[ 9.154e-01],
         [-4.607e-01],
         [ 9.542e-01],
         [-1.302e-01],
         [-1.704e-01],
         [ 5.430e-01],
         [ 4.458e-01],
         [-1.894e-01],
         [ 3.711e-01],
         [ 8.336e-01]],

        [[-6.052e-01],
         [-4.045e-01],
         [ 2.072e-01],
         [ 2.803e-01],
         [-4.823e-01],
         [-5.949e-02],
         [-8.897e-02],
         [ 8.294e-01],
         [ 9.195e-01],
         [-6.139e-01]],

        [[-9.310e-02],
         [ 7.263e-01],
         [-3.391e-01],
         [ 7.114e-01],
         [ 4.145e-01],
         [-4.232e-01],
         [-2.040e-01],
         [ 7.185e-01],
         [ 5.628e-01],
         [-3.355e-01]],

        [[ 3.888e-01],
         [ 3.514e-01],
         [ 1.645e-01],
         [ 2.377e-01],
         [ 4.784e-01],
         [ 1.127e-01],
         [ 6.043e-01],
         [ 2.722e-01],
         [-2.498e-01],
         [-6.006e-01]],

        [[-5.339e-01],
         [ 1.015e-01],
         [-4.376e-01],
         [-5.961e-01],
         [-1.033e-01],
         [-1.869e-01],
         [ 4.927e-01],
         [ 8.454e-01],
         [ 2.203e-01],
         [-1.909e-01]],

        [[ 7.129e-01],
         [-1.897e-01],
         [ 7.154e-03],
         [ 2.481e-01],
         [-7.341e-01],
         [ 4.293e-01],
         [-4.403e-01],
         [ 3.920e-01],
         [ 7.495e-03],
         [-1.186e-01]],

        [[ 1.681e+00],
         [-2.275e-01],
         [-3.449e-01],
         [ 1.979e-01],
         [ 7.970e-01],
         [ 7.478e-01],
         [ 2.275e-01],
         [ 7.748e-02],
         [-5.809e-01],
         [ 1.580e-01]],

        [[-2.978e-02],
         [ 4.713e-02],
         [ 8.588e-02],
         [-3.342e-01],
         [-1.656e-01],
         [ 4.640e-01],
         [ 8.285e-01],
         [-5.760e-01],
         [ 5.431e-01],
         [-7.221e-01]],

        [[-1.548e-01],
         [ 2.369e-01],
         [-4.068e-01],
         [-3.416e-01],
         [ 1.353e-01],
         [ 5.822e-01],
         [ 1.007e+00],
         [ 3.866e-03],
         [-1.231e-02],
         [ 7.747e-01]],

        [[ 2.111e-01],
         [ 2.093e-01],
         [-3.254e-02],
         [ 5.604e-01],
         [ 4.710e-02],
         [ 9.609e-02],
         [ 2.868e-01],
         [-1.153e-01],
         [-3.974e-01],
         [ 4.827e-01]],

        [[-1.967e-01],
         [ 4.565e-01],
         [ 6.879e-01],
         [-1.272e-01],
         [ 3.422e-01],
         [ 4.439e-01],
         [-1.493e-01],
         [ 1.002e-01],
         [-2.013e-02],
         [ 6.074e-01]],

        [[-9.709e-01],
         [ 2.639e-01],
         [ 3.927e-01],
         [-4.351e-01],
         [ 1.377e-01],
         [-4.303e-01],
         [-1.461e-01],
         [-2.496e-01],
         [ 5.231e-02],
         [-7.007e-01]],

        [[-1.514e-01],
         [ 8.027e-01],
         [ 2.626e-01],
         [ 1.262e-01],
         [ 1.313e-02],
         [-3.702e-01],
         [-2.039e-01],
         [-1.232e-01],
         [ 6.947e-01],
         [ 1.822e-01]],

        [[ 9.856e-01],
         [ 3.446e-01],
         [ 6.012e-02],
         [ 5.577e-01],
         [-4.041e-01],
         [-4.156e-01],
         [-4.561e-01],
         [-4.132e-01],
         [-8.229e-01],
         [ 7.563e-01]],

        [[-3.642e-01],
         [ 1.467e-01],
         [ 3.895e-01],
         [ 4.057e-01],
         [ 2.845e-01],
         [-3.602e-03],
         [-3.879e-01],
         [-5.116e-01],
         [ 7.140e-03],
         [-1.594e-01]],

        [[-1.068e-01],
         [ 1.891e-01],
         [-8.461e-01],
         [-2.399e-01],
         [ 2.354e-01],
         [-5.410e-01],
         [ 2.825e-01],
         [-2.818e-01],
         [ 2.141e-01],
         [ 6.753e-01]],

        [[-6.953e-02],
         [ 9.023e-02],
         [-1.907e-01],
         [-6.721e-01],
         [-4.012e-02],
         [-4.269e-01],
         [-8.466e-03],
         [-8.242e-01],
         [-8.195e-01],
         [ 5.379e-01]],

        [[-2.765e-01],
         [ 3.570e-02],
         [-1.236e+00],
         [ 7.978e-01],
         [-1.408e-01],
         [-6.486e-01],
         [-5.544e-01],
         [ 2.343e-01],
         [-5.155e-01],
         [ 1.162e+00]],

        [[-6.106e-01],
         [-1.962e-02],
         [-3.366e-01],
         [-1.816e-01],
         [ 4.424e-02],
         [-4.485e-01],
         [-6.182e-01],
         [ 1.716e-01],
         [-3.737e-02],
         [ 2.211e-01]],

        [[-1.712e-01],
         [-2.765e-01],
         [-2.528e-02],
         [ 3.782e-01],
         [ 6.837e-01],
         [-4.477e-01],
         [ 9.987e-01],
         [ 2.315e-01],
         [ 1.376e-01],
         [ 1.614e-01]]], device='cuda:0')
s after update for 1 param tensor([[[1.777],
         [1.537],
         [1.524],
         [1.917],
         [1.893],
         [2.132],
         [1.411],
         [1.624],
         [1.694],
         [1.772]],

        [[1.637],
         [1.777],
         [1.996],
         [1.518],
         [1.322],
         [1.976],
         [2.078],
         [2.018],
         [1.967],
         [1.621]],

        [[1.558],
         [1.275],
         [1.882],
         [1.706],
         [1.777],
         [1.676],
         [1.618],
         [2.002],
         [0.695],
         [1.891]],

        [[1.914],
         [1.588],
         [1.184],
         [1.190],
         [1.928],
         [1.182],
         [1.732],
         [1.939],
         [1.727],
         [1.307]],

        [[1.577],
         [1.466],
         [1.890],
         [1.898],
         [1.430],
         [1.749],
         [1.753],
         [2.043],
         [1.739],
         [1.489]],

        [[2.126],
         [1.095],
         [2.029],
         [1.504],
         [1.961],
         [2.117],
         [2.064],
         [1.659],
         [1.885],
         [1.924]],

        [[1.858],
         [1.635],
         [1.791],
         [2.292],
         [1.976],
         [1.515],
         [1.817],
         [1.187],
         [1.818],
         [0.858]],

        [[1.102],
         [1.536],
         [1.500],
         [1.699],
         [1.522],
         [1.866],
         [1.841],
         [2.019],
         [1.516],
         [1.720]],

        [[2.100],
         [1.666],
         [1.605],
         [2.254],
         [1.818],
         [2.190],
         [1.741],
         [1.865],
         [1.589],
         [2.073]],

        [[1.730],
         [1.914],
         [1.633],
         [0.929],
         [1.652],
         [1.842],
         [1.727],
         [1.850],
         [1.919],
         [2.120]],

        [[2.251],
         [1.442],
         [1.888],
         [1.143],
         [1.599],
         [1.729],
         [2.213],
         [2.119],
         [2.385],
         [1.734]],

        [[2.428],
         [1.164],
         [1.583],
         [1.247],
         [1.559],
         [2.092],
         [1.488],
         [1.837],
         [1.952],
         [1.585]],

        [[1.236],
         [1.445],
         [2.072],
         [1.556],
         [1.693],
         [1.162],
         [1.276],
         [1.921],
         [2.142],
         [2.012]],

        [[1.505],
         [1.559],
         [1.519],
         [1.813],
         [1.972],
         [2.372],
         [1.919],
         [1.496],
         [1.999],
         [1.753]],

        [[1.980],
         [1.568],
         [2.229],
         [2.052],
         [1.215],
         [2.263],
         [1.347],
         [1.653],
         [1.940],
         [1.919]],

        [[1.679],
         [2.025],
         [1.670],
         [2.009],
         [1.709],
         [1.456],
         [1.634],
         [1.165],
         [2.140],
         [1.519]],

        [[1.194],
         [1.773],
         [1.680],
         [1.391],
         [2.166],
         [2.000],
         [1.619],
         [1.866],
         [2.580],
         [2.219]],

        [[1.418],
         [1.592],
         [1.651],
         [1.964],
         [1.311],
         [1.910],
         [2.331],
         [1.528],
         [1.899],
         [1.963]],

        [[1.133],
         [2.079],
         [1.583],
         [2.182],
         [2.051],
         [1.902],
         [1.802],
         [0.921],
         [1.532],
         [1.807]],

        [[1.379],
         [1.628],
         [1.800],
         [2.073],
         [1.992],
         [1.676],
         [1.980],
         [1.264],
         [0.808],
         [1.054]],

        [[1.979],
         [2.019],
         [1.948],
         [1.965],
         [2.301],
         [1.644],
         [1.771],
         [1.239],
         [1.447],
         [2.099]],

        [[1.616],
         [1.749],
         [2.110],
         [1.752],
         [2.096],
         [2.064],
         [1.698],
         [1.267],
         [1.639],
         [1.777]],

        [[1.608],
         [1.864],
         [1.474],
         [1.402],
         [1.505],
         [1.686],
         [1.767],
         [1.132],
         [2.169],
         [1.866]],

        [[1.280],
         [2.111],
         [1.549],
         [2.098],
         [2.246],
         [2.354],
         [1.397],
         [2.019],
         [0.981],
         [1.708]],

        [[1.852],
         [1.821],
         [0.841],
         [1.557],
         [2.006],
         [1.324],
         [2.049],
         [1.598],
         [1.754],
         [1.862]],

        [[1.632],
         [2.201],
         [1.495],
         [1.319],
         [1.775],
         [1.647],
         [1.427],
         [2.075],
         [1.320],
         [2.048]],

        [[1.789],
         [1.380],
         [2.066],
         [2.325],
         [1.556],
         [1.944],
         [1.714],
         [1.381],
         [2.135],
         [2.029]],

        [[1.821],
         [1.654],
         [1.975],
         [1.869],
         [1.749],
         [2.299],
         [1.847],
         [2.040],
         [1.634],
         [2.122]],

        [[1.774],
         [1.271],
         [1.913],
         [2.061],
         [2.331],
         [1.977],
         [1.832],
         [1.507],
         [1.777],
         [1.555]],

        [[2.006],
         [2.309],
         [2.024],
         [1.835],
         [1.505],
         [1.534],
         [1.736],
         [2.098],
         [1.585],
         [1.246]]], device='cuda:0')
b after update for 1 param tensor([[[176.198],
         [163.884],
         [163.190],
         [183.003],
         [181.854],
         [192.987],
         [157.005],
         [168.427],
         [172.054],
         [175.945]],

        [[169.114],
         [176.212],
         [186.755],
         [162.852],
         [151.975],
         [185.818],
         [190.548],
         [187.750],
         [185.395],
         [168.278]],

        [[164.975],
         [149.225],
         [181.309],
         [172.667],
         [176.200],
         [171.111],
         [168.147],
         [187.002],
         [110.229],
         [181.747]],

        [[182.868],
         [166.560],
         [143.819],
         [144.186],
         [183.518],
         [143.678],
         [173.950],
         [184.067],
         [173.701],
         [151.125]],

        [[165.981],
         [160.025],
         [181.718],
         [182.109],
         [158.042],
         [174.784],
         [175.018],
         [188.934],
         [174.292],
         [161.309]],

        [[192.727],
         [138.332],
         [188.260],
         [162.092],
         [185.077],
         [192.302],
         [189.909],
         [170.240],
         [181.471],
         [183.364]],

        [[180.167],
         [168.995],
         [176.873],
         [200.127],
         [185.823],
         [162.700],
         [178.188],
         [143.992],
         [178.212],
         [122.415]],

        [[138.775],
         [163.807],
         [161.896],
         [172.313],
         [163.063],
         [180.548],
         [179.368],
         [187.835],
         [162.751],
         [173.370]],

        [[191.564],
         [170.612],
         [167.467],
         [198.433],
         [178.229],
         [195.610],
         [174.408],
         [180.526],
         [166.598],
         [190.323]],

        [[173.832],
         [182.851],
         [168.935],
         [127.389],
         [169.883],
         [179.393],
         [173.722],
         [179.806],
         [183.108],
         [192.436]],

        [[198.329],
         [158.703],
         [181.618],
         [141.329],
         [167.123],
         [173.801],
         [196.622],
         [192.415],
         [204.144],
         [174.035]],

        [[205.944],
         [142.585],
         [166.315],
         [147.632],
         [165.063],
         [191.164],
         [161.238],
         [179.165],
         [184.672],
         [166.394]],

        [[146.949],
         [158.899],
         [190.264],
         [164.868],
         [171.999],
         [142.482],
         [149.334],
         [183.190],
         [193.447],
         [187.474]],

        [[162.179],
         [165.041],
         [162.907],
         [177.997],
         [185.640],
         [203.588],
         [183.118],
         [161.670],
         [186.894],
         [175.011]],

        [[185.995],
         [165.520],
         [197.355],
         [189.364],
         [145.670],
         [198.856],
         [153.397],
         [169.956],
         [184.092],
         [183.093]],

        [[171.273],
         [188.077],
         [170.791],
         [187.344],
         [172.798],
         [159.498],
         [168.939],
         [142.669],
         [193.368],
         [162.936]],

        [[144.425],
         [175.997],
         [171.336],
         [155.899],
         [194.535],
         [186.927],
         [168.182],
         [180.562],
         [212.318],
         [196.881]],

        [[157.390],
         [166.758],
         [169.818],
         [185.220],
         [151.336],
         [182.688],
         [201.809],
         [163.385],
         [182.162],
         [185.179]],

        [[140.694],
         [190.567],
         [166.298],
         [195.246],
         [189.294],
         [182.294],
         [177.449],
         [126.855],
         [163.623],
         [177.673]],

        [[155.235],
         [168.628],
         [177.333],
         [190.332],
         [186.560],
         [171.102],
         [185.976],
         [148.614],
         [118.812],
         [135.733]],

        [[185.925],
         [187.838],
         [184.471],
         [185.267],
         [200.500],
         [169.456],
         [175.889],
         [147.134],
         [159.002],
         [191.497]],

        [[168.043],
         [174.828],
         [192.020],
         [174.960],
         [191.353],
         [189.912],
         [172.245],
         [148.800],
         [169.206],
         [176.218]],

        [[167.610],
         [180.478],
         [160.481],
         [156.496],
         [162.171],
         [171.641],
         [175.709],
         [140.642],
         [194.689],
         [180.550]],

        [[149.571],
         [192.045],
         [164.508],
         [191.440],
         [198.083],
         [202.790],
         [156.228],
         [187.826],
         [130.891],
         [172.726]],

        [[179.864],
         [178.382],
         [121.201],
         [164.952],
         [187.226],
         [152.121],
         [189.229],
         [167.103],
         [175.071],
         [180.364]],

        [[168.852],
         [196.116],
         [161.637],
         [151.817],
         [176.116],
         [169.630],
         [157.899],
         [190.390],
         [151.841],
         [189.169]],

        [[176.789],
         [155.260],
         [189.971],
         [201.539],
         [164.867],
         [184.282],
         [173.049],
         [155.317],
         [193.121],
         [188.301]],

        [[178.371],
         [169.995],
         [185.777],
         [180.706],
         [174.808],
         [200.397],
         [179.627],
         [188.792],
         [168.952],
         [192.565]],

        [[176.060],
         [149.039],
         [182.820],
         [189.772],
         [201.824],
         [185.857],
         [178.914],
         [162.266],
         [176.181],
         [164.846]],

        [[187.226],
         [200.832],
         [188.033],
         [179.057],
         [162.166],
         [163.708],
         [174.132],
         [191.450],
         [166.394],
         [147.549]]], device='cuda:0')
clipping threshold 1.6895145338824729
a after update for 1 param tensor([[-0.210],
        [-0.355],
        [-0.768],
        [-0.192],
        [ 0.240],
        [ 0.189],
        [ 0.426],
        [ 0.098],
        [ 0.119],
        [ 0.272],
        [-0.531],
        [ 0.450],
        [-0.285],
        [ 0.003],
        [-0.091],
        [-0.228],
        [-0.627],
        [-0.107],
        [ 0.163],
        [ 0.380],
        [ 0.378],
        [ 0.649],
        [ 0.489],
        [-0.103],
        [-0.126],
        [ 0.370],
        [-0.405],
        [-0.520],
        [ 0.861],
        [-0.087]], device='cuda:0')
s after update for 1 param tensor([[2.100],
        [2.006],
        [1.570],
        [2.258],
        [2.387],
        [1.641],
        [1.501],
        [1.496],
        [1.812],
        [1.708],
        [1.184],
        [1.772],
        [1.778],
        [1.899],
        [1.835],
        [2.005],
        [1.331],
        [1.680],
        [1.852],
        [1.883],
        [1.592],
        [1.616],
        [1.763],
        [1.843],
        [2.280],
        [1.326],
        [1.920],
        [1.763],
        [1.463],
        [2.059]], device='cuda:0')
b after update for 1 param tensor([[191.556],
        [187.231],
        [165.640],
        [198.639],
        [204.202],
        [169.327],
        [161.915],
        [161.658],
        [177.933],
        [172.766],
        [143.820],
        [175.944],
        [176.233],
        [182.168],
        [179.049],
        [187.155],
        [152.488],
        [171.343],
        [179.895],
        [181.362],
        [166.798],
        [168.025],
        [175.510],
        [179.445],
        [199.588],
        [152.187],
        [183.140],
        [175.494],
        [159.877],
        [189.662]], device='cuda:0')
clipping threshold 1.6895145338824729
cuda
Objective function 95.99 = squared loss an data 55.23 + 0.5*rho*h**2 32.279767 + alpha*h 5.731853 + L2reg 2.41 + L1reg 0.34 ; SHD = 142 ; DAG True
Proportion of microbatches that were clipped  0.7812774100948887
iteration 3 in inner loop, alpha 71.33699959943343 rho 10000.0 h 0.08034894768984557
iteration 3 in outer loop, alpha = 874.8264764978891, rho = 10000.0, h = 0.08034894768984557
cuda
9630
cuda
Objective function 160.55 = squared loss an data 55.23 + 0.5*rho*h**2 32.279767 + alpha*h 70.291387 + L2reg 2.41 + L1reg 0.34 ; SHD = 142 ; DAG True
||w||^2 2652385272489.1714
exp ma of ||w||^2 580970571155.6349
||w|| 1628614.5254446098
exp ma of ||w|| 369716.7815451526
||w||^2 10.407769171786047
exp ma of ||w||^2 495.4889469175049
||w|| 3.226107433391834
exp ma of ||w|| 2.9244890199714826
||w||^2 3.6213563793222248
exp ma of ||w||^2 5.131278935012375
||w|| 1.9029861742330723
exp ma of ||w|| 2.2448263176578838
||w||^2 7.653309113129736
exp ma of ||w||^2 5.350887164728414
||w|| 2.766461478699773
exp ma of ||w|| 2.2871014382000485
||w||^2 4.196244965254556
exp ma of ||w||^2 4.734453393749212
||w|| 2.0484738136609306
exp ma of ||w|| 2.149477975165924
||w||^2 5.782805846384988
exp ma of ||w||^2 5.0659049532714135
||w|| 2.4047465243524084
exp ma of ||w|| 2.2190452487590346
||w||^2 6.3811769552036335
exp ma of ||w||^2 5.1713487883579345
||w|| 2.5260991578328102
exp ma of ||w|| 2.2418728086708324
||w||^2 4.2408461946000715
exp ma of ||w||^2 5.242203576388879
||w|| 2.059331492159548
exp ma of ||w|| 2.25978941384221
||w||^2 4.474413396632737
exp ma of ||w||^2 5.238677054287945
||w|| 2.1152809261733383
exp ma of ||w|| 2.2656345485373963
||w||^2 8.804492345057913
exp ma of ||w||^2 5.149325690137716
||w|| 2.967236482833465
exp ma of ||w|| 2.245108889870593
||w||^2 4.7257995235794015
exp ma of ||w||^2 5.968386201149788
||w|| 2.173890412044591
exp ma of ||w|| 2.4292430680143977
cuda
Objective function 130.83 = squared loss an data 57.18 + 0.5*rho*h**2 18.122541 + alpha*h 52.667955 + L2reg 2.53 + L1reg 0.33 ; SHD = 142 ; DAG True
Proportion of microbatches that were clipped  0.7848573925478668
iteration 1 in inner loop, alpha 874.8264764978891 rho 10000.0 h 0.06020388790949838
9630
cuda
Objective function 293.93 = squared loss an data 57.18 + 0.5*rho*h**2 181.225406 + alpha*h 52.667955 + L2reg 2.53 + L1reg 0.33 ; SHD = 142 ; DAG True
||w||^2 64.02095508021637
exp ma of ||w||^2 72000.93397882419
||w|| 8.001309585325165
exp ma of ||w|| 8.449826355082653
||w||^2 32.34893383710298
exp ma of ||w||^2 97.48267192560046
||w|| 5.687612314240747
exp ma of ||w|| 5.6005669887055936
||w||^2 9.755818363424064
exp ma of ||w||^2 11.302516904156079
||w|| 3.1234305440371273
exp ma of ||w|| 3.3464354142729804
||w||^2 11.179275312396491
exp ma of ||w||^2 11.13148981527074
||w|| 3.3435423299842477
exp ma of ||w|| 3.3216616144658375
||w||^2 14.118847360095794
exp ma of ||w||^2 11.120487786770644
||w|| 3.757505470401313
exp ma of ||w|| 3.319358871492116
v before min max tensor([[ 2.848e+04,  6.730e+03, -3.036e+03,  ..., -4.703e+03, -3.996e+02,
         -3.104e+03],
        [ 2.884e+04, -4.899e+03,  9.972e+03,  ..., -4.673e+03, -1.686e+03,
          7.413e+03],
        [ 6.361e+04,  5.068e+02, -2.845e+03,  ..., -1.009e+03,  4.645e+03,
          5.550e+01],
        ...,
        [ 2.159e+03,  1.744e+04,  1.317e+04,  ..., -3.578e+03, -2.408e+03,
         -2.362e+03],
        [-4.163e+03, -3.833e+03, -5.601e+02,  ..., -2.832e+03,  1.717e+04,
         -5.238e+03],
        [ 1.873e+04, -4.644e+03,  3.515e+04,  ...,  9.735e+03, -4.139e+03,
         -5.964e+03]], device='cuda:0')
v tensor([[1.000e+01, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e+01],
        [1.000e+01, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         1.000e+01],
        ...,
        [1.000e+01, 1.000e+01, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([ 6.137e+03, -3.730e+03,  1.649e+03, -2.777e+03,  2.947e+03, -4.172e+03,
        -3.428e+03, -2.975e+03, -4.014e+03,  1.083e+04,  1.578e+03, -3.577e+03,
         9.258e+03, -3.848e+03,  7.034e+03,  1.540e+03, -3.025e+03, -2.882e+03,
         1.388e+04, -7.090e+02, -2.550e+03, -2.576e+02, -1.065e+03, -3.707e+03,
        -2.216e+03, -3.607e+03, -2.080e+03,  3.228e+03,  1.655e+02,  1.214e+03,
         5.635e+04, -1.950e+03, -8.698e+02,  5.568e+03, -2.450e+03, -1.499e+03,
         2.675e+04, -5.706e+03, -2.660e+03,  4.543e+04,  9.572e+02,  2.134e+04,
        -5.291e+03, -3.584e+03,  6.503e+00, -3.892e+03,  1.198e+04,  1.533e+03,
        -1.042e+03, -2.444e+03, -5.649e+02, -4.513e+03, -5.681e+03, -5.881e+03,
        -4.634e+03, -3.008e+03,  9.252e+02,  1.602e+04,  1.338e+04, -5.284e+03,
        -1.468e+03,  1.889e+04,  7.641e+03, -3.342e+03, -4.935e+03, -4.656e+03,
         1.632e+03, -3.953e+03, -3.269e+03, -4.444e+03, -1.113e+03, -3.316e+03,
        -7.675e+02, -3.494e+03,  2.337e+04, -3.787e+03,  8.076e+03, -3.057e+03,
        -3.286e+03, -3.219e+03, -3.681e+03, -4.322e+03, -1.239e+03, -1.084e+02,
         3.491e+04,  1.452e+02,  4.348e+04,  2.427e+03, -3.408e+03, -1.787e+03,
        -4.912e+03, -4.101e+03, -3.443e+03, -3.289e+03, -3.228e+03, -3.670e+03,
         9.958e+03, -4.185e+03,  6.775e+04, -4.124e+03, -4.261e+03, -4.223e+03,
         1.582e+04,  2.108e+03,  1.446e+03, -1.034e+02,  4.088e+02, -4.120e+03,
         6.540e+03, -2.396e+03, -1.454e+03,  1.574e+04, -3.538e+03,  1.596e+03,
        -8.363e+02, -3.851e+03, -9.336e+02, -3.802e+03, -3.299e+03, -3.282e+03,
         3.872e+04, -1.405e+03,  7.712e+03,  1.473e+04, -3.256e+03, -4.488e+03,
        -3.672e+03, -1.653e+03, -3.957e+03, -4.826e+03, -9.830e+02,  2.329e+03,
        -5.403e+03, -3.867e+03,  2.483e+04,  1.932e+03, -5.355e+03, -4.124e+03,
        -4.129e+03, -1.730e+03,  7.541e+03, -3.401e+03, -3.946e+03, -4.200e+03,
         6.224e+03, -4.289e+03,  5.612e+03, -3.626e+03, -2.676e+03, -4.678e+03,
        -2.903e+03, -3.712e+03, -4.083e+03,  7.976e+03, -4.727e+02, -2.268e+03,
         8.191e+02, -4.578e+03, -2.455e+03, -4.543e+03, -4.172e+03, -1.736e+03,
         5.800e+03, -2.140e+03,  5.598e+03, -4.070e+03, -4.262e+03,  1.396e+03,
         3.720e+03, -1.670e+03,  1.018e+03, -3.828e+03,  7.530e+03, -4.279e+03,
        -4.698e+03,  7.843e+02, -3.852e+03,  4.824e+03, -3.355e+03, -2.518e+03,
        -3.383e+03,  2.660e+03, -2.657e+02, -3.246e+03, -4.123e+03,  1.061e+04,
        -2.854e+03, -2.567e+03,  2.704e+03,  1.563e+04, -2.102e+03, -4.046e+03,
        -3.326e+03, -4.065e+03, -3.569e+03,  3.670e+04, -3.646e+03, -2.658e+03,
        -1.832e+03,  1.316e+04,  1.979e+03, -1.784e+03,  4.486e+03,  2.794e+03,
         1.952e+04, -4.621e+03,  9.276e+03, -4.121e+03, -1.898e+02,  1.149e+04,
         2.071e+03, -1.199e+03,  2.365e+04,  1.047e+04, -3.440e+03,  1.938e+04,
        -4.698e+03, -3.601e+03, -1.909e+03,  1.307e+04,  7.384e+03, -5.748e+02,
        -4.667e+03, -2.554e+03,  2.381e+04,  2.512e+04, -4.540e+03, -4.824e+03,
         1.200e+04, -4.116e+03,  1.514e+04, -2.286e+03, -2.897e+03, -3.235e+03,
        -6.737e+02,  7.504e+03,  1.355e+02,  1.553e+03,  5.513e+03,  1.720e+03,
        -5.093e+03, -3.362e+03, -1.469e+03,  4.429e+04,  8.050e+03,  1.513e+03,
        -1.750e+03,  1.204e+03, -1.955e+03,  7.518e+02, -3.100e+03,  5.586e+03,
        -2.673e+03, -3.342e+03,  1.138e+03,  7.355e+03, -4.340e+03, -9.731e+00,
        -2.583e+03, -5.395e+03,  4.150e+03, -3.216e+02,  3.389e+03, -3.345e+03,
         9.988e+03, -3.093e+03,  1.122e+04, -5.417e+03,  1.223e+03,  4.025e+03,
        -3.715e+03, -3.694e+03,  1.401e+04,  1.181e+03,  5.053e+02,  8.426e+03,
        -4.172e+03,  5.731e+03, -9.477e+02, -3.804e+03, -2.140e+03,  4.471e+03,
         1.152e+04,  2.288e+04, -1.016e+03, -5.047e+03,  9.026e+03, -3.980e+03,
        -2.217e+03, -3.731e+03, -3.728e+03, -4.819e+03, -4.151e+03, -3.911e+03,
        -3.857e+03,  1.316e+03, -2.020e+03, -4.883e+03,  3.317e+03, -3.776e+03],
       device='cuda:0')
v tensor([1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 6.503e+00, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-4106.128],
         [ 7068.976],
         [17161.392],
         [  765.630],
         [-5195.535],
         [-3347.359],
         [-2516.955],
         [ 1102.483],
         [ -186.733],
         [-1445.014]],

        [[ -290.826],
         [  940.384],
         [-3350.472],
         [-1385.217],
         [-1087.397],
         [  492.937],
         [ 5080.051],
         [27756.148],
         [14678.122],
         [ -685.367]],

        [[ 2685.043],
         [-4036.604],
         [-3259.045],
         [12346.627],
         [ 7956.215],
         [10720.086],
         [-5166.390],
         [-2398.242],
         [-1346.039],
         [ 5552.493]],

        [[-3938.255],
         [-4614.057],
         [16893.685],
         [14259.541],
         [-2889.347],
         [-3124.777],
         [-4536.166],
         [ 2680.229],
         [-3304.707],
         [-2659.981]],

        [[14568.332],
         [-3985.154],
         [ -760.093],
         [-4955.450],
         [-5430.750],
         [-3237.908],
         [-3004.246],
         [-4692.149],
         [-4523.506],
         [-1337.853]],

        [[44098.447],
         [ 9526.159],
         [  374.889],
         [ 7102.535],
         [-2669.630],
         [11865.378],
         [ 2566.903],
         [  -93.888],
         [ 7357.829],
         [13643.760]],

        [[-2942.896],
         [-5149.249],
         [-2481.095],
         [-4613.544],
         [ 9532.924],
         [ -132.119],
         [-3185.129],
         [ 4751.194],
         [ 8879.604],
         [-2143.942]],

        [[ 6322.040],
         [10425.832],
         [-3480.276],
         [13052.138],
         [ -186.799],
         [-2506.074],
         [-3434.803],
         [-1613.988],
         [-3971.289],
         [ 2904.122]],

        [[-3992.720],
         [-4207.454],
         [-3483.900],
         [ 4397.852],
         [ 4280.947],
         [-2540.290],
         [-4238.522],
         [  543.611],
         [-3554.846],
         [ -965.385]],

        [[-3723.459],
         [-4032.113],
         [19870.314],
         [12115.418],
         [ 1426.772],
         [27712.575],
         [ -976.731],
         [29838.296],
         [-3099.752],
         [19639.692]],

        [[ 7797.385],
         [ 5623.062],
         [-4497.743],
         [ 8180.060],
         [-4950.458],
         [-4299.709],
         [ 8151.071],
         [ -558.729],
         [-2312.811],
         [-3494.085]],

        [[-4028.550],
         [-1955.467],
         [-3849.809],
         [ 6548.076],
         [  492.989],
         [-2106.543],
         [-2912.365],
         [-3711.477],
         [ 5498.755],
         [-2157.742]],

        [[14519.291],
         [  646.639],
         [ 5414.854],
         [-4490.248],
         [  895.307],
         [ 1290.271],
         [-3554.971],
         [-2985.156],
         [ 3150.842],
         [ -387.622]],

        [[-1370.728],
         [ 8823.465],
         [ 1542.428],
         [-2626.059],
         [-3761.904],
         [ -886.397],
         [-1851.212],
         [ 4571.822],
         [ 8925.383],
         [ 4681.003]],

        [[-4298.591],
         [-4250.395],
         [-4608.890],
         [-1499.789],
         [22933.389],
         [26721.654],
         [-3438.606],
         [-3343.974],
         [11327.801],
         [10183.050]],

        [[-4795.220],
         [ 4671.220],
         [ 5013.337],
         [  415.666],
         [ 4752.452],
         [-3570.162],
         [ 9895.594],
         [-4502.907],
         [-1566.640],
         [16480.879]],

        [[ 6964.098],
         [ 1783.423],
         [-2626.203],
         [-4979.697],
         [-4566.493],
         [16656.256],
         [-4103.366],
         [-1114.747],
         [-1154.937],
         [-1810.792]],

        [[ 4441.084],
         [11603.617],
         [ 1669.354],
         [ -945.095],
         [-1404.122],
         [-2623.906],
         [ 1228.444],
         [ 2012.924],
         [ 3255.686],
         [-4465.652]],

        [[-2501.591],
         [-2467.466],
         [-2657.943],
         [26129.089],
         [-4000.149],
         [ 7304.818],
         [-1880.280],
         [11675.606],
         [-2279.133],
         [-4545.458]],

        [[ 2591.404],
         [-2245.265],
         [-1411.540],
         [-4141.278],
         [-3733.312],
         [ 2329.199],
         [-2973.408],
         [-4038.224],
         [ 1085.087],
         [10221.350]],

        [[-5175.420],
         [-1652.835],
         [-4598.148],
         [-4849.382],
         [-4072.587],
         [-2903.101],
         [-2849.996],
         [-4707.093],
         [  605.168],
         [ 9180.307]],

        [[-1497.023],
         [-5269.754],
         [ 4327.833],
         [-4812.077],
         [ -184.515],
         [ 2084.640],
         [ 8991.729],
         [-3958.854],
         [-3215.295],
         [10364.930]],

        [[-2152.410],
         [-3772.439],
         [-3891.463],
         [-3854.059],
         [-2549.582],
         [-2717.211],
         [13025.123],
         [  100.137],
         [-5464.676],
         [-1182.614]],

        [[-4158.229],
         [ 6451.786],
         [-2936.575],
         [-2444.216],
         [-4444.017],
         [-1324.181],
         [-1656.719],
         [ 4249.668],
         [  611.636],
         [ 7773.403]],

        [[-2737.149],
         [-3122.933],
         [-2782.269],
         [-3506.065],
         [-2074.303],
         [ 2861.804],
         [ 1710.043],
         [-4157.932],
         [-3345.311],
         [ 3214.868]],

        [[-4619.367],
         [-4845.963],
         [-4427.840],
         [ 4002.794],
         [-4495.232],
         [-3836.852],
         [-2339.164],
         [ 5473.326],
         [ -978.416],
         [ 8052.188]],

        [[-2543.333],
         [-2703.742],
         [  893.624],
         [10904.266],
         [ -435.152],
         [ -753.621],
         [25552.405],
         [-5045.584],
         [12152.259],
         [-1159.772]],

        [[-2402.923],
         [-3618.468],
         [-3742.640],
         [-4232.963],
         [-4793.458],
         [24909.157],
         [ 2993.480],
         [-3523.245],
         [  578.438],
         [ 4624.309]],

        [[ 9800.048],
         [-4167.232],
         [-4870.491],
         [  274.686],
         [-5239.268],
         [-5077.788],
         [-3143.371],
         [-5560.552],
         [ 2495.567],
         [ 5501.342]],

        [[ 4759.544],
         [  -45.751],
         [-1085.731],
         [  264.399],
         [ 8980.695],
         [-1713.731],
         [-3972.552],
         [12003.372],
         [-5145.860],
         [-3116.472]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[-1466.403],
        [-1754.095],
        [-1161.440],
        [ 2737.435],
        [ 8803.282],
        [-3618.441],
        [-4061.269],
        [ 4892.510],
        [-3882.069],
        [-1181.649],
        [-1213.728],
        [ 5835.832],
        [-3878.422],
        [-3936.830],
        [-3404.171],
        [ 2758.631],
        [-4182.768],
        [-2794.225],
        [ 9984.619],
        [-3321.297],
        [12278.619],
        [ -280.374],
        [ 1341.982],
        [11037.302],
        [ 8104.485],
        [-1876.542],
        [  254.218],
        [-2553.369],
        [ -296.265],
        [-5153.480]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-0.060,  1.891,  0.268,  ..., -1.588, -0.642, -0.726],
        [-0.027, -0.647, -0.214,  ..., -0.359,  0.542, -0.609],
        [-0.217, -0.504,  0.705,  ..., -1.040, -0.252,  0.883],
        ...,
        [-0.552, -0.294,  0.404,  ...,  0.954,  0.090,  0.107],
        [-0.381, -0.080, -0.432,  ..., -2.561, -0.071, -0.182],
        [-0.038, -0.360,  0.367,  ..., -2.122,  0.332, -0.110]],
       device='cuda:0')
s after update for 1 param tensor([[2.679, 1.512, 2.186,  ..., 1.915, 1.222, 1.683],
        [1.749, 1.992, 1.930,  ..., 1.865, 0.794, 1.800],
        [2.803, 1.716, 1.597,  ..., 0.915, 1.333, 1.891],
        ...,
        [2.083, 1.855, 1.851,  ..., 1.634, 1.735, 1.626],
        [1.699, 1.512, 2.005,  ..., 2.046, 2.294, 2.062],
        [2.096, 1.896, 1.958,  ..., 1.827, 1.767, 2.340]], device='cuda:0')
b after update for 1 param tensor([[219.196, 164.642, 197.985,  ..., 185.329, 148.031, 173.727],
        [177.120, 188.997, 186.024,  ..., 182.891, 119.341, 179.643],
        [224.197, 175.403, 169.244,  ..., 128.065, 154.594, 184.130],
        ...,
        [193.286, 182.366, 182.172,  ..., 171.153, 176.377, 170.735],
        [174.536, 164.654, 189.597,  ..., 191.564, 202.802, 192.279],
        [193.893, 184.391, 187.357,  ..., 180.983, 178.018, 204.855]],
       device='cuda:0')
clipping threshold 2.5577662968511463
a after update for 1 param tensor([ 0.489,  0.730,  1.600, -1.263, -0.637, -0.146, -0.145,  0.063, -0.451,
         0.106, -3.262, -0.665,  1.350,  0.241, -0.013,  0.866, -2.272,  0.384,
         1.068,  1.323,  3.026,  0.224, -0.104,  0.509, -0.641, -0.879, -1.260,
         0.990, -0.636,  1.687, -0.452,  2.062, -0.136, -0.236, -1.000, -2.104,
        -0.645,  0.225,  0.509,  0.105, -0.790, -0.696,  1.572,  1.778,  0.537,
        -1.014,  2.027,  3.620, -1.441, -1.357, -0.209, -0.657, -0.043, -0.581,
        -0.024,  0.836, -1.329,  0.013,  0.595,  0.095, -0.268, -1.393,  1.555,
         0.883,  1.097, -0.601,  0.304,  0.133,  0.999,  0.097,  0.222,  0.360,
         2.076,  0.434,  0.046,  0.413,  0.114,  1.513, -1.044,  1.591,  1.502,
        -1.528, -0.091, -2.877, -1.934,  2.073, -0.046, -0.723,  0.520,  2.250,
        -0.275, -1.091,  0.307, -1.059,  1.516, -1.882,  0.101,  1.424, -1.853,
         0.964,  0.204, -0.139, -0.074,  0.277, -1.640,  0.189,  0.041, -1.127,
         0.105, -1.853, -0.188,  0.192,  1.206, -0.591,  1.152,  1.115, -1.073,
         0.270,  0.749,  0.515,  0.757, -1.164,  2.062,  0.800,  1.478,  0.445,
         0.104,  1.832, -0.227, -1.020, -5.088,  0.011, -1.414,  0.537, -0.344,
        -1.227,  1.091, -1.638,  0.649,  1.437, -1.137,  0.252, -0.110, -0.884,
         0.876, -1.065,  1.186, -0.100,  1.506,  2.219, -0.668, -0.533, -0.632,
        -0.759, -0.857, -0.924, -0.047, -0.813, -0.681,  0.863,  0.205, -0.293,
         0.671,  1.360, -0.141,  0.453,  1.521,  0.395,  0.211, -0.681, -0.169,
         0.401,  0.573, -0.014, -0.804, -1.402,  0.007,  1.935, -1.957,  0.731,
         1.655,  1.581,  0.144, -0.104, -0.396, -1.178, -0.494,  0.245,  0.771,
        -0.715, -0.936,  1.556, -0.503, -1.757,  1.360,  0.129, -0.463,  0.633,
         1.452, -0.544, -0.326,  0.597, -1.477, -1.917,  0.410, -1.308,  1.834,
         0.760, -0.600,  0.222, -0.439, -0.147,  0.518, -1.103, -1.340,  0.753,
         0.071,  0.831,  0.080, -0.833, -1.132, -0.565,  0.930, -0.956,  1.911,
         1.461,  0.753,  0.237,  1.652, -1.623, -1.240,  0.496, -2.306, -0.354,
        -1.392,  1.533, -0.027,  1.974,  1.625, -0.216, -0.734, -0.761, -0.427,
        -0.757, -0.236, -0.061,  0.227,  0.398, -0.663, -1.791, -0.323,  0.492,
         1.505, -0.827, -2.777,  0.813, -2.307, -1.201, -2.366,  0.963,  2.247,
        -0.857, -0.244,  0.306,  0.657, -0.066, -0.993,  1.332, -1.542, -1.220,
         2.671,  0.052,  0.777,  0.043, -0.483,  0.230,  1.645, -0.788, -0.056,
        -0.924,  0.398, -1.875, -1.837, -0.353,  0.868,  0.751,  1.234, -1.704,
         1.620,  0.588, -1.257, -1.284,  0.802,  0.007,  0.298,  1.176, -0.274,
         0.942,  0.897,  1.340], device='cuda:0')
s after update for 1 param tensor([1.969, 1.837, 2.150, 2.132, 1.857, 1.772, 1.508, 2.068, 2.336, 2.057,
        1.538, 1.425, 1.666, 1.746, 1.820, 2.081, 1.360, 1.620, 1.874, 1.104,
        1.519, 1.818, 1.911, 1.742, 1.390, 1.506, 1.162, 1.623, 1.978, 2.116,
        2.294, 1.532, 1.610, 1.686, 1.794, 1.636, 1.846, 2.244, 1.514, 2.131,
        1.803, 1.873, 2.184, 1.987, 1.785, 1.555, 1.963, 1.672, 1.830, 1.870,
        2.040, 1.886, 2.250, 2.308, 1.895, 1.749, 1.909, 2.224, 2.139, 2.084,
        1.315, 2.142, 1.550, 1.547, 2.018, 1.824, 1.777, 2.006, 1.291, 1.891,
        0.951, 2.072, 1.522, 1.386, 2.125, 1.490, 2.330, 1.589, 1.634, 1.318,
        1.762, 1.965, 1.685, 1.419, 2.222, 1.681, 2.620, 2.087, 1.547, 1.448,
        1.931, 1.836, 1.840, 1.706, 1.532, 1.540, 2.000, 1.675, 2.625, 1.703,
        1.669, 1.708, 1.998, 1.652, 2.152, 1.643, 1.731, 1.619, 2.623, 1.449,
        1.286, 1.590, 1.389, 1.861, 1.793, 1.528, 1.249, 1.562, 1.338, 1.365,
        2.271, 1.539, 1.917, 1.654, 1.644, 1.785, 1.594, 1.383, 1.868, 1.927,
        2.232, 2.009, 2.154, 1.596, 1.846, 2.200, 2.100, 1.744, 1.800, 1.690,
        1.842, 1.465, 1.625, 1.696, 2.205, 1.682, 2.201, 1.427, 2.062, 1.844,
        1.570, 1.873, 1.599, 2.232, 1.493, 1.795, 2.153, 1.869, 1.864, 1.785,
        1.665, 1.294, 1.750, 1.786, 1.657, 1.776, 1.873, 2.342, 1.335, 1.658,
        2.209, 1.727, 1.267, 1.788, 1.842, 1.641, 1.510, 2.166, 1.366, 1.716,
        1.346, 2.044, 1.698, 1.272, 1.656, 1.959, 1.851, 1.962, 2.402, 1.842,
        1.534, 1.938, 1.701, 1.789, 1.544, 1.561, 1.484, 1.491, 1.460, 2.012,
        2.159, 1.505, 1.857, 2.059, 1.905, 1.882, 1.756, 1.827, 1.742, 1.929,
        1.586, 2.079, 2.270, 2.002, 1.604, 1.886, 1.911, 1.460, 2.091, 1.783,
        2.053, 2.144, 1.828, 1.952, 1.832, 2.160, 1.788, 1.891, 1.730, 1.614,
        2.055, 1.281, 2.038, 1.544, 1.471, 2.343, 1.692, 2.153, 1.867, 2.057,
        2.058, 1.792, 1.196, 2.045, 2.005, 2.254, 2.180, 1.620, 1.315, 1.857,
        1.563, 1.991, 1.274, 1.347, 1.900, 2.282, 1.776, 1.903, 1.416, 2.115,
        1.756, 1.555, 2.605, 2.136, 1.784, 1.217, 2.093, 2.209, 1.851, 1.903,
        1.471, 1.658, 1.866, 1.781, 2.242, 2.288, 1.636, 2.079, 1.201, 1.519,
        2.072, 1.952, 1.674, 2.372, 1.453, 1.979, 2.284, 2.090, 1.258, 1.501,
        1.475, 1.942, 1.796, 1.806, 1.698, 1.616, 1.512, 2.121, 2.088, 1.799],
       device='cuda:0')
b after update for 1 param tensor([187.883, 181.503, 196.349, 195.526, 182.498, 178.273, 164.419, 192.579,
        204.675, 192.068, 166.088, 159.854, 172.848, 176.960, 180.647, 193.170,
        156.176, 170.431, 183.297, 140.710, 165.047, 180.532, 185.106, 176.760,
        157.906, 164.327, 144.326, 170.614, 188.321, 194.802, 202.842, 165.768,
        169.927, 173.860, 179.365, 171.280, 181.964, 200.583, 164.789, 195.466,
        179.809, 183.268, 197.914, 188.742, 178.899, 166.991, 187.621, 173.144,
        181.171, 183.112, 191.249, 183.896, 200.887, 203.447, 184.349, 177.115,
        185.004, 199.683, 195.873, 193.323, 153.564, 196.006, 166.721, 166.561,
        190.232, 180.865, 178.530, 189.675, 152.130, 184.126, 130.586, 192.740,
        165.210, 157.665, 195.202, 163.436, 204.395, 168.821, 171.186, 153.727,
        177.766, 187.724, 173.823, 159.501, 199.594, 173.608, 216.752, 193.447,
        166.562, 161.123, 186.105, 181.437, 181.638, 174.929, 165.772, 166.166,
        189.363, 173.314, 216.942, 174.767, 173.003, 175.001, 189.262, 172.108,
        196.459, 171.660, 176.205, 170.369, 216.871, 161.200, 151.885, 168.841,
        157.810, 182.674, 179.294, 165.533, 149.680, 167.351, 154.880, 156.470,
        201.796, 166.126, 185.427, 172.204, 171.705, 178.891, 169.089, 157.488,
        183.047, 185.906, 200.061, 189.821, 196.548, 169.173, 181.936, 198.625,
        194.078, 176.845, 179.653, 174.063, 181.749, 162.063, 170.695, 174.372,
        198.852, 173.686, 198.668, 159.975, 192.287, 181.851, 167.781, 183.261,
        169.344, 200.062, 163.614, 179.434, 196.490, 183.080, 182.844, 178.920,
        172.768, 152.315, 177.161, 178.960, 172.399, 178.476, 183.281, 204.928,
        154.748, 172.428, 199.014, 175.975, 150.706, 179.073, 181.732, 171.551,
        164.553, 197.067, 156.498, 175.435, 155.380, 191.464, 174.485, 151.000,
        172.349, 187.439, 182.174, 187.562, 207.546, 181.742, 165.829, 186.421,
        174.631, 179.125, 166.422, 167.335, 163.141, 163.538, 161.810, 189.939,
        196.772, 164.267, 182.480, 192.130, 184.838, 183.732, 177.462, 180.982,
        176.743, 186.003, 168.656, 193.076, 201.757, 189.477, 169.589, 183.923,
        185.109, 161.807, 193.621, 178.807, 191.854, 196.084, 181.071, 187.090,
        181.227, 196.821, 179.056, 184.149, 176.154, 170.115, 191.984, 151.579,
        191.147, 166.407, 162.421, 204.961, 174.169, 196.504, 182.975, 192.070,
        192.087, 179.250, 146.457, 191.480, 189.596, 201.048, 197.708, 170.455,
        153.587, 182.487, 167.415, 188.972, 151.160, 155.418, 184.574, 202.280,
        178.483, 184.727, 159.334, 194.760, 177.430, 166.968, 216.138, 195.715,
        178.873, 147.717, 193.751, 199.049, 182.206, 184.711, 162.415, 172.440,
        182.927, 178.702, 200.492, 202.545, 171.301, 193.086, 146.751, 165.037,
        192.781, 187.086, 173.237, 206.249, 161.419, 188.385, 202.367, 193.616,
        150.200, 164.079, 162.648, 186.620, 179.458, 179.943, 174.502, 170.229,
        164.643, 195.019, 193.482, 179.623], device='cuda:0')
clipping threshold 2.5577662968511463
a after update for 1 param tensor([[[ 4.173e-01],
         [ 1.281e+00],
         [-1.179e+00],
         [ 4.283e-01],
         [-5.027e-01],
         [ 2.587e-01],
         [ 9.440e-02],
         [ 7.924e-01],
         [ 1.815e+00],
         [ 1.796e-01]],

        [[-3.650e-01],
         [ 2.448e-01],
         [ 1.393e+00],
         [-9.735e-01],
         [ 1.640e+00],
         [ 7.896e-01],
         [ 8.850e-01],
         [ 7.707e-01],
         [-2.121e+00],
         [ 3.263e-01]],

        [[-3.639e-01],
         [ 5.696e-04],
         [-2.254e+00],
         [ 1.684e+00],
         [ 1.985e-01],
         [ 1.454e+00],
         [ 3.691e-01],
         [ 1.017e+00],
         [ 3.314e-01],
         [-3.090e-01]],

        [[-1.142e+00],
         [-6.739e-01],
         [ 5.762e-01],
         [ 1.956e+00],
         [-1.413e+00],
         [-2.555e-01],
         [ 3.870e-01],
         [-1.689e+00],
         [-9.461e-02],
         [ 1.866e-01]],

        [[-9.637e-01],
         [-5.854e-01],
         [ 1.300e+00],
         [ 2.634e-01],
         [ 5.643e-01],
         [-8.804e-02],
         [-5.883e-01],
         [ 1.740e+00],
         [-2.853e-01],
         [ 1.703e+00]],

        [[-2.238e+00],
         [-3.517e+00],
         [-2.696e-01],
         [ 8.082e-01],
         [-4.297e-01],
         [ 7.426e-02],
         [-5.030e-01],
         [-4.070e-01],
         [-3.689e-01],
         [-8.240e-01]],

        [[ 7.091e-01],
         [ 1.893e+00],
         [-3.939e-01],
         [ 4.698e-01],
         [-4.198e-02],
         [ 1.503e+00],
         [ 3.069e-01],
         [-2.645e+00],
         [-5.424e-01],
         [ 1.251e+00]],

        [[ 4.790e-01],
         [ 2.027e+00],
         [ 1.136e+00],
         [-1.239e+00],
         [ 5.785e-02],
         [-7.763e-02],
         [-1.206e+00],
         [ 1.885e+00],
         [ 5.520e-01],
         [ 3.515e-01]],

        [[-1.356e+00],
         [-4.057e-01],
         [ 2.431e-01],
         [ 6.815e-02],
         [-3.612e-01],
         [ 3.884e-01],
         [ 1.119e+00],
         [ 5.418e-01],
         [-1.989e+00],
         [ 5.263e-01]],

        [[-5.169e-01],
         [-4.387e-01],
         [-2.833e-01],
         [ 5.928e-01],
         [ 2.062e-01],
         [ 1.836e-01],
         [ 9.450e-01],
         [-1.401e+00],
         [-5.556e-01],
         [-4.633e-02]],

        [[ 6.034e-01],
         [ 1.978e+00],
         [-1.511e-01],
         [-9.815e-01],
         [ 1.696e-01],
         [ 3.755e-01],
         [ 2.928e-01],
         [-4.309e-01],
         [-1.388e+00],
         [-1.762e-01]],

        [[-1.715e+00],
         [-1.604e+00],
         [ 2.213e+00],
         [ 1.515e+00],
         [-6.565e-01],
         [-2.252e-01],
         [ 1.095e+00],
         [ 1.194e+00],
         [-7.954e-01],
         [ 8.060e-02]],

        [[ 1.398e+00],
         [-4.942e-01],
         [-1.433e+00],
         [ 1.382e+00],
         [ 1.989e-01],
         [-1.548e+00],
         [-5.933e-01],
         [ 2.469e+00],
         [-8.025e-01],
         [ 1.163e+00]],

        [[-2.288e+00],
         [ 1.296e+00],
         [ 3.980e-01],
         [-1.525e+00],
         [ 1.821e+00],
         [-5.343e-01],
         [ 4.625e-01],
         [-1.631e+00],
         [-1.668e+00],
         [-3.712e-01]],

        [[-1.296e+00],
         [ 3.434e-01],
         [ 1.914e+00],
         [-6.776e-02],
         [ 6.299e-01],
         [ 2.314e+00],
         [ 5.403e-01],
         [ 3.626e-01],
         [ 1.762e+00],
         [-1.662e-02]],

        [[ 7.883e-01],
         [ 3.529e-01],
         [-1.068e+00],
         [-1.122e+00],
         [ 1.445e+00],
         [-1.435e+00],
         [-6.589e-01],
         [-1.603e+00],
         [-3.712e-01],
         [-6.974e-01]],

        [[ 1.863e+00],
         [-1.059e-01],
         [-7.552e-02],
         [-1.204e+00],
         [ 1.525e+00],
         [ 6.586e-01],
         [ 6.317e-01],
         [ 1.698e+00],
         [ 5.873e-02],
         [ 7.473e-01]],

        [[ 9.658e-01],
         [-8.188e-01],
         [ 1.008e+00],
         [ 8.316e-02],
         [-8.122e-01],
         [ 3.489e-01],
         [-3.751e-01],
         [ 1.646e+00],
         [ 1.526e-01],
         [ 3.113e-01]],

        [[-2.049e-01],
         [-8.450e-01],
         [ 1.604e+00],
         [ 1.261e-01],
         [ 5.245e-01],
         [ 7.351e-01],
         [ 1.305e+00],
         [ 3.523e-01],
         [-9.699e-01],
         [-1.719e+00]],

        [[-5.690e-01],
         [ 1.637e-02],
         [ 6.139e-02],
         [-1.411e+00],
         [-3.000e-01],
         [ 1.903e-01],
         [-4.366e-01],
         [-1.346e+00],
         [ 1.529e+00],
         [-1.931e+00]],

        [[ 2.944e+00],
         [-4.047e-01],
         [ 7.519e-01],
         [-1.393e+00],
         [ 4.955e-01],
         [-5.951e-01],
         [-1.784e+00],
         [-3.201e-02],
         [ 1.263e+00],
         [ 3.524e-01]],

        [[ 8.747e-01],
         [ 1.695e+00],
         [ 1.357e+00],
         [ 8.416e-01],
         [-3.917e-01],
         [ 3.705e-01],
         [-6.216e-01],
         [-1.490e+00],
         [-3.620e-01],
         [-2.010e+00]],

        [[-9.900e-01],
         [-7.633e-01],
         [-1.795e+00],
         [-2.640e+00],
         [-1.717e-01],
         [ 2.908e-02],
         [ 1.260e+00],
         [ 7.926e-01],
         [ 1.087e+00],
         [ 5.111e-01]],

        [[-5.265e-01],
         [-1.768e+00],
         [-4.067e-01],
         [ 1.628e-01],
         [-1.190e-01],
         [-1.558e+00],
         [ 6.548e-01],
         [ 1.791e-01],
         [-8.933e-01],
         [ 2.291e+00]],

        [[ 1.133e+00],
         [-1.588e-01],
         [-4.025e-01],
         [ 1.450e+00],
         [ 7.251e-01],
         [ 2.689e-01],
         [-2.091e-01],
         [ 9.863e-01],
         [ 3.655e-01],
         [ 1.442e-01]],

        [[ 1.932e+00],
         [ 7.015e-03],
         [-1.687e+00],
         [ 1.219e+00],
         [-6.917e-01],
         [-4.936e-01],
         [-2.365e-01],
         [-1.785e-01],
         [ 1.531e+00],
         [ 9.356e-01]],

        [[-9.890e-01],
         [ 6.595e-01],
         [-4.881e-01],
         [ 5.538e-03],
         [-9.931e-01],
         [ 5.989e-01],
         [ 7.611e-01],
         [ 4.434e-02],
         [-9.561e-01],
         [ 1.993e-01]],

        [[-8.939e-01],
         [-2.983e-02],
         [-4.971e+00],
         [ 4.539e-01],
         [-6.483e-01],
         [ 1.385e+00],
         [ 1.697e-01],
         [ 8.094e-01],
         [ 2.593e-01],
         [-2.290e-01]],

        [[-1.440e+00],
         [ 8.388e-03],
         [-2.243e+00],
         [ 4.836e-01],
         [ 2.152e+00],
         [-5.338e-01],
         [ 4.070e-01],
         [-4.155e-01],
         [-1.431e+00],
         [-9.140e-02]],

        [[ 8.738e-01],
         [-4.871e-01],
         [ 1.003e+00],
         [ 7.563e-01],
         [-1.880e+00],
         [-5.590e-01],
         [-1.722e-01],
         [ 1.277e-01],
         [-8.030e-02],
         [ 1.607e+00]]], device='cuda:0')
s after update for 1 param tensor([[[1.674],
         [1.768],
         [2.056],
         [1.892],
         [2.097],
         [1.786],
         [1.539],
         [1.680],
         [1.349],
         [1.472]],

        [[1.914],
         [2.090],
         [1.474],
         [1.536],
         [1.568],
         [1.750],
         [1.905],
         [1.931],
         [2.115],
         [2.176]],

        [[1.672],
         [1.973],
         [1.522],
         [2.302],
         [2.055],
         [2.000],
         [2.025],
         [1.038],
         [1.060],
         [2.185]],

        [[1.690],
         [1.810],
         [2.022],
         [2.109],
         [1.906],
         [1.759],
         [1.971],
         [1.675],
         [1.683],
         [1.378]],

        [[2.204],
         [1.569],
         [2.051],
         [1.968],
         [2.128],
         [1.578],
         [1.416],
         [2.008],
         [1.797],
         [1.718]],

        [[2.370],
         [1.916],
         [2.260],
         [1.609],
         [1.731],
         [1.589],
         [1.853],
         [2.074],
         [2.370],
         [2.186]],

        [[1.614],
         [2.067],
         [1.098],
         [1.887],
         [2.085],
         [2.085],
         [1.456],
         [1.168],
         [1.949],
         [1.821]],

        [[2.382],
         [2.244],
         [1.516],
         [1.888],
         [1.152],
         [1.842],
         [1.647],
         [0.853],
         [1.605],
         [2.082]],

        [[1.747],
         [1.672],
         [1.603],
         [1.978],
         [1.928],
         [1.425],
         [1.714],
         [2.129],
         [1.512],
         [1.875]],

        [[2.167],
         [1.618],
         [1.702],
         [1.934],
         [2.041],
         [1.702],
         [1.574],
         [1.851],
         [2.022],
         [1.629]],

        [[2.173],
         [2.025],
         [1.771],
         [2.231],
         [1.950],
         [2.053],
         [1.723],
         [1.218],
         [1.614],
         [1.626]],

        [[2.180],
         [1.582],
         [1.566],
         [1.964],
         [1.956],
         [1.514],
         [1.975],
         [1.813],
         [2.171],
         [1.600]],

        [[1.969],
         [1.243],
         [2.322],
         [1.760],
         [1.891],
         [1.993],
         [1.425],
         [1.424],
         [2.492],
         [1.723]],

        [[1.359],
         [2.150],
         [1.699],
         [1.786],
         [1.634],
         [1.552],
         [1.933],
         [2.034],
         [2.122],
         [2.058]],

        [[1.747],
         [1.676],
         [1.847],
         [1.709],
         [2.288],
         [2.141],
         [1.477],
         [1.775],
         [1.820],
         [2.123]],

        [[1.920],
         [2.576],
         [2.033],
         [2.049],
         [1.787],
         [1.399],
         [1.760],
         [1.772],
         [2.037],
         [2.029]],

        [[2.176],
         [2.016],
         [1.213],
         [2.143],
         [1.859],
         [2.272],
         [1.621],
         [1.954],
         [1.519],
         [1.568]],

        [[2.336],
         [2.184],
         [1.600],
         [1.152],
         [1.775],
         [1.211],
         [1.718],
         [1.693],
         [1.830],
         [1.887]],

        [[1.222],
         [1.332],
         [2.167],
         [2.067],
         [1.903],
         [2.352],
         [1.565],
         [1.926],
         [1.199],
         [1.837]],

        [[2.108],
         [1.875],
         [2.218],
         [1.930],
         [2.090],
         [2.239],
         [1.890],
         [1.692],
         [1.849],
         [2.268]],

        [[2.062],
         [1.924],
         [1.801],
         [2.005],
         [1.920],
         [1.560],
         [1.601],
         [1.846],
         [2.065],
         [1.953]],

        [[1.810],
         [2.064],
         [2.037],
         [1.917],
         [1.662],
         [1.997],
         [1.836],
         [1.563],
         [1.813],
         [2.121]],

        [[0.969],
         [1.578],
         [1.668],
         [1.610],
         [1.480],
         [1.607],
         [1.734],
         [1.598],
         [2.162],
         [1.960]],

        [[1.676],
         [2.210],
         [1.262],
         [1.918],
         [1.805],
         [1.164],
         [1.611],
         [2.244],
         [1.502],
         [1.930]],

        [[1.468],
         [1.388],
         [1.773],
         [1.462],
         [1.723],
         [2.188],
         [2.316],
         [1.642],
         [1.354],
         [1.656]],

        [[2.093],
         [2.096],
         [1.912],
         [1.972],
         [1.868],
         [1.627],
         [0.918],
         [1.980],
         [1.390],
         [2.115]],

        [[1.576],
         [1.358],
         [2.020],
         [2.284],
         [1.544],
         [1.407],
         [2.187],
         [2.002],
         [1.866],
         [1.603]],

        [[1.706],
         [1.877],
         [1.493],
         [1.662],
         [1.919],
         [2.091],
         [1.706],
         [1.638],
         [2.105],
         [1.395]],

        [[1.630],
         [1.977],
         [2.000],
         [1.878],
         [2.052],
         [1.993],
         [1.844],
         [2.201],
         [2.396],
         [1.817]],

        [[1.982],
         [1.727],
         [1.143],
         [2.085],
         [2.026],
         [1.647],
         [1.564],
         [2.423],
         [2.080],
         [1.224]]], device='cuda:0')
b after update for 1 param tensor([[[173.281],
         [178.047],
         [192.031],
         [184.200],
         [193.927],
         [178.945],
         [166.138],
         [173.563],
         [155.558],
         [162.490]],

        [[185.254],
         [193.580],
         [162.603],
         [165.961],
         [167.708],
         [177.148],
         [184.819],
         [186.084],
         [194.763],
         [197.531]],

        [[173.164],
         [188.119],
         [165.206],
         [203.159],
         [191.962],
         [189.356],
         [190.578],
         [136.415],
         [137.873],
         [197.965]],

        [[174.074],
         [180.141],
         [190.409],
         [194.457],
         [184.885],
         [177.627],
         [188.015],
         [173.317],
         [173.742],
         [157.206]],

        [[198.793],
         [167.713],
         [191.775],
         [187.873],
         [195.325],
         [168.228],
         [159.367],
         [189.749],
         [179.528],
         [175.536]],

        [[206.143],
         [185.361],
         [201.331],
         [169.871],
         [176.184],
         [168.805],
         [182.306],
         [192.859],
         [206.156],
         [197.967]],

        [[170.136],
         [192.542],
         [140.309],
         [183.958],
         [193.349],
         [193.383],
         [161.608],
         [144.730],
         [186.972],
         [180.681]],

        [[206.674],
         [200.601],
         [164.867],
         [184.012],
         [143.753],
         [181.735],
         [171.860],
         [123.668],
         [169.630],
         [193.238]],

        [[176.979],
         [173.161],
         [169.521],
         [188.356],
         [185.959],
         [159.836],
         [175.320],
         [195.405],
         [164.651],
         [183.371]],

        [[197.149],
         [170.357],
         [174.727],
         [186.216],
         [191.291],
         [174.718],
         [168.021],
         [182.192],
         [190.426],
         [170.916]],

        [[197.385],
         [190.574],
         [178.199],
         [200.009],
         [187.010],
         [191.856],
         [175.773],
         [147.807],
         [170.132],
         [170.774]],

        [[197.725],
         [168.455],
         [167.562],
         [187.673],
         [187.270],
         [164.774],
         [188.173],
         [180.331],
         [197.294],
         [169.381]],

        [[187.907],
         [149.319],
         [204.046],
         [177.640],
         [184.133],
         [189.049],
         [159.834],
         [159.803],
         [211.410],
         [175.783]],

        [[156.095],
         [196.331],
         [174.535],
         [178.939],
         [171.156],
         [166.815],
         [186.159],
         [190.973],
         [195.074],
         [192.111]],

        [[176.983],
         [173.377],
         [181.993],
         [175.040],
         [202.558],
         [195.938],
         [162.760],
         [178.422],
         [180.676],
         [195.120]],

        [[185.564],
         [214.919],
         [190.915],
         [191.690],
         [179.011],
         [158.390],
         [177.633],
         [178.275],
         [191.128],
         [190.745]],

        [[197.522],
         [190.116],
         [147.477],
         [196.023],
         [182.594],
         [201.859],
         [170.475],
         [187.199],
         [165.055],
         [167.679]],

        [[204.666],
         [197.911],
         [169.374],
         [143.705],
         [178.413],
         [147.386],
         [175.523],
         [174.259],
         [181.169],
         [183.933]],

        [[148.008],
         [154.569],
         [197.122],
         [192.513],
         [184.709],
         [205.369],
         [167.541],
         [185.855],
         [146.616],
         [181.501]],

        [[194.433],
         [183.342],
         [199.423],
         [186.044],
         [193.614],
         [200.374],
         [184.083],
         [174.181],
         [182.075],
         [201.675]],

        [[192.271],
         [185.768],
         [179.719],
         [189.625],
         [185.529],
         [167.235],
         [169.438],
         [181.929],
         [192.431],
         [187.146]],

        [[180.137],
         [192.407],
         [191.104],
         [185.419],
         [172.614],
         [189.223],
         [181.460],
         [167.415],
         [180.300],
         [195.042]],

        [[131.807],
         [168.192],
         [172.955],
         [169.924],
         [162.937],
         [169.767],
         [176.311],
         [169.260],
         [196.909],
         [187.456]],

        [[173.376],
         [199.096],
         [150.438],
         [185.467],
         [179.927],
         [144.501],
         [169.968],
         [200.612],
         [164.101],
         [186.018]],

        [[162.273],
         [157.744],
         [178.286],
         [161.934],
         [175.760],
         [198.083],
         [203.784],
         [171.571],
         [155.846],
         [172.301]],

        [[193.749],
         [193.889],
         [185.165],
         [188.049],
         [183.035],
         [170.820],
         [128.273],
         [188.414],
         [157.874],
         [194.762]],

        [[168.123],
         [156.032],
         [190.309],
         [202.357],
         [166.379],
         [158.864],
         [198.054],
         [189.474],
         [182.933],
         [169.557]],

        [[174.895],
         [183.459],
         [163.647],
         [172.639],
         [185.515],
         [193.647],
         [174.885],
         [171.388],
         [194.264],
         [158.169]],

        [[170.962],
         [188.271],
         [189.402],
         [183.522],
         [191.839],
         [189.040],
         [181.852],
         [198.669],
         [207.269],
         [180.522]],

        [[188.504],
         [175.998],
         [143.154],
         [193.362],
         [190.586],
         [171.846],
         [167.488],
         [208.461],
         [193.153],
         [148.159]]], device='cuda:0')
clipping threshold 2.5577662968511463
a after update for 1 param tensor([[-0.260],
        [-0.690],
        [-0.333],
        [-0.968],
        [ 0.559],
        [-2.365],
        [ 0.260],
        [-1.561],
        [-0.157],
        [ 0.461],
        [-0.503],
        [-0.345],
        [ 1.405],
        [ 0.574],
        [-2.101],
        [ 0.626],
        [-1.277],
        [-0.614],
        [-0.850],
        [-0.583],
        [-1.945],
        [-0.454],
        [ 0.388],
        [-0.134],
        [ 2.623],
        [-0.381],
        [ 1.493],
        [-1.838],
        [ 0.436],
        [-0.482]], device='cuda:0')
s after update for 1 param tensor([[1.810],
        [1.884],
        [1.376],
        [2.338],
        [1.985],
        [1.739],
        [2.125],
        [2.081],
        [2.134],
        [1.378],
        [1.790],
        [1.781],
        [1.537],
        [1.628],
        [1.541],
        [2.050],
        [2.051],
        [1.315],
        [1.859],
        [1.349],
        [2.379],
        [1.384],
        [1.506],
        [2.381],
        [1.986],
        [1.569],
        [2.022],
        [1.163],
        [1.276],
        [2.249]], device='cuda:0')
b after update for 1 param tensor([[180.141],
        [183.789],
        [157.104],
        [204.772],
        [188.688],
        [176.575],
        [195.194],
        [193.171],
        [195.637],
        [157.216],
        [179.138],
        [178.691],
        [166.002],
        [170.885],
        [166.228],
        [191.730],
        [191.755],
        [153.553],
        [182.584],
        [155.538],
        [206.555],
        [157.548],
        [164.326],
        [206.649],
        [188.711],
        [167.714],
        [190.422],
        [144.436],
        [151.238],
        [200.807]], device='cuda:0')
clipping threshold 2.5577662968511463
||w||^2 8.82060581599126
exp ma of ||w||^2 6.940789202428769
||w|| 2.969950473659664
exp ma of ||w|| 2.6040510491131665
||w||^2 6.451758338688168
exp ma of ||w||^2 5.574497884340234
||w|| 2.5400311688418644
exp ma of ||w|| 2.3212777948483017
||w||^2 7.242220636687564
exp ma of ||w||^2 5.819911083805727
||w|| 2.691137424340787
exp ma of ||w|| 2.387293217292752
||w||^2 6.192789845232357
exp ma of ||w||^2 6.143930629415952
||w|| 2.4885316645026556
exp ma of ||w|| 2.4529390662574158
||w||^2 5.563221031116138
exp ma of ||w||^2 5.876820119147261
||w|| 2.3586481363518677
exp ma of ||w|| 2.4002326681778645
||w||^2 5.624804029562594
exp ma of ||w||^2 6.2137740996958835
||w|| 2.3716669305706892
exp ma of ||w|| 2.4707343877940673
||w||^2 5.772793405174737
exp ma of ||w||^2 6.378056660218321
||w|| 2.4026638144307118
exp ma of ||w|| 2.5070634545781285
||w||^2 5.747086419761412
exp ma of ||w||^2 6.753870614004952
||w|| 2.3973081612011025
exp ma of ||w|| 2.579507887878488
cuda
Objective function 100.34 = squared loss an data 56.58 + 0.5*rho*h**2 22.346161 + alpha*h 18.494321 + L2reg 2.61 + L1reg 0.31 ; SHD = 157 ; DAG True
Proportion of microbatches that were clipped  0.781021897810219
iteration 2 in inner loop, alpha 874.8264764978891 rho 100000.0 h 0.02114055882979926
iteration 4 in outer loop, alpha = 22015.38530629715, rho = 1000000.0, h = 0.02114055882979926
Threshold 0.3
[[0.005 0.035 0.11  0.151 0.099 0.106 0.091 0.042 0.068 0.076 0.014 0.038
  0.231 0.041 0.037 0.064 0.12  0.114 0.564 0.267 0.174 0.025 0.128 0.169
  0.028 0.062 0.036 0.023 0.075 0.042]
 [0.158 0.005 0.156 0.401 0.058 0.212 0.307 0.047 0.07  0.109 0.03  0.055
  0.26  0.101 0.047 0.163 0.289 0.19  0.285 0.212 0.559 0.099 0.254 0.329
  0.071 0.161 0.045 0.015 0.314 0.044]
 [0.058 0.045 0.009 0.224 0.048 0.047 0.054 0.017 0.022 0.028 0.01  0.052
  0.113 0.01  0.019 0.052 0.072 0.067 0.104 0.056 0.075 0.04  0.073 0.116
  0.027 0.033 0.03  0.023 0.043 0.023]
 [0.037 0.007 0.035 0.006 0.05  0.03  0.04  0.013 0.024 0.025 0.005 0.014
  0.083 0.027 0.011 0.021 0.097 0.074 0.16  0.068 0.057 0.019 0.105 0.107
  0.016 0.011 0.017 0.007 0.042 0.015]
 [0.082 0.102 0.164 0.145 0.005 0.067 0.078 0.024 0.053 0.048 0.018 0.043
  0.164 0.161 0.084 0.088 0.239 0.052 0.247 0.334 0.117 0.045 0.238 0.215
  0.061 0.106 0.022 0.033 0.129 0.081]
 [0.077 0.019 0.096 0.176 0.112 0.006 0.065 0.013 0.049 0.066 0.012 0.018
  0.074 0.184 0.096 0.141 0.237 0.18  0.283 0.224 0.204 0.092 0.272 0.154
  0.092 0.032 0.031 0.011 0.175 0.096]
 [0.085 0.024 0.145 0.166 0.078 0.081 0.005 0.035 0.028 0.081 0.009 0.057
  0.161 0.089 0.051 0.074 0.201 0.185 0.216 0.152 0.084 0.049 0.13  0.267
  0.067 0.088 0.034 0.031 0.118 0.013]
 [0.228 0.184 0.442 0.409 0.271 0.504 0.296 0.005 0.096 0.191 0.015 0.168
  0.241 0.255 0.101 0.251 0.346 0.481 0.698 0.241 0.38  0.168 0.377 0.359
  0.228 0.132 0.056 0.049 0.238 0.224]
 [0.156 0.086 0.183 0.315 0.153 0.146 0.189 0.083 0.003 0.244 0.016 0.041
  0.451 0.151 0.062 0.123 0.371 0.1   0.312 0.434 0.343 0.032 0.355 0.255
  0.056 0.134 0.063 0.019 0.169 0.112]
 [0.055 0.055 0.2   0.21  0.116 0.086 0.077 0.028 0.032 0.007 0.004 0.017
  0.289 0.526 0.046 0.111 0.229 0.09  0.286 0.246 0.157 0.033 0.259 0.239
  0.022 0.047 0.033 0.016 0.121 0.033]
 [0.46  0.295 0.567 0.959 0.458 0.418 0.44  0.353 0.318 1.229 0.005 0.503
  0.457 0.851 0.268 0.508 0.606 0.28  0.918 0.7   0.542 0.316 0.824 0.703
  0.211 0.425 0.151 0.093 0.432 0.295]
 [0.152 0.143 0.146 0.453 0.172 0.309 0.127 0.016 0.108 0.247 0.01  0.005
  0.417 0.169 0.076 0.226 0.253 0.584 0.305 0.212 0.563 0.103 0.488 0.266
  0.052 0.102 0.083 0.021 0.093 0.082]
 [0.026 0.019 0.05  0.091 0.072 0.073 0.034 0.018 0.02  0.023 0.008 0.019
  0.007 0.017 0.019 0.049 0.039 0.068 0.169 0.093 0.173 0.01  0.075 0.117
  0.017 0.021 0.017 0.015 0.018 0.024]
 [0.158 0.058 0.51  0.211 0.043 0.029 0.072 0.034 0.04  0.012 0.006 0.051
  0.167 0.005 0.05  0.305 0.142 0.137 0.415 0.278 0.156 0.025 0.075 0.162
  0.03  0.023 0.017 0.022 0.126 0.065]
 [0.11  0.098 0.173 0.46  0.082 0.116 0.129 0.039 0.098 0.104 0.015 0.088
  0.259 0.179 0.006 0.269 0.304 0.259 0.673 0.226 0.385 0.1   0.278 0.202
  0.085 0.117 0.034 0.113 0.198 0.073]
 [0.137 0.036 0.147 0.297 0.074 0.038 0.085 0.023 0.028 0.042 0.012 0.03
  0.218 0.022 0.021 0.006 0.259 0.044 0.183 0.102 0.349 0.079 0.094 0.213
  0.026 0.06  0.023 0.028 0.091 0.021]
 [0.06  0.028 0.102 0.055 0.029 0.041 0.031 0.017 0.016 0.026 0.008 0.031
  0.166 0.039 0.015 0.02  0.005 0.07  0.362 0.055 0.082 0.016 0.175 0.098
  0.019 0.041 0.013 0.017 0.084 0.021]
 [0.051 0.042 0.055 0.085 0.092 0.038 0.027 0.012 0.065 0.083 0.018 0.009
  0.115 0.048 0.032 0.146 0.107 0.007 0.243 0.196 0.119 0.039 0.082 0.14
  0.028 0.053 0.014 0.014 0.183 0.046]
 [0.009 0.021 0.063 0.042 0.023 0.028 0.027 0.007 0.019 0.017 0.004 0.012
  0.035 0.018 0.008 0.028 0.019 0.022 0.005 0.034 0.041 0.01  0.045 0.025
  0.016 0.027 0.005 0.009 0.023 0.011]
 [0.028 0.028 0.096 0.079 0.027 0.022 0.038 0.018 0.013 0.029 0.006 0.027
  0.082 0.024 0.036 0.061 0.146 0.026 0.149 0.006 0.132 0.011 0.079 0.203
  0.032 0.019 0.013 0.007 0.049 0.016]
 [0.048 0.01  0.109 0.113 0.036 0.031 0.051 0.013 0.024 0.037 0.011 0.01
  0.041 0.029 0.017 0.017 0.083 0.034 0.205 0.039 0.006 0.021 0.057 0.067
  0.023 0.03  0.008 0.032 0.093 0.031]
 [0.284 0.076 0.141 0.266 0.241 0.076 0.154 0.034 0.193 0.205 0.018 0.065
  0.445 0.198 0.065 0.068 0.368 0.148 0.548 0.484 0.303 0.003 0.364 0.331
  0.038 0.14  0.037 0.027 0.234 0.066]
 [0.039 0.025 0.065 0.085 0.033 0.022 0.036 0.013 0.016 0.021 0.005 0.009
  0.153 0.059 0.024 0.063 0.039 0.068 0.116 0.062 0.098 0.018 0.005 0.077
  0.038 0.029 0.005 0.007 0.066 0.02 ]
 [0.05  0.022 0.065 0.069 0.034 0.048 0.032 0.01  0.027 0.03  0.009 0.023
  0.054 0.033 0.027 0.034 0.037 0.049 0.358 0.023 0.072 0.014 0.091 0.003
  0.043 0.024 0.013 0.016 0.059 0.011]
 [0.26  0.118 0.296 0.367 0.093 0.087 0.078 0.025 0.123 0.274 0.033 0.12
  0.283 0.216 0.067 0.336 0.282 0.214 0.406 0.179 0.25  0.166 0.162 0.141
  0.005 0.047 0.038 0.033 0.184 0.132]
 [0.152 0.031 0.214 0.437 0.038 0.249 0.051 0.043 0.049 0.181 0.018 0.064
  0.26  0.153 0.051 0.117 0.274 0.14  0.247 0.449 0.199 0.059 0.292 0.283
  0.092 0.005 0.046 0.022 0.233 0.05 ]
 [0.187 0.188 0.162 0.318 0.241 0.218 0.186 0.107 0.086 0.184 0.022 0.135
  0.43  0.114 0.179 0.235 0.471 0.53  0.972 0.431 0.571 0.274 1.03  0.307
  0.142 0.13  0.006 0.028 0.239 0.133]
 [0.358 0.213 0.186 0.732 0.192 0.312 0.178 0.14  0.187 0.32  0.064 0.3
  0.391 0.237 0.078 0.233 0.383 0.439 0.521 0.51  0.198 0.235 0.565 0.529
  0.163 0.305 0.216 0.005 0.341 0.219]
 [0.092 0.01  0.12  0.12  0.047 0.034 0.072 0.02  0.027 0.053 0.014 0.047
  0.235 0.047 0.041 0.088 0.07  0.037 0.327 0.12  0.066 0.018 0.089 0.131
  0.038 0.04  0.031 0.02  0.005 0.036]
 [0.175 0.175 0.333 0.358 0.082 0.066 0.555 0.037 0.059 0.219 0.016 0.095
  0.372 0.099 0.072 0.273 0.285 0.148 0.487 0.315 0.205 0.103 0.287 0.4
  0.066 0.145 0.052 0.034 0.23  0.006]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.564 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.401 0.    0.    0.307 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.559 0.    0.    0.329
  0.    0.    0.    0.    0.314 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.334 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.442 0.409 0.    0.504 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.346 0.481 0.698 0.    0.38  0.    0.377 0.359
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.315 0.    0.    0.    0.    0.    0.    0.    0.
  0.451 0.    0.    0.    0.371 0.    0.312 0.434 0.343 0.    0.355 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.526 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.46  0.    0.567 0.959 0.458 0.418 0.44  0.353 0.318 1.229 0.    0.503
  0.457 0.851 0.    0.508 0.606 0.    0.918 0.7   0.542 0.316 0.824 0.703
  0.    0.425 0.    0.    0.432 0.   ]
 [0.    0.    0.    0.453 0.    0.309 0.    0.    0.    0.    0.    0.
  0.417 0.    0.    0.    0.    0.584 0.305 0.    0.563 0.    0.488 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.51  0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.305 0.    0.    0.415 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.46  0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.304 0.    0.673 0.    0.385 0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.349 0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.362 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.445 0.    0.    0.    0.368 0.    0.548 0.484 0.303 0.    0.364 0.331
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.358 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.367 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.336 0.    0.    0.406 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.437 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.449 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.318 0.    0.    0.    0.    0.    0.    0.    0.
  0.43  0.    0.    0.    0.471 0.53  0.972 0.431 0.571 0.    1.03  0.307
  0.    0.    0.    0.    0.    0.   ]
 [0.358 0.    0.    0.732 0.    0.312 0.    0.    0.    0.32  0.    0.3
  0.391 0.    0.    0.    0.383 0.439 0.521 0.51  0.    0.    0.565 0.529
  0.    0.305 0.    0.    0.341 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.327 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.333 0.358 0.    0.    0.555 0.    0.    0.    0.    0.
  0.372 0.    0.    0.    0.    0.    0.487 0.315 0.    0.    0.    0.4
  0.    0.    0.    0.    0.    0.   ]]
{'fdr': 0.8301886792452831, 'tpr': 0.2, 'fpr': 0.25507246376811593, 'f1': 0.18367346938775508, 'shd': 157, 'npred': 106, 'ntrue': 90}
[0.035 0.11  0.151 0.099 0.106 0.091 0.042 0.068 0.076 0.014 0.038 0.231
 0.041 0.037 0.064 0.12  0.114 0.564 0.267 0.174 0.025 0.128 0.169 0.028
 0.062 0.036 0.023 0.075 0.042 0.158 0.156 0.401 0.058 0.212 0.307 0.047
 0.07  0.109 0.03  0.055 0.26  0.101 0.047 0.163 0.289 0.19  0.285 0.212
 0.559 0.099 0.254 0.329 0.071 0.161 0.045 0.015 0.314 0.044 0.058 0.045
 0.224 0.048 0.047 0.054 0.017 0.022 0.028 0.01  0.052 0.113 0.01  0.019
 0.052 0.072 0.067 0.104 0.056 0.075 0.04  0.073 0.116 0.027 0.033 0.03
 0.023 0.043 0.023 0.037 0.007 0.035 0.05  0.03  0.04  0.013 0.024 0.025
 0.005 0.014 0.083 0.027 0.011 0.021 0.097 0.074 0.16  0.068 0.057 0.019
 0.105 0.107 0.016 0.011 0.017 0.007 0.042 0.015 0.082 0.102 0.164 0.145
 0.067 0.078 0.024 0.053 0.048 0.018 0.043 0.164 0.161 0.084 0.088 0.239
 0.052 0.247 0.334 0.117 0.045 0.238 0.215 0.061 0.106 0.022 0.033 0.129
 0.081 0.077 0.019 0.096 0.176 0.112 0.065 0.013 0.049 0.066 0.012 0.018
 0.074 0.184 0.096 0.141 0.237 0.18  0.283 0.224 0.204 0.092 0.272 0.154
 0.092 0.032 0.031 0.011 0.175 0.096 0.085 0.024 0.145 0.166 0.078 0.081
 0.035 0.028 0.081 0.009 0.057 0.161 0.089 0.051 0.074 0.201 0.185 0.216
 0.152 0.084 0.049 0.13  0.267 0.067 0.088 0.034 0.031 0.118 0.013 0.228
 0.184 0.442 0.409 0.271 0.504 0.296 0.096 0.191 0.015 0.168 0.241 0.255
 0.101 0.251 0.346 0.481 0.698 0.241 0.38  0.168 0.377 0.359 0.228 0.132
 0.056 0.049 0.238 0.224 0.156 0.086 0.183 0.315 0.153 0.146 0.189 0.083
 0.244 0.016 0.041 0.451 0.151 0.062 0.123 0.371 0.1   0.312 0.434 0.343
 0.032 0.355 0.255 0.056 0.134 0.063 0.019 0.169 0.112 0.055 0.055 0.2
 0.21  0.116 0.086 0.077 0.028 0.032 0.004 0.017 0.289 0.526 0.046 0.111
 0.229 0.09  0.286 0.246 0.157 0.033 0.259 0.239 0.022 0.047 0.033 0.016
 0.121 0.033 0.46  0.295 0.567 0.959 0.458 0.418 0.44  0.353 0.318 1.229
 0.503 0.457 0.851 0.268 0.508 0.606 0.28  0.918 0.7   0.542 0.316 0.824
 0.703 0.211 0.425 0.151 0.093 0.432 0.295 0.152 0.143 0.146 0.453 0.172
 0.309 0.127 0.016 0.108 0.247 0.01  0.417 0.169 0.076 0.226 0.253 0.584
 0.305 0.212 0.563 0.103 0.488 0.266 0.052 0.102 0.083 0.021 0.093 0.082
 0.026 0.019 0.05  0.091 0.072 0.073 0.034 0.018 0.02  0.023 0.008 0.019
 0.017 0.019 0.049 0.039 0.068 0.169 0.093 0.173 0.01  0.075 0.117 0.017
 0.021 0.017 0.015 0.018 0.024 0.158 0.058 0.51  0.211 0.043 0.029 0.072
 0.034 0.04  0.012 0.006 0.051 0.167 0.05  0.305 0.142 0.137 0.415 0.278
 0.156 0.025 0.075 0.162 0.03  0.023 0.017 0.022 0.126 0.065 0.11  0.098
 0.173 0.46  0.082 0.116 0.129 0.039 0.098 0.104 0.015 0.088 0.259 0.179
 0.269 0.304 0.259 0.673 0.226 0.385 0.1   0.278 0.202 0.085 0.117 0.034
 0.113 0.198 0.073 0.137 0.036 0.147 0.297 0.074 0.038 0.085 0.023 0.028
 0.042 0.012 0.03  0.218 0.022 0.021 0.259 0.044 0.183 0.102 0.349 0.079
 0.094 0.213 0.026 0.06  0.023 0.028 0.091 0.021 0.06  0.028 0.102 0.055
 0.029 0.041 0.031 0.017 0.016 0.026 0.008 0.031 0.166 0.039 0.015 0.02
 0.07  0.362 0.055 0.082 0.016 0.175 0.098 0.019 0.041 0.013 0.017 0.084
 0.021 0.051 0.042 0.055 0.085 0.092 0.038 0.027 0.012 0.065 0.083 0.018
 0.009 0.115 0.048 0.032 0.146 0.107 0.243 0.196 0.119 0.039 0.082 0.14
 0.028 0.053 0.014 0.014 0.183 0.046 0.009 0.021 0.063 0.042 0.023 0.028
 0.027 0.007 0.019 0.017 0.004 0.012 0.035 0.018 0.008 0.028 0.019 0.022
 0.034 0.041 0.01  0.045 0.025 0.016 0.027 0.005 0.009 0.023 0.011 0.028
 0.028 0.096 0.079 0.027 0.022 0.038 0.018 0.013 0.029 0.006 0.027 0.082
 0.024 0.036 0.061 0.146 0.026 0.149 0.132 0.011 0.079 0.203 0.032 0.019
 0.013 0.007 0.049 0.016 0.048 0.01  0.109 0.113 0.036 0.031 0.051 0.013
 0.024 0.037 0.011 0.01  0.041 0.029 0.017 0.017 0.083 0.034 0.205 0.039
 0.021 0.057 0.067 0.023 0.03  0.008 0.032 0.093 0.031 0.284 0.076 0.141
 0.266 0.241 0.076 0.154 0.034 0.193 0.205 0.018 0.065 0.445 0.198 0.065
 0.068 0.368 0.148 0.548 0.484 0.303 0.364 0.331 0.038 0.14  0.037 0.027
 0.234 0.066 0.039 0.025 0.065 0.085 0.033 0.022 0.036 0.013 0.016 0.021
 0.005 0.009 0.153 0.059 0.024 0.063 0.039 0.068 0.116 0.062 0.098 0.018
 0.077 0.038 0.029 0.005 0.007 0.066 0.02  0.05  0.022 0.065 0.069 0.034
 0.048 0.032 0.01  0.027 0.03  0.009 0.023 0.054 0.033 0.027 0.034 0.037
 0.049 0.358 0.023 0.072 0.014 0.091 0.043 0.024 0.013 0.016 0.059 0.011
 0.26  0.118 0.296 0.367 0.093 0.087 0.078 0.025 0.123 0.274 0.033 0.12
 0.283 0.216 0.067 0.336 0.282 0.214 0.406 0.179 0.25  0.166 0.162 0.141
 0.047 0.038 0.033 0.184 0.132 0.152 0.031 0.214 0.437 0.038 0.249 0.051
 0.043 0.049 0.181 0.018 0.064 0.26  0.153 0.051 0.117 0.274 0.14  0.247
 0.449 0.199 0.059 0.292 0.283 0.092 0.046 0.022 0.233 0.05  0.187 0.188
 0.162 0.318 0.241 0.218 0.186 0.107 0.086 0.184 0.022 0.135 0.43  0.114
 0.179 0.235 0.471 0.53  0.972 0.431 0.571 0.274 1.03  0.307 0.142 0.13
 0.028 0.239 0.133 0.358 0.213 0.186 0.732 0.192 0.312 0.178 0.14  0.187
 0.32  0.064 0.3   0.391 0.237 0.078 0.233 0.383 0.439 0.521 0.51  0.198
 0.235 0.565 0.529 0.163 0.305 0.216 0.341 0.219 0.092 0.01  0.12  0.12
 0.047 0.034 0.072 0.02  0.027 0.053 0.014 0.047 0.235 0.047 0.041 0.088
 0.07  0.037 0.327 0.12  0.066 0.018 0.089 0.131 0.038 0.04  0.031 0.02
 0.036 0.175 0.175 0.333 0.358 0.082 0.066 0.555 0.037 0.059 0.219 0.016
 0.095 0.372 0.099 0.072 0.273 0.285 0.148 0.487 0.315 0.205 0.103 0.287
 0.4   0.066 0.145 0.052 0.034 0.23 ]
[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 1. 0. 0. 1. 0.]
 [1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
  0. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 0. 1. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0.]
aucroc, aucpr (0.6335185185185186, 0.18955998657639506)
Iterations 2250
Achieves (3.524517146579602, 1e-05)-DP
