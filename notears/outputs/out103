samples  5000  graph  10 20 ER mim  minibatch size  100  noise  0.8  minibatches per NN training  63 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.2478778610411254
iteration 1 in outer loop, alpha = 1.2478778610411254, rho = 1.0, h = 1.2478778610411254
cuda
iteration 1 in inner loop,alpha 1.2478778610411254 rho 1.0 h 0.8084888745241194
iteration 2 in inner loop,alpha 1.2478778610411254 rho 10.0 h 0.33057833071344156
iteration 3 in inner loop,alpha 1.2478778610411254 rho 100.0 h 0.08917599829296385
iteration 2 in outer loop, alpha = 10.16547769033751, rho = 100.0, h = 0.08917599829296385
cuda
iteration 1 in inner loop,alpha 10.16547769033751 rho 100.0 h 0.04477612329798397
iteration 2 in inner loop,alpha 10.16547769033751 rho 1000.0 h 0.01475614729775998
iteration 3 in outer loop, alpha = 24.92162498809749, rho = 1000.0, h = 0.01475614729775998
cuda
iteration 1 in inner loop,alpha 24.92162498809749 rho 1000.0 h 0.006747604373583016
iteration 2 in inner loop,alpha 24.92162498809749 rho 10000.0 h 0.0009845269108446075
iteration 4 in outer loop, alpha = 34.76689409654357, rho = 10000.0, h = 0.0009845269108446075
cuda
iteration 1 in inner loop,alpha 34.76689409654357 rho 10000.0 h 0.0006367139972880409
iteration 2 in inner loop,alpha 34.76689409654357 rho 100000.0 h 0.0002659665090032348
iteration 5 in outer loop, alpha = 300.7334030997784, rho = 1000000.0, h = 0.0002659665090032348
Threshold 0.3
[[0.006 0.    0.    0.    0.497 0.    0.08  0.    0.    1.78 ]
 [2.764 0.006 0.577 0.    0.104 0.003 1.103 0.004 0.    0.993]
 [0.294 0.005 0.007 0.    0.075 0.004 1.208 0.011 0.    0.21 ]
 [1.782 2.985 1.099 0.    0.008 2.619 0.198 2.692 0.003 0.151]
 [0.    0.    0.001 0.    0.005 0.    0.002 0.    0.    0.002]
 [0.388 0.281 0.722 0.    0.043 0.005 0.959 1.04  0.004 0.132]
 [0.009 0.001 0.002 0.    0.983 0.001 0.005 0.001 0.    0.019]
 [0.247 0.252 0.02  0.    0.007 0.001 0.236 0.002 0.008 0.036]
 [0.247 2.116 0.013 0.008 1.483 0.074 0.527 0.043 0.    0.041]
 [0.001 0.    0.002 0.    0.89  0.    0.055 0.001 0.    0.005]]
[[0.    0.    0.    0.    0.497 0.    0.    0.    0.    1.78 ]
 [2.764 0.    0.577 0.    0.    0.    1.103 0.    0.    0.993]
 [0.    0.    0.    0.    0.    0.    1.208 0.    0.    0.   ]
 [1.782 2.985 1.099 0.    0.    2.619 0.    2.692 0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.388 0.    0.722 0.    0.    0.    0.959 1.04  0.    0.   ]
 [0.    0.    0.    0.    0.983 0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    2.116 0.    0.    1.483 0.    0.527 0.    0.    0.   ]
 [0.    0.    0.    0.    0.89  0.    0.    0.    0.    0.   ]]
{'fdr': 0.09523809523809523, 'tpr': 0.95, 'fpr': 0.08, 'f1': 0.9268292682926829, 'shd': 2, 'npred': 21, 'ntrue': 20}
[2.171e-04 2.542e-04 2.300e-05 4.968e-01 3.873e-04 7.987e-02 4.451e-04
 4.830e-06 1.780e+00 2.764e+00 5.767e-01 7.075e-06 1.041e-01 3.219e-03
 1.103e+00 3.582e-03 3.383e-05 9.934e-01 2.938e-01 5.236e-03 3.577e-05
 7.537e-02 3.724e-03 1.208e+00 1.112e-02 1.032e-04 2.100e-01 1.782e+00
 2.985e+00 1.099e+00 7.782e-03 2.619e+00 1.983e-01 2.692e+00 3.356e-03
 1.509e-01 1.818e-04 1.041e-04 9.311e-04 5.426e-06 4.511e-04 1.769e-03
 4.062e-04 1.140e-05 1.845e-03 3.883e-01 2.813e-01 7.218e-01 1.448e-05
 4.333e-02 9.593e-01 1.040e+00 4.466e-03 1.322e-01 8.833e-03 1.071e-03
 1.816e-03 1.383e-05 9.827e-01 7.567e-04 9.749e-04 7.131e-05 1.913e-02
 2.470e-01 2.522e-01 2.039e-02 5.639e-06 6.898e-03 1.284e-03 2.361e-01
 7.577e-03 3.593e-02 2.469e-01 2.116e+00 1.302e-02 7.793e-03 1.483e+00
 7.386e-02 5.273e-01 4.265e-02 4.053e-02 9.944e-04 1.665e-04 2.056e-03
 6.416e-06 8.901e-01 3.087e-04 5.540e-02 6.418e-04 8.262e-06]
[[0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 1. 1. 0. 0. 1. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9657142857142857, 0.9419402177200167)
cuda
1210
cuda
Objective function 188.58 = squared loss an data 11.52 + 0.5*rho*h**2 176.710652 + alpha*h 0.000000 + L2reg 0.19 + L1reg 0.16 ; SHD = 55 ; DAG False
||w||^2 0.12283652427655815
exp ma of ||w||^2 494.1380795426504
||w|| 0.35048041924843415
exp ma of ||w|| 0.2834647161523668
||w||^2 0.2818430451719615
exp ma of ||w||^2 0.150250387535103
||w|| 0.5308889198052277
exp ma of ||w|| 0.37339644301694924
||w||^2 0.3680931613760078
exp ma of ||w||^2 0.3714544096875068
||w|| 0.6067068166553
exp ma of ||w|| 0.5785502503679898
cuda
Objective function 9.00 = squared loss an data 8.56 + 0.5*rho*h**2 0.296651 + alpha*h 0.000000 + L2reg 0.08 + L1reg 0.07 ; SHD = 26 ; DAG False
Proportion of microbatches that were clipped  0.7422532973144764
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 0.7702611669637349
iteration 1 in outer loop, alpha = 0.7702611669637349, rho = 1.0, h = 0.7702611669637349
cuda
1210
cuda
Objective function 9.60 = squared loss an data 8.56 + 0.5*rho*h**2 0.296651 + alpha*h 0.593302 + L2reg 0.08 + L1reg 0.07 ; SHD = 26 ; DAG False
||w||^2 1.311051777553392
exp ma of ||w||^2 351.53533799684897
||w|| 1.1450116931950487
exp ma of ||w|| 3.8110299461687274
||w||^2 0.05076114540790232
exp ma of ||w||^2 1.4966179982464507
||w|| 0.22530234221574866
exp ma of ||w|| 0.29616229051557347
||w||^2 0.03506652228919646
exp ma of ||w||^2 0.08126642623387292
||w|| 0.18726057323739148
exp ma of ||w|| 0.271809132683756
||w||^2 0.23385674430552195
exp ma of ||w||^2 0.15406874362132272
||w|| 0.4835873698780004
exp ma of ||w|| 0.3719349848501723
||w||^2 0.07296491946100533
exp ma of ||w||^2 0.15390024416602338
||w|| 0.27012019447091573
exp ma of ||w|| 0.3726090114762586
cuda
Objective function 8.75 = squared loss an data 7.97 + 0.5*rho*h**2 0.152371 + alpha*h 0.425211 + L2reg 0.13 + L1reg 0.07 ; SHD = 21 ; DAG False
Proportion of microbatches that were clipped  0.7275085102934025
iteration 1 in inner loop, alpha 0.7702611669637349 rho 1.0 h 0.5520349693117801
1210
cuda
Objective function 10.12 = squared loss an data 7.97 + 0.5*rho*h**2 1.523713 + alpha*h 0.425211 + L2reg 0.13 + L1reg 0.07 ; SHD = 21 ; DAG False
||w||^2 49648639.7637278
exp ma of ||w||^2 259873222.1303034
||w|| 7046.179089671778
exp ma of ||w|| 14178.732405460152
||w||^2 11725277.695807742
exp ma of ||w||^2 36664965.803516194
||w|| 3424.219282669809
exp ma of ||w|| 5053.992695905175
||w||^2 4.793304765764589
exp ma of ||w||^2 5439.120550129388
||w|| 2.189361725655354
exp ma of ||w|| 29.165651026120745
||w||^2 0.049778790481093564
exp ma of ||w||^2 1.5278555637702684
||w|| 0.22311160991999848
exp ma of ||w|| 0.2877257143986931
||w||^2 0.05913283244821332
exp ma of ||w||^2 0.08007414531708991
||w|| 0.2431724335697065
exp ma of ||w|| 0.26728241420112014
||w||^2 0.09820113726415983
exp ma of ||w||^2 0.1685084085298133
||w|| 0.31337060689247775
exp ma of ||w|| 0.3898464909673414
||w||^2 0.3518097227802419
exp ma of ||w||^2 0.21579825397151822
||w|| 0.5931355011970215
exp ma of ||w|| 0.43701227328466236
||w||^2 0.5565408955604365
exp ma of ||w||^2 0.22969022820321744
||w|| 0.7460166858458572
exp ma of ||w|| 0.455992796413757
||w||^2 0.2668668682382028
exp ma of ||w||^2 0.23426210108054696
||w|| 0.5165915874636392
exp ma of ||w|| 0.45653266819969207
||w||^2 0.059127671769231616
exp ma of ||w||^2 0.2816111340339565
||w|| 0.24316182218685484
exp ma of ||w|| 0.4983156455577546
cuda
Objective function 8.61 = squared loss an data 7.98 + 0.5*rho*h**2 0.242397 + alpha*h 0.169597 + L2reg 0.17 + L1reg 0.06 ; SHD = 14 ; DAG True
Proportion of microbatches that were clipped  0.7336596147773918
iteration 2 in inner loop, alpha 0.7702611669637349 rho 10.0 h 0.22018055930747238
1210
cuda
Objective function 10.80 = squared loss an data 7.98 + 0.5*rho*h**2 2.423974 + alpha*h 0.169597 + L2reg 0.17 + L1reg 0.06 ; SHD = 14 ; DAG True
||w||^2 411872037.76200855
exp ma of ||w||^2 2376300511.644136
||w|| 20294.630761903714
exp ma of ||w|| 43065.51611896315
||w||^2 22939222.322692428
exp ma of ||w||^2 157183543.920579
||w|| 4789.490820817222
exp ma of ||w|| 10864.963726888696
||w||^2 16457.827413108782
exp ma of ||w||^2 228088.2064265004
||w|| 128.28806418801705
exp ma of ||w|| 306.09338851468635
||w||^2 0.06627075012959815
exp ma of ||w||^2 0.9609361133194402
||w|| 0.2574310589839504
exp ma of ||w|| 0.30555185346768027
||w||^2 0.050778963985725976
exp ma of ||w||^2 0.15584506055472966
||w|| 0.22534188244914877
exp ma of ||w|| 0.3677013363180732
||w||^2 0.14026513280726155
exp ma of ||w||^2 0.20772639985518346
||w|| 0.3745198697095543
exp ma of ||w|| 0.431174998356622
||w||^2 0.3055246533174831
exp ma of ||w||^2 0.30040579072878826
||w|| 0.5527428455597441
exp ma of ||w|| 0.5172502536631421
cuda
Objective function 8.79 = squared loss an data 8.32 + 0.5*rho*h**2 0.179070 + alpha*h 0.046096 + L2reg 0.20 + L1reg 0.05 ; SHD = 13 ; DAG True
Proportion of microbatches that were clipped  0.738258164852255
iteration 3 in inner loop, alpha 0.7702611669637349 rho 100.0 h 0.059844783879178465
iteration 2 in outer loop, alpha = 6.754739554881581, rho = 100.0, h = 0.059844783879178465
cuda
1210
cuda
Objective function 9.15 = squared loss an data 8.32 + 0.5*rho*h**2 0.179070 + alpha*h 0.404236 + L2reg 0.20 + L1reg 0.05 ; SHD = 13 ; DAG True
||w||^2 2172454255.2961392
exp ma of ||w||^2 2055160601.8686893
||w|| 46609.59402629612
exp ma of ||w|| 41654.870142816224
||w||^2 70257087.31526259
exp ma of ||w||^2 339654877.22547394
||w|| 8381.9500902393
exp ma of ||w|| 15865.512112870561
||w||^2 24659912.905671418
exp ma of ||w||^2 250765991.2270625
||w|| 4965.874837898295
exp ma of ||w|| 13559.751034289673
||w||^2 12008718.523832126
exp ma of ||w||^2 43775010.22224452
||w|| 3465.3597971685604
exp ma of ||w|| 5505.833611311696
||w||^2 0.06725616674810492
exp ma of ||w||^2 3.2171753278283486
||w|| 0.2593379392763522
exp ma of ||w|| 0.37143770946005966
v before min max tensor([[ 8.488e+00,  9.185e-01, -1.529e+00,  5.033e-01,  3.544e+00,  9.008e-01,
         -8.878e-01,  2.454e+00, -3.215e-01,  2.705e+00],
        [-2.960e+00,  1.437e+01,  3.930e-01, -1.478e-01, -2.101e+00,  7.621e-01,
         -1.858e+00,  2.537e+00,  3.522e+00, -2.348e+00],
        [ 1.637e+00,  3.479e-01, -1.962e+00, -8.326e-01,  1.816e+00, -2.395e-01,
         -2.255e+00, -1.364e+00, -4.117e-01, -2.131e+00],
        [-9.577e-01, -3.463e-01, -3.766e-02,  9.318e-01, -2.497e+00, -1.457e+00,
          7.714e-02,  1.748e+00, -1.271e+00,  1.178e+01],
        [ 1.473e+01,  3.464e+01, -8.019e-01, -1.424e+00,  3.246e-01,  3.773e+00,
         -4.221e-01, -1.473e+00,  6.560e-01, -2.113e+00],
        [ 1.956e+01,  1.714e+01, -8.275e-01, -1.953e+00, -2.393e+00, -1.505e+00,
         -1.666e-01, -2.205e+00,  1.373e-01, -8.585e-01],
        [ 3.899e+00, -2.373e+00,  6.290e+00, -1.070e+00, -1.190e+00, -2.589e+00,
         -3.478e-01,  3.447e+00, -1.213e-01,  2.995e+00],
        [-2.734e+00,  1.299e+00,  3.031e+00, -1.059e+00,  1.378e+01,  1.443e+01,
          4.325e+00, -2.052e+00, -1.863e+00,  7.744e+00],
        [ 2.921e+01, -1.563e+00, -1.124e+00, -2.827e+00,  1.352e+01, -2.286e+00,
         -1.214e+00, -1.843e+00, -2.018e+00, -3.180e-01],
        [ 2.546e-01,  2.448e+01, -1.379e+00, -1.648e+00, -1.917e+00, -9.291e-01,
          2.649e+00, -2.238e+00,  6.711e+00, -5.255e-01],
        [-1.249e+00, -5.135e-01, -2.855e+00, -7.310e-01,  5.347e-02, -1.861e+00,
          5.512e-01, -2.922e+00, -5.349e-01, -1.225e+00],
        [-1.242e+00, -2.232e+00, -1.308e+00,  6.441e+00,  2.661e+01, -1.262e+00,
          6.540e-01,  5.236e-01,  5.331e-03, -6.212e-01],
        [ 2.837e+00,  3.710e+01, -1.889e+00, -2.989e-01, -3.203e-01, -1.216e+00,
         -6.433e-01, -1.746e+00, -1.636e+00,  9.746e-01],
        [ 4.022e+00, -2.476e+00,  2.335e+00, -1.172e+00,  1.313e+01, -1.177e+00,
          1.229e+00,  2.751e+00, -1.575e+00,  1.119e+00],
        [-9.337e-01,  3.778e+01,  2.071e+00,  3.726e+00, -1.236e+00,  3.286e+00,
         -1.789e+00, -4.729e-01, -1.762e+00,  7.497e+00],
        [ 2.753e+00,  1.630e+01, -1.651e+00,  5.599e+00,  1.596e+01,  1.225e+00,
         -4.752e-01, -1.931e+00, -2.096e+00, -2.598e+00],
        [ 9.133e+00,  1.706e+01,  1.083e+01, -3.095e-01,  6.508e-01,  1.700e+00,
          8.308e+00,  8.506e+00,  3.856e-01,  9.385e+00],
        [-1.717e+00,  9.631e-02,  2.806e+00, -7.336e-01,  6.409e+00, -2.103e+00,
         -2.399e+00,  5.085e+00, -7.338e-01, -1.246e+00],
        [ 1.092e+00,  1.565e-01, -2.800e+00, -3.523e-03,  1.427e+01, -1.301e+00,
         -1.846e+00, -1.905e+00,  1.086e+01,  3.805e+00],
        [ 8.348e+00, -1.484e+00, -4.141e-01,  1.817e+01,  9.032e-01,  6.479e+00,
         -2.320e+00,  5.858e-01,  1.918e+00, -6.003e-01],
        [ 3.161e+00, -1.408e+00,  2.238e+00, -1.129e+00, -2.788e-01, -9.640e-01,
         -2.253e+00,  1.372e+01,  2.583e-01, -1.681e+00],
        [-1.951e+00,  9.296e-01,  1.463e+01, -1.468e+00,  8.419e+00,  2.972e-01,
          2.944e+00, -2.004e+00, -7.619e-01,  3.376e+01],
        [-3.370e-01,  2.352e+00,  1.449e+01,  9.922e+00,  2.794e+00,  5.158e+00,
         -2.074e+00,  3.393e+00, -7.301e-01, -2.965e-01],
        [-1.526e+00,  6.114e+00,  1.282e+02,  6.572e+00,  1.354e+01,  5.005e+00,
          3.546e+00, -8.970e-01,  9.696e-01,  7.003e+00],
        [ 5.013e-01, -2.824e+00,  3.200e+01,  1.811e+00,  2.160e+00, -2.016e+00,
          6.276e-01,  9.659e-02, -1.260e+00, -4.880e-01],
        [ 4.724e+00,  4.976e+00, -1.404e-02,  6.968e+00, -2.053e+00,  1.076e+01,
          4.699e-01, -8.085e-02,  4.635e-01, -1.789e+00],
        [ 9.805e+00, -5.009e-01,  1.620e+00, -2.612e+00,  2.099e+01,  4.988e-01,
         -1.319e+00, -6.762e-01, -1.717e+00, -2.481e+00],
        [ 1.869e-01, -2.054e+00,  3.801e+01, -1.479e+00, -1.190e+00, -8.744e-01,
          1.759e+00, -1.895e+00, -2.287e+00, -7.423e-01],
        [-1.653e+00, -1.124e+00, -1.655e+00, -1.624e+00, -2.456e-01,  5.688e+00,
          1.009e+01,  5.893e-01,  1.424e+00, -2.843e+00],
        [-2.399e-01, -1.760e+00,  7.838e-01,  1.367e+01, -1.687e+00, -1.188e+00,
         -9.920e-01, -2.751e-01, -1.352e+00, -1.521e+00],
        [ 4.377e+00,  3.415e+00,  2.574e+00,  2.516e+01,  4.465e+00, -1.203e+00,
         -6.642e-01,  2.374e+01, -6.504e-02,  9.696e-01],
        [ 9.450e+00, -1.929e+00,  7.607e+00,  1.037e+00,  1.632e+01,  2.185e+01,
          4.068e+01,  4.324e+00,  2.623e+00, -1.019e+00],
        [-2.167e+00,  1.983e+00, -5.373e-01,  1.472e+01,  1.130e+00,  6.070e+00,
          2.759e-01, -1.378e-01,  4.504e+00,  1.118e+00],
        [-1.709e+00, -1.262e+00, -1.707e+00,  2.473e+01, -1.151e+00, -2.192e+00,
          1.023e+01, -1.828e+00,  1.386e-01, -1.416e+00],
        [-1.751e+00, -1.273e+00,  4.512e+00,  1.253e-01,  5.293e-02, -1.375e+00,
         -1.690e+00,  4.371e+00,  3.207e-01, -1.884e-01],
        [-4.716e-02,  5.571e+00,  2.855e+00,  2.006e+00,  5.434e+01,  3.961e+00,
         -1.823e-01,  2.940e+00, -1.383e+00, -2.153e+00],
        [-8.430e-01,  3.350e+00,  3.049e+01, -3.037e+00, -2.805e+00,  4.578e+01,
          8.092e-01, -1.279e+00, -1.429e-02,  1.821e-01],
        [ 1.040e+01, -2.639e+00,  1.145e+01,  3.753e+00, -2.499e+00, -1.520e+00,
         -1.496e+00, -2.171e+00,  7.814e+00,  5.433e-01],
        [-2.122e+00,  2.105e+00,  3.124e+00,  2.809e+01, -2.470e+00, -1.112e+00,
         -9.397e-01, -1.222e+00,  2.666e+00,  2.655e+00],
        [ 4.147e+00,  2.010e+01,  2.046e+01, -1.548e+00, -5.685e-02,  3.331e+00,
          4.189e+00, -2.776e+00,  2.552e+00, -2.628e+00],
        [-1.793e+00, -1.246e+00, -7.793e-01, -1.150e+00,  8.189e+00,  5.836e+00,
         -8.362e-02, -1.634e-01,  1.225e+00, -1.611e+00],
        [ 5.310e+00, -2.281e+00, -4.635e-02,  3.426e+00,  9.864e+01,  2.109e+00,
          3.670e+00, -1.883e+00, -1.322e+00, -1.312e+00],
        [ 9.039e-01,  3.600e+00, -1.305e+00,  9.414e-01,  3.707e+01, -2.000e+00,
         -4.815e-01, -2.510e+00,  2.460e-01,  2.273e+00],
        [ 6.525e+00, -8.193e-01, -1.426e+00, -2.285e+00,  2.708e+01,  3.990e+00,
         -8.870e-01, -2.242e+00,  3.155e-01,  8.604e+00],
        [-9.053e-01, -1.233e+00,  7.114e-01,  5.511e+00,  3.858e+00, -1.797e+00,
          6.109e+00, -6.763e-01, -2.288e+00, -6.185e-01],
        [-1.507e+00,  2.520e+00, -2.182e+00, -1.763e+00,  1.182e+00,  1.197e+00,
          2.113e+00,  7.033e+00,  5.617e-01,  1.248e+00],
        [ 5.933e+00, -2.219e+00, -1.708e+00, -1.963e+00,  1.378e+01, -2.892e+00,
         -3.941e-01, -4.845e-01,  1.395e+00,  6.929e+00],
        [-2.639e+00, -6.728e-01, -1.314e-02, -1.247e-01, -2.150e+00,  3.943e-02,
          2.392e-01, -2.349e+00,  9.241e-01,  2.880e+00],
        [-1.637e+00, -2.004e+00, -1.065e+00, -2.251e+00,  1.159e+00,  4.874e-01,
         -1.174e+00, -5.741e-01, -6.070e-01,  9.940e+00],
        [-4.993e-01, -4.929e-01, -2.311e+00, -8.450e-01,  8.759e+00, -2.072e+00,
         -1.318e+00,  8.277e+00, -1.120e+00, -2.156e+00],
        [-2.202e+00,  6.684e-03, -1.953e+00,  9.037e+00,  9.491e-01,  3.059e+00,
         -2.281e+00, -2.339e+00, -2.867e-01,  2.246e-01],
        [-3.754e-01, -2.405e-01,  2.507e+01,  1.140e+01,  1.086e+01, -2.369e+00,
          5.481e-01, -1.824e+00, -2.396e-01, -1.439e+00],
        [ 1.648e-01,  5.883e+00, -1.907e+00, -1.823e+00,  2.032e+00,  4.821e+00,
         -8.066e-03, -8.261e-01, -1.558e+00, -7.104e-01],
        [-1.952e+00, -2.508e-01,  3.393e+00, -1.763e+00,  1.742e+01,  9.543e+00,
         -2.477e+00, -6.509e-01, -1.301e+00,  1.841e+00],
        [-1.719e-01,  4.226e+00,  1.189e-01,  2.265e+00,  3.012e+00, -2.410e+00,
         -1.285e+00,  4.333e-01, -2.076e-01, -8.907e-01],
        [-2.249e+00, -1.921e+00,  3.636e+00,  2.747e+00,  1.362e-01,  2.101e+01,
         -2.210e+00, -1.203e+00,  1.432e+00,  1.396e+01],
        [-8.708e-01,  1.957e+00,  3.108e+00, -1.663e+00,  5.492e-02,  4.304e+01,
         -2.309e+00,  1.633e+01, -9.002e-01, -1.505e+00],
        [ 1.061e-02, -9.174e-01,  2.154e+01,  4.237e+00, -1.009e+00,  1.107e+01,
          2.455e+00,  2.602e+00, -5.818e-01, -1.540e+00],
        [-2.332e+00,  7.535e+00,  1.733e+00,  8.441e-01,  1.578e-02,  1.366e+01,
         -2.751e+00,  1.222e+00,  1.713e+01,  3.753e+00],
        [-6.678e-01,  5.084e-01,  1.567e+00, -1.893e-01,  2.296e+00,  9.195e+00,
          4.296e+00,  4.060e+00, -2.193e+00,  3.103e+00],
        [ 2.054e+00,  1.677e-01, -1.362e-01,  1.394e+00,  2.052e+00, -1.976e-01,
          1.828e+00, -1.315e+00,  1.426e+01,  2.089e+00],
        [-4.544e-02, -2.304e-01,  1.162e+01,  6.250e+00,  5.165e+00,  6.628e-01,
          7.832e+00, -1.569e+00,  9.117e-01,  8.864e+00],
        [-3.262e-01, -6.953e-01, -2.524e+00, -1.277e+00,  5.042e+00, -1.577e+00,
          6.422e+01, -8.313e-01,  6.237e+00,  5.706e+00],
        [-3.072e+00,  9.275e-01, -3.830e-01,  1.130e+00, -1.369e+00, -7.097e-01,
          1.407e+00, -1.481e+00,  9.866e-01,  3.479e+00],
        [-3.756e-01,  7.205e-02,  9.968e-01, -1.640e+00,  3.887e+00, -1.620e+00,
          1.297e+01, -2.398e+00, -9.929e-01,  4.432e+00],
        [-2.095e+00, -2.240e+00, -5.845e-01, -5.190e-02, -3.289e+00,  3.203e+00,
          9.639e+01,  1.897e+01,  6.299e-01, -3.878e-01],
        [-1.726e+00, -1.001e+00,  4.752e+00,  8.446e+00,  8.532e+00,  3.149e+00,
         -1.403e+00, -1.595e+00, -2.171e+00, -1.697e+00],
        [-7.696e-01, -8.767e-01, -1.412e+00,  3.577e+00, -5.444e-01,  7.275e-01,
          6.820e+00, -1.632e+00, -7.022e-01,  1.419e+01],
        [ 6.067e-01,  3.986e+00, -1.708e+00,  7.114e+00,  3.693e+00,  1.196e+01,
         -1.949e+00,  3.476e+00, -1.905e+00,  3.080e+00],
        [-1.038e+00, -6.713e-01, -2.131e+00, -1.769e+00, -1.676e+00,  8.857e+00,
          3.998e+01, -2.689e+00, -1.084e+00,  1.196e+00],
        [-1.045e+00,  5.989e+00,  3.410e+00, -6.267e-02, -7.602e-02,  2.719e+01,
          4.630e-02,  9.401e+00, -1.702e+00, -1.733e+00],
        [ 2.556e-02, -1.274e+00,  2.203e+00, -1.955e+00, -1.817e+00,  4.920e+00,
          4.193e+00,  1.047e+01,  6.919e+00, -1.839e+00],
        [-1.149e+00, -1.652e+00,  2.468e+00, -1.122e+00, -2.079e+00, -1.871e+00,
          9.599e+00,  2.096e+00,  3.115e+00, -4.592e-01],
        [-2.871e+00, -1.064e+00, -1.719e+00,  1.378e+00,  1.094e+00, -1.135e+00,
          1.103e+00,  1.709e+01,  3.882e+00, -2.485e+00],
        [-2.996e-01,  1.359e+00, -2.251e+00, -1.687e+00,  5.281e-01,  6.636e+00,
         -5.035e-01, -2.514e+00, -2.583e+00,  3.993e+00],
        [-2.790e+00, -1.461e+00,  7.199e+00,  4.774e-01,  7.271e-01,  1.748e+01,
          5.026e+00,  3.930e+01, -2.645e+00, -3.575e-02],
        [-1.117e+00, -2.390e+00,  2.378e+00, -8.086e-01,  2.895e+00, -2.467e+00,
          2.258e+00,  1.941e-01,  1.072e+00,  1.096e+00],
        [-1.732e+00, -5.847e-01, -2.268e+00, -1.706e+00, -1.934e+00, -8.011e-01,
          1.558e+00,  4.893e+00,  2.101e-01, -1.759e-01],
        [-6.248e-01, -2.062e+00, -2.005e+00, -1.756e+00, -2.368e+00,  7.631e+00,
         -6.902e-01, -3.432e-01,  6.712e+00, -4.745e-01],
        [-2.394e+00, -9.282e-01, -2.561e-01,  1.491e+01, -4.728e-01, -2.643e+00,
          2.038e-01,  8.004e+01,  4.043e+00, -2.067e+00],
        [ 4.112e-01, -2.643e+00, -3.471e-01, -1.004e+00,  2.661e+00,  2.545e+00,
         -8.599e-01, -1.322e+00, -2.306e+00,  6.113e+00],
        [ 9.891e+00,  1.695e+02, -2.886e+00, -1.248e+00, -2.735e+00,  3.052e+00,
         -1.435e+00,  1.192e+00, -5.965e-01,  6.153e-01],
        [ 3.400e+00,  3.261e+01, -2.017e+00,  2.669e+00,  1.094e+01,  9.462e+00,
          9.115e+00,  1.746e+00,  1.618e+01,  3.470e+00],
        [ 1.986e+01, -1.945e+00, -5.886e-01,  9.389e+00,  1.163e+01, -1.848e+00,
         -1.793e+00,  2.702e+00,  1.119e+01, -2.738e+00],
        [-2.372e+00,  4.765e+01, -2.114e+00,  4.360e+00, -1.931e+00, -2.451e+00,
         -3.004e-01, -2.634e+00,  1.504e+01, -6.644e-01],
        [-1.395e+00,  1.097e+01, -2.176e+00, -5.120e-01,  8.071e-01, -4.540e-01,
         -2.094e+00,  1.602e+00,  4.740e+01,  1.490e+01],
        [ 3.326e+00,  3.340e+00,  2.834e+01, -9.495e-01,  1.999e+01,  5.203e-01,
         -1.044e-01, -2.167e+00, -1.766e+00,  5.447e+00],
        [ 5.785e+00,  2.534e+01, -1.794e+00,  6.804e+00,  3.605e+00,  2.616e+00,
         -1.260e+00,  1.283e+01,  2.727e+01,  4.274e+00],
        [-2.141e+00,  2.470e+00, -1.256e+00, -1.173e+00,  2.123e+00,  3.296e+01,
          1.294e+01,  1.500e+00, -2.887e+00,  4.719e-01],
        [-8.042e-01,  5.170e+00,  3.978e+00, -9.462e-01,  1.254e+01, -5.164e-01,
          6.620e+00, -2.780e+00,  6.572e+00, -3.788e-01],
        [-2.000e+00,  1.018e+01, -2.096e+00, -2.347e+00,  5.040e-01,  3.789e+00,
          1.335e+00,  1.374e+00, -1.544e+00, -4.548e-01],
        [-2.598e+00, -1.652e+00, -1.527e+00,  6.086e-01,  1.459e+01,  2.961e+00,
         -9.870e-01, -2.318e+00, -1.903e+00,  5.888e+01],
        [-5.585e-01, -1.926e+00,  4.907e+00, -6.751e-01, -4.637e-01, -1.750e-01,
         -1.032e+00, -2.145e+00,  1.185e+01, -9.672e-01],
        [-1.523e+00,  3.900e+00, -1.752e+00,  3.663e+00,  8.252e-01, -9.375e-01,
          2.651e+00, -1.142e+00,  1.179e+01,  5.612e+00],
        [ 1.505e+00,  3.551e+00, -1.268e+00,  7.813e+00,  1.717e-01, -1.208e+00,
         -1.352e+00,  3.439e+00, -1.127e+00, -1.486e+00],
        [ 1.657e+00,  3.866e+01, -1.118e+00, -1.068e+00, -2.111e+00,  1.875e+00,
         -5.872e-01, -1.598e+00,  4.256e-01,  1.234e+00],
        [ 1.276e+01, -9.836e-01,  2.626e+00,  1.194e+00, -9.406e-01, -1.910e+00,
          1.487e+01, -7.536e-01,  8.397e-02,  4.582e+00],
        [-1.940e+00,  8.667e-01, -1.684e+00, -1.336e+00,  3.386e-01,  1.859e+01,
          9.402e+00, -1.402e+00,  1.929e+00,  5.778e+00],
        [ 1.539e+00,  3.837e+00, -1.485e+00,  4.201e-01, -1.606e+00, -1.843e+00,
          1.526e+01,  1.823e+00,  1.186e+00, -4.603e-01],
        [-1.506e+00, -1.470e+00,  8.302e-01,  2.473e+00,  2.808e+00,  3.747e+00,
         -1.744e+00, -1.037e-01, -2.537e+00,  3.508e+01]], device='cuda:0')
v tensor([[8.488e+00, 9.185e-01, 1.000e-12, 5.033e-01, 3.544e+00, 9.008e-01,
         1.000e-12, 2.454e+00, 1.000e-12, 2.705e+00],
        [1.000e-12, 1.000e+01, 3.930e-01, 1.000e-12, 1.000e-12, 7.621e-01,
         1.000e-12, 2.537e+00, 3.522e+00, 1.000e-12],
        [1.637e+00, 3.479e-01, 1.000e-12, 1.000e-12, 1.816e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 9.318e-01, 1.000e-12, 1.000e-12,
         7.714e-02, 1.748e+00, 1.000e-12, 1.000e+01],
        [1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 3.246e-01, 3.773e+00,
         1.000e-12, 1.000e-12, 6.560e-01, 1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.373e-01, 1.000e-12],
        [3.899e+00, 1.000e-12, 6.290e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 3.447e+00, 1.000e-12, 2.995e+00],
        [1.000e-12, 1.299e+00, 3.031e+00, 1.000e-12, 1.000e+01, 1.000e+01,
         4.325e+00, 1.000e-12, 1.000e-12, 7.744e+00],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [2.546e-01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         2.649e+00, 1.000e-12, 6.711e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.347e-02, 1.000e-12,
         5.512e-01, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 6.441e+00, 1.000e+01, 1.000e-12,
         6.540e-01, 5.236e-01, 5.331e-03, 1.000e-12],
        [2.837e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 9.746e-01],
        [4.022e+00, 1.000e-12, 2.335e+00, 1.000e-12, 1.000e+01, 1.000e-12,
         1.229e+00, 2.751e+00, 1.000e-12, 1.119e+00],
        [1.000e-12, 1.000e+01, 2.071e+00, 3.726e+00, 1.000e-12, 3.286e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 7.497e+00],
        [2.753e+00, 1.000e+01, 1.000e-12, 5.599e+00, 1.000e+01, 1.225e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [9.133e+00, 1.000e+01, 1.000e+01, 1.000e-12, 6.508e-01, 1.700e+00,
         8.308e+00, 8.506e+00, 3.856e-01, 9.385e+00],
        [1.000e-12, 9.631e-02, 2.806e+00, 1.000e-12, 6.409e+00, 1.000e-12,
         1.000e-12, 5.085e+00, 1.000e-12, 1.000e-12],
        [1.092e+00, 1.565e-01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e+01, 3.805e+00],
        [8.348e+00, 1.000e-12, 1.000e-12, 1.000e+01, 9.032e-01, 6.479e+00,
         1.000e-12, 5.858e-01, 1.918e+00, 1.000e-12],
        [3.161e+00, 1.000e-12, 2.238e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e+01, 2.583e-01, 1.000e-12],
        [1.000e-12, 9.296e-01, 1.000e+01, 1.000e-12, 8.419e+00, 2.972e-01,
         2.944e+00, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e-12, 2.352e+00, 1.000e+01, 9.922e+00, 2.794e+00, 5.158e+00,
         1.000e-12, 3.393e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 6.114e+00, 1.000e+01, 6.572e+00, 1.000e+01, 5.005e+00,
         3.546e+00, 1.000e-12, 9.696e-01, 7.003e+00],
        [5.013e-01, 1.000e-12, 1.000e+01, 1.811e+00, 2.160e+00, 1.000e-12,
         6.276e-01, 9.659e-02, 1.000e-12, 1.000e-12],
        [4.724e+00, 4.976e+00, 1.000e-12, 6.968e+00, 1.000e-12, 1.000e+01,
         4.699e-01, 1.000e-12, 4.635e-01, 1.000e-12],
        [9.805e+00, 1.000e-12, 1.620e+00, 1.000e-12, 1.000e+01, 4.988e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.869e-01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.759e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.688e+00,
         1.000e+01, 5.893e-01, 1.424e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 7.838e-01, 1.000e+01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [4.377e+00, 3.415e+00, 2.574e+00, 1.000e+01, 4.465e+00, 1.000e-12,
         1.000e-12, 1.000e+01, 1.000e-12, 9.696e-01],
        [9.450e+00, 1.000e-12, 7.607e+00, 1.037e+00, 1.000e+01, 1.000e+01,
         1.000e+01, 4.324e+00, 2.623e+00, 1.000e-12],
        [1.000e-12, 1.983e+00, 1.000e-12, 1.000e+01, 1.130e+00, 6.070e+00,
         2.759e-01, 1.000e-12, 4.504e+00, 1.118e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e-12, 1.386e-01, 1.000e-12],
        [1.000e-12, 1.000e-12, 4.512e+00, 1.253e-01, 5.293e-02, 1.000e-12,
         1.000e-12, 4.371e+00, 3.207e-01, 1.000e-12],
        [1.000e-12, 5.571e+00, 2.855e+00, 2.006e+00, 1.000e+01, 3.961e+00,
         1.000e-12, 2.940e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 3.350e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
         8.092e-01, 1.000e-12, 1.000e-12, 1.821e-01],
        [1.000e+01, 1.000e-12, 1.000e+01, 3.753e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 7.814e+00, 5.433e-01],
        [1.000e-12, 2.105e+00, 3.124e+00, 1.000e+01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 2.666e+00, 2.655e+00],
        [4.147e+00, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 3.331e+00,
         4.189e+00, 1.000e-12, 2.552e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 8.189e+00, 5.836e+00,
         1.000e-12, 1.000e-12, 1.225e+00, 1.000e-12],
        [5.310e+00, 1.000e-12, 1.000e-12, 3.426e+00, 1.000e+01, 2.109e+00,
         3.670e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [9.039e-01, 3.600e+00, 1.000e-12, 9.414e-01, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 2.460e-01, 2.273e+00],
        [6.525e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 3.990e+00,
         1.000e-12, 1.000e-12, 3.155e-01, 8.604e+00],
        [1.000e-12, 1.000e-12, 7.114e-01, 5.511e+00, 3.858e+00, 1.000e-12,
         6.109e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 2.520e+00, 1.000e-12, 1.000e-12, 1.182e+00, 1.197e+00,
         2.113e+00, 7.033e+00, 5.617e-01, 1.248e+00],
        [5.933e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.395e+00, 6.929e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.943e-02,
         2.392e-01, 1.000e-12, 9.241e-01, 2.880e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.159e+00, 4.874e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 9.940e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 8.759e+00, 1.000e-12,
         1.000e-12, 8.277e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 6.684e-03, 1.000e-12, 9.037e+00, 9.491e-01, 3.059e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 2.246e-01],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
         5.481e-01, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.648e-01, 5.883e+00, 1.000e-12, 1.000e-12, 2.032e+00, 4.821e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 3.393e+00, 1.000e-12, 1.000e+01, 9.543e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.841e+00],
        [1.000e-12, 4.226e+00, 1.189e-01, 2.265e+00, 3.012e+00, 1.000e-12,
         1.000e-12, 4.333e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 3.636e+00, 2.747e+00, 1.362e-01, 1.000e+01,
         1.000e-12, 1.000e-12, 1.432e+00, 1.000e+01],
        [1.000e-12, 1.957e+00, 3.108e+00, 1.000e-12, 5.492e-02, 1.000e+01,
         1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.061e-02, 1.000e-12, 1.000e+01, 4.237e+00, 1.000e-12, 1.000e+01,
         2.455e+00, 2.602e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 7.535e+00, 1.733e+00, 8.441e-01, 1.578e-02, 1.000e+01,
         1.000e-12, 1.222e+00, 1.000e+01, 3.753e+00],
        [1.000e-12, 5.084e-01, 1.567e+00, 1.000e-12, 2.296e+00, 9.195e+00,
         4.296e+00, 4.060e+00, 1.000e-12, 3.103e+00],
        [2.054e+00, 1.677e-01, 1.000e-12, 1.394e+00, 2.052e+00, 1.000e-12,
         1.828e+00, 1.000e-12, 1.000e+01, 2.089e+00],
        [1.000e-12, 1.000e-12, 1.000e+01, 6.250e+00, 5.165e+00, 6.628e-01,
         7.832e+00, 1.000e-12, 9.117e-01, 8.864e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.042e+00, 1.000e-12,
         1.000e+01, 1.000e-12, 6.237e+00, 5.706e+00],
        [1.000e-12, 9.275e-01, 1.000e-12, 1.130e+00, 1.000e-12, 1.000e-12,
         1.407e+00, 1.000e-12, 9.866e-01, 3.479e+00],
        [1.000e-12, 7.205e-02, 9.968e-01, 1.000e-12, 3.887e+00, 1.000e-12,
         1.000e+01, 1.000e-12, 1.000e-12, 4.432e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.203e+00,
         1.000e+01, 1.000e+01, 6.299e-01, 1.000e-12],
        [1.000e-12, 1.000e-12, 4.752e+00, 8.446e+00, 8.532e+00, 3.149e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 3.577e+00, 1.000e-12, 7.275e-01,
         6.820e+00, 1.000e-12, 1.000e-12, 1.000e+01],
        [6.067e-01, 3.986e+00, 1.000e-12, 7.114e+00, 3.693e+00, 1.000e+01,
         1.000e-12, 3.476e+00, 1.000e-12, 3.080e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 8.857e+00,
         1.000e+01, 1.000e-12, 1.000e-12, 1.196e+00],
        [1.000e-12, 5.989e+00, 3.410e+00, 1.000e-12, 1.000e-12, 1.000e+01,
         4.630e-02, 9.401e+00, 1.000e-12, 1.000e-12],
        [2.556e-02, 1.000e-12, 2.203e+00, 1.000e-12, 1.000e-12, 4.920e+00,
         4.193e+00, 1.000e+01, 6.919e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 2.468e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         9.599e+00, 2.096e+00, 3.115e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.378e+00, 1.094e+00, 1.000e-12,
         1.103e+00, 1.000e+01, 3.882e+00, 1.000e-12],
        [1.000e-12, 1.359e+00, 1.000e-12, 1.000e-12, 5.281e-01, 6.636e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 3.993e+00],
        [1.000e-12, 1.000e-12, 7.199e+00, 4.774e-01, 7.271e-01, 1.000e+01,
         5.026e+00, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 2.378e+00, 1.000e-12, 2.895e+00, 1.000e-12,
         2.258e+00, 1.941e-01, 1.072e+00, 1.096e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.558e+00, 4.893e+00, 2.101e-01, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 7.631e+00,
         1.000e-12, 1.000e-12, 6.712e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
         2.038e-01, 1.000e+01, 4.043e+00, 1.000e-12],
        [4.112e-01, 1.000e-12, 1.000e-12, 1.000e-12, 2.661e+00, 2.545e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 6.113e+00],
        [9.891e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 3.052e+00,
         1.000e-12, 1.192e+00, 1.000e-12, 6.153e-01],
        [3.400e+00, 1.000e+01, 1.000e-12, 2.669e+00, 1.000e+01, 9.462e+00,
         9.115e+00, 1.746e+00, 1.000e+01, 3.470e+00],
        [1.000e+01, 1.000e-12, 1.000e-12, 9.389e+00, 1.000e+01, 1.000e-12,
         1.000e-12, 2.702e+00, 1.000e+01, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12, 4.360e+00, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 8.071e-01, 1.000e-12,
         1.000e-12, 1.602e+00, 1.000e+01, 1.000e+01],
        [3.326e+00, 3.340e+00, 1.000e+01, 1.000e-12, 1.000e+01, 5.203e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 5.447e+00],
        [5.785e+00, 1.000e+01, 1.000e-12, 6.804e+00, 3.605e+00, 2.616e+00,
         1.000e-12, 1.000e+01, 1.000e+01, 4.274e+00],
        [1.000e-12, 2.470e+00, 1.000e-12, 1.000e-12, 2.123e+00, 1.000e+01,
         1.000e+01, 1.500e+00, 1.000e-12, 4.719e-01],
        [1.000e-12, 5.170e+00, 3.978e+00, 1.000e-12, 1.000e+01, 1.000e-12,
         6.620e+00, 1.000e-12, 6.572e+00, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 5.040e-01, 3.789e+00,
         1.335e+00, 1.374e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 6.086e-01, 1.000e+01, 2.961e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e-12, 1.000e-12, 4.907e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12],
        [1.000e-12, 3.900e+00, 1.000e-12, 3.663e+00, 8.252e-01, 1.000e-12,
         2.651e+00, 1.000e-12, 1.000e+01, 5.612e+00],
        [1.505e+00, 3.551e+00, 1.000e-12, 7.813e+00, 1.717e-01, 1.000e-12,
         1.000e-12, 3.439e+00, 1.000e-12, 1.000e-12],
        [1.657e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.875e+00,
         1.000e-12, 1.000e-12, 4.256e-01, 1.234e+00],
        [1.000e+01, 1.000e-12, 2.626e+00, 1.194e+00, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e-12, 8.397e-02, 4.582e+00],
        [1.000e-12, 8.667e-01, 1.000e-12, 1.000e-12, 3.386e-01, 1.000e+01,
         9.402e+00, 1.000e-12, 1.929e+00, 5.778e+00],
        [1.539e+00, 3.837e+00, 1.000e-12, 4.201e-01, 1.000e-12, 1.000e-12,
         1.000e+01, 1.823e+00, 1.186e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 8.302e-01, 2.473e+00, 2.808e+00, 3.747e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01]], device='cuda:0')
v before min max tensor([-2.247, -1.228,  7.490, -0.951,  1.341, -1.200,  0.651, -0.815,  5.505,
        -1.473, -1.550, 11.850, -1.434, -0.265, -2.105, -1.222,  0.936, -0.364,
        -0.633, -0.907,  4.045,  1.554, -0.247, -2.915, -2.261,  0.425, -1.231,
         0.417, -1.637,  2.989, -2.321, -1.602, -1.298, -2.334,  0.182,  0.612,
         1.502,  2.727, 12.230, -0.970, -0.522, -0.822, -0.515,  0.382, -2.450,
        35.814, -0.839, -0.694, -1.383, -0.886,  2.969, -0.251, -0.844, -0.176,
        -2.216, -1.958,  0.338, -1.448,  6.309, -1.421, -0.542,  0.998, -1.811,
        10.842, -3.184,  6.326,  0.832,  1.636, -1.308,  8.884, -2.018, -1.403,
        -0.337, -2.501,  0.523, -1.152, -1.736,  1.899, 15.268, -1.334, -0.686,
        -1.406, -0.455, -0.467,  0.393, -1.269,  0.741, -1.061, -1.187,  0.387,
        11.844,  2.579, -1.250,  0.400, -1.599,  5.440,  9.654,  1.448,  1.559,
         3.367], device='cuda:0')
v tensor([1.000e-12, 1.000e-12, 7.490e+00, 1.000e-12, 1.341e+00, 1.000e-12,
        6.514e-01, 1.000e-12, 5.505e+00, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 9.355e-01, 1.000e-12,
        1.000e-12, 1.000e-12, 4.045e+00, 1.554e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 4.254e-01, 1.000e-12, 4.172e-01, 1.000e-12, 2.989e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.817e-01, 6.118e-01,
        1.502e+00, 2.727e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 3.817e-01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 2.969e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 3.381e-01, 1.000e-12, 6.309e+00, 1.000e-12,
        1.000e-12, 9.982e-01, 1.000e-12, 1.000e+01, 1.000e-12, 6.326e+00,
        8.321e-01, 1.636e+00, 1.000e-12, 8.884e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 5.234e-01, 1.000e-12, 1.000e-12, 1.899e+00,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        3.933e-01, 1.000e-12, 7.408e-01, 1.000e-12, 1.000e-12, 3.871e-01,
        1.000e+01, 2.579e+00, 1.000e-12, 4.001e-01, 1.000e-12, 5.440e+00,
        9.654e+00, 1.448e+00, 1.559e+00, 3.367e+00], device='cuda:0')
v before min max tensor([[[ 1.267e+00],
         [-1.954e+00],
         [ 1.409e+01],
         [-2.599e+00],
         [ 1.974e+00],
         [ 8.340e+00],
         [ 6.936e+00],
         [ 3.074e+00],
         [ 2.106e+00],
         [ 7.069e+00]],

        [[ 1.462e+01],
         [-1.054e+00],
         [-1.318e+00],
         [ 4.823e+00],
         [-1.890e+00],
         [ 1.917e+01],
         [ 2.419e+01],
         [ 1.445e+01],
         [ 1.556e+00],
         [-2.856e+00]],

        [[-2.166e+00],
         [-1.166e+00],
         [ 2.763e+01],
         [ 9.519e-01],
         [-1.325e+00],
         [ 2.460e+01],
         [-1.732e+00],
         [ 3.541e+00],
         [-1.941e+00],
         [-2.610e+00]],

        [[ 4.739e+00],
         [ 1.559e+00],
         [-1.958e+00],
         [ 3.356e-01],
         [-4.072e-01],
         [-1.487e+00],
         [ 1.149e+00],
         [-9.644e-01],
         [ 5.396e+00],
         [ 1.717e+01]],

        [[-1.862e+00],
         [ 3.885e+00],
         [-2.256e+00],
         [-2.365e+00],
         [-1.776e+00],
         [ 6.451e+00],
         [-1.871e+00],
         [ 2.329e-01],
         [-1.376e+00],
         [-1.435e+00]],

        [[-2.557e+00],
         [ 3.940e+00],
         [ 1.040e+00],
         [ 4.223e+00],
         [-1.499e+00],
         [ 5.996e+00],
         [-1.561e+00],
         [-1.704e+00],
         [ 4.397e+00],
         [ 9.876e+00]],

        [[-7.030e-01],
         [-2.548e-02],
         [ 2.872e+00],
         [-2.180e+00],
         [-2.233e+00],
         [-1.645e+00],
         [-2.451e+00],
         [-9.764e-01],
         [-1.585e+00],
         [ 1.509e+01]],

        [[ 9.744e+00],
         [ 1.482e+01],
         [-2.721e+00],
         [ 1.451e+00],
         [-2.259e+00],
         [ 1.130e+01],
         [ 4.085e-01],
         [ 3.717e+00],
         [ 1.744e+00],
         [ 3.912e+00]],

        [[ 4.471e-01],
         [ 1.636e-02],
         [ 4.605e+00],
         [ 2.072e-01],
         [-2.465e+00],
         [-1.096e-01],
         [-1.130e+00],
         [ 7.832e-01],
         [ 6.180e-02],
         [-1.869e+00]],

        [[ 1.769e+01],
         [-3.097e-01],
         [ 1.276e+01],
         [ 1.492e+00],
         [-3.053e+00],
         [ 1.296e+01],
         [ 5.719e+00],
         [ 2.041e+01],
         [ 7.849e+00],
         [ 2.042e+01]]], device='cuda:0')
v tensor([[[1.267e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.974e+00],
         [8.340e+00],
         [6.936e+00],
         [3.074e+00],
         [2.106e+00],
         [7.069e+00]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [4.823e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.556e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [9.519e-01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [3.541e+00],
         [1.000e-12],
         [1.000e-12]],

        [[4.739e+00],
         [1.559e+00],
         [1.000e-12],
         [3.356e-01],
         [1.000e-12],
         [1.000e-12],
         [1.149e+00],
         [1.000e-12],
         [5.396e+00],
         [1.000e+01]],

        [[1.000e-12],
         [3.885e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.451e+00],
         [1.000e-12],
         [2.329e-01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [3.940e+00],
         [1.040e+00],
         [4.223e+00],
         [1.000e-12],
         [5.996e+00],
         [1.000e-12],
         [1.000e-12],
         [4.397e+00],
         [9.876e+00]],

        [[1.000e-12],
         [1.000e-12],
         [2.872e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[9.744e+00],
         [1.000e+01],
         [1.000e-12],
         [1.451e+00],
         [1.000e-12],
         [1.000e+01],
         [4.085e-01],
         [3.717e+00],
         [1.744e+00],
         [3.912e+00]],

        [[4.471e-01],
         [1.636e-02],
         [4.605e+00],
         [2.072e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.832e-01],
         [6.180e-02],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.492e+00],
         [1.000e-12],
         [1.000e+01],
         [5.719e+00],
         [1.000e+01],
         [7.849e+00],
         [1.000e+01]]], device='cuda:0')
v before min max tensor([[ 0.678],
        [16.131],
        [-0.249],
        [-0.801],
        [-2.805],
        [ 2.667],
        [-2.327],
        [ 1.824],
        [ 8.420],
        [71.913]], device='cuda:0')
v tensor([[6.783e-01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [2.667e+00],
        [1.000e-12],
        [1.824e+00],
        [8.420e+00],
        [1.000e+01]], device='cuda:0')
a after update for 1 param tensor([[-5.953e-03, -6.554e-03, -4.568e-02, -4.197e-03, -1.041e-02,  4.666e-03,
         -4.014e-02,  1.917e-02,  2.675e-03, -2.505e-02],
        [-2.541e-03,  2.591e-02, -1.668e-02,  2.002e-03, -7.709e-03, -5.358e-03,
          1.198e-02, -2.766e-02, -8.352e-03,  3.756e-03],
        [ 8.706e-03, -1.210e-03, -1.563e-02, -5.908e-03,  4.435e-03,  3.862e-03,
         -2.278e-02,  3.494e-02,  1.046e-02,  2.982e-03],
        [-1.139e-02,  1.851e-03,  2.290e-03,  4.058e-03,  1.081e-02,  1.880e-04,
          7.515e-03, -3.262e-03,  1.477e-02,  4.791e-03],
        [ 1.385e-02, -3.987e-02,  9.147e-03,  5.570e-03, -8.897e-03, -2.967e-03,
         -2.602e-02,  1.498e-02,  3.800e-03, -6.922e-03],
        [ 1.104e-02,  1.476e-02,  1.873e-02,  3.254e-02, -1.042e-02, -3.928e-03,
         -1.213e-03, -5.605e-03,  1.801e-02, -6.038e-03],
        [-3.952e-02, -2.016e-02,  3.778e-03,  5.971e-03, -2.448e-02, -1.722e-02,
         -8.554e-03, -5.557e-04,  5.582e-03,  2.549e-03],
        [ 2.856e-02, -1.680e-02,  6.125e-03, -2.499e-03, -1.540e-02,  9.078e-03,
          8.038e-03,  1.287e-03, -9.468e-03,  1.028e-03],
        [-3.107e-03, -1.056e-02,  1.147e-02, -2.785e-02,  1.655e-02,  1.543e-02,
         -6.218e-03,  2.130e-03, -6.105e-03, -8.987e-03],
        [ 1.672e-02,  6.585e-03,  1.067e-02, -1.723e-02,  3.076e-03,  1.114e-02,
         -2.068e-03, -3.657e-02,  3.159e-03, -1.276e-02],
        [ 8.958e-03, -2.929e-02,  5.015e-02, -8.828e-04,  6.449e-03, -3.611e-02,
          2.903e-03,  1.620e-02, -8.754e-03,  1.282e-02],
        [-1.467e-03,  4.750e-04,  5.017e-03,  2.807e-02, -7.155e-03, -5.736e-03,
         -3.610e-02,  1.966e-02,  2.762e-02,  5.620e-03],
        [ 1.789e-02, -1.335e-02,  1.135e-02, -4.593e-04,  1.365e-02,  2.242e-03,
         -1.312e-02,  1.286e-02, -5.381e-03,  8.815e-04],
        [ 1.460e-03, -2.121e-02,  1.208e-02, -3.903e-03, -8.686e-03,  2.098e-04,
          2.978e-03,  8.363e-03, -8.332e-03,  1.650e-02],
        [-7.117e-03, -9.062e-03,  7.835e-03,  2.585e-02,  4.083e-04, -4.110e-04,
         -1.603e-02, -2.345e-03,  1.990e-02, -1.862e-02],
        [-1.135e-03,  5.053e-03, -4.905e-03,  9.949e-03,  9.166e-03,  2.078e-02,
          5.330e-04,  1.074e-02,  6.975e-04, -6.324e-03],
        [ 1.003e-02, -7.698e-03,  1.920e-03, -9.129e-03,  8.354e-04, -3.785e-04,
          1.347e-02,  5.132e-03, -1.364e-02, -7.736e-03],
        [-6.619e-04, -3.292e-04, -9.316e-03,  1.087e-02,  1.684e-02, -1.820e-03,
          9.794e-03,  1.215e-02,  2.998e-03, -1.524e-02],
        [ 1.288e-02,  1.524e-02, -1.125e-04, -6.076e-04, -1.843e-02,  9.386e-03,
         -1.223e-02, -4.870e-02,  3.241e-02,  1.107e-02],
        [-5.201e-03,  1.779e-02, -1.855e-03,  6.367e-03, -1.126e-03,  1.855e-02,
         -3.331e-02,  4.260e-03, -1.359e-02,  3.021e-03],
        [-5.638e-03, -2.746e-05, -2.556e-03, -1.433e-02, -9.975e-04, -1.033e-02,
         -5.961e-03,  3.595e-02,  2.623e-02,  1.021e-04],
        [-2.999e-02,  5.740e-03,  3.555e-04,  1.321e-02, -1.624e-02, -1.050e-03,
          2.745e-03,  1.530e-03,  2.249e-04, -2.359e-02],
        [-5.803e-03,  1.163e-02,  2.664e-03, -4.894e-03, -1.378e-02,  1.089e-03,
         -1.787e-02,  1.285e-03,  1.173e-02,  4.643e-04],
        [ 1.080e-02,  5.663e-03, -2.157e-02, -1.348e-02,  9.436e-03, -7.169e-03,
          6.815e-03, -3.215e-02, -9.159e-03,  7.712e-03],
        [ 4.441e-03, -2.623e-02, -1.460e-02,  2.395e-03,  3.977e-03,  1.854e-02,
         -3.205e-03,  4.257e-03,  5.212e-03, -1.504e-02],
        [-2.023e-03,  1.098e-02,  1.264e-03,  3.118e-02, -4.550e-03, -5.147e-03,
         -4.966e-03, -1.085e-03,  3.799e-03,  7.653e-03],
        [ 1.121e-02,  4.184e-03,  8.168e-03,  7.817e-04,  9.022e-03,  6.793e-03,
         -4.037e-03,  3.649e-04,  2.576e-02, -1.151e-03],
        [-3.351e-02,  3.092e-02,  2.218e-02,  1.073e-02,  1.581e-02,  3.014e-03,
          8.540e-03, -8.409e-03,  2.842e-02,  2.898e-02],
        [ 4.708e-03, -5.160e-03, -9.161e-03, -2.631e-02,  2.748e-03,  6.189e-03,
         -1.513e-02, -6.426e-03,  1.548e-03,  1.388e-02],
        [ 1.201e-04,  9.493e-03, -4.700e-02,  1.337e-02,  2.424e-02, -3.175e-03,
         -1.121e-02, -2.883e-03, -1.195e-02, -2.031e-02],
        [ 7.590e-04, -7.900e-03, -2.085e-02, -1.920e-02,  1.510e-02,  2.420e-03,
         -1.281e-02, -9.077e-03, -1.521e-02, -4.961e-03],
        [ 4.355e-03,  6.485e-03, -4.868e-03, -2.962e-03, -6.305e-03, -8.086e-03,
         -2.801e-02, -2.062e-02, -4.622e-03, -7.820e-04],
        [-1.014e-02,  1.863e-02, -9.055e-03, -6.867e-03, -3.938e-04, -1.782e-02,
         -1.651e-02, -2.134e-03,  9.951e-03, -1.481e-03],
        [-5.324e-03,  2.541e-02, -3.799e-03,  1.347e-02, -5.577e-03,  3.113e-02,
          9.800e-03,  9.074e-03,  8.030e-03, -6.234e-03],
        [-2.494e-03,  1.183e-02, -1.484e-02,  5.424e-03, -1.184e-02, -9.677e-03,
         -2.446e-02, -1.739e-02, -4.604e-02, -4.615e-03],
        [ 4.749e-02, -3.967e-03,  4.133e-03, -1.962e-04,  2.156e-02, -3.731e-03,
          5.963e-04, -4.353e-03, -6.157e-03, -2.235e-02],
        [ 2.800e-04, -1.342e-02,  4.669e-02, -5.999e-03,  1.283e-02,  6.150e-04,
          3.309e-02, -2.968e-03,  3.825e-02, -1.603e-02],
        [-8.528e-03, -2.342e-02,  4.610e-02,  4.884e-03,  1.123e-02,  1.273e-02,
         -8.027e-04,  1.008e-02, -7.753e-03, -1.737e-02],
        [-8.412e-03, -8.526e-03,  5.866e-03,  8.739e-03,  3.896e-02,  9.946e-03,
          2.854e-03,  1.920e-03, -1.894e-02,  3.256e-03],
        [ 8.943e-03, -7.937e-03, -1.436e-03,  1.635e-02,  2.428e-04, -1.312e-02,
         -1.218e-04, -2.803e-02,  2.394e-02,  1.168e-03],
        [-1.421e-02,  2.108e-03, -1.353e-02, -2.291e-03,  3.234e-02, -1.761e-02,
          9.313e-03, -1.677e-02,  1.793e-02,  3.450e-02],
        [-3.858e-03,  1.167e-03,  5.855e-03,  1.262e-02,  1.930e-03, -2.290e-02,
         -7.342e-04,  3.668e-02,  3.406e-03, -4.862e-03],
        [ 2.504e-03, -1.950e-02,  2.727e-03, -1.698e-03,  2.139e-03,  5.280e-02,
          1.029e-03, -4.679e-03, -5.446e-03,  2.212e-03],
        [ 8.351e-03, -4.077e-03,  2.842e-02, -2.134e-03,  1.177e-02,  6.908e-04,
          7.942e-02,  1.227e-03,  4.514e-03, -5.232e-03],
        [ 1.869e-02,  1.220e-03, -1.465e-02,  1.425e-02, -8.008e-03,  4.784e-03,
         -1.630e-02,  1.190e-02,  1.182e-02, -1.167e-02],
        [-2.908e-02,  7.146e-03, -2.579e-03, -2.151e-02, -3.512e-03,  8.519e-03,
         -1.341e-02,  7.807e-03,  2.750e-02,  1.477e-03],
        [-2.817e-02,  1.922e-02,  3.054e-04,  4.670e-03,  1.072e-02, -5.099e-03,
         -1.651e-02, -3.698e-03,  5.859e-03, -6.037e-03],
        [ 3.380e-02,  2.452e-04,  1.935e-03,  1.297e-02, -1.462e-02, -1.185e-03,
         -4.400e-03, -1.203e-02, -1.643e-02, -4.354e-04],
        [-1.835e-02,  3.085e-02,  2.219e-02, -2.357e-03, -1.381e-02, -4.265e-03,
         -1.935e-02,  1.492e-02, -3.100e-02, -8.184e-03],
        [-5.900e-03,  8.583e-03,  3.119e-02, -3.936e-03,  3.975e-03, -3.809e-02,
         -5.907e-03, -4.370e-03,  6.010e-03, -1.595e-02],
        [-6.337e-03, -2.813e-04,  9.510e-03, -2.483e-02,  5.462e-03, -1.698e-02,
         -5.598e-03,  3.114e-02, -1.971e-03,  2.277e-04],
        [ 2.172e-03, -1.818e-02,  7.599e-02, -3.520e-02, -8.928e-03, -5.164e-03,
          6.821e-03, -2.261e-02, -2.803e-04,  1.198e-02],
        [-1.121e-02, -2.221e-02,  1.818e-02,  2.728e-02, -1.509e-02, -4.051e-04,
         -1.313e-02,  7.104e-03, -1.803e-02,  1.051e-02],
        [-1.583e-02, -3.667e-02,  3.232e-03,  1.465e-02,  8.187e-03,  5.779e-03,
         -7.931e-03,  1.537e-02, -3.328e-03, -2.139e-02],
        [-2.299e-02,  1.358e-02, -1.082e-02,  3.082e-04, -1.312e-02, -6.596e-03,
         -2.096e-02,  1.359e-02,  2.892e-03, -3.095e-03],
        [-1.295e-02, -7.339e-03, -2.479e-02, -4.701e-02,  3.936e-03, -2.390e-04,
         -6.071e-02, -1.880e-02,  1.127e-02,  6.719e-02],
        [ 5.619e-03,  8.214e-03, -1.664e-02, -1.173e-02,  5.182e-03,  1.325e-02,
         -1.137e-02, -5.404e-03, -1.348e-02,  2.510e-02],
        [-1.271e-03,  2.050e-03,  2.044e-02, -3.980e-03, -8.047e-03, -2.529e-02,
          1.201e-02, -8.139e-03, -8.175e-03,  1.794e-02],
        [-2.706e-02, -2.925e-02, -1.389e-02, -4.416e-03, -2.030e-02,  1.331e-03,
          1.317e-02, -8.056e-03,  4.039e-03,  6.496e-03],
        [-6.217e-03,  7.485e-03, -1.248e-04, -1.737e-03, -1.807e-03, -7.369e-03,
         -1.332e-02,  6.325e-03,  2.732e-02, -1.337e-02],
        [-3.396e-03, -4.838e-03, -1.739e-03,  4.180e-03, -1.402e-02,  1.381e-02,
          1.369e-02, -1.569e-02, -1.068e-02, -4.233e-02],
        [ 1.607e-03,  1.128e-02, -1.267e-02,  9.776e-03, -4.237e-03, -2.007e-03,
          7.385e-03, -3.061e-02, -7.942e-03,  1.848e-02],
        [ 7.503e-03, -7.686e-03, -4.421e-02,  1.063e-02,  1.933e-02, -8.319e-03,
         -4.192e-03, -2.842e-02, -2.372e-02, -6.176e-03],
        [ 2.114e-02,  2.217e-02,  9.023e-03, -2.982e-03,  1.447e-02, -3.643e-04,
          5.922e-03,  9.951e-03, -2.585e-02, -6.745e-03],
        [ 2.541e-03, -6.166e-03,  2.858e-03, -1.321e-02,  7.742e-03, -1.204e-02,
         -1.571e-02, -1.509e-02, -1.337e-04,  6.918e-03],
        [ 7.966e-03, -1.627e-03,  4.231e-03,  3.953e-03,  8.221e-03,  7.287e-03,
          2.254e-03, -2.990e-03,  1.889e-02,  1.799e-02],
        [-9.275e-03,  7.383e-03, -7.476e-03, -4.019e-03, -3.039e-04, -2.151e-02,
          5.366e-05,  3.597e-02,  2.094e-02, -2.358e-02],
        [ 1.117e-02,  1.382e-02,  5.500e-02,  3.378e-02, -4.711e-03, -2.700e-03,
          1.289e-02, -1.349e-03,  2.619e-03, -8.801e-03],
        [ 8.655e-04,  1.097e-02, -1.805e-02, -2.085e-02,  2.337e-03,  8.080e-03,
         -3.552e-03, -4.357e-02, -5.527e-03,  4.738e-03],
        [ 2.405e-03, -1.457e-02,  8.872e-03,  2.772e-03,  3.075e-04,  1.398e-02,
         -8.995e-03, -2.867e-03,  2.515e-03, -1.263e-02],
        [ 9.776e-03,  3.147e-03, -1.542e-02, -1.922e-02, -2.148e-03,  4.117e-02,
          8.640e-04,  1.112e-02, -7.295e-03, -2.303e-02],
        [ 2.899e-03, -1.733e-02, -1.351e-02,  2.152e-03, -8.404e-04, -5.983e-04,
          9.654e-03, -2.011e-03,  2.354e-02, -1.982e-02],
        [-9.059e-03, -1.594e-02, -4.330e-03, -1.871e-02,  5.539e-04,  4.553e-03,
          2.600e-02, -1.844e-03, -3.599e-02, -2.776e-04],
        [ 3.427e-03, -2.669e-03, -3.448e-02, -8.316e-03,  4.272e-03,  1.367e-02,
          2.500e-03,  8.683e-03,  1.244e-02, -1.328e-02],
        [ 1.764e-02, -2.954e-02, -7.198e-03, -8.381e-03,  1.082e-02,  4.251e-04,
         -7.006e-03, -1.078e-02, -5.820e-03,  1.578e-03],
        [ 4.790e-03,  1.324e-02,  2.942e-02, -3.609e-03,  2.292e-03,  1.732e-02,
          2.041e-02,  2.103e-02,  4.879e-03,  5.759e-03],
        [-4.837e-03,  3.788e-02, -5.515e-03,  1.290e-02, -3.889e-03, -3.427e-03,
          2.181e-03,  4.345e-03,  1.255e-02,  2.196e-02],
        [-1.574e-02,  2.777e-02, -2.357e-03,  7.039e-03,  1.509e-02, -3.243e-02,
         -6.107e-05,  1.632e-02, -1.527e-03, -3.529e-03],
        [ 3.131e-04,  5.027e-03,  5.880e-03,  4.113e-03, -1.146e-02,  1.515e-02,
         -2.050e-02, -3.468e-03,  1.151e-02,  2.151e-03],
        [-2.654e-02, -6.064e-03,  3.750e-04,  1.175e-02, -4.646e-03, -9.540e-03,
          2.254e-02,  8.612e-03, -9.091e-04, -2.170e-02],
        [-2.151e-02,  1.388e-02, -3.802e-04,  8.663e-03,  9.075e-03, -2.947e-03,
         -9.618e-03, -2.154e-04, -9.551e-04,  3.833e-03],
        [ 9.252e-03,  5.519e-03,  1.817e-04,  4.330e-03,  1.781e-04,  2.273e-02,
          1.148e-02, -5.774e-03,  2.766e-02,  6.867e-03],
        [-1.037e-02,  1.335e-02, -8.337e-03,  5.009e-03, -2.597e-02,  2.658e-03,
          8.318e-04,  8.841e-03,  2.314e-02, -8.040e-03],
        [ 1.204e-02,  8.471e-03,  9.597e-03, -1.117e-02,  5.651e-03,  2.149e-02,
          5.816e-03, -1.458e-02,  8.131e-03,  1.919e-02],
        [ 1.723e-02, -5.465e-03, -1.034e-02, -6.685e-04,  7.430e-03,  2.915e-02,
         -5.023e-03,  5.156e-03, -1.270e-02,  3.862e-03],
        [-8.758e-03,  1.830e-03,  4.920e-03,  4.116e-03,  3.798e-03,  5.851e-03,
         -6.515e-04,  4.433e-03, -3.663e-03,  1.043e-02],
        [-3.205e-03, -2.393e-03, -1.089e-02, -1.572e-02,  2.054e-03, -4.412e-04,
         -2.654e-03,  5.349e-03,  2.037e-02, -2.239e-03],
        [ 2.369e-04,  3.117e-02, -5.560e-04, -2.018e-02, -1.005e-03, -4.296e-03,
         -1.660e-02, -2.015e-02, -1.111e-02, -1.416e-02],
        [ 8.705e-03,  1.998e-02,  1.235e-02, -1.716e-02, -6.358e-04, -8.197e-03,
         -2.875e-02, -3.061e-02,  2.604e-02, -1.333e-02],
        [ 2.332e-04,  1.868e-03, -2.354e-03, -4.282e-03, -1.281e-02,  8.503e-03,
          4.575e-03, -3.404e-02,  9.918e-03,  8.560e-03],
        [ 2.034e-02,  3.273e-03,  2.747e-03, -6.299e-03,  1.740e-03, -4.641e-02,
         -7.399e-03,  1.484e-03,  2.468e-02,  1.122e-02],
        [-8.304e-03,  6.632e-03, -2.474e-02, -1.002e-02, -1.334e-02,  1.230e-02,
          8.825e-04, -8.666e-04, -2.986e-02, -4.657e-03],
        [-7.173e-03,  1.388e-03,  1.121e-03, -1.654e-02, -4.778e-03,  3.840e-02,
         -1.139e-03, -2.710e-02,  1.247e-02, -1.629e-02],
        [-1.517e-03, -5.873e-03, -7.806e-03,  1.039e-02, -5.510e-03, -9.034e-03,
         -3.558e-03,  1.116e-03, -9.223e-03, -2.781e-03],
        [ 1.953e-02,  7.827e-03,  6.185e-03,  1.331e-02,  1.399e-02,  9.892e-03,
          3.081e-03,  4.096e-03, -2.142e-02, -6.521e-03],
        [ 1.605e-02, -3.376e-03, -4.666e-03,  2.234e-02, -4.015e-03, -2.010e-02,
          8.537e-03, -8.581e-03,  7.930e-03,  1.983e-02],
        [-4.362e-03,  3.742e-03,  5.614e-04, -5.004e-03,  5.356e-03,  3.319e-03,
         -2.579e-03,  6.251e-03, -1.804e-03, -7.099e-03],
        [-3.785e-03,  1.818e-02, -1.092e-02,  9.924e-03, -1.530e-03,  2.271e-03,
         -1.572e-02, -6.543e-04,  1.031e-02, -8.808e-04],
        [-5.472e-03, -2.169e-02, -2.509e-03,  7.307e-03,  2.330e-03,  1.071e-02,
         -2.239e-02,  5.627e-03,  7.553e-03,  3.951e-03],
        [-2.674e-02,  1.859e-02,  4.780e-04, -1.988e-02, -1.809e-02, -1.143e-02,
          1.800e-02,  5.301e-03,  2.952e-02, -4.873e-03]], device='cuda:0')
s after update for 1 param tensor([[1.576, 0.787, 1.169, 0.521, 1.156, 1.962, 1.858, 1.582, 0.362, 1.885],
        [1.943, 1.909, 0.661, 1.148, 1.417, 1.395, 1.333, 1.399, 0.883, 1.845],
        [1.630, 0.403, 1.296, 1.070, 1.919, 1.267, 1.483, 1.158, 0.319, 1.546],
        [1.302, 0.328, 0.078, 1.821, 1.838, 1.660, 0.901, 0.717, 1.253, 1.880],
        [2.167, 2.094, 1.646, 0.937, 1.663, 1.675, 1.587, 1.449, 0.950, 1.602],
        [2.141, 1.545, 1.604, 1.510, 1.664, 1.501, 0.751, 1.521, 1.221, 1.141],
        [2.115, 1.740, 1.275, 0.745, 1.459, 1.741, 1.006, 2.087, 1.086, 1.786],
        [2.042, 1.692, 1.530, 1.231, 1.713, 1.534, 1.486, 1.728, 1.266, 1.322],
        [2.241, 1.371, 1.488, 1.850, 1.655, 1.515, 1.503, 1.436, 1.335, 1.328],
        [1.861, 2.107, 1.325, 1.172, 1.423, 1.718, 1.092, 1.550, 1.801, 1.534],
        [1.468, 1.597, 1.918, 1.568, 1.318, 1.344, 1.508, 1.915, 1.064, 1.383],
        [0.824, 1.746, 0.936, 2.215, 1.948, 1.216, 1.528, 1.770, 1.481, 0.533],
        [1.544, 1.575, 1.287, 0.249, 0.851, 1.100, 1.225, 1.159, 1.117, 1.343],
        [1.897, 1.622, 1.630, 1.667, 1.884, 1.394, 1.901, 1.418, 1.261, 1.311],
        [1.203, 2.190, 1.209, 1.408, 1.687, 2.082, 1.506, 0.978, 1.380, 1.534],
        [1.417, 1.693, 1.229, 0.939, 1.528, 1.126, 0.385, 1.445, 1.400, 1.701],
        [2.025, 1.540, 1.588, 1.071, 0.815, 1.030, 1.611, 1.766, 1.275, 1.165],
        [1.127, 1.192, 1.589, 1.150, 1.784, 1.594, 1.689, 1.745, 0.481, 1.296],
        [1.483, 1.961, 1.911, 0.080, 1.435, 1.047, 1.467, 1.377, 1.619, 1.441],
        [1.576, 1.951, 1.556, 1.770, 1.499, 1.702, 1.964, 1.075, 1.613, 1.122],
        [1.461, 1.100, 1.511, 0.936, 1.236, 1.470, 1.493, 1.939, 1.089, 1.618],
        [1.726, 0.606, 2.099, 0.973, 1.726, 1.002, 1.688, 1.345, 1.646, 1.652],
        [1.463, 1.721, 1.552, 1.172, 1.695, 1.438, 1.869, 1.721, 1.171, 0.207],
        [1.247, 1.853, 2.310, 1.881, 1.569, 1.477, 1.759, 1.388, 1.032, 1.374],
        [1.687, 2.064, 2.266, 1.308, 1.196, 1.476, 0.600, 1.421, 1.006, 1.709],
        [0.900, 1.904, 1.427, 2.098, 1.702, 1.698, 0.858, 1.489, 0.392, 1.243],
        [1.731, 1.297, 1.678, 1.719, 1.716, 1.638, 1.520, 1.620, 1.394, 1.628],
        [1.889, 1.568, 1.989, 1.002, 1.280, 0.683, 1.433, 1.286, 1.532, 1.538],
        [1.090, 0.883, 1.115, 1.363, 2.050, 1.817, 1.776, 0.993, 1.011, 1.914],
        [1.380, 1.254, 2.011, 1.434, 1.910, 0.777, 1.644, 0.862, 1.320, 1.907],
        [1.362, 1.531, 1.617, 2.036, 1.844, 1.060, 1.259, 1.825, 1.257, 1.606],
        [1.578, 1.314, 1.865, 1.278, 1.724, 2.046, 2.097, 1.293, 1.523, 0.942],
        [1.699, 2.013, 1.100, 1.451, 1.023, 2.123, 1.645, 1.684, 1.493, 0.795],
        [1.742, 1.173, 1.151, 2.305, 0.966, 1.605, 1.971, 1.707, 1.134, 1.692],
        [1.162, 1.243, 1.921, 1.019, 1.254, 1.242, 1.447, 1.395, 2.165, 0.721],
        [1.571, 1.664, 0.706, 1.571, 1.991, 1.123, 0.540, 1.053, 1.121, 1.454],
        [1.585, 0.922, 2.022, 2.004, 1.848, 2.312, 1.873, 1.190, 1.360, 1.552],
        [2.075, 1.786, 1.950, 1.311, 1.646, 1.411, 1.014, 2.053, 1.574, 1.719],
        [1.414, 1.714, 1.491, 2.188, 2.023, 1.661, 2.101, 1.321, 1.753, 1.416],
        [1.744, 1.996, 2.004, 1.440, 1.079, 1.905, 0.995, 1.824, 1.252, 1.796],
        [1.463, 1.033, 0.807, 0.753, 2.137, 1.564, 1.385, 1.117, 1.651, 1.484],
        [0.874, 1.493, 0.137, 1.075, 2.372, 1.860, 1.794, 1.452, 1.124, 1.077],
        [0.831, 1.702, 0.864, 1.287, 1.907, 2.102, 0.741, 1.644, 1.466, 1.987],
        [1.719, 1.839, 1.798, 1.761, 1.981, 1.602, 1.569, 1.570, 1.356, 1.095],
        [1.048, 1.259, 1.241, 1.429, 1.127, 1.201, 2.154, 1.007, 1.569, 1.074],
        [1.405, 1.754, 1.515, 1.606, 1.843, 0.813, 1.527, 1.974, 1.663, 1.347],
        [1.458, 1.455, 1.435, 1.285, 2.217, 1.939, 1.486, 0.629, 0.748, 1.969],
        [1.736, 0.508, 0.011, 1.478, 1.672, 0.187, 0.798, 1.955, 1.336, 1.550],
        [1.374, 1.321, 2.001, 1.535, 1.596, 0.624, 1.430, 1.671, 1.157, 1.705],
        [1.568, 0.376, 1.624, 0.950, 1.338, 1.489, 1.510, 1.432, 1.111, 1.576],
        [1.513, 0.028, 1.278, 2.076, 1.850, 1.556, 1.495, 1.532, 0.945, 0.555],
        [1.492, 1.446, 2.128, 1.521, 1.499, 1.554, 1.730, 1.199, 0.672, 2.020],
        [1.478, 1.737, 1.263, 1.667, 1.254, 1.147, 1.311, 0.654, 1.821, 1.402],
        [1.285, 1.532, 0.939, 1.363, 1.936, 2.044, 1.655, 0.951, 1.579, 1.355],
        [1.378, 1.086, 1.123, 0.936, 1.243, 2.023, 1.043, 1.308, 0.184, 0.688],
        [1.485, 1.521, 1.682, 1.429, 1.085, 1.594, 1.446, 1.582, 0.897, 1.947],
        [1.432, 1.433, 1.976, 1.235, 1.179, 1.709, 1.891, 1.442, 0.850, 1.449],
        [0.917, 0.833, 1.931, 1.600, 1.593, 2.022, 1.845, 1.170, 1.194, 1.020],
        [1.770, 2.034, 1.455, 1.181, 1.779, 1.611, 1.820, 1.518, 1.930, 1.241],
        [0.447, 1.612, 0.789, 1.371, 1.359, 2.048, 1.458, 1.344, 1.773, 1.040],
        [0.673, 0.915, 0.737, 1.667, 1.603, 1.199, 1.706, 1.458, 1.991, 1.567],
        [0.480, 1.403, 1.372, 1.775, 1.993, 1.088, 1.595, 1.218, 1.369, 1.558],
        [0.711, 1.105, 1.693, 0.912, 1.487, 1.079, 2.012, 1.419, 1.725, 1.818],
        [2.057, 1.388, 0.266, 0.461, 1.329, 1.213, 1.060, 1.770, 1.755, 1.866],
        [0.352, 1.269, 1.434, 1.127, 1.723, 1.778, 1.972, 1.630, 0.728, 1.255],
        [1.374, 1.478, 1.074, 0.142, 2.156, 1.493, 2.213, 2.261, 1.555, 1.536],
        [1.584, 1.348, 1.598, 1.370, 1.676, 1.842, 2.058, 1.817, 1.545, 1.686],
        [1.496, 1.473, 1.552, 1.071, 1.391, 1.309, 1.796, 1.463, 1.430, 1.792],
        [1.131, 1.755, 1.518, 1.658, 1.102, 1.787, 1.276, 1.960, 1.254, 1.995],
        [1.096, 1.018, 1.495, 1.197, 1.501, 1.713, 2.069, 1.839, 1.604, 1.512],
        [1.519, 1.851, 1.360, 1.295, 0.125, 2.388, 0.319, 2.346, 1.201, 1.534],
        [0.724, 1.451, 1.686, 1.457, 1.615, 0.764, 1.572, 1.973, 1.446, 1.519],
        [1.172, 1.286, 1.742, 1.722, 1.907, 1.289, 1.442, 1.586, 1.894, 0.346],
        [2.064, 1.199, 1.639, 1.005, 0.866, 2.021, 1.246, 2.217, 1.541, 1.630],
        [1.055, 1.946, 1.520, 1.364, 1.504, 1.268, 1.049, 1.788, 1.962, 1.297],
        [1.840, 0.979, 2.073, 1.437, 0.456, 1.865, 1.271, 2.314, 1.864, 1.092],
        [0.921, 1.659, 0.575, 0.870, 1.462, 1.971, 0.886, 1.285, 1.653, 2.180],
        [1.137, 1.671, 1.516, 1.440, 1.805, 1.072, 1.582, 1.837, 0.289, 0.517],
        [1.600, 1.720, 1.354, 1.457, 1.596, 1.943, 1.650, 1.556, 1.803, 0.634],
        [1.688, 0.825, 1.404, 1.822, 0.357, 1.732, 1.389, 2.305, 0.749, 1.626],
        [1.808, 1.773, 1.338, 1.776, 1.489, 0.729, 1.093, 0.943, 1.633, 1.685],
        [1.611, 2.105, 1.938, 0.821, 1.799, 1.497, 1.445, 1.005, 1.975, 1.907],
        [1.814, 2.041, 1.432, 0.765, 2.150, 1.335, 1.687, 1.628, 1.991, 1.165],
        [2.074, 1.860, 1.329, 1.990, 1.696, 1.241, 1.528, 2.089, 2.015, 2.078],
        [1.575, 1.744, 1.525, 1.260, 1.319, 1.681, 1.806, 1.734, 2.169, 1.548],
        [1.101, 2.166, 1.959, 0.757, 1.604, 0.624, 1.372, 1.072, 2.341, 1.704],
        [1.905, 1.724, 1.414, 1.100, 2.031, 1.582, 0.686, 1.721, 1.919, 1.632],
        [1.569, 2.307, 1.247, 1.670, 1.309, 0.900, 1.784, 1.725, 1.941, 0.966],
        [1.407, 1.521, 0.982, 1.286, 1.130, 1.711, 1.936, 1.598, 2.012, 1.512],
        [0.603, 1.775, 1.763, 1.217, 1.727, 1.314, 1.711, 1.873, 2.042, 1.149],
        [1.649, 1.973, 1.513, 1.868, 0.503, 1.844, 1.250, 1.455, 1.084, 1.481],
        [1.737, 1.320, 1.079, 0.738, 2.122, 1.150, 1.235, 1.539, 1.639, 2.160],
        [2.069, 1.371, 1.594, 1.243, 0.429, 1.798, 1.081, 1.605, 2.036, 1.299],
        [1.360, 2.027, 1.272, 1.665, 1.364, 1.124, 1.138, 1.060, 1.770, 2.191],
        [1.727, 1.912, 1.034, 1.765, 1.380, 1.636, 1.116, 1.836, 1.180, 1.864],
        [1.656, 1.591, 1.188, 1.359, 1.699, 1.592, 2.027, 1.425, 1.584, 1.871],
        [1.639, 1.300, 1.352, 1.195, 1.728, 1.784, 1.535, 1.594, 0.311, 1.866],
        [1.308, 1.846, 1.180, 1.914, 0.217, 1.849, 2.342, 1.408, 1.284, 1.822],
        [0.744, 1.703, 1.762, 1.440, 1.362, 1.733, 2.000, 1.390, 1.368, 1.221],
        [1.728, 1.228, 1.093, 1.405, 1.063, 1.192, 1.620, 1.561, 1.834, 1.745]],
       device='cuda:0')
b after update for 1 param tensor([[52.693, 37.234, 45.387, 30.305, 45.126, 58.803, 57.213, 52.797, 25.273,
         57.629],
        [58.516, 57.998, 34.130, 44.977, 49.968, 49.583, 48.466, 49.655, 39.445,
         57.014],
        [53.592, 26.660, 47.784, 43.429, 58.151, 47.255, 51.116, 45.168, 23.705,
         52.191],
        [47.908, 24.028, 11.696, 56.644, 56.905, 54.089, 39.842, 35.548, 46.987,
         57.566],
        [61.802, 60.750, 53.864, 40.635, 54.137, 54.334, 52.875, 50.539, 40.923,
         53.131],
        [61.422, 52.182, 53.165, 51.586, 54.148, 51.439, 36.378, 51.780, 46.392,
         44.846],
        [61.044, 55.381, 47.397, 36.233, 50.710, 55.395, 42.095, 60.643, 43.746,
         56.097],
        [59.985, 54.597, 51.920, 46.580, 54.946, 51.987, 51.180, 55.190, 47.241,
         48.268],
        [62.847, 49.157, 51.211, 57.103, 54.011, 51.670, 51.466, 50.299, 48.504,
         48.373],
        [57.263, 60.939, 48.327, 45.444, 50.074, 55.024, 43.860, 52.261, 56.335,
         51.998],
        [50.867, 53.044, 58.142, 52.566, 48.185, 48.675, 51.552, 58.098, 43.311,
         49.372],
        [38.102, 55.461, 40.614, 62.478, 58.588, 46.292, 51.896, 55.843, 51.079,
         30.643],
        [52.166, 52.689, 47.620, 20.928, 38.720, 44.021, 46.463, 45.185, 44.371,
         48.645],
        [57.815, 53.471, 53.589, 54.198, 57.616, 49.571, 57.883, 49.993, 47.148,
         48.073],
        [46.040, 62.124, 46.162, 49.813, 54.530, 60.574, 51.509, 41.507, 49.309,
         51.991],
        [49.963, 54.615, 46.546, 40.670, 51.892, 44.553, 26.058, 50.458, 49.662,
         54.748],
        [59.730, 52.089, 52.905, 43.447, 37.888, 42.599, 53.278, 55.790, 47.406,
         45.319],
        [44.563, 45.834, 52.912, 45.015, 56.071, 53.000, 54.550, 55.453, 29.099,
         47.797],
        [51.126, 58.788, 58.033, 11.845, 50.294, 42.946, 50.849, 49.258, 53.408,
         50.390],
        [52.702, 58.641, 52.368, 55.842, 51.391, 54.762, 58.827, 43.515, 53.312,
         44.461],
        [50.736, 44.026, 51.596, 40.621, 46.677, 50.889, 51.291, 58.458, 43.812,
         53.391],
        [55.144, 32.673, 60.814, 41.416, 55.146, 42.022, 54.543, 48.691, 53.855,
         53.951],
        [50.767, 55.064, 52.299, 45.450, 54.646, 50.333, 57.387, 55.078, 45.419,
         19.103],
        [46.878, 57.148, 63.807, 57.574, 52.582, 51.013, 55.682, 49.462, 42.637,
         49.212],
        [54.520, 60.306, 63.195, 48.018, 45.909, 51.001, 32.527, 50.047, 42.094,
         54.880],
        [39.819, 57.919, 50.155, 60.809, 54.763, 54.696, 38.877, 51.231, 26.297,
         46.805],
        [55.226, 47.808, 54.370, 55.032, 54.991, 53.721, 51.750, 53.426, 49.568,
         53.568],
        [57.702, 52.559, 59.197, 42.031, 47.491, 34.691, 50.251, 47.606, 51.955,
         52.053],
        [43.826, 39.451, 44.333, 49.013, 60.099, 56.579, 55.937, 41.825, 42.209,
         58.074],
        [49.320, 47.007, 59.536, 50.271, 58.014, 37.014, 53.824, 38.974, 48.226,
         57.973],
        [48.986, 51.935, 53.381, 59.897, 56.999, 43.218, 47.102, 56.716, 47.062,
         53.198],
        [52.735, 48.112, 57.321, 47.447, 55.117, 60.048, 60.790, 47.729, 51.813,
         40.749],
        [54.724, 59.553, 44.025, 50.568, 42.462, 61.167, 53.840, 54.482, 51.294,
         37.427],
        [55.413, 45.457, 45.042, 63.731, 41.257, 53.184, 58.936, 54.846, 44.709,
         54.604],
        [45.252, 46.810, 58.180, 42.367, 47.011, 46.785, 50.491, 49.586, 61.767,
         35.650],
        [52.618, 54.156, 35.263, 52.610, 59.240, 44.480, 30.838, 43.069, 44.443,
         50.616],
        [52.855, 40.316, 59.688, 59.429, 57.064, 63.825, 57.458, 45.801, 48.962,
         52.293],
        [60.472, 56.108, 58.621, 48.060, 53.853, 49.869, 42.266, 60.148, 52.661,
         55.033],
        [49.911, 54.964, 51.252, 62.094, 59.708, 54.104, 60.850, 48.250, 55.579,
         49.960],
        [55.442, 59.312, 59.428, 50.373, 43.613, 57.944, 41.883, 56.699, 46.967,
         56.260],
        [50.781, 42.656, 37.720, 36.432, 61.364, 52.500, 49.406, 44.363, 53.946,
         51.142],
        [39.246, 51.296, 15.532, 43.515, 64.659, 57.252, 56.227, 50.578, 44.510,
         43.557],
        [38.259, 54.758, 39.026, 47.628, 57.969, 60.869, 36.129, 53.818, 50.835,
         59.174],
        [55.046, 56.922, 56.296, 55.703, 59.089, 53.126, 52.586, 52.591, 48.877,
         43.937],
        [42.973, 47.101, 46.759, 50.184, 44.570, 46.014, 61.603, 42.115, 52.586,
         43.506],
        [49.762, 55.589, 51.666, 53.206, 56.981, 37.853, 51.874, 58.978, 54.127,
         48.729],
        [50.681, 50.637, 50.292, 47.585, 62.503, 58.457, 51.165, 33.301, 36.300,
         58.904],
        [55.309, 29.923,  4.318, 51.039, 54.288, 18.140, 37.493, 58.694, 48.514,
         52.262],
        [49.199, 48.250, 59.389, 52.004, 53.034, 33.164, 50.198, 54.269, 45.150,
         54.815],
        [52.563, 25.747, 53.495, 40.921, 48.559, 51.229, 51.579, 50.234, 44.247,
         52.706],
        [51.632,  6.968, 47.465, 60.487, 57.104, 52.356, 51.319, 51.956, 40.816,
         31.269],
        [51.277, 50.479, 61.238, 51.772, 51.388, 52.332, 55.214, 45.973, 34.418,
         59.655],
        [51.029, 55.320, 47.168, 54.199, 47.009, 44.959, 48.069, 33.940, 56.642,
         49.704],
        [47.577, 51.964, 40.683, 49.017, 58.414, 60.014, 54.000, 40.946, 52.746,
         48.872],
        [49.269, 43.753, 44.493, 40.616, 46.808, 59.710, 42.862, 48.003, 17.998,
         34.827],
        [51.151, 51.771, 54.438, 50.179, 43.722, 53.004, 50.487, 52.797, 39.756,
         58.573],
        [50.228, 50.259, 59.006, 46.656, 45.587, 54.875, 57.726, 50.402, 38.708,
         50.538],
        [40.197, 38.323, 58.330, 53.098, 52.986, 59.686, 57.021, 45.410, 45.861,
         42.398],
        [55.849, 59.867, 50.633, 45.611, 55.983, 53.273, 56.625, 51.728, 58.321,
         46.771],
        [28.068, 53.293, 37.279, 49.144, 48.940, 60.068, 50.684, 48.660, 55.893,
         42.810],
        [34.430, 40.159, 36.039, 54.207, 53.152, 45.973, 54.823, 50.691, 59.227,
         52.557],
        [29.089, 49.731, 49.179, 55.929, 59.264, 43.791, 53.011, 46.324, 49.125,
         52.392],
        [35.398, 44.127, 54.613, 40.080, 51.187, 43.605, 59.542, 49.999, 55.132,
         56.597],
        [60.201, 49.451, 21.648, 28.488, 48.386, 46.225, 43.222, 55.857, 55.619,
         57.342],
        [24.908, 47.287, 50.273, 44.572, 55.109, 55.980, 58.952, 53.587, 35.827,
         47.022],
        [49.198, 51.036, 43.507, 15.836, 61.642, 51.288, 62.445, 63.115, 52.339,
         52.027],
        [52.827, 48.730, 53.064, 49.129, 54.347, 56.970, 60.224, 56.593, 52.187,
         54.510],
        [51.351, 50.948, 52.294, 43.438, 49.518, 48.030, 56.255, 50.776, 50.198,
         56.196],
        [44.651, 55.608, 51.717, 54.048, 44.069, 56.109, 47.419, 58.767, 47.017,
         59.289],
        [43.951, 42.348, 51.327, 45.937, 51.434, 54.939, 60.388, 56.921, 53.161,
         51.619],
        [51.746, 57.108, 48.953, 47.773, 14.846, 64.876, 23.712, 64.303, 46.011,
         51.996],
        [35.711, 50.571, 54.513, 50.668, 53.344, 36.687, 52.640, 58.966, 50.477,
         51.744],
        [45.442, 47.606, 55.403, 55.083, 57.971, 47.656, 50.412, 52.863, 57.775,
         24.679],
        [60.307, 45.968, 53.744, 42.075, 39.065, 59.673, 46.854, 62.504, 52.114,
         53.588],
        [43.116, 58.566, 51.759, 49.031, 51.474, 47.275, 42.994, 56.135, 58.801,
         47.808],
        [56.942, 41.536, 60.440, 50.316, 28.351, 57.333, 47.329, 63.855, 57.313,
         43.873],
        [40.294, 54.072, 31.839, 39.165, 50.755, 58.935, 39.507, 47.588, 53.978,
         61.983],
        [44.769, 54.257, 51.695, 50.378, 56.399, 43.472, 52.803, 56.903, 22.558,
         30.178],
        [53.098, 55.061, 48.841, 50.668, 53.036, 58.516, 53.924, 52.364, 56.365,
         33.417],
        [54.546, 38.137, 49.738, 56.665, 25.090, 55.243, 49.474, 63.733, 36.328,
         53.536],
        [56.442, 55.899, 48.560, 55.951, 51.227, 35.834, 43.888, 40.772, 53.640,
         54.492],
        [53.275, 60.905, 58.438, 38.035, 56.299, 51.353, 50.462, 42.081, 58.993,
         57.968],
        [56.537, 59.971, 50.227, 36.721, 61.549, 48.508, 54.523, 53.564, 59.234,
         45.317],
        [60.453, 57.245, 48.386, 59.223, 54.663, 46.757, 51.899, 60.674, 59.591,
         60.518],
        [52.677, 55.431, 51.837, 47.126, 48.209, 54.429, 56.415, 55.285, 61.824,
         52.225],
        [44.047, 61.776, 58.752, 36.517, 53.172, 33.157, 49.165, 43.468, 64.231,
         54.796],
        [57.946, 55.115, 49.914, 44.030, 59.825, 52.805, 34.772, 55.073, 58.148,
         53.622],
        [52.576, 63.756, 46.882, 54.253, 48.023, 39.835, 56.065, 55.140, 58.489,
         41.259],
        [49.802, 51.779, 41.596, 47.596, 44.614, 54.915, 58.407, 53.064, 59.547,
         51.625],
        [32.594, 55.928, 55.742, 46.312, 55.173, 48.126, 54.910, 57.455, 59.982,
         44.990],
        [53.900, 58.970, 51.632, 57.375, 29.770, 56.999, 46.925, 50.644, 43.708,
         51.094],
        [55.326, 48.230, 43.607, 36.061, 61.155, 45.024, 46.642, 52.080, 53.741,
         61.690],
        [60.378, 49.144, 53.003, 46.807, 27.483, 56.289, 43.650, 53.180, 59.895,
         47.837],
        [48.960, 59.766, 47.353, 54.160, 49.024, 44.515, 44.776, 43.221, 55.855,
         62.136],
        [55.166, 58.042, 42.692, 55.763, 49.313, 53.693, 44.354, 56.877, 45.602,
         57.317],
        [54.015, 52.950, 45.756, 48.937, 54.712, 52.963, 59.762, 50.104, 52.829,
         57.428],
        [53.743, 47.861, 48.813, 45.895, 55.188, 56.069, 52.011, 53.007, 23.421,
         57.344],
        [48.002, 57.029, 45.600, 58.074, 19.560, 57.080, 64.236, 49.804, 47.561,
         56.668],
        [36.207, 54.786, 55.720, 50.381, 48.990, 55.260, 59.362, 49.487, 49.097,
         46.392],
        [55.186, 46.511, 43.886, 49.757, 43.288, 45.831, 53.432, 52.456, 56.854,
         55.445]], device='cuda:0')
clipping threshold 0.3577287972381335
a after update for 1 param tensor([ 4.108e-03,  1.821e-03,  1.572e-02,  7.796e-03,  1.209e-02, -1.273e-02,
         1.465e-02, -1.703e-02,  2.916e-02, -3.802e-03, -9.797e-03, -1.810e-02,
         2.088e-02, -3.755e-02, -1.383e-02, -1.331e-02, -2.007e-02,  1.072e-02,
         3.640e-04, -7.916e-03,  1.098e-02, -3.235e-03, -1.415e-02,  4.100e-02,
         2.823e-02,  2.696e-03, -7.049e-03,  1.485e-02,  2.267e-02, -3.185e-02,
        -3.620e-02, -1.695e-02, -9.040e-03,  1.022e-02, -1.607e-02,  2.688e-03,
         3.152e-02, -5.582e-03, -6.989e-03,  4.215e-03, -2.785e-02, -9.752e-04,
        -2.397e-03,  1.113e-02,  1.936e-02,  1.896e-03,  4.918e-03,  4.417e-03,
        -2.410e-02, -8.577e-03, -1.353e-02, -4.503e-05,  1.461e-02, -7.749e-03,
        -1.620e-02, -1.105e-02,  2.867e-02,  2.976e-02, -2.957e-02, -1.310e-02,
        -1.205e-02,  6.121e-03, -7.485e-03,  2.367e-03, -6.935e-03, -2.679e-02,
        -5.087e-03,  1.959e-02,  1.788e-02, -1.631e-02,  2.995e-02, -1.920e-02,
         2.607e-03, -2.163e-04, -1.364e-03, -1.378e-02, -2.287e-02,  1.770e-03,
        -2.617e-02,  3.912e-03,  8.252e-03,  1.296e-02,  3.647e-03,  9.300e-03,
        -1.166e-02, -6.166e-03,  1.094e-02,  4.262e-02,  7.682e-03, -1.072e-02,
        -1.987e-02,  6.125e-03, -6.378e-03, -1.880e-03, -2.757e-02,  5.501e-03,
        -1.634e-02, -5.917e-04,  6.483e-03, -1.599e-02], device='cuda:0')
s after update for 1 param tensor([1.546, 0.804, 1.514, 0.677, 1.439, 1.272, 0.932, 1.192, 1.753, 1.142,
        1.501, 1.891, 1.653, 1.955, 1.737, 1.831, 1.261, 1.348, 1.395, 1.093,
        1.234, 1.143, 0.768, 2.034, 1.749, 0.486, 0.822, 1.058, 1.261, 1.345,
        1.723, 1.309, 1.457, 1.687, 2.346, 0.814, 1.804, 1.739, 1.304, 1.346,
        1.314, 0.746, 0.339, 1.573, 1.604, 1.903, 1.097, 0.457, 1.255, 1.573,
        1.414, 0.293, 1.770, 0.355, 1.530, 1.327, 1.108, 1.957, 1.718, 1.023,
        1.686, 0.883, 1.209, 1.731, 2.138, 1.965, 0.843, 1.297, 1.132, 1.207,
        1.411, 1.082, 0.291, 1.638, 1.128, 1.451, 1.155, 1.463, 1.974, 1.078,
        1.795, 1.487, 0.780, 1.575, 1.453, 1.465, 1.186, 1.503, 1.077, 2.089,
        1.831, 1.125, 1.998, 1.243, 1.838, 1.356, 1.498, 1.200, 1.218, 1.215],
       device='cuda:0')
b after update for 1 param tensor([52.202, 37.642, 51.659, 34.538, 50.353, 47.345, 40.517, 45.824, 55.581,
        44.851, 51.435, 57.726, 53.971, 58.697, 55.334, 56.805, 47.134, 48.731,
        49.574, 43.890, 46.634, 44.885, 36.789, 59.873, 55.520, 29.250, 38.060,
        43.188, 47.141, 48.684, 55.103, 48.032, 50.669, 54.523, 64.293, 37.867,
        56.387, 55.358, 47.943, 48.705, 48.116, 36.261, 24.435, 52.646, 53.163,
        57.913, 43.973, 28.381, 47.035, 52.641, 49.918, 22.714, 55.846, 25.013,
        51.930, 48.366, 44.191, 58.720, 55.021, 42.467, 54.510, 39.448, 46.155,
        55.229, 61.378, 58.841, 38.546, 47.805, 44.659, 46.119, 49.857, 43.662,
        22.653, 53.718, 44.581, 50.571, 45.112, 50.774, 58.979, 43.577, 56.247,
        51.183, 37.085, 52.683, 50.601, 50.803, 45.718, 51.468, 43.561, 60.670,
        56.803, 44.526, 59.330, 46.795, 56.917, 48.876, 51.375, 45.983, 46.338,
        46.264], device='cuda:0')
clipping threshold 0.3577287972381335
a after update for 1 param tensor([[[-0.030],
         [ 0.001],
         [ 0.006],
         [ 0.003],
         [-0.028],
         [-0.004],
         [-0.000],
         [-0.033],
         [ 0.026],
         [ 0.013]],

        [[-0.002],
         [ 0.011],
         [ 0.009],
         [-0.009],
         [-0.020],
         [-0.013],
         [-0.007],
         [ 0.003],
         [ 0.006],
         [-0.009]],

        [[-0.012],
         [-0.003],
         [ 0.005],
         [-0.035],
         [-0.016],
         [-0.003],
         [-0.001],
         [ 0.005],
         [-0.008],
         [-0.021]],

        [[ 0.023],
         [ 0.021],
         [-0.010],
         [-0.018],
         [-0.001],
         [-0.002],
         [-0.032],
         [ 0.004],
         [ 0.004],
         [ 0.002]],

        [[ 0.020],
         [-0.005],
         [-0.027],
         [-0.024],
         [ 0.014],
         [ 0.039],
         [ 0.004],
         [-0.015],
         [-0.033],
         [ 0.017]],

        [[-0.011],
         [-0.000],
         [ 0.010],
         [-0.001],
         [-0.000],
         [ 0.025],
         [-0.010],
         [ 0.021],
         [-0.001],
         [-0.004]],

        [[ 0.009],
         [ 0.017],
         [ 0.044],
         [ 0.024],
         [-0.001],
         [ 0.010],
         [ 0.007],
         [ 0.014],
         [-0.016],
         [-0.005]],

        [[ 0.006],
         [ 0.001],
         [-0.028],
         [ 0.018],
         [-0.002],
         [-0.001],
         [ 0.065],
         [ 0.009],
         [ 0.010],
         [-0.002]],

        [[ 0.001],
         [-0.001],
         [ 0.001],
         [-0.002],
         [ 0.016],
         [ 0.014],
         [ 0.013],
         [ 0.033],
         [ 0.012],
         [-0.031]],

        [[ 0.004],
         [-0.010],
         [-0.013],
         [-0.006],
         [-0.030],
         [ 0.017],
         [-0.021],
         [ 0.001],
         [-0.017],
         [-0.012]]], device='cuda:0')
s after update for 1 param tensor([[[1.621],
         [1.804],
         [1.487],
         [1.719],
         [1.337],
         [1.511],
         [1.666],
         [1.900],
         [1.188],
         [2.095]],

        [[1.660],
         [1.480],
         [1.486],
         [1.374],
         [1.265],
         [1.970],
         [1.841],
         [1.569],
         [1.746],
         [2.009]],

        [[1.457],
         [1.243],
         [1.758],
         [1.694],
         [1.675],
         [1.740],
         [1.135],
         [1.437],
         [1.364],
         [1.726]],

        [[1.567],
         [1.731],
         [1.588],
         [1.682],
         [0.291],
         [1.075],
         [2.012],
         [1.509],
         [1.125],
         [1.552]],

        [[1.397],
         [1.621],
         [1.789],
         [1.768],
         [1.318],
         [1.775],
         [1.303],
         [1.573],
         [1.426],
         [0.954]],

        [[1.682],
         [1.004],
         [1.019],
         [1.421],
         [1.912],
         [1.583],
         [1.214],
         [2.108],
         [1.356],
         [1.544]],

        [[1.476],
         [1.482],
         [1.617],
         [1.559],
         [1.463],
         [1.782],
         [1.811],
         [0.695],
         [1.510],
         [1.872]],

        [[1.630],
         [2.130],
         [2.028],
         [1.525],
         [1.628],
         [1.684],
         [1.950],
         [1.614],
         [1.177],
         [1.433]],

        [[0.549],
         [0.472],
         [1.519],
         [1.557],
         [1.626],
         [1.244],
         [0.778],
         [1.591],
         [1.356],
         [2.192]],

        [[1.695],
         [1.352],
         [1.547],
         [1.233],
         [2.005],
         [1.992],
         [1.162],
         [1.520],
         [1.855],
         [1.365]]], device='cuda:0')
b after update for 1 param tensor([[[53.445],
         [56.380],
         [51.198],
         [55.039],
         [48.534],
         [51.593],
         [54.175],
         [57.861],
         [45.751],
         [60.758]],

        [[54.083],
         [51.070],
         [51.172],
         [49.212],
         [47.217],
         [58.922],
         [56.965],
         [52.578],
         [55.474],
         [59.506]],

        [[50.674],
         [46.796],
         [55.666],
         [54.635],
         [54.331],
         [55.368],
         [44.717],
         [50.319],
         [49.022],
         [55.146]],

        [[52.541],
         [55.224],
         [52.899],
         [54.440],
         [22.642],
         [43.519],
         [59.538],
         [51.562],
         [44.534],
         [52.294]],

        [[49.608],
         [53.445],
         [56.152],
         [55.824],
         [48.187],
         [55.935],
         [47.918],
         [52.647],
         [50.123],
         [41.003]],

        [[54.436],
         [42.072],
         [42.384],
         [50.043],
         [58.045],
         [52.809],
         [46.249],
         [60.952],
         [48.877],
         [52.155]],

        [[50.998],
         [51.107],
         [53.376],
         [52.421],
         [50.782],
         [56.039],
         [56.498],
         [35.005],
         [51.577],
         [57.442]],

        [[53.601],
         [61.264],
         [59.776],
         [51.846],
         [53.558],
         [54.482],
         [58.627],
         [53.323],
         [45.539],
         [50.245]],

        [[31.103],
         [28.826],
         [51.736],
         [52.389],
         [53.526],
         [46.830],
         [37.036],
         [52.955],
         [48.882],
         [62.150]],

        [[54.650],
         [48.810],
         [52.219],
         [46.619],
         [59.444],
         [59.247],
         [45.258],
         [51.761],
         [57.173],
         [49.040]]], device='cuda:0')
clipping threshold 0.3577287972381335
a after update for 1 param tensor([[ 0.017],
        [-0.007],
        [-0.003],
        [ 0.003],
        [-0.045],
        [-0.010],
        [ 0.025],
        [ 0.024],
        [-0.007],
        [-0.006]], device='cuda:0')
s after update for 1 param tensor([[1.589],
        [1.793],
        [0.426],
        [1.365],
        [2.170],
        [1.656],
        [1.930],
        [1.618],
        [1.830],
        [1.836]], device='cuda:0')
b after update for 1 param tensor([[52.911],
        [56.215],
        [27.383],
        [49.053],
        [61.842],
        [54.028],
        [58.318],
        [53.401],
        [56.793],
        [56.874]], device='cuda:0')
clipping threshold 0.3577287972381335
||w||^2 0.04433942432852222
exp ma of ||w||^2 0.08131279429660145
||w|| 0.2105692862896254
exp ma of ||w|| 0.2595966685137899
||w||^2 0.1323469140386745
exp ma of ||w||^2 0.14742873649733404
||w|| 0.36379515395160844
exp ma of ||w|| 0.36375437218957357
cuda
Objective function 8.89 = squared loss an data 8.33 + 0.5*rho*h**2 0.057249 + alpha*h 0.228563 + L2reg 0.23 + L1reg 0.05 ; SHD = 11 ; DAG True
Proportion of microbatches that were clipped  0.7276131553239987
iteration 1 in inner loop, alpha 6.754739554881581 rho 100.0 h 0.03383743126760308
1210
cuda
Objective function 9.41 = squared loss an data 8.33 + 0.5*rho*h**2 0.572486 + alpha*h 0.228563 + L2reg 0.23 + L1reg 0.05 ; SHD = 11 ; DAG True
||w||^2 1960131397.1960711
exp ma of ||w||^2 1700896454.622679
||w|| 44273.37119755024
exp ma of ||w|| 36732.85718710614
||w||^2 13635.198891296672
exp ma of ||w||^2 250580.0423830278
||w|| 116.76985437730353
exp ma of ||w|| 272.51190243944137
||w||^2 38.97835128518058
exp ma of ||w||^2 11756.888632281216
||w|| 6.243264473428991
exp ma of ||w|| 36.52734333053098
||w||^2 0.2405518746211006
exp ma of ||w||^2 0.2639454509925711
||w|| 0.49046087980704495
exp ma of ||w|| 0.48310154110413456
cuda
Objective function 8.86 = squared loss an data 8.40 + 0.5*rho*h**2 0.075203 + alpha*h 0.082840 + L2reg 0.25 + L1reg 0.05 ; SHD = 12 ; DAG True
Proportion of microbatches that were clipped  0.7303890306122449
iteration 2 in inner loop, alpha 6.754739554881581 rho 1000.0 h 0.012264032332835129
iteration 3 in outer loop, alpha = 19.01877188771671, rho = 1000.0, h = 0.012264032332835129
cuda
1210
cuda
Objective function 9.01 = squared loss an data 8.40 + 0.5*rho*h**2 0.075203 + alpha*h 0.233247 + L2reg 0.25 + L1reg 0.05 ; SHD = 12 ; DAG True
||w||^2 1000529344.8883305
exp ma of ||w||^2 1956313751.9778461
||w|| 31631.1451719398
exp ma of ||w|| 40074.32113135085
||w||^2 209170968.45857468
exp ma of ||w||^2 480443055.66375434
||w|| 14462.744153810323
exp ma of ||w|| 19076.407812542093
||w||^2 0.09839770863937562
exp ma of ||w||^2 0.2784058255212151
||w|| 0.31368409051046187
exp ma of ||w|| 0.2982836207242553
||w||^2 0.05654159110883428
exp ma of ||w||^2 0.0921849095142434
||w|| 0.23778475794052545
exp ma of ||w|| 0.2733663825934053
||w||^2 0.2163866844571714
exp ma of ||w||^2 0.13593118393181272
||w|| 0.46517382176684385
exp ma of ||w|| 0.3500401212080045
cuda
Objective function 8.98 = squared loss an data 8.50 + 0.5*rho*h**2 0.027341 + alpha*h 0.140638 + L2reg 0.27 + L1reg 0.05 ; SHD = 12 ; DAG True
Proportion of microbatches that were clipped  0.7275221953188055
iteration 1 in inner loop, alpha 19.01877188771671 rho 1000.0 h 0.007394718758897412
1210
cuda
Objective function 9.23 = squared loss an data 8.50 + 0.5*rho*h**2 0.273409 + alpha*h 0.140638 + L2reg 0.27 + L1reg 0.05 ; SHD = 12 ; DAG True
||w||^2 35117536106.90517
exp ma of ||w||^2 18058777519.703133
||w|| 187396.73451505275
exp ma of ||w|| 110104.68508000075
||w||^2 1587052.6547831076
exp ma of ||w||^2 5497344.864077445
||w|| 1259.7827807932238
exp ma of ||w|| 1685.901951458868
||w||^2 88756.00861158711
exp ma of ||w||^2 689717.5798866868
||w|| 297.9194666543076
exp ma of ||w|| 509.98359823428603
||w||^2 2494.861122409331
exp ma of ||w||^2 190374.10193913567
||w|| 49.948584788853935
exp ma of ||w|| 222.0262001937412
||w||^2 1708.4078763177572
exp ma of ||w||^2 29336.37755862062
||w|| 41.332890974595
exp ma of ||w|| 68.46366550109407
||w||^2 75.60748566818961
exp ma of ||w||^2 12008.467529665766
||w|| 8.695256503875525
exp ma of ||w|| 38.426885601010355
||w||^2 0.2600823516932505
exp ma of ||w||^2 0.09463534291208496
||w|| 0.5099826974449726
exp ma of ||w|| 0.29570533538319094
||w||^2 0.10169783334371862
exp ma of ||w||^2 0.11624332017872409
||w|| 0.3189009773326489
exp ma of ||w|| 0.3268340644685598
||w||^2 0.2185058526907912
exp ma of ||w||^2 0.128010993070137
||w|| 0.46744609602690146
exp ma of ||w|| 0.33793119879291794
cuda
Objective function 8.99 = squared loss an data 8.57 + 0.5*rho*h**2 0.042171 + alpha*h 0.055234 + L2reg 0.27 + L1reg 0.05 ; SHD = 13 ; DAG True
Proportion of microbatches that were clipped  0.7321030862233535
iteration 2 in inner loop, alpha 19.01877188771671 rho 10000.0 h 0.00290415814055045
iteration 4 in outer loop, alpha = 48.06035329322121, rho = 10000.0, h = 0.00290415814055045
cuda
1210
cuda
Objective function 9.08 = squared loss an data 8.57 + 0.5*rho*h**2 0.042171 + alpha*h 0.139575 + L2reg 0.27 + L1reg 0.05 ; SHD = 13 ; DAG True
||w||^2 27095.55051754126
exp ma of ||w||^2 1412932.4572258897
||w|| 164.60726143624788
exp ma of ||w|| 683.741883025248
||w||^2 21859.885032256236
exp ma of ||w||^2 732553.484041135
||w|| 147.85088783046328
exp ma of ||w|| 460.3569678449127
||w||^2 2.059669400203226
exp ma of ||w||^2 372.92447440901316
||w|| 1.4351548349231265
exp ma of ||w|| 2.933512349867564
||w||^2 0.16721124226480544
exp ma of ||w||^2 19.82677671724331
||w|| 0.4089147127027902
exp ma of ||w|| 0.7394663867458122
||w||^2 0.10755329728149643
exp ma of ||w||^2 0.12358635509806336
||w|| 0.3279531937357775
exp ma of ||w|| 0.33621827311329966
||w||^2 0.17684797956876028
exp ma of ||w||^2 0.17527206060422684
||w|| 0.4205329708462349
exp ma of ||w|| 0.3931340740536059
||w||^2 0.3582123756096508
exp ma of ||w||^2 0.2386915575064747
||w|| 0.5985084590961525
exp ma of ||w|| 0.4640277336208318
cuda
Objective function 9.04 = squared loss an data 8.59 + 0.5*rho*h**2 0.021222 + alpha*h 0.099015 + L2reg 0.28 + L1reg 0.04 ; SHD = 13 ; DAG True
Proportion of microbatches that were clipped  0.7245362837617962
iteration 1 in inner loop, alpha 48.06035329322121 rho 10000.0 h 0.0020602126107647223
1210
cuda
Objective function 9.23 = squared loss an data 8.59 + 0.5*rho*h**2 0.212224 + alpha*h 0.099015 + L2reg 0.28 + L1reg 0.04 ; SHD = 13 ; DAG True
||w||^2 813001167.7836033
exp ma of ||w||^2 159158553322.83646
||w|| 28513.17533673869
exp ma of ||w|| 141759.8602262355
||w||^2 388.15539407354476
exp ma of ||w||^2 747685.7335808453
||w|| 19.701659678147543
exp ma of ||w|| 50.532235958275294
||w||^2 0.21280172375132064
exp ma of ||w||^2 0.10613252596787054
||w|| 0.4613043721354922
exp ma of ||w|| 0.3162685927500832
cuda
Objective function 9.03 = squared loss an data 8.65 + 0.5*rho*h**2 0.028001 + alpha*h 0.035966 + L2reg 0.27 + L1reg 0.04 ; SHD = 11 ; DAG True
Proportion of microbatches that were clipped  0.727039589677833
iteration 2 in inner loop, alpha 48.06035329322121 rho 100000.0 h 0.0007483479684182726
iteration 5 in outer loop, alpha = 796.4083217114937, rho = 1000000.0, h = 0.0007483479684182726
Threshold 0.3
[[0.004 0.011 0.024 0.003 0.224 0.041 0.065 0.023 0.008 0.937]
 [0.294 0.005 0.016 0.008 0.172 0.029 0.455 0.025 0.002 0.223]
 [0.078 0.318 0.006 0.101 0.151 0.429 0.578 0.024 0.012 0.146]
 [0.883 0.493 0.045 0.004 0.206 1.386 0.375 0.024 0.062 0.495]
 [0.012 0.014 0.008 0.009 0.006 0.016 0.006 0.015 0.003 0.014]
 [0.063 0.122 0.009 0.003 0.187 0.005 0.315 0.01  0.007 0.189]
 [0.049 0.012 0.004 0.007 0.559 0.015 0.006 0.009 0.009 0.087]
 [0.061 0.134 0.115 0.126 0.222 0.319 0.244 0.003 0.066 0.063]
 [0.172 1.114 0.282 0.057 0.773 0.416 0.233 0.048 0.002 0.262]
 [0.004 0.022 0.02  0.005 0.334 0.022 0.053 0.043 0.009 0.004]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.937]
 [0.    0.    0.    0.    0.    0.    0.455 0.    0.    0.   ]
 [0.    0.318 0.    0.    0.    0.429 0.578 0.    0.    0.   ]
 [0.883 0.493 0.    0.    0.    1.386 0.375 0.    0.    0.495]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.315 0.    0.    0.   ]
 [0.    0.    0.    0.    0.559 0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.319 0.    0.    0.    0.   ]
 [0.    1.114 0.    0.    0.773 0.416 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.334 0.    0.    0.    0.    0.   ]]
{'fdr': 0.29411764705882354, 'tpr': 0.6, 'fpr': 0.2, 'f1': 0.6486486486486487, 'shd': 11, 'npred': 17, 'ntrue': 20}
[0.011 0.024 0.003 0.224 0.041 0.065 0.023 0.008 0.937 0.294 0.016 0.008
 0.172 0.029 0.455 0.025 0.002 0.223 0.078 0.318 0.101 0.151 0.429 0.578
 0.024 0.012 0.146 0.883 0.493 0.045 0.206 1.386 0.375 0.024 0.062 0.495
 0.012 0.014 0.008 0.009 0.016 0.006 0.015 0.003 0.014 0.063 0.122 0.009
 0.003 0.187 0.315 0.01  0.007 0.189 0.049 0.012 0.004 0.007 0.559 0.015
 0.009 0.009 0.087 0.061 0.134 0.115 0.126 0.222 0.319 0.244 0.066 0.063
 0.172 1.114 0.282 0.057 0.773 0.416 0.233 0.048 0.262 0.004 0.022 0.02
 0.005 0.334 0.022 0.053 0.043 0.009]
[[0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 1. 1. 0. 0. 1. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.8464285714285715, 0.7423718585908587)
Iterations 630
Achieves (6.682218196030888, 1e-05)-DP
