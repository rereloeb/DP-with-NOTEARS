samples  5000  graph  30 120 ER mlp  minibatch size  50  noise  1.0  minibatches per NN training  250 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 2.407192360868244
iteration 1 in outer loop, alpha = 2.407192360868244, rho = 1.0, h = 2.407192360868244
cuda
iteration 1 in inner loop,alpha 2.407192360868244 rho 1.0 h 1.519847643277938
iteration 2 in inner loop,alpha 2.407192360868244 rho 10.0 h 0.6681085661998409
iteration 3 in inner loop,alpha 2.407192360868244 rho 100.0 h 0.2142382096787543
iteration 2 in outer loop, alpha = 23.831013328743673, rho = 100.0, h = 0.2142382096787543
cuda
iteration 1 in inner loop,alpha 23.831013328743673 rho 100.0 h 0.12124247667774668
iteration 2 in inner loop,alpha 23.831013328743673 rho 1000.0 h 0.0435616092855291
iteration 3 in outer loop, alpha = 67.39262261427277, rho = 1000.0, h = 0.0435616092855291
cuda
iteration 1 in inner loop,alpha 67.39262261427277 rho 1000.0 h 0.022202384750453774
iteration 2 in inner loop,alpha 67.39262261427277 rho 10000.0 h 0.007856225524086824
iteration 4 in outer loop, alpha = 145.954877855141, rho = 10000.0, h = 0.007856225524086824
cuda
iteration 1 in inner loop,alpha 145.954877855141 rho 10000.0 h 0.0035604447514003823
iteration 2 in inner loop,alpha 145.954877855141 rho 100000.0 h 0.0012145103490155407
iteration 5 in outer loop, alpha = 267.4059127566951, rho = 100000.0, h = 0.0012145103490155407
cuda
iteration 1 in inner loop,alpha 267.4059127566951 rho 100000.0 h 0.0006121952545790066
iteration 6 in outer loop, alpha = 879.6011673357017, rho = 1000000.0, h = 0.0006121952545790066
Threshold 0.3
[[0.002 0.    0.001 1.911 0.001 0.155 0.158 0.    0.    0.    0.    0.
  0.    0.    0.    0.913 0.    0.    0.638 0.159 0.    0.    0.149 0.
  0.    0.    0.141 0.    0.215 0.   ]
 [0.416 0.003 0.013 0.136 0.163 1.542 0.186 0.    1.187 0.    0.    0.134
  0.    0.    0.    0.818 0.    1.192 0.317 0.619 0.    0.002 0.98  0.001
  0.    0.    0.163 0.    0.22  0.143]
 [0.166 0.05  0.002 0.462 0.017 0.441 0.194 0.003 0.083 0.    0.    0.167
  0.    0.    0.    0.733 0.    0.258 0.103 0.077 0.    0.    0.179 0.
  0.    0.002 0.182 0.    0.224 0.004]
 [0.    0.    0.    0.002 0.    0.001 0.162 0.    0.    0.    0.    0.
  0.    0.    0.    0.9   0.    0.    0.215 0.554 0.    0.    0.158 0.
  0.    0.    0.    0.    0.246 0.   ]
 [0.092 0.008 0.066 0.182 0.003 0.103 0.27  0.    0.261 0.    0.    0.254
  0.    0.    0.    0.199 0.    0.002 0.665 0.162 0.    0.001 1.401 0.
  0.    0.001 0.116 0.    0.211 0.004]
 [0.001 0.    0.    0.205 0.003 0.002 1.615 0.    0.003 0.    0.    0.
  0.    0.    0.    0.18  0.    0.    0.139 0.157 0.    0.    0.281 0.
  0.    0.    0.    0.    0.765 0.   ]
 [0.    0.    0.    0.001 0.    0.    0.005 0.    0.001 0.    0.    0.
  0.    0.    0.    0.973 0.    0.    0.011 0.001 0.    0.    0.    0.
  0.    0.    0.    0.    0.163 0.   ]
 [0.417 0.769 0.105 0.172 2.179 0.182 0.149 0.002 1.319 0.    0.    0.149
  0.    0.    0.    0.538 0.    0.303 0.218 0.711 0.    0.003 0.245 0.001
  0.    0.006 0.132 0.    0.428 0.269]
 [1.211 0.    0.001 0.252 0.001 0.101 0.086 0.    0.002 0.    0.    0.
  0.    0.    0.    0.117 0.    0.    0.25  0.831 0.    0.    0.128 0.
  0.    0.    0.097 0.    0.14  0.   ]
 [0.306 0.955 0.169 0.265 0.234 0.352 0.243 0.313 1.201 0.001 0.    0.213
  2.238 0.126 0.007 0.329 0.001 0.395 0.261 0.097 0.002 0.481 0.453 0.086
  0.    0.162 0.24  0.002 0.312 1.857]
 [1.658 1.794 0.318 0.157 0.226 0.328 0.279 1.956 0.326 1.271 0.002 0.08
  0.166 0.289 0.005 1.055 0.    0.282 0.17  0.125 0.019 0.09  0.253 0.02
  0.    0.206 0.086 0.016 1.047 0.416]
 [0.141 0.002 0.003 0.124 0.003 0.134 0.858 0.    1.024 0.    0.    0.001
  0.    0.    0.    0.343 0.    0.    0.17  0.121 0.    0.    0.162 0.
  0.    0.001 0.923 0.    0.144 0.   ]
 [0.149 1.633 0.097 0.197 2.38  0.347 0.311 1.362 0.791 0.    0.    1.731
  0.001 0.    0.    0.275 0.    0.184 0.618 0.138 0.    2.54  0.536 0.003
  0.    0.032 1.043 0.001 0.33  0.256]
 [0.214 0.183 2.756 1.113 0.114 1.687 0.292 0.138 0.43  0.003 0.002 0.474
  0.297 0.001 0.    0.497 0.    1.74  0.39  0.185 0.    0.125 0.328 2.615
  0.    0.522 0.358 0.007 0.206 2.423]
 [0.215 0.84  0.07  0.285 0.221 0.237 0.435 0.28  0.233 0.025 0.018 0.683
  2.497 0.081 0.002 0.256 0.    0.174 0.129 0.151 0.361 0.623 1.031 3.571
  0.006 0.102 0.445 0.003 0.45  0.27 ]
 [0.    0.    0.    0.    0.001 0.    0.002 0.    0.    0.    0.    0.
  0.    0.    0.    0.006 0.    0.    0.005 0.001 0.    0.    0.    0.
  0.    0.    0.    0.    0.124 0.   ]
 [0.213 0.229 0.147 0.089 0.389 1.068 0.533 0.302 0.541 0.127 0.077 0.124
  1.091 0.096 3.016 0.444 0.001 0.024 0.219 0.055 0.713 1.349 0.188 0.331
  0.001 0.053 0.131 0.004 0.255 0.141]
 [0.162 0.    0.001 0.263 0.131 0.251 0.158 0.    1.098 0.    0.    0.191
  0.    0.    0.    0.213 0.    0.001 0.658 0.275 0.    0.    0.337 0.
  0.    0.    0.698 0.    0.18  0.001]
 [0.001 0.001 0.002 0.001 0.    0.002 0.158 0.    0.    0.    0.    0.
  0.    0.    0.    0.186 0.    0.    0.012 0.    0.    0.    0.016 0.
  0.    0.001 0.001 0.    0.013 0.   ]
 [0.    0.    0.001 0.003 0.001 0.002 0.167 0.001 0.    0.    0.    0.
  0.    0.    0.    0.265 0.    0.    0.751 0.004 0.    0.    0.22  0.
  0.    0.    0.    0.    0.434 0.   ]
 [0.188 0.533 0.213 0.368 1.841 1.013 0.271 1.102 0.198 0.083 0.026 0.218
  0.222 3.738 0.001 0.169 0.001 0.215 0.237 0.068 0.001 1.714 0.63  0.074
  0.001 2.438 0.233 0.001 0.227 0.16 ]
 [0.087 0.205 2.462 1.075 1.588 0.226 0.581 0.278 0.477 0.    0.    0.386
  0.    0.    0.    0.266 0.    2.284 0.352 0.261 0.    0.001 0.519 0.
  0.    0.004 0.277 0.    0.537 2.105]
 [0.001 0.001 0.001 0.002 0.    0.001 0.976 0.    0.001 0.    0.    0.
  0.    0.    0.    0.228 0.    0.    0.388 0.002 0.    0.    0.005 0.
  0.    0.    0.001 0.    0.129 0.   ]
 [2.071 0.277 0.128 0.275 0.142 0.151 0.881 0.147 0.294 0.002 0.    2.177
  0.248 0.    0.    0.787 0.    0.087 0.726 0.845 0.    0.262 0.427 0.002
  0.    0.014 1.531 0.    0.138 0.125]
 [0.228 0.445 0.696 0.14  0.166 0.529 0.507 0.28  0.118 1.153 4.367 0.165
  0.185 2.146 0.043 0.156 0.013 0.395 0.162 0.059 0.034 0.109 0.88  0.105
  0.001 2.788 0.11  0.001 0.238 0.907]
 [0.22  1.717 0.178 0.078 0.168 0.239 0.231 0.112 0.216 0.003 0.004 0.117
  0.016 0.    0.    0.106 0.    0.116 0.342 0.194 0.    0.124 1.321 0.037
  0.    0.003 0.06  0.    0.109 0.134]
 [0.002 0.    0.001 1.548 0.004 1.771 0.314 0.    0.003 0.    0.    0.
  0.    0.    0.    0.724 0.    0.    0.813 0.144 0.    0.    1.3   0.
  0.    0.    0.003 0.    0.745 0.   ]
 [2.084 0.354 0.189 0.278 0.131 0.22  0.1   0.096 0.22  0.013 0.006 0.981
  0.006 0.016 0.021 0.198 0.018 0.121 0.172 0.08  0.001 0.052 0.885 0.031
  0.003 2.997 0.134 0.    0.136 0.091]
 [0.001 0.001 0.001 0.005 0.002 0.002 0.01  0.001 0.001 0.    0.    0.001
  0.    0.    0.    0.066 0.    0.    0.097 0.012 0.    0.    0.003 0.
  0.    0.    0.001 0.    0.01  0.   ]
 [0.237 0.004 0.237 0.452 0.155 0.239 0.262 0.002 0.316 0.    0.    1.973
  0.    0.    0.    0.208 0.    0.313 0.641 0.209 0.    0.    0.171 0.
  0.    0.001 0.701 0.    0.103 0.002]]
[[0.    0.    0.    1.911 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.913 0.    0.    0.638 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.416 0.    0.    0.    0.    1.542 0.    0.    1.187 0.    0.    0.
  0.    0.    0.    0.818 0.    1.192 0.317 0.619 0.    0.    0.98  0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.462 0.    0.441 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.733 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.9   0.    0.    0.    0.554 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.665 0.    0.    0.    1.401 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    1.615 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.765 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.973 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.417 0.769 0.    0.    2.179 0.    0.    0.    1.319 0.    0.    0.
  0.    0.    0.    0.538 0.    0.303 0.    0.711 0.    0.    0.    0.
  0.    0.    0.    0.    0.428 0.   ]
 [1.211 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.831 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.306 0.955 0.    0.    0.    0.352 0.    0.313 1.201 0.    0.    0.
  2.238 0.    0.    0.329 0.    0.395 0.    0.    0.    0.481 0.453 0.
  0.    0.    0.    0.    0.312 1.857]
 [1.658 1.794 0.318 0.    0.    0.328 0.    1.956 0.326 1.271 0.    0.
  0.    0.    0.    1.055 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    1.047 0.416]
 [0.    0.    0.    0.    0.    0.    0.858 0.    1.024 0.    0.    0.
  0.    0.    0.    0.343 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.923 0.    0.    0.   ]
 [0.    1.633 0.    0.    2.38  0.347 0.311 1.362 0.791 0.    0.    1.731
  0.    0.    0.    0.    0.    0.    0.618 0.    0.    2.54  0.536 0.
  0.    0.    1.043 0.    0.33  0.   ]
 [0.    0.    2.756 1.113 0.    1.687 0.    0.    0.43  0.    0.    0.474
  0.    0.    0.    0.497 0.    1.74  0.39  0.    0.    0.    0.328 2.615
  0.    0.522 0.358 0.    0.    2.423]
 [0.    0.84  0.    0.    0.    0.    0.435 0.    0.    0.    0.    0.683
  2.497 0.    0.    0.    0.    0.    0.    0.    0.361 0.623 1.031 3.571
  0.    0.    0.445 0.    0.45  0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.389 1.068 0.533 0.302 0.541 0.    0.    0.
  1.091 0.    3.016 0.444 0.    0.    0.    0.    0.713 1.349 0.    0.331
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    1.098 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.658 0.    0.    0.    0.337 0.
  0.    0.    0.698 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.751 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.434 0.   ]
 [0.    0.533 0.    0.368 1.841 1.013 0.    1.102 0.    0.    0.    0.
  0.    3.738 0.    0.    0.    0.    0.    0.    0.    1.714 0.63  0.
  0.    2.438 0.    0.    0.    0.   ]
 [0.    0.    2.462 1.075 1.588 0.    0.581 0.    0.477 0.    0.    0.386
  0.    0.    0.    0.    0.    2.284 0.352 0.    0.    0.    0.519 0.
  0.    0.    0.    0.    0.537 2.105]
 [0.    0.    0.    0.    0.    0.    0.976 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.388 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [2.071 0.    0.    0.    0.    0.    0.881 0.    0.    0.    0.    2.177
  0.    0.    0.    0.787 0.    0.    0.726 0.845 0.    0.    0.427 0.
  0.    0.    1.531 0.    0.    0.   ]
 [0.    0.445 0.696 0.    0.    0.529 0.507 0.    0.    1.153 4.367 0.
  0.    2.146 0.    0.    0.    0.395 0.    0.    0.    0.    0.88  0.
  0.    2.788 0.    0.    0.    0.907]
 [0.    1.717 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.342 0.    0.    0.    1.321 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    1.548 0.    1.771 0.314 0.    0.    0.    0.    0.
  0.    0.    0.    0.724 0.    0.    0.813 0.    0.    0.    1.3   0.
  0.    0.    0.    0.    0.745 0.   ]
 [2.084 0.354 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.981
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.885 0.
  0.    2.997 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.452 0.    0.    0.    0.    0.316 0.    0.    1.973
  0.    0.    0.    0.    0.    0.313 0.641 0.    0.    0.    0.    0.
  0.    0.    0.701 0.    0.    0.   ]]
{'fdr': 0.3216374269005848, 'tpr': 0.9666666666666667, 'fpr': 0.1746031746031746, 'f1': 0.7972508591065292, 'shd': 59, 'npred': 171, 'ntrue': 120}
[2.110e-04 8.488e-04 1.911e+00 1.304e-03 1.546e-01 1.576e-01 1.999e-05
 3.331e-04 1.549e-05 1.487e-05 1.133e-04 1.085e-05 1.820e-05 3.387e-05
 9.127e-01 2.171e-05 7.548e-05 6.378e-01 1.591e-01 6.874e-07 1.593e-05
 1.493e-01 1.598e-04 2.065e-06 8.870e-05 1.412e-01 2.524e-05 2.151e-01
 5.453e-05 4.162e-01 1.295e-02 1.360e-01 1.630e-01 1.542e+00 1.863e-01
 2.300e-04 1.187e+00 7.402e-05 5.447e-05 1.337e-01 2.257e-04 1.232e-04
 8.770e-05 8.181e-01 4.990e-05 1.192e+00 3.174e-01 6.186e-01 1.037e-05
 2.447e-03 9.799e-01 6.531e-04 3.406e-07 3.555e-04 1.625e-01 2.570e-05
 2.196e-01 1.428e-01 1.663e-01 4.974e-02 4.623e-01 1.744e-02 4.407e-01
 1.942e-01 2.812e-03 8.272e-02 1.452e-06 6.759e-06 1.667e-01 1.057e-04
 1.904e-04 4.573e-06 7.327e-01 5.843e-06 2.580e-01 1.025e-01 7.696e-02
 1.787e-05 9.765e-05 1.785e-01 3.270e-04 1.811e-05 2.402e-03 1.816e-01
 1.201e-04 2.244e-01 3.659e-03 1.037e-04 8.773e-05 1.431e-04 3.067e-04
 1.224e-03 1.624e-01 5.150e-05 1.139e-04 4.730e-06 2.113e-05 3.833e-05
 4.158e-06 1.868e-05 2.007e-06 9.004e-01 6.512e-06 3.010e-05 2.151e-01
 5.542e-01 6.158e-06 1.218e-05 1.578e-01 1.701e-05 1.070e-05 9.327e-05
 1.107e-04 1.156e-05 2.459e-01 3.542e-04 9.179e-02 8.277e-03 6.621e-02
 1.823e-01 1.027e-01 2.705e-01 2.972e-04 2.608e-01 2.676e-05 6.234e-05
 2.538e-01 5.899e-05 1.606e-05 1.552e-05 1.994e-01 1.442e-06 1.581e-03
 6.652e-01 1.623e-01 8.496e-06 5.182e-04 1.401e+00 3.146e-04 8.199e-07
 6.161e-04 1.156e-01 1.362e-04 2.107e-01 4.239e-03 9.296e-04 2.478e-04
 7.022e-05 2.048e-01 3.237e-03 1.615e+00 3.673e-04 2.630e-03 1.916e-05
 1.169e-05 7.687e-05 3.390e-05 7.463e-06 7.003e-06 1.798e-01 3.097e-06
 1.922e-04 1.394e-01 1.566e-01 2.805e-06 1.723e-05 2.811e-01 3.037e-05
 1.668e-06 4.735e-05 2.017e-04 3.433e-06 7.646e-01 6.668e-05 3.099e-04
 1.932e-04 1.829e-04 1.271e-03 1.403e-04 2.138e-04 1.679e-04 1.060e-03
 3.257e-05 5.484e-06 5.897e-05 6.931e-06 2.105e-05 1.606e-05 9.728e-01
 1.227e-05 3.580e-05 1.056e-02 1.269e-03 2.177e-06 2.595e-05 4.475e-04
 1.211e-04 4.128e-06 1.842e-05 3.679e-05 9.599e-06 1.629e-01 5.408e-05
 4.173e-01 7.695e-01 1.051e-01 1.718e-01 2.179e+00 1.821e-01 1.490e-01
 1.319e+00 3.779e-05 2.047e-05 1.491e-01 1.689e-04 1.302e-04 1.711e-05
 5.376e-01 1.902e-05 3.035e-01 2.177e-01 7.113e-01 1.967e-05 2.531e-03
 2.447e-01 1.372e-03 5.837e-06 5.563e-03 1.319e-01 1.984e-04 4.280e-01
 2.692e-01 1.211e+00 3.094e-04 1.409e-03 2.520e-01 1.108e-03 1.015e-01
 8.600e-02 1.520e-04 2.698e-06 5.699e-06 1.042e-04 1.766e-05 2.347e-06
 6.895e-06 1.171e-01 7.707e-06 1.744e-04 2.497e-01 8.314e-01 2.716e-06
 6.886e-05 1.277e-01 2.339e-05 4.624e-07 1.600e-04 9.658e-02 9.422e-06
 1.398e-01 9.259e-05 3.058e-01 9.552e-01 1.693e-01 2.651e-01 2.339e-01
 3.521e-01 2.428e-01 3.129e-01 1.201e+00 9.740e-05 2.126e-01 2.238e+00
 1.261e-01 7.384e-03 3.289e-01 6.411e-04 3.946e-01 2.608e-01 9.730e-02
 1.969e-03 4.807e-01 4.531e-01 8.586e-02 4.745e-05 1.619e-01 2.403e-01
 1.522e-03 3.120e-01 1.857e+00 1.658e+00 1.794e+00 3.184e-01 1.566e-01
 2.259e-01 3.279e-01 2.794e-01 1.956e+00 3.262e-01 1.271e+00 7.952e-02
 1.657e-01 2.890e-01 4.512e-03 1.055e+00 2.937e-04 2.816e-01 1.702e-01
 1.245e-01 1.924e-02 9.035e-02 2.530e-01 1.962e-02 2.089e-04 2.061e-01
 8.630e-02 1.550e-02 1.047e+00 4.158e-01 1.409e-01 1.894e-03 2.712e-03
 1.240e-01 2.643e-03 1.344e-01 8.582e-01 4.322e-04 1.024e+00 2.662e-05
 5.235e-06 3.810e-05 1.055e-05 3.741e-06 3.429e-01 6.774e-06 3.517e-04
 1.700e-01 1.210e-01 2.729e-06 3.109e-05 1.619e-01 5.084e-05 4.401e-06
 5.430e-04 9.233e-01 5.813e-05 1.437e-01 2.531e-04 1.485e-01 1.633e+00
 9.748e-02 1.970e-01 2.380e+00 3.467e-01 3.107e-01 1.362e+00 7.913e-01
 2.013e-04 3.105e-05 1.731e+00 1.161e-04 7.602e-05 2.747e-01 2.384e-05
 1.844e-01 6.180e-01 1.379e-01 3.611e-05 2.540e+00 5.361e-01 3.301e-03
 8.075e-06 3.247e-02 1.043e+00 9.822e-04 3.296e-01 2.558e-01 2.136e-01
 1.834e-01 2.756e+00 1.113e+00 1.135e-01 1.687e+00 2.924e-01 1.384e-01
 4.301e-01 2.669e-03 1.553e-03 4.737e-01 2.970e-01 8.486e-05 4.968e-01
 1.526e-04 1.740e+00 3.903e-01 1.848e-01 6.972e-05 1.250e-01 3.276e-01
 2.615e+00 2.617e-04 5.219e-01 3.580e-01 7.084e-03 2.058e-01 2.423e+00
 2.155e-01 8.398e-01 6.968e-02 2.850e-01 2.209e-01 2.369e-01 4.355e-01
 2.803e-01 2.326e-01 2.542e-02 1.828e-02 6.826e-01 2.497e+00 8.109e-02
 2.564e-01 2.474e-04 1.743e-01 1.294e-01 1.512e-01 3.610e-01 6.231e-01
 1.031e+00 3.571e+00 5.706e-03 1.021e-01 4.450e-01 2.638e-03 4.503e-01
 2.697e-01 6.678e-05 4.623e-04 3.228e-04 1.494e-04 5.409e-04 2.278e-04
 1.642e-03 5.098e-05 3.885e-05 2.806e-05 3.943e-05 8.942e-05 3.720e-05
 1.036e-05 5.067e-06 8.665e-06 1.118e-04 4.626e-03 6.452e-04 3.261e-06
 1.384e-05 3.125e-04 3.076e-05 2.823e-06 9.606e-05 1.481e-04 1.250e-05
 1.237e-01 5.328e-05 2.132e-01 2.288e-01 1.466e-01 8.941e-02 3.893e-01
 1.068e+00 5.332e-01 3.021e-01 5.413e-01 1.270e-01 7.722e-02 1.235e-01
 1.091e+00 9.605e-02 3.016e+00 4.438e-01 2.441e-02 2.187e-01 5.512e-02
 7.130e-01 1.349e+00 1.876e-01 3.306e-01 8.815e-04 5.273e-02 1.313e-01
 4.292e-03 2.547e-01 1.415e-01 1.618e-01 4.674e-04 6.607e-04 2.630e-01
 1.311e-01 2.505e-01 1.584e-01 1.409e-04 1.098e+00 5.600e-06 1.416e-05
 1.912e-01 1.327e-05 1.245e-04 4.968e-06 2.131e-01 3.653e-07 6.583e-01
 2.752e-01 2.055e-05 1.207e-04 3.373e-01 1.019e-04 6.935e-06 1.354e-04
 6.976e-01 9.879e-06 1.801e-01 9.448e-04 1.059e-03 5.502e-04 1.687e-03
 8.998e-04 3.442e-04 2.420e-03 1.576e-01 5.654e-05 1.947e-04 4.701e-05
 7.904e-06 4.408e-04 5.873e-05 6.134e-05 7.407e-05 1.856e-01 5.866e-05
 3.571e-04 4.574e-04 5.241e-06 7.631e-05 1.605e-02 3.266e-04 1.115e-06
 5.019e-04 1.363e-03 2.034e-05 1.312e-02 1.258e-04 4.330e-04 3.136e-04
 6.268e-04 3.318e-03 8.616e-04 1.752e-03 1.675e-01 5.575e-04 1.671e-04
 9.809e-06 1.219e-05 3.246e-04 2.381e-05 5.640e-05 5.624e-05 2.650e-01
 3.066e-05 7.014e-05 7.513e-01 1.430e-05 2.138e-05 2.199e-01 2.259e-04
 1.786e-05 1.400e-04 2.049e-04 2.407e-05 4.336e-01 1.010e-04 1.879e-01
 5.326e-01 2.129e-01 3.679e-01 1.841e+00 1.013e+00 2.711e-01 1.102e+00
 1.984e-01 8.284e-02 2.578e-02 2.182e-01 2.218e-01 3.738e+00 7.440e-04
 1.694e-01 6.589e-04 2.146e-01 2.368e-01 6.774e-02 1.714e+00 6.296e-01
 7.367e-02 1.155e-03 2.438e+00 2.328e-01 1.099e-03 2.274e-01 1.598e-01
 8.684e-02 2.054e-01 2.462e+00 1.075e+00 1.588e+00 2.256e-01 5.812e-01
 2.778e-01 4.766e-01 5.774e-06 5.052e-06 3.860e-01 1.010e-05 4.072e-05
 2.375e-05 2.658e-01 6.005e-06 2.284e+00 3.516e-01 2.611e-01 2.081e-05
 5.187e-01 2.555e-04 1.245e-06 3.782e-03 2.765e-01 4.570e-05 5.374e-01
 2.105e+00 7.682e-04 1.040e-03 7.114e-04 2.207e-03 4.515e-04 8.582e-04
 9.757e-01 5.430e-05 1.252e-03 7.877e-06 2.010e-05 2.271e-04 2.569e-05
 5.442e-06 4.037e-06 2.279e-01 2.947e-06 1.112e-04 3.877e-01 2.333e-03
 3.072e-06 5.564e-05 2.539e-05 8.187e-06 1.591e-04 8.532e-04 3.863e-06
 1.292e-01 7.250e-05 2.071e+00 2.769e-01 1.280e-01 2.748e-01 1.423e-01
 1.514e-01 8.808e-01 1.467e-01 2.938e-01 1.922e-03 5.372e-05 2.177e+00
 2.483e-01 9.449e-05 1.792e-04 7.867e-01 6.273e-05 8.663e-02 7.262e-01
 8.451e-01 6.030e-06 2.618e-01 4.270e-01 6.456e-05 1.443e-02 1.531e+00
 4.312e-04 1.375e-01 1.248e-01 2.275e-01 4.454e-01 6.961e-01 1.401e-01
 1.656e-01 5.294e-01 5.074e-01 2.800e-01 1.176e-01 1.153e+00 4.367e+00
 1.650e-01 1.849e-01 2.146e+00 4.262e-02 1.563e-01 1.257e-02 3.946e-01
 1.618e-01 5.879e-02 3.368e-02 1.087e-01 8.796e-01 1.054e-01 2.788e+00
 1.103e-01 8.046e-04 2.381e-01 9.071e-01 2.202e-01 1.717e+00 1.777e-01
 7.777e-02 1.685e-01 2.392e-01 2.313e-01 1.118e-01 2.158e-01 3.099e-03
 4.344e-03 1.166e-01 1.584e-02 3.654e-04 1.403e-04 1.063e-01 8.953e-05
 1.160e-01 3.419e-01 1.937e-01 4.085e-05 1.238e-01 1.321e+00 3.666e-02
 3.659e-04 5.973e-02 7.493e-05 1.094e-01 1.341e-01 2.147e-03 2.028e-04
 7.329e-04 1.548e+00 3.882e-03 1.771e+00 3.143e-01 2.971e-04 3.074e-03
 1.111e-05 1.699e-05 3.170e-04 4.721e-05 8.679e-06 5.470e-06 7.236e-01
 6.987e-06 1.706e-04 8.130e-01 1.441e-01 3.721e-06 5.315e-05 1.300e+00
 4.595e-05 1.270e-06 3.030e-04 5.478e-05 7.452e-01 5.329e-05 2.084e+00
 3.537e-01 1.890e-01 2.776e-01 1.309e-01 2.198e-01 1.002e-01 9.586e-02
 2.204e-01 1.295e-02 6.302e-03 9.811e-01 5.953e-03 1.574e-02 2.091e-02
 1.982e-01 1.787e-02 1.206e-01 1.724e-01 7.952e-02 9.169e-04 5.206e-02
 8.853e-01 3.121e-02 3.295e-03 2.997e+00 1.341e-01 1.361e-01 9.128e-02
 1.454e-03 6.253e-04 5.596e-04 5.097e-03 2.367e-03 1.633e-03 1.002e-02
 1.493e-03 6.284e-04 1.311e-05 1.428e-04 7.826e-04 7.162e-05 3.257e-05
 4.924e-05 6.629e-02 5.298e-05 3.758e-04 9.668e-02 1.165e-02 9.929e-06
 1.940e-04 2.612e-03 1.430e-04 7.680e-05 4.925e-05 1.403e-03 8.388e-06
 2.616e-04 2.365e-01 4.397e-03 2.367e-01 4.515e-01 1.554e-01 2.394e-01
 2.616e-01 1.856e-03 3.163e-01 2.739e-05 2.989e-05 1.973e+00 3.123e-05
 1.139e-04 2.623e-06 2.083e-01 5.404e-06 3.135e-01 6.406e-01 2.089e-01
 2.023e-05 1.102e-04 1.707e-01 3.219e-04 2.350e-05 8.257e-04 7.014e-01
 2.351e-05 1.035e-01]
[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 1.]
 [1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 0. 1.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.
  0. 1. 1. 0. 0. 0.]
 [0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
  0. 1. 0. 0. 0. 1.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1.
 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0.]
aucroc, aucpr (0.9895666666666667, 0.9646210303190258)
cuda
9630
cuda
Objective function 1220.30 = squared loss an data 964.29 + 0.5*rho*h**2 254.631624 + alpha*h 0.000000 + L2reg 0.55 + L1reg 0.82 ; SHD = 397 ; DAG False
||w||^2 80237921.80464481
exp ma of ||w||^2 47016961835.15442
||w|| 8957.562269091117
exp ma of ||w|| 84207.29632001201
||w||^2 0.18081243508901865
exp ma of ||w||^2 0.17829064952902607
||w|| 0.4252204546926437
exp ma of ||w|| 0.41120875717764915
||w||^2 0.12259604508168875
exp ma of ||w||^2 0.19534181038726606
||w|| 0.3501371803760474
exp ma of ||w|| 0.4255437094526843
||w||^2 0.6962046876215603
exp ma of ||w||^2 0.21963939191837156
||w|| 0.834388810819968
exp ma of ||w|| 0.45056012967244585
||w||^2 0.11063147474951608
exp ma of ||w||^2 0.2373063126694246
||w|| 0.33261310068834643
exp ma of ||w|| 0.4678768842017076
||w||^2 0.5025279112411087
exp ma of ||w||^2 0.29798044158526854
||w|| 0.7088920307360697
exp ma of ||w|| 0.5218575660879559
||w||^2 0.9112777494859002
exp ma of ||w||^2 0.3007987934274906
||w|| 0.9546086891946355
exp ma of ||w|| 0.5275395282116275
||w||^2 0.3555939171037437
exp ma of ||w||^2 0.40224751095962064
||w|| 0.5963169602683993
exp ma of ||w|| 0.6054111621514607
||w||^2 0.38043923250706835
exp ma of ||w||^2 0.6145337146152624
||w|| 0.6167975620145303
exp ma of ||w|| 0.7529077698391212
||w||^2 0.5257062980744852
exp ma of ||w||^2 0.6492337842020729
||w|| 0.7250560654697574
exp ma of ||w|| 0.775387317077638
||w||^2 1.7500684713230215
exp ma of ||w||^2 0.7433749917268224
||w|| 1.3229015350066766
exp ma of ||w|| 0.8273304684682188
||w||^2 0.6174715080627297
exp ma of ||w||^2 0.7382768769649218
||w|| 0.7857935530804065
exp ma of ||w|| 0.8245674340445414
cuda
Objective function 121.63 = squared loss an data 100.68 + 0.5*rho*h**2 18.803398 + alpha*h 0.000000 + L2reg 1.53 + L1reg 0.62 ; SHD = 268 ; DAG False
Proportion of microbatches that were clipped  0.7707088648474084
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 6.13243799650548
iteration 1 in outer loop, alpha = 6.13243799650548, rho = 1.0, h = 6.13243799650548
cuda
9630
cuda
Objective function 159.24 = squared loss an data 100.68 + 0.5*rho*h**2 18.803398 + alpha*h 37.606796 + L2reg 1.53 + L1reg 0.62 ; SHD = 268 ; DAG False
||w||^2 292345.65710882767
exp ma of ||w||^2 1428252682.5640988
||w|| 540.6899824380212
exp ma of ||w|| 8883.073571001969
||w||^2 2.4332218539490693
exp ma of ||w||^2 2645691.600060774
||w|| 1.5598787946340797
exp ma of ||w|| 22.917703642212548
||w||^2 0.9586868990857924
exp ma of ||w||^2 893595.7257097383
||w|| 0.979125578812949
exp ma of ||w|| 8.72483702145987
||w||^2 0.9993415161563737
exp ma of ||w||^2 1.8289242233001646
||w|| 0.999670703860213
exp ma of ||w|| 1.2930305781727136
||w||^2 0.5540143353277539
exp ma of ||w||^2 1.5694931200225573
||w|| 0.7443213924963825
exp ma of ||w|| 1.2011294871249925
||w||^2 0.631318629782708
exp ma of ||w||^2 1.512913014853755
||w|| 0.7945556178032523
exp ma of ||w|| 1.1730415043300741
||w||^2 2.001473223189485
exp ma of ||w||^2 1.455354971046842
||w|| 1.414734329543708
exp ma of ||w|| 1.1619231823486706
||w||^2 1.2014866932459023
exp ma of ||w||^2 1.6455510972697582
||w|| 1.096123484487903
exp ma of ||w|| 1.2248019854601342
cuda
Objective function 118.62 = squared loss an data 77.45 + 0.5*rho*h**2 10.492711 + alpha*h 28.092606 + L2reg 2.00 + L1reg 0.59 ; SHD = 230 ; DAG False
Proportion of microbatches that were clipped  0.7724940965719403
iteration 1 in inner loop, alpha 6.13243799650548 rho 1.0 h 4.580984903758306
9630
cuda
Objective function 213.06 = squared loss an data 77.45 + 0.5*rho*h**2 104.927113 + alpha*h 28.092606 + L2reg 2.00 + L1reg 0.59 ; SHD = 230 ; DAG False
||w||^2 83628.38244023283
exp ma of ||w||^2 2055361685.2293873
||w|| 289.1857230919826
exp ma of ||w|| 7786.813335152668
||w||^2 2.1411052024421124
exp ma of ||w||^2 3.570643209584577
||w|| 1.463251585491064
exp ma of ||w|| 1.8057663730323132
||w||^2 3.269197738133065
exp ma of ||w||^2 3.346696288278569
||w|| 1.8080922924820693
exp ma of ||w|| 1.7724398207688323
||w||^2 2.402617032743889
exp ma of ||w||^2 3.1249073728155037
||w|| 1.5500377520382815
exp ma of ||w|| 1.720460246446864
||w||^2 1.0715647903520114
exp ma of ||w||^2 3.2580380251624956
||w|| 1.0351641369135676
exp ma of ||w|| 1.738915576610846
||w||^2 4.0966886823342685
exp ma of ||w||^2 3.105595611628965
||w|| 2.0240278363536084
exp ma of ||w|| 1.6870743809839168
||w||^2 2.7661689947869634
exp ma of ||w||^2 3.0857491925057365
||w|| 1.6631803855225575
exp ma of ||w|| 1.689776083370384
||w||^2 4.720524514724446
exp ma of ||w||^2 3.296449128616272
||w|| 2.1726768086221306
exp ma of ||w|| 1.7563342049243174
||w||^2 1.832808557493138
exp ma of ||w||^2 3.1915730273111786
||w|| 1.3538126005814608
exp ma of ||w|| 1.7315373194530932
||w||^2 14.915479118979801
exp ma of ||w||^2 3.6224443000289623
||w|| 3.862056332963024
exp ma of ||w|| 1.81007985708782
||w||^2 3.523498702021115
exp ma of ||w||^2 3.7465690687330926
||w|| 1.8770984795745573
exp ma of ||w|| 1.869498523952194
||w||^2 1.9159931511388715
exp ma of ||w||^2 3.641680845855133
||w|| 1.3841940438893932
exp ma of ||w|| 1.8438844196406796
||w||^2 9.771761242110824
exp ma of ||w||^2 3.318290424217277
||w|| 3.125981644557566
exp ma of ||w|| 1.7583491746194235
cuda
Objective function 119.11 = squared loss an data 80.06 + 0.5*rho*h**2 23.140107 + alpha*h 13.192614 + L2reg 2.20 + L1reg 0.52 ; SHD = 181 ; DAG False
Proportion of microbatches that were clipped  0.777938575333655
iteration 2 in inner loop, alpha 6.13243799650548 rho 10.0 h 2.151283679621116
9630
cuda
Objective function 327.37 = squared loss an data 80.06 + 0.5*rho*h**2 231.401074 + alpha*h 13.192614 + L2reg 2.20 + L1reg 0.52 ; SHD = 181 ; DAG False
||w||^2 2227983577228.279
exp ma of ||w||^2 781243049413.3395
||w|| 1492643.1513353346
exp ma of ||w|| 466753.7742757751
||w||^2 93.01009889018123
exp ma of ||w||^2 78141705.87529798
||w|| 9.6441743498436
exp ma of ||w|| 202.2021701888459
||w||^2 146.80615114789342
exp ma of ||w||^2 76586688.24699666
||w|| 12.116358823833727
exp ma of ||w|| 198.39127387550113
||w||^2 20.388678421247928
exp ma of ||w||^2 298395.56866666756
||w|| 4.515382422480728
exp ma of ||w|| 3.509864473985146
||w||^2 3.458989709818209
exp ma of ||w||^2 14936.774777211345
||w|| 1.8598359362637902
exp ma of ||w|| 2.5206319752738446
||w||^2 6.617312929483119
exp ma of ||w||^2 12.705907499005317
||w|| 2.5724138332475044
exp ma of ||w|| 2.3390215201266655
||w||^2 8.091563410116198
exp ma of ||w||^2 5.241356924017658
||w|| 2.844567350251387
exp ma of ||w|| 2.2098878789415104
||w||^2 4.249206966432515
exp ma of ||w||^2 5.264079528122802
||w|| 2.061360464943605
exp ma of ||w|| 2.21179866039407
||w||^2 2.4046724438457265
exp ma of ||w||^2 4.961186743743282
||w|| 1.5507006299881763
exp ma of ||w|| 2.1616234266160292
||w||^2 6.340967383019845
exp ma of ||w||^2 5.283355841619736
||w|| 2.518127753514473
exp ma of ||w|| 2.2169566119773343
||w||^2 3.909736831574117
exp ma of ||w||^2 5.117040724248576
||w|| 1.977305447211967
exp ma of ||w|| 2.1959065812807994
||w||^2 6.477000210673381
exp ma of ||w||^2 4.846964490285834
||w|| 2.5449951297936466
exp ma of ||w|| 2.131095179744485
||w||^2 3.023304694899269
exp ma of ||w||^2 4.64969748210265
||w|| 1.7387652788399213
exp ma of ||w|| 2.084833615251845
||w||^2 11.804204013829633
exp ma of ||w||^2 5.052698807864301
||w|| 3.435724670841602
exp ma of ||w|| 2.1799621862936833
||w||^2 2.132845566675391
exp ma of ||w||^2 4.824261525044196
||w|| 1.46042650163416
exp ma of ||w|| 2.117782655103922
||w||^2 3.0640459291111153
exp ma of ||w||^2 4.843653165927597
||w|| 1.750441638304778
exp ma of ||w|| 2.144087019261388
||w||^2 2.727738478141266
exp ma of ||w||^2 5.119307000534461
||w|| 1.651586654747872
exp ma of ||w|| 2.1848671026340285
cuda
Objective function 127.53 = squared loss an data 83.84 + 0.5*rho*h**2 35.741344 + alpha*h 5.184819 + L2reg 2.32 + L1reg 0.45 ; SHD = 172 ; DAG True
Proportion of microbatches that were clipped  0.7789422373872776
iteration 3 in inner loop, alpha 6.13243799650548 rho 100.0 h 0.8454743510752181
iteration 2 in outer loop, alpha = 90.67987310402728, rho = 100.0, h = 0.8454743510752181
cuda
9630
cuda
Objective function 199.02 = squared loss an data 83.84 + 0.5*rho*h**2 35.741344 + alpha*h 76.667507 + L2reg 2.32 + L1reg 0.45 ; SHD = 172 ; DAG True
||w||^2 48900618997.367195
exp ma of ||w||^2 391534777688.8557
||w|| 221134.8434719576
exp ma of ||w|| 506042.11782659823
||w||^2 151775411.9695427
exp ma of ||w||^2 21474949626.48584
||w|| 12319.71639160345
exp ma of ||w|| 55846.387462099854
||w||^2 340854.66526484495
exp ma of ||w||^2 4263020186.6385202
||w|| 583.8275989235564
exp ma of ||w|| 12584.91382470683
||w||^2 11.553185846407395
exp ma of ||w||^2 7738617.093629433
||w|| 3.3989977708741432
exp ma of ||w|| 32.55864275485619
||w||^2 2.6833136924814656
exp ma of ||w||^2 840.5448687221027
||w|| 1.6380823216436546
exp ma of ||w|| 2.51069242257216
v before min max tensor([[-2.511e+03, -1.138e+00,  1.048e+03,  ..., -1.242e+02, -1.811e+03,
         -6.548e+02],
        [-1.307e+03, -1.511e+03,  5.747e+02,  ..., -1.247e+03, -2.660e+03,
         -2.303e+03],
        [-1.043e+03, -1.813e+03, -2.064e+03,  ..., -2.335e+03, -1.500e+03,
         -8.571e+02],
        ...,
        [-1.730e+03,  1.722e+03, -2.871e+03,  ..., -1.397e+03, -1.687e+03,
         -2.895e+03],
        [-7.759e+02, -2.011e+03, -1.690e+03,  ..., -1.882e+03, -1.968e+03,
          5.091e+02],
        [-9.099e+02, -2.296e+03, -2.706e+03,  ..., -8.157e+02,  4.587e+03,
         -2.791e+03]], device='cuda:0')
v tensor([[1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         1.000e-12]], device='cuda:0')
v before min max tensor([ 2.102e+03, -2.756e+03, -1.202e+03, -1.677e+03,  4.343e+02,  1.580e+02,
        -2.507e+03,  2.543e+01,  1.742e+03, -3.282e+03, -2.309e+03, -2.734e+03,
        -2.394e+03,  7.494e+02,  2.522e+03, -2.489e+03,  1.680e+03, -1.828e+03,
        -1.904e+03, -2.200e+03,  4.921e+02, -2.246e+03,  3.209e+03,  1.859e+03,
        -1.908e+03, -7.813e+02,  3.385e+03, -1.329e+03,  6.235e+03,  9.062e+00,
        -1.535e+03,  9.776e+03,  3.669e+03, -1.715e+03, -1.586e+03, -2.749e+03,
         2.591e+03, -1.332e+03, -8.103e+02, -2.325e+03, -1.391e+03,  1.186e+03,
        -6.155e+02, -9.731e+02, -9.661e+02, -1.979e+03, -1.733e+03, -5.647e+02,
        -1.548e+03, -1.734e+03,  2.388e+03,  1.048e+04, -1.601e+03, -1.622e+03,
        -1.231e+03, -1.740e+03, -2.339e+03,  6.323e+02,  8.846e+03, -7.275e+02,
        -1.621e+03,  4.419e+02, -2.001e+03, -2.758e+03, -5.586e+02, -5.827e+02,
        -1.579e+03,  7.986e+03,  7.429e+01, -1.458e+03, -1.186e+03, -2.448e+02,
        -1.822e+03, -8.318e+02,  1.420e+03, -1.788e+03, -1.362e+02, -2.909e+03,
        -4.254e+02,  5.153e+03, -1.346e+03, -2.143e+03, -1.442e+03, -1.745e+03,
        -1.885e+03, -2.293e+03,  1.261e+03,  3.010e+03,  3.669e+03, -2.140e+03,
        -2.258e+03, -2.021e+03, -2.383e+03, -2.115e+03,  2.491e+03, -2.012e+03,
        -1.705e+03, -1.448e+03, -1.968e+01, -2.271e+03, -6.743e+02, -2.365e+03,
         5.309e+03, -2.425e+03, -3.094e+03, -1.936e+03, -1.876e+03, -6.875e+02,
        -2.355e+03, -1.656e+03, -2.516e+03, -5.417e+02,  8.797e+02, -2.347e+03,
        -1.950e+03,  1.366e+03, -2.288e+03,  1.015e+04, -1.949e+03, -2.696e+03,
        -1.505e+03, -1.179e+03, -4.754e+02, -1.469e+02, -2.243e+03, -1.899e+03,
        -1.383e+03, -1.300e+03, -2.034e+03, -4.410e+02,  4.914e+03, -5.334e+02,
         7.106e+02,  4.610e+01,  2.047e+03, -1.909e+03, -2.723e+03,  1.353e+02,
         1.250e+03,  4.394e+03, -1.984e+03, -1.594e+03,  7.454e+03,  7.076e+03,
         1.086e+03, -1.307e+02, -2.244e+03,  1.806e+03, -1.604e+03, -2.252e+03,
        -6.393e+02, -1.602e+03, -2.255e+03, -1.523e+03,  3.455e+02,  6.282e+02,
        -1.327e+03, -2.023e+03,  4.065e+03,  2.012e+03, -1.310e+03, -2.245e+03,
        -3.012e+01, -9.480e+02, -1.803e+03, -2.442e+03, -2.459e+03, -3.156e+03,
        -1.202e+03,  5.335e+03, -1.993e+03,  1.221e+03,  7.437e+03, -2.719e+03,
        -1.511e+03, -2.370e+03,  6.937e+02, -8.422e+02, -1.977e+03, -1.622e+03,
        -1.925e+03,  2.675e+03, -1.291e+03, -7.876e+02, -8.571e+02,  2.318e+03,
        -2.019e+03,  2.042e+03, -2.453e+03, -2.177e+03,  1.057e+03,  1.721e+03,
         7.875e+03, -1.813e+03, -1.973e+03, -1.089e+03, -3.108e+03,  9.890e+02,
        -2.932e+03, -1.457e+03, -1.731e+03,  2.845e+03, -3.046e+03, -1.696e+03,
        -1.290e+03, -2.243e+03, -6.375e+02,  5.248e+02, -2.461e+03, -2.115e+03,
         1.575e+02, -6.818e+02, -2.676e+03, -1.731e+03, -1.912e+03, -2.078e+03,
        -1.627e+03, -4.443e+02, -2.283e+03,  6.537e+02, -9.143e+01, -2.185e+03,
        -2.703e+03,  1.551e+03, -2.724e+03, -1.785e+03,  9.810e+02, -2.011e+03,
        -3.200e+01, -9.771e+02,  4.064e+03, -1.894e+03, -1.276e+03,  2.977e+02,
        -4.878e+02,  7.336e+02, -1.682e+03, -2.153e+03,  6.386e+03, -2.281e+02,
        -2.431e+03,  2.762e+03, -2.603e+03, -1.165e+03, -1.667e+03, -1.294e+03,
        -2.506e+03,  2.442e+01, -1.203e+03, -1.285e+03, -1.328e+03, -1.911e+03,
        -1.264e+03,  7.056e+03,  6.445e+02,  2.627e+02, -2.586e+03, -1.803e+03,
         3.109e+02, -2.117e+03, -2.379e+03, -1.966e+03, -3.130e+03, -2.632e+03,
        -2.519e+03, -1.995e+03,  1.119e+03, -1.364e+03, -2.369e+03, -2.436e+03,
        -1.144e+03, -2.322e+03,  9.811e+03, -1.762e+03, -2.271e+03, -1.831e+03,
        -2.523e+03, -2.047e+03,  1.386e+03,  2.406e+03,  2.560e+03, -2.339e+03,
        -2.223e+03, -9.250e+02, -1.427e+03, -2.636e+03, -1.281e+03,  1.566e+04,
         9.094e+02, -1.574e+03,  2.786e+03, -1.590e+03, -3.518e+02, -1.486e+03,
        -2.488e+03,  1.452e+03, -1.572e+03, -2.362e+03, -6.365e+02, -1.785e+03],
       device='cuda:0')
v tensor([1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 9.062e+00,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-1.237e+03],
         [-2.505e+03],
         [ 2.856e+03],
         [-2.160e+03],
         [-2.191e+03],
         [-1.010e+03],
         [ 1.245e+03],
         [ 2.786e+03],
         [-1.704e+03],
         [-4.743e+02]],

        [[ 5.192e+03],
         [-1.666e+03],
         [ 3.917e+02],
         [-2.935e+03],
         [-3.650e+01],
         [-1.846e+03],
         [ 2.880e+03],
         [-2.846e+03],
         [-1.695e+02],
         [ 3.130e+02]],

        [[ 1.134e+03],
         [-3.499e+02],
         [-2.881e+03],
         [-1.561e+03],
         [ 4.849e+03],
         [ 2.666e+03],
         [-1.890e+03],
         [-2.385e+03],
         [-1.186e+03],
         [ 5.630e+03]],

        [[-1.189e+03],
         [-7.525e+02],
         [ 1.079e+03],
         [-2.035e+03],
         [-4.356e+02],
         [-1.974e+03],
         [-1.113e+03],
         [ 3.296e+03],
         [-2.123e+03],
         [-1.759e+03]],

        [[-3.121e+02],
         [-5.542e+02],
         [ 5.086e+03],
         [-2.002e+03],
         [ 1.373e+04],
         [-1.757e+03],
         [-2.517e+03],
         [ 7.673e+03],
         [ 5.440e+02],
         [ 9.353e+03]],

        [[-9.968e+02],
         [ 3.927e+03],
         [-2.355e+03],
         [-1.216e+03],
         [-9.869e+02],
         [ 1.297e+03],
         [-2.449e+03],
         [-2.817e+03],
         [ 6.338e+02],
         [-1.688e+03]],

        [[-2.694e+03],
         [-1.327e+03],
         [-1.155e+03],
         [-1.837e+03],
         [-1.870e+03],
         [ 6.249e+01],
         [-2.752e+03],
         [-2.000e+03],
         [-1.111e+03],
         [-6.153e+02]],

        [[-2.497e+03],
         [-2.291e+03],
         [-2.584e+03],
         [-3.103e+03],
         [ 6.368e+03],
         [-2.880e+03],
         [-2.767e+03],
         [ 7.316e+02],
         [-2.674e+03],
         [-2.745e+03]],

        [[-2.235e+03],
         [ 6.658e+02],
         [ 8.288e+02],
         [-2.832e+03],
         [ 4.704e+03],
         [ 2.098e+03],
         [-1.708e+03],
         [-2.028e+03],
         [-2.404e+03],
         [-9.896e+02]],

        [[-1.819e+03],
         [-1.552e+03],
         [-1.893e+03],
         [-1.089e+03],
         [-2.148e+03],
         [ 1.329e+03],
         [-2.621e+03],
         [-1.847e+02],
         [-1.429e+03],
         [-2.550e+03]],

        [[-2.458e+03],
         [-1.707e+02],
         [-1.761e+03],
         [-1.524e+03],
         [-2.147e+03],
         [ 2.032e+03],
         [-2.485e+03],
         [-2.022e+03],
         [-2.530e+03],
         [ 3.436e+03]],

        [[-3.773e+02],
         [-8.278e+02],
         [-2.534e+03],
         [ 6.484e+02],
         [ 1.401e+04],
         [ 9.152e+03],
         [-1.457e+03],
         [ 1.362e+01],
         [-1.950e+03],
         [ 2.288e+04]],

        [[-1.672e+03],
         [ 3.058e+02],
         [-1.810e+03],
         [ 2.694e+02],
         [-1.946e+03],
         [ 4.008e+03],
         [-2.441e+03],
         [-7.188e+02],
         [ 3.771e+02],
         [-2.441e+03]],

        [[ 3.932e+02],
         [ 1.088e+04],
         [ 2.013e+03],
         [-2.572e+03],
         [-2.432e+03],
         [ 5.920e-01],
         [-2.618e+03],
         [-1.349e+03],
         [-2.014e+03],
         [-6.170e+02]],

        [[-1.444e+03],
         [-1.856e+03],
         [-2.741e+03],
         [-1.237e+03],
         [ 7.367e+02],
         [ 8.156e+03],
         [-1.666e+03],
         [-2.132e+03],
         [-2.620e+03],
         [ 2.681e+02]],

        [[-1.312e+03],
         [-1.413e+03],
         [ 9.957e+02],
         [ 5.891e+03],
         [-1.659e+03],
         [-1.504e+03],
         [-2.447e+03],
         [-1.911e+03],
         [-2.678e+03],
         [ 9.373e+02]],

        [[-2.115e+03],
         [-2.233e+03],
         [-1.444e+03],
         [-1.475e+03],
         [-4.558e+02],
         [ 1.973e+03],
         [-2.485e+03],
         [-5.961e+02],
         [-1.486e+03],
         [ 2.425e+03]],

        [[-1.519e+03],
         [ 5.425e+03],
         [ 3.169e+03],
         [-2.663e+03],
         [-2.518e+03],
         [-2.310e+03],
         [ 1.094e+03],
         [-2.063e+03],
         [ 4.962e+03],
         [-2.309e+03]],

        [[-1.553e+03],
         [ 1.091e+03],
         [-1.939e+03],
         [ 3.069e+03],
         [-1.741e+03],
         [-9.036e+02],
         [-1.441e+03],
         [-1.447e+03],
         [-1.965e+02],
         [ 9.533e+02]],

        [[-2.480e+03],
         [-1.514e+03],
         [-1.819e+03],
         [-9.998e+02],
         [-1.736e+03],
         [ 1.203e+03],
         [-2.575e+03],
         [ 5.197e+03],
         [ 7.375e+02],
         [-2.498e+03]],

        [[ 9.159e+02],
         [-1.786e+03],
         [-1.661e+03],
         [-4.481e+02],
         [-9.277e+02],
         [-2.407e+03],
         [-9.289e+02],
         [-2.317e+03],
         [ 2.474e+03],
         [ 2.064e+02]],

        [[-7.056e+01],
         [-1.454e+03],
         [-2.736e+03],
         [-2.009e+03],
         [ 2.905e+03],
         [ 7.155e+02],
         [ 3.528e+02],
         [-2.227e+03],
         [-6.857e+02],
         [-5.619e+02]],

        [[-2.223e+03],
         [ 2.504e+03],
         [-2.874e+03],
         [ 8.346e+03],
         [-1.769e+03],
         [ 4.352e+03],
         [ 3.989e+03],
         [-2.541e+03],
         [-1.828e+02],
         [-2.521e+03]],

        [[-2.206e+03],
         [-1.974e+03],
         [-1.523e+03],
         [-2.243e+03],
         [ 7.058e+03],
         [-2.620e+03],
         [ 7.927e+03],
         [-1.738e+03],
         [ 3.673e+02],
         [-1.906e+03]],

        [[-1.051e+03],
         [-1.682e+03],
         [ 1.328e+04],
         [-2.013e+03],
         [ 2.627e+03],
         [-8.854e+01],
         [-2.092e+03],
         [ 1.013e+04],
         [-1.734e+03],
         [ 7.048e+03]],

        [[-2.792e+03],
         [-2.657e+03],
         [-3.607e+02],
         [-1.690e+03],
         [-8.986e+02],
         [-1.844e+03],
         [-2.032e+03],
         [-2.991e+03],
         [-1.934e+02],
         [-1.308e+03]],

        [[-1.751e+03],
         [-7.876e+02],
         [-2.370e+03],
         [-1.903e+03],
         [ 2.234e+04],
         [-6.201e+01],
         [ 1.816e+04],
         [ 9.273e+01],
         [-1.831e+03],
         [-3.118e+02]],

        [[ 2.725e+02],
         [-1.621e+03],
         [-8.636e+02],
         [-2.431e+03],
         [ 1.200e+04],
         [-2.766e+03],
         [-7.711e+02],
         [-2.701e+03],
         [-9.021e+02],
         [ 1.483e+03]],

        [[ 8.990e+02],
         [-2.237e+02],
         [ 3.227e+03],
         [ 5.980e+03],
         [ 2.671e+03],
         [-1.367e+03],
         [ 1.095e+04],
         [ 6.025e+03],
         [ 4.540e+03],
         [-1.626e+03]],

        [[-2.170e+03],
         [-1.355e+02],
         [ 9.685e+03],
         [-1.583e+03],
         [-2.479e+03],
         [-1.709e+03],
         [-1.862e+03],
         [-1.223e+03],
         [ 2.860e+03],
         [-7.818e+02]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [5.920e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[-2713.637],
        [ 3031.614],
        [-2766.268],
        [-2407.208],
        [ 1473.623],
        [-1839.230],
        [  -81.616],
        [ -462.305],
        [ 3927.915],
        [-2817.403],
        [-2201.560],
        [ 2810.602],
        [-1398.476],
        [-2900.281],
        [-2494.359],
        [-2356.871],
        [-2634.092],
        [-1649.539],
        [ 3025.620],
        [-2319.196],
        [ -411.865],
        [ 2702.882],
        [  284.651],
        [ -782.226],
        [-1330.055],
        [-2601.503],
        [ -622.502],
        [ 1648.676],
        [-1980.745],
        [-2122.964]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-0.029,  0.066, -0.081,  ..., -0.450,  0.089,  0.609],
        [-0.034,  0.157,  0.555,  ...,  0.026,  0.063, -0.556],
        [ 0.070, -0.334, -0.438,  ..., -0.039, -0.217, -0.289],
        ...,
        [-0.275,  0.389, -0.897,  ...,  0.162,  0.013,  0.148],
        [-0.521,  0.033, -0.414,  ..., -0.067,  1.564, -0.267],
        [-0.013,  0.009, -0.531,  ...,  0.041, -0.735,  0.198]],
       device='cuda:0')
s after update for 1 param tensor([[1.696, 1.862, 1.991,  ..., 1.722, 1.788, 1.104],
        [1.275, 1.594, 1.567,  ..., 1.820, 1.830, 1.623],
        [1.286, 1.503, 1.504,  ..., 1.793, 1.034, 1.318],
        ...,
        [1.376, 2.123, 1.967,  ..., 1.195, 1.158, 1.962],
        [1.130, 1.398, 1.445,  ..., 1.283, 1.530, 1.852],
        [1.453, 1.709, 1.883,  ..., 2.027, 1.594, 2.143]], device='cuda:0')
b after update for 1 param tensor([[168.545, 176.602, 182.594,  ..., 169.815, 173.057, 135.946],
        [146.106, 163.381, 162.017,  ..., 174.565, 175.076, 164.865],
        [146.760, 158.633, 158.721,  ..., 173.311, 131.598, 148.572],
        ...,
        [151.812, 188.548, 181.492,  ..., 141.475, 139.276, 181.277],
        [137.549, 153.023, 155.558,  ..., 146.559, 160.076, 176.110],
        [155.989, 169.162, 177.590,  ..., 184.230, 163.364, 189.443]],
       device='cuda:0')
clipping threshold 2.002416815458805
a after update for 1 param tensor([ 1.364e-01, -6.552e-02, -2.092e-01,  9.938e-02,  5.598e-01,  2.114e-01,
        -6.243e-01, -8.420e-01, -7.688e-02,  8.048e-01, -5.016e-01,  2.240e-01,
        -4.184e-01, -3.764e-03,  4.684e-01,  7.107e-01,  6.122e-01,  2.067e-01,
        -7.030e-01,  2.206e-01,  3.134e-01,  3.503e-01, -9.678e-01, -3.270e-01,
        -1.785e-01, -6.433e-01,  2.385e-01, -2.395e-02,  2.133e-03,  5.170e-01,
        -2.496e-02,  3.019e-01,  2.606e-01, -4.595e-02, -7.528e-01, -6.192e-01,
         2.825e-01,  2.135e-01, -3.887e-01,  2.754e-01,  1.528e-01, -5.509e-01,
         7.004e-01, -1.338e-01,  2.319e-01,  1.453e-02, -2.008e-01,  6.260e-02,
         2.971e-01,  4.863e-01, -6.073e-01,  4.403e-01,  5.374e-01, -2.662e-01,
        -3.329e-01,  3.161e-01, -3.242e-01, -3.786e-02,  3.491e-01, -3.692e-01,
        -6.592e-01, -7.139e-01, -2.847e-01, -4.856e-02, -1.389e-01, -3.278e-02,
         5.374e-01,  2.130e-01, -3.662e-01,  1.669e-01,  3.913e-01,  5.396e-02,
        -1.933e-01,  4.866e-02, -5.347e-01,  3.454e-01, -4.433e-02,  4.140e-01,
        -1.312e+00, -3.119e-02, -3.620e-01, -1.159e+00,  1.507e-01, -4.850e-01,
        -1.198e-01, -3.250e-02, -2.955e-01,  1.143e-01,  6.451e-01, -6.716e-01,
         3.679e-01,  2.828e-01, -3.574e-01,  2.490e-01, -6.274e-02,  1.015e-01,
         2.012e-01, -6.496e-01,  8.763e-02, -2.248e-01,  1.753e-01,  1.457e-02,
        -5.321e-01, -1.841e-01,  3.451e-01, -9.823e-01, -5.342e-01, -6.743e-02,
         7.135e-02,  4.389e-01,  1.609e-01,  9.939e-02,  2.519e-01,  2.545e-01,
        -2.843e-01,  6.784e-01, -6.261e-02, -1.181e-01, -1.852e-01, -1.723e-02,
         2.263e-01, -2.406e-01,  2.361e-01,  1.604e-01, -5.318e-02,  1.083e+00,
         6.336e-02, -1.468e-01, -1.016e+00, -1.752e-01, -1.105e-01,  3.427e-01,
        -8.294e-01, -7.119e-02, -4.764e-01, -3.842e-01,  2.360e-01,  1.327e-01,
         4.558e-01,  2.198e-01, -3.964e-02,  1.713e-01,  9.731e-02,  9.314e-02,
        -2.053e-01, -7.778e-02, -7.172e-01,  8.118e-01,  3.121e-01,  1.603e-01,
        -1.040e-01, -1.477e-01,  9.347e-01,  7.079e-02,  1.024e+00,  3.719e-01,
         9.970e-01, -4.005e-02,  1.296e-01, -3.653e-01, -2.430e-01, -5.144e-01,
         8.162e-01,  7.137e-01, -4.044e-02, -4.492e-02, -5.099e-02,  4.419e-01,
         6.186e-01,  1.313e-01,  1.164e-01,  4.640e-01,  6.327e-01, -3.399e-01,
        -2.570e-01,  1.259e-02,  1.740e-01, -5.897e-01,  4.479e-02, -7.993e-02,
        -9.921e-01,  1.990e-04,  8.421e-02,  1.729e-01,  8.106e-05,  2.128e-01,
         1.181e-01,  3.812e-01, -3.717e-01, -1.484e-01, -1.012e+00, -1.909e-01,
         7.132e-01,  5.362e-01,  7.042e-02, -8.929e-02,  5.134e-01, -3.785e-01,
         1.731e-01, -1.114e+00, -2.624e-01,  2.205e-01, -7.401e-01, -5.935e-01,
         6.190e-01,  2.048e-01, -1.676e-01, -9.876e-02,  3.580e-01, -1.121e-01,
        -1.889e-01, -3.197e-01,  4.014e-01, -1.936e-01,  4.113e-01, -3.940e-01,
         5.107e-01, -8.097e-01, -4.103e-01, -5.347e-01, -1.604e-01,  6.016e-02,
         1.012e+00, -8.784e-01,  1.140e+00, -3.715e-01, -3.673e-01,  4.320e-01,
         1.209e-01, -2.871e-01,  3.788e-01,  5.639e-01, -2.217e-01,  1.627e-01,
        -2.382e-01, -1.644e-01,  2.904e-01, -4.457e-02, -3.609e-01,  3.618e-01,
         7.493e-01, -4.964e-02,  1.970e-01, -7.269e-01, -6.504e-01, -2.564e-01,
        -6.830e-01,  3.208e-01, -2.225e-01, -2.220e-01, -2.819e-01, -2.551e-01,
         3.817e-01,  4.753e-01,  3.832e-01, -3.829e-01, -3.972e-01, -5.919e-01,
        -1.202e-01, -4.915e-01,  1.145e-02,  8.940e-02,  2.312e-01, -3.429e-01,
         2.905e-01,  1.730e-01, -2.409e-01, -2.841e-01, -3.290e-01,  1.434e-01,
         3.218e-02, -4.862e-01,  1.143e+00, -3.388e-01, -1.828e-01,  6.758e-01,
        -7.184e-02, -1.312e-01, -1.114e+00,  4.746e-01, -4.371e-01, -4.022e-01,
        -3.364e-01,  5.521e-01, -3.702e-01, -1.084e+00, -3.352e-01,  1.661e+00,
        -7.706e-01,  8.948e-01,  3.937e-01, -1.513e-01,  3.943e-01,  7.736e-02,
        -1.124e-01, -9.405e-01,  1.024e+00, -6.729e-01, -4.050e-01, -3.700e-01],
       device='cuda:0')
s after update for 1 param tensor([1.723, 1.966, 1.753, 1.180, 1.209, 2.041, 1.929, 1.952, 1.940, 2.218,
        1.584, 1.983, 1.645, 1.561, 2.166, 1.706, 1.436, 1.812, 1.585, 1.504,
        2.144, 1.736, 1.623, 2.085, 1.832, 2.087, 2.129, 1.483, 1.906, 2.178,
        1.586, 2.213, 1.574, 1.369, 1.629, 2.065, 1.860, 1.410, 1.783, 1.904,
        1.253, 1.655, 1.850, 1.856, 1.684, 2.153, 1.172, 1.303, 1.283, 1.810,
        1.837, 1.819, 1.745, 1.760, 1.888, 1.515, 1.589, 2.273, 2.138, 1.878,
        1.918, 1.733, 1.881, 1.903, 1.247, 1.662, 1.627, 2.176, 2.122, 1.608,
        1.800, 1.600, 1.464, 1.871, 2.191, 1.526, 1.421, 1.966, 1.535, 1.337,
        2.420, 1.459, 1.978, 1.198, 1.347, 1.601, 1.517, 1.754, 1.851, 1.569,
        1.525, 1.691, 1.626, 1.518, 1.899, 1.439, 1.875, 1.236, 1.820, 1.594,
        0.784, 1.944, 1.979, 1.685, 2.107, 1.531, 1.271, 1.462, 1.603, 1.379,
        2.178, 2.207, 1.899, 1.643, 1.484, 1.731, 1.706, 1.785, 1.340, 1.891,
        1.776, 1.875, 1.923, 1.184, 1.536, 1.708, 1.265, 1.854, 1.783, 1.526,
        2.504, 1.819, 2.114, 1.924, 1.753, 1.433, 2.087, 1.778, 2.061, 1.666,
        1.376, 1.476, 1.906, 1.641, 2.153, 1.384, 1.820, 1.865, 1.099, 1.528,
        1.814, 1.677, 2.258, 1.040, 1.508, 2.042, 1.319, 1.781, 1.765, 2.292,
        1.195, 1.591, 1.666, 2.095, 1.425, 1.831, 1.665, 2.174, 1.401, 1.757,
        1.348, 1.577, 1.690, 1.843, 1.794, 1.609, 2.165, 1.827, 1.688, 1.111,
        1.866, 1.873, 1.012, 1.558, 2.002, 2.005, 2.299, 1.803, 1.809, 1.798,
        2.028, 1.511, 2.169, 1.389, 1.503, 1.557, 2.203, 2.099, 1.988, 1.850,
        1.703, 2.022, 2.060, 1.694, 1.439, 1.599, 1.341, 1.941, 1.719, 1.473,
        1.614, 1.398, 1.842, 1.174, 1.777, 1.626, 2.195, 1.644, 1.593, 1.757,
        2.158, 1.566, 1.943, 2.076, 2.143, 1.445, 1.847, 1.442, 1.282, 1.310,
        2.015, 1.388, 1.635, 1.925, 1.359, 1.845, 1.885, 1.851, 1.833, 1.790,
        2.048, 1.995, 1.776, 1.126, 1.541, 1.320, 2.051, 1.435, 0.849, 1.446,
        1.475, 1.296, 1.699, 1.645, 1.577, 1.816, 1.929, 1.997, 1.846, 1.550,
        1.616, 1.384, 2.202, 1.779, 1.723, 1.412, 1.761, 1.724, 1.606, 1.692,
        1.392, 1.790, 1.785, 1.300, 1.717, 1.382, 1.855, 1.384, 1.887, 2.033,
        1.658, 1.658, 1.886, 0.898, 1.401, 1.795, 1.414, 1.907, 1.779, 1.414,
        1.751, 1.600, 1.640, 1.592, 1.838, 2.223, 1.526, 1.851, 0.970, 2.014],
       device='cuda:0')
b after update for 1 param tensor([169.855, 181.444, 171.346, 140.569, 142.298, 184.861, 179.727, 180.818,
        180.231, 192.731, 162.874, 182.256, 165.960, 161.701, 190.478, 169.011,
        155.099, 174.220, 162.904, 158.714, 189.508, 170.510, 164.869, 186.882,
        175.161, 186.976, 188.830, 157.610, 178.648, 190.996, 162.960, 192.506,
        162.373, 151.437, 165.183, 185.948, 176.518, 153.680, 172.798, 178.559,
        144.864, 166.476, 176.042, 176.287, 167.951, 189.900, 140.072, 147.697,
        146.571, 174.106, 175.382, 174.541, 170.931, 171.667, 177.826, 159.288,
        163.147, 195.127, 189.239, 177.326, 179.216, 170.377, 177.469, 178.544,
        144.496, 166.857, 165.077, 190.892, 188.532, 164.080, 173.633, 163.685,
        156.604, 176.998, 191.538, 159.880, 154.280, 181.455, 160.320, 149.662,
        201.309, 156.327, 182.029, 141.663, 150.212, 163.723, 159.369, 171.375,
        176.070, 162.102, 159.822, 168.285, 165.004, 159.427, 178.321, 155.253,
        177.199, 143.847, 174.577, 163.378, 114.593, 180.440, 182.070, 167.981,
        187.835, 160.104, 145.887, 156.488, 163.871, 151.950, 190.996, 192.239,
        178.349, 165.866, 157.640, 170.254, 169.036, 172.881, 149.798, 177.983,
        172.449, 177.209, 179.460, 140.824, 160.389, 169.123, 145.556, 176.197,
        172.795, 159.864, 204.797, 174.554, 188.142, 179.508, 171.342, 154.936,
        186.943, 172.580, 185.803, 167.058, 151.786, 157.225, 178.683, 165.773,
        189.899, 152.262, 174.602, 176.752, 135.689, 159.992, 174.292, 167.581,
        194.485, 131.984, 158.921, 184.950, 148.640, 172.687, 171.935, 195.919,
        141.497, 163.223, 167.042, 187.292, 154.469, 175.097, 167.010, 190.834,
        153.197, 171.562, 150.265, 162.504, 168.254, 175.710, 173.318, 164.173,
        190.400, 174.908, 168.155, 136.436, 176.757, 177.101, 130.178, 161.536,
        183.128, 183.247, 196.217, 173.776, 174.058, 173.509, 184.302, 159.094,
        190.601, 152.518, 158.672, 161.486, 192.065, 187.508, 182.470, 176.017,
        168.903, 184.016, 185.737, 168.413, 155.266, 163.662, 149.857, 180.305,
        169.673, 157.050, 164.409, 153.006, 175.658, 140.224, 172.521, 165.017,
        191.713, 165.929, 163.318, 171.561, 190.104, 161.937, 180.394, 186.478,
        189.448, 155.589, 175.875, 155.397, 146.550, 148.145, 183.685, 152.488,
        165.488, 179.542, 150.845, 175.805, 177.684, 176.070, 175.197, 173.144,
        185.178, 182.776, 172.441, 137.345, 160.632, 148.673, 185.353, 155.035,
        119.248, 155.622, 157.171, 147.317, 168.675, 165.960, 162.502, 174.380,
        179.756, 182.899, 175.842, 161.118, 164.535, 152.237, 192.042, 172.600,
        169.859, 153.800, 171.729, 169.944, 164.001, 168.351, 152.674, 173.165,
        172.921, 147.549, 169.583, 152.139, 176.251, 152.254, 177.759, 184.501,
        166.638, 166.646, 177.725, 122.606, 153.204, 173.392, 153.871, 178.703,
        172.615, 153.876, 171.244, 163.671, 165.734, 163.308, 175.452, 192.949,
        159.872, 176.085, 127.470, 183.678], device='cuda:0')
clipping threshold 2.002416815458805
a after update for 1 param tensor([[[ 3.674e-01],
         [-6.729e-01],
         [-4.715e-01],
         [-3.330e-01],
         [-5.534e-01],
         [ 6.448e-01],
         [-2.979e-01],
         [-4.292e-03],
         [-5.451e-02],
         [ 3.569e-01]],

        [[-3.369e-01],
         [ 6.000e-01],
         [-2.598e-01],
         [-3.463e-01],
         [ 2.927e-01],
         [ 8.137e-01],
         [ 6.930e-01],
         [-2.497e-01],
         [-2.324e-01],
         [-1.090e-01]],

        [[-2.607e-01],
         [-6.759e-01],
         [ 3.133e-02],
         [-8.611e-01],
         [ 5.456e-01],
         [ 3.123e-01],
         [-5.021e-01],
         [-5.801e-01],
         [ 6.645e-01],
         [-4.870e-01]],

        [[ 6.212e-01],
         [-1.224e-02],
         [ 3.541e-01],
         [ 1.641e-01],
         [ 6.875e-01],
         [ 3.502e-01],
         [ 4.460e-02],
         [ 1.418e-01],
         [ 2.162e-01],
         [-4.426e-01]],

        [[ 3.592e-01],
         [ 1.515e-01],
         [-6.876e-03],
         [-1.302e-01],
         [-4.280e-02],
         [-5.461e-01],
         [ 5.548e-02],
         [-1.545e-01],
         [-4.409e-02],
         [ 6.176e-01]],

        [[ 5.005e-01],
         [-1.084e-01],
         [-1.190e-01],
         [-6.482e-01],
         [-6.662e-02],
         [-6.968e-01],
         [-3.406e-01],
         [ 7.483e-01],
         [-2.592e-01],
         [ 1.024e+00]],

        [[ 1.137e-01],
         [ 3.162e-01],
         [-5.890e-01],
         [-1.557e-01],
         [-5.784e-01],
         [ 5.472e-01],
         [ 2.127e-01],
         [ 6.755e-01],
         [-6.092e-01],
         [-4.230e-02]],

        [[ 1.954e-02],
         [ 4.945e-03],
         [ 6.023e-01],
         [ 5.280e-01],
         [-5.790e-01],
         [ 6.666e-01],
         [-1.018e+00],
         [-5.029e-01],
         [-3.001e-01],
         [ 1.821e-01]],

        [[-2.572e-01],
         [ 3.083e-02],
         [-2.974e-01],
         [ 1.175e-01],
         [ 3.366e-01],
         [ 3.321e-01],
         [-1.349e-01],
         [ 1.014e+00],
         [ 5.660e-01],
         [ 1.853e-01]],

        [[-4.445e-01],
         [-2.906e-01],
         [ 5.424e-01],
         [ 2.897e-01],
         [ 1.437e-01],
         [ 1.102e-01],
         [ 3.155e-01],
         [ 1.412e-01],
         [-8.092e-02],
         [-1.665e-01]],

        [[ 7.502e-01],
         [-1.594e-03],
         [ 2.600e-01],
         [ 3.258e-01],
         [-3.272e-01],
         [-4.047e-01],
         [ 1.336e-01],
         [-3.908e-01],
         [-6.784e-01],
         [-4.491e-01]],

        [[ 8.960e-01],
         [ 9.948e-01],
         [ 5.471e-01],
         [ 7.567e-01],
         [-1.114e-01],
         [ 7.662e-01],
         [ 3.820e-01],
         [-7.991e-02],
         [ 2.951e-01],
         [ 7.871e-02]],

        [[ 3.984e-01],
         [ 5.230e-01],
         [ 3.113e-01],
         [ 4.886e-01],
         [ 5.230e-02],
         [-3.576e-01],
         [-2.575e-01],
         [ 3.992e-01],
         [-6.338e-02],
         [ 2.122e-01]],

        [[-1.747e-01],
         [ 6.232e-01],
         [ 7.641e-01],
         [ 1.700e-01],
         [-6.265e-01],
         [-5.794e-01],
         [ 6.739e-01],
         [ 7.839e-02],
         [-1.510e-01],
         [-2.794e-01]],

        [[ 6.910e-01],
         [ 1.971e-01],
         [ 2.652e-01],
         [-1.265e-02],
         [ 3.347e-01],
         [ 6.961e-01],
         [-1.757e-01],
         [-1.198e-01],
         [ 4.088e-01],
         [-2.873e-03]],

        [[ 2.748e-03],
         [-8.065e-01],
         [ 5.626e-01],
         [ 7.367e-01],
         [-4.910e-02],
         [ 1.699e-01],
         [-6.960e-01],
         [ 5.213e-01],
         [ 4.706e-01],
         [ 6.887e-02]],

        [[-1.292e+00],
         [ 4.524e-01],
         [-4.212e-01],
         [ 1.665e-01],
         [ 3.091e-01],
         [ 2.113e-01],
         [ 9.093e-01],
         [-1.088e-01],
         [ 3.103e-02],
         [ 8.952e-01]],

        [[ 2.709e-02],
         [ 3.235e-01],
         [-9.732e-02],
         [-5.270e-01],
         [ 5.017e-01],
         [ 5.941e-01],
         [ 4.567e-01],
         [ 6.831e-03],
         [ 1.392e-01],
         [-1.377e-01]],

        [[ 1.491e-01],
         [-9.201e-01],
         [ 3.156e-01],
         [ 3.657e-01],
         [ 4.193e-02],
         [-9.102e-01],
         [ 6.526e-01],
         [-6.119e-01],
         [ 4.121e-01],
         [ 5.763e-01]],

        [[ 1.252e+00],
         [ 9.133e-02],
         [-2.957e-01],
         [-7.330e-01],
         [-2.716e-01],
         [-4.992e-01],
         [ 9.131e-02],
         [-1.326e-01],
         [-2.549e-02],
         [ 2.610e-01]],

        [[-6.368e-01],
         [-6.066e-01],
         [ 1.230e-01],
         [ 9.666e-02],
         [ 2.614e-01],
         [-2.840e-01],
         [-3.263e-01],
         [-6.531e-01],
         [-2.493e-01],
         [-1.898e-01]],

        [[ 4.671e-02],
         [-1.347e-01],
         [ 2.162e-01],
         [-8.999e-02],
         [-6.372e-01],
         [-1.050e+00],
         [ 1.030e-01],
         [-5.911e-01],
         [ 2.749e-01],
         [-1.430e-01]],

        [[ 2.192e-01],
         [ 6.703e-01],
         [ 6.597e-01],
         [ 4.562e-01],
         [ 2.817e-01],
         [ 1.037e-01],
         [ 1.634e-01],
         [ 4.022e-01],
         [-7.615e-01],
         [-2.453e-02]],

        [[ 3.054e-03],
         [-2.832e-01],
         [-1.289e-03],
         [ 6.549e-02],
         [ 8.381e-02],
         [-2.487e-01],
         [ 7.272e-01],
         [-1.067e-01],
         [-1.672e-01],
         [ 6.381e-01]],

        [[-4.729e-01],
         [ 9.381e-02],
         [ 4.188e-01],
         [-2.066e-01],
         [-3.614e-03],
         [-4.257e-01],
         [ 4.118e-01],
         [-5.788e-02],
         [ 3.160e-01],
         [ 2.029e-01]],

        [[-2.401e-01],
         [-7.122e-01],
         [-8.839e-02],
         [ 5.478e-01],
         [-4.292e-01],
         [ 3.109e-01],
         [-8.810e-02],
         [-7.278e-01],
         [ 3.087e-01],
         [ 3.018e-01]],

        [[ 2.664e-01],
         [ 5.662e-01],
         [-2.811e-03],
         [ 3.315e-01],
         [-4.048e-01],
         [-1.351e+00],
         [ 6.069e-01],
         [ 1.400e-01],
         [-5.378e-01],
         [-1.534e-01]],

        [[ 2.817e-01],
         [ 6.544e-01],
         [ 7.758e-02],
         [ 2.516e-01],
         [ 3.996e-01],
         [-5.995e-02],
         [ 2.473e-01],
         [ 2.697e-01],
         [-1.030e-01],
         [ 1.377e-01]],

        [[ 5.876e-02],
         [ 6.124e-01],
         [ 3.041e-03],
         [-3.547e-01],
         [-1.383e-01],
         [-1.642e-02],
         [-3.687e-01],
         [ 3.698e-01],
         [-4.113e-01],
         [ 4.671e-01]],

        [[ 8.529e-02],
         [-5.495e-01],
         [-5.520e-01],
         [-1.222e-01],
         [ 3.788e-01],
         [ 2.350e-01],
         [-1.811e-01],
         [ 7.749e-01],
         [ 9.171e-01],
         [-7.818e-01]]], device='cuda:0')
s after update for 1 param tensor([[[1.394],
         [1.733],
         [2.141],
         [1.479],
         [1.486],
         [1.526],
         [2.365],
         [1.261],
         [1.319],
         [0.997]],

        [[2.373],
         [1.382],
         [1.667],
         [1.983],
         [0.961],
         [1.578],
         [2.166],
         [1.940],
         [1.355],
         [1.853]],

        [[1.901],
         [1.675],
         [1.946],
         [1.055],
         [1.512],
         [1.727],
         [1.335],
         [1.624],
         [1.416],
         [2.301]],

        [[1.373],
         [1.637],
         [2.306],
         [1.407],
         [1.514],
         [1.600],
         [0.948],
         [2.387],
         [1.700],
         [1.223]],

        [[1.758],
         [1.505],
         [2.038],
         [1.480],
         [1.822],
         [1.188],
         [1.710],
         [1.659],
         [1.889],
         [1.918]],

        [[1.622],
         [1.778],
         [1.610],
         [2.026],
         [1.647],
         [1.355],
         [1.816],
         [1.968],
         [1.944],
         [1.725]],

        [[1.827],
         [1.317],
         [1.200],
         [1.670],
         [1.267],
         [1.563],
         [1.979],
         [1.656],
         [0.998],
         [1.706]],

        [[1.702],
         [1.664],
         [1.950],
         [2.105],
         [2.137],
         [1.959],
         [2.012],
         [2.064],
         [1.840],
         [1.982]],

        [[1.726],
         [1.503],
         [2.038],
         [1.952],
         [2.169],
         [1.455],
         [1.448],
         [1.428],
         [1.721],
         [1.621]],

        [[1.261],
         [2.186],
         [1.664],
         [1.451],
         [1.679],
         [2.272],
         [2.169],
         [1.865],
         [1.653],
         [1.723]],

        [[1.673],
         [1.378],
         [1.655],
         [1.382],
         [1.749],
         [2.286],
         [1.830],
         [1.636],
         [1.711],
         [2.144]],

        [[1.811],
         [1.595],
         [2.239],
         [1.750],
         [2.041],
         [1.631],
         [1.410],
         [2.205],
         [1.356],
         [1.885]],

        [[1.373],
         [1.854],
         [2.116],
         [2.157],
         [1.316],
         [1.638],
         [1.649],
         [1.377],
         [1.882],
         [1.727]],

        [[1.487],
         [1.791],
         [1.869],
         [1.806],
         [1.726],
         [1.555],
         [1.850],
         [1.483],
         [1.653],
         [1.380]],

        [[1.330],
         [1.732],
         [1.877],
         [1.499],
         [1.583],
         [1.847],
         [1.879],
         [1.515],
         [1.771],
         [2.099]],

        [[1.839],
         [1.233],
         [1.831],
         [2.107],
         [1.627],
         [1.691],
         [1.674],
         [1.650],
         [1.827],
         [1.674]],

        [[1.699],
         [1.511],
         [1.795],
         [1.481],
         [1.729],
         [1.863],
         [1.678],
         [1.484],
         [1.831],
         [1.751]],

        [[1.564],
         [2.162],
         [1.863],
         [1.822],
         [1.824],
         [1.689],
         [1.670],
         [1.402],
         [2.361],
         [1.780]],

        [[1.053],
         [2.168],
         [1.763],
         [1.665],
         [1.515],
         [2.238],
         [1.528],
         [1.207],
         [2.107],
         [2.035]],

        [[1.948],
         [1.572],
         [1.507],
         [1.673],
         [1.283],
         [1.868],
         [1.744],
         [1.649],
         [1.910],
         [1.687]],

        [[1.856],
         [1.974],
         [1.588],
         [1.538],
         [1.841],
         [1.651],
         [1.684],
         [1.776],
         [1.512],
         [2.250]],

        [[1.758],
         [2.072],
         [1.892],
         [1.399],
         [2.166],
         [2.111],
         [2.517],
         [1.762],
         [0.844],
         [2.210]],

        [[1.937],
         [2.056],
         [2.054],
         [2.117],
         [1.665],
         [2.138],
         [1.889],
         [1.850],
         [1.323],
         [1.971]],

        [[1.506],
         [1.387],
         [1.838],
         [1.918],
         [1.478],
         [1.769],
         [2.006],
         [1.185],
         [1.963],
         [1.340]],

        [[1.206],
         [1.141],
         [1.973],
         [1.552],
         [1.682],
         [1.727],
         [1.413],
         [2.392],
         [1.615],
         [2.165]],

        [[1.957],
         [1.802],
         [0.954],
         [1.526],
         [0.839],
         [1.887],
         [1.417],
         [2.164],
         [1.409],
         [1.757]],

        [[1.668],
         [1.116],
         [1.833],
         [1.595],
         [2.121],
         [1.555],
         [2.350],
         [2.000],
         [1.553],
         [1.643]],

        [[1.674],
         [1.602],
         [1.141],
         [1.643],
         [2.238],
         [1.871],
         [1.856],
         [1.836],
         [1.235],
         [1.480]],

        [[1.606],
         [1.298],
         [1.905],
         [1.761],
         [2.036],
         [1.762],
         [1.682],
         [2.040],
         [1.993],
         [1.244]],

        [[1.478],
         [1.536],
         [2.278],
         [1.207],
         [1.886],
         [1.179],
         [1.840],
         [2.030],
         [1.799],
         [2.088]]], device='cuda:0')
b after update for 1 param tensor([[[152.777],
         [170.360],
         [189.354],
         [157.385],
         [157.782],
         [159.872],
         [199.026],
         [145.343],
         [148.616],
         [129.228]],

        [[199.370],
         [152.160],
         [167.070],
         [182.254],
         [126.896],
         [162.585],
         [190.467],
         [180.265],
         [150.614],
         [176.171]],

        [[178.446],
         [167.487],
         [180.517],
         [132.908],
         [159.115],
         [170.055],
         [149.509],
         [164.916],
         [154.002],
         [196.319]],

        [[151.651],
         [165.582],
         [196.501],
         [153.512],
         [159.232],
         [163.678],
         [126.029],
         [199.925],
         [168.732],
         [143.108]],

        [[171.603],
         [158.743],
         [184.732],
         [157.427],
         [174.670],
         [141.047],
         [169.230],
         [166.701],
         [177.853],
         [179.249]],

        [[164.833],
         [172.569],
         [164.198],
         [184.199],
         [166.085],
         [150.659],
         [174.383],
         [181.561],
         [180.438],
         [169.990]],

        [[174.925],
         [148.500],
         [141.744],
         [167.253],
         [145.677],
         [161.785],
         [182.064],
         [166.560],
         [129.301],
         [169.038]],

        [[168.825],
         [166.955],
         [180.698],
         [187.764],
         [189.161],
         [181.137],
         [183.570],
         [185.936],
         [175.557],
         [182.186]],

        [[170.017],
         [158.655],
         [184.742],
         [180.803],
         [190.606],
         [156.111],
         [155.747],
         [154.625],
         [169.776],
         [164.768]],

        [[145.313],
         [191.327],
         [166.914],
         [155.894],
         [167.697],
         [195.048],
         [190.593],
         [176.748],
         [166.372],
         [169.852]],

        [[167.383],
         [151.915],
         [166.481],
         [152.110],
         [171.129],
         [195.650],
         [175.053],
         [165.537],
         [169.262],
         [189.495]],

        [[174.151],
         [163.427],
         [193.631],
         [171.204],
         [184.877],
         [165.274],
         [153.661],
         [192.171],
         [150.685],
         [177.692]],

        [[151.619],
         [176.219],
         [188.255],
         [190.075],
         [148.437],
         [165.653],
         [166.205],
         [151.849],
         [177.550],
         [170.058]],

        [[157.810],
         [173.201],
         [176.911],
         [173.891],
         [170.028],
         [161.398],
         [176.042],
         [157.593],
         [166.397],
         [152.040]],

        [[149.228],
         [170.294],
         [177.293],
         [158.431],
         [162.824],
         [175.883],
         [177.404],
         [159.290],
         [172.244],
         [187.486]],

        [[175.486],
         [143.712],
         [175.124],
         [187.832],
         [165.048],
         [168.305],
         [167.460],
         [166.217],
         [174.931],
         [167.425]],

        [[168.705],
         [159.077],
         [173.381],
         [157.498],
         [170.186],
         [176.630],
         [167.652],
         [157.637],
         [175.136],
         [171.238]],

        [[161.862],
         [190.275],
         [176.658],
         [174.693],
         [174.775],
         [168.206],
         [167.233],
         [153.238],
         [198.852],
         [172.676]],

        [[132.775],
         [190.541],
         [171.850],
         [166.963],
         [159.282],
         [193.604],
         [159.969],
         [142.190],
         [187.862],
         [184.598]],

        [[180.601],
         [162.237],
         [158.841],
         [167.409],
         [146.612],
         [176.859],
         [170.903],
         [166.177],
         [178.837],
         [168.101]],

        [[176.317],
         [181.803],
         [163.085],
         [160.492],
         [175.568],
         [166.307],
         [167.949],
         [172.473],
         [159.131],
         [194.132]],

        [[171.583],
         [186.289],
         [178.012],
         [153.071],
         [190.469],
         [188.034],
         [205.313],
         [171.803],
         [118.891],
         [192.379]],

        [[180.122],
         [185.539],
         [185.492],
         [188.305],
         [166.977],
         [189.235],
         [177.873],
         [176.016],
         [148.857],
         [181.665]],

        [[158.799],
         [152.396],
         [175.433],
         [179.213],
         [157.340],
         [172.145],
         [183.289],
         [140.900],
         [181.331],
         [149.780]],

        [[142.147],
         [138.255],
         [181.769],
         [161.232],
         [167.829],
         [170.082],
         [153.839],
         [200.146],
         [164.436],
         [190.431]],

        [[181.060],
         [173.745],
         [126.402],
         [159.886],
         [118.530],
         [177.763],
         [154.031],
         [190.391],
         [153.610],
         [171.556]],

        [[167.158],
         [136.698],
         [175.228],
         [163.436],
         [188.469],
         [161.389],
         [198.393],
         [183.017],
         [161.254],
         [165.889]],

        [[167.460],
         [163.809],
         [138.265],
         [165.881],
         [193.615],
         [177.018],
         [176.308],
         [175.365],
         [143.793],
         [157.417]],

        [[164.012],
         [147.429],
         [178.605],
         [171.724],
         [184.679],
         [171.784],
         [167.856],
         [184.845],
         [182.716],
         [144.362]],

        [[157.316],
         [160.387],
         [195.304],
         [142.166],
         [177.743],
         [140.524],
         [175.567],
         [184.362],
         [173.579],
         [187.015]]], device='cuda:0')
clipping threshold 2.002416815458805
a after update for 1 param tensor([[ 0.352],
        [-0.754],
        [ 0.137],
        [ 0.303],
        [ 0.148],
        [-0.249],
        [-0.275],
        [-0.025],
        [ 0.410],
        [-0.846],
        [ 0.010],
        [ 1.081],
        [ 0.284],
        [ 0.015],
        [-0.116],
        [ 0.190],
        [ 0.011],
        [ 0.403],
        [ 0.087],
        [-0.320],
        [ 1.173],
        [ 0.635],
        [-0.139],
        [-0.594],
        [ 0.148],
        [ 0.011],
        [-0.413],
        [ 0.473],
        [ 0.120],
        [ 0.402]], device='cuda:0')
s after update for 1 param tensor([[1.878],
        [1.942],
        [1.886],
        [1.635],
        [1.328],
        [1.935],
        [1.670],
        [1.387],
        [1.912],
        [1.920],
        [1.932],
        [2.009],
        [1.606],
        [2.087],
        [1.849],
        [1.783],
        [1.990],
        [1.585],
        [1.983],
        [1.827],
        [1.402],
        [1.748],
        [2.176],
        [1.742],
        [1.414],
        [2.072],
        [1.676],
        [1.869],
        [1.362],
        [1.561]], device='cuda:0')
b after update for 1 param tensor([[177.333],
        [180.364],
        [177.710],
        [165.470],
        [149.158],
        [180.009],
        [167.236],
        [152.406],
        [178.946],
        [179.338],
        [179.867],
        [183.440],
        [163.978],
        [186.947],
        [175.967],
        [172.806],
        [182.579],
        [162.914],
        [182.238],
        [174.910],
        [153.206],
        [171.097],
        [190.918],
        [170.789],
        [153.871],
        [186.298],
        [167.521],
        [176.903],
        [151.049],
        [161.684]], device='cuda:0')
clipping threshold 2.002416815458805
||w||^2 4.302729220437777
exp ma of ||w||^2 6.009194598815137
||w|| 2.074302104428807
exp ma of ||w|| 2.369774574184723
||w||^2 4.950632289761247
exp ma of ||w||^2 6.050554915359721
||w|| 2.2250016381479916
exp ma of ||w|| 2.3785823062968325
||w||^2 2.038276495008809
exp ma of ||w||^2 6.1696472366666155
||w|| 1.427682210790906
exp ma of ||w|| 2.399457378885576
||w||^2 6.500627519829127
exp ma of ||w||^2 5.745216543874659
||w|| 2.549632820589884
exp ma of ||w|| 2.3246479408355367
||w||^2 9.263189557743527
exp ma of ||w||^2 5.6563664856619145
||w|| 3.0435488426742108
exp ma of ||w|| 2.3032291151746023
||w||^2 4.413029224134043
exp ma of ||w||^2 6.036246912970463
||w|| 2.1007211200285587
exp ma of ||w|| 2.3844771519532246
||w||^2 10.401304616620436
exp ma of ||w||^2 6.057380674667603
||w|| 3.225105365196684
exp ma of ||w|| 2.4039608566272683
||w||^2 4.81468982033833
exp ma of ||w||^2 5.89519149177441
||w|| 2.194240146460348
exp ma of ||w|| 2.3655838806269776
||w||^2 13.86553542885256
exp ma of ||w||^2 6.207914080627058
||w|| 3.723645448864937
exp ma of ||w|| 2.4119365942035556
||w||^2 6.525549877214429
exp ma of ||w||^2 5.661456621577616
||w|| 2.5545155856276214
exp ma of ||w|| 2.3069456645461837
cuda
Objective function 160.45 = squared loss an data 88.83 + 0.5*rho*h**2 16.555460 + alpha*h 52.179094 + L2reg 2.46 + L1reg 0.43 ; SHD = 181 ; DAG True
Proportion of microbatches that were clipped  0.7787481804949054
iteration 1 in inner loop, alpha 90.67987310402728 rho 100.0 h 0.5754208969701828
9630
cuda
Objective function 309.45 = squared loss an data 88.83 + 0.5*rho*h**2 165.554604 + alpha*h 52.179094 + L2reg 2.46 + L1reg 0.43 ; SHD = 181 ; DAG True
||w||^2 1902741195.5173273
exp ma of ||w||^2 203686086596.1822
||w|| 43620.42177142866
exp ma of ||w|| 261445.74470204746
||w||^2 23749.483582046356
exp ma of ||w||^2 1654276161.866378
||w|| 154.10867458402967
exp ma of ||w|| 3168.0676965443754
||w||^2 4.281002266734901
exp ma of ||w||^2 6.945661096814651
||w|| 2.0690583043343413
exp ma of ||w|| 2.5650167108240702
||w||^2 10.935681452660953
exp ma of ||w||^2 6.9564645922093336
||w|| 3.3069141888868168
exp ma of ||w|| 2.566985383256096
||w||^2 3.8261360351987452
exp ma of ||w||^2 7.392470468399667
||w|| 1.956051133073659
exp ma of ||w|| 2.638903850338507
||w||^2 3.2525887768489357
exp ma of ||w||^2 6.8217978373927926
||w|| 1.8034934923223138
exp ma of ||w|| 2.5327213059922458
||w||^2 5.654320115305813
exp ma of ||w||^2 6.965853402499828
||w|| 2.3778814342405328
exp ma of ||w|| 2.558178429958273
||w||^2 6.563415839925772
exp ma of ||w||^2 7.060822073883613
||w|| 2.5619164389038476
exp ma of ||w|| 2.5783533291942
||w||^2 12.505951539105931
exp ma of ||w||^2 6.391694463256101
||w|| 3.5363754805034393
exp ma of ||w|| 2.4573705581631486
||w||^2 7.614346528446673
exp ma of ||w||^2 6.390422071377756
||w|| 2.7594105400332647
exp ma of ||w|| 2.4607764118441153
||w||^2 3.909345296212698
exp ma of ||w||^2 6.610436869673387
||w|| 1.9772064374295109
exp ma of ||w|| 2.5026509283910316
||w||^2 5.949695591981142
exp ma of ||w||^2 6.953755872093176
||w|| 2.439199785171592
exp ma of ||w|| 2.566476430314776
||w||^2 6.410772719351046
exp ma of ||w||^2 7.398605214002198
||w|| 2.531950378532535
exp ma of ||w|| 2.640634228232138
||w||^2 6.46157310106292
exp ma of ||w||^2 7.23914261876579
||w|| 2.541962450757863
exp ma of ||w|| 2.623162606434766
cuda
Objective function 157.82 = squared loss an data 91.00 + 0.5*rho*h**2 38.621826 + alpha*h 25.202424 + L2reg 2.60 + L1reg 0.39 ; SHD = 176 ; DAG True
Proportion of microbatches that were clipped  0.7834328952608522
iteration 2 in inner loop, alpha 90.67987310402728 rho 1000.0 h 0.27792742397672043
9630
cuda
Objective function 505.41 = squared loss an data 91.00 + 0.5*rho*h**2 386.218265 + alpha*h 25.202424 + L2reg 2.60 + L1reg 0.39 ; SHD = 176 ; DAG True
||w||^2 205999117072.73438
exp ma of ||w||^2 3478177060806.142
||w|| 453871.25605476974
exp ma of ||w|| 1284322.173960382
||w||^2 18751577.901141938
exp ma of ||w||^2 112797736320.05916
||w|| 4330.30921541891
exp ma of ||w|| 70993.50958235051
||w||^2 11.26108168966969
exp ma of ||w||^2 415.62717109069615
||w|| 3.3557535203989115
exp ma of ||w|| 3.341942553440199
||w||^2 12.701362494924656
exp ma of ||w||^2 142.55650777335947
||w|| 3.5638970937619194
exp ma of ||w|| 3.3253184722168063
||w||^2 8.842258862895887
exp ma of ||w||^2 75.32859903086471
||w|| 2.973593594103923
exp ma of ||w|| 3.276058963078431
||w||^2 14.769348801285565
exp ma of ||w||^2 9.463968576249897
||w|| 3.8430910477486173
exp ma of ||w|| 3.016683895033922
||w||^2 5.535723214036245
exp ma of ||w||^2 9.50251557374163
||w|| 2.352811767659335
exp ma of ||w|| 3.0212237460751483
||w||^2 9.019305150777033
exp ma of ||w||^2 9.828380051047436
||w|| 3.00321580156622
exp ma of ||w|| 3.0661934386439715
||w||^2 17.56005653088598
exp ma of ||w||^2 9.202399438537332
||w|| 4.190472113125916
exp ma of ||w|| 2.9703038011191913
||w||^2 16.645225916774628
exp ma of ||w||^2 10.599521149543289
||w|| 4.079856114714663
exp ma of ||w|| 3.2005535131009744
||w||^2 7.067168813860677
exp ma of ||w||^2 10.660983998084623
||w|| 2.6584147181846323
exp ma of ||w|| 3.209165965625348
||w||^2 6.508965498351443
exp ma of ||w||^2 10.284432200507093
||w|| 2.5512674297986564
exp ma of ||w|| 3.149351169228558
v before min max tensor([[ 9148.771, -3582.830,  1382.166,  ..., -2423.728, -2158.984,
         -2333.704],
        [-4038.415,  1918.283, -1680.457,  ..., -2670.995, -5457.763,
         -3867.974],
        [-4024.528,  3990.898, -2686.282,  ..., 45464.684, -4780.806,
         -3926.550],
        ...,
        [ 8070.507, -4447.418, -4410.489,  ..., -3999.367, -3558.814,
         -4613.981],
        [-4623.934, 12797.204, -5000.549,  ...,  5412.496, -4651.602,
          3598.805],
        [ 1285.416,  7028.896, -4823.769,  ..., -2763.795,  -738.069,
          8322.193]], device='cuda:0')
v tensor([[1.000e+01, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e+01, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e+01, 1.000e-12,
         1.000e+01],
        [1.000e+01, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e+01]], device='cuda:0')
v before min max tensor([-1.193e+02,  1.167e+03, -5.204e+03, -4.616e+03, -8.617e+02, -6.069e+02,
         1.367e+03, -4.670e+03, -4.423e+03,  4.770e+03,  3.490e+03,  2.401e+03,
        -1.892e+03, -3.028e+03, -4.919e+03,  8.302e+03, -4.013e+03, -3.190e+03,
         1.302e+03,  9.624e+03,  1.586e+03, -3.051e+03, -1.657e+03, -4.848e+03,
         3.519e+03,  2.567e+03, -4.786e+03, -9.543e+02,  1.131e+03, -4.499e+03,
         3.348e+03, -1.882e+03, -1.854e+03, -3.687e+03,  3.819e+03, -1.371e+03,
        -3.008e+03, -3.527e+03, -3.232e+03,  5.238e+03, -1.949e+03,  3.884e+02,
        -2.536e+03, -2.700e+03,  4.196e+03,  3.171e+03,  2.182e+04, -3.171e+03,
         2.498e+04, -1.653e+03, -1.912e+03,  2.085e+03, -2.848e+03, -4.703e+03,
         1.440e+03, -2.996e+03,  2.434e+03, -5.016e+03, -4.690e+03, -4.865e+03,
        -3.615e+03, -4.677e+03, -1.550e+03, -1.282e+03, -3.366e+03, -3.858e+03,
         8.544e+02, -3.607e+03,  8.759e+03, -2.347e+03,  9.446e+03, -4.842e+03,
        -2.759e+03, -3.173e+03, -2.928e+03, -3.168e+03,  4.249e+03, -3.745e+03,
        -4.891e+03, -3.748e+03, -4.370e+03, -4.540e+03, -4.520e+03,  4.296e+03,
        -3.858e+03, -3.227e+03, -2.084e+03,  2.070e+03, -3.294e+03, -1.615e+03,
        -1.539e+03,  1.599e+03, -7.665e+02, -1.980e+03,  2.136e+02, -4.165e+03,
        -3.382e+03, -4.136e+03, -2.707e+03, -2.334e+03, -5.344e+02,  1.602e+04,
        -3.442e+03,  5.590e+02, -2.579e+03, -4.368e+03, -5.170e+03, -2.426e+03,
        -4.905e+03,  1.331e+03, -3.649e+03, -1.865e+03, -7.947e+02,  2.629e+03,
        -1.518e+03,  6.135e+03,  4.190e+03,  2.717e+03, -3.894e+03, -3.580e+03,
        -3.245e+03,  3.305e+03, -4.435e+03, -4.888e+03, -4.190e+03, -1.390e+03,
        -2.516e+03, -2.559e+03,  9.862e+03, -2.339e+03,  1.845e+03,  5.405e+03,
        -4.295e+03, -2.199e+03,  2.732e+03, -3.630e+03, -4.197e+03, -2.365e+03,
        -1.677e+03, -4.470e+03, -3.422e+03, -2.030e+03, -2.935e+03,  2.178e+03,
        -1.646e+03, -3.390e+03, -2.425e+03, -5.219e+03, -2.881e+03, -4.716e+03,
        -3.496e+03, -2.094e+03,  1.882e+04, -3.818e+03, -4.041e+03, -3.166e+02,
         3.943e+03, -5.419e+03,  7.812e+02, -4.516e+03, -5.945e+02, -3.673e+03,
        -1.142e+03, -3.279e+03, -2.555e+03, -3.169e+03, -1.821e+03, -5.225e+03,
        -4.664e+03, -3.561e+03,  2.235e+04, -4.754e+03,  6.359e+03, -3.611e+03,
        -2.987e+03, -2.870e+03, -2.286e+03, -3.325e+03,  8.608e+02, -3.127e+03,
        -4.563e+03,  3.314e+02, -4.321e+03, -3.607e+03, -3.540e+03, -3.224e+03,
        -2.122e+03, -2.752e+03, -3.702e+03, -4.160e+03,  8.718e+03, -2.408e+03,
         1.077e+04, -4.418e+03,  1.466e+02, -3.982e+02, -4.501e+03,  4.293e+03,
        -2.015e+03, -2.936e+03, -3.563e+03, -2.330e+02, -4.827e+03, -4.271e+02,
         1.137e+03, -2.200e+03, -3.220e+03,  1.232e+04,  2.267e+03, -3.170e+03,
        -3.824e+03, -3.515e+03, -2.907e+03, -9.967e+01,  4.853e+00, -1.546e+03,
        -3.917e+03, -1.119e+03, -3.249e+03,  1.520e+03,  7.475e+03, -3.735e+03,
        -4.014e+03, -1.690e+03,  1.150e+04,  2.983e+03, -4.481e+03, -2.289e+03,
        -4.358e+03, -3.229e+03, -3.900e+03, -3.648e+03, -2.979e+03,  6.665e+03,
         9.802e+02, -2.909e+03,  8.889e+03, -3.997e+03, -4.482e+03,  1.279e+04,
         9.644e+03,  5.066e+03, -3.777e+03, -5.075e+03, -1.585e+03, -3.372e+01,
        -5.918e+03, -2.098e+03, -4.748e+03, -5.245e+03,  1.417e+03, -3.968e+03,
        -9.397e+02, -3.912e+03, -4.472e+03, -4.490e+03, -4.501e+03,  3.256e+03,
        -4.181e+03, -3.057e+03,  3.934e+02, -3.491e+03,  5.616e+03, -2.135e+03,
        -3.182e+03, -3.408e+03,  6.775e+00, -1.772e+03,  1.015e+03, -3.497e+03,
        -4.039e+03, -2.841e+03, -2.371e+03,  5.922e+03, -3.855e+03,  2.543e+03,
        -4.137e+03, -2.305e+03, -1.760e+03, -4.333e+03,  9.778e+02, -3.103e+03,
        -4.587e+03, -3.973e+03, -8.373e+02,  2.550e+03, -3.494e+01, -1.901e+03,
        -2.776e+03,  5.256e+03, -4.709e+03, -4.006e+03, -2.309e+02,  9.370e+03,
        -4.137e+03, -2.201e+03, -2.765e+03, -6.810e+02,  5.231e+03, -1.608e+03],
       device='cuda:0')
v tensor([1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 4.853e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 6.775e+00, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-3.715e+03],
         [-4.014e+03],
         [-3.431e+03],
         [-1.978e+03],
         [ 1.842e+03],
         [ 4.488e+03],
         [-3.332e+03],
         [-3.423e+03],
         [-4.136e+03],
         [ 5.057e+03]],

        [[-4.158e+03],
         [-2.128e+03],
         [ 3.729e+03],
         [-3.736e+03],
         [-1.977e+03],
         [ 5.207e+03],
         [ 1.750e+04],
         [-5.178e+03],
         [-5.442e+03],
         [-3.669e+03]],

        [[-6.151e+00],
         [-3.964e+03],
         [-3.127e+03],
         [-4.097e+03],
         [-3.692e+03],
         [ 1.812e+04],
         [-2.882e+03],
         [-1.816e+03],
         [-1.822e+03],
         [ 7.554e+03]],

        [[-6.519e+02],
         [-4.252e+03],
         [-2.417e+03],
         [-3.060e+03],
         [ 2.989e+03],
         [-2.657e+03],
         [ 9.471e+03],
         [ 2.419e+03],
         [-4.392e+03],
         [-2.985e+03]],

        [[-2.243e+03],
         [-3.330e+03],
         [ 2.268e+03],
         [-4.043e+03],
         [-2.470e+03],
         [-3.772e+03],
         [-4.502e+03],
         [ 1.359e+03],
         [-3.721e+03],
         [-2.008e+03]],

        [[ 3.777e+04],
         [-2.695e+03],
         [ 1.305e+04],
         [-4.018e+03],
         [-4.865e+03],
         [ 1.379e+04],
         [-3.799e+03],
         [-9.593e+02],
         [ 6.062e+03],
         [-2.689e+03]],

        [[ 2.033e+03],
         [-4.175e+03],
         [-2.507e+02],
         [ 3.187e+04],
         [ 6.333e+03],
         [-2.801e+03],
         [-3.453e+03],
         [-1.545e+03],
         [ 2.066e+03],
         [-1.984e+03]],

        [[-1.459e+03],
         [-3.050e+03],
         [-3.502e+03],
         [-4.300e+03],
         [-1.992e+03],
         [ 1.261e+03],
         [-4.465e+03],
         [ 9.948e+02],
         [-3.895e+03],
         [ 2.781e+03]],

        [[ 9.942e+03],
         [ 2.671e+02],
         [-3.500e+03],
         [-5.156e+03],
         [ 3.437e+02],
         [-5.498e+03],
         [-4.317e+03],
         [-4.055e+03],
         [-3.219e+03],
         [ 8.074e+03]],

        [[ 1.679e+03],
         [-7.434e+01],
         [-3.813e+03],
         [-1.516e+03],
         [-3.905e+03],
         [-2.126e+03],
         [-4.042e+03],
         [-3.541e+03],
         [-3.279e+03],
         [ 3.914e+04]],

        [[-5.175e+03],
         [-3.570e+03],
         [-4.061e+03],
         [-8.249e+02],
         [-4.142e+03],
         [-4.421e+03],
         [ 2.472e+03],
         [-2.258e+03],
         [ 2.139e+03],
         [ 4.987e+03]],

        [[ 1.555e+04],
         [-3.846e+03],
         [-2.842e+03],
         [-3.024e+03],
         [-2.605e+03],
         [-4.563e+03],
         [ 1.344e+04],
         [-4.004e+03],
         [ 1.039e+04],
         [ 1.772e+03]],

        [[-2.967e+03],
         [-1.028e+03],
         [ 3.121e+03],
         [-2.921e+03],
         [-2.630e+03],
         [-1.411e+03],
         [-2.887e+03],
         [ 8.770e+03],
         [-2.698e+03],
         [ 2.058e+03]],

        [[-4.004e+03],
         [-1.926e+03],
         [-3.684e+03],
         [-4.701e+03],
         [-3.744e+03],
         [ 1.731e+03],
         [ 6.127e+03],
         [-3.423e+03],
         [-1.626e+03],
         [-3.128e+03]],

        [[-1.190e+03],
         [-3.787e+03],
         [ 2.279e+03],
         [ 6.131e+02],
         [ 1.125e+03],
         [-5.231e+03],
         [-2.749e+03],
         [ 1.113e+03],
         [-4.248e+03],
         [ 1.146e+04]],

        [[-4.132e+03],
         [ 8.475e+03],
         [-1.409e+03],
         [-3.550e+03],
         [-1.396e+03],
         [-3.339e+03],
         [-3.921e+03],
         [-2.745e+03],
         [ 1.175e+04],
         [-7.704e+01]],

        [[-3.050e+03],
         [-3.341e+03],
         [-3.424e+03],
         [-3.041e+03],
         [-4.794e+03],
         [-3.804e+03],
         [ 9.720e+02],
         [-4.674e+03],
         [ 3.933e+03],
         [ 2.044e+04]],

        [[-2.603e+03],
         [-6.907e+02],
         [ 2.189e+03],
         [-1.392e+03],
         [-2.610e+03],
         [-4.914e+03],
         [-5.592e+03],
         [-2.854e+03],
         [ 4.436e+03],
         [ 1.184e+03]],

        [[-2.821e+03],
         [-3.804e+03],
         [-4.091e+03],
         [ 2.495e+03],
         [ 4.906e+02],
         [ 6.619e+02],
         [-4.632e+03],
         [-9.073e+02],
         [-3.917e+03],
         [-4.293e+03]],

        [[-2.981e+03],
         [ 2.998e+03],
         [-3.623e+03],
         [-5.284e+03],
         [-2.093e+03],
         [-3.202e+03],
         [-2.155e+03],
         [-1.581e+03],
         [-1.988e+03],
         [-1.602e+03]],

        [[ 3.142e+02],
         [-2.868e+03],
         [ 1.701e+03],
         [ 2.124e+04],
         [ 2.808e+03],
         [-4.000e+03],
         [ 1.059e+04],
         [-2.591e+03],
         [-6.911e+02],
         [ 4.466e+03]],

        [[-3.900e+03],
         [ 4.291e+03],
         [-4.397e+03],
         [-3.338e+03],
         [-5.354e+03],
         [ 4.186e+03],
         [ 9.619e+02],
         [-2.398e+03],
         [ 1.883e+04],
         [-2.891e+03]],

        [[ 2.377e+03],
         [-1.882e+03],
         [-3.516e+03],
         [-2.105e+03],
         [-3.825e+03],
         [-4.036e+03],
         [-4.474e+03],
         [-2.229e+03],
         [ 3.874e+03],
         [ 6.051e+02]],

        [[-3.652e+03],
         [-2.315e+03],
         [-3.478e+03],
         [ 7.909e+03],
         [ 7.879e+03],
         [-3.740e+03],
         [-3.405e+03],
         [-4.587e+03],
         [-1.965e+03],
         [ 3.959e+03]],

        [[-1.304e+03],
         [-4.410e+03],
         [-2.214e+03],
         [ 1.338e+04],
         [ 1.163e+03],
         [-2.691e+03],
         [-5.255e+03],
         [-3.114e+03],
         [ 1.197e+04],
         [-6.939e+01]],

        [[-3.780e+03],
         [-5.152e+03],
         [-1.026e+03],
         [-1.722e+03],
         [-4.732e+03],
         [-3.537e+03],
         [-3.938e+03],
         [ 3.240e+04],
         [-7.225e+02],
         [ 9.648e+03]],

        [[-5.077e+03],
         [-3.538e+03],
         [ 1.296e+04],
         [ 5.247e+03],
         [-3.977e+03],
         [-4.699e+03],
         [-3.017e+03],
         [-2.586e+03],
         [-4.703e+03],
         [ 3.321e+03]],

        [[ 8.151e+02],
         [-8.882e+02],
         [-2.841e+03],
         [-1.429e+03],
         [ 1.463e+04],
         [ 1.290e+04],
         [-2.479e+03],
         [ 5.272e+02],
         [-7.722e+01],
         [-8.651e+02]],

        [[-4.877e+03],
         [-2.401e+03],
         [ 4.271e+03],
         [ 1.142e+03],
         [ 2.010e+04],
         [-5.077e+03],
         [ 6.408e+03],
         [ 3.665e+03],
         [-3.589e+03],
         [-1.317e+03]],

        [[ 1.357e+04],
         [ 1.200e+04],
         [-2.193e+03],
         [-4.267e+03],
         [-2.393e+03],
         [ 2.527e+03],
         [ 1.883e+04],
         [-4.218e+03],
         [-2.094e+03],
         [-1.413e+03]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[ 2967.442],
        [ 1512.213],
        [ -307.861],
        [ 3849.301],
        [34841.284],
        [-1875.901],
        [-3740.480],
        [-3948.835],
        [-4564.631],
        [ 1135.898],
        [-2270.148],
        [ 2773.004],
        [-1611.308],
        [-3121.611],
        [-4688.863],
        [  926.851],
        [-3331.786],
        [-3018.641],
        [-4767.861],
        [-1209.653],
        [-1174.357],
        [-2814.478],
        [-4500.643],
        [-4840.063],
        [ 2701.111],
        [-3128.563],
        [-4592.224],
        [  433.740],
        [-1229.374],
        [ -940.236]], device='cuda:0')
v tensor([[1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-0.043, -0.169,  0.424,  ..., -0.363,  0.580, -0.191],
        [-0.079,  0.735,  0.367,  ..., -0.859,  0.044,  0.050],
        [ 0.102, -0.617,  0.467,  ..., -0.500, -0.209,  0.328],
        ...,
        [ 0.043, -0.267, -0.335,  ...,  0.885,  0.018,  0.023],
        [ 0.243,  0.692,  0.296,  ..., -0.220,  0.208, -0.084],
        [-0.159,  0.144,  0.085,  ...,  1.024,  0.299, -0.219]],
       device='cuda:0')
s after update for 1 param tensor([[1.969, 1.398, 2.071,  ..., 1.836, 1.852, 1.771],
        [2.417, 1.898, 1.158,  ..., 1.518, 2.222, 1.515],
        [2.112, 1.591, 1.453,  ..., 2.464, 1.861, 1.613],
        ...,
        [1.843, 1.762, 1.720,  ..., 1.916, 1.570, 1.797],
        [1.808, 1.786, 1.952,  ..., 1.640, 1.880, 1.544],
        [2.240, 1.485, 1.898,  ..., 1.751, 1.383, 2.662]], device='cuda:0')
b after update for 1 param tensor([[185.594, 156.362, 190.318,  ..., 179.197, 179.987, 175.979],
        [205.612, 182.207, 142.319,  ..., 162.940, 197.121, 162.772],
        [192.184, 166.815, 159.406,  ..., 207.571, 180.400, 167.958],
        ...,
        [179.548, 175.560, 173.427,  ..., 183.079, 165.688, 177.303],
        [177.818, 176.742, 184.745,  ..., 169.374, 181.331, 164.348],
        [197.929, 161.162, 182.176,  ..., 174.999, 155.516, 215.772]],
       device='cuda:0')
clipping threshold 2.581682271365785
a after update for 1 param tensor([-4.798e-01,  7.052e-01, -4.584e-01, -3.153e-01, -6.031e-01,  2.132e-01,
        -3.122e-01,  1.028e+00,  4.542e-01, -2.482e-01,  1.838e-01,  4.551e-01,
        -1.285e+00,  1.241e+00,  5.988e-01,  2.537e-01,  9.847e-02,  1.605e-01,
         8.767e-01,  6.182e-02, -4.200e-01,  2.161e-01,  1.711e+00,  1.294e+00,
         1.052e+00, -1.591e-02, -9.678e-01, -2.624e-01,  2.901e-01,  6.715e-01,
        -1.077e+00,  1.221e+00, -6.708e-01,  7.184e-02,  6.799e-01, -2.584e-01,
         4.897e-01, -1.382e+00, -9.782e-01,  5.499e-01, -3.538e-01, -5.070e-01,
        -7.293e-01, -9.715e-01,  2.107e-01,  5.880e-01,  9.362e-01,  1.385e-02,
        -1.067e+00,  9.249e-02, -2.603e-04,  1.171e+00, -2.589e-01,  1.801e-01,
        -1.032e+00,  6.065e-01, -6.343e-01,  6.274e-01,  1.536e-01,  5.622e-01,
        -7.686e-01, -3.504e-02, -6.870e-01, -7.881e-01, -1.797e+00,  1.739e+00,
        -1.299e-03, -3.012e-01,  1.035e+00, -8.954e-02, -1.179e-01, -9.541e-01,
         6.614e-01,  4.464e-01,  3.027e-01,  9.478e-01, -8.104e-02,  8.273e-01,
        -5.068e-01, -9.994e-02, -1.034e-01,  4.269e-01, -1.195e-01,  9.767e-01,
        -7.682e-01, -1.141e+00,  2.547e-01, -4.198e-01, -7.568e-01, -1.541e+00,
         3.240e-01,  6.391e-01,  2.386e-02,  1.354e-01, -3.783e-01, -3.632e-01,
         1.788e-01, -5.688e-01, -2.195e-01,  9.437e-01, -5.287e-02,  1.996e+00,
        -1.177e-01, -8.162e-01,  3.209e-01, -2.949e-03, -6.024e-01,  5.529e-01,
         5.161e-01, -8.766e-01,  4.176e-01,  3.928e-01, -1.252e+00, -6.277e-01,
        -6.134e-01,  4.247e-01,  8.103e-01, -3.413e-01,  4.759e-01, -3.084e-01,
        -7.626e-01, -9.252e-02, -3.190e-01,  8.326e-02,  7.490e-02,  1.660e+00,
         2.142e-01,  5.520e-02,  1.896e-02, -2.509e-01, -1.610e-01,  2.514e-02,
         4.440e-02,  8.315e-01,  1.353e-01, -7.086e-01, -1.379e-01,  1.075e+00,
         2.300e-02, -2.778e-01, -6.562e-01, -3.134e-01, -8.267e-01,  6.676e-01,
         1.929e-02, -2.473e-01,  7.545e-01, -2.196e-01,  6.875e-02,  6.719e-01,
         3.236e-01, -1.013e-01,  1.017e+00, -3.057e-01,  3.175e-01, -7.633e-02,
         2.904e-01, -3.268e-01, -1.119e+00, -9.427e-01,  1.228e-01,  1.490e-01,
         3.549e-01,  2.901e-01,  5.161e-02,  3.664e-02, -6.693e-01, -3.029e-01,
        -2.171e-02,  4.304e-01, -1.665e-01, -1.623e-01, -2.099e-01, -1.207e+00,
        -8.373e-02,  9.262e-01,  2.591e-01, -1.327e-01,  4.029e-01,  6.056e-01,
        -9.005e-02, -1.018e-01,  4.840e-01,  3.298e-01, -4.427e-01, -6.377e-01,
        -5.107e-01,  1.241e+00, -5.142e-01,  7.958e-01,  1.626e-01,  7.365e-01,
         2.795e-01, -5.172e-01, -4.947e-01,  9.158e-01,  9.111e-01,  8.443e-01,
         4.204e-01,  8.365e-01,  7.693e-01, -5.331e-01,  9.390e-01, -2.243e-01,
         1.514e+00,  1.243e+00,  6.037e-01, -4.139e-01, -4.295e-02,  3.485e-01,
         2.401e-01,  1.530e+00,  7.761e-01, -4.784e-01,  4.574e-01,  2.455e-01,
        -7.421e-01, -6.216e-01,  6.334e-01, -5.007e-01, -7.219e-01, -3.509e-01,
         8.913e-01, -1.575e-01,  9.304e-02,  5.324e-01,  6.142e-01,  2.948e-01,
         2.357e-01,  8.148e-01,  8.367e-02, -5.017e-01, -6.265e-01,  2.139e-01,
        -2.942e-01, -1.076e+00,  2.717e-01, -4.442e-01, -9.964e-02,  4.963e-01,
         1.090e+00,  6.540e-01,  3.390e-01,  6.414e-01, -1.005e+00,  5.762e-01,
         5.754e-01,  7.044e-01, -1.614e+00,  1.103e-01, -1.090e+00, -2.931e-01,
         1.568e+00,  2.562e-01, -2.623e-01,  7.414e-01, -5.274e-02,  1.245e+00,
         7.665e-01, -5.521e-01,  7.817e-02, -3.882e-01,  1.246e-01, -9.590e-02,
        -1.060e+00, -1.436e+00, -9.912e-01,  3.399e-01,  9.702e-02, -7.047e-01,
         4.180e-01,  1.131e-02, -1.386e+00, -3.380e-01,  9.488e-02, -1.030e+00,
         3.869e-01, -3.040e-02, -1.710e-01, -1.543e+00,  3.119e-01, -7.183e-01,
        -2.319e-01, -4.818e-02,  3.458e-01, -9.859e-01,  3.160e-01,  7.808e-01,
         3.963e-01, -1.180e+00,  1.335e-01, -1.393e+00, -1.808e+00, -1.267e-01,
        -1.320e-01,  6.511e-01, -1.100e+00,  3.949e-01,  1.477e+00,  8.508e-01],
       device='cuda:0')
s after update for 1 param tensor([1.595, 1.875, 2.029, 1.819, 1.388, 1.521, 2.297, 1.824, 1.767, 2.179,
        2.279, 1.645, 1.402, 1.377, 2.087, 1.639, 1.564, 2.051, 1.842, 1.770,
        2.110, 1.244, 1.755, 1.913, 1.948, 2.017, 2.058, 1.855, 1.743, 1.916,
        2.008, 1.523, 0.831, 1.458, 2.037, 2.200, 1.283, 1.701, 1.324, 2.063,
        1.644, 1.932, 1.800, 1.318, 2.365, 1.665, 1.870, 2.316, 2.120, 1.523,
        1.936, 1.797, 1.684, 2.121, 1.956, 2.152, 2.000, 1.985, 2.039, 1.910,
        1.745, 1.952, 1.193, 1.828, 1.530, 1.681, 1.965, 1.417, 2.009, 1.645,
        1.909, 1.885, 1.295, 1.758, 1.588, 1.492, 2.292, 1.503, 1.918, 2.062,
        1.739, 1.855, 1.827, 1.931, 1.833, 1.532, 1.718, 2.016, 1.319, 1.549,
        1.871, 2.071, 1.183, 1.185, 1.525, 1.623, 1.498, 1.775, 1.770, 1.601,
        2.099, 2.014, 1.422, 1.526, 1.154, 1.865, 2.015, 1.866, 1.930, 2.474,
        1.957, 1.378, 1.316, 2.290, 1.199, 2.250, 2.299, 1.628, 1.745, 1.592,
        1.690, 1.922, 1.752, 1.903, 1.630, 1.475, 1.437, 1.786, 1.988, 1.324,
        1.779, 2.187, 1.702, 1.900, 1.873, 1.566, 1.739, 1.557, 0.653, 1.740,
        2.160, 1.538, 1.650, 1.706, 2.073, 2.195, 1.311, 2.044, 1.689, 1.871,
        1.858, 1.558, 2.171, 1.667, 1.593, 1.574, 2.187, 2.183, 1.597, 1.758,
        1.438, 1.523, 0.981, 1.607, 0.994, 1.687, 1.497, 2.067, 1.872, 1.694,
        1.962, 1.940, 1.799, 1.423, 1.275, 1.855, 1.486, 1.429, 1.636, 1.355,
        1.830, 1.829, 2.242, 1.404, 1.718, 1.304, 1.414, 1.214, 1.895, 1.754,
        1.932, 1.634, 2.481, 2.028, 1.983, 2.095, 1.759, 1.507, 1.626, 1.681,
        1.794, 1.911, 1.997, 1.787, 2.011, 1.832, 1.784, 1.673, 1.933, 1.234,
        1.649, 2.038, 1.698, 1.778, 1.084, 1.324, 1.605, 0.765, 1.446, 2.230,
        2.064, 2.341, 2.082, 1.787, 1.980, 2.064, 1.865, 1.677, 1.751, 1.580,
        1.729, 1.677, 1.493, 1.543, 1.965, 1.247, 2.137, 1.690, 2.014, 2.061,
        2.035, 2.124, 1.470, 1.976, 1.976, 1.620, 2.303, 1.517, 1.857, 2.115,
        1.819, 1.702, 1.690, 1.772, 1.749, 2.014, 1.910, 1.720, 1.635, 1.523,
        1.789, 1.358, 2.010, 1.933, 1.419, 1.502, 1.935, 0.944, 2.326, 1.566,
        1.731, 2.010, 1.191, 2.095, 1.656, 1.652, 1.750, 1.133, 1.395, 1.904,
        1.699, 1.389, 1.915, 1.550, 2.239, 1.430, 1.492, 1.466, 1.498, 2.136,
        1.891, 1.564, 1.593, 2.031, 1.615, 1.195, 1.711, 1.604, 1.855, 1.396],
       device='cuda:0')
b after update for 1 param tensor([167.030, 181.067, 188.384, 178.379, 155.807, 163.078, 200.443, 178.628,
        175.810, 195.211, 199.655, 169.637, 156.580, 155.165, 191.057, 169.292,
        165.368, 189.374, 179.485, 175.926, 192.104, 147.529, 175.215, 182.913,
        184.595, 187.832, 189.719, 180.096, 174.607, 183.034, 187.417, 163.195,
        120.542, 159.700, 188.750, 196.137, 149.817, 172.486, 152.160, 189.940,
        169.548, 183.839, 177.414, 151.813, 203.396, 170.637, 180.862, 201.239,
        192.578, 163.231, 184.031, 177.305, 171.617, 192.583, 184.937, 194.001,
        187.020, 186.345, 188.846, 182.791, 174.700, 184.770, 144.425, 178.784,
        163.580, 171.466, 185.393, 157.422, 187.464, 169.629, 182.711, 181.588,
        150.478, 175.346, 166.639, 161.530, 200.228, 162.129, 183.167, 189.898,
        174.382, 180.138, 178.734, 183.760, 179.057, 163.664, 173.361, 187.762,
        151.857, 164.584, 180.897, 190.328, 143.839, 143.974, 163.307, 168.473,
        161.888, 176.200, 175.922, 167.342, 191.578, 187.658, 157.696, 163.348,
        142.038, 180.600, 187.705, 180.655, 183.704, 208.012, 184.992, 155.252,
        151.688, 200.118, 144.807, 198.390, 200.541, 168.764, 174.689, 166.865,
        171.912, 183.358, 175.025, 182.442, 168.868, 160.635, 158.540, 176.732,
        186.445, 152.162, 176.408, 195.552, 172.550, 182.271, 180.998, 165.472,
        174.403, 165.021, 106.831, 174.427, 194.341, 164.005, 169.891, 172.729,
        190.389, 195.915, 151.450, 189.074, 171.890, 180.914, 180.252, 165.091,
        194.847, 170.748, 166.908, 165.892, 195.585, 195.410, 167.103, 175.324,
        158.611, 163.185, 130.956, 167.639, 131.854, 171.746, 161.809, 190.143,
        180.957, 172.137, 185.225, 184.223, 177.403, 157.743, 149.336, 180.111,
        161.194, 158.107, 169.131, 153.919, 178.900, 178.835, 198.022, 156.674,
        173.361, 151.042, 157.281, 145.699, 182.043, 175.145, 183.840, 169.053,
        208.303, 188.349, 186.212, 191.434, 175.380, 162.360, 168.660, 171.473,
        177.109, 182.832, 186.888, 176.793, 187.521, 178.979, 176.636, 171.043,
        183.852, 146.903, 169.823, 188.808, 172.342, 176.356, 137.708, 152.147,
        167.554, 115.701, 159.027, 197.474, 190.006, 202.364, 190.820, 176.780,
        186.095, 190.000, 180.603, 171.258, 175.017, 166.248, 173.888, 171.252,
        161.582, 164.274, 185.364, 147.668, 193.346, 171.898, 187.690, 189.847,
        188.653, 192.753, 160.316, 185.922, 185.880, 168.298, 200.694, 162.898,
        180.225, 192.308, 178.359, 172.525, 171.917, 176.053, 174.891, 187.662,
        182.761, 173.456, 169.082, 163.230, 176.907, 154.130, 187.507, 183.875,
        157.561, 162.053, 183.980, 128.508, 201.693, 165.492, 173.973, 187.497,
        144.336, 191.427, 170.194, 169.976, 174.946, 140.773, 156.218, 182.477,
        172.391, 155.842, 183.021, 164.635, 197.899, 158.119, 161.552, 160.118,
        161.887, 193.286, 181.873, 165.368, 166.900, 188.470, 168.073, 144.591,
        172.985, 167.473, 180.115, 156.247], device='cuda:0')
clipping threshold 2.581682271365785
a after update for 1 param tensor([[[-0.168],
         [ 1.232],
         [-0.123],
         [ 0.325],
         [ 0.203],
         [-0.263],
         [-0.845],
         [ 0.062],
         [ 0.225],
         [ 1.049]],

        [[ 0.150],
         [-0.956],
         [ 1.947],
         [-0.900],
         [ 0.582],
         [-0.106],
         [ 0.210],
         [-0.371],
         [-0.963],
         [ 0.880]],

        [[-0.646],
         [ 0.270],
         [ 0.975],
         [ 1.102],
         [ 0.249],
         [ 0.488],
         [ 0.309],
         [ 0.092],
         [-0.797],
         [-0.409]],

        [[ 0.157],
         [-1.214],
         [-1.064],
         [ 1.167],
         [-0.233],
         [ 1.179],
         [ 0.042],
         [ 0.416],
         [ 0.627],
         [ 0.161]],

        [[ 0.751],
         [-1.464],
         [ 0.478],
         [ 0.164],
         [ 0.655],
         [ 1.052],
         [-0.368],
         [-0.269],
         [ 0.741],
         [ 0.593]],

        [[-0.210],
         [-0.917],
         [-0.036],
         [-0.212],
         [-0.630],
         [-1.056],
         [-0.605],
         [-0.816],
         [-0.108],
         [-0.733]],

        [[-0.658],
         [ 0.315],
         [-0.511],
         [-0.594],
         [ 1.062],
         [ 0.489],
         [ 0.825],
         [-0.286],
         [-0.522],
         [ 0.289]],

        [[-0.166],
         [ 0.657],
         [ 0.162],
         [-0.848],
         [ 0.197],
         [-0.907],
         [-0.683],
         [ 0.716],
         [-1.166],
         [ 0.306]],

        [[-0.060],
         [ 0.412],
         [-0.913],
         [-0.128],
         [ 0.537],
         [ 2.022],
         [ 0.237],
         [ 0.630],
         [-0.126],
         [-0.214]],

        [[ 0.290],
         [ 0.693],
         [ 0.320],
         [ 1.079],
         [ 1.104],
         [ 0.264],
         [ 0.362],
         [ 0.035],
         [ 0.579],
         [ 1.477]],

        [[ 1.138],
         [-0.845],
         [ 1.338],
         [-0.427],
         [-0.245],
         [ 0.665],
         [ 0.345],
         [-0.293],
         [ 0.506],
         [ 1.229]],

        [[-0.800],
         [-0.449],
         [ 0.588],
         [ 0.673],
         [-0.630],
         [-0.070],
         [ 0.112],
         [ 1.589],
         [ 1.375],
         [-0.747]],

        [[-0.167],
         [ 1.234],
         [-0.504],
         [ 1.097],
         [ 0.567],
         [-0.578],
         [-0.337],
         [ 1.074],
         [ 0.851],
         [-0.599]],

        [[ 0.924],
         [ 0.825],
         [-0.153],
         [-0.148],
         [ 0.610],
         [ 0.479],
         [ 1.091],
         [ 0.356],
         [-0.531],
         [-0.719]],

        [[-0.740],
         [ 0.281],
         [-0.513],
         [-0.766],
         [-0.071],
         [-0.237],
         [ 0.939],
         [ 1.493],
         [ 0.400],
         [-0.220]],

        [[ 1.210],
         [-0.270],
         [-0.116],
         [ 0.532],
         [-0.995],
         [ 0.477],
         [-0.568],
         [ 0.693],
         [ 0.156],
         [ 0.091]],

        [[ 2.556],
         [-0.396],
         [-0.625],
         [ 0.237],
         [ 1.151],
         [ 0.985],
         [ 0.329],
         [-0.061],
         [-0.853],
         [ 0.232]],

        [[-0.143],
         [ 0.066],
         [ 0.034],
         [-0.528],
         [-0.272],
         [ 0.531],
         [ 1.232],
         [-0.948],
         [ 0.767],
         [-1.301]],

        [[-0.202],
         [ 0.302],
         [-0.539],
         [-0.262],
         [ 0.204],
         [ 0.825],
         [ 1.579],
         [-0.069],
         [-0.051],
         [ 1.384]],

        [[ 0.374],
         [ 0.233],
         [ 0.014],
         [ 0.868],
         [-0.179],
         [ 0.288],
         [ 0.329],
         [-0.272],
         [-0.608],
         [ 0.703]],

        [[-0.284],
         [ 0.624],
         [ 1.019],
         [-0.206],
         [ 0.467],
         [ 0.596],
         [-0.345],
         [ 0.205],
         [-0.048],
         [ 0.940]],

        [[-1.694],
         [ 0.239],
         [ 0.378],
         [-0.757],
         [ 0.054],
         [-0.731],
         [-0.418],
         [-0.495],
         [ 0.007],
         [-1.137]],

        [[-0.160],
         [ 1.021],
         [ 0.188],
         [ 0.277],
         [ 0.110],
         [-0.712],
         [-0.085],
         [-0.424],
         [ 1.078],
         [ 0.041]],

        [[ 1.558],
         [ 0.558],
         [-0.375],
         [ 1.004],
         [-0.413],
         [-0.776],
         [-0.641],
         [-0.752],
         [-1.217],
         [ 1.246]],

        [[-0.594],
         [ 0.295],
         [ 0.612],
         [ 0.575],
         [ 0.371],
         [ 0.006],
         [-0.598],
         [-0.795],
         [ 0.144],
         [-0.421]],

        [[-0.384],
         [ 0.253],
         [-1.327],
         [-0.537],
         [ 0.236],
         [-0.910],
         [ 0.235],
         [-0.537],
         [ 0.226],
         [ 0.963]],

        [[ 0.068],
         [ 0.413],
         [-0.095],
         [-0.746],
         [ 0.158],
         [-0.618],
         [ 0.234],
         [-1.085],
         [-1.071],
         [ 1.018]],

        [[-0.554],
         [ 0.102],
         [-1.999],
         [ 1.317],
         [-0.196],
         [-0.972],
         [-0.872],
         [ 0.263],
         [-0.984],
         [ 1.726]],

        [[-0.787],
         [ 0.134],
         [-0.382],
         [-0.044],
         [ 0.354],
         [-0.323],
         [-1.058],
         [ 0.718],
         [ 0.205],
         [ 0.523]],

        [[-0.284],
         [-0.403],
         [-0.085],
         [ 0.504],
         [ 1.083],
         [-0.644],
         [ 1.515],
         [ 0.330],
         [ 0.123],
         [ 0.262]]], device='cuda:0')
s after update for 1 param tensor([[[1.802],
         [1.626],
         [1.524],
         [1.930],
         [1.894],
         [2.130],
         [1.411],
         [1.470],
         [1.694],
         [1.772]],

        [[1.664],
         [1.784],
         [1.993],
         [1.512],
         [1.548],
         [2.192],
         [2.076],
         [2.018],
         [2.160],
         [1.633]],

        [[1.154],
         [1.542],
         [1.887],
         [1.706],
         [1.777],
         [1.901],
         [1.454],
         [2.001],
         [0.751],
         [1.772]],

        [[1.975],
         [1.825],
         [1.176],
         [1.191],
         [1.980],
         [1.183],
         [1.726],
         [2.047],
         [1.804],
         [1.313]],

        [[1.580],
         [1.514],
         [1.767],
         [1.809],
         [1.438],
         [1.642],
         [1.752],
         [1.850],
         [1.599],
         [1.592]],

        [[2.118],
         [1.098],
         [2.035],
         [1.609],
         [1.960],
         [2.056],
         [1.978],
         [1.665],
         [1.885],
         [2.013]],

        [[1.859],
         [1.635],
         [1.795],
         [2.358],
         [1.864],
         [1.280],
         [1.804],
         [1.224],
         [1.813],
         [0.857]],

        [[1.126],
         [1.721],
         [1.503],
         [1.865],
         [1.522],
         [1.839],
         [1.834],
         [1.852],
         [1.516],
         [1.720]],

        [[2.100],
         [1.666],
         [1.605],
         [2.243],
         [1.978],
         [2.190],
         [1.739],
         [1.980],
         [1.521],
         [1.864]],

        [[1.728],
         [1.508],
         [1.658],
         [0.930],
         [1.650],
         [1.776],
         [1.891],
         [1.854],
         [1.919],
         [2.166]],

        [[2.214],
         [1.450],
         [1.892],
         [1.201],
         [1.616],
         [1.727],
         [2.212],
         [2.130],
         [2.373],
         [1.765]],

        [[2.427],
         [1.507],
         [1.361],
         [1.236],
         [1.560],
         [1.928],
         [1.765],
         [1.730],
         [1.958],
         [1.585]],

        [[1.396],
         [1.445],
         [2.210],
         [1.554],
         [1.695],
         [1.166],
         [1.279],
         [1.923],
         [2.162],
         [2.012]],

        [[1.567],
         [1.342],
         [1.519],
         [1.854],
         [1.976],
         [2.372],
         [1.930],
         [1.496],
         [2.045],
         [1.611]],

        [[1.994],
         [1.568],
         [2.229],
         [2.056],
         [1.297],
         [2.197],
         [1.283],
         [1.653],
         [1.953],
         [1.919]],

        [[1.683],
         [2.032],
         [1.771],
         [1.937],
         [1.705],
         [1.457],
         [1.622],
         [1.165],
         [2.036],
         [1.149]],

        [[1.194],
         [1.773],
         [1.680],
         [1.395],
         [2.166],
         [1.999],
         [1.619],
         [1.866],
         [2.581],
         [2.219]],

        [[1.421],
         [1.592],
         [1.336],
         [2.050],
         [1.341],
         [1.916],
         [2.245],
         [1.528],
         [1.913],
         [2.084]],

        [[1.133],
         [2.108],
         [1.681],
         [2.189],
         [2.051],
         [1.732],
         [1.802],
         [0.949],
         [1.533],
         [1.813]],

        [[1.393],
         [1.744],
         [1.606],
         [2.073],
         [1.992],
         [1.682],
         [1.980],
         [1.081],
         [0.811],
         [1.034]],

        [[1.979],
         [1.772],
         [1.948],
         [2.037],
         [2.312],
         [1.644],
         [1.889],
         [1.239],
         [1.453],
         [2.099]],

        [[1.623],
         [1.749],
         [2.110],
         [1.703],
         [2.085],
         [2.066],
         [1.723],
         [1.267],
         [1.711],
         [1.778]],

        [[1.609],
         [1.847],
         [1.475],
         [1.411],
         [1.511],
         [1.723],
         [1.767],
         [1.138],
         [2.135],
         [1.866]],

        [[1.539],
         [2.225],
         [1.358],
         [2.118],
         [2.246],
         [2.201],
         [1.397],
         [2.017],
         [0.981],
         [1.712]],

        [[1.864],
         [1.821],
         [0.945],
         [1.557],
         [1.981],
         [1.048],
         [2.046],
         [1.598],
         [1.769],
         [1.635]],

        [[1.506],
         [2.248],
         [1.495],
         [1.319],
         [1.871],
         [1.645],
         [1.533],
         [2.080],
         [1.356],
         [2.049]],

        [[2.068],
         [1.399],
         [2.066],
         [2.445],
         [1.556],
         [1.944],
         [1.651],
         [1.441],
         [2.135],
         [1.983]],

        [[1.699],
         [1.654],
         [1.975],
         [1.850],
         [1.787],
         [2.299],
         [1.867],
         [2.040],
         [1.339],
         [1.872]],

        [[1.982],
         [1.260],
         [1.913],
         [2.157],
         [2.348],
         [1.977],
         [1.858],
         [1.514],
         [1.779],
         [1.370]],

        [[2.005],
         [2.352],
         [2.029],
         [1.662],
         [1.505],
         [1.526],
         [1.736],
         [2.102],
         [1.585],
         [1.243]]], device='cuda:0')
b after update for 1 param tensor([[[177.525],
         [168.658],
         [163.280],
         [183.741],
         [181.994],
         [193.004],
         [157.085],
         [160.341],
         [172.132],
         [176.034]],

        [[170.582],
         [176.616],
         [186.711],
         [162.620],
         [164.557],
         [195.790],
         [190.561],
         [187.846],
         [194.352],
         [168.994]],

        [[142.060],
         [164.237],
         [181.662],
         [172.744],
         [176.306],
         [182.362],
         [159.483],
         [187.094],
         [114.575],
         [176.039]],

        [[185.862],
         [178.659],
         [143.415],
         [144.325],
         [186.101],
         [143.867],
         [173.727],
         [189.227],
         [177.643],
         [151.564]],

        [[166.228],
         [162.739],
         [175.782],
         [177.873],
         [158.573],
         [169.444],
         [175.063],
         [179.877],
         [167.221],
         [166.837]],

        [[192.458],
         [138.566],
         [188.642],
         [167.760],
         [185.154],
         [189.611],
         [185.993],
         [170.670],
         [181.553],
         [187.614]],

        [[180.332],
         [169.083],
         [177.190],
         [203.059],
         [180.543],
         [149.645],
         [177.639],
         [146.282],
         [178.056],
         [122.445]],

        [[140.317],
         [173.487],
         [162.105],
         [180.608],
         [163.146],
         [179.349],
         [179.090],
         [179.992],
         [162.837],
         [173.447]],

        [[191.659],
         [170.714],
         [167.564],
         [198.072],
         [185.996],
         [195.709],
         [174.394],
         [186.074],
         [163.125],
         [180.569]],

        [[173.852],
         [162.417],
         [170.279],
         [127.508],
         [169.887],
         [176.252],
         [181.836],
         [180.063],
         [183.201],
         [194.655]],

        [[196.774],
         [159.258],
         [181.917],
         [144.921],
         [168.141],
         [173.775],
         [196.671],
         [193.018],
         [203.736],
         [175.702]],

        [[206.046],
         [162.373],
         [154.279],
         [147.043],
         [165.202],
         [183.640],
         [175.684],
         [173.931],
         [185.067],
         [166.482]],

        [[156.275],
         [158.972],
         [196.595],
         [164.841],
         [172.173],
         [142.784],
         [149.541],
         [183.402],
         [194.474],
         [187.569]],

        [[165.541],
         [153.229],
         [162.991],
         [180.052],
         [185.910],
         [203.688],
         [183.737],
         [161.744],
         [189.120],
         [167.849]],

        [[186.752],
         [165.614],
         [197.455],
         [189.645],
         [150.583],
         [196.025],
         [149.819],
         [170.043],
         [184.823],
         [183.186]],

        [[171.542],
         [188.524],
         [175.993],
         [184.034],
         [172.706],
         [159.621],
         [168.410],
         [142.720],
         [188.699],
         [141.772]],

        [[144.499],
         [176.086],
         [171.423],
         [156.220],
         [194.634],
         [186.990],
         [168.275],
         [180.654],
         [212.444],
         [196.982]],

        [[157.659],
         [166.843],
         [152.880],
         [189.359],
         [153.165],
         [183.062],
         [198.155],
         [163.469],
         [182.912],
         [190.892]],

        [[140.765],
         [191.992],
         [171.462],
         [195.662],
         [189.391],
         [174.030],
         [177.538],
         [128.833],
         [163.759],
         [178.080]],

        [[156.096],
         [174.628],
         [167.615],
         [190.429],
         [186.654],
         [171.531],
         [186.072],
         [137.468],
         [119.080],
         [134.494]],

        [[186.020],
         [176.024],
         [184.575],
         [188.733],
         [201.097],
         [169.551],
         [181.756],
         [147.208],
         [159.394],
         [191.594]],

        [[168.490],
         [174.917],
         [192.106],
         [172.598],
         [190.939],
         [190.064],
         [173.576],
         [148.875],
         [172.983],
         [176.352]],

        [[167.773],
         [179.725],
         [160.628],
         [157.113],
         [162.542],
         [173.590],
         [175.800],
         [141.080],
         [193.215],
         [180.642]],

        [[164.062],
         [197.249],
         [154.085],
         [192.462],
         [198.184],
         [196.217],
         [156.311],
         [187.810],
         [130.958],
         [173.047]],

        [[180.570],
         [178.472],
         [128.530],
         [165.006],
         [186.146],
         [135.380],
         [189.142],
         [167.189],
         [175.900],
         [169.094]],

        [[162.288],
         [198.268],
         [161.718],
         [151.894],
         [180.894],
         [169.593],
         [163.744],
         [190.736],
         [154.002],
         [189.297]],

        [[190.192],
         [156.396],
         [190.067],
         [206.768],
         [164.956],
         [184.376],
         [169.903],
         [158.750],
         [193.219],
         [186.253]],

        [[172.363],
         [170.077],
         [185.872],
         [179.862],
         [176.796],
         [200.499],
         [180.725],
         [188.902],
         [153.010],
         [180.944]],

        [[186.190],
         [148.469],
         [182.904],
         [194.213],
         [202.653],
         [185.971],
         [180.250],
         [162.711],
         [176.389],
         [154.768]],

        [[187.275],
         [202.808],
         [188.364],
         [170.491],
         [162.249],
         [163.350],
         [174.269],
         [191.735],
         [166.479],
         [147.425]]], device='cuda:0')
clipping threshold 2.581682271365785
a after update for 1 param tensor([[-0.467],
        [-0.612],
        [-0.739],
        [-0.320],
        [ 0.204],
        [ 0.221],
        [ 0.582],
        [-0.073],
        [ 0.110],
        [ 0.466],
        [-0.605],
        [ 0.922],
        [-0.538],
        [-0.201],
        [ 0.062],
        [-0.287],
        [-0.945],
        [-0.329],
        [ 0.289],
        [ 0.638],
        [ 0.483],
        [ 0.792],
        [ 0.908],
        [-0.474],
        [-0.119],
        [ 0.546],
        [-0.275],
        [-0.796],
        [ 1.400],
        [-0.172]], device='cuda:0')
s after update for 1 param tensor([[2.132],
        [2.026],
        [1.544],
        [2.258],
        [2.387],
        [1.610],
        [1.501],
        [1.536],
        [1.812],
        [1.650],
        [1.184],
        [1.783],
        [1.583],
        [1.708],
        [1.828],
        [2.001],
        [1.331],
        [1.682],
        [1.913],
        [1.881],
        [1.834],
        [1.617],
        [1.778],
        [1.896],
        [2.280],
        [1.303],
        [1.917],
        [1.763],
        [1.483],
        [2.038]], device='cuda:0')
b after update for 1 param tensor([[193.086],
        [188.217],
        [164.338],
        [198.741],
        [204.304],
        [167.799],
        [161.998],
        [163.928],
        [178.024],
        [169.881],
        [143.886],
        [176.576],
        [166.400],
        [172.826],
        [178.808],
        [187.077],
        [152.565],
        [171.531],
        [182.913],
        [181.377],
        [179.077],
        [168.193],
        [176.319],
        [182.076],
        [199.690],
        [150.982],
        [183.118],
        [175.583],
        [161.030],
        [188.816]], device='cuda:0')
clipping threshold 2.581682271365785
cuda
Objective function 159.53 = squared loss an data 95.36 + 0.5*rho*h**2 51.813018 + alpha*h 9.230928 + L2reg 2.76 + L1reg 0.36 ; SHD = 173 ; DAG True
Proportion of microbatches that were clipped  0.7854238099035165
iteration 3 in inner loop, alpha 90.67987310402728 rho 10000.0 h 0.10179687405446458
iteration 3 in outer loop, alpha = 1108.648613648673, rho = 10000.0, h = 0.10179687405446458
cuda
9630
cuda
Objective function 263.16 = squared loss an data 95.36 + 0.5*rho*h**2 51.813018 + alpha*h 112.856963 + L2reg 2.76 + L1reg 0.36 ; SHD = 173 ; DAG True
||w||^2 4937177940157.979
exp ma of ||w||^2 1313906441196.5864
||w|| 2221976.1340207905
exp ma of ||w|| 556553.2871269742
||w||^2 11.543732699084664
exp ma of ||w||^2 1102.1082080319115
||w|| 3.3976069076755575
exp ma of ||w|| 4.1359394598929535
||w||^2 6.90582833425756
exp ma of ||w||^2 10.613505409749601
||w|| 2.6278942776028034
exp ma of ||w|| 3.2055396001785104
||w||^2 6.831129369207868
exp ma of ||w||^2 10.62984716004749
||w|| 2.6136429307018716
exp ma of ||w|| 3.211949519440869
||w||^2 8.357310078170212
exp ma of ||w||^2 10.334595524593901
||w|| 2.890901257077144
exp ma of ||w|| 3.162391468138811
||w||^2 12.657928960862778
exp ma of ||w||^2 12.078514225094874
||w|| 3.5577983305497765
exp ma of ||w|| 3.4159066528596336
||w||^2 16.716870439735548
exp ma of ||w||^2 11.836251899162779
||w|| 4.0886269626533
exp ma of ||w|| 3.3738726093201534
||w||^2 14.41366335795508
exp ma of ||w||^2 11.454119039158504
||w|| 3.796533070836481
exp ma of ||w|| 3.3355523561562057
||w||^2 13.122155878839605
exp ma of ||w||^2 11.54661951392936
||w|| 3.6224516392685775
exp ma of ||w|| 3.351646624864547
||w||^2 7.912645698717658
exp ma of ||w||^2 10.961024927844726
||w|| 2.812942533845592
exp ma of ||w|| 3.2607363807515464
||w||^2 9.89514447008424
exp ma of ||w||^2 12.828538234904206
||w|| 3.145654855524401
exp ma of ||w|| 3.543075780536146
cuda
Objective function 197.79 = squared loss an data 94.64 + 0.5*rho*h**2 23.699832 + alpha*h 76.327591 + L2reg 2.78 + L1reg 0.35 ; SHD = 171 ; DAG True
Proportion of microbatches that were clipped  0.7884325097322634
iteration 1 in inner loop, alpha 1108.648613648673 rho 10000.0 h 0.06884741459420951
9630
cuda
Objective function 411.09 = squared loss an data 94.64 + 0.5*rho*h**2 236.998325 + alpha*h 76.327591 + L2reg 2.78 + L1reg 0.35 ; SHD = 171 ; DAG True
||w||^2 114.79725025089203
exp ma of ||w||^2 105810.28146305069
||w|| 10.71434786867087
exp ma of ||w|| 10.452755134878316
||w||^2 55.63212398909335
exp ma of ||w||^2 151.03172101337154
||w|| 7.4586945231114905
exp ma of ||w|| 7.3355077013687
||w||^2 22.36392753660669
exp ma of ||w||^2 21.24340252621744
||w|| 4.729051441526798
exp ma of ||w|| 4.572288094698767
||w||^2 16.893022088636997
exp ma of ||w||^2 21.081529535238968
||w|| 4.1101121747024125
exp ma of ||w|| 4.553136239109219
||w||^2 24.00516267304161
exp ma of ||w||^2 21.032851406522262
||w|| 4.899506370344017
exp ma of ||w|| 4.548365174570916
v before min max tensor([[52754.519, 18428.487, -3151.111,  ..., -8927.352,  -245.836,
         -1752.738],
        [49686.777, -9083.327, 10814.314,  ..., -8514.855, -5718.272,
         14080.612],
        [91911.783,  -832.003, -6119.903,  ..., -3569.263,  5386.825,
         -3377.415],
        ...,
        [ 4084.698, 28524.832, 14552.333,  ..., -6597.347, -4595.744,
         -4547.200],
        [-7386.228, -7618.498, -5172.384,  ..., -4811.282, 37159.963,
         -6286.932],
        [35816.375, -8427.133, 77641.546,  ..., 21344.688, -6435.323,
         -3580.714]], device='cuda:0')
v tensor([[1.000e+01, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e+01],
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         1.000e-12],
        ...,
        [1.000e+01, 1.000e+01, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([ 1.274e+04, -5.757e+03,  3.258e+03, -4.556e+03,  5.205e+03, -8.457e+03,
        -7.986e+03, -4.126e+03, -7.528e+03,  2.087e+04,  3.749e+03, -5.125e+03,
         1.641e+04, -7.303e+03,  1.326e+04,  3.557e+03, -6.058e+03, -5.526e+03,
         2.209e+04, -1.273e+03, -4.643e+03, -5.565e+02, -6.634e+02, -5.806e+03,
        -3.609e+03, -6.226e+03, -3.901e+03,  6.831e+03, -1.159e+02,  1.879e+03,
         1.056e+05, -3.608e+03, -1.236e+03,  1.078e+04, -4.491e+03, -3.833e+03,
         4.977e+04, -1.066e+04, -4.782e+03,  7.906e+04,  1.954e+03,  4.197e+04,
        -9.551e+03, -6.595e+03,  4.508e+02, -6.148e+03,  2.069e+04,  2.211e+03,
        -1.681e+03, -4.005e+03, -4.720e+02, -8.549e+03, -1.028e+04, -1.147e+04,
        -8.789e+03, -5.700e+03,  2.224e+03,  3.036e+04,  2.617e+04, -8.504e+03,
        -2.534e+03,  3.342e+04,  1.569e+04, -6.117e+03, -8.915e+03, -8.831e+03,
         4.287e+03, -7.346e+03, -6.303e+03, -8.324e+03, -2.275e+03, -6.115e+03,
        -5.841e+02, -7.740e+03,  4.203e+04, -7.012e+03,  1.537e+04, -6.213e+03,
        -6.061e+03, -4.495e+03, -6.524e+03, -7.734e+03, -2.379e+03,  5.242e+02,
         6.439e+04,  1.797e+03,  7.927e+04,  4.990e+03, -6.194e+03, -2.475e+03,
        -9.818e+03, -7.802e+03, -6.161e+03, -5.449e+03, -6.192e+03, -7.057e+03,
         1.947e+04, -7.581e+03,  1.305e+05, -7.843e+03, -7.922e+03, -7.632e+03,
         3.126e+04,  5.155e+03,  4.427e+03,  7.819e+01,  3.736e+02, -8.288e+03,
         1.227e+04, -4.504e+03, -2.512e+03,  3.318e+04, -6.532e+03,  3.683e+03,
        -1.866e+03, -7.351e+03, -2.325e+03, -6.905e+03, -5.914e+03, -6.201e+03,
         7.415e+04, -2.448e+03,  1.547e+04,  2.709e+04, -6.022e+03, -5.614e+03,
        -7.044e+03, -2.628e+03, -7.958e+03, -8.874e+03,  1.113e+03,  4.366e+03,
        -1.019e+04, -6.845e+03,  4.833e+04,  2.560e+03, -9.650e+03, -7.477e+03,
        -6.703e+03, -2.776e+03,  1.415e+04, -6.138e+03, -7.073e+03, -7.639e+03,
         1.224e+04, -7.849e+03,  1.080e+04, -6.639e+03, -4.112e+03, -8.305e+03,
        -4.516e+03, -6.826e+03, -8.268e+03,  1.646e+04, -1.346e+03, -4.661e+03,
         1.620e+03, -8.361e+03, -4.825e+03, -8.811e+03, -7.880e+03, -3.584e+03,
         1.363e+04, -3.352e+03,  9.722e+03, -7.270e+03, -7.483e+03,  3.258e+03,
         4.685e+03, -3.471e+03,  2.564e+03, -7.148e+03,  1.155e+04, -7.160e+03,
        -8.434e+03,  1.400e+03, -7.316e+03,  8.185e+03, -7.220e+03, -4.500e+03,
        -6.211e+03,  5.106e+03, -8.953e+02, -5.810e+03, -8.169e+03,  2.190e+04,
        -4.170e+03, -4.633e+03,  5.574e+03,  3.228e+04, -3.797e+03, -7.183e+03,
        -5.992e+03, -7.480e+03, -7.940e+03,  8.385e+04, -6.469e+03, -3.708e+03,
        -3.052e+03,  2.369e+04,  3.914e+03, -3.134e+03,  8.153e+03,  5.881e+03,
         3.557e+04, -9.153e+03,  1.655e+04, -6.856e+03, -2.127e+02,  2.272e+04,
         3.913e+03, -1.584e+03,  3.561e+04,  1.845e+04, -6.445e+03,  3.540e+04,
        -9.687e+03, -8.278e+03, -3.022e+03,  2.491e+04,  1.534e+04, -8.441e+02,
        -8.443e+03, -3.978e+03,  4.282e+04,  4.613e+04, -6.734e+03, -8.376e+03,
         2.173e+04, -7.361e+03,  2.740e+04, -4.119e+03, -4.158e+03, -5.884e+03,
        -1.043e+03,  1.498e+04,  7.788e+02,  4.079e+03,  1.016e+04,  3.273e+03,
        -9.587e+03, -6.059e+03, -2.515e+03,  8.041e+04,  1.527e+04,  2.958e+03,
        -3.192e+03,  2.690e+03, -3.297e+03,  1.048e+03, -4.832e+03,  1.178e+04,
        -5.411e+03, -6.115e+03,  2.806e+03,  1.452e+04, -7.438e+03,  7.328e+02,
        -4.645e+03, -9.931e+03,  8.571e+03, -1.885e+02,  7.269e+03, -6.307e+03,
         1.945e+04, -5.116e+03,  2.022e+04, -9.821e+03,  3.456e+03,  8.297e+03,
        -6.757e+03, -6.231e+03,  2.631e+04,  2.708e+03,  1.145e+03,  1.487e+04,
        -7.430e+03,  1.101e+04, -9.249e+02, -7.049e+03, -3.563e+03,  7.371e+03,
         1.949e+04,  3.508e+04, -1.921e+03, -1.010e+04,  1.872e+04, -6.752e+03,
        -3.971e+03, -7.830e+03, -6.343e+03, -9.860e+03, -6.915e+03, -6.972e+03,
        -7.216e+03,  2.698e+03, -3.268e+03, -8.848e+03,  6.858e+03, -7.770e+03],
       device='cuda:0')
v tensor([1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-8.323e+03],
         [ 1.473e+04],
         [ 3.074e+04],
         [ 1.442e+03],
         [-9.780e+03],
         [-5.903e+03],
         [-4.683e+03],
         [ 2.025e+03],
         [ 3.776e+02],
         [-2.625e+03]],

        [[-9.006e+00],
         [ 2.126e+03],
         [-6.335e+03],
         [-2.380e+03],
         [-2.111e+03],
         [ 1.007e+03],
         [ 1.007e+04],
         [ 5.207e+04],
         [ 2.594e+04],
         [-1.368e+03]],

        [[ 2.965e+03],
         [-6.620e+03],
         [-6.038e+03],
         [ 2.159e+04],
         [ 1.429e+04],
         [ 1.697e+04],
         [-9.361e+03],
         [-4.181e+03],
         [-2.500e+03],
         [ 1.035e+04]],

        [[-7.191e+03],
         [-8.366e+03],
         [ 3.043e+04],
         [ 2.350e+04],
         [-5.491e+03],
         [-5.787e+03],
         [-8.646e+03],
         [ 5.919e+03],
         [-5.958e+03],
         [-4.957e+03]],

        [[ 2.658e+04],
         [-7.248e+03],
         [-1.809e+03],
         [-8.928e+03],
         [-1.006e+04],
         [-5.492e+03],
         [-5.540e+03],
         [-7.291e+03],
         [-8.367e+03],
         [-2.554e+03]],

        [[ 8.041e+04],
         [ 1.758e+04],
         [ 3.588e+02],
         [ 1.541e+04],
         [-4.515e+03],
         [ 1.932e+04],
         [ 4.804e+03],
         [-7.327e+02],
         [ 1.366e+04],
         [ 2.597e+04]],

        [[-5.396e+03],
         [-9.458e+03],
         [-4.725e+03],
         [-7.491e+03],
         [ 1.844e+04],
         [ 6.694e+02],
         [-4.431e+03],
         [ 1.407e+04],
         [ 1.435e+04],
         [-4.355e+03]],

        [[ 1.180e+04],
         [ 1.998e+04],
         [-7.069e+03],
         [ 2.808e+04],
         [-2.070e+02],
         [-4.542e+03],
         [-5.936e+03],
         [-3.841e+03],
         [-6.785e+03],
         [ 6.115e+03]],

        [[-6.491e+03],
         [-7.891e+03],
         [-6.442e+03],
         [ 7.375e+03],
         [ 6.443e+03],
         [-6.076e+03],
         [-7.614e+03],
         [-2.612e+02],
         [-6.346e+03],
         [-1.626e+03]],

        [[-5.698e+03],
         [-7.309e+03],
         [ 3.496e+04],
         [ 2.468e+04],
         [ 2.415e+03],
         [ 6.107e+04],
         [-1.087e+03],
         [ 5.634e+04],
         [-4.725e+03],
         [ 3.962e+04]],

        [[ 1.649e+04],
         [ 1.120e+04],
         [-8.020e+03],
         [ 1.461e+04],
         [-9.458e+03],
         [-6.824e+03],
         [ 1.412e+04],
         [-6.595e+02],
         [-4.160e+03],
         [-6.430e+03]],

        [[-6.916e+03],
         [-3.541e+03],
         [-8.339e+03],
         [ 1.387e+04],
         [ 4.427e+02],
         [-3.624e+03],
         [-4.448e+03],
         [-7.387e+03],
         [ 9.891e+03],
         [-4.390e+03]],

        [[ 2.858e+04],
         [ 1.812e+03],
         [ 1.151e+04],
         [-8.196e+03],
         [ 2.876e+03],
         [ 2.194e+03],
         [-7.055e+03],
         [-5.742e+03],
         [ 6.952e+03],
         [-6.439e+01]],

        [[-1.496e+03],
         [ 1.672e+04],
         [ 4.367e+03],
         [-5.109e+03],
         [-6.441e+03],
         [-1.084e+03],
         [-2.547e+03],
         [ 9.424e+03],
         [ 2.117e+04],
         [ 9.398e+03]],

        [[-8.119e+03],
         [-7.378e+03],
         [-8.329e+03],
         [-2.387e+03],
         [ 3.989e+04],
         [ 4.919e+04],
         [-7.323e+03],
         [-5.434e+03],
         [ 2.157e+04],
         [ 2.001e+04]],

        [[-8.802e+03],
         [ 9.468e+03],
         [ 1.234e+04],
         [-2.792e+02],
         [ 1.035e+04],
         [-6.994e+03],
         [ 2.184e+04],
         [-8.281e+03],
         [-3.485e+03],
         [ 2.980e+04]],

        [[ 1.378e+04],
         [ 3.446e+03],
         [-4.561e+03],
         [-9.039e+03],
         [-8.372e+03],
         [ 3.131e+04],
         [-7.680e+03],
         [-1.768e+03],
         [-1.746e+03],
         [-2.975e+03]],

        [[ 1.001e+04],
         [ 2.281e+04],
         [ 3.131e+03],
         [-1.650e+03],
         [-2.385e+03],
         [-5.475e+03],
         [ 1.943e+03],
         [ 4.631e+03],
         [ 6.462e+03],
         [-8.132e+03]],

        [[-4.486e+03],
         [-4.125e+03],
         [-5.130e+03],
         [ 4.805e+04],
         [-7.319e+03],
         [ 1.280e+04],
         [-2.091e+03],
         [ 2.151e+04],
         [-5.045e+03],
         [-8.249e+03]],

        [[ 5.607e+03],
         [-3.618e+03],
         [-1.997e+03],
         [-7.652e+03],
         [-5.819e+03],
         [ 5.317e+03],
         [-5.111e+03],
         [-7.234e+03],
         [ 1.989e+03],
         [ 1.947e+04]],

        [[-9.113e+03],
         [-3.111e+03],
         [-8.674e+03],
         [-8.868e+03],
         [-7.396e+03],
         [-5.668e+03],
         [-4.812e+03],
         [-8.125e+03],
         [ 4.296e+02],
         [ 2.313e+04]],

        [[-2.137e+03],
         [-8.871e+03],
         [ 1.078e+04],
         [-9.059e+03],
         [-1.130e+03],
         [ 6.188e+03],
         [ 1.611e+04],
         [-7.293e+03],
         [-5.956e+03],
         [ 2.098e+04]],

        [[-5.572e+03],
         [-6.942e+03],
         [-7.408e+03],
         [-7.169e+03],
         [-4.552e+03],
         [-4.944e+03],
         [ 2.565e+04],
         [ 2.617e+02],
         [-1.084e+04],
         [-1.810e+03]],

        [[-6.705e+03],
         [ 1.305e+04],
         [-3.270e+03],
         [-4.888e+03],
         [-8.175e+03],
         [-2.327e+03],
         [-2.448e+03],
         [ 7.908e+03],
         [ 9.323e+02],
         [ 1.729e+04]],

        [[-5.316e+03],
         [-6.072e+03],
         [-5.538e+03],
         [-7.195e+03],
         [-3.713e+03],
         [ 5.067e+03],
         [ 3.279e+03],
         [-7.543e+03],
         [-7.046e+03],
         [ 6.672e+03]],

        [[-7.417e+03],
         [-8.265e+03],
         [-8.122e+03],
         [ 8.144e+03],
         [-8.242e+03],
         [-6.869e+03],
         [-4.312e+03],
         [ 1.187e+04],
         [-1.621e+03],
         [ 1.235e+04]],

        [[-3.719e+03],
         [-5.481e+03],
         [ 1.789e+03],
         [ 2.160e+04],
         [-1.005e+03],
         [-6.363e+02],
         [ 5.099e+04],
         [-9.475e+03],
         [ 2.078e+04],
         [-1.334e+03]],

        [[-4.005e+03],
         [-6.984e+03],
         [-7.416e+03],
         [-8.619e+03],
         [-8.381e+03],
         [ 4.846e+04],
         [ 5.044e+03],
         [-7.378e+03],
         [ 2.148e+03],
         [ 8.318e+03]],

        [[ 1.627e+04],
         [-6.412e+03],
         [-8.572e+03],
         [ 3.660e+02],
         [-8.547e+03],
         [-1.042e+04],
         [-5.212e+03],
         [-9.657e+03],
         [ 4.374e+03],
         [ 8.861e+03]],

        [[ 8.726e+03],
         [-2.377e+02],
         [-2.127e+03],
         [ 4.456e+02],
         [ 1.770e+04],
         [-2.914e+03],
         [-7.520e+03],
         [ 2.129e+04],
         [-9.384e+03],
         [-5.114e+03]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[-2636.104],
        [-2663.194],
        [-3062.537],
        [ 6455.496],
        [15264.178],
        [-6553.673],
        [-6980.383],
        [ 8467.152],
        [-5348.098],
        [-2224.642],
        [-2847.593],
        [ 8956.107],
        [-6410.277],
        [-6597.328],
        [-6211.534],
        [ 7592.953],
        [-7482.898],
        [-3807.467],
        [19005.632],
        [-6129.525],
        [25539.383],
        [ 1829.913],
        [ 2240.577],
        [21270.209],
        [13172.108],
        [-2977.557],
        [ 2011.098],
        [-4668.013],
        [  362.124],
        [-9296.792]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e+01],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-0.156,  2.658,  0.459,  ..., -1.946,  0.163, -1.347],
        [-0.017, -0.831, -0.868,  ..., -0.849,  0.322, -0.396],
        [-0.205, -0.303,  0.082,  ..., -1.287,  0.055,  1.192],
        ...,
        [-0.684, -0.732,  0.777,  ...,  1.327,  0.107,  0.187],
        [-0.503, -0.122,  0.028,  ..., -3.209,  0.049, -0.034],
        [-0.148, -0.474,  0.105,  ..., -2.645,  0.616, -0.008]],
       device='cuda:0')
s after update for 1 param tensor([[2.710, 2.117, 2.079,  ..., 1.961, 1.285, 1.514],
        [1.607, 1.991, 1.852,  ..., 1.865, 1.280, 1.754],
        [2.684, 1.521, 1.726,  ..., 1.302, 1.321, 1.512],
        ...,
        [2.239, 1.835, 1.964,  ..., 1.661, 1.946, 1.536],
        [1.690, 1.800, 2.040,  ..., 1.896, 2.430, 1.840],
        [2.101, 1.848, 1.704,  ..., 1.859, 1.492, 2.380]], device='cuda:0')
b after update for 1 param tensor([[220.239, 194.638, 192.869,  ..., 187.352, 151.646, 164.596],
        [169.563, 188.770, 182.034,  ..., 182.706, 151.339, 177.191],
        [219.157, 164.964, 175.772,  ..., 152.662, 153.768, 164.520],
        ...,
        [200.155, 181.197, 187.476,  ..., 172.434, 186.611, 165.811],
        [173.928, 179.460, 191.083,  ..., 184.204, 208.527, 181.472],
        [193.905, 181.863, 174.607,  ..., 182.405, 163.413, 206.391]],
       device='cuda:0')
clipping threshold 3.4664615148314244
a after update for 1 param tensor([ 1.162,  0.732,  2.179, -1.666, -0.634, -0.345, -0.038,  0.317, -0.455,
         0.059, -3.830, -1.008,  1.677,  0.628,  0.113,  1.161, -2.830,  0.363,
         0.956,  1.761,  3.894, -0.095,  0.266,  0.976, -0.828, -0.642, -1.363,
         1.351, -0.861,  2.153, -0.503,  2.377, -0.345, -0.486, -1.337, -2.466,
        -1.088,  0.590,  0.916,  0.160, -1.140, -0.532,  2.215,  2.587,  0.553,
        -1.478,  2.566,  4.366, -2.147, -1.723, -0.304, -0.893, -0.119, -0.709,
         0.182,  1.133, -1.616, -0.052,  0.769,  0.347, -0.134, -1.793,  1.916,
         1.175,  1.253, -0.375,  0.509,  0.054,  1.017, -0.088,  0.285,  0.316,
         2.322,  0.402, -0.023,  0.475,  0.116,  2.077, -1.241,  2.156,  2.042,
        -1.473, -0.231, -3.425, -2.427,  2.656,  0.163, -0.570,  0.718,  2.782,
        -0.444, -1.672,  0.602, -1.246,  1.857, -2.259,  0.347,  1.783, -2.228,
         1.240,  0.446, -0.334, -0.212,  0.574, -1.867,  0.023, -0.020, -1.587,
         0.336, -2.307, -0.391,  0.048,  1.598, -0.569,  1.202,  1.258, -0.909,
         0.250,  1.159,  0.625,  0.532, -1.076,  2.746,  0.770,  1.886,  0.707,
         0.327,  2.165, -0.171, -1.193, -5.745, -0.330, -1.364,  0.918, -0.212,
        -1.201,  1.083, -2.126,  0.789,  1.655, -1.344,  0.284,  0.095, -1.059,
         1.034, -1.361,  1.820, -0.104,  1.927,  2.438, -0.648, -0.624, -0.600,
        -0.877, -0.895, -1.192,  0.018, -1.290, -0.678,  1.054,  0.276, -0.364,
         0.975,  1.603,  0.066,  0.424,  1.707,  0.355,  0.157, -0.910,  0.087,
         0.586,  1.010, -0.073, -1.232, -1.668,  0.147,  2.319, -2.587,  1.315,
         1.858,  1.872, -0.227, -0.243, -0.347, -1.672, -0.297,  0.084,  0.908,
        -1.236, -1.237,  2.021, -0.632, -2.204,  1.827, -0.498, -0.750,  0.461,
         1.591, -0.697, -0.362,  0.874, -1.736, -2.328,  0.565, -1.513,  2.535,
         0.877, -0.729,  0.411, -0.580, -0.010,  0.763, -1.499, -1.991,  0.848,
         0.048,  1.109,  0.195, -0.801, -1.578, -0.852,  1.210, -0.898,  2.169,
         1.915,  0.768,  0.118,  2.046, -2.344, -1.636,  0.794, -2.757, -0.249,
        -1.652,  1.877,  0.319,  2.238,  2.079, -0.131, -1.001, -1.017, -0.400,
        -0.950, -0.339,  0.062,  0.019,  0.365, -0.653, -2.035, -0.594,  0.493,
         1.967, -1.284, -3.144,  1.117, -2.646, -1.585, -2.839,  1.129,  2.791,
        -1.119, -0.455,  0.661,  0.833, -0.096, -1.135,  1.606, -2.016, -1.401,
         3.096,  0.200,  0.881,  0.091, -0.727,  0.507,  2.114, -1.003, -0.073,
        -0.730,  0.648, -1.983, -1.875, -0.773,  1.101,  0.765,  1.798, -2.469,
         2.098,  0.717, -1.032, -1.717,  1.009, -0.200,  0.540,  1.696, -0.258,
         1.205,  1.248,  1.597], device='cuda:0')
s after update for 1 param tensor([1.945, 1.532, 1.972, 1.957, 1.869, 1.943, 1.966, 1.773, 2.326, 2.040,
        1.496, 1.121, 1.617, 1.789, 1.814, 2.133, 1.457, 1.757, 1.623, 1.103,
        1.796, 1.717, 1.943, 1.473, 1.386, 1.504, 1.239, 1.607, 1.828, 1.882,
        2.278, 1.517, 1.612, 1.686, 1.809, 1.781, 1.826, 2.286, 1.470, 2.015,
        1.802, 1.848, 2.172, 2.018, 1.866, 1.353, 1.828, 1.433, 1.698, 1.652,
        1.875, 1.936, 2.237, 2.460, 1.961, 1.779, 1.843, 2.222, 2.126, 1.829,
        1.178, 2.044, 1.579, 1.545, 2.011, 1.893, 2.109, 2.084, 1.370, 1.925,
        1.002, 2.083, 1.544, 1.680, 2.037, 1.507, 2.306, 1.742, 1.631, 1.021,
        1.822, 1.931, 1.466, 1.734, 2.203, 1.635, 2.546, 2.091, 1.547, 1.168,
        2.107, 1.870, 1.814, 1.575, 1.567, 1.571, 2.079, 1.669, 2.615, 1.772,
        1.697, 1.694, 2.009, 1.928, 2.215, 1.865, 1.684, 1.785, 2.632, 1.685,
        1.303, 1.656, 1.405, 2.023, 1.791, 1.602, 1.412, 1.534, 1.316, 1.392,
        2.243, 1.334, 2.019, 1.635, 1.645, 1.214, 1.641, 1.385, 2.046, 1.946,
        2.417, 1.788, 2.219, 1.561, 1.896, 2.222, 2.067, 1.744, 1.594, 1.604,
        1.855, 1.455, 1.583, 1.693, 2.173, 1.683, 2.201, 1.428, 1.802, 1.778,
        1.317, 1.924, 1.770, 2.233, 1.726, 2.008, 2.347, 1.869, 1.864, 1.891,
        1.717, 1.476, 2.036, 1.518, 1.520, 1.758, 1.843, 2.345, 1.161, 1.893,
        2.195, 1.770, 1.188, 1.632, 1.805, 1.615, 1.565, 2.069, 1.591, 1.775,
        1.342, 2.177, 1.728, 1.243, 1.804, 2.083, 1.599, 2.092, 2.286, 1.912,
        1.547, 1.872, 1.701, 1.838, 1.855, 1.794, 1.445, 1.210, 1.459, 1.921,
        2.076, 1.508, 1.863, 2.013, 1.851, 2.019, 1.674, 1.688, 1.725, 1.929,
        1.588, 1.834, 1.962, 1.861, 1.621, 1.869, 2.157, 1.852, 2.064, 1.783,
        2.205, 2.175, 1.806, 1.837, 1.811, 2.158, 1.446, 1.792, 1.710, 1.576,
        1.978, 1.279, 1.788, 1.541, 1.460, 2.342, 1.622, 2.181, 1.867, 2.024,
        2.117, 1.792, 1.104, 1.991, 1.971, 2.237, 2.106, 1.885, 1.315, 1.838,
        1.343, 2.063, 1.394, 1.342, 1.768, 2.308, 1.634, 2.150, 1.317, 2.127,
        1.749, 1.557, 2.613, 2.255, 1.787, 1.098, 2.096, 2.207, 2.063, 1.908,
        1.450, 1.546, 1.853, 1.948, 2.142, 2.170, 1.595, 2.060, 0.690, 1.559,
        1.876, 1.912, 1.651, 2.082, 1.565, 2.165, 2.384, 1.949, 1.332, 1.730,
        1.394, 2.153, 1.632, 1.770, 1.720, 1.599, 1.493, 2.094, 2.073, 2.069],
       device='cuda:0')
b after update for 1 param tensor([186.570, 165.572, 187.848, 187.150, 182.872, 186.488, 187.578, 178.123,
        204.026, 191.055, 163.634, 141.646, 170.115, 178.919, 180.186, 195.381,
        161.493, 177.340, 170.450, 140.500, 179.292, 175.300, 186.449, 162.357,
        157.479, 164.078, 148.893, 169.566, 180.883, 183.505, 201.907, 164.764,
        169.860, 173.685, 179.921, 178.521, 180.777, 202.241, 162.187, 189.908,
        179.563, 181.878, 197.161, 190.046, 182.721, 155.591, 180.851, 160.167,
        174.297, 171.949, 183.159, 186.153, 200.106, 209.801, 187.323, 178.406,
        181.626, 199.420, 195.077, 180.909, 145.200, 191.257, 168.082, 166.292,
        189.717, 184.053, 194.260, 193.129, 156.582, 185.595, 133.927, 193.089,
        166.212, 173.406, 190.952, 164.209, 203.152, 176.569, 170.822, 135.155,
        180.598, 185.909, 161.962, 176.138, 198.546, 171.048, 213.463, 193.446,
        166.394, 144.577, 194.189, 182.934, 180.176, 167.868, 167.480, 167.696,
        192.870, 172.825, 216.333, 178.084, 174.280, 174.114, 189.593, 185.741,
        199.111, 182.697, 173.582, 178.755, 217.042, 173.639, 152.694, 172.175,
        158.568, 190.292, 179.014, 169.298, 158.941, 165.683, 153.454, 157.823,
        200.356, 154.488, 190.071, 171.045, 171.585, 147.387, 171.369, 157.433,
        191.369, 186.606, 207.964, 178.879, 199.257, 167.158, 184.201, 199.432,
        192.342, 176.666, 168.920, 169.418, 182.187, 161.348, 168.298, 174.064,
        197.218, 173.550, 198.478, 159.884, 179.586, 178.387, 153.541, 185.557,
        177.976, 199.901, 175.733, 189.545, 204.959, 182.895, 182.659, 183.941,
        175.307, 162.527, 190.902, 164.801, 164.944, 177.383, 181.609, 204.861,
        144.162, 184.065, 198.218, 177.958, 145.801, 170.904, 179.713, 170.003,
        167.376, 192.413, 168.737, 178.214, 154.966, 197.405, 175.861, 149.176,
        179.677, 193.071, 169.187, 193.504, 202.270, 184.990, 166.396, 183.012,
        174.499, 181.369, 182.213, 179.205, 160.783, 147.169, 161.594, 185.421,
        192.728, 164.277, 182.593, 189.784, 181.986, 190.072, 173.078, 173.783,
        175.713, 185.815, 168.593, 181.165, 187.396, 182.512, 170.334, 182.895,
        196.458, 182.031, 192.204, 178.607, 198.633, 197.271, 179.790, 181.313,
        180.030, 196.530, 160.884, 179.076, 174.954, 167.921, 188.158, 151.263,
        178.883, 166.087, 161.636, 204.704, 170.398, 197.562, 182.790, 190.324,
        194.664, 179.069, 140.531, 188.739, 187.793, 200.102, 194.136, 183.681,
        153.404, 181.346, 155.030, 192.147, 157.930, 154.980, 177.892, 203.221,
        170.986, 196.141, 153.533, 195.098, 176.935, 166.909, 216.247, 200.873,
        178.828, 140.163, 193.674, 198.759, 192.135, 184.790, 161.097, 166.337,
        182.121, 186.716, 195.797, 197.060, 168.928, 192.004, 111.106, 167.018,
        183.226, 184.984, 171.907, 193.036, 167.341, 196.859, 206.532, 186.742,
        154.381, 175.980, 157.969, 196.277, 170.904, 177.976, 175.421, 169.163,
        163.477, 193.566, 192.605, 192.402], device='cuda:0')
clipping threshold 3.4664615148314244
a after update for 1 param tensor([[[ 4.659e-01],
         [ 1.246e+00],
         [-1.366e+00],
         [ 2.676e-01],
         [-4.195e-01],
         [ 4.122e-01],
         [ 5.349e-01],
         [ 6.350e-01],
         [ 2.060e+00],
         [ 7.583e-02]],

        [[-4.224e-01],
         [ 2.039e-01],
         [ 1.723e+00],
         [-1.183e+00],
         [ 1.927e+00],
         [ 1.116e+00],
         [ 9.993e-01],
         [ 1.139e+00],
         [-2.436e+00],
         [ 7.032e-01]],

        [[-2.830e-01],
         [-2.018e-02],
         [-2.404e+00],
         [ 2.159e+00],
         [ 6.302e-02],
         [ 1.506e+00],
         [ 5.559e-01],
         [ 1.125e+00],
         [ 5.282e-01],
         [-6.671e-01]],

        [[-1.383e+00],
         [-1.060e+00],
         [ 5.526e-01],
         [ 2.161e+00],
         [-1.751e+00],
         [-2.214e-01],
         [ 2.663e-01],
         [-2.209e+00],
         [-7.955e-02],
         [ 6.043e-02]],

        [[-1.446e+00],
         [-9.078e-01],
         [ 1.515e+00],
         [ 2.226e-02],
         [ 5.293e-01],
         [-2.934e-01],
         [-1.190e+00],
         [ 1.701e+00],
         [-5.728e-01],
         [ 2.115e+00]],

        [[-2.744e+00],
         [-4.280e+00],
         [-1.101e-01],
         [ 5.772e-01],
         [-5.390e-01],
         [-1.396e-01],
         [-8.846e-01],
         [-8.641e-01],
         [-4.137e-01],
         [-1.178e+00]],

        [[ 9.181e-01],
         [ 2.228e+00],
         [-3.946e-01],
         [ 2.366e-01],
         [-6.632e-01],
         [ 1.686e+00],
         [ 3.492e-01],
         [-3.360e+00],
         [-8.371e-01],
         [ 1.424e+00]],

        [[ 6.708e-01],
         [ 2.627e+00],
         [ 1.088e+00],
         [-1.341e+00],
         [-2.440e-01],
         [-7.486e-02],
         [-2.017e+00],
         [ 2.471e+00],
         [ 3.687e-01],
         [ 6.585e-01]],

        [[-1.683e+00],
         [-7.044e-01],
         [ 3.294e-01],
         [ 7.409e-03],
         [-3.444e-01],
         [ 3.059e-01],
         [ 1.304e+00],
         [ 7.338e-01],
         [-2.329e+00],
         [ 2.635e-01]],

        [[-7.947e-01],
         [-1.401e-03],
         [-4.715e-01],
         [ 9.040e-01],
         [ 4.731e-01],
         [ 1.706e-01],
         [ 1.111e+00],
         [-1.796e+00],
         [-7.976e-01],
         [ 4.753e-01]],

        [[ 9.372e-01],
         [ 2.248e+00],
         [ 4.420e-01],
         [-1.301e+00],
         [ 1.686e-01],
         [ 5.396e-01],
         [ 4.293e-01],
         [-1.675e-01],
         [-1.497e+00],
         [ 2.469e-01]],

        [[-2.120e+00],
         [-1.774e+00],
         [ 2.832e+00],
         [ 2.030e+00],
         [-1.033e+00],
         [-1.512e-01],
         [ 1.206e+00],
         [ 1.295e+00],
         [-8.058e-01],
         [-3.124e-02]],

        [[ 1.807e+00],
         [-6.937e-01],
         [-1.879e+00],
         [ 1.312e+00],
         [ 2.855e-01],
         [-2.464e+00],
         [-6.715e-01],
         [ 3.143e+00],
         [-1.029e+00],
         [ 1.222e+00]],

        [[-2.434e+00],
         [ 1.775e+00],
         [ 3.236e-01],
         [-2.190e+00],
         [ 2.517e+00],
         [-5.056e-01],
         [ 8.003e-01],
         [-1.955e+00],
         [-1.797e+00],
         [-1.479e-01]],

        [[-1.721e+00],
         [ 1.390e-01],
         [ 2.267e+00],
         [-2.579e-01],
         [ 8.413e-01],
         [ 2.870e+00],
         [ 5.806e-01],
         [ 3.007e-01],
         [ 2.403e+00],
         [ 2.379e-01]],

        [[ 8.031e-01],
         [ 4.493e-01],
         [-1.531e+00],
         [-1.458e+00],
         [ 2.073e+00],
         [-1.992e+00],
         [-5.875e-01],
         [-1.527e+00],
         [-1.258e-01],
         [-9.712e-01]],

        [[ 2.367e+00],
         [-1.848e-01],
         [-1.045e-01],
         [-1.431e+00],
         [ 1.602e+00],
         [ 8.941e-01],
         [ 7.938e-01],
         [ 2.199e+00],
         [-1.043e-01],
         [ 7.985e-01]],

        [[ 7.548e-01],
         [-1.475e+00],
         [ 1.145e+00],
         [ 2.080e-01],
         [-1.443e+00],
         [ 3.154e-01],
         [-2.954e-01],
         [ 1.910e+00],
         [-1.687e-01],
         [-9.255e-02]],

        [[ 5.537e-02],
         [-1.177e+00],
         [ 1.681e+00],
         [ 4.248e-01],
         [ 6.378e-01],
         [ 7.381e-01],
         [ 1.545e+00],
         [ 2.353e-01],
         [-1.243e+00],
         [-2.163e+00]],

        [[-3.730e-01],
         [-1.736e-01],
         [-2.072e-01],
         [-1.785e+00],
         [-8.016e-01],
         [ 4.720e-03],
         [-5.949e-01],
         [-1.544e+00],
         [ 1.921e+00],
         [-2.896e+00]],

        [[ 3.644e+00],
         [-4.687e-01],
         [ 1.016e+00],
         [-1.424e+00],
         [ 7.705e-01],
         [-8.357e-01],
         [-2.374e+00],
         [-6.081e-02],
         [ 1.400e+00],
         [ 6.537e-02]],

        [[ 6.509e-01],
         [ 2.228e+00],
         [ 1.865e+00],
         [ 9.410e-01],
         [-4.803e-01],
         [ 6.158e-01],
         [-9.652e-01],
         [-1.901e+00],
         [-6.433e-01],
         [-2.752e+00]],

        [[-1.453e+00],
         [-5.691e-01],
         [-2.435e+00],
         [-3.427e+00],
         [-3.853e-01],
         [-4.301e-01],
         [ 1.585e+00],
         [ 4.567e-01],
         [ 1.391e+00],
         [ 4.736e-01]],

        [[-6.744e-01],
         [-2.180e+00],
         [-6.611e-01],
         [ 9.520e-02],
         [-2.953e-02],
         [-2.137e+00],
         [ 5.117e-01],
         [ 2.663e-01],
         [-8.092e-01],
         [ 2.941e+00]],

        [[ 1.524e+00],
         [-5.833e-01],
         [-7.424e-01],
         [ 1.841e+00],
         [ 7.919e-01],
         [ 1.404e-01],
         [-2.218e-01],
         [ 9.193e-01],
         [ 4.961e-01],
         [ 5.468e-02]],

        [[ 2.389e+00],
         [ 1.804e-01],
         [-2.424e+00],
         [ 1.319e+00],
         [-1.467e+00],
         [-2.460e-01],
         [-5.311e-01],
         [ 6.700e-02],
         [ 1.890e+00],
         [ 1.002e+00]],

        [[-1.390e+00],
         [ 2.049e-01],
         [-3.290e-01],
         [ 1.582e-01],
         [-1.123e+00],
         [ 9.335e-01],
         [ 1.101e+00],
         [-3.070e-02],
         [-7.974e-01],
         [ 3.435e-01]],

        [[-9.893e-01],
         [-4.131e-01],
         [-6.254e+00],
         [ 5.800e-01],
         [-5.758e-01],
         [ 1.581e+00],
         [ 5.080e-01],
         [ 1.097e+00],
         [ 3.386e-01],
         [-2.977e-01]],

        [[-1.965e+00],
         [ 2.576e-01],
         [-2.369e+00],
         [ 8.973e-01],
         [ 2.778e+00],
         [-8.908e-01],
         [ 4.054e-01],
         [-6.072e-01],
         [-1.437e+00],
         [-1.007e-01]],

        [[ 1.236e+00],
         [-8.074e-01],
         [ 1.353e+00],
         [ 9.004e-01],
         [-2.494e+00],
         [-6.718e-01],
         [-4.777e-01],
         [ 9.748e-02],
         [ 3.331e-01],
         [ 1.886e+00]]], device='cuda:0')
s after update for 1 param tensor([[[1.865],
         [1.793],
         [2.022],
         [2.027],
         [2.139],
         [1.789],
         [1.527],
         [1.692],
         [1.682],
         [1.494]],

        [[1.691],
         [2.074],
         [1.513],
         [1.775],
         [1.530],
         [1.721],
         [1.997],
         [1.923],
         [2.083],
         [2.125]],

        [[1.453],
         [1.882],
         [1.536],
         [2.421],
         [2.041],
         [1.825],
         [2.014],
         [1.018],
         [1.147],
         [2.227]],

        [[1.688],
         [1.790],
         [2.005],
         [2.055],
         [1.887],
         [1.759],
         [1.974],
         [1.731],
         [1.662],
         [1.323]],

        [[2.244],
         [1.568],
         [1.864],
         [1.984],
         [2.155],
         [1.578],
         [1.374],
         [1.844],
         [1.796],
         [1.476]],

        [[2.262],
         [1.832],
         [1.879],
         [1.623],
         [1.726],
         [1.498],
         [1.869],
         [1.816],
         [2.400],
         [2.195]],

        [[1.719],
         [2.051],
         [1.163],
         [1.723],
         [1.936],
         [2.249],
         [1.175],
         [1.327],
         [1.794],
         [1.818]],

        [[2.219],
         [2.226],
         [1.668],
         [2.051],
         [1.195],
         [1.772],
         [1.604],
         [1.326],
         [1.511],
         [2.082]],

        [[1.672],
         [1.691],
         [1.527],
         [2.042],
         [1.940],
         [1.730],
         [1.714],
         [1.847],
         [1.426],
         [1.839]],

        [[2.025],
         [1.614],
         [1.596],
         [1.929],
         [2.198],
         [1.909],
         [1.558],
         [1.764],
         [2.006],
         [1.689]],

        [[2.298],
         [2.183],
         [1.723],
         [2.100],
         [2.028],
         [1.821],
         [1.650],
         [1.313],
         [1.628],
         [1.646]],

        [[2.089],
         [1.561],
         [1.812],
         [1.966],
         [1.893],
         [1.490],
         [1.998],
         [1.881],
         [2.115],
         [1.637]],

        [[2.092],
         [1.193],
         [2.370],
         [1.755],
         [2.055],
         [1.994],
         [1.537],
         [1.421],
         [2.605],
         [1.682]],

        [[1.384],
         [2.150],
         [1.734],
         [1.695],
         [1.641],
         [1.435],
         [2.075],
         [1.941],
         [2.174],
         [2.234]],

        [[1.814],
         [1.586],
         [1.841],
         [1.511],
         [2.131],
         [2.127],
         [1.737],
         [1.618],
         [1.835],
         [2.108]],

        [[1.917],
         [2.432],
         [2.030],
         [1.560],
         [1.932],
         [1.500],
         [1.789],
         [1.772],
         [2.016],
         [1.905]],

        [[2.308],
         [2.016],
         [1.153],
         [2.109],
         [1.906],
         [2.263],
         [1.653],
         [2.197],
         [1.376],
         [1.538]],

        [[2.445],
         [2.181],
         [1.604],
         [1.391],
         [1.793],
         [1.362],
         [1.697],
         [1.780],
         [1.860],
         [1.882]],

        [[1.174],
         [1.281],
         [2.165],
         [2.033],
         [1.964],
         [2.460],
         [1.546],
         [1.927],
         [1.455],
         [1.822]],

        [[2.093],
         [1.730],
         [2.191],
         [1.927],
         [1.775],
         [2.277],
         [1.851],
         [1.642],
         [1.675],
         [2.277]],

        [[1.958],
         [1.921],
         [1.856],
         [2.025],
         [1.918],
         [1.597],
         [1.485],
         [1.744],
         [2.019],
         [2.320]],

        [[1.881],
         [1.917],
         [2.044],
         [1.956],
         [1.677],
         [2.066],
         [1.911],
         [1.563],
         [1.751],
         [2.049]],

        [[1.365],
         [1.577],
         [1.823],
         [1.623],
         [1.475],
         [1.631],
         [1.712],
         [1.439],
         [2.338],
         [1.944]],

        [[1.459],
         [2.208],
         [0.768],
         [1.900],
         [1.785],
         [1.165],
         [1.613],
         [2.245],
         [1.509],
         [1.931]],

        [[1.623],
         [1.433],
         [1.928],
         [1.622],
         [1.805],
         [2.162],
         [2.273],
         [1.641],
         [1.579],
         [1.661]],

        [[1.829],
         [2.021],
         [1.921],
         [1.962],
         [1.883],
         [1.627],
         [0.924],
         [2.071],
         [1.456],
         [1.798]],

        [[1.359],
         [1.341],
         [2.064],
         [2.286],
         [1.565],
         [1.421],
         [2.198],
         [2.039],
         [1.712],
         [1.585]],

        [[1.784],
         [1.971],
         [1.588],
         [1.846],
         [1.863],
         [2.129],
         [1.682],
         [1.853],
         [2.126],
         [1.393]],

        [[1.614],
         [1.714],
         [1.872],
         [1.713],
         [1.828],
         [2.229],
         [1.846],
         [2.089],
         [2.414],
         [1.606]],

        [[1.991],
         [1.799],
         [1.174],
         [2.287],
         [2.059],
         [1.446],
         [1.612],
         [2.269],
         [2.085],
         [1.107]]], device='cuda:0')
b after update for 1 param tensor([[[182.689],
         [179.114],
         [190.224],
         [190.472],
         [195.660],
         [178.951],
         [165.325],
         [174.035],
         [173.510],
         [163.522]],

        [[173.967],
         [192.638],
         [164.559],
         [178.215],
         [165.476],
         [175.485],
         [189.031],
         [185.513],
         [193.081],
         [195.026]],

        [[161.250],
         [183.531],
         [165.789],
         [208.135],
         [191.117],
         [180.736],
         [189.837],
         [134.970],
         [143.288],
         [199.626]],

        [[173.810],
         [178.962],
         [189.444],
         [191.790],
         [183.782],
         [177.447],
         [187.936],
         [176.015],
         [172.457],
         [153.871]],

        [[200.392],
         [167.539],
         [182.660],
         [188.420],
         [196.390],
         [168.036],
         [156.791],
         [181.636],
         [179.276],
         [162.539]],

        [[201.201],
         [181.067],
         [183.353],
         [170.445],
         [175.774],
         [163.732],
         [182.883],
         [180.282],
         [207.238],
         [198.205]],

        [[175.383],
         [191.600],
         [144.268],
         [175.574],
         [186.127],
         [200.607],
         [145.000],
         [154.103],
         [179.159],
         [180.377]],

        [[199.255],
         [199.570],
         [172.792],
         [191.569],
         [146.218],
         [178.054],
         [169.433],
         [154.028],
         [164.451],
         [193.043]],

        [[172.961],
         [173.978],
         [165.313],
         [191.185],
         [186.347],
         [175.955],
         [175.140],
         [181.795],
         [159.759],
         [181.416]],

        [[190.362],
         [169.958],
         [168.999],
         [185.782],
         [198.343],
         [184.845],
         [166.953],
         [177.680],
         [189.467],
         [173.876]],

        [[202.813],
         [197.661],
         [175.592],
         [193.865],
         [190.509],
         [180.545],
         [171.862],
         [153.310],
         [170.682],
         [171.633]],

        [[193.359],
         [167.153],
         [180.056],
         [187.574],
         [184.037],
         [163.304],
         [189.099],
         [183.485],
         [194.563],
         [171.185]],

        [[193.487],
         [146.094],
         [205.959],
         [177.225],
         [191.778],
         [188.918],
         [165.871],
         [159.469],
         [215.905],
         [173.483]],

        [[157.393],
         [196.133],
         [176.165],
         [174.180],
         [171.361],
         [160.261],
         [192.710],
         [186.373],
         [197.245],
         [199.931]],

        [[180.199],
         [168.455],
         [181.512],
         [164.416],
         [195.269],
         [195.117],
         [176.321],
         [170.174],
         [181.202],
         [194.216]],

        [[185.226],
         [208.615],
         [190.589],
         [167.068],
         [185.968],
         [163.824],
         [178.940],
         [178.079],
         [189.954],
         [184.659]],

        [[203.224],
         [189.954],
         [143.633],
         [194.292],
         [184.711],
         [201.227],
         [171.982],
         [198.303],
         [156.944],
         [165.878]],

        [[209.197],
         [197.570],
         [169.431],
         [157.750],
         [179.112],
         [156.119],
         [174.270],
         [178.505],
         [182.434],
         [183.509]],

        [[144.949],
         [151.399],
         [196.821],
         [190.737],
         [187.479],
         [209.804],
         [166.330],
         [185.679],
         [161.366],
         [180.564]],

        [[193.539],
         [175.960],
         [198.006],
         [185.715],
         [178.204],
         [201.886],
         [182.001],
         [171.434],
         [173.116],
         [201.868]],

        [[187.174],
         [185.401],
         [182.229],
         [190.349],
         [185.282],
         [169.040],
         [163.042],
         [176.662],
         [190.107],
         [203.765]],

        [[183.491],
         [185.221],
         [191.246],
         [187.095],
         [173.256],
         [192.296],
         [184.918],
         [167.246],
         [177.025],
         [191.483]],

        [[156.292],
         [168.001],
         [180.637],
         [170.408],
         [162.445],
         [170.845],
         [175.018],
         [160.480],
         [204.546],
         [186.525]],

        [[161.607],
         [198.772],
         [117.234],
         [184.411],
         [178.733],
         [144.390],
         [169.881],
         [200.446],
         [164.328],
         [185.917]],

        [[170.417],
         [160.140],
         [185.746],
         [170.349],
         [179.717],
         [196.679],
         [201.707],
         [171.392],
         [168.100],
         [172.415]],

        [[180.944],
         [190.196],
         [185.413],
         [187.382],
         [183.581],
         [170.648],
         [128.602],
         [192.535],
         [161.447],
         [179.358]],

        [[155.951],
         [154.907],
         [192.187],
         [202.247],
         [167.336],
         [159.492],
         [198.310],
         [191.031],
         [175.063],
         [168.419]],

        [[178.675],
         [187.804],
         [168.564],
         [181.756],
         [182.595],
         [195.195],
         [173.512],
         [182.126],
         [195.060],
         [157.865]],

        [[169.967],
         [175.116],
         [183.042],
         [175.083],
         [180.889],
         [199.746],
         [181.779],
         [193.333],
         [207.870],
         [169.540]],

        [[188.752],
         [179.425],
         [144.919],
         [202.290],
         [191.977],
         [160.890],
         [169.838],
         [201.510],
         [193.190],
         [140.754]]], device='cuda:0')
clipping threshold 3.4664615148314244
a after update for 1 param tensor([[-0.464],
        [-0.885],
        [-0.344],
        [-1.347],
        [ 0.404],
        [-2.910],
        [ 0.186],
        [-1.788],
        [ 0.039],
        [ 0.738],
        [-0.626],
        [-0.399],
        [ 1.563],
        [ 0.651],
        [-2.902],
        [ 0.824],
        [-1.351],
        [-1.131],
        [-0.897],
        [-1.083],
        [-2.520],
        [-0.741],
        [ 0.564],
        [-0.084],
        [ 3.249],
        [-0.770],
        [ 2.168],
        [-2.377],
        [ 0.372],
        [-0.407]], device='cuda:0')
s after update for 1 param tensor([[1.821],
        [1.839],
        [1.376],
        [2.298],
        [2.014],
        [1.730],
        [2.122],
        [2.002],
        [2.016],
        [1.321],
        [1.881],
        [1.616],
        [1.386],
        [1.557],
        [1.521],
        [2.061],
        [1.968],
        [0.995],
        [1.749],
        [1.350],
        [2.513],
        [1.727],
        [1.357],
        [2.366],
        [1.831],
        [1.410],
        [2.015],
        [1.287],
        [1.703],
        [2.227]], device='cuda:0')
b after update for 1 param tensor([[180.511],
        [181.426],
        [156.946],
        [202.786],
        [189.846],
        [175.957],
        [194.858],
        [189.296],
        [189.920],
        [153.775],
        [183.481],
        [170.078],
        [157.491],
        [166.905],
        [164.963],
        [192.036],
        [187.646],
        [133.452],
        [176.929],
        [155.450],
        [212.082],
        [175.815],
        [155.851],
        [205.750],
        [180.998],
        [158.830],
        [189.887],
        [151.749],
        [174.568],
        [199.651]], device='cuda:0')
clipping threshold 3.4664615148314244
||w||^2 20.859078465725837
exp ma of ||w||^2 14.512188698721124
||w|| 4.567174013076997
exp ma of ||w|| 3.761644883862832
||w||^2 14.071607721615132
exp ma of ||w||^2 12.819919540617171
||w|| 3.7512141663220366
exp ma of ||w|| 3.532142678278378
||w||^2 13.0232522906031
exp ma of ||w||^2 13.724730881372723
||w|| 3.608774347420894
exp ma of ||w|| 3.6611735093840596
||w||^2 12.804000420261575
exp ma of ||w||^2 14.297263848061052
||w|| 3.5782677960518234
exp ma of ||w|| 3.7447310486404355
||w||^2 13.517822351754141
exp ma of ||w||^2 14.372030836380183
||w|| 3.676659129121728
exp ma of ||w|| 3.750657018894564
||w||^2 19.260338194684955
exp ma of ||w||^2 15.378129912423425
||w|| 4.388660182183733
exp ma of ||w|| 3.8823650047022853
||w||^2 15.456806244286208
exp ma of ||w||^2 15.416566554960113
||w|| 3.9315144975296996
exp ma of ||w|| 3.8961333632076465
||w||^2 17.081047364779618
exp ma of ||w||^2 17.635365494715757
||w|| 4.13292237584734
exp ma of ||w|| 4.163484250767382
cuda
Objective function 173.07 = squared loss an data 93.96 + 0.5*rho*h**2 43.280994 + alpha*h 32.618015 + L2reg 2.88 + L1reg 0.33 ; SHD = 164 ; DAG True
Proportion of microbatches that were clipped  0.7853533327985883
iteration 2 in inner loop, alpha 1108.648613648673 rho 100000.0 h 0.02942141863602643
iteration 4 in outer loop, alpha = 30530.067249675107, rho = 1000000.0, h = 0.02942141863602643
Threshold 0.3
[[0.005 0.069 0.135 0.212 0.099 0.015 0.09  0.177 0.129 0.081 0.117 0.098
  0.094 0.027 0.016 0.061 0.134 0.1   0.573 0.024 0.106 0.014 0.129 0.032
  0.033 0.046 0.061 0.029 0.166 0.056]
 [0.068 0.006 0.182 0.403 0.058 0.015 0.204 0.445 0.109 0.104 0.234 0.243
  0.217 0.036 0.016 0.098 0.318 0.099 0.255 0.06  0.197 0.046 0.233 0.136
  0.074 0.105 0.397 0.016 0.343 0.095]
 [0.044 0.043 0.01  0.039 0.038 0.012 0.049 0.056 0.046 0.031 0.08  0.053
  0.09  0.009 0.009 0.051 0.084 0.035 0.08  0.023 0.062 0.01  0.07  0.019
  0.029 0.019 0.052 0.022 0.065 0.049]
 [0.028 0.008 0.113 0.006 0.057 0.017 0.052 0.113 0.101 0.032 0.109 0.066
  0.05  0.021 0.006 0.04  0.157 0.028 0.2   0.024 0.028 0.014 0.102 0.024
  0.02  0.018 0.064 0.008 0.049 0.017]
 [0.091 0.118 0.27  0.146 0.005 0.011 0.074 0.444 0.281 0.048 0.178 0.207
  0.084 0.103 0.022 0.075 0.188 0.05  0.308 0.067 0.114 0.022 0.235 0.052
  0.078 0.078 0.062 0.042 0.22  0.066]
 [0.317 0.416 0.455 0.548 0.625 0.006 0.682 0.595 0.256 0.356 0.447 0.471
  0.191 0.298 0.104 0.394 0.638 0.309 0.657 0.276 0.367 0.292 0.542 0.202
  0.362 0.115 0.415 0.083 0.656 0.484]
 [0.104 0.049 0.213 0.149 0.095 0.008 0.004 0.273 0.106 0.076 0.224 0.225
  0.15  0.024 0.017 0.107 0.269 0.06  0.268 0.043 0.063 0.023 0.118 0.039
  0.088 0.05  0.082 0.038 0.243 0.042]
 [0.04  0.015 0.158 0.055 0.02  0.01  0.03  0.006 0.03  0.039 0.029 0.044
  0.085 0.021 0.006 0.037 0.169 0.033 0.083 0.019 0.055 0.011 0.034 0.029
  0.025 0.023 0.021 0.013 0.089 0.017]
 [0.084 0.045 0.124 0.081 0.028 0.025 0.078 0.188 0.005 0.045 0.097 0.058
  0.157 0.039 0.013 0.067 0.141 0.022 0.252 0.052 0.043 0.016 0.165 0.045
  0.038 0.017 0.068 0.025 0.085 0.069]
 [0.084 0.068 0.282 0.176 0.125 0.022 0.09  0.187 0.135 0.006 0.163 0.142
  0.216 0.048 0.021 0.075 0.287 0.054 0.511 0.037 0.159 0.044 0.249 0.085
  0.049 0.051 0.109 0.027 0.133 0.053]
 [0.053 0.037 0.089 0.087 0.047 0.01  0.036 0.237 0.082 0.044 0.007 0.125
  0.077 0.011 0.02  0.068 0.134 0.037 0.175 0.045 0.062 0.022 0.142 0.033
  0.026 0.008 0.04  0.013 0.233 0.037]
 [0.08  0.037 0.106 0.125 0.048 0.017 0.041 0.181 0.093 0.052 0.057 0.005
  0.056 0.03  0.009 0.024 0.178 0.038 0.232 0.015 0.095 0.015 0.043 0.024
  0.025 0.04  0.08  0.012 0.049 0.054]
 [0.072 0.04  0.095 0.145 0.118 0.025 0.053 0.072 0.051 0.033 0.048 0.158
  0.009 0.026 0.011 0.103 0.1   0.085 0.302 0.038 0.137 0.012 0.108 0.032
  0.024 0.029 0.044 0.019 0.067 0.073]
 [0.228 0.261 0.735 0.365 0.096 0.022 0.19  0.235 0.167 0.237 0.343 0.322
  0.236 0.004 0.033 0.272 0.294 0.175 0.641 0.084 0.169 0.039 0.372 0.081
  0.15  0.14  0.146 0.056 0.267 0.434]
 [0.423 0.589 0.737 1.222 0.201 0.129 0.466 0.651 0.431 0.272 0.349 0.814
  0.685 0.243 0.008 0.418 0.647 0.355 1.309 0.306 0.695 0.207 0.347 1.131
  0.185 0.303 0.376 0.15  0.524 0.344]
 [0.166 0.069 0.149 0.238 0.095 0.018 0.075 0.189 0.097 0.104 0.108 0.269
  0.093 0.028 0.011 0.007 0.28  0.033 0.187 0.03  0.164 0.034 0.108 0.038
  0.03  0.038 0.076 0.031 0.228 0.038]
 [0.064 0.028 0.102 0.035 0.038 0.012 0.028 0.064 0.037 0.029 0.042 0.044
  0.073 0.019 0.005 0.026 0.006 0.035 0.363 0.022 0.046 0.012 0.099 0.017
  0.015 0.024 0.051 0.018 0.1   0.031]
 [0.073 0.125 0.11  0.251 0.12  0.036 0.115 0.221 0.367 0.192 0.29  0.164
  0.122 0.054 0.029 0.219 0.205 0.008 0.452 0.069 0.113 0.062 0.133 0.106
  0.064 0.086 0.267 0.028 0.372 0.111]
 [0.011 0.024 0.091 0.025 0.025 0.004 0.029 0.103 0.023 0.012 0.034 0.024
  0.018 0.008 0.003 0.033 0.024 0.01  0.005 0.008 0.021 0.009 0.022 0.007
  0.019 0.02  0.019 0.012 0.044 0.019]
 [0.224 0.174 0.302 0.278 0.089 0.026 0.176 0.319 0.192 0.197 0.141 0.412
  0.169 0.108 0.031 0.234 0.405 0.122 0.512 0.007 0.296 0.049 0.158 0.383
  0.068 0.054 0.17  0.018 0.752 0.165]
 [0.094 0.027 0.185 0.177 0.046 0.017 0.087 0.124 0.224 0.05  0.125 0.097
  0.058 0.029 0.01  0.053 0.195 0.04  0.326 0.027 0.007 0.032 0.06  0.057
  0.05  0.036 0.179 0.044 0.228 0.073]
 [0.437 0.191 0.545 0.39  0.474 0.024 0.293 0.688 0.44  0.197 0.282 0.446
  0.407 0.149 0.036 0.168 0.583 0.087 0.795 0.144 0.27  0.004 0.421 0.276
  0.066 0.156 0.231 0.033 0.455 0.138]
 [0.043 0.035 0.09  0.1   0.041 0.013 0.046 0.141 0.067 0.029 0.059 0.174
  0.121 0.017 0.022 0.074 0.077 0.035 0.384 0.037 0.09  0.02  0.004 0.027
  0.042 0.022 0.052 0.023 0.102 0.037]
 [0.301 0.102 0.361 0.252 0.11  0.026 0.214 0.248 0.271 0.086 0.132 0.315
  0.196 0.087 0.005 0.248 0.264 0.065 0.95  0.019 0.138 0.025 0.19  0.005
  0.076 0.119 0.39  0.028 0.457 0.114]
 [0.257 0.127 0.342 0.371 0.081 0.02  0.074 0.328 0.3   0.14  0.281 0.361
  0.277 0.044 0.029 0.348 0.338 0.113 0.477 0.113 0.186 0.106 0.18  0.068
  0.005 0.195 0.148 0.037 0.473 0.137]
 [0.198 0.067 0.371 0.502 0.079 0.065 0.106 0.308 0.39  0.176 0.82  0.206
  0.208 0.079 0.02  0.181 0.422 0.117 0.283 0.138 0.207 0.062 0.392 0.075
  0.053 0.006 0.164 0.04  0.513 0.121]
 [0.129 0.018 0.148 0.136 0.124 0.017 0.087 0.299 0.079 0.05  0.114 0.144
  0.185 0.025 0.016 0.094 0.139 0.027 0.515 0.041 0.046 0.051 0.151 0.021
  0.059 0.05  0.006 0.014 0.263 0.062]
 [0.397 0.284 0.255 0.822 0.214 0.07  0.173 0.339 0.32  0.267 0.493 0.641
  0.36  0.131 0.063 0.249 0.461 0.276 0.579 0.377 0.202 0.235 0.393 0.221
  0.172 0.174 0.684 0.006 0.444 0.289]
 [0.042 0.016 0.108 0.109 0.027 0.011 0.038 0.091 0.066 0.035 0.034 0.156
  0.065 0.035 0.011 0.031 0.068 0.022 0.261 0.012 0.044 0.02  0.067 0.018
  0.019 0.015 0.034 0.014 0.006 0.037]
 [0.091 0.09  0.145 0.397 0.092 0.021 0.253 0.456 0.091 0.111 0.26  0.161
  0.056 0.023 0.011 0.156 0.212 0.077 0.325 0.036 0.125 0.062 0.244 0.071
  0.072 0.059 0.118 0.033 0.264 0.009]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.573 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.403 0.    0.    0.    0.445 0.    0.    0.    0.
  0.    0.    0.    0.    0.318 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.397 0.    0.343 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.444 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.308 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.317 0.416 0.455 0.548 0.625 0.    0.682 0.595 0.    0.356 0.447 0.471
  0.    0.    0.    0.394 0.638 0.309 0.657 0.    0.367 0.    0.542 0.
  0.362 0.    0.415 0.    0.656 0.484]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.511 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.302 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.735 0.365 0.    0.    0.    0.    0.    0.    0.343 0.322
  0.    0.    0.    0.    0.    0.    0.641 0.    0.    0.    0.372 0.
  0.    0.    0.    0.    0.    0.434]
 [0.423 0.589 0.737 1.222 0.    0.    0.466 0.651 0.431 0.    0.349 0.814
  0.685 0.    0.    0.418 0.647 0.355 1.309 0.306 0.695 0.    0.347 1.131
  0.    0.303 0.376 0.    0.524 0.344]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.363 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.367 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.452 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.372 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.302 0.    0.    0.    0.    0.319 0.    0.    0.    0.412
  0.    0.    0.    0.    0.405 0.    0.512 0.    0.    0.    0.    0.383
  0.    0.    0.    0.    0.752 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.326 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.437 0.    0.545 0.39  0.474 0.    0.    0.688 0.44  0.    0.    0.446
  0.407 0.    0.    0.    0.583 0.    0.795 0.    0.    0.    0.421 0.
  0.    0.    0.    0.    0.455 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.384 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.301 0.    0.361 0.    0.    0.    0.    0.    0.    0.    0.    0.315
  0.    0.    0.    0.    0.    0.    0.95  0.    0.    0.    0.    0.
  0.    0.    0.39  0.    0.457 0.   ]
 [0.    0.    0.342 0.371 0.    0.    0.    0.328 0.    0.    0.    0.361
  0.    0.    0.    0.348 0.338 0.    0.477 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.473 0.   ]
 [0.    0.    0.371 0.502 0.    0.    0.    0.308 0.39  0.    0.82  0.
  0.    0.    0.    0.    0.422 0.    0.    0.    0.    0.    0.392 0.
  0.    0.    0.    0.    0.513 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.515 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.397 0.    0.    0.822 0.    0.    0.    0.339 0.32  0.    0.493 0.641
  0.36  0.    0.    0.    0.461 0.    0.579 0.377 0.    0.    0.393 0.
  0.    0.    0.684 0.    0.444 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.397 0.    0.    0.    0.456 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.325 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]]
{'fdr': 0.7235772357723578, 'tpr': 0.2833333333333333, 'fpr': 0.28253968253968254, 'f1': 0.279835390946502, 'shd': 164, 'npred': 123, 'ntrue': 120}
[0.069 0.135 0.212 0.099 0.015 0.09  0.177 0.129 0.081 0.117 0.098 0.094
 0.027 0.016 0.061 0.134 0.1   0.573 0.024 0.106 0.014 0.129 0.032 0.033
 0.046 0.061 0.029 0.166 0.056 0.068 0.182 0.403 0.058 0.015 0.204 0.445
 0.109 0.104 0.234 0.243 0.217 0.036 0.016 0.098 0.318 0.099 0.255 0.06
 0.197 0.046 0.233 0.136 0.074 0.105 0.397 0.016 0.343 0.095 0.044 0.043
 0.039 0.038 0.012 0.049 0.056 0.046 0.031 0.08  0.053 0.09  0.009 0.009
 0.051 0.084 0.035 0.08  0.023 0.062 0.01  0.07  0.019 0.029 0.019 0.052
 0.022 0.065 0.049 0.028 0.008 0.113 0.057 0.017 0.052 0.113 0.101 0.032
 0.109 0.066 0.05  0.021 0.006 0.04  0.157 0.028 0.2   0.024 0.028 0.014
 0.102 0.024 0.02  0.018 0.064 0.008 0.049 0.017 0.091 0.118 0.27  0.146
 0.011 0.074 0.444 0.281 0.048 0.178 0.207 0.084 0.103 0.022 0.075 0.188
 0.05  0.308 0.067 0.114 0.022 0.235 0.052 0.078 0.078 0.062 0.042 0.22
 0.066 0.317 0.416 0.455 0.548 0.625 0.682 0.595 0.256 0.356 0.447 0.471
 0.191 0.298 0.104 0.394 0.638 0.309 0.657 0.276 0.367 0.292 0.542 0.202
 0.362 0.115 0.415 0.083 0.656 0.484 0.104 0.049 0.213 0.149 0.095 0.008
 0.273 0.106 0.076 0.224 0.225 0.15  0.024 0.017 0.107 0.269 0.06  0.268
 0.043 0.063 0.023 0.118 0.039 0.088 0.05  0.082 0.038 0.243 0.042 0.04
 0.015 0.158 0.055 0.02  0.01  0.03  0.03  0.039 0.029 0.044 0.085 0.021
 0.006 0.037 0.169 0.033 0.083 0.019 0.055 0.011 0.034 0.029 0.025 0.023
 0.021 0.013 0.089 0.017 0.084 0.045 0.124 0.081 0.028 0.025 0.078 0.188
 0.045 0.097 0.058 0.157 0.039 0.013 0.067 0.141 0.022 0.252 0.052 0.043
 0.016 0.165 0.045 0.038 0.017 0.068 0.025 0.085 0.069 0.084 0.068 0.282
 0.176 0.125 0.022 0.09  0.187 0.135 0.163 0.142 0.216 0.048 0.021 0.075
 0.287 0.054 0.511 0.037 0.159 0.044 0.249 0.085 0.049 0.051 0.109 0.027
 0.133 0.053 0.053 0.037 0.089 0.087 0.047 0.01  0.036 0.237 0.082 0.044
 0.125 0.077 0.011 0.02  0.068 0.134 0.037 0.175 0.045 0.062 0.022 0.142
 0.033 0.026 0.008 0.04  0.013 0.233 0.037 0.08  0.037 0.106 0.125 0.048
 0.017 0.041 0.181 0.093 0.052 0.057 0.056 0.03  0.009 0.024 0.178 0.038
 0.232 0.015 0.095 0.015 0.043 0.024 0.025 0.04  0.08  0.012 0.049 0.054
 0.072 0.04  0.095 0.145 0.118 0.025 0.053 0.072 0.051 0.033 0.048 0.158
 0.026 0.011 0.103 0.1   0.085 0.302 0.038 0.137 0.012 0.108 0.032 0.024
 0.029 0.044 0.019 0.067 0.073 0.228 0.261 0.735 0.365 0.096 0.022 0.19
 0.235 0.167 0.237 0.343 0.322 0.236 0.033 0.272 0.294 0.175 0.641 0.084
 0.169 0.039 0.372 0.081 0.15  0.14  0.146 0.056 0.267 0.434 0.423 0.589
 0.737 1.222 0.201 0.129 0.466 0.651 0.431 0.272 0.349 0.814 0.685 0.243
 0.418 0.647 0.355 1.309 0.306 0.695 0.207 0.347 1.131 0.185 0.303 0.376
 0.15  0.524 0.344 0.166 0.069 0.149 0.238 0.095 0.018 0.075 0.189 0.097
 0.104 0.108 0.269 0.093 0.028 0.011 0.28  0.033 0.187 0.03  0.164 0.034
 0.108 0.038 0.03  0.038 0.076 0.031 0.228 0.038 0.064 0.028 0.102 0.035
 0.038 0.012 0.028 0.064 0.037 0.029 0.042 0.044 0.073 0.019 0.005 0.026
 0.035 0.363 0.022 0.046 0.012 0.099 0.017 0.015 0.024 0.051 0.018 0.1
 0.031 0.073 0.125 0.11  0.251 0.12  0.036 0.115 0.221 0.367 0.192 0.29
 0.164 0.122 0.054 0.029 0.219 0.205 0.452 0.069 0.113 0.062 0.133 0.106
 0.064 0.086 0.267 0.028 0.372 0.111 0.011 0.024 0.091 0.025 0.025 0.004
 0.029 0.103 0.023 0.012 0.034 0.024 0.018 0.008 0.003 0.033 0.024 0.01
 0.008 0.021 0.009 0.022 0.007 0.019 0.02  0.019 0.012 0.044 0.019 0.224
 0.174 0.302 0.278 0.089 0.026 0.176 0.319 0.192 0.197 0.141 0.412 0.169
 0.108 0.031 0.234 0.405 0.122 0.512 0.296 0.049 0.158 0.383 0.068 0.054
 0.17  0.018 0.752 0.165 0.094 0.027 0.185 0.177 0.046 0.017 0.087 0.124
 0.224 0.05  0.125 0.097 0.058 0.029 0.01  0.053 0.195 0.04  0.326 0.027
 0.032 0.06  0.057 0.05  0.036 0.179 0.044 0.228 0.073 0.437 0.191 0.545
 0.39  0.474 0.024 0.293 0.688 0.44  0.197 0.282 0.446 0.407 0.149 0.036
 0.168 0.583 0.087 0.795 0.144 0.27  0.421 0.276 0.066 0.156 0.231 0.033
 0.455 0.138 0.043 0.035 0.09  0.1   0.041 0.013 0.046 0.141 0.067 0.029
 0.059 0.174 0.121 0.017 0.022 0.074 0.077 0.035 0.384 0.037 0.09  0.02
 0.027 0.042 0.022 0.052 0.023 0.102 0.037 0.301 0.102 0.361 0.252 0.11
 0.026 0.214 0.248 0.271 0.086 0.132 0.315 0.196 0.087 0.005 0.248 0.264
 0.065 0.95  0.019 0.138 0.025 0.19  0.076 0.119 0.39  0.028 0.457 0.114
 0.257 0.127 0.342 0.371 0.081 0.02  0.074 0.328 0.3   0.14  0.281 0.361
 0.277 0.044 0.029 0.348 0.338 0.113 0.477 0.113 0.186 0.106 0.18  0.068
 0.195 0.148 0.037 0.473 0.137 0.198 0.067 0.371 0.502 0.079 0.065 0.106
 0.308 0.39  0.176 0.82  0.206 0.208 0.079 0.02  0.181 0.422 0.117 0.283
 0.138 0.207 0.062 0.392 0.075 0.053 0.164 0.04  0.513 0.121 0.129 0.018
 0.148 0.136 0.124 0.017 0.087 0.299 0.079 0.05  0.114 0.144 0.185 0.025
 0.016 0.094 0.139 0.027 0.515 0.041 0.046 0.051 0.151 0.021 0.059 0.05
 0.014 0.263 0.062 0.397 0.284 0.255 0.822 0.214 0.07  0.173 0.339 0.32
 0.267 0.493 0.641 0.36  0.131 0.063 0.249 0.461 0.276 0.579 0.377 0.202
 0.235 0.393 0.221 0.172 0.174 0.684 0.444 0.289 0.042 0.016 0.108 0.109
 0.027 0.011 0.038 0.091 0.066 0.035 0.034 0.156 0.065 0.035 0.011 0.031
 0.068 0.022 0.261 0.012 0.044 0.02  0.067 0.018 0.019 0.015 0.034 0.014
 0.037 0.091 0.09  0.145 0.397 0.092 0.021 0.253 0.456 0.091 0.111 0.26
 0.161 0.056 0.023 0.011 0.156 0.212 0.077 0.325 0.036 0.125 0.062 0.244
 0.071 0.072 0.059 0.118 0.033 0.264]
[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 1.]
 [1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 0. 1.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.
  0. 1. 1. 0. 0. 0.]
 [0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
  0. 1. 0. 0. 0. 1.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1.
 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0.]
aucroc, aucpr (0.6028111111111111, 0.21807543887153302)
Iterations 2250
Achieves (3.524517146579602, 1e-05)-DP
