samples  5000  SCM  10 2 RE mim  minibatch size  50  noise  0.6  minibatches per NN training  250  DP methodology  plain_vanilla 8.0  box penalty  0
cpu
max degree  2.0  complexity indicator 1  625.0  complexity indicator 2  1086.9565217391305
model created without box penalty
model created without box penalty
cpu
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.1601221069006407
iteration 1 in outer loop, alpha = 1.1601221069006407, rho = 1.0, h = 1.1601221069006407
model created without box penalty
cpu
iteration 1 in inner loop,alpha 1.1601221069006407 rho 1.0 h 0.697926845742554
iteration 2 in inner loop,alpha 1.1601221069006407 rho 10.0 h 0.29175731529299753
iteration 3 in inner loop,alpha 1.1601221069006407 rho 100.0 h 0.08501950555491611
iteration 2 in outer loop, alpha = 9.662072662392251, rho = 100.0, h = 0.08501950555491611
model created without box penalty
cpu
iteration 1 in inner loop,alpha 9.662072662392251 rho 100.0 h 0.040170488512167424
iteration 2 in inner loop,alpha 9.662072662392251 rho 1000.0 h 0.00868366913203289
iteration 3 in outer loop, alpha = 18.34574179442514, rho = 1000.0, h = 0.00868366913203289
model created without box penalty
cpu
iteration 1 in inner loop,alpha 18.34574179442514 rho 1000.0 h 0.0030868790422431402
iteration 2 in inner loop,alpha 18.34574179442514 rho 10000.0 h 0.0008995705368377571
iteration 4 in outer loop, alpha = 27.341447162802712, rho = 10000.0, h = 0.0008995705368377571
model created without box penalty
cpu
iteration 1 in inner loop,alpha 27.341447162802712 rho 10000.0 h 0.0006484053062099093
iteration 2 in inner loop,alpha 27.341447162802712 rho 100000.0 h 0.0002616647124735749
iteration 5 in outer loop, alpha = 289.0061596363776, rho = 1000000.0, h = 0.0002616647124735749
Threshold 0.3
[[0.01  0.    2.439 0.    0.313 0.    0.201 0.    0.    0.052]
 [3.167 0.    0.255 0.    0.057 0.    0.025 0.    0.    0.049]
 [0.001 0.    0.003 0.    0.02  0.    3.039 0.    0.    0.016]
 [2.626 0.    0.121 0.    0.976 0.006 0.072 0.    0.    0.013]
 [0.001 0.    0.015 0.    0.003 0.    0.011 0.    0.    0.001]
 [0.021 0.007 0.019 0.    0.045 0.    0.033 0.    0.005 0.045]
 [0.    0.    0.    0.    0.004 0.    0.009 0.    0.    0.001]
 [0.045 0.    0.003 0.    0.143 0.009 0.081 0.    0.    3.237]
 [0.04  0.    0.064 0.004 0.117 0.    2.722 0.    0.    2.883]
 [0.016 0.    0.012 0.    2.19  0.    0.301 0.    0.    0.008]]
[[0.    0.    2.439 0.    0.313 0.    0.    0.    0.    0.   ]
 [3.167 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    3.039 0.    0.    0.   ]
 [2.626 0.    0.    0.    0.976 0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    3.237]
 [0.    0.    0.    0.    0.    0.    2.722 0.    0.    2.883]
 [0.    0.    0.    0.    2.19  0.    0.301 0.    0.    0.   ]]
{'fdr': 0.18181818181818182, 'tpr': 1.0, 'fpr': 0.05555555555555555, 'f1': 0.8999999999999999, 'shd': 2, 'npred': 11, 'ntrue': 9}
[3.269e-06 2.439e+00 2.360e-05 3.127e-01 1.057e-04 2.009e-01 1.136e-04
 6.644e-05 5.173e-02 3.167e+00 2.553e-01 1.845e-04 5.678e-02 1.726e-04
 2.526e-02 1.867e-04 1.036e-04 4.862e-02 6.936e-04 1.064e-05 4.596e-06
 2.025e-02 6.305e-05 3.039e+00 1.164e-04 1.147e-04 1.567e-02 2.626e+00
 1.722e-04 1.206e-01 9.764e-01 5.872e-03 7.239e-02 3.245e-04 5.762e-05
 1.254e-02 9.900e-04 2.162e-05 1.487e-02 2.243e-05 6.487e-05 1.146e-02
 5.745e-06 4.002e-06 6.108e-04 2.138e-02 6.722e-03 1.936e-02 2.459e-04
 4.486e-02 3.297e-02 1.213e-04 5.333e-03 4.493e-02 7.180e-05 2.638e-05
 9.349e-05 2.986e-06 4.291e-03 1.041e-04 1.811e-04 4.376e-06 1.285e-03
 4.487e-02 1.554e-04 2.565e-03 8.778e-05 1.427e-01 8.665e-03 8.118e-02
 8.880e-05 3.237e+00 4.033e-02 3.416e-04 6.358e-02 4.082e-03 1.167e-01
 8.093e-05 2.722e+00 2.648e-04 2.883e+00 1.620e-02 1.016e-04 1.176e-02
 1.046e-04 2.190e+00 2.991e-05 3.007e-01 3.538e-06 1.440e-05]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (1.0, 1.0)
model created without box penalty
cpu
cpu
[0.559 0.633 0.599 0.618 0.582 0.65  0.581 0.777 0.565 0.59  0.563 0.595
 0.599 0.652 0.572 0.425 0.563 0.623 0.674 0.547 0.67  0.464 0.587 0.633
 0.513 0.67  0.619 0.664 0.569 0.534 0.421 0.561 0.638 0.437 0.543 0.523
 0.602 0.65  0.636 0.545 0.456 0.5   0.452 0.503 0.559 0.545 0.595 0.518
 0.583 0.615 0.586 0.566 0.608 0.69  0.562 0.643 0.552 0.466 0.638 0.594
 0.626 0.59  0.652 0.749 0.536 0.64  0.519 0.682 0.581 0.683 0.469 0.408
 0.488 0.647 0.596 0.555 0.586 0.613 0.659 0.696 0.579 0.623 0.589 0.663
 0.464 0.539 0.399 0.605 0.732 0.502]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.49382716049382713, 0.11721121018714775)
Objective function 186.49 = squared loss an data 9.43 + 0.5*rho*h**2 176.710652 + alpha*h 0.000000 + L2reg 0.19 + L1reg 0.16 ; SHD = 55 ; DAG False
microbatch grad before clipping 14.548165053057545
microbatch grad before clipping 10.939749167908415
microbatch grad before clipping 10.265402271176994
microbatch grad before clipping 6.899970339352924
microbatch grad before clipping 12.783104770423183
microbatch grad before clipping 7.9678470004240385
microbatch grad before clipping 7.229504311245636
microbatch grad before clipping 12.129844019339236
microbatch grad before clipping 5.4761219571959385
microbatch grad before clipping 7.5924547988931765
cpu
[0.238 0.392 0.218 0.127 0.266 0.19  0.097 0.189 0.131 0.495 0.093 0.194
 0.131 0.18  0.277 0.106 0.197 0.206 0.315 0.342 0.244 0.2   0.305 0.37
 0.137 0.245 0.211 0.628 0.269 0.163 0.329 0.215 0.291 0.271 0.212 0.174
 0.252 0.295 0.149 0.222 0.107 0.165 0.206 0.183 0.287 0.181 0.191 0.182
 0.16  0.328 0.181 0.142 0.111 0.096 0.158 0.138 0.286 0.148 0.193 0.183
 0.141 0.135 0.133 0.262 0.325 0.173 0.148 0.264 0.18  0.237 0.196 0.707
 0.171 0.245 0.258 0.133 0.161 0.303 0.602 0.226 0.418 0.183 0.19  0.195
 0.215 0.418 0.25  0.148 0.195 0.164]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9986282578875171, 0.9888888888888889)
Objective function 5.63 = squared loss an data 4.82 + 0.5*rho*h**2 0.471159 + alpha*h 0.000000 + L2reg 0.28 + L1reg 0.06 ; SHD = 10 ; DAG False
Proportion of microbatches that were clipped  0.5197827144478677
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 0.9707302655239687
iteration 1 in outer loop, alpha = 0.9707302655239687, rho = 1.0, h = 0.9707302655239687
cpu
cpu
[0.238 0.392 0.218 0.127 0.266 0.19  0.097 0.189 0.131 0.495 0.093 0.194
 0.131 0.18  0.277 0.106 0.197 0.206 0.315 0.342 0.244 0.2   0.305 0.37
 0.137 0.245 0.211 0.628 0.269 0.163 0.329 0.215 0.291 0.271 0.212 0.174
 0.252 0.295 0.149 0.222 0.107 0.165 0.206 0.183 0.287 0.181 0.191 0.182
 0.16  0.328 0.181 0.142 0.111 0.096 0.158 0.138 0.286 0.148 0.193 0.183
 0.141 0.135 0.133 0.262 0.325 0.173 0.148 0.264 0.18  0.237 0.196 0.707
 0.171 0.245 0.258 0.133 0.161 0.303 0.602 0.226 0.418 0.183 0.19  0.195
 0.215 0.418 0.25  0.148 0.195 0.164]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9986282578875171, 0.9888888888888889)
Objective function 6.57 = squared loss an data 4.82 + 0.5*rho*h**2 0.471159 + alpha*h 0.942317 + L2reg 0.28 + L1reg 0.06 ; SHD = 10 ; DAG False
microbatch grad before clipping 13.07023107550281
microbatch grad before clipping 15.125871319405636
microbatch grad before clipping 7.378934681678469
microbatch grad before clipping 7.793439144719593
microbatch grad before clipping 6.236617434451054
microbatch grad before clipping 11.230390678881927
microbatch grad before clipping 11.648412153362141
microbatch grad before clipping 8.639113264456201
microbatch grad before clipping 13.425029612453047
microbatch grad before clipping 13.434595534933283
cpu
[0.332 0.325 0.279 0.122 0.138 0.193 0.152 0.233 0.111 0.233 0.225 0.182
 0.129 0.209 0.132 0.094 0.13  0.194 0.228 0.178 0.209 0.253 0.135 0.252
 0.128 0.194 0.3   0.32  0.279 0.217 0.153 0.214 0.252 0.195 0.15  0.18
 0.219 0.16  0.196 0.278 0.283 0.163 0.278 0.245 0.269 0.256 0.204 0.159
 0.201 0.138 0.211 0.099 0.181 0.195 0.16  0.197 0.25  0.135 0.199 0.249
 0.161 0.253 0.189 0.258 0.365 0.201 0.14  0.121 0.189 0.137 0.34  0.341
 0.106 0.238 0.307 0.22  0.149 0.22  0.281 0.072 0.302 0.25  0.187 0.067
 0.139 0.276 0.172 0.108 0.321 0.259]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.821673525377229, 0.3572240656101239)
Objective function 5.77 = squared loss an data 4.31 + 0.5*rho*h**2 0.231762 + alpha*h 0.660898 + L2reg 0.51 + L1reg 0.05 ; SHD = 13 ; DAG False
Proportion of microbatches that were clipped  0.6877269426289034
iteration 1 in inner loop, alpha 0.9707302655239687 rho 1.0 h 0.6808258448748727
cpu
[0.332 0.325 0.279 0.122 0.138 0.193 0.152 0.233 0.111 0.233 0.225 0.182
 0.129 0.209 0.132 0.094 0.13  0.194 0.228 0.178 0.209 0.253 0.135 0.252
 0.128 0.194 0.3   0.32  0.279 0.217 0.153 0.214 0.252 0.195 0.15  0.18
 0.219 0.16  0.196 0.278 0.283 0.163 0.278 0.245 0.269 0.256 0.204 0.159
 0.201 0.138 0.211 0.099 0.181 0.195 0.16  0.197 0.25  0.135 0.199 0.249
 0.161 0.253 0.189 0.258 0.365 0.201 0.14  0.121 0.189 0.137 0.34  0.341
 0.106 0.238 0.307 0.22  0.149 0.22  0.281 0.072 0.302 0.25  0.187 0.067
 0.139 0.276 0.172 0.108 0.321 0.259]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.821673525377229, 0.3572240656101239)
Objective function 7.86 = squared loss an data 4.31 + 0.5*rho*h**2 2.317619 + alpha*h 0.660898 + L2reg 0.51 + L1reg 0.05 ; SHD = 13 ; DAG False
microbatch grad before clipping 10.232119186140805
microbatch grad before clipping 10.872216695243186
microbatch grad before clipping 6.51532998792757
microbatch grad before clipping 9.61578744955379
microbatch grad before clipping 8.386279448929196
microbatch grad before clipping 6.925307820484758
microbatch grad before clipping 17.503653225725024
microbatch grad before clipping 8.94347811101345
microbatch grad before clipping 10.254972627545731
microbatch grad before clipping 7.805849405842635
microbatch grad before clipping 18.160814276306375
cpu
[0.322 0.293 0.207 0.133 0.218 0.177 0.177 0.161 0.181 0.255 0.126 0.194
 0.136 0.25  0.198 0.106 0.237 0.276 0.226 0.227 0.147 0.166 0.163 0.215
 0.072 0.173 0.198 0.331 0.171 0.158 0.236 0.09  0.217 0.1   0.156 0.154
 0.16  0.13  0.111 0.187 0.36  0.208 0.226 0.168 0.23  0.157 0.123 0.141
 0.263 0.104 0.143 0.202 0.112 0.15  0.1   0.138 0.218 0.132 0.107 0.219
 0.081 0.163 0.147 0.122 0.216 0.308 0.248 0.126 0.147 0.22  0.115 0.371
 0.115 0.13  0.24  0.183 0.119 0.221 0.437 0.313 0.327 0.121 0.086 0.12
 0.162 0.24  0.134 0.196 0.201 0.194]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9300411522633745, 0.6462962962962964)
Objective function 6.37 = squared loss an data 5.10 + 0.5*rho*h**2 0.341328 + alpha*h 0.253629 + L2reg 0.63 + L1reg 0.05 ; SHD = 8 ; DAG True
Proportion of microbatches that were clipped  0.8310620111281348
iteration 2 in inner loop, alpha 0.9707302655239687 rho 10.0 h 0.26127687857990445
cpu
[0.322 0.293 0.207 0.133 0.218 0.177 0.177 0.161 0.181 0.255 0.126 0.194
 0.136 0.25  0.198 0.106 0.237 0.276 0.226 0.227 0.147 0.166 0.163 0.215
 0.072 0.173 0.198 0.331 0.171 0.158 0.236 0.09  0.217 0.1   0.156 0.154
 0.16  0.13  0.111 0.187 0.36  0.208 0.226 0.168 0.23  0.157 0.123 0.141
 0.263 0.104 0.143 0.202 0.112 0.15  0.1   0.138 0.218 0.132 0.107 0.219
 0.081 0.163 0.147 0.122 0.216 0.308 0.248 0.126 0.147 0.22  0.115 0.371
 0.115 0.13  0.24  0.183 0.119 0.221 0.437 0.313 0.327 0.121 0.086 0.12
 0.162 0.24  0.134 0.196 0.201 0.194]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9300411522633745, 0.6462962962962964)
Objective function 9.44 = squared loss an data 5.10 + 0.5*rho*h**2 3.413280 + alpha*h 0.253629 + L2reg 0.63 + L1reg 0.05 ; SHD = 8 ; DAG True
microbatch grad before clipping 21.020637687333043
microbatch grad before clipping 19.66361611225757
microbatch grad before clipping 12.271764436569574
microbatch grad before clipping 10.519058140179517
microbatch grad before clipping 40.94323863189334
microbatch grad before clipping 17.612632349527804
microbatch grad before clipping 33.47331575107193
microbatch grad before clipping 48.41575006788536
microbatch grad before clipping 6.376822045927018
microbatch grad before clipping 17.349731031092357
microbatch grad before clipping 11.358182082126449
microbatch grad before clipping 15.483517574920812
microbatch grad before clipping 16.439018499920916
cpu
[0.124 0.275 0.062 0.113 0.34  0.164 0.279 0.097 0.269 0.266 0.158 0.209
 0.179 0.308 0.16  0.173 0.169 0.137 0.18  0.119 0.209 0.17  0.192 0.202
 0.174 0.071 0.198 0.42  0.091 0.159 0.199 0.363 0.332 0.153 0.105 0.149
 0.131 0.128 0.093 0.098 0.229 0.084 0.173 0.105 0.233 0.038 0.095 0.098
 0.062 0.113 0.102 0.106 0.113 0.096 0.11  0.144 0.192 0.064 0.154 0.231
 0.124 0.084 0.115 0.097 0.138 0.071 0.182 0.128 0.132 0.108 0.05  0.46
 0.201 0.097 0.234 0.202 0.188 0.193 0.424 0.308 0.309 0.053 0.133 0.063
 0.135 0.256 0.275 0.159 0.055 0.094]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9245541838134431, 0.6272053872053871)
Objective function 7.18 = squared loss an data 6.11 + 0.5*rho*h**2 0.320533 + alpha*h 0.077723 + L2reg 0.63 + L1reg 0.04 ; SHD = 10 ; DAG True
Proportion of microbatches that were clipped  0.9051195090439277
iteration 3 in inner loop, alpha 0.9707302655239687 rho 100.0 h 0.0800665825059017
iteration 2 in outer loop, alpha = 8.97738851611414, rho = 100.0, h = 0.0800665825059017
cpu
cpu
[0.124 0.275 0.062 0.113 0.34  0.164 0.279 0.097 0.269 0.266 0.158 0.209
 0.179 0.308 0.16  0.173 0.169 0.137 0.18  0.119 0.209 0.17  0.192 0.202
 0.174 0.071 0.198 0.42  0.091 0.159 0.199 0.363 0.332 0.153 0.105 0.149
 0.131 0.128 0.093 0.098 0.229 0.084 0.173 0.105 0.233 0.038 0.095 0.098
 0.062 0.113 0.102 0.106 0.113 0.096 0.11  0.144 0.192 0.064 0.154 0.231
 0.124 0.084 0.115 0.097 0.138 0.071 0.182 0.128 0.132 0.108 0.05  0.46
 0.201 0.097 0.234 0.202 0.188 0.193 0.424 0.308 0.309 0.053 0.133 0.063
 0.135 0.256 0.275 0.159 0.055 0.094]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9245541838134431, 0.6272053872053871)
Objective function 7.82 = squared loss an data 6.11 + 0.5*rho*h**2 0.320533 + alpha*h 0.718789 + L2reg 0.63 + L1reg 0.04 ; SHD = 10 ; DAG True
microbatch grad before clipping 14.761818939939603
microbatch grad before clipping 13.383049076399397
microbatch grad before clipping 27.642978145301115
microbatch grad before clipping 9.541203213699792
microbatch grad before clipping 18.103858168259247
microbatch grad before clipping 21.87259281168722
microbatch grad before clipping 13.470870559208024
microbatch grad before clipping 24.636720606568502
microbatch grad before clipping 14.695211840320649
microbatch grad before clipping 10.82467489322655
microbatch grad before clipping 6.129608132968443
microbatch grad before clipping 9.95647559794419
microbatch grad before clipping 14.484994698453887
microbatch grad before clipping 18.667672438167738
microbatch grad before clipping 14.749407650299549
microbatch grad before clipping 10.898568798749258
microbatch grad before clipping 13.395682635120991
cpu
[0.059 0.277 0.049 0.202 0.177 0.107 0.135 0.102 0.142 0.468 0.127 0.126
 0.177 0.275 0.15  0.155 0.12  0.107 0.187 0.151 0.191 0.163 0.072 0.188
 0.117 0.051 0.194 0.486 0.083 0.111 0.12  0.107 0.152 0.234 0.123 0.19
 0.075 0.11  0.084 0.133 0.12  0.112 0.238 0.098 0.195 0.076 0.053 0.18
 0.148 0.089 0.179 0.078 0.109 0.07  0.099 0.11  0.163 0.139 0.146 0.102
 0.105 0.034 0.179 0.094 0.093 0.133 0.098 0.041 0.184 0.141 0.048 0.508
 0.155 0.167 0.332 0.12  0.173 0.136 0.567 0.355 0.364 0.09  0.152 0.106
 0.082 0.216 0.168 0.066 0.067 0.069]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9176954732510287, 0.7723171889838558)
Objective function 7.61 = squared loss an data 6.55 + 0.5*rho*h**2 0.072827 + alpha*h 0.342619 + L2reg 0.61 + L1reg 0.04 ; SHD = 6 ; DAG True
Proportion of microbatches that were clipped  0.9109262698861342
iteration 1 in inner loop, alpha 8.97738851611414 rho 100.0 h 0.03816464915658102
cpu
[0.059 0.277 0.049 0.202 0.177 0.107 0.135 0.102 0.142 0.468 0.127 0.126
 0.177 0.275 0.15  0.155 0.12  0.107 0.187 0.151 0.191 0.163 0.072 0.188
 0.117 0.051 0.194 0.486 0.083 0.111 0.12  0.107 0.152 0.234 0.123 0.19
 0.075 0.11  0.084 0.133 0.12  0.112 0.238 0.098 0.195 0.076 0.053 0.18
 0.148 0.089 0.179 0.078 0.109 0.07  0.099 0.11  0.163 0.139 0.146 0.102
 0.105 0.034 0.179 0.094 0.093 0.133 0.098 0.041 0.184 0.141 0.048 0.508
 0.155 0.167 0.332 0.12  0.173 0.136 0.567 0.355 0.364 0.09  0.152 0.106
 0.082 0.216 0.168 0.066 0.067 0.069]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9176954732510287, 0.7723171889838558)
Objective function 8.27 = squared loss an data 6.55 + 0.5*rho*h**2 0.728270 + alpha*h 0.342619 + L2reg 0.61 + L1reg 0.04 ; SHD = 6 ; DAG True
microbatch grad before clipping 10.212665008005047
microbatch grad before clipping 15.02376790876366
microbatch grad before clipping 10.740784352976789
microbatch grad before clipping 23.500043521971786
microbatch grad before clipping 12.955921349572863
microbatch grad before clipping 19.90612993577693
microbatch grad before clipping 28.336689789335367
cpu
[0.037 0.218 0.029 0.176 0.226 0.089 0.041 0.089 0.223 0.505 0.123 0.132
 0.104 0.156 0.192 0.118 0.083 0.109 0.125 0.115 0.123 0.063 0.132 0.246
 0.156 0.066 0.127 0.509 0.085 0.125 0.333 0.259 0.074 0.102 0.104 0.16
 0.086 0.091 0.146 0.04  0.131 0.12  0.108 0.079 0.171 0.051 0.031 0.092
 0.059 0.088 0.059 0.17  0.147 0.108 0.095 0.055 0.136 0.105 0.098 0.105
 0.1   0.024 0.119 0.187 0.098 0.098 0.139 0.109 0.081 0.128 0.117 0.666
 0.189 0.104 0.226 0.12  0.088 0.082 0.715 0.119 0.468 0.043 0.143 0.112
 0.075 0.213 0.115 0.087 0.028 0.025]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9876543209876543, 0.9148860398860401)
Objective function 7.86 = squared loss an data 6.92 + 0.5*rho*h**2 0.178173 + alpha*h 0.169467 + L2reg 0.56 + L1reg 0.03 ; SHD = 3 ; DAG True
Proportion of microbatches that were clipped  0.9316789946711207
iteration 2 in inner loop, alpha 8.97738851611414 rho 1000.0 h 0.018877132635836347
iteration 3 in outer loop, alpha = 27.854521151950486, rho = 1000.0, h = 0.018877132635836347
cpu
cpu
[0.037 0.218 0.029 0.176 0.226 0.089 0.041 0.089 0.223 0.505 0.123 0.132
 0.104 0.156 0.192 0.118 0.083 0.109 0.125 0.115 0.123 0.063 0.132 0.246
 0.156 0.066 0.127 0.509 0.085 0.125 0.333 0.259 0.074 0.102 0.104 0.16
 0.086 0.091 0.146 0.04  0.131 0.12  0.108 0.079 0.171 0.051 0.031 0.092
 0.059 0.088 0.059 0.17  0.147 0.108 0.095 0.055 0.136 0.105 0.098 0.105
 0.1   0.024 0.119 0.187 0.098 0.098 0.139 0.109 0.081 0.128 0.117 0.666
 0.189 0.104 0.226 0.12  0.088 0.082 0.715 0.119 0.468 0.043 0.143 0.112
 0.075 0.213 0.115 0.087 0.028 0.025]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9876543209876543, 0.9148860398860401)
Objective function 8.22 = squared loss an data 6.92 + 0.5*rho*h**2 0.178173 + alpha*h 0.525813 + L2reg 0.56 + L1reg 0.03 ; SHD = 3 ; DAG True
microbatch grad before clipping 21.607855584757353
microbatch grad before clipping 13.155434269382624
microbatch grad before clipping 19.341772419927505
microbatch grad before clipping 9.8090141811336
microbatch grad before clipping 12.522816979943023
microbatch grad before clipping 7.280608478454789
microbatch grad before clipping 15.783804125743575
microbatch grad before clipping 11.717878413402277
microbatch grad before clipping 15.86117624007505
microbatch grad before clipping 20.937718877282634
microbatch grad before clipping 15.15197847432904
microbatch grad before clipping 13.045469549795202
microbatch grad before clipping 19.45208086812724
microbatch grad before clipping 10.163915417351115
microbatch grad before clipping 11.827902331690819
microbatch grad before clipping 42.54477096906093
microbatch grad before clipping 11.14097082838951
microbatch grad before clipping 26.148317497837834
microbatch grad before clipping 8.507515450469095
microbatch grad before clipping 14.268158607998886
microbatch grad before clipping 17.284509248755015
microbatch grad before clipping 25.8561616490342
cpu
[0.009 0.29  0.016 0.138 0.04  0.088 0.052 0.046 0.115 0.887 0.31  0.065
 0.216 0.119 0.25  0.049 0.185 0.219 0.105 0.031 0.066 0.049 0.086 0.306
 0.071 0.064 0.148 0.819 0.134 0.186 0.327 0.16  0.14  0.228 0.107 0.195
 0.041 0.06  0.159 0.035 0.122 0.146 0.016 0.075 0.116 0.121 0.056 0.139
 0.08  0.062 0.153 0.068 0.122 0.177 0.088 0.035 0.065 0.085 0.071 0.046
 0.068 0.017 0.121 0.185 0.188 0.184 0.049 0.346 0.156 0.219 0.066 0.799
 0.128 0.059 0.137 0.086 0.148 0.089 0.68  0.189 0.498 0.06  0.059 0.068
 0.062 0.253 0.058 0.095 0.013 0.029]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.99039780521262, 0.9170113836780505)
Objective function 7.99 = squared loss an data 7.12 + 0.5*rho*h**2 0.045995 + alpha*h 0.267155 + L2reg 0.52 + L1reg 0.04 ; SHD = 4 ; DAG True
Proportion of microbatches that were clipped  0.9320923543980187
iteration 1 in inner loop, alpha 27.854521151950486 rho 1000.0 h 0.009591096214194295
cpu
[0.009 0.29  0.016 0.138 0.04  0.088 0.052 0.046 0.115 0.887 0.31  0.065
 0.216 0.119 0.25  0.049 0.185 0.219 0.105 0.031 0.066 0.049 0.086 0.306
 0.071 0.064 0.148 0.819 0.134 0.186 0.327 0.16  0.14  0.228 0.107 0.195
 0.041 0.06  0.159 0.035 0.122 0.146 0.016 0.075 0.116 0.121 0.056 0.139
 0.08  0.062 0.153 0.068 0.122 0.177 0.088 0.035 0.065 0.085 0.071 0.046
 0.068 0.017 0.121 0.185 0.188 0.184 0.049 0.346 0.156 0.219 0.066 0.799
 0.128 0.059 0.137 0.086 0.148 0.089 0.68  0.189 0.498 0.06  0.059 0.068
 0.062 0.253 0.058 0.095 0.013 0.029]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.99039780521262, 0.9170113836780505)
Objective function 8.40 = squared loss an data 7.12 + 0.5*rho*h**2 0.459946 + alpha*h 0.267155 + L2reg 0.52 + L1reg 0.04 ; SHD = 4 ; DAG True
microbatch grad before clipping 20.21203912939851
microbatch grad before clipping 16.087243980224507
microbatch grad before clipping 10.469254194067162
microbatch grad before clipping 12.067980155234034
microbatch grad before clipping 10.954950717067291
microbatch grad before clipping 9.409606670081907
microbatch grad before clipping 36.840135466645975
microbatch grad before clipping 20.034737599300144
microbatch grad before clipping 14.400050503936297
microbatch grad before clipping 9.19273507770155
microbatch grad before clipping 10.308592505950601
microbatch grad before clipping 12.93729678871581
cpu
[0.006 0.381 0.01  0.079 0.045 0.074 0.024 0.039 0.06  1.245 0.455 0.038
 0.276 0.178 0.194 0.14  0.216 0.291 0.032 0.013 0.025 0.084 0.044 0.4
 0.035 0.031 0.121 1.027 0.272 0.256 0.17  0.119 0.224 0.071 0.087 0.144
 0.104 0.022 0.087 0.048 0.076 0.121 0.013 0.045 0.047 0.148 0.042 0.104
 0.052 0.102 0.098 0.074 0.031 0.093 0.082 0.02  0.023 0.028 0.07  0.09
 0.054 0.009 0.073 0.19  0.059 0.149 0.091 0.301 0.091 0.151 0.031 1.194
 0.141 0.033 0.224 0.087 0.078 0.239 0.682 0.218 0.585 0.11  0.03  0.061
 0.055 0.313 0.087 0.072 0.005 0.014]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9766803840877915, 0.8902595659842039)
Objective function 7.94 = squared loss an data 7.25 + 0.5*rho*h**2 0.081407 + alpha*h 0.112393 + L2reg 0.46 + L1reg 0.04 ; SHD = 3 ; DAG True
Proportion of microbatches that were clipped  0.937430522471018
iteration 2 in inner loop, alpha 27.854521151950486 rho 10000.0 h 0.004035017553290388
iteration 4 in outer loop, alpha = 68.20469668485435, rho = 10000.0, h = 0.004035017553290388
cpu
cpu
[0.006 0.381 0.01  0.079 0.045 0.074 0.024 0.039 0.06  1.245 0.455 0.038
 0.276 0.178 0.194 0.14  0.216 0.291 0.032 0.013 0.025 0.084 0.044 0.4
 0.035 0.031 0.121 1.027 0.272 0.256 0.17  0.119 0.224 0.071 0.087 0.144
 0.104 0.022 0.087 0.048 0.076 0.121 0.013 0.045 0.047 0.148 0.042 0.104
 0.052 0.102 0.098 0.074 0.031 0.093 0.082 0.02  0.023 0.028 0.07  0.09
 0.054 0.009 0.073 0.19  0.059 0.149 0.091 0.301 0.091 0.151 0.031 1.194
 0.141 0.033 0.224 0.087 0.078 0.239 0.682 0.218 0.585 0.11  0.03  0.061
 0.055 0.313 0.087 0.072 0.005 0.014]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9766803840877915, 0.8902595659842039)
Objective function 8.10 = squared loss an data 7.25 + 0.5*rho*h**2 0.081407 + alpha*h 0.275207 + L2reg 0.46 + L1reg 0.04 ; SHD = 3 ; DAG True
microbatch grad before clipping 18.400293661481346
microbatch grad before clipping 17.1242269401443
microbatch grad before clipping 12.283522668845402
microbatch grad before clipping 11.033013664033488
microbatch grad before clipping 16.402848895831166
microbatch grad before clipping 13.043323887069604
microbatch grad before clipping 12.611561829667492
microbatch grad before clipping 9.72959044153957
cpu
[0.004 0.365 0.005 0.111 0.069 0.098 0.02  0.036 0.102 1.522 0.33  0.034
 0.286 0.267 0.184 0.087 0.156 0.416 0.021 0.008 0.013 0.182 0.036 0.378
 0.053 0.039 0.097 1.278 0.183 0.464 0.314 0.118 0.427 0.069 0.141 0.278
 0.045 0.021 0.046 0.017 0.048 0.167 0.012 0.025 0.021 0.049 0.023 0.091
 0.035 0.116 0.19  0.023 0.076 0.082 0.044 0.024 0.028 0.02  0.029 0.037
 0.016 0.012 0.047 0.31  0.084 0.081 0.075 0.32  0.28  0.184 0.081 1.237
 0.154 0.041 0.142 0.054 0.149 0.067 0.744 0.076 0.747 0.04  0.008 0.059
 0.02  0.467 0.065 0.128 0.002 0.005]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9849108367626885, 0.8966810966810967)
Objective function 7.96 = squared loss an data 7.35 + 0.5*rho*h**2 0.022030 + alpha*h 0.143164 + L2reg 0.40 + L1reg 0.04 ; SHD = 6 ; DAG True
Proportion of microbatches that were clipped  0.9386057032070442
iteration 1 in inner loop, alpha 68.20469668485435 rho 10000.0 h 0.0020990311977477916
cpu
[0.004 0.365 0.005 0.111 0.069 0.098 0.02  0.036 0.102 1.522 0.33  0.034
 0.286 0.267 0.184 0.087 0.156 0.416 0.021 0.008 0.013 0.182 0.036 0.378
 0.053 0.039 0.097 1.278 0.183 0.464 0.314 0.118 0.427 0.069 0.141 0.278
 0.045 0.021 0.046 0.017 0.048 0.167 0.012 0.025 0.021 0.049 0.023 0.091
 0.035 0.116 0.19  0.023 0.076 0.082 0.044 0.024 0.028 0.02  0.029 0.037
 0.016 0.012 0.047 0.31  0.084 0.081 0.075 0.32  0.28  0.184 0.081 1.237
 0.154 0.041 0.142 0.054 0.149 0.067 0.744 0.076 0.747 0.04  0.008 0.059
 0.02  0.467 0.065 0.128 0.002 0.005]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9849108367626885, 0.8966810966810967)
Objective function 8.15 = squared loss an data 7.35 + 0.5*rho*h**2 0.220297 + alpha*h 0.143164 + L2reg 0.40 + L1reg 0.04 ; SHD = 6 ; DAG True
microbatch grad before clipping 15.274890985808677
microbatch grad before clipping 13.225800915343235
microbatch grad before clipping 15.446064289987955
microbatch grad before clipping 8.109604665545422
microbatch grad before clipping 19.824095297896438
microbatch grad before clipping 12.450201634079152
microbatch grad before clipping 9.797353604502874
microbatch grad before clipping 10.69789566082053
microbatch grad before clipping 12.387466908064937
microbatch grad before clipping 14.51850436885061
microbatch grad before clipping 10.752055045580068
microbatch grad before clipping 18.113303736625923
microbatch grad before clipping 12.091556773624543
microbatch grad before clipping 15.492779439413122
cpu
[1.109e-03 4.002e-01 2.642e-03 6.958e-02 9.332e-02 1.127e-01 1.546e-02
 2.967e-02 6.479e-02 1.948e+00 4.133e-01 3.873e-02 2.757e-01 4.207e-01
 3.778e-01 5.344e-02 1.260e-01 3.721e-01 1.533e-02 3.467e-03 8.368e-03
 1.251e-01 8.144e-02 4.458e-01 1.850e-02 1.969e-02 5.849e-02 1.648e+00
 1.269e-01 5.227e-01 5.107e-01 2.956e-01 3.030e-01 6.280e-02 1.314e-01
 2.352e-01 5.303e-02 1.098e-02 4.329e-02 9.573e-03 3.721e-02 5.157e-02
 5.015e-03 1.001e-02 1.186e-02 5.075e-02 1.353e-02 5.092e-02 2.217e-02
 1.883e-01 7.866e-02 1.998e-02 4.586e-02 3.820e-02 3.061e-02 1.087e-02
 9.217e-03 1.250e-02 7.296e-02 5.924e-02 1.717e-02 4.585e-03 5.959e-02
 2.625e-01 7.212e-02 1.125e-01 7.105e-02 3.024e-01 2.401e-01 2.673e-01
 9.291e-02 1.527e+00 1.852e-01 4.719e-02 2.101e-01 3.386e-02 2.435e-01
 1.001e-01 7.396e-01 5.437e-02 7.790e-01 4.604e-02 7.156e-03 6.594e-02
 2.315e-02 5.049e-01 7.314e-02 6.796e-02 2.430e-03 4.444e-03]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9917695473251029, 0.9301146384479719)
Objective function 7.84 = squared loss an data 7.30 + 0.5*rho*h**2 0.051504 + alpha*h 0.069223 + L2reg 0.38 + L1reg 0.04 ; SHD = 7 ; DAG True
Proportion of microbatches that were clipped  0.9706091490874614
iteration 2 in inner loop, alpha 68.20469668485435 rho 100000.0 h 0.001014933073228974
iteration 5 in outer loop, alpha = 1083.1377699138284, rho = 1000000.0, h = 0.001014933073228974
Threshold 0.3
[[0.003 0.001 0.4   0.003 0.07  0.093 0.113 0.015 0.03  0.065]
 [1.948 0.002 0.413 0.039 0.276 0.421 0.378 0.053 0.126 0.372]
 [0.015 0.003 0.006 0.008 0.125 0.081 0.446 0.019 0.02  0.058]
 [1.648 0.127 0.523 0.004 0.511 0.296 0.303 0.063 0.131 0.235]
 [0.053 0.011 0.043 0.01  0.003 0.037 0.052 0.005 0.01  0.012]
 [0.051 0.014 0.051 0.022 0.188 0.002 0.079 0.02  0.046 0.038]
 [0.031 0.011 0.009 0.012 0.073 0.059 0.006 0.017 0.005 0.06 ]
 [0.263 0.072 0.112 0.071 0.302 0.24  0.267 0.003 0.093 1.527]
 [0.185 0.047 0.21  0.034 0.244 0.1   0.74  0.054 0.003 0.779]
 [0.046 0.007 0.066 0.023 0.505 0.073 0.068 0.002 0.004 0.004]]
[[0.    0.    0.4   0.    0.    0.    0.    0.    0.    0.   ]
 [1.948 0.    0.413 0.    0.    0.421 0.378 0.    0.    0.372]
 [0.    0.    0.    0.    0.    0.    0.446 0.    0.    0.   ]
 [1.648 0.    0.523 0.    0.511 0.    0.303 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.302 0.    0.    0.    0.    1.527]
 [0.    0.    0.    0.    0.    0.    0.74  0.    0.    0.779]
 [0.    0.    0.    0.    0.505 0.    0.    0.    0.    0.   ]]
{'fdr': 0.4375, 'tpr': 1.0, 'fpr': 0.19444444444444445, 'f1': 0.72, 'shd': 7, 'npred': 16, 'ntrue': 9}
[1.109e-03 4.002e-01 2.642e-03 6.958e-02 9.332e-02 1.127e-01 1.546e-02
 2.967e-02 6.479e-02 1.948e+00 4.133e-01 3.873e-02 2.757e-01 4.207e-01
 3.778e-01 5.344e-02 1.260e-01 3.721e-01 1.533e-02 3.467e-03 8.368e-03
 1.251e-01 8.144e-02 4.458e-01 1.850e-02 1.969e-02 5.849e-02 1.648e+00
 1.269e-01 5.227e-01 5.107e-01 2.956e-01 3.030e-01 6.280e-02 1.314e-01
 2.352e-01 5.303e-02 1.098e-02 4.329e-02 9.573e-03 3.721e-02 5.157e-02
 5.015e-03 1.001e-02 1.186e-02 5.075e-02 1.353e-02 5.092e-02 2.217e-02
 1.883e-01 7.866e-02 1.998e-02 4.586e-02 3.820e-02 3.061e-02 1.087e-02
 9.217e-03 1.250e-02 7.296e-02 5.924e-02 1.717e-02 4.585e-03 5.959e-02
 2.625e-01 7.212e-02 1.125e-01 7.105e-02 3.024e-01 2.401e-01 2.673e-01
 9.291e-02 1.527e+00 1.852e-01 4.719e-02 2.101e-01 3.386e-02 2.435e-01
 1.001e-01 7.396e-01 5.437e-02 7.790e-01 4.604e-02 7.156e-03 6.594e-02
 2.315e-02 5.049e-01 7.314e-02 6.796e-02 2.430e-03 4.444e-03]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9917695473251029, 0.9301146384479719)
Iterations 2500
Achieves (13.610683049707138, 1e-05)-DP
