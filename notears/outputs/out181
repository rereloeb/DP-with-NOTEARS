samples  5000  graph  20 80 ER mlp  minibatch size  50  noise  0.6  minibatches per NN training  250 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.7622777646747636
iteration 1 in outer loop, alpha = 1.7622777646747636, rho = 1.0, h = 1.7622777646747636
cuda
iteration 1 in inner loop,alpha 1.7622777646747636 rho 1.0 h 1.1769941079911774
iteration 2 in inner loop,alpha 1.7622777646747636 rho 10.0 h 0.546699080645368
iteration 3 in inner loop,alpha 1.7622777646747636 rho 100.0 h 0.18576399615164618
iteration 2 in outer loop, alpha = 20.338677379839382, rho = 100.0, h = 0.18576399615164618
cuda
iteration 1 in inner loop,alpha 20.338677379839382 rho 100.0 h 0.1095608426621908
iteration 2 in inner loop,alpha 20.338677379839382 rho 1000.0 h 0.04370983218316127
iteration 3 in outer loop, alpha = 64.04850956300065, rho = 1000.0, h = 0.04370983218316127
cuda
iteration 1 in inner loop,alpha 64.04850956300065 rho 1000.0 h 0.023592627798716848
iteration 2 in inner loop,alpha 64.04850956300065 rho 10000.0 h 0.008006307647868027
iteration 4 in outer loop, alpha = 144.11158604168094, rho = 10000.0, h = 0.008006307647868027
cuda
iteration 1 in inner loop,alpha 144.11158604168094 rho 10000.0 h 0.0041674095898649455
iteration 2 in inner loop,alpha 144.11158604168094 rho 100000.0 h 0.0014209538164706714
iteration 5 in outer loop, alpha = 286.2069676887481, rho = 100000.0, h = 0.0014209538164706714
cuda
iteration 1 in inner loop,alpha 286.2069676887481 rho 100000.0 h 0.0006536102144423239
iteration 6 in outer loop, alpha = 939.8171821310721, rho = 1000000.0, h = 0.0006536102144423239
Threshold 0.3
[[0.001 3.147 0.081 0.246 0.908 1.118 0.317 0.    1.946 1.114 0.125 1.121
  0.274 0.001 0.368 0.433 0.298 1.209 1.297 0.475]
 [0.    0.001 0.025 0.508 0.487 1.652 1.787 0.    0.572 0.469 0.094 0.677
  0.318 0.001 1.177 0.299 0.366 0.862 0.48  1.889]
 [0.002 0.008 0.001 0.067 0.44  0.551 1.518 0.    0.186 0.474 0.094 0.19
  1.301 0.002 1.491 0.319 0.601 0.002 1.19  0.329]
 [0.    0.    0.    0.02  0.    0.002 0.001 0.    0.    0.002 0.    0.
  0.    0.    0.206 0.239 0.193 0.    0.001 0.724]
 [0.    0.    0.    0.624 0.004 0.324 0.22  0.    0.    0.416 0.002 0.001
  0.003 0.    0.212 0.347 1.201 0.    0.349 1.057]
 [0.    0.    0.    0.55  0.002 0.003 0.001 0.    0.    0.    0.    0.
  0.    0.    0.348 1.651 1.791 0.    0.297 0.303]
 [0.    0.    0.    0.194 0.001 0.225 0.002 0.    0.    0.01  0.    0.
  0.    0.    0.327 0.353 0.298 0.    0.167 0.196]
 [2.484 0.131 0.003 0.111 0.709 0.223 0.719 0.001 0.301 0.455 0.134 0.381
  1.948 0.688 0.221 0.181 0.182 1.129 0.494 0.447]
 [0.    0.    0.002 0.358 1.592 0.946 1.294 0.    0.001 0.824 0.439 0.297
  1.767 0.    1.211 1.249 0.811 0.    1.332 0.69 ]
 [0.    0.    0.    0.112 0.016 2.203 0.119 0.    0.    0.008 0.001 0.001
  0.    0.    1.174 1.418 1.737 0.    0.817 0.228]
 [0.    0.    0.    1.011 0.11  0.592 2.319 0.    0.    0.258 0.001 0.
  0.    0.    1.507 0.477 1.022 0.    0.276 1.296]
 [0.    0.    0.    0.158 0.442 0.262 1.665 0.    0.    0.251 0.127 0.001
  0.113 0.    0.163 0.818 0.279 0.    0.121 0.218]
 [0.    0.    0.    0.099 0.138 1.383 1.076 0.    0.    0.172 2.141 0.002
  0.001 0.    0.302 0.322 0.291 0.    0.483 1.077]
 [0.156 0.038 0.033 0.798 0.337 1.627 0.324 0.001 0.287 0.357 1.709 0.533
  2.058 0.001 0.436 0.449 1.012 0.355 0.731 1.95 ]
 [0.    0.    0.    0.003 0.001 0.001 0.    0.    0.    0.    0.    0.
  0.    0.    0.002 0.252 0.003 0.    0.001 0.002]
 [0.    0.    0.    0.003 0.001 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.001 0.005 0.001 0.    0.001 0.   ]
 [0.    0.    0.    0.002 0.001 0.001 0.001 0.    0.    0.    0.    0.
  0.    0.    1.097 1.185 0.005 0.    0.001 0.002]
 [0.    0.    0.032 0.051 0.454 0.292 1.386 0.    3.186 0.543 0.095 0.727
  0.082 0.    0.342 0.186 0.185 0.001 0.422 0.243]
 [0.    0.    0.    0.787 0.001 0.001 0.001 0.    0.    0.001 0.    0.
  0.    0.    0.332 1.052 0.395 0.    0.001 0.258]
 [0.    0.    0.    0.003 0.    0.    0.001 0.    0.    0.001 0.    0.
  0.    0.    0.116 1.753 0.275 0.    0.001 0.002]]
[[0.    3.147 0.    0.    0.908 1.118 0.317 0.    1.946 1.114 0.    1.121
  0.    0.    0.368 0.433 0.    1.209 1.297 0.475]
 [0.    0.    0.    0.508 0.487 1.652 1.787 0.    0.572 0.469 0.    0.677
  0.318 0.    1.177 0.    0.366 0.862 0.48  1.889]
 [0.    0.    0.    0.    0.44  0.551 1.518 0.    0.    0.474 0.    0.
  1.301 0.    1.491 0.319 0.601 0.    1.19  0.329]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.724]
 [0.    0.    0.    0.624 0.    0.324 0.    0.    0.    0.416 0.    0.
  0.    0.    0.    0.347 1.201 0.    0.349 1.057]
 [0.    0.    0.    0.55  0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.348 1.651 1.791 0.    0.    0.303]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.327 0.353 0.    0.    0.    0.   ]
 [2.484 0.    0.    0.    0.709 0.    0.719 0.    0.301 0.455 0.    0.381
  1.948 0.688 0.    0.    0.    1.129 0.494 0.447]
 [0.    0.    0.    0.358 1.592 0.946 1.294 0.    0.    0.824 0.439 0.
  1.767 0.    1.211 1.249 0.811 0.    1.332 0.69 ]
 [0.    0.    0.    0.    0.    2.203 0.    0.    0.    0.    0.    0.
  0.    0.    1.174 1.418 1.737 0.    0.817 0.   ]
 [0.    0.    0.    1.011 0.    0.592 2.319 0.    0.    0.    0.    0.
  0.    0.    1.507 0.477 1.022 0.    0.    1.296]
 [0.    0.    0.    0.    0.442 0.    1.665 0.    0.    0.    0.    0.
  0.    0.    0.    0.818 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    1.383 1.076 0.    0.    0.    2.141 0.
  0.    0.    0.302 0.322 0.    0.    0.483 1.077]
 [0.    0.    0.    0.798 0.337 1.627 0.324 0.    0.    0.357 1.709 0.533
  2.058 0.    0.436 0.449 1.012 0.355 0.731 1.95 ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    1.097 1.185 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.454 0.    1.386 0.    3.186 0.543 0.    0.727
  0.    0.    0.342 0.    0.    0.    0.422 0.   ]
 [0.    0.    0.    0.787 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.332 1.052 0.395 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    1.753 0.    0.    0.    0.   ]]
{'fdr': 0.43089430894308944, 'tpr': 0.875, 'fpr': 0.4818181818181818, 'f1': 0.689655172413793, 'shd': 58, 'npred': 123, 'ntrue': 80}
[3.147e+00 8.083e-02 2.460e-01 9.083e-01 1.118e+00 3.168e-01 2.674e-04
 1.946e+00 1.114e+00 1.246e-01 1.121e+00 2.742e-01 1.376e-03 3.679e-01
 4.333e-01 2.975e-01 1.209e+00 1.297e+00 4.745e-01 4.054e-04 2.457e-02
 5.076e-01 4.874e-01 1.652e+00 1.787e+00 1.819e-04 5.720e-01 4.692e-01
 9.395e-02 6.772e-01 3.177e-01 1.177e-03 1.177e+00 2.989e-01 3.665e-01
 8.621e-01 4.802e-01 1.889e+00 2.203e-03 8.308e-03 6.743e-02 4.400e-01
 5.511e-01 1.518e+00 2.377e-04 1.860e-01 4.738e-01 9.446e-02 1.904e-01
 1.301e+00 2.297e-03 1.491e+00 3.191e-01 6.008e-01 2.303e-03 1.190e+00
 3.288e-01 7.199e-05 1.872e-05 7.850e-05 4.841e-04 2.261e-03 1.129e-03
 6.654e-05 8.666e-05 1.614e-03 3.733e-04 2.640e-04 7.937e-05 2.142e-06
 2.061e-01 2.390e-01 1.929e-01 1.753e-05 1.113e-03 7.238e-01 2.912e-06
 6.699e-06 1.372e-05 6.244e-01 3.240e-01 2.203e-01 1.895e-05 1.503e-04
 4.162e-01 2.401e-03 1.177e-03 2.905e-03 7.241e-05 2.117e-01 3.471e-01
 1.201e+00 3.078e-05 3.491e-01 1.057e+00 8.636e-05 1.853e-04 7.731e-05
 5.501e-01 2.029e-03 1.462e-03 5.252e-05 7.726e-05 4.244e-04 6.867e-05
 3.330e-04 2.645e-04 3.712e-05 3.476e-01 1.651e+00 1.791e+00 1.303e-05
 2.974e-01 3.033e-01 5.928e-05 4.674e-05 2.954e-05 1.940e-01 1.381e-03
 2.253e-01 3.242e-05 1.793e-05 9.577e-03 1.363e-04 2.179e-04 7.084e-05
 4.116e-06 3.274e-01 3.529e-01 2.982e-01 1.872e-06 1.667e-01 1.961e-01
 2.484e+00 1.307e-01 2.806e-03 1.109e-01 7.092e-01 2.232e-01 7.188e-01
 3.014e-01 4.554e-01 1.340e-01 3.812e-01 1.948e+00 6.878e-01 2.215e-01
 1.813e-01 1.816e-01 1.129e+00 4.944e-01 4.475e-01 1.097e-05 3.457e-05
 1.860e-03 3.578e-01 1.592e+00 9.465e-01 1.294e+00 1.111e-05 8.243e-01
 4.389e-01 2.969e-01 1.767e+00 2.755e-05 1.211e+00 1.249e+00 8.108e-01
 5.050e-05 1.332e+00 6.901e-01 3.106e-05 3.868e-05 1.221e-04 1.125e-01
 1.584e-02 2.203e+00 1.186e-01 5.534e-05 1.736e-04 6.659e-04 1.210e-03
 3.908e-04 1.298e-04 1.174e+00 1.418e+00 1.737e+00 3.677e-05 8.167e-01
 2.281e-01 7.845e-06 3.395e-05 6.917e-05 1.011e+00 1.096e-01 5.918e-01
 2.319e+00 2.336e-05 8.438e-05 2.575e-01 4.749e-04 2.169e-04 4.735e-05
 1.507e+00 4.775e-01 1.022e+00 1.417e-05 2.759e-01 1.296e+00 1.902e-05
 4.836e-05 3.669e-04 1.583e-01 4.416e-01 2.616e-01 1.665e+00 2.503e-05
 2.221e-04 2.514e-01 1.273e-01 1.134e-01 9.341e-05 1.632e-01 8.180e-01
 2.789e-01 1.719e-04 1.209e-01 2.176e-01 5.597e-06 2.038e-05 1.836e-04
 9.950e-02 1.378e-01 1.383e+00 1.076e+00 3.274e-05 2.486e-04 1.720e-01
 2.141e+00 1.769e-03 8.376e-05 3.021e-01 3.221e-01 2.915e-01 2.474e-05
 4.834e-01 1.077e+00 1.563e-01 3.768e-02 3.312e-02 7.983e-01 3.374e-01
 1.627e+00 3.239e-01 6.816e-04 2.873e-01 3.565e-01 1.709e+00 5.333e-01
 2.058e+00 4.362e-01 4.486e-01 1.012e+00 3.548e-01 7.308e-01 1.950e+00
 4.638e-05 7.325e-05 3.146e-05 3.029e-03 1.271e-03 8.169e-04 3.702e-04
 3.201e-05 8.252e-06 4.601e-05 9.115e-05 2.405e-04 6.234e-05 4.760e-06
 2.524e-01 2.837e-03 2.160e-06 6.183e-04 2.095e-03 2.842e-05 2.333e-05
 3.312e-05 2.564e-03 6.030e-04 5.181e-05 3.493e-04 2.606e-05 2.326e-05
 3.010e-04 9.464e-05 6.774e-05 2.252e-05 1.388e-05 1.185e-03 1.275e-03
 5.675e-06 5.864e-04 2.706e-04 5.401e-05 1.128e-04 1.268e-05 2.127e-03
 9.787e-04 6.410e-04 8.580e-04 4.560e-05 2.783e-05 5.077e-05 7.555e-05
 8.963e-05 2.750e-05 3.119e-05 1.097e+00 1.185e+00 5.596e-06 6.570e-04
 1.565e-03 8.968e-05 2.166e-05 3.226e-02 5.095e-02 4.543e-01 2.916e-01
 1.386e+00 9.442e-05 3.186e+00 5.433e-01 9.507e-02 7.269e-01 8.159e-02
 1.141e-04 3.423e-01 1.861e-01 1.847e-01 4.222e-01 2.432e-01 6.874e-05
 1.538e-05 1.552e-04 7.872e-01 1.004e-03 7.431e-04 9.950e-04 4.916e-05
 1.620e-04 5.573e-04 1.794e-04 2.946e-04 1.533e-04 2.241e-05 3.321e-01
 1.052e+00 3.951e-01 1.319e-05 2.580e-01 3.906e-05 7.786e-05 7.081e-05
 2.714e-03 2.648e-04 3.211e-04 5.967e-04 2.050e-05 7.199e-05 9.269e-04
 3.466e-04 1.372e-04 2.314e-04 6.356e-05 1.157e-01 1.753e+00 2.747e-01
 1.577e-05 5.984e-04]
[[0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0.]
 [0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1.]
 [0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0.]
 [0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.]
 [0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.]
 [0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]
 [0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]
[1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1.
 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.
 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.
 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1.
 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
aucroc, aucpr (0.9380416666666666, 0.8893654169764621)
cuda
4420
cuda
Objective function 730.81 = squared loss an data 514.80 + 0.5*rho*h**2 215.201283 + alpha*h 0.000000 + L2reg 0.37 + L1reg 0.45 ; SHD = 206 ; DAG False
v before min max tensor([[-1.161e-03,  3.347e-05, -2.542e-04,  ..., -2.155e-05,  1.009e-03,
         -2.815e-05],
        [-1.877e-03, -4.633e-04, -1.961e-03,  ..., -5.849e-04, -9.481e-06,
         -1.789e-04],
        [-8.307e-04,  1.887e-04, -9.068e-04,  ..., -7.699e-05,  3.338e-05,
         -7.088e-05],
        ...,
        [ 1.149e-02, -2.727e-03, -1.948e-04,  ...,  2.048e-07,  4.783e-05,
         -8.708e-04],
        [-2.870e-04, -1.105e-03, -1.026e-04,  ...,  1.631e-04,  5.481e-06,
          3.996e-04],
        [ 1.349e-03, -1.860e-05, -3.168e-04,  ..., -2.707e-05,  3.712e-04,
         -1.890e-03]], device='cuda:0')
v tensor([[1.000e-12, 3.347e-05, 1.000e-12,  ..., 1.000e-12, 1.009e-03,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.887e-04, 1.000e-12,  ..., 1.000e-12, 3.338e-05,
         1.000e-12],
        ...,
        [1.149e-02, 1.000e-12, 1.000e-12,  ..., 2.048e-07, 4.783e-05,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.631e-04, 5.481e-06,
         3.996e-04],
        [1.349e-03, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 3.712e-04,
         1.000e-12]], device='cuda:0')
v before min max tensor([-2.668e-05,  6.953e-04, -3.291e-06, -1.887e-04, -1.331e-05, -5.530e-03,
        -7.677e-05, -1.439e-04, -1.822e-04, -1.782e-04, -8.974e-04, -7.019e-05,
         1.233e-06, -9.161e-04, -1.898e-04, -8.882e-04, -9.138e-06, -7.944e-05,
        -8.028e-05,  3.212e-06, -3.295e-05, -5.577e-04,  7.463e-05,  3.737e-06,
         7.133e-03,  3.539e-05, -6.903e-04,  1.707e-06,  2.908e-04, -1.098e-06,
        -5.858e-04, -1.160e-03, -1.655e-03, -1.117e-06,  3.243e-05, -4.491e-04,
        -2.024e-05, -1.878e-03, -2.147e-04, -4.389e-05, -1.206e-05, -8.932e-04,
        -2.824e-04, -4.898e-04, -7.455e-06,  2.339e-05,  2.478e-05, -1.980e-05,
        -7.482e-05,  1.367e-03, -1.132e-03,  9.057e-06, -8.728e-06, -5.729e-06,
        -8.525e-04,  2.459e-04, -1.263e-04, -7.037e-05, -1.600e-04, -5.690e-04,
         9.845e-06, -1.192e-03,  2.064e-04, -2.935e-05, -5.632e-04, -1.763e-06,
         5.117e-05, -2.463e-03, -1.671e-03,  1.134e-05, -1.960e-04, -4.849e-04,
        -9.011e-07, -1.626e-05,  1.035e-04, -2.321e-05,  6.911e-05, -1.595e-05,
        -2.072e-04, -4.204e-06,  2.792e-05,  5.623e-04, -1.798e-04, -1.878e-04,
        -6.320e-03, -9.330e-05, -2.810e-05, -1.044e-05, -3.397e-05, -2.550e-04,
         6.342e-04,  7.036e-04, -1.529e-04,  1.882e-03, -1.688e-05, -3.693e-05,
        -3.647e-05, -3.214e-05, -1.032e-04,  1.154e-05,  1.701e-06,  1.987e-05,
        -8.353e-04, -7.981e-05, -8.181e-04, -1.057e-04,  6.559e-03, -1.157e-04,
        -2.346e-05, -4.081e-04, -1.531e-04,  8.463e-06,  2.783e-05, -4.947e-04,
        -1.778e-03, -7.966e-05, -2.081e-05,  5.184e-05, -3.109e-03,  1.715e-04,
        -3.746e-06,  2.802e-05, -1.140e-04,  2.739e-04, -7.611e-05, -3.670e-05,
         2.213e-04,  4.735e-04, -8.456e-05, -2.052e-03,  2.186e-03,  3.800e-03,
         6.272e-05, -1.997e-04,  4.808e-05, -1.717e-04, -9.235e-07,  1.940e-06,
         1.256e-04, -4.716e-05, -7.828e-06,  6.415e-08, -2.872e-06, -1.243e-04,
        -1.528e-04,  9.766e-06,  3.030e-06,  6.903e-03, -2.344e-03, -2.853e-05,
        -2.786e-04, -2.730e-04,  3.259e-05, -6.916e-03, -1.625e-03,  4.408e-05,
        -1.063e-03,  5.799e-05, -9.018e-05, -3.160e-06, -1.012e-03, -1.359e-05,
        -7.843e-04, -1.337e-05, -7.850e-04,  1.462e-04,  1.467e-03, -1.306e-05,
         1.245e-03, -5.084e-07, -6.023e-05, -6.137e-03, -9.895e-06, -6.265e-05,
        -3.605e-05,  3.606e-04, -9.696e-05, -9.047e-05, -4.105e-06,  5.324e-06,
        -5.958e-05, -6.234e-06, -1.285e-04, -1.207e-05, -2.010e-04,  4.928e-03,
        -1.173e-04,  1.966e-03,  7.276e-05, -2.241e-05, -5.458e-04, -1.338e-05,
        -5.230e-04, -1.093e-04, -1.183e-04, -3.250e-04,  3.760e-04, -4.065e-07,
         2.144e-04, -4.843e-04], device='cuda:0')
v tensor([1.000e-12, 6.953e-04, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.233e-06, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 3.212e-06, 1.000e-12, 1.000e-12, 7.463e-05, 3.737e-06,
        7.133e-03, 3.539e-05, 1.000e-12, 1.707e-06, 2.908e-04, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.243e-05, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 2.339e-05, 2.478e-05, 1.000e-12,
        1.000e-12, 1.367e-03, 1.000e-12, 9.057e-06, 1.000e-12, 1.000e-12,
        1.000e-12, 2.459e-04, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        9.845e-06, 1.000e-12, 2.064e-04, 1.000e-12, 1.000e-12, 1.000e-12,
        5.117e-05, 1.000e-12, 1.000e-12, 1.134e-05, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.035e-04, 1.000e-12, 6.911e-05, 1.000e-12,
        1.000e-12, 1.000e-12, 2.792e-05, 5.623e-04, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        6.342e-04, 7.036e-04, 1.000e-12, 1.882e-03, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.154e-05, 1.701e-06, 1.987e-05,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 6.559e-03, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 8.463e-06, 2.783e-05, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 5.184e-05, 1.000e-12, 1.715e-04,
        1.000e-12, 2.802e-05, 1.000e-12, 2.739e-04, 1.000e-12, 1.000e-12,
        2.213e-04, 4.735e-04, 1.000e-12, 1.000e-12, 2.186e-03, 3.800e-03,
        6.272e-05, 1.000e-12, 4.808e-05, 1.000e-12, 1.000e-12, 1.940e-06,
        1.256e-04, 1.000e-12, 1.000e-12, 6.415e-08, 1.000e-12, 1.000e-12,
        1.000e-12, 9.766e-06, 3.030e-06, 6.903e-03, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 3.259e-05, 1.000e-12, 1.000e-12, 4.408e-05,
        1.000e-12, 5.799e-05, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.462e-04, 1.467e-03, 1.000e-12,
        1.245e-03, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 3.606e-04, 1.000e-12, 1.000e-12, 1.000e-12, 5.324e-06,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 4.928e-03,
        1.000e-12, 1.966e-03, 7.276e-05, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.760e-04, 1.000e-12,
        2.144e-04, 1.000e-12], device='cuda:0')
v before min max tensor([[[ 3.119e-03],
         [-2.826e-04],
         [-1.809e-04],
         [-6.536e-04],
         [-2.065e-03],
         [ 2.964e-04],
         [ 5.053e-04],
         [-1.253e-04],
         [-4.124e-06],
         [-7.686e-04]],

        [[-1.501e-02],
         [-1.073e-03],
         [-5.427e-03],
         [-1.580e-02],
         [ 4.141e-03],
         [ 2.050e-03],
         [-1.686e-04],
         [ 2.587e-04],
         [ 5.544e-02],
         [-5.157e-02]],

        [[ 2.419e-03],
         [ 6.235e-03],
         [ 2.095e-04],
         [-8.546e-03],
         [ 4.178e-03],
         [-8.477e-03],
         [ 2.078e-03],
         [ 7.975e-05],
         [-2.064e-03],
         [-2.567e-04]],

        [[-3.739e-03],
         [-7.987e-04],
         [ 2.635e-03],
         [ 1.045e-03],
         [-6.349e-06],
         [-8.600e-04],
         [-2.237e-03],
         [ 9.753e-04],
         [ 2.394e-04],
         [-8.511e-04]],

        [[ 5.439e-02],
         [ 1.942e-01],
         [-8.714e-03],
         [-9.717e-03],
         [ 1.429e-03],
         [-4.027e-05],
         [ 4.359e-03],
         [ 1.633e-01],
         [ 5.333e-02],
         [-1.068e-03]],

        [[ 1.228e-04],
         [ 2.408e-04],
         [-1.364e-03],
         [-4.189e-03],
         [-3.124e-04],
         [-7.111e-05],
         [-2.680e-04],
         [-1.702e-03],
         [-1.563e-03],
         [-1.095e-03]],

        [[ 3.835e-02],
         [-9.136e-04],
         [ 1.163e-02],
         [ 3.687e-03],
         [ 5.200e-03],
         [-1.380e-02],
         [-7.003e-03],
         [ 6.372e-03],
         [ 7.725e-03],
         [-2.717e-03]],

        [[-2.722e-06],
         [ 4.532e-04],
         [-1.213e-04],
         [-9.553e-04],
         [-4.620e-04],
         [-6.844e-04],
         [ 2.713e-04],
         [ 3.462e-03],
         [-1.591e-04],
         [ 2.642e-04]],

        [[-2.811e-03],
         [-8.140e-03],
         [ 1.734e-03],
         [ 3.938e-02],
         [ 1.936e-02],
         [ 1.450e-03],
         [ 1.341e-02],
         [-1.326e-03],
         [-3.529e-03],
         [-3.019e-03]],

        [[ 7.917e-02],
         [ 8.336e-02],
         [ 1.042e-01],
         [-8.944e-04],
         [ 5.974e-02],
         [ 9.168e-02],
         [ 1.495e-04],
         [-2.390e-02],
         [-2.041e-03],
         [-4.753e-03]],

        [[-4.683e-03],
         [ 2.914e-03],
         [-1.426e-03],
         [ 1.057e-03],
         [-1.114e-02],
         [ 1.233e-04],
         [ 4.990e-03],
         [-1.493e-04],
         [ 3.977e-03],
         [ 5.982e-02]],

        [[ 3.255e-05],
         [ 3.666e-04],
         [-1.439e-04],
         [ 1.022e-02],
         [ 8.734e-03],
         [ 5.266e-02],
         [ 3.260e-02],
         [-2.336e-02],
         [ 1.727e-03],
         [-1.891e-04]],

        [[ 1.593e-02],
         [-1.292e-03],
         [ 2.505e-02],
         [-5.801e-03],
         [ 2.110e-03],
         [ 1.217e-01],
         [ 1.342e-03],
         [ 3.890e-03],
         [-8.122e-04],
         [ 2.012e-02]],

        [[-2.993e-04],
         [ 2.423e-03],
         [-1.086e-02],
         [ 3.822e-04],
         [ 1.799e-05],
         [ 1.324e-02],
         [ 1.470e-03],
         [ 6.303e-04],
         [ 2.222e-03],
         [-2.124e-02]],

        [[-3.760e-04],
         [-4.979e-04],
         [-1.347e-03],
         [ 2.032e-02],
         [ 1.022e-03],
         [ 1.229e-03],
         [-4.181e-03],
         [ 5.951e-02],
         [ 2.002e-05],
         [-2.524e-05]],

        [[ 1.019e-02],
         [ 4.153e-03],
         [ 1.221e-03],
         [ 2.226e-02],
         [-1.263e-03],
         [ 1.558e-02],
         [-5.491e-04],
         [-1.255e-03],
         [-6.322e-03],
         [-1.362e-03]],

        [[ 2.128e-02],
         [-4.453e-04],
         [ 1.349e-02],
         [-5.390e-04],
         [-1.302e-04],
         [-4.999e-05],
         [-1.593e-03],
         [-7.353e-04],
         [-2.630e-03],
         [ 2.261e-03]],

        [[ 1.646e-02],
         [-1.701e-02],
         [ 6.145e-03],
         [ 2.205e-02],
         [-1.720e-02],
         [-4.248e-03],
         [-6.479e-04],
         [-2.046e-04],
         [ 1.292e-03],
         [-5.043e-03]],

        [[ 3.722e-03],
         [ 3.592e-03],
         [-5.679e-04],
         [ 3.879e-04],
         [-1.817e-05],
         [-7.211e-04],
         [-4.802e-05],
         [-2.208e-04],
         [ 2.689e-06],
         [ 3.153e-03]],

        [[ 9.062e-05],
         [-1.578e-05],
         [-4.566e-05],
         [-2.524e-04],
         [-1.118e-04],
         [-1.404e-05],
         [ 2.168e-03],
         [-1.145e-03],
         [ 1.534e-03],
         [-4.333e-06]]], device='cuda:0')
v tensor([[[3.119e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.964e-04],
         [5.053e-04],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.141e-03],
         [2.050e-03],
         [1.000e-12],
         [2.587e-04],
         [5.544e-02],
         [1.000e-12]],

        [[2.419e-03],
         [6.235e-03],
         [2.095e-04],
         [1.000e-12],
         [4.178e-03],
         [1.000e-12],
         [2.078e-03],
         [7.975e-05],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [2.635e-03],
         [1.045e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [9.753e-04],
         [2.394e-04],
         [1.000e-12]],

        [[5.439e-02],
         [1.942e-01],
         [1.000e-12],
         [1.000e-12],
         [1.429e-03],
         [1.000e-12],
         [4.359e-03],
         [1.633e-01],
         [5.333e-02],
         [1.000e-12]],

        [[1.228e-04],
         [2.408e-04],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[3.835e-02],
         [1.000e-12],
         [1.163e-02],
         [3.687e-03],
         [5.200e-03],
         [1.000e-12],
         [1.000e-12],
         [6.372e-03],
         [7.725e-03],
         [1.000e-12]],

        [[1.000e-12],
         [4.532e-04],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.713e-04],
         [3.462e-03],
         [1.000e-12],
         [2.642e-04]],

        [[1.000e-12],
         [1.000e-12],
         [1.734e-03],
         [3.938e-02],
         [1.936e-02],
         [1.450e-03],
         [1.341e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[7.917e-02],
         [8.336e-02],
         [1.042e-01],
         [1.000e-12],
         [5.974e-02],
         [9.168e-02],
         [1.495e-04],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [2.914e-03],
         [1.000e-12],
         [1.057e-03],
         [1.000e-12],
         [1.233e-04],
         [4.990e-03],
         [1.000e-12],
         [3.977e-03],
         [5.982e-02]],

        [[3.255e-05],
         [3.666e-04],
         [1.000e-12],
         [1.022e-02],
         [8.734e-03],
         [5.266e-02],
         [3.260e-02],
         [1.000e-12],
         [1.727e-03],
         [1.000e-12]],

        [[1.593e-02],
         [1.000e-12],
         [2.505e-02],
         [1.000e-12],
         [2.110e-03],
         [1.217e-01],
         [1.342e-03],
         [3.890e-03],
         [1.000e-12],
         [2.012e-02]],

        [[1.000e-12],
         [2.423e-03],
         [1.000e-12],
         [3.822e-04],
         [1.799e-05],
         [1.324e-02],
         [1.470e-03],
         [6.303e-04],
         [2.222e-03],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.032e-02],
         [1.022e-03],
         [1.229e-03],
         [1.000e-12],
         [5.951e-02],
         [2.002e-05],
         [1.000e-12]],

        [[1.019e-02],
         [4.153e-03],
         [1.221e-03],
         [2.226e-02],
         [1.000e-12],
         [1.558e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[2.128e-02],
         [1.000e-12],
         [1.349e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.261e-03]],

        [[1.646e-02],
         [1.000e-12],
         [6.145e-03],
         [2.205e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.292e-03],
         [1.000e-12]],

        [[3.722e-03],
         [3.592e-03],
         [1.000e-12],
         [3.879e-04],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.689e-06],
         [3.153e-03]],

        [[9.062e-05],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.168e-03],
         [1.000e-12],
         [1.534e-03],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[ 0.002],
        [ 0.150],
        [-0.002],
        [-0.001],
        [ 0.180],
        [-0.000],
        [-0.005],
        [-0.001],
        [ 0.029],
        [ 0.211],
        [ 0.046],
        [ 0.036],
        [ 0.035],
        [ 0.014],
        [-0.012],
        [-0.005],
        [ 0.020],
        [ 0.029],
        [-0.005],
        [ 0.008]], device='cuda:0')
v tensor([[2.017e-03],
        [1.504e-01],
        [1.000e-12],
        [1.000e-12],
        [1.804e-01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [2.854e-02],
        [2.105e-01],
        [4.572e-02],
        [3.563e-02],
        [3.489e-02],
        [1.422e-02],
        [1.000e-12],
        [1.000e-12],
        [2.035e-02],
        [2.938e-02],
        [1.000e-12],
        [7.606e-03]], device='cuda:0')
a after update for 1 param tensor([[-9.354e-06, -8.783e-06, -9.821e-06,  ...,  1.816e-05,  2.212e-05,
         -2.671e-05],
        [-3.000e-05,  1.874e-06,  1.940e-05,  ..., -1.791e-05, -1.337e-06,
         -1.388e-05],
        [ 4.641e-05, -1.064e-05, -1.533e-05,  ...,  2.679e-06, -5.432e-05,
          2.277e-06],
        ...,
        [ 2.868e-04,  1.197e-06, -4.295e-05,  ..., -3.032e-06,  1.301e-05,
          8.207e-05],
        [-1.111e-05, -9.461e-06, -7.321e-06,  ..., -4.947e-05,  1.895e-05,
         -6.398e-05],
        [ 3.473e-05,  5.405e-06,  6.075e-06,  ..., -9.221e-06,  5.538e-05,
         -1.103e-04]], device='cuda:0')
s after update for 1 param tensor([[2.270e-03, 1.830e-03, 4.421e-04,  ..., 5.257e-05, 1.006e-02,
         4.104e-04],
        [3.049e-03, 7.578e-04, 5.445e-03,  ..., 1.397e-03, 5.375e-05,
         2.901e-04],
        [1.529e-03, 4.349e-03, 1.779e-03,  ..., 1.281e-04, 2.672e-03,
         1.287e-04],
        ...,
        [3.826e-02, 5.209e-03, 8.277e-04,  ..., 1.467e-04, 2.187e-03,
         2.153e-03],
        [8.298e-04, 1.804e-03, 2.008e-04,  ..., 4.187e-03, 7.533e-04,
         6.953e-03],
        [1.175e-02, 6.986e-05, 6.213e-04,  ..., 6.319e-05, 6.265e-03,
         8.225e-03]], device='cuda:0')
b after update for 1 param tensor([[0.225, 0.202, 0.099,  ..., 0.034, 0.473, 0.095],
        [0.260, 0.130, 0.348,  ..., 0.176, 0.035, 0.080],
        [0.184, 0.311, 0.199,  ..., 0.053, 0.244, 0.053],
        ...,
        [0.922, 0.340, 0.136,  ..., 0.057, 0.220, 0.219],
        [0.136, 0.200, 0.067,  ..., 0.305, 0.129, 0.393],
        [0.511, 0.039, 0.117,  ..., 0.037, 0.373, 0.427]], device='cuda:0')
clipping threshold 2.782537623814828
a after update for 1 param tensor([ 8.034e-06,  8.935e-05, -4.773e-06,  6.928e-06,  1.140e-06, -2.312e-05,
         1.977e-05,  1.994e-05, -7.865e-06,  6.872e-06, -1.373e-05, -5.137e-06,
         4.771e-06, -1.967e-05, -6.364e-05, -1.445e-05, -1.817e-06, -1.184e-05,
         3.242e-05, -3.575e-06, -6.974e-06, -1.062e-05, -2.593e-05, -4.695e-06,
        -1.985e-04, -2.458e-05,  6.224e-06, -3.734e-06, -5.071e-05, -7.681e-07,
         1.837e-05, -3.921e-05,  7.456e-05, -2.553e-08,  1.817e-05,  7.753e-07,
         3.969e-06,  1.890e-05, -7.168e-07,  8.316e-06, -1.231e-05,  5.040e-06,
         7.146e-06, -4.244e-05, -2.144e-06,  1.162e-05, -5.525e-06,  8.663e-06,
         5.402e-06,  7.301e-05, -8.166e-05,  4.342e-05,  9.030e-07, -3.666e-06,
         6.235e-06,  2.978e-05, -1.772e-05,  1.560e-05, -9.476e-06, -3.874e-05,
        -7.779e-06,  1.847e-05, -1.406e-04, -6.846e-06, -3.487e-05, -2.915e-06,
         1.621e-05,  1.028e-05, -7.042e-05,  9.683e-06, -1.233e-06,  3.473e-05,
         1.305e-06, -2.278e-06,  1.494e-05,  3.248e-06,  2.436e-05, -2.493e-06,
        -6.985e-07,  1.251e-06,  6.760e-06,  8.361e-05, -3.804e-06, -1.563e-06,
        -1.013e-04,  5.804e-07, -2.776e-07,  1.123e-07,  1.096e-05,  1.171e-05,
        -4.245e-05, -4.818e-05, -3.387e-05, -7.127e-05,  2.397e-06, -6.826e-06,
        -4.016e-07, -1.062e-05, -6.007e-06, -5.048e-06, -3.128e-06, -1.158e-05,
        -9.785e-06,  1.413e-06,  2.208e-05,  1.434e-05,  1.679e-04,  1.692e-05,
         5.223e-06,  5.661e-05,  1.565e-06, -3.798e-06, -1.894e-05,  2.098e-05,
        -5.039e-05,  4.630e-06,  4.228e-06, -2.683e-05, -1.188e-05, -2.196e-05,
         9.130e-07,  7.331e-06, -7.770e-06,  3.167e-05,  3.442e-06, -7.987e-06,
         4.818e-05, -2.013e-05,  3.504e-05, -1.766e-05, -8.123e-05,  1.056e-04,
        -1.712e-05, -2.528e-05,  1.587e-05, -1.873e-05,  1.212e-05,  3.728e-06,
        -4.613e-05, -4.228e-05,  2.299e-06,  3.330e-06,  2.976e-06, -1.446e-05,
         1.932e-05, -7.678e-06, -6.413e-06, -1.822e-04,  2.359e-07, -6.306e-06,
        -1.317e-05, -3.514e-06,  3.509e-05,  1.118e-04, -6.852e-05, -1.218e-05,
        -1.072e-04,  3.100e-06, -6.180e-06,  8.406e-06,  1.099e-05, -4.043e-06,
         4.239e-05, -5.952e-06, -3.322e-06,  1.888e-05,  6.856e-05,  5.087e-06,
        -6.238e-05,  2.129e-06,  7.725e-06, -6.447e-05, -1.400e-06,  2.574e-06,
         3.060e-06,  2.351e-05, -1.131e-05,  4.990e-06,  1.999e-07, -7.517e-06,
         8.476e-06,  2.606e-05,  1.796e-05,  2.351e-06, -3.233e-06,  1.042e-04,
         2.674e-06,  4.926e-05, -1.236e-05, -1.555e-06, -2.439e-05,  6.485e-07,
         8.470e-06,  1.425e-05,  5.139e-05,  7.704e-06, -2.952e-05, -8.816e-06,
        -2.132e-05,  2.010e-06], device='cuda:0')
s after update for 1 param tensor([4.630e-05, 8.600e-03, 3.042e-05, 3.069e-04, 2.160e-05, 1.085e-02,
        1.642e-04, 5.273e-04, 4.016e-04, 2.900e-04, 1.471e-03, 3.296e-04,
        3.513e-04, 1.625e-03, 1.526e-03, 1.515e-03, 1.631e-05, 1.594e-04,
        1.423e-03, 5.669e-04, 1.753e-04, 1.627e-03, 2.751e-03, 6.114e-04,
        2.725e-02, 1.903e-03, 1.424e-03, 4.131e-04, 5.396e-03, 1.882e-06,
        9.954e-04, 2.308e-03, 4.757e-03, 1.882e-06, 1.812e-03, 8.169e-04,
        3.292e-05, 3.185e-03, 3.979e-04, 1.035e-04, 5.165e-05, 1.624e-03,
        5.248e-04, 2.189e-03, 1.214e-05, 1.530e-03, 1.574e-03, 4.914e-05,
        1.241e-04, 1.173e-02, 4.250e-03, 1.163e-03, 1.439e-05, 2.314e-05,
        1.615e-03, 4.961e-03, 4.670e-04, 2.466e-04, 2.704e-04, 1.239e-03,
        9.930e-04, 1.957e-03, 6.779e-03, 9.023e-05, 2.145e-03, 4.321e-06,
        2.263e-03, 4.158e-03, 3.942e-03, 1.073e-03, 4.114e-04, 8.463e-04,
        1.882e-06, 2.754e-05, 3.218e-03, 3.767e-05, 2.632e-03, 2.727e-05,
        4.067e-04, 8.846e-06, 1.672e-03, 7.889e-03, 2.964e-04, 3.251e-04,
        1.030e-02, 1.512e-04, 4.812e-05, 1.750e-05, 2.187e-04, 6.824e-04,
        7.964e-03, 8.407e-03, 4.293e-04, 1.386e-02, 3.150e-05, 5.993e-05,
        8.840e-05, 8.868e-05, 1.802e-04, 1.116e-03, 4.125e-04, 1.410e-03,
        2.151e-03, 1.300e-04, 1.481e-03, 3.056e-04, 2.599e-02, 3.145e-04,
        4.370e-05, 8.670e-04, 2.480e-04, 9.200e-04, 1.720e-03, 1.206e-03,
        3.447e-03, 4.066e-04, 3.426e-05, 2.289e-03, 6.890e-03, 4.142e-03,
        6.104e-06, 1.674e-03, 2.088e-04, 5.257e-03, 1.233e-04, 6.613e-05,
        4.824e-03, 6.965e-03, 4.348e-04, 3.467e-03, 1.510e-02, 1.954e-02,
        2.506e-03, 5.979e-04, 2.194e-03, 3.056e-04, 2.046e-05, 4.405e-04,
        3.568e-03, 6.037e-04, 1.054e-04, 8.171e-05, 5.425e-06, 4.226e-04,
        4.077e-04, 1.008e-03, 5.505e-04, 2.704e-02, 4.263e-03, 5.708e-05,
        5.544e-04, 5.919e-04, 1.862e-03, 1.347e-02, 4.268e-03, 2.100e-03,
        4.854e-03, 2.411e-03, 3.030e-04, 1.219e-05, 1.642e-03, 2.201e-05,
        2.230e-03, 2.693e-05, 2.113e-03, 3.826e-03, 1.228e-02, 2.344e-05,
        1.117e-02, 3.198e-05, 1.028e-03, 9.951e-03, 1.785e-05, 1.036e-04,
        1.042e-04, 6.026e-03, 1.656e-04, 1.760e-04, 6.710e-06, 7.315e-04,
        9.671e-05, 2.167e-04, 2.081e-04, 1.957e-05, 3.356e-04, 2.385e-02,
        2.003e-04, 1.618e-02, 2.698e-03, 4.315e-05, 2.521e-03, 2.185e-05,
        8.786e-04, 1.831e-04, 3.101e-03, 5.484e-04, 6.135e-03, 6.817e-05,
        4.632e-03, 8.456e-04], device='cuda:0')
b after update for 1 param tensor([0.032, 0.437, 0.026, 0.083, 0.022, 0.491, 0.060, 0.108, 0.094, 0.080,
        0.181, 0.086, 0.088, 0.190, 0.184, 0.183, 0.019, 0.060, 0.178, 0.112,
        0.062, 0.190, 0.247, 0.117, 0.778, 0.206, 0.178, 0.096, 0.346, 0.006,
        0.149, 0.226, 0.325, 0.006, 0.201, 0.135, 0.027, 0.266, 0.094, 0.048,
        0.034, 0.190, 0.108, 0.221, 0.016, 0.184, 0.187, 0.033, 0.053, 0.510,
        0.307, 0.161, 0.018, 0.023, 0.189, 0.332, 0.102, 0.074, 0.078, 0.166,
        0.149, 0.208, 0.388, 0.045, 0.218, 0.010, 0.224, 0.304, 0.296, 0.154,
        0.096, 0.137, 0.006, 0.025, 0.267, 0.029, 0.242, 0.025, 0.095, 0.014,
        0.193, 0.419, 0.081, 0.085, 0.478, 0.058, 0.033, 0.020, 0.070, 0.123,
        0.421, 0.432, 0.098, 0.555, 0.026, 0.036, 0.044, 0.044, 0.063, 0.157,
        0.096, 0.177, 0.219, 0.054, 0.181, 0.082, 0.760, 0.084, 0.031, 0.139,
        0.074, 0.143, 0.195, 0.164, 0.277, 0.095, 0.028, 0.226, 0.391, 0.303,
        0.012, 0.193, 0.068, 0.342, 0.052, 0.038, 0.327, 0.393, 0.098, 0.278,
        0.579, 0.659, 0.236, 0.115, 0.221, 0.082, 0.021, 0.099, 0.282, 0.116,
        0.048, 0.043, 0.011, 0.097, 0.095, 0.150, 0.111, 0.775, 0.308, 0.036,
        0.111, 0.115, 0.203, 0.547, 0.308, 0.216, 0.328, 0.231, 0.082, 0.016,
        0.191, 0.022, 0.223, 0.024, 0.217, 0.292, 0.522, 0.023, 0.498, 0.027,
        0.151, 0.470, 0.020, 0.048, 0.048, 0.366, 0.061, 0.063, 0.012, 0.127,
        0.046, 0.069, 0.068, 0.021, 0.086, 0.728, 0.067, 0.600, 0.245, 0.031,
        0.237, 0.022, 0.140, 0.064, 0.262, 0.110, 0.369, 0.039, 0.321, 0.137],
       device='cuda:0')
clipping threshold 2.782537623814828
a after update for 1 param tensor([[[ 1.276e-04],
         [-6.930e-06],
         [ 8.541e-05],
         [-5.022e-05],
         [-8.408e-05],
         [ 1.342e-04],
         [ 1.431e-04],
         [ 2.612e-05],
         [-3.771e-06],
         [ 2.376e-05]],

        [[-2.996e-04],
         [-3.416e-05],
         [-4.784e-04],
         [-4.079e-04],
         [-4.199e-04],
         [ 7.870e-05],
         [ 6.445e-05],
         [-8.057e-05],
         [-5.984e-04],
         [-6.187e-04]],

        [[ 1.150e-04],
         [-3.731e-05],
         [ 8.243e-05],
         [ 6.177e-05],
         [ 1.022e-04],
         [ 1.252e-04],
         [ 1.443e-04],
         [ 2.108e-04],
         [ 1.467e-04],
         [-1.807e-05]],

        [[ 9.594e-05],
         [ 1.110e-04],
         [ 1.548e-04],
         [ 7.589e-05],
         [ 8.337e-06],
         [ 1.468e-05],
         [ 6.047e-05],
         [ 6.570e-05],
         [ 2.619e-05],
         [ 1.085e-04]],

        [[-6.732e-04],
         [-9.851e-04],
         [-2.228e-04],
         [-2.162e-04],
         [-7.559e-05],
         [-1.670e-06],
         [ 9.802e-05],
         [-8.679e-04],
         [-8.620e-04],
         [-1.876e-05]],

        [[ 2.225e-05],
         [ 3.308e-05],
         [-2.769e-05],
         [ 1.256e-04],
         [ 2.262e-05],
         [ 1.265e-05],
         [-7.332e-06],
         [ 2.342e-05],
         [-4.401e-05],
         [ 6.942e-05]],

        [[-4.239e-04],
         [-2.354e-06],
         [-2.332e-04],
         [-1.519e-04],
         [-1.522e-04],
         [-1.604e-04],
         [-1.198e-04],
         [-2.485e-04],
         [-1.611e-04],
         [ 2.842e-05]],

        [[ 2.750e-06],
         [ 5.046e-05],
         [ 9.955e-06],
         [ 5.538e-06],
         [-8.185e-07],
         [ 3.966e-05],
         [-3.179e-05],
         [ 1.248e-04],
         [ 4.822e-06],
         [ 3.636e-05]],

        [[ 8.404e-05],
         [ 1.505e-04],
         [ 1.226e-04],
         [ 5.033e-04],
         [ 2.953e-04],
         [ 1.209e-04],
         [-3.301e-05],
         [-1.861e-05],
         [ 4.087e-04],
         [ 1.458e-04]],

        [[ 7.930e-04],
         [ 9.051e-04],
         [ 7.854e-04],
         [-9.423e-06],
         [ 7.018e-04],
         [ 6.399e-04],
         [ 1.898e-05],
         [ 7.239e-04],
         [-1.766e-05],
         [-1.327e-05]],

        [[ 2.274e-04],
         [ 1.477e-04],
         [-1.223e-05],
         [ 3.954e-04],
         [ 3.515e-04],
         [ 3.559e-05],
         [ 2.355e-04],
         [ 1.860e-05],
         [ 1.589e-04],
         [ 5.864e-04]],

        [[-2.503e-05],
         [ 5.413e-05],
         [-1.897e-05],
         [ 3.264e-04],
         [ 1.576e-04],
         [ 7.298e-04],
         [ 6.136e-04],
         [ 4.179e-04],
         [ 2.124e-04],
         [ 1.017e-05]],

        [[ 2.468e-04],
         [-7.003e-05],
         [ 2.867e-04],
         [ 7.620e-05],
         [ 1.690e-04],
         [ 6.570e-04],
         [ 9.718e-05],
         [ 4.553e-04],
         [ 5.063e-04],
         [ 2.701e-04]],

        [[ 5.246e-05],
         [ 1.239e-04],
         [ 3.821e-04],
         [ 1.626e-04],
         [-1.030e-05],
         [ 2.691e-04],
         [ 1.426e-04],
         [ 3.596e-05],
         [ 1.563e-04],
         [ 3.164e-04]],

        [[ 1.582e-04],
         [-1.665e-05],
         [ 5.585e-05],
         [ 3.544e-04],
         [ 1.227e-04],
         [ 9.665e-05],
         [ 2.461e-04],
         [ 5.180e-04],
         [ 2.036e-05],
         [ 2.205e-05]],

        [[ 2.985e-04],
         [ 3.628e-04],
         [-8.741e-05],
         [ 3.981e-04],
         [-1.448e-06],
         [ 3.280e-04],
         [-8.920e-09],
         [ 1.356e-04],
         [ 1.085e-04],
         [ 1.476e-04]],

        [[-3.405e-04],
         [ 1.306e-05],
         [-4.639e-04],
         [ 1.969e-05],
         [-7.089e-05],
         [-7.024e-06],
         [-3.575e-04],
         [ 1.108e-04],
         [-2.819e-04],
         [-6.186e-04]],

        [[-5.194e-04],
         [-4.668e-04],
         [-5.765e-04],
         [-3.395e-04],
         [-4.988e-04],
         [-2.248e-04],
         [ 5.472e-06],
         [-3.802e-05],
         [ 5.002e-05],
         [ 3.103e-06]],

        [[ 3.265e-04],
         [-5.442e-05],
         [ 4.699e-05],
         [ 3.216e-05],
         [-7.434e-09],
         [-5.310e-05],
         [ 2.647e-06],
         [ 1.044e-06],
         [-5.246e-06],
         [ 8.500e-05]],

        [[ 3.172e-05],
         [ 1.390e-04],
         [-1.982e-06],
         [ 4.098e-05],
         [-2.107e-05],
         [ 5.782e-06],
         [ 1.039e-04],
         [-6.082e-06],
         [ 8.624e-05],
         [-5.832e-07]]], device='cuda:0')
s after update for 1 param tensor([[[1.776e-02],
         [7.049e-04],
         [1.930e-03],
         [2.263e-03],
         [5.777e-03],
         [6.474e-03],
         [8.023e-03],
         [4.238e-04],
         [9.121e-06],
         [2.083e-03]],

        [[2.518e-02],
         [1.873e-03],
         [3.072e-02],
         [3.137e-02],
         [3.040e-02],
         [1.435e-02],
         [1.916e-03],
         [5.500e-03],
         [7.853e-02],
         [8.542e-02]],

        [[1.591e-02],
         [3.007e-02],
         [4.700e-03],
         [1.663e-02],
         [2.071e-02],
         [1.462e-02],
         [1.487e-02],
         [7.843e-03],
         [4.190e-03],
         [7.367e-04]],

        [[6.090e-03],
         [4.916e-03],
         [1.699e-02],
         [1.023e-02],
         [1.710e-05],
         [1.463e-03],
         [3.635e-03],
         [1.027e-02],
         [4.894e-03],
         [4.168e-03]],

        [[7.734e-02],
         [1.414e-01],
         [1.588e-02],
         [1.937e-02],
         [1.203e-02],
         [1.151e-04],
         [2.174e-02],
         [1.318e-01],
         [8.972e-02],
         [2.100e-03]],

        [[3.508e-03],
         [4.937e-03],
         [2.687e-03],
         [6.911e-03],
         [9.138e-04],
         [1.152e-04],
         [4.338e-04],
         [4.487e-03],
         [2.643e-03],
         [1.823e-03]],

        [[6.224e-02],
         [1.540e-03],
         [3.530e-02],
         [1.928e-02],
         [2.301e-02],
         [2.253e-02],
         [1.318e-02],
         [2.555e-02],
         [2.783e-02],
         [4.452e-03]],

        [[7.642e-06],
         [6.750e-03],
         [1.984e-04],
         [1.565e-03],
         [7.885e-04],
         [1.622e-03],
         [5.217e-03],
         [1.869e-02],
         [2.772e-04],
         [5.142e-03]],

        [[5.224e-03],
         [1.319e-02],
         [1.336e-02],
         [6.578e-02],
         [4.461e-02],
         [1.271e-02],
         [4.324e-02],
         [3.463e-03],
         [2.189e-02],
         [5.879e-03]],

        [[9.462e-02],
         [1.045e-01],
         [1.073e-01],
         [1.541e-03],
         [8.089e-02],
         [9.776e-02],
         [3.868e-03],
         [6.995e-02],
         [6.729e-03],
         [7.801e-03]],

        [[1.095e-02],
         [1.725e-02],
         [2.309e-03],
         [2.414e-02],
         [2.581e-02],
         [3.517e-03],
         [2.326e-02],
         [3.508e-04],
         [2.013e-02],
         [7.972e-02]],

        [[1.887e-03],
         [6.089e-03],
         [2.423e-04],
         [3.329e-02],
         [2.965e-02],
         [8.012e-02],
         [6.324e-02],
         [4.043e-02],
         [1.403e-02],
         [3.193e-04]],

        [[4.313e-02],
         [2.857e-03],
         [5.029e-02],
         [1.863e-02],
         [1.490e-02],
         [1.116e-01],
         [1.169e-02],
         [3.744e-02],
         [3.447e-02],
         [4.540e-02]],

        [[1.170e-03],
         [1.568e-02],
         [2.492e-02],
         [9.928e-03],
         [1.358e-03],
         [3.681e-02],
         [1.227e-02],
         [7.983e-03],
         [1.518e-02],
         [3.518e-02]],

        [[6.559e-03],
         [1.195e-03],
         [2.305e-03],
         [4.642e-02],
         [1.039e-02],
         [1.122e-02],
         [1.273e-02],
         [7.882e-02],
         [1.416e-03],
         [2.847e-04]],

        [[3.400e-02],
         [3.210e-02],
         [1.125e-02],
         [4.860e-02],
         [2.089e-03],
         [4.269e-02],
         [9.857e-04],
         [3.294e-03],
         [1.411e-02],
         [3.685e-03]],

        [[4.631e-02],
         [9.761e-04],
         [4.504e-02],
         [2.274e-03],
         [1.856e-03],
         [8.164e-05],
         [1.622e-02],
         [4.821e-03],
         [1.721e-02],
         [5.138e-02]],

        [[4.523e-02],
         [3.805e-02],
         [4.338e-02],
         [4.749e-02],
         [4.756e-02],
         [1.744e-02],
         [1.429e-03],
         [3.887e-04],
         [1.140e-02],
         [1.066e-02]],

        [[2.787e-02],
         [1.904e-02],
         [1.268e-03],
         [6.233e-03],
         [4.583e-05],
         [1.375e-03],
         [8.599e-05],
         [4.630e-04],
         [5.187e-04],
         [1.779e-02]],

        [[3.026e-03],
         [6.450e-03],
         [7.485e-05],
         [5.030e-04],
         [1.915e-04],
         [8.410e-05],
         [1.475e-02],
         [1.968e-03],
         [1.243e-02],
         [9.163e-05]]], device='cuda:0')
b after update for 1 param tensor([[[0.628],
         [0.125],
         [0.207],
         [0.224],
         [0.358],
         [0.379],
         [0.422],
         [0.097],
         [0.014],
         [0.215]],

        [[0.748],
         [0.204],
         [0.826],
         [0.835],
         [0.822],
         [0.565],
         [0.206],
         [0.350],
         [1.321],
         [1.378]],

        [[0.595],
         [0.817],
         [0.323],
         [0.608],
         [0.678],
         [0.570],
         [0.575],
         [0.417],
         [0.305],
         [0.128]],

        [[0.368],
         [0.330],
         [0.614],
         [0.477],
         [0.019],
         [0.180],
         [0.284],
         [0.478],
         [0.330],
         [0.304]],

        [[1.311],
         [1.772],
         [0.594],
         [0.656],
         [0.517],
         [0.051],
         [0.695],
         [1.711],
         [1.412],
         [0.216]],

        [[0.279],
         [0.331],
         [0.244],
         [0.392],
         [0.142],
         [0.051],
         [0.098],
         [0.316],
         [0.242],
         [0.201]],

        [[1.176],
         [0.185],
         [0.886],
         [0.654],
         [0.715],
         [0.708],
         [0.541],
         [0.753],
         [0.786],
         [0.315]],

        [[0.013],
         [0.387],
         [0.066],
         [0.186],
         [0.132],
         [0.190],
         [0.340],
         [0.644],
         [0.078],
         [0.338]],

        [[0.341],
         [0.541],
         [0.545],
         [1.209],
         [0.996],
         [0.531],
         [0.980],
         [0.277],
         [0.697],
         [0.361]],

        [[1.450],
         [1.523],
         [1.544],
         [0.185],
         [1.341],
         [1.474],
         [0.293],
         [1.247],
         [0.387],
         [0.416]],

        [[0.493],
         [0.619],
         [0.226],
         [0.732],
         [0.757],
         [0.280],
         [0.719],
         [0.088],
         [0.669],
         [1.331]],

        [[0.205],
         [0.368],
         [0.073],
         [0.860],
         [0.812],
         [1.334],
         [1.185],
         [0.948],
         [0.558],
         [0.084]],

        [[0.979],
         [0.252],
         [1.057],
         [0.643],
         [0.575],
         [1.574],
         [0.510],
         [0.912],
         [0.875],
         [1.004]],

        [[0.161],
         [0.590],
         [0.744],
         [0.470],
         [0.174],
         [0.904],
         [0.522],
         [0.421],
         [0.581],
         [0.884]],

        [[0.382],
         [0.163],
         [0.226],
         [1.016],
         [0.480],
         [0.499],
         [0.532],
         [1.323],
         [0.177],
         [0.080]],

        [[0.869],
         [0.844],
         [0.500],
         [1.039],
         [0.215],
         [0.974],
         [0.148],
         [0.271],
         [0.560],
         [0.286]],

        [[1.014],
         [0.147],
         [1.000],
         [0.225],
         [0.203],
         [0.043],
         [0.600],
         [0.327],
         [0.618],
         [1.068]],

        [[1.002],
         [0.919],
         [0.982],
         [1.027],
         [1.028],
         [0.623],
         [0.178],
         [0.093],
         [0.503],
         [0.487]],

        [[0.787],
         [0.650],
         [0.168],
         [0.372],
         [0.032],
         [0.175],
         [0.044],
         [0.101],
         [0.107],
         [0.629]],

        [[0.259],
         [0.379],
         [0.041],
         [0.106],
         [0.065],
         [0.043],
         [0.573],
         [0.209],
         [0.526],
         [0.045]]], device='cuda:0')
clipping threshold 2.782537623814828
a after update for 1 param tensor([[ 9.045e-05],
        [-1.379e-03],
        [ 3.939e-04],
        [-4.575e-05],
        [-1.229e-03],
        [ 6.452e-05],
        [-2.743e-05],
        [ 6.100e-05],
        [ 3.790e-04],
        [ 1.077e-03],
        [ 4.675e-04],
        [ 4.915e-04],
        [ 5.255e-04],
        [ 3.255e-04],
        [ 1.900e-04],
        [ 1.470e-04],
        [-5.730e-04],
        [-4.173e-04],
        [ 1.101e-04],
        [ 1.304e-04]], device='cuda:0')
s after update for 1 param tensor([[0.014],
        [0.151],
        [0.029],
        [0.004],
        [0.149],
        [0.006],
        [0.013],
        [0.004],
        [0.054],
        [0.150],
        [0.071],
        [0.060],
        [0.061],
        [0.039],
        [0.020],
        [0.008],
        [0.053],
        [0.056],
        [0.009],
        [0.028]], device='cuda:0')
b after update for 1 param tensor([[0.563],
        [1.830],
        [0.797],
        [0.281],
        [1.818],
        [0.360],
        [0.534],
        [0.279],
        [1.098],
        [1.823],
        [1.252],
        [1.156],
        [1.162],
        [0.930],
        [0.666],
        [0.421],
        [1.090],
        [1.115],
        [0.435],
        [0.784]], device='cuda:0')
clipping threshold 2.782537623814828
||w||^2 0.10363249569327608
exp ma of ||w||^2 0.2694886213634526
||w|| 0.3219200144341387
exp ma of ||w|| 0.47197807540161635
||w||^2 0.14181210994211652
exp ma of ||w||^2 0.2795262329636835
||w|| 0.376579486884398
exp ma of ||w|| 0.48499288941391583
||w||^2 0.1857815247970191
exp ma of ||w||^2 0.24469075474214888
||w|| 0.43102381001171974
exp ma of ||w|| 0.4744612308834207
||w||^2 0.18419245206178195
exp ma of ||w||^2 0.31905232180626386
||w|| 0.42917648125425273
exp ma of ||w|| 0.5190402872999954
||w||^2 0.31817737027768456
exp ma of ||w||^2 0.5292968083622116
||w|| 0.5640721321583655
exp ma of ||w|| 0.6731919165468149
||w||^2 0.36579447945440424
exp ma of ||w||^2 0.5266787199870736
||w|| 0.6048094571469631
exp ma of ||w|| 0.6656453962004035
||w||^2 0.6946739834444253
exp ma of ||w||^2 0.5034732271391288
||w|| 0.8334710453545614
exp ma of ||w|| 0.6579295318209786
v before min max tensor([[-17.749,   2.509, -12.227,  ..., -12.031,  -8.600,   3.021],
        [-22.068,   8.876,  -1.995,  ...,  -5.995, -13.247, -11.554],
        [-12.590,  14.459, -14.629,  ..., -13.221, -15.658,  -7.070],
        ...,
        [-11.489, -17.448, -12.408,  ..., -10.335,  -7.385,  -9.413],
        [-16.235,  18.017,  -6.332,  ..., -14.781, -16.261,   8.241],
        [ -7.696, -14.978,   8.022,  ...,  58.083, -13.060,  -2.388]],
       device='cuda:0')
v tensor([[1.000e-12, 2.509e+00, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         3.021e+00],
        [1.000e-12, 8.876e+00, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         8.241e+00],
        [1.000e-12, 1.000e-12, 8.022e+00,  ..., 1.000e+01, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([-18.816,  -9.994, -18.608, -12.094,  15.557, -15.339, -12.875, -10.869,
        -16.639,  -8.280,  -5.280,  -2.311,  -1.406, -13.676,  -9.373, -17.458,
        -15.657,  12.244,  -5.201,   6.894, -11.906,  16.508,  38.840,  40.436,
        -17.753,  -1.313,  -9.053,  -0.674, -19.319, -20.356,  -4.714, -17.530,
        -17.669, -17.500, -16.755, -14.199, -17.619, -16.421,  -9.285, -13.011,
         25.668,  -6.573,  -0.355, -18.149,  13.159,  -6.784,  -0.122,  -3.029,
        -13.512,  -2.791, -12.559,  -7.596, -15.058, -17.304, -23.603,  27.386,
         -4.369, -13.642,  -8.155, -20.784, -18.812,  92.054,  17.880, -15.930,
        -17.667, -17.396, -15.204,  31.511, -12.115,  49.541,  26.883, -18.027,
          2.957,  -7.622, -14.512,  45.275,  -9.543,  -3.400,   7.531,  -5.202,
          1.565,  -3.678,  -5.601, -12.278, -11.133,  -7.838,   6.287, -19.967,
        -18.009,  -6.536,  28.059,  14.164, -18.769, -19.711,  -6.411, -13.250,
          0.594, -17.109,   0.763,  -8.422,  10.025, -10.621,  -1.847,  -5.933,
         34.974,  10.542,  -7.740, -16.255, -14.526, -13.723,  -1.571, -13.390,
        -18.646,  -9.671, -15.068, -12.594,  -8.928,  -3.812,  17.059, -21.788,
         27.574,  -4.019,  -9.112, -17.642, -20.623, -16.849, -15.927, -17.732,
        -15.865, -17.473,  -7.557, -17.116,  38.589,  17.496,  -6.773, -15.341,
        -19.363,  -6.785,  -5.576,   6.297,  -2.765,  -2.953, -16.952,   4.019,
         -7.637, -14.400, -14.670, -17.019, -11.783, -17.172, -19.858,   0.246,
         -5.895,  -3.157,  -5.312,  26.071, -10.121, -13.929,  41.195,   0.864,
        -17.989,   6.896,   1.733,   4.201,  22.172,  -1.438, -11.170,  -0.154,
         14.326, -13.385, -15.009, -10.824, -13.886,  12.673, -13.164, -15.080,
        -18.478,  -9.138,  -5.179, -22.540, -13.376, -11.660,  -4.293,  11.185,
        -15.040, -11.144, -10.303,  -8.925,  -8.317,  69.147, -18.492, -17.701,
          0.436, -13.828,  -9.447,  -6.414, -15.363,   3.133, -11.211, -16.854],
       device='cuda:0')
v tensor([1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 6.894e+00, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        2.957e+00, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        7.531e+00, 1.000e-12, 1.565e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 6.287e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        5.945e-01, 1.000e-12, 7.628e-01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 6.297e+00, 1.000e-12, 1.000e-12, 1.000e-12, 4.019e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 2.464e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 8.637e-01, 1.000e-12, 6.896e+00,
        1.733e+00, 4.201e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        4.355e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.133e+00,
        1.000e-12, 1.000e-12], device='cuda:0')
v before min max tensor([[[-1.324e+01],
         [-9.965e+00],
         [-1.552e+01],
         [ 7.252e+00],
         [-1.326e+01],
         [ 5.698e+01],
         [-1.153e+01],
         [-1.665e+01],
         [-6.511e+00],
         [ 1.793e+01]],

        [[-1.188e+01],
         [-1.517e+01],
         [ 1.106e+02],
         [ 1.178e+02],
         [ 4.841e+01],
         [-1.612e+01],
         [-3.211e+00],
         [ 6.734e+00],
         [ 2.113e+02],
         [-2.799e+00]],

        [[-1.436e+01],
         [ 8.721e+01],
         [ 1.754e+01],
         [-1.689e+01],
         [-1.917e+01],
         [-1.040e+01],
         [-1.782e+01],
         [-1.246e+01],
         [ 3.868e+00],
         [ 3.070e+01]],

        [[-1.423e+01],
         [-5.388e+00],
         [ 2.020e+01],
         [-1.992e+01],
         [-1.928e+00],
         [-1.859e+01],
         [-1.609e+01],
         [-1.691e+01],
         [-8.486e+00],
         [-1.277e+01]],

        [[ 1.465e+02],
         [ 4.256e+01],
         [ 4.467e+01],
         [ 9.631e+01],
         [-1.577e+01],
         [ 1.981e+01],
         [ 3.973e+01],
         [-4.998e+00],
         [ 3.334e+01],
         [ 3.908e+02]],

        [[-2.059e+01],
         [ 1.570e+01],
         [ 6.231e+01],
         [-1.003e+01],
         [-7.896e+00],
         [-8.211e+00],
         [ 3.257e+00],
         [ 5.797e+01],
         [-1.666e+01],
         [-1.034e+00]],

        [[-1.880e+01],
         [-9.594e+00],
         [-1.885e+01],
         [-2.153e+01],
         [ 1.504e+00],
         [-1.651e+01],
         [-9.331e+00],
         [-2.259e+01],
         [ 1.615e+01],
         [ 3.176e+01]],

        [[ 6.213e+01],
         [ 7.571e+00],
         [-2.213e+01],
         [-5.624e-01],
         [-9.967e+00],
         [ 8.339e-01],
         [ 4.265e+01],
         [ 3.732e+00],
         [-1.230e+01],
         [ 1.666e+00]],

        [[ 5.949e+01],
         [ 7.545e+01],
         [ 3.317e+01],
         [-1.654e+01],
         [-1.711e+01],
         [ 5.689e+00],
         [-2.139e+01],
         [ 6.996e+01],
         [-3.075e+00],
         [-2.781e+00]],

        [[ 9.264e+01],
         [-2.338e+01],
         [ 9.315e+01],
         [-1.271e+01],
         [ 5.511e+01],
         [-6.528e+00],
         [ 1.871e+01],
         [ 2.849e+02],
         [ 2.910e+00],
         [-1.536e+01]],

        [[-1.247e+01],
         [ 3.773e+01],
         [-3.931e+00],
         [-6.485e+00],
         [-1.646e+01],
         [-1.014e+01],
         [ 1.234e+00],
         [-8.203e+00],
         [-1.014e+01],
         [-1.861e+01]],

        [[-1.627e+00],
         [-6.919e+00],
         [ 5.602e-02],
         [-1.105e+01],
         [-1.230e+01],
         [ 1.417e+01],
         [-1.156e+01],
         [ 1.241e+00],
         [-1.914e+01],
         [-1.665e+01]],

        [[ 9.710e+00],
         [-1.267e+01],
         [ 8.711e+01],
         [-1.560e+01],
         [-2.284e+01],
         [ 7.661e+01],
         [-6.814e+00],
         [ 4.360e+01],
         [-1.927e+01],
         [-1.741e+01]],

        [[-1.246e+01],
         [-1.828e+00],
         [ 1.923e+01],
         [-9.536e+00],
         [-6.575e+00],
         [ 1.992e+01],
         [-8.038e+00],
         [ 3.710e+01],
         [-4.750e+00],
         [-1.870e+01]],

        [[ 1.781e+00],
         [-1.143e+00],
         [-1.836e+01],
         [-6.389e+00],
         [-1.865e+01],
         [-1.747e+01],
         [ 7.422e+00],
         [-1.420e+01],
         [-5.042e+00],
         [-1.632e+01]],

        [[-1.065e+01],
         [-1.015e+01],
         [ 2.607e+01],
         [-1.435e+01],
         [-7.194e+00],
         [-4.149e+00],
         [-7.146e-01],
         [-1.160e+01],
         [-1.554e+01],
         [-1.275e+01]],

        [[-1.086e+01],
         [-1.406e+01],
         [-1.712e+01],
         [-1.380e+01],
         [ 2.319e+01],
         [ 1.507e+01],
         [ 6.479e+01],
         [-1.056e+01],
         [ 1.400e+00],
         [ 8.253e+01]],

        [[-2.112e+01],
         [-1.399e+01],
         [-8.485e+00],
         [-2.441e+01],
         [-2.306e+01],
         [ 5.972e+01],
         [-1.203e+01],
         [-8.105e+00],
         [ 1.030e+01],
         [-3.891e+00]],

        [[-9.522e+00],
         [ 2.404e+01],
         [-1.576e+01],
         [-1.462e+01],
         [-1.474e+01],
         [-8.829e+00],
         [-1.437e+01],
         [-1.043e+01],
         [-1.314e+01],
         [-3.582e+00]],

        [[-9.621e+00],
         [ 9.663e+00],
         [-1.500e+01],
         [-2.106e+01],
         [-9.732e+00],
         [-6.944e-01],
         [-1.695e+01],
         [-9.123e+00],
         [ 1.195e+01],
         [-5.864e+00]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.252e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [6.734e+00],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.868e+00],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.257e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.504e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [7.571e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [8.339e-01],
         [1.000e+01],
         [3.732e+00],
         [1.000e-12],
         [1.666e+00]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [5.689e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [2.910e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.234e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [5.602e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.241e+00],
         [1.000e-12],
         [1.000e-12]],

        [[9.710e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.781e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.422e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.400e+00],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [9.663e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[ 34.993],
        [ 94.418],
        [ -6.322],
        [-17.083],
        [243.324],
        [-15.079],
        [-16.421],
        [ -6.472],
        [-19.303],
        [ 49.290],
        [ 54.147],
        [-22.551],
        [-13.566],
        [-21.832],
        [ -4.625],
        [-16.383],
        [-12.051],
        [ 27.374],
        [ 58.861],
        [ -2.348]], device='cuda:0')
v tensor([[1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-0.010, -0.037, -0.017,  ...,  0.005, -0.011,  0.000],
        [-0.037, -0.013,  0.086,  ...,  0.028, -0.008, -0.024],
        [ 0.028, -0.047, -0.016,  ..., -0.031, -0.091,  0.046],
        ...,
        [-0.022,  0.011, -0.035,  ...,  0.004, -0.034,  0.045],
        [-0.014, -0.007, -0.054,  ...,  0.007, -0.026, -0.016],
        [ 0.011, -0.006,  0.021,  ...,  0.041, -0.046,  0.007]],
       device='cuda:0')
s after update for 1 param tensor([[1.634, 1.652, 1.513,  ..., 1.157, 1.149, 1.002],
        [2.039, 1.789, 1.158,  ..., 0.740, 1.455, 1.180],
        [1.397, 1.944, 1.321,  ..., 1.441, 1.346, 1.634],
        ...,
        [1.081, 1.495, 1.540,  ..., 1.571, 0.835, 1.701],
        [1.523, 1.838, 1.342,  ..., 1.750, 1.654, 1.713],
        [1.175, 1.285, 1.507,  ..., 1.594, 1.150, 1.057]], device='cuda:0')
b after update for 1 param tensor([[104.574, 105.164, 100.645,  ...,  87.993,  87.712,  81.903],
        [116.813, 109.431,  88.057,  ...,  70.398,  98.700,  88.890],
        [ 96.699, 114.067,  94.042,  ...,  98.208,  94.905, 104.587],
        ...,
        [ 85.075, 100.033, 101.525,  ..., 102.542,  74.756, 106.715],
        [100.978, 110.914,  94.776,  ..., 108.221, 105.209, 107.088],
        [ 88.666,  92.735, 100.440,  ..., 103.282,  87.745,  84.094]],
       device='cuda:0')
clipping threshold 0.4740575156559753
a after update for 1 param tensor([ 0.034, -0.050,  0.010,  0.004, -0.024, -0.002,  0.017, -0.049,  0.031,
        -0.008,  0.005, -0.002,  0.009, -0.014, -0.005,  0.018, -0.011, -0.040,
         0.023,  0.044, -0.032,  0.030, -0.038,  0.073, -0.005,  0.070, -0.062,
         0.006,  0.056, -0.005,  0.035, -0.053, -0.071, -0.043, -0.024, -0.010,
         0.042, -0.069, -0.014, -0.032, -0.006, -0.105,  0.004, -0.082, -0.017,
        -0.040,  0.045, -0.020, -0.088, -0.037,  0.000, -0.019,  0.009, -0.033,
         0.054,  0.013,  0.038, -0.083,  0.029, -0.028,  0.000, -0.011,  0.044,
        -0.027, -0.015, -0.027, -0.032,  0.012, -0.044, -0.054, -0.053,  0.018,
         0.044,  0.042, -0.032,  0.041, -0.063,  0.010,  0.035, -0.029, -0.019,
        -0.027, -0.009,  0.062,  0.028, -0.001, -0.018, -0.021,  0.033,  0.007,
         0.036, -0.005, -0.060,  0.031,  0.021, -0.017, -0.052,  0.002, -0.001,
        -0.010, -0.003,  0.002,  0.034,  0.036,  0.003, -0.038, -0.018, -0.045,
        -0.019,  0.003,  0.034, -0.004,  0.033, -0.005,  0.050, -0.026, -0.058,
        -0.012, -0.028,  0.002, -0.061,  0.010, -0.033,  0.001, -0.065, -0.031,
        -0.066,  0.074,  0.031, -0.017,  0.023,  0.002,  0.065,  0.001, -0.025,
        -0.055,  0.042,  0.010, -0.023,  0.019,  0.030,  0.056, -0.000, -0.011,
        -0.049, -0.037, -0.079,  0.004, -0.011,  0.008, -0.023,  0.017,  0.023,
         0.004, -0.026, -0.033, -0.016,  0.050, -0.045,  0.051, -0.026, -0.027,
        -0.049,  0.003, -0.002,  0.063,  0.020, -0.030,  0.051,  0.016, -0.044,
        -0.021, -0.037, -0.007,  0.003,  0.007, -0.022,  0.027, -0.016, -0.007,
         0.028,  0.064, -0.088, -0.007, -0.029, -0.047,  0.022, -0.014, -0.001,
        -0.002,  0.002, -0.099,  0.072, -0.017, -0.012,  0.025,  0.039,  0.024,
        -0.069,  0.046], device='cuda:0')
s after update for 1 param tensor([1.789, 1.531, 1.797, 1.291, 1.598, 1.361, 1.463, 1.250, 1.510, 0.710,
        1.503, 0.884, 1.487, 1.417, 1.099, 1.497, 1.343, 1.838, 0.835, 1.759,
        1.846, 1.517, 2.050, 2.133, 1.534, 1.422, 1.696, 1.190, 1.667, 2.045,
        1.999, 1.620, 1.557, 1.761, 1.699, 1.256, 1.698, 1.489, 1.465, 1.495,
        1.583, 1.519, 1.461, 1.768, 1.677, 1.432, 1.765, 1.309, 1.244, 1.366,
        1.225, 0.940, 1.739, 1.687, 2.034, 1.937, 0.457, 1.193, 1.256, 1.980,
        1.705, 1.709, 1.990, 1.648, 1.756, 1.557, 1.643, 1.357, 1.043, 1.949,
        1.868, 1.600, 1.497, 1.243, 1.250, 1.680, 1.514, 0.351, 2.031, 0.576,
        1.453, 1.748, 1.374, 1.315, 1.201, 1.705, 1.752, 1.726, 1.572, 1.043,
        1.986, 2.297, 1.611, 2.043, 1.843, 1.136, 1.157, 1.489, 1.732, 1.411,
        1.679, 1.152, 1.120, 0.948, 1.468, 1.991, 1.166, 1.627, 1.383, 1.270,
        0.896, 1.233, 1.598, 0.845, 1.653, 1.151, 1.696, 1.286, 1.687, 1.881,
        2.107, 0.939, 1.175, 1.822, 1.892, 1.690, 1.630, 1.526, 1.827, 1.499,
        1.713, 1.564, 1.739, 2.043, 1.304, 1.357, 1.696, 0.924, 1.399, 1.800,
        1.049, 0.953, 1.455, 1.135, 1.649, 1.245, 1.941, 1.485, 1.276, 1.479,
        1.744, 1.098, 0.563, 0.685, 1.221, 2.100, 1.246, 1.373, 1.797, 1.937,
        1.544, 1.633, 1.769, 1.279, 1.943, 1.649, 1.665, 1.545, 1.900, 1.174,
        1.430, 1.016, 1.207, 1.908, 1.720, 1.344, 1.644, 1.428, 1.969, 2.002,
        1.297, 1.039, 1.216, 2.133, 1.659, 1.574, 1.060, 1.089, 0.878, 1.784,
        1.660, 1.911, 1.714, 1.266, 1.344, 0.719, 1.394, 1.411, 0.961, 1.469],
       device='cuda:0')
b after update for 1 param tensor([109.423, 101.240, 109.685,  92.969, 103.408,  95.432,  98.970,  91.483,
        100.530,  68.927, 100.290,  76.907,  99.774,  97.395,  85.756, 100.110,
         94.800, 110.930,  74.770, 108.522, 111.171, 100.781, 117.150, 119.493,
        101.343,  97.553, 106.540,  89.262, 105.634, 117.004, 115.669, 104.131,
        102.086, 108.557, 106.627,  91.681, 106.604,  99.830,  99.012, 100.025,
        102.929, 100.826,  98.904, 108.790, 105.950,  97.913, 108.707,  93.587,
         91.258,  95.625,  90.557,  79.335, 107.879, 106.261, 116.691, 113.851,
         55.319,  89.363,  91.702, 115.111, 106.831, 106.964, 115.410, 105.038,
        108.417, 102.090, 104.862,  95.289,  83.563, 114.208, 111.814, 103.496,
        100.106,  91.216,  91.478, 106.047, 100.657,  48.458, 116.608,  62.071,
         98.618, 108.154,  95.915,  93.833,  89.641, 106.843, 108.294, 107.469,
        102.570,  83.546, 115.293, 123.999, 103.851, 116.928, 111.067,  87.180,
         88.004,  99.828, 107.683,  97.168, 106.021,  87.792,  86.568,  79.651,
         99.140, 115.434,  88.331, 104.352,  96.208,  92.185,  77.433,  90.840,
        103.417,  75.214, 105.199,  87.769, 106.537,  92.788, 106.252, 112.210,
        118.743,  79.282,  88.695, 110.429, 112.530, 106.349, 104.452, 101.081,
        110.592, 100.180, 107.088, 102.300, 107.897, 116.935,  93.434,  95.315,
        106.561,  78.622,  96.782, 109.754,  83.794,  79.866,  98.694,  87.168,
        105.048,  91.285, 113.982,  99.688,  92.424,  99.505, 108.031,  85.739,
         61.408,  67.734,  90.408, 118.573,  91.321,  95.859, 109.666, 113.866,
        101.665, 104.554, 108.801,  92.520, 114.049, 105.074, 105.575, 101.704,
        112.785,  88.635,  97.822,  82.458,  89.876, 113.013, 107.305,  94.838,
        104.909,  97.781, 114.808, 115.751,  93.162,  83.384,  90.213, 119.493,
        105.392, 102.628,  84.215,  85.364,  76.672, 109.290, 105.402, 113.092,
        107.097,  92.065,  94.845,  69.378,  96.597,  97.193,  80.197,  99.159],
       device='cuda:0')
clipping threshold 0.4740575156559753
a after update for 1 param tensor([[[ 1.432e-01],
         [-8.883e-02],
         [ 9.571e-04],
         [ 1.815e-01],
         [-7.629e-02],
         [ 1.013e-01],
         [ 1.521e-01],
         [-1.268e-01],
         [-3.169e-02],
         [ 1.181e-01]],

        [[-2.119e+00],
         [-1.742e+00],
         [-3.870e+00],
         [-3.916e+00],
         [-3.773e+00],
         [ 7.039e-02],
         [-7.127e-01],
         [-3.585e+00],
         [-3.749e+00],
         [-3.878e+00]],

        [[ 1.415e-01],
         [ 1.463e-01],
         [ 1.918e-01],
         [ 1.065e-01],
         [ 1.158e-02],
         [ 1.644e-01],
         [ 9.571e-02],
         [ 1.702e-01],
         [ 1.843e-01],
         [ 2.592e-02]],

        [[ 1.754e-01],
         [ 2.610e-01],
         [ 2.205e-01],
         [ 2.357e-01],
         [ 4.073e-02],
         [ 1.250e-01],
         [ 2.183e-01],
         [-6.493e-02],
         [-1.236e-01],
         [-1.506e-02]],

        [[-2.640e+00],
         [-2.656e+00],
         [-6.606e-01],
         [-2.779e+00],
         [-2.359e-02],
         [-4.039e-01],
         [-2.226e+00],
         [-6.957e-02],
         [-2.695e+00],
         [-2.479e+00]],

        [[ 5.853e-02],
         [ 9.336e-01],
         [-7.536e-01],
         [ 9.785e-01],
         [ 5.057e-01],
         [ 6.775e-01],
         [-2.713e-01],
         [-8.465e-01],
         [-9.814e-01],
         [-1.785e-01]],

        [[-9.171e-01],
         [ 1.824e-01],
         [-1.261e+00],
         [-1.106e+00],
         [-1.119e+00],
         [-1.089e+00],
         [ 2.065e-01],
         [-1.092e+00],
         [-1.090e+00],
         [ 6.317e-02]],

        [[-2.792e-02],
         [ 9.996e-03],
         [ 1.166e-01],
         [ 7.696e-02],
         [ 3.768e-02],
         [-2.588e-03],
         [-6.554e-02],
         [-4.114e-02],
         [-1.902e-02],
         [ 1.004e-01]],

        [[ 1.896e-01],
         [ 2.995e-01],
         [ 2.357e-01],
         [ 2.957e-01],
         [ 3.187e-01],
         [ 2.247e-01],
         [ 2.499e-01],
         [ 1.803e-01],
         [ 1.119e-02],
         [ 3.290e-01]],

        [[ 3.350e+00],
         [ 3.311e+00],
         [ 3.147e+00],
         [ 1.748e-02],
         [ 3.331e+00],
         [ 3.128e+00],
         [ 3.067e+00],
         [ 3.287e+00],
         [ 4.924e-03],
         [-2.868e-03]],

        [[ 4.538e-01],
         [ 5.217e-01],
         [-7.321e-02],
         [ 4.735e-01],
         [ 4.534e-01],
         [ 1.405e-01],
         [ 4.808e-01],
         [-3.601e-02],
         [ 6.825e-02],
         [ 3.607e-01]],

        [[ 2.434e-02],
         [ 1.652e-01],
         [ 2.850e-02],
         [ 7.961e-02],
         [ 1.045e+00],
         [ 1.057e+00],
         [ 1.097e+00],
         [ 9.734e-01],
         [ 8.630e-01],
         [ 8.692e-01]],

        [[ 9.641e-01],
         [ 7.960e-02],
         [ 8.189e-01],
         [-5.282e-02],
         [ 1.015e+00],
         [ 1.021e+00],
         [ 6.260e-02],
         [ 1.133e+00],
         [ 2.061e-02],
         [ 1.093e+00]],

        [[-3.794e-02],
         [ 6.395e-01],
         [ 6.393e-01],
         [ 6.474e-01],
         [ 1.633e-02],
         [ 6.704e-01],
         [-2.314e-03],
         [-7.440e-02],
         [ 3.244e-01],
         [ 6.852e-01]],

        [[-2.649e-02],
         [-8.661e-02],
         [ 1.017e+00],
         [ 1.077e+00],
         [-3.273e-02],
         [-8.380e-02],
         [ 1.178e+00],
         [ 1.306e+00],
         [-1.187e-01],
         [ 4.892e-01]],

        [[ 1.183e+00],
         [ 1.233e+00],
         [-4.427e-01],
         [ 1.148e+00],
         [ 5.095e-01],
         [-3.342e-01],
         [-1.150e-01],
         [ 1.280e+00],
         [ 8.408e-01],
         [-2.475e-01]],

        [[ 1.878e-01],
         [ 2.740e-01],
         [-1.205e+00],
         [-1.252e+00],
         [-1.198e+00],
         [ 1.814e-01],
         [-1.328e+00],
         [ 2.512e-01],
         [-1.250e+00],
         [-1.168e+00]],

        [[-9.082e-01],
         [-8.364e-01],
         [-8.515e-01],
         [-6.739e-01],
         [-8.445e-01],
         [-7.325e-01],
         [ 1.644e-02],
         [ 2.056e-02],
         [-6.839e-02],
         [-1.606e-02]],

        [[ 4.025e-01],
         [ 2.571e-01],
         [-9.537e-02],
         [ 3.188e-01],
         [-1.076e-01],
         [-8.364e-02],
         [-1.254e-01],
         [-2.968e-02],
         [-9.370e-02],
         [ 2.755e-01]],

        [[-1.290e-01],
         [ 4.047e-01],
         [ 1.963e-01],
         [-1.203e-01],
         [-4.979e-02],
         [ 1.769e-02],
         [ 3.981e-01],
         [ 2.609e-01],
         [ 4.068e-01],
         [ 1.906e-01]]], device='cuda:0')
s after update for 1 param tensor([[[1.438],
         [1.236],
         [1.758],
         [1.695],
         [1.306],
         [1.890],
         [1.741],
         [1.623],
         [1.310],
         [1.521]],

        [[2.326],
         [2.121],
         [2.198],
         [2.471],
         [2.024],
         [1.461],
         [2.802],
         [2.237],
         [2.715],
         [2.057]],

        [[1.413],
         [2.019],
         [1.932],
         [1.652],
         [2.063],
         [1.265],
         [1.596],
         [1.070],
         [1.508],
         [1.398]],

        [[1.265],
         [1.567],
         [1.518],
         [1.988],
         [1.372],
         [1.638],
         [1.388],
         [1.733],
         [1.607],
         [1.878]],

        [[2.871],
         [2.918],
         [1.553],
         [2.851],
         [1.352],
         [2.161],
         [2.732],
         [1.523],
         [3.050],
         [2.928]],

        [[1.806],
         [1.480],
         [2.147],
         [1.442],
         [1.217],
         [2.042],
         [1.782],
         [1.721],
         [1.471],
         [1.277]],

        [[1.939],
         [0.939],
         [1.653],
         [1.919],
         [1.986],
         [1.831],
         [1.156],
         [1.968],
         [1.904],
         [2.040]],

        [[2.237],
         [1.421],
         [1.907],
         [1.947],
         [0.854],
         [0.858],
         [1.880],
         [1.276],
         [1.054],
         [1.470]],

        [[2.045],
         [2.395],
         [2.056],
         [1.717],
         [1.639],
         [1.728],
         [1.875],
         [1.685],
         [1.643],
         [1.653]],

        [[2.765],
         [2.571],
         [2.743],
         [1.092],
         [2.705],
         [2.664],
         [2.631],
         [2.628],
         [1.877],
         [1.323]],

        [[1.362],
         [2.134],
         [1.238],
         [0.882],
         [1.497],
         [1.499],
         [1.065],
         [1.010],
         [1.138],
         [1.718]],

        [[1.589],
         [1.525],
         [1.488],
         [1.180],
         [1.861],
         [2.621],
         [2.186],
         [2.322],
         [1.641],
         [2.051]],

        [[2.292],
         [1.092],
         [2.311],
         [1.791],
         [2.244],
         [2.164],
         [1.502],
         [2.065],
         [1.664],
         [2.497]],

        [[1.489],
         [1.158],
         [1.812],
         [1.934],
         [1.305],
         [2.030],
         [0.774],
         [1.872],
         [1.145],
         [1.604]],

        [[1.818],
         [1.572],
         [1.635],
         [2.239],
         [1.641],
         [1.654],
         [2.009],
         [1.512],
         [1.165],
         [1.423]],

        [[0.943],
         [1.755],
         [1.766],
         [2.082],
         [1.933],
         [1.271],
         [1.582],
         [1.120],
         [1.884],
         [1.278]],

        [[1.106],
         [1.273],
         [1.735],
         [1.183],
         [1.925],
         [1.964],
         [1.758],
         [0.921],
         [1.849],
         [2.042]],

        [[2.078],
         [1.877],
         [1.637],
         [2.523],
         [2.020],
         [2.417],
         [1.331],
         [1.067],
         [1.580],
         [1.480]],

        [[1.519],
         [1.699],
         [1.352],
         [1.598],
         [1.268],
         [1.205],
         [1.394],
         [1.042],
         [1.180],
         [1.785]],

        [[1.004],
         [1.732],
         [1.484],
         [1.882],
         [1.803],
         [0.455],
         [1.486],
         [1.914],
         [1.494],
         [1.242]]], device='cuda:0')
b after update for 1 param tensor([[[ 98.124],
         [ 90.971],
         [108.469],
         [106.516],
         [ 93.503],
         [112.486],
         [107.937],
         [104.216],
         [ 93.634],
         [100.908]],

        [[124.770],
         [119.153],
         [121.305],
         [128.610],
         [116.401],
         [ 98.875],
         [136.960],
         [122.358],
         [134.810],
         [117.340]],

        [[ 97.261],
         [116.260],
         [113.712],
         [105.151],
         [117.510],
         [ 92.005],
         [103.343],
         [ 84.618],
         [100.457],
         [ 96.736]],

        [[ 92.029],
         [102.427],
         [100.787],
         [115.346],
         [ 95.825],
         [104.723],
         [ 96.391],
         [107.701],
         [103.697],
         [112.107]],

        [[138.632],
         [139.760],
         [101.947],
         [138.137],
         [ 95.111],
         [120.280],
         [135.233],
         [100.962],
         [142.878],
         [139.989]],

        [[109.933],
         [ 99.529],
         [119.878],
         [ 98.239],
         [ 90.264],
         [116.923],
         [109.202],
         [107.327],
         [ 99.226],
         [ 92.443]],

        [[113.924],
         [ 79.286],
         [105.185],
         [113.327],
         [115.292],
         [110.705],
         [ 87.959],
         [114.777],
         [112.879],
         [116.858]],

        [[122.355],
         [ 97.509],
         [112.977],
         [114.155],
         [ 75.608],
         [ 75.801],
         [112.169],
         [ 92.410],
         [ 83.986],
         [ 99.177]],

        [[116.987],
         [126.623],
         [117.304],
         [107.216],
         [104.753],
         [107.553],
         [112.036],
         [106.213],
         [104.865],
         [105.190]],

        [[136.039],
         [131.176],
         [135.509],
         [ 85.501],
         [134.548],
         [133.538],
         [132.704],
         [132.636],
         [112.088],
         [ 94.099]],

        [[ 95.466],
         [119.503],
         [ 91.023],
         [ 76.822],
         [100.109],
         [100.150],
         [ 84.444],
         [ 82.235],
         [ 87.263],
         [107.244]],

        [[103.140],
         [101.038],
         [ 99.794],
         [ 88.877],
         [111.611],
         [132.444],
         [120.950],
         [124.658],
         [104.818],
         [117.160]],

        [[123.859],
         [ 85.494],
         [124.369],
         [109.480],
         [122.550],
         [120.358],
         [100.252],
         [117.567],
         [105.549],
         [129.268]],

        [[ 99.837],
         [ 88.051],
         [110.134],
         [113.783],
         [ 93.473],
         [116.578],
         [ 71.989],
         [111.929],
         [ 87.544],
         [103.610]],

        [[110.324],
         [102.564],
         [104.602],
         [122.425],
         [104.799],
         [105.205],
         [115.948],
         [100.602],
         [ 88.299],
         [ 97.586]],

        [[ 79.451],
         [108.391],
         [108.735],
         [118.056],
         [113.750],
         [ 92.221],
         [102.914],
         [ 86.567],
         [112.308],
         [ 92.500]],

        [[ 86.040],
         [ 92.317],
         [107.771],
         [ 89.002],
         [113.524],
         [114.660],
         [108.464],
         [ 78.501],
         [111.258],
         [116.898]],

        [[117.946],
         [112.076],
         [104.684],
         [129.962],
         [116.285],
         [127.194],
         [ 94.385],
         [ 84.526],
         [102.831],
         [ 99.542]],

        [[100.844],
         [106.633],
         [ 95.123],
         [103.427],
         [ 92.109],
         [ 89.811],
         [ 96.589],
         [ 83.500],
         [ 88.861],
         [109.293]],

        [[ 81.983],
         [107.676],
         [ 99.651],
         [112.242],
         [109.846],
         [ 55.200],
         [ 99.745],
         [113.185],
         [100.011],
         [ 91.178]]], device='cuda:0')
clipping threshold 0.4740575156559753
a after update for 1 param tensor([[ 0.065],
        [-3.786],
        [ 0.154],
        [ 0.045],
        [-2.639],
        [-0.070],
        [-0.982],
        [-0.013],
        [ 0.275],
        [ 3.349],
        [ 0.393],
        [ 1.001],
        [ 1.090],
        [ 0.677],
        [ 1.106],
        [ 0.768],
        [-0.978],
        [-0.713],
        [ 0.292],
        [ 0.049]], device='cuda:0')
s after update for 1 param tensor([[1.450],
        [2.411],
        [0.933],
        [1.465],
        [3.005],
        [1.432],
        [1.871],
        [1.123],
        [1.695],
        [2.863],
        [2.005],
        [2.252],
        [1.679],
        [1.871],
        [1.520],
        [2.034],
        [2.155],
        [2.148],
        [2.198],
        [1.483]], device='cuda:0')
b after update for 1 param tensor([[ 98.507],
        [127.035],
        [ 79.009],
        [ 99.008],
        [141.830],
        [ 97.896],
        [111.897],
        [ 86.701],
        [106.519],
        [138.430],
        [115.856],
        [122.763],
        [106.025],
        [111.902],
        [100.873],
        [116.681],
        [120.108],
        [119.898],
        [121.299],
        [ 99.635]], device='cuda:0')
clipping threshold 0.4740575156559753
||w||^2 0.2748013340416083
exp ma of ||w||^2 0.7196278102077281
||w|| 0.5242149693032508
exp ma of ||w|| 0.7790248574681227
||w||^2 0.8521879540020402
exp ma of ||w||^2 0.7613558008445478
||w|| 0.9231402677827678
exp ma of ||w|| 0.8213476238198049
||w||^2 0.6402806674491333
exp ma of ||w||^2 0.7615005397249799
||w|| 0.8001753979279376
exp ma of ||w|| 0.83417655408231
||w||^2 0.585237933098668
exp ma of ||w||^2 0.7474598140861354
||w|| 0.7650084529589644
exp ma of ||w|| 0.8266519277583959
||w||^2 2.0233354402035637
exp ma of ||w||^2 0.8999659703109799
||w|| 1.4224399601401683
exp ma of ||w|| 0.9123428266828373
cuda
Objective function 37.39 = squared loss an data 30.39 + 0.5*rho*h**2 5.388575 + alpha*h 0.000000 + L2reg 1.31 + L1reg 0.29 ; SHD = 137 ; DAG False
Proportion of microbatches that were clipped  0.7703117428525279
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 3.2828569791828244
iteration 1 in outer loop, alpha = 3.2828569791828244, rho = 1.0, h = 3.2828569791828244
cuda
4420
cuda
Objective function 48.16 = squared loss an data 30.39 + 0.5*rho*h**2 5.388575 + alpha*h 10.777150 + L2reg 1.31 + L1reg 0.29 ; SHD = 137 ; DAG False
||w||^2 90898244874.5986
exp ma of ||w||^2 133518678791.3006
||w|| 301493.35792782996
exp ma of ||w|| 280994.95742935344
||w||^2 6948.508699237327
exp ma of ||w||^2 147151775.75170207
||w|| 83.35771529521024
exp ma of ||w|| 2072.5986820557573
||w||^2 3.8014920509383363
exp ma of ||w||^2 3165575.0426850845
||w|| 1.9497415343932991
exp ma of ||w|| 53.47979087028487
||w||^2 1.0289920937879666
exp ma of ||w||^2 1.1250648472078388
||w|| 1.0143924752224687
exp ma of ||w|| 1.0216232930078157
||w||^2 0.881127029170635
exp ma of ||w||^2 1.1203146046683854
||w|| 0.9386836683199697
exp ma of ||w|| 1.0092838870242735
||w||^2 2.1311986730070327
exp ma of ||w||^2 1.4224175860142505
||w|| 1.4598625527792104
exp ma of ||w|| 1.1323116076433803
||w||^2 0.7579694417860624
exp ma of ||w||^2 1.253011022065154
||w|| 0.8706144047660034
exp ma of ||w|| 1.077504086042043
||w||^2 3.340412635749539
exp ma of ||w||^2 1.4573311562451774
||w|| 1.8276795768814453
exp ma of ||w|| 1.1511514079226837
||w||^2 1.778441877496123
exp ma of ||w||^2 1.2180327577912273
||w|| 1.3335823474746968
exp ma of ||w|| 1.0710249793584654
||w||^2 0.7327144528139835
exp ma of ||w||^2 1.2771877664429938
||w|| 0.8559874139343309
exp ma of ||w|| 1.0789390089492537
||w||^2 1.1460233035213283
exp ma of ||w||^2 1.242760357697743
||w|| 1.0705247794989747
exp ma of ||w|| 1.0852436617251544
||w||^2 0.9972053735690416
exp ma of ||w||^2 1.357226915191557
||w|| 0.9986017091759064
exp ma of ||w|| 1.1257622140625716
cuda
Objective function 34.41 = squared loss an data 23.38 + 0.5*rho*h**2 2.166705 + alpha*h 6.833872 + L2reg 1.76 + L1reg 0.27 ; SHD = 96 ; DAG False
Proportion of microbatches that were clipped  0.768541887161117
iteration 1 in inner loop, alpha 3.2828569791828244 rho 1.0 h 2.081684311813291
4420
cuda
Objective function 53.91 = squared loss an data 23.38 + 0.5*rho*h**2 21.667048 + alpha*h 6.833872 + L2reg 1.76 + L1reg 0.27 ; SHD = 96 ; DAG False
||w||^2 1540.6281015269888
exp ma of ||w||^2 44312428.99090734
||w|| 39.25083567934559
exp ma of ||w|| 547.1936998159015
||w||^2 1.9284162844871964
exp ma of ||w||^2 5.397947999121729
||w|| 1.3886742902809126
exp ma of ||w|| 1.4482612295907242
v before min max tensor([[-110.453, -102.777,  173.351,  ...,    5.409, -117.539,  466.226],
        [ -51.082,  -57.851, 1165.581,  ...,  -18.222,  388.627, -122.503],
        [ 219.105,   47.820,  194.823,  ...,  133.621,  -14.575,   30.257],
        ...,
        [ -39.664,  207.356,   55.027,  ...,  246.827,  -58.295,  -71.344],
        [ -18.426,  500.699,  -17.519,  ..., -124.933,  -71.768, -111.461],
        [  -3.538,   49.343,  -81.623,  ...,  -59.031,  -47.618, -107.489]],
       device='cuda:0')
v tensor([[1.000e-12, 1.000e-12, 1.000e+01,  ..., 5.409e+00, 1.000e-12,
         1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e+01,
         1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.000e+01],
        ...,
        [1.000e-12, 1.000e+01, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([ -62.327,  150.986,  -10.592, -123.406,  -95.201,  -55.862,  196.046,
         -80.346,   62.266,   10.181,  119.822,  -68.877,  -94.724,  -33.191,
         -78.513,  -14.914,  548.148, -105.129,  312.333,   20.490,  -46.682,
         139.273,   62.473,  -98.758,  114.177,  -23.060, -114.305,  -74.451,
         194.874,   98.335,  -26.527,  -96.518,   22.828,   25.994,  -71.888,
         -87.221, -129.967,  115.828,  -74.480,  -91.856,  499.445,  -84.974,
        -124.033, -102.706, -101.310, -113.026,    6.687,  -49.337,  235.252,
         -43.098, -102.405,   61.549,   53.043,  -90.040,  -99.783,   43.827,
          42.156, -112.073,  118.742,   83.041,   63.855, -103.357,  -94.178,
        -127.882,  -15.587,  -87.995,  -97.595,  217.046,   59.325,   59.157,
        -125.367,  -63.953,  -28.212,  173.506,  -81.694,  -72.079,   21.900,
         -71.472,  247.334,  108.712, -110.077, -115.402,  199.151,   22.731,
         -86.004,  -47.466,  -78.752,   93.567,  296.206,  389.768, 1472.889,
         172.676,  616.204,  -91.952,   87.673,  199.258,  -93.190,  -69.895,
         194.741,  -64.133, -120.516, -125.526,  -64.359,  843.170,  -79.851,
        -123.188,  101.614,  -11.781,  -12.314,  196.270, -122.778, -109.505,
         -31.575,   25.269,  121.581,  -57.922,  -66.715, -114.021, -120.881,
         576.152, -104.214,  -76.278,   75.025,  573.503, -109.854,  -84.441,
         -96.660,  245.733,  -97.128,   84.776, -130.782, -111.478,  101.906,
         -96.196,  -93.133,  289.327, -106.399, -122.721,  -75.316,  -99.911,
         -29.447,  218.899, -112.186,  -18.109,   13.974,  -87.476, -106.327,
         115.605,  -67.415,  -88.427,  -78.006,  -94.450,  -73.127,  -81.320,
         -23.583,   25.493,  -77.582, -118.444,  428.028,  -71.030,  -28.138,
         158.746,  -74.306,  -99.528,  -87.968, -114.215,  -79.293,   73.116,
         155.500, -137.677, -111.339,  182.274,  -62.947,   -3.548,  -67.679,
         -76.350,  -50.451,  -72.299, -128.520,  -80.472, -129.886, -102.544,
        -104.155,  257.354, -116.181, -102.974,   56.844,  -46.601,  -77.675,
         -81.890, -108.894,  -78.224,  -80.171,   74.542, -131.096,  -41.937,
          15.022, -107.072,   16.633,   -5.486], device='cuda:0')
v tensor([1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 6.687e+00, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12], device='cuda:0')
v before min max tensor([[[ 7.284e+01],
         [-2.621e+01],
         [-2.566e+01],
         [-9.382e+01],
         [-7.808e+01],
         [ 7.191e+01],
         [-1.269e+02],
         [ 2.333e+01],
         [ 3.567e+01],
         [-1.221e+01]],

        [[ 1.871e+01],
         [-5.556e+01],
         [-1.232e+02],
         [ 1.388e+02],
         [-2.089e+01],
         [ 2.018e+01],
         [ 2.042e+01],
         [ 4.333e+02],
         [-7.436e+01],
         [ 1.057e+02]],

        [[ 9.124e+00],
         [-1.019e+02],
         [-7.346e+01],
         [ 1.099e+02],
         [-7.229e+01],
         [-3.124e+00],
         [ 7.390e+00],
         [-1.190e+02],
         [ 2.218e+02],
         [-1.114e+02]],

        [[-9.984e+01],
         [ 2.053e-01],
         [-1.213e+02],
         [-1.019e+02],
         [-7.190e+01],
         [ 9.003e+02],
         [-8.590e+01],
         [ 5.212e+01],
         [-1.218e+02],
         [-1.009e+02]],

        [[-9.086e+01],
         [-1.087e+01],
         [-1.066e+02],
         [-9.347e+01],
         [ 3.237e+00],
         [-2.937e+01],
         [-2.342e+01],
         [-9.267e+01],
         [ 1.221e+03],
         [-5.854e+01]],

        [[-8.542e+01],
         [-5.289e+01],
         [ 4.525e+01],
         [ 3.892e+01],
         [-2.390e+01],
         [-1.085e+02],
         [ 1.051e+02],
         [ 4.455e+02],
         [-8.281e+01],
         [-1.150e+02]],

        [[-2.247e+01],
         [ 1.171e+01],
         [-6.291e+01],
         [-9.387e+01],
         [-3.039e+01],
         [-4.505e+01],
         [-1.248e+02],
         [-7.433e+01],
         [-1.644e+01],
         [-5.056e+01]],

        [[ 6.829e+01],
         [ 9.913e+01],
         [-6.548e+01],
         [-6.901e+01],
         [ 5.262e+01],
         [ 4.830e+02],
         [-4.974e+01],
         [-1.279e+02],
         [-1.158e+02],
         [ 6.066e+02]],

        [[-6.415e+01],
         [-9.697e+01],
         [ 1.543e+02],
         [-9.906e+01],
         [ 1.971e+01],
         [ 6.697e+01],
         [ 2.133e+02],
         [-8.406e+01],
         [-7.766e+01],
         [ 1.650e+02]],

        [[-8.794e+01],
         [-5.663e+01],
         [-1.095e+02],
         [-1.007e+02],
         [ 1.700e+02],
         [ 2.362e+01],
         [ 7.995e+01],
         [-2.008e+01],
         [-1.099e+02],
         [ 8.446e+01]],

        [[-7.891e+01],
         [ 2.136e+02],
         [ 3.872e+02],
         [-1.263e+02],
         [-1.067e+02],
         [-2.261e+01],
         [-8.371e+01],
         [-9.648e+01],
         [-1.277e+02],
         [ 2.035e+02]],

        [[-9.675e+01],
         [ 2.498e+02],
         [-3.303e+01],
         [-1.146e+02],
         [ 2.643e+02],
         [-1.064e+02],
         [ 8.037e+01],
         [-4.452e+01],
         [ 4.256e+01],
         [-9.927e+01]],

        [[-9.055e+01],
         [-3.484e+00],
         [-1.116e+02],
         [-1.062e+02],
         [-1.376e+02],
         [-5.890e+01],
         [-4.873e+01],
         [-7.042e+01],
         [ 4.386e+01],
         [ 2.350e+02]],

        [[-1.000e+02],
         [-9.073e+01],
         [-3.738e+01],
         [-1.391e+02],
         [ 9.082e+01],
         [ 8.889e+00],
         [-1.156e+02],
         [ 3.808e+01],
         [-5.692e+01],
         [-1.041e+02]],

        [[-9.027e+01],
         [ 3.414e+02],
         [-9.285e+01],
         [-1.025e+02],
         [-6.279e+00],
         [-8.294e+01],
         [-6.692e+01],
         [ 1.301e+03],
         [ 2.510e+02],
         [ 6.887e+01]],

        [[-2.595e+01],
         [-1.179e+02],
         [-1.213e+02],
         [ 2.094e+02],
         [ 2.383e+01],
         [ 2.466e+02],
         [ 4.967e+02],
         [-1.054e+02],
         [-8.148e+01],
         [ 1.077e+02]],

        [[-7.310e+01],
         [-1.088e+02],
         [-7.588e+01],
         [ 1.844e+01],
         [ 2.788e+00],
         [-4.828e+01],
         [-9.346e+01],
         [-9.935e+01],
         [ 5.812e+01],
         [-9.939e+01]],

        [[ 1.606e+01],
         [-1.143e+02],
         [-1.966e+01],
         [ 1.956e+02],
         [-1.111e+02],
         [-1.261e+02],
         [-8.404e+01],
         [-5.384e+01],
         [-7.919e+01],
         [ 6.076e+01]],

        [[-9.394e+01],
         [ 2.783e+01],
         [ 8.973e+01],
         [-1.069e+02],
         [-1.045e+02],
         [-3.446e+01],
         [ 6.037e+01],
         [-2.347e+01],
         [-1.129e+02],
         [-2.879e+01]],

        [[-1.144e+02],
         [ 1.137e+02],
         [-8.512e+01],
         [-5.450e+01],
         [-1.117e+02],
         [-5.281e+01],
         [ 2.471e+02],
         [-9.423e+01],
         [-1.121e+02],
         [-1.101e+02]]], device='cuda:0')
v tensor([[[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[9.124e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [7.390e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [2.053e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.237e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [8.889e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [2.788e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[  70.991],
        [-103.791],
        [ -23.454],
        [ -73.097],
        [ 126.519],
        [ 180.029],
        [ -81.664],
        [-107.612],
        [ 103.778],
        [-117.655],
        [ 182.891],
        [ 743.927],
        [  68.694],
        [-116.734],
        [ 487.090],
        [-105.947],
        [ 484.033],
        [ -54.545],
        [ -80.783],
        [ -32.515]], device='cuda:0')
v tensor([[1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 0.027, -0.032, -0.219,  ..., -0.256,  0.058, -0.055],
        [-0.087, -0.277,  0.089,  ...,  0.262,  0.070,  0.073],
        [-0.030,  0.013,  0.069,  ..., -0.042,  0.091,  0.094],
        ...,
        [ 0.015, -0.035, -0.061,  ...,  0.016,  0.124,  0.162],
        [ 0.018,  0.078,  0.106,  ...,  0.021,  0.008,  0.016],
        [ 0.055, -0.045, -0.097,  ..., -0.088,  0.072, -0.013]],
       device='cuda:0')
s after update for 1 param tensor([[1.626, 1.662, 2.024,  ..., 1.756, 1.711, 1.724],
        [1.554, 1.070, 2.072,  ..., 1.366, 1.929, 2.094],
        [1.706, 1.820, 1.703,  ..., 1.874, 1.023, 1.693],
        ...,
        [1.179, 1.726, 2.383,  ..., 1.621, 1.726, 2.094],
        [1.402, 2.259, 1.588,  ..., 2.094, 1.374, 1.667],
        [2.122, 2.026, 1.188,  ..., 1.182, 1.540, 1.565]], device='cuda:0')
b after update for 1 param tensor([[111.887, 113.113, 124.850,  ..., 116.279, 114.766, 115.211],
        [109.380,  90.768, 126.296,  ..., 102.564, 121.877, 126.989],
        [114.619, 118.372, 114.512,  ..., 120.128,  88.764, 114.178],
        ...,
        [ 95.289, 115.270, 135.444,  ..., 111.711, 115.297, 126.967],
        [103.893, 131.885, 110.565,  ..., 126.989, 102.867, 113.291],
        [127.833, 124.909,  95.631,  ...,  95.385, 108.905, 109.775]],
       device='cuda:0')
clipping threshold 1.0815881601389479
a after update for 1 param tensor([-0.087,  0.059,  0.022, -0.049, -0.030, -0.150,  0.182,  0.094,  0.147,
         0.063, -0.018,  0.118,  0.142, -0.117,  0.292,  0.004,  0.124,  0.036,
        -0.008,  0.102,  0.083,  0.177, -0.074,  0.007,  0.002,  0.182, -0.146,
         0.073,  0.165,  0.139, -0.102, -0.062, -0.110, -0.087,  0.062, -0.180,
        -0.059, -0.003, -0.058, -0.095,  0.253, -0.022, -0.312, -0.007,  0.055,
        -0.120,  0.040, -0.039, -0.179,  0.158,  0.031,  0.284, -0.016, -0.154,
        -0.064,  0.171,  0.106, -0.179,  0.074, -0.135, -0.037,  0.105, -0.138,
        -0.264,  0.243,  0.003,  0.247,  0.082, -0.181, -0.004,  0.018, -0.290,
        -0.016, -0.051,  0.191,  0.151,  0.044,  0.099,  0.132,  0.152,  0.001,
        -0.032,  0.073,  0.342, -0.119,  0.067, -0.067, -0.145,  0.186, -0.043,
        -0.073,  0.127, -0.234,  0.074,  0.095,  0.068, -0.137, -0.204, -0.113,
        -0.084, -0.085,  0.096, -0.090,  0.065, -0.159, -0.042, -0.083, -0.082,
        -0.038,  0.302, -0.155,  0.062, -0.231,  0.013,  0.081, -0.095,  0.281,
        -0.096,  0.004, -0.240,  0.174,  0.048,  0.023, -0.044, -0.014, -0.134,
         0.237,  0.083,  0.075,  0.093, -0.006, -0.010, -0.028,  0.110, -0.057,
         0.020,  0.067,  0.008,  0.291,  0.220,  0.055,  0.154,  0.192, -0.081,
        -0.117, -0.025, -0.036,  0.110, -0.017,  0.062,  0.093,  0.048, -0.189,
         0.169, -0.026,  0.083,  0.226,  0.007,  0.146,  0.068,  0.069,  0.098,
         0.158, -0.066,  0.072,  0.265,  0.094,  0.156,  0.119, -0.059, -0.216,
         0.088,  0.197, -0.026,  0.230,  0.164, -0.028,  0.184,  0.047,  0.118,
         0.178,  0.034,  0.094,  0.118,  0.056,  0.079, -0.075,  0.088, -0.065,
        -0.009, -0.030,  0.178, -0.008, -0.130, -0.201, -0.091, -0.216,  0.068,
        -0.048,  0.204], device='cuda:0')
s after update for 1 param tensor([1.293, 1.729, 0.883, 1.802, 1.621, 1.536, 1.880, 2.003, 2.035, 1.758,
        1.184, 1.200, 1.788, 1.604, 1.395, 1.818, 1.744, 1.547, 1.672, 1.541,
        1.672, 1.997, 1.980, 1.550, 2.015, 1.737, 1.667, 1.971, 1.694, 1.850,
        1.083, 1.732, 2.012, 2.191, 1.558, 1.270, 1.960, 1.662, 1.530, 1.393,
        1.883, 1.435, 1.852, 1.851, 1.707, 1.646, 2.311, 1.446, 1.922, 2.044,
        1.851, 1.715, 1.743, 1.545, 1.922, 1.265, 1.679, 1.746, 2.030, 2.049,
        2.236, 1.539, 1.439, 1.933, 1.370, 1.424, 1.447, 1.812, 2.276, 1.804,
        1.825, 1.602, 1.520, 2.100, 1.639, 1.909, 2.089, 1.633, 2.206, 2.259,
        1.805, 1.779, 1.953, 1.964, 1.642, 1.231, 1.399, 2.143, 1.977, 1.969,
        1.960, 1.552, 2.103, 1.489, 1.630, 1.903, 1.510, 1.741, 2.121, 1.207,
        1.757, 1.882, 1.374, 2.184, 1.591, 1.900, 1.968, 1.733, 1.716, 2.066,
        1.790, 1.602, 1.758, 1.514, 2.056, 0.850, 1.626, 1.690, 2.260, 2.303,
        1.561, 1.172, 1.973, 2.463, 1.600, 1.448, 1.786, 2.067, 2.023, 2.084,
        1.917, 1.630, 2.001, 1.753, 1.358, 2.183, 1.925, 1.789, 1.104, 2.086,
        1.744, 1.846, 1.633, 1.505, 1.984, 1.273, 1.553, 2.161, 1.034, 1.416,
        1.555, 1.403, 1.279, 1.327, 1.495, 1.803, 1.763, 1.768, 2.051, 1.545,
        1.546, 1.920, 1.780, 1.708, 1.837, 1.885, 1.595, 1.678, 2.253, 2.023,
        1.661, 1.736, 1.086, 1.786, 1.346, 1.876, 1.717, 1.506, 1.887, 1.500,
        1.976, 1.999, 1.616, 1.634, 1.884, 1.522, 1.682, 1.493, 1.298, 1.279,
        1.588, 1.622, 1.264, 2.153, 1.935, 2.050, 2.145, 1.650, 1.391, 1.961],
       device='cuda:0')
b after update for 1 param tensor([ 99.779, 115.391,  82.468, 117.791, 111.729, 108.764, 120.304, 124.187,
        125.165, 116.334,  95.462,  96.121, 117.330, 111.148, 103.636, 118.329,
        115.864, 109.123, 113.446, 108.916, 113.457, 124.005, 123.463, 109.261,
        124.572, 115.661, 113.292, 123.204, 114.212, 119.335,  91.311, 115.495,
        124.457, 129.884, 109.521,  98.881, 122.848, 113.130, 108.541, 103.549,
        120.418, 105.123, 119.405, 119.382, 114.631, 112.578, 133.383, 105.513,
        121.638, 125.465, 119.366, 114.912, 115.833, 109.054, 121.648,  98.682,
        113.696, 115.945, 125.017, 125.608, 131.221, 108.860, 105.256, 121.991,
        102.690, 104.702, 105.557, 118.106, 132.377, 117.843, 118.539, 111.062,
        108.173, 127.156, 112.334, 121.252, 126.831, 112.137, 130.334, 131.892,
        117.886, 117.024, 122.640, 122.969, 112.448,  97.364, 103.780, 128.454,
        123.374, 123.129, 122.860, 109.312, 127.244, 107.085, 112.028, 121.062,
        107.844, 115.795, 127.802,  96.394, 116.310, 120.366, 102.838, 129.683,
        110.665, 120.952, 123.095, 115.527, 114.958, 126.138, 117.396, 111.069,
        116.333, 107.968, 125.826,  80.905, 111.903, 114.061, 131.918, 133.162,
        109.629,  95.006, 123.267, 137.724, 111.003, 105.596, 117.278, 126.168,
        124.803, 126.677, 121.497, 112.039, 124.123, 116.178, 102.253, 129.654,
        121.745, 117.362,  92.207, 126.721, 115.893, 119.236, 112.132, 107.665,
        123.597,  99.006, 109.343, 128.985,  89.223, 104.405, 109.434, 103.928,
         99.218, 101.082, 107.281, 117.815, 116.509, 116.671, 125.666, 109.060,
        109.090, 121.598, 117.071, 114.685, 118.919, 120.459, 110.809, 113.679,
        131.701, 124.819, 113.096, 115.628,  91.430, 117.280, 101.786, 120.196,
        114.981, 107.667, 120.526, 107.452, 123.343, 124.064, 111.561, 112.157,
        120.431, 108.242, 113.813, 107.204,  99.955,  99.223, 110.566, 111.758,
         98.660, 128.739, 122.050, 125.643, 128.511, 112.722, 103.499, 122.883],
       device='cuda:0')
clipping threshold 1.0815881601389479
a after update for 1 param tensor([[[-7.156e-02],
         [-1.234e-01],
         [-1.448e-02],
         [ 3.475e-01],
         [ 1.643e-02],
         [-1.566e-01],
         [ 1.311e-01],
         [-1.444e-01],
         [-4.070e-02],
         [-2.722e-01]],

        [[-1.927e-01],
         [-6.310e-02],
         [-1.745e-01],
         [-2.760e-01],
         [ 2.987e-01],
         [ 2.168e-01],
         [-8.869e-02],
         [ 1.231e-01],
         [ 4.066e-02],
         [ 1.848e-01]],

        [[ 9.510e-03],
         [ 1.008e-02],
         [ 5.044e-02],
         [-3.090e-01],
         [ 1.760e-02],
         [ 1.181e-01],
         [ 2.160e-01],
         [-4.422e-02],
         [ 5.895e-02],
         [-1.846e-01]],

        [[ 1.218e-02],
         [-1.236e-01],
         [ 4.257e-02],
         [ 5.576e-03],
         [ 6.213e-02],
         [ 5.268e-02],
         [ 8.658e-02],
         [-1.059e-01],
         [-1.581e-01],
         [-7.656e-02]],

        [[-1.042e-01],
         [ 4.038e-01],
         [-6.761e-02],
         [ 1.373e-01],
         [-1.526e-03],
         [ 1.479e-01],
         [ 1.247e-01],
         [-3.062e-02],
         [-1.644e-01],
         [-6.767e-02]],

        [[-1.734e-02],
         [ 5.851e-02],
         [-3.791e-02],
         [ 8.247e-02],
         [-2.755e-01],
         [ 4.753e-02],
         [-1.471e-01],
         [ 3.628e-02],
         [ 3.553e-02],
         [ 4.022e-02]],

        [[-2.927e-01],
         [-3.621e-02],
         [-3.134e-02],
         [ 2.230e-02],
         [-7.200e-02],
         [-1.324e-02],
         [ 1.596e-01],
         [-1.353e-01],
         [ 3.135e-01],
         [-5.565e-02]],

        [[ 1.600e-01],
         [-3.588e-02],
         [ 1.265e-01],
         [ 2.755e-02],
         [ 1.289e-01],
         [ 2.704e-02],
         [-8.836e-02],
         [ 5.284e-03],
         [-8.317e-02],
         [-1.536e-01]],

        [[-1.335e-01],
         [ 1.070e-01],
         [-1.717e-01],
         [-3.446e-02],
         [ 8.919e-02],
         [ 4.268e-02],
         [ 3.488e-01],
         [-6.211e-02],
         [-2.630e-02],
         [-6.827e-02]],

        [[ 3.424e-02],
         [-4.614e-02],
         [ 1.312e-01],
         [ 1.753e-01],
         [ 9.702e-03],
         [ 5.280e-02],
         [ 6.276e-02],
         [ 5.069e-02],
         [ 6.599e-02],
         [ 1.682e-01]],

        [[-1.476e-01],
         [ 6.435e-02],
         [-8.670e-03],
         [-1.221e-01],
         [-3.581e-02],
         [ 1.560e-04],
         [ 1.178e-01],
         [ 2.570e-01],
         [ 2.063e-01],
         [-1.408e-01]],

        [[ 2.193e-02],
         [ 1.022e-01],
         [-2.378e-02],
         [ 8.765e-02],
         [ 3.746e-02],
         [ 6.062e-02],
         [-4.641e-01],
         [ 1.101e-01],
         [-1.473e-01],
         [-3.039e-02]],

        [[-1.713e-01],
         [ 6.496e-02],
         [-4.497e-02],
         [ 1.021e-01],
         [ 1.206e-01],
         [-3.228e-01],
         [-1.535e-03],
         [-9.807e-02],
         [ 2.151e-01],
         [-1.014e-01]],

        [[-9.382e-02],
         [ 9.571e-02],
         [ 3.315e-02],
         [-2.697e-01],
         [ 8.256e-02],
         [ 2.237e-01],
         [-1.784e-01],
         [-1.005e-01],
         [ 1.138e-01],
         [-1.863e-01]],

        [[ 7.842e-02],
         [-1.583e-01],
         [ 1.653e-01],
         [-9.784e-03],
         [ 1.663e-01],
         [ 6.157e-02],
         [-3.023e-01],
         [-2.890e-02],
         [ 6.596e-02],
         [ 2.872e-01]],

        [[-1.940e-02],
         [ 4.980e-02],
         [ 7.573e-02],
         [ 9.135e-02],
         [-1.851e-01],
         [-3.595e-01],
         [ 2.228e-01],
         [ 4.336e-02],
         [ 7.623e-03],
         [ 2.781e-01]],

        [[-2.343e-02],
         [ 3.859e-03],
         [-9.934e-02],
         [-2.064e-02],
         [-1.206e-01],
         [ 2.663e-02],
         [-1.380e-01],
         [ 1.396e-01],
         [-2.366e-02],
         [ 4.501e-03]],

        [[-2.153e-01],
         [ 2.172e-01],
         [-1.012e-01],
         [-3.363e-02],
         [ 1.836e-01],
         [ 1.310e-01],
         [ 1.033e-01],
         [ 2.393e-01],
         [-3.176e-02],
         [ 3.540e-01]],

        [[ 1.453e-01],
         [-2.068e-02],
         [-6.860e-02],
         [-7.288e-02],
         [-1.505e-01],
         [ 2.148e-01],
         [ 1.526e-01],
         [-1.109e-01],
         [-1.098e-01],
         [-1.006e-02]],

        [[-1.583e-01],
         [ 3.124e-02],
         [ 9.206e-02],
         [-4.364e-03],
         [ 5.138e-01],
         [ 5.649e-02],
         [ 3.966e-02],
         [ 1.100e-01],
         [ 2.569e-02],
         [ 8.393e-02]]], device='cuda:0')
s after update for 1 param tensor([[[2.050],
         [1.532],
         [1.839],
         [1.483],
         [1.704],
         [2.076],
         [1.922],
         [2.325],
         [2.028],
         [1.511]],

        [[1.661],
         [2.046],
         [1.794],
         [2.015],
         [1.400],
         [1.777],
         [1.501],
         [1.448],
         [1.754],
         [2.466]],

        [[2.116],
         [1.603],
         [1.847],
         [1.963],
         [1.052],
         [1.472],
         [1.680],
         [1.750],
         [1.804],
         [1.669]],

        [[1.572],
         [1.299],
         [1.813],
         [1.723],
         [1.292],
         [2.189],
         [1.466],
         [1.552],
         [1.941],
         [1.544]],

        [[2.202],
         [1.856],
         [1.558],
         [1.802],
         [1.578],
         [1.789],
         [1.424],
         [1.563],
         [2.125],
         [1.577]],

        [[1.816],
         [1.080],
         [1.953],
         [1.915],
         [2.197],
         [1.581],
         [1.464],
         [1.762],
         [1.523],
         [1.695]],

        [[1.047],
         [1.785],
         [0.928],
         [1.541],
         [1.512],
         [1.736],
         [1.842],
         [1.465],
         [1.510],
         [1.082]],

        [[2.336],
         [1.644],
         [1.496],
         [1.643],
         [2.070],
         [1.856],
         [1.382],
         [1.946],
         [1.769],
         [2.026]],

        [[1.025],
         [1.920],
         [1.878],
         [1.488],
         [2.264],
         [1.815],
         [1.716],
         [2.185],
         [1.142],
         [1.960]],

        [[1.312],
         [1.330],
         [1.616],
         [1.504],
         [1.894],
         [1.863],
         [2.249],
         [1.264],
         [1.760],
         [1.774]],

        [[2.161],
         [1.338],
         [2.173],
         [1.929],
         [1.661],
         [1.733],
         [1.307],
         [1.966],
         [2.022],
         [2.280]],

        [[1.463],
         [1.718],
         [1.735],
         [1.699],
         [2.088],
         [1.771],
         [1.701],
         [1.355],
         [1.819],
         [1.666]],

        [[2.007],
         [1.770],
         [1.663],
         [1.564],
         [2.013],
         [1.386],
         [1.065],
         [1.949],
         [1.812],
         [1.967]],

        [[1.613],
         [1.980],
         [1.822],
         [2.051],
         [1.737],
         [1.486],
         [2.031],
         [1.883],
         [1.555],
         [1.515]],

        [[1.331],
         [1.541],
         [1.538],
         [1.658],
         [1.935],
         [1.258],
         [1.138],
         [2.088],
         [2.202],
         [1.852]],

        [[1.592],
         [1.865],
         [1.771],
         [1.856],
         [2.152],
         [1.512],
         [1.961],
         [1.804],
         [1.618],
         [1.650]],

        [[1.484],
         [1.744],
         [1.731],
         [1.834],
         [1.958],
         [1.513],
         [1.372],
         [1.579],
         [2.204],
         [1.567]],

        [[1.991],
         [1.745],
         [1.620],
         [2.087],
         [1.959],
         [1.854],
         [1.265],
         [1.808],
         [1.760],
         [1.777]],

        [[1.794],
         [2.104],
         [2.242],
         [1.559],
         [1.539],
         [1.770],
         [1.651],
         [1.663],
         [1.769],
         [2.014]],

        [[1.748],
         [1.937],
         [2.188],
         [2.042],
         [2.216],
         [1.423],
         [2.053],
         [1.511],
         [1.724],
         [1.767]]], device='cuda:0')
b after update for 1 param tensor([[[125.645],
         [108.625],
         [118.983],
         [106.876],
         [114.552],
         [126.437],
         [121.644],
         [133.794],
         [124.958],
         [107.849]],

        [[113.090],
         [125.505],
         [117.543],
         [124.549],
         [103.820],
         [116.957],
         [107.521],
         [105.598],
         [116.219],
         [137.797]],

        [[127.634],
         [111.092],
         [119.260],
         [122.940],
         [ 90.003],
         [106.468],
         [113.742],
         [116.064],
         [117.851],
         [113.351]],

        [[110.016],
         [100.027],
         [118.150],
         [115.184],
         [ 99.720],
         [129.832],
         [106.256],
         [109.317],
         [122.257],
         [109.016]],

        [[130.202],
         [119.545],
         [109.534],
         [117.786],
         [110.230],
         [117.351],
         [104.701],
         [109.712],
         [127.906],
         [110.190]],

        [[118.255],
         [ 91.197],
         [122.622],
         [121.430],
         [130.062],
         [110.320],
         [106.179],
         [116.463],
         [108.301],
         [114.239]],

        [[ 89.807],
         [117.223],
         [ 84.521],
         [108.928],
         [107.896],
         [115.611],
         [119.087],
         [106.212],
         [107.844],
         [ 91.265]],

        [[134.128],
         [112.497],
         [107.309],
         [112.490],
         [126.251],
         [119.557],
         [103.159],
         [122.396],
         [116.705],
         [124.885]],

        [[ 88.827],
         [121.574],
         [120.241],
         [107.041],
         [132.037],
         [118.215],
         [114.944],
         [129.696],
         [ 93.755],
         [122.843]],

        [[100.504],
         [101.192],
         [111.547],
         [107.599],
         [120.775],
         [119.760],
         [131.600],
         [ 98.654],
         [116.403],
         [116.868]],

        [[128.982],
         [101.485],
         [129.363],
         [121.870],
         [113.091],
         [115.509],
         [100.303],
         [123.024],
         [124.784],
         [132.493]],

        [[106.135],
         [114.998],
         [115.580],
         [114.363],
         [126.782],
         [116.761],
         [114.456],
         [102.148],
         [118.343],
         [113.255]],

        [[124.320],
         [116.739],
         [113.172],
         [109.746],
         [124.501],
         [103.309],
         [ 90.572],
         [122.500],
         [118.113],
         [123.067]],

        [[111.438],
         [123.458],
         [118.442],
         [125.665],
         [115.631],
         [106.979],
         [125.039],
         [120.420],
         [109.419],
         [108.002]],

        [[101.237],
         [108.945],
         [108.823],
         [112.973],
         [122.049],
         [ 98.401],
         [ 93.621],
         [126.802],
         [130.217],
         [119.426]],

        [[110.716],
         [119.843],
         [116.762],
         [119.541],
         [128.724],
         [107.900],
         [122.876],
         [117.866],
         [111.621],
         [112.713]],

        [[106.880],
         [115.882],
         [115.458],
         [118.817],
         [122.787],
         [107.937],
         [102.766],
         [110.250],
         [130.268],
         [109.835]],

        [[123.804],
         [115.929],
         [111.687],
         [126.750],
         [122.803],
         [119.471],
         [ 98.685],
         [117.980],
         [116.425],
         [116.986]],

        [[117.535],
         [127.282],
         [131.388],
         [109.552],
         [108.859],
         [116.740],
         [112.762],
         [113.151],
         [116.714],
         [124.523]],

        [[116.007],
         [122.136],
         [129.803],
         [125.393],
         [130.622],
         [104.658],
         [125.715],
         [107.846],
         [115.204],
         [116.646]]], device='cuda:0')
clipping threshold 1.0815881601389479
a after update for 1 param tensor([[ 0.014],
        [ 0.003],
        [ 0.092],
        [ 0.025],
        [ 0.087],
        [-0.195],
        [ 0.111],
        [-0.070],
        [-0.064],
        [-0.026],
        [-0.033],
        [ 0.353],
        [ 0.064],
        [-0.058],
        [-0.217],
        [-0.117],
        [-0.132],
        [-0.007],
        [-0.361],
        [ 0.012]], device='cuda:0')
s after update for 1 param tensor([[2.273],
        [1.522],
        [1.126],
        [1.485],
        [1.948],
        [2.007],
        [1.442],
        [1.886],
        [1.934],
        [1.804],
        [2.112],
        [2.200],
        [1.899],
        [1.795],
        [2.133],
        [1.780],
        [2.052],
        [1.273],
        [1.583],
        [1.438]], device='cuda:0')
b after update for 1 param tensor([[132.301],
        [108.256],
        [ 93.123],
        [106.931],
        [122.482],
        [124.302],
        [105.358],
        [120.491],
        [122.028],
        [117.843],
        [127.515],
        [130.159],
        [120.936],
        [117.549],
        [128.150],
        [117.055],
        [125.686],
        [ 99.009],
        [110.396],
        [105.219]], device='cuda:0')
clipping threshold 1.0815881601389479
||w||^2 1.2552474614420186
exp ma of ||w||^2 2.31739829755062
||w|| 1.1203782671232152
exp ma of ||w|| 1.4382979675479108
||w||^2 1.6547115994012898
exp ma of ||w||^2 2.0773800796633974
||w|| 1.2863559380674112
exp ma of ||w|| 1.3904837409231148
v before min max tensor([[ -61.840,   35.423,   72.804,  ...,  403.674,  140.910,  -91.645],
        [ -76.347,  378.156, -110.616,  ..., -118.231,  -73.304,  -92.852],
        [ -84.207, -120.653,  474.868,  ...,  -98.420,  -49.089,  -46.525],
        ...,
        [-102.032, -113.210,  -54.892,  ..., -143.980,  -49.264, -156.969],
        [   7.894,  538.410,  -58.388,  ...,   60.403,  -17.453,   -5.535],
        [ 193.817, -127.453,  -68.876,  ...,  -64.380, -121.585,  -66.710]],
       device='cuda:0')
v tensor([[1.000e-12, 1.000e+01, 1.000e+01,  ..., 1.000e+01, 1.000e+01,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [7.894e+00, 1.000e+01, 1.000e-12,  ..., 1.000e+01, 1.000e-12,
         1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([ 8.109e+01, -1.060e+02, -1.364e+02, -9.420e+01, -1.013e+02,  7.550e+01,
        -1.078e+02, -9.187e+01,  9.588e+01, -1.423e+02, -7.599e+01, -1.516e+02,
        -1.968e+01, -3.701e+01, -1.055e+02, -1.405e+02, -5.020e+01, -6.093e+01,
        -1.145e+02,  1.059e+02,  4.028e+02, -5.363e+01, -1.117e+02, -3.074e+01,
        -4.110e+01, -9.110e+01,  4.536e+01, -1.159e+02,  2.431e+03, -9.159e+01,
        -1.029e+02, -3.230e+01,  3.685e+02, -1.229e+02, -7.839e+01, -1.338e+02,
        -8.922e+01, -9.508e+01, -7.314e+01, -1.136e+02, -1.565e+02, -1.126e+02,
        -1.226e+02, -8.918e+01, -5.747e+01, -1.375e+02, -1.217e+02, -1.059e+02,
         2.440e+01,  2.822e+01, -2.528e+01, -1.345e+02,  6.569e+02, -6.835e+01,
        -1.025e+02, -4.787e+01, -3.553e+00, -1.124e+02, -9.741e+01, -4.757e+01,
        -4.953e+01,  8.400e+00, -1.006e+02,  2.051e+02, -5.798e+01, -1.224e+02,
        -1.121e+02,  1.687e+02, -3.949e+00, -1.185e+02, -1.161e+02, -6.761e+01,
        -1.217e+02,  1.370e+02, -8.304e+01, -8.084e+01,  2.228e+02, -1.009e+02,
         9.567e+01,  4.692e+01,  1.500e+01, -1.143e+02,  1.305e+01, -7.345e+01,
        -8.885e+01, -9.934e+01,  1.123e+02, -1.226e+02, -1.285e+02, -1.097e+02,
        -1.101e+02, -3.983e+01, -1.177e+02,  1.081e+02,  2.059e+02, -9.263e+01,
        -3.629e+01,  2.523e+02, -4.527e+01, -2.317e+01, -1.320e+02, -1.084e+02,
        -8.544e+01,  2.262e+02, -8.464e+01, -5.919e+00, -1.173e+02, -4.794e+00,
        -1.188e+02, -8.195e+01, -2.585e+01, -5.038e+01, -1.031e+02,  2.992e+02,
        -1.180e+02,  1.252e+02, -4.185e+01,  5.167e+01, -1.440e+02, -1.116e+02,
        -1.047e+02,  3.933e+01,  2.319e+02, -8.778e+01,  4.170e+02,  7.689e+01,
        -8.996e+01, -4.973e+01, -1.284e+02,  5.976e+01, -5.934e+01,  3.508e+01,
         1.435e+02, -7.468e+01, -6.661e-01, -1.051e+02, -1.261e+02,  3.548e+01,
         2.810e+01, -1.038e+02, -8.394e+01, -1.122e+02,  1.078e+02, -1.468e+02,
        -1.435e+02,  5.375e+01, -1.252e+02, -4.167e+01, -8.054e+01, -1.188e+02,
        -6.804e+01, -8.375e+01, -3.516e+01,  4.820e+02, -6.241e+01,  1.709e+02,
        -1.003e+02, -9.301e+01, -1.253e+02, -7.286e+01, -1.075e+02, -1.154e+02,
         1.239e+02, -7.707e+01,  7.032e+00, -1.023e+02, -8.942e+01,  1.366e+01,
        -3.453e+01, -9.694e+01, -1.253e+02, -7.691e+01,  3.252e+01, -6.448e+01,
        -6.585e+01,  8.663e+01, -1.034e+02, -8.929e+01, -2.688e+01,  3.096e+01,
         4.679e+01, -6.530e+01, -1.303e+02, -1.774e+01, -1.437e+02,  1.817e+02,
        -6.772e+01,  7.030e+02, -1.247e+02, -1.116e+02, -1.160e+02, -8.486e+01,
         1.233e+02, -1.016e+02, -1.248e+02, -1.040e+02, -1.399e+02, -1.290e+02,
        -1.326e+02, -1.867e+01], device='cuda:0')
v tensor([1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 8.400e+00, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 7.032e+00, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12], device='cuda:0')
v before min max tensor([[[-150.390],
         [ -85.961],
         [  67.568],
         [ -97.612],
         [ -80.115],
         [-130.239],
         [-125.928],
         [ -70.140],
         [   5.041],
         [  60.116]],

        [[  69.060],
         [ 307.928],
         [ -63.192],
         [ -65.622],
         [ 311.312],
         [ 347.461],
         [-140.403],
         [ -82.345],
         [-110.763],
         [ 185.112]],

        [[  90.391],
         [-105.002],
         [-133.205],
         [  34.863],
         [  37.830],
         [-136.035],
         [ -10.936],
         [ 171.543],
         [-106.137],
         [  87.447]],

        [[-100.543],
         [ -19.805],
         [  68.841],
         [  70.755],
         [-153.781],
         [ -80.292],
         [ -99.241],
         [ -95.362],
         [ 364.043],
         [-109.055]],

        [[-136.757],
         [-118.536],
         [ -81.066],
         [ -27.847],
         [ -50.142],
         [ -25.307],
         [-113.056],
         [-102.405],
         [ -35.929],
         [ -80.465]],

        [[ -97.750],
         [ 117.834],
         [ -82.220],
         [  72.234],
         [-140.958],
         [ -94.266],
         [ -64.015],
         [ 252.665],
         [ 303.898],
         [ -57.787]],

        [[  96.205],
         [ -96.948],
         [ -19.164],
         [ 173.549],
         [ -98.273],
         [ -96.463],
         [-103.938],
         [ 196.690],
         [   5.526],
         [ -71.570]],

        [[  95.707],
         [ 148.356],
         [ 267.557],
         [-125.744],
         [-120.915],
         [ 153.182],
         [ 163.840],
         [ 103.367],
         [ 179.843],
         [-129.915]],

        [[-107.707],
         [ -15.744],
         [ 147.021],
         [ -79.304],
         [ 375.394],
         [ -53.001],
         [ -55.505],
         [ -91.489],
         [ -82.677],
         [-100.175]],

        [[-120.844],
         [-104.611],
         [ -62.376],
         [   4.280],
         [ -46.408],
         [ -40.990],
         [ -37.544],
         [-128.720],
         [  32.655],
         [ -95.086]],

        [[-110.054],
         [ -42.832],
         [  37.937],
         [ -73.383],
         [ -95.765],
         [ -86.367],
         [ -81.055],
         [-141.229],
         [ -70.451],
         [-115.818]],

        [[-116.449],
         [ -80.979],
         [ -65.958],
         [ 157.733],
         [ -60.921],
         [ 111.117],
         [-154.369],
         [-111.888],
         [   2.572],
         [ -16.188]],

        [[  41.315],
         [ -59.301],
         [  -6.100],
         [-142.047],
         [ 132.827],
         [ -82.581],
         [   7.401],
         [ -64.357],
         [ -82.460],
         [  12.781]],

        [[  69.337],
         [ 287.067],
         [-129.618],
         [  39.658],
         [ 563.931],
         [-135.571],
         [-103.277],
         [ 307.807],
         [ -82.320],
         [ 277.351]],

        [[ -72.323],
         [ -88.318],
         [-126.083],
         [ -59.943],
         [ -91.605],
         [ -27.210],
         [ -20.692],
         [ -14.534],
         [  21.947],
         [ -66.490]],

        [[ -54.016],
         [   6.524],
         [   6.878],
         [-121.282],
         [ -57.753],
         [ -95.255],
         [ -85.796],
         [-106.872],
         [ -96.281],
         [ 211.842]],

        [[ -96.646],
         [-115.341],
         [-119.170],
         [-126.208],
         [  -0.590],
         [ -36.789],
         [-151.060],
         [-102.711],
         [ 300.270],
         [ -25.207]],

        [[  58.305],
         [-126.367],
         [-143.822],
         [ -68.118],
         [-127.553],
         [ 203.153],
         [-120.184],
         [-112.643],
         [ -68.899],
         [-138.470]],

        [[-128.475],
         [  90.431],
         [ -65.539],
         [ -97.006],
         [ -10.781],
         [ -74.794],
         [  77.266],
         [ -72.354],
         [  36.001],
         [  84.859]],

        [[ -30.829],
         [ -90.485],
         [ -93.630],
         [-111.873],
         [ 297.970],
         [  77.124],
         [ -70.369],
         [ -79.265],
         [ -76.074],
         [ -80.114]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.041e+00],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [5.526e+00],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.280e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [2.572e+00],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [7.401e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [6.524e+00],
         [6.878e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[ -31.341],
        [ 123.234],
        [ 389.567],
        [-121.424],
        [ -41.761],
        [ -85.878],
        [ -21.959],
        [ -39.195],
        [ -66.334],
        [ -80.480],
        [ -48.371],
        [ -61.954],
        [ 255.222],
        [ -44.591],
        [ -74.124],
        [-160.002],
        [ -99.961],
        [-142.392],
        [ -75.383],
        [-136.821]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 9.587e-03, -9.157e-02, -2.518e-01,  ..., -2.079e-01,  7.127e-02,
         -8.790e-02],
        [-1.288e-01, -1.619e-01, -5.228e-02,  ...,  1.564e-01,  1.294e-01,
          5.828e-02],
        [ 9.618e-03, -8.804e-02,  2.287e-02,  ..., -9.000e-02,  9.523e-02,
          1.050e-02],
        ...,
        [-6.381e-02, -8.479e-02, -6.996e-02,  ...,  5.148e-02,  9.705e-02,
          9.656e-02],
        [ 3.809e-02,  1.206e-02,  1.481e-01,  ..., -1.187e-01, -1.436e-02,
          2.075e-04],
        [ 9.485e-03, -5.365e-02, -2.539e-02,  ..., -3.657e-02, -1.118e-01,
         -4.514e-03]], device='cuda:0')
s after update for 1 param tensor([[1.640, 1.314, 1.535,  ..., 2.089, 1.575, 1.341],
        [1.608, 1.783, 2.130,  ..., 1.989, 1.662, 2.073],
        [1.962, 1.962, 2.016,  ..., 1.363, 0.994, 1.291],
        ...,
        [1.360, 1.597, 1.554,  ..., 1.997, 1.450, 2.097],
        [1.941, 1.934, 1.722,  ..., 1.825, 1.270, 1.559],
        [2.289, 1.736, 1.613,  ..., 0.871, 1.587, 1.759]], device='cuda:0')
b after update for 1 param tensor([[110.258,  98.698, 106.667,  ..., 124.416, 108.052,  99.675],
        [109.158, 114.967, 125.627,  ..., 121.404, 110.971, 123.943],
        [120.589, 120.589, 122.232,  ..., 100.508,  85.831,  97.813],
        ...,
        [100.384, 108.786, 107.304,  ..., 121.667, 103.648, 124.661],
        [119.944, 119.721, 112.953,  ..., 116.311,  97.014, 107.480],
        [130.240, 113.430, 109.342,  ...,  80.325, 108.451, 114.167]],
       device='cuda:0')
clipping threshold 1.1609161885824602
a after update for 1 param tensor([-0.043,  0.069,  0.013, -0.070,  0.062, -0.208,  0.182,  0.052,  0.109,
         0.024, -0.011,  0.098,  0.201, -0.165,  0.187,  0.050,  0.101,  0.063,
        -0.008,  0.011,  0.111,  0.125, -0.118,  0.003,  0.104,  0.259, -0.110,
         0.123,  0.172,  0.033, -0.148, -0.112, -0.039, -0.104, -0.046, -0.187,
        -0.036, -0.017, -0.096, -0.034,  0.129,  0.001, -0.226, -0.004,  0.126,
        -0.129,  0.079,  0.086, -0.202,  0.094, -0.003,  0.160,  0.013, -0.168,
        -0.127,  0.107,  0.134, -0.040, -0.010, -0.190, -0.120,  0.118, -0.151,
        -0.202,  0.233, -0.087,  0.151,  0.121, -0.115, -0.007,  0.131, -0.313,
        -0.009, -0.007,  0.102,  0.034, -0.043,  0.067, -0.040,  0.164,  0.089,
        -0.056,  0.097,  0.320, -0.183, -0.049,  0.020,  0.017,  0.143, -0.093,
        -0.120,  0.104, -0.239,  0.068, -0.056,  0.103, -0.075, -0.112, -0.067,
        -0.177, -0.167,  0.104, -0.197,  0.010, -0.053, -0.039, -0.168, -0.004,
         0.042,  0.319, -0.125,  0.017, -0.161, -0.076,  0.120, -0.091,  0.211,
        -0.093,  0.097, -0.209,  0.062, -0.014,  0.009, -0.006,  0.049, -0.027,
         0.331,  0.021,  0.008, -0.036, -0.025,  0.059, -0.101,  0.099,  0.002,
         0.047, -0.029, -0.068,  0.256,  0.182,  0.140,  0.051,  0.188,  0.067,
         0.069, -0.001, -0.136,  0.096,  0.008,  0.078,  0.026,  0.045, -0.240,
         0.035, -0.103,  0.087,  0.175, -0.035,  0.142,  0.159,  0.081,  0.057,
         0.209, -0.088,  0.011,  0.131,  0.049,  0.047,  0.119, -0.016, -0.233,
         0.134,  0.161, -0.009,  0.212,  0.136, -0.067,  0.199, -0.105,  0.059,
         0.253,  0.167, -0.017,  0.118,  0.059,  0.057,  0.039,  0.007, -0.000,
        -0.065, -0.088,  0.290,  0.116, -0.135, -0.239, -0.123, -0.089,  0.027,
        -0.074,  0.165], device='cuda:0')
s after update for 1 param tensor([1.740, 1.644, 1.778, 1.452, 1.318, 1.592, 1.822, 2.161, 1.679, 1.859,
        1.105, 2.020, 1.853, 1.287, 1.458, 2.076, 1.892, 1.592, 1.963, 1.779,
        1.932, 1.519, 1.550, 1.898, 1.221, 1.770, 1.751, 1.516, 2.100, 1.691,
        1.420, 1.280, 1.906, 1.855, 1.940, 1.804, 1.246, 1.310, 1.779, 1.570,
        2.047, 1.798, 1.647, 1.631, 1.146, 1.819, 1.801, 1.503, 1.649, 1.882,
        1.323, 1.806, 2.068, 1.440, 1.338, 1.428, 1.706, 1.464, 1.269, 1.136,
        1.562, 1.690, 1.309, 1.785, 1.529, 1.749, 1.525, 2.443, 1.155, 1.940,
        1.656, 1.838, 1.589, 1.663, 1.585, 1.091, 1.476, 1.868, 2.336, 2.260,
        1.838, 1.831, 1.926, 1.583, 1.605, 1.616, 2.104, 1.608, 1.772, 1.584,
        1.462, 0.893, 1.723, 1.897, 1.888, 1.394, 1.891, 1.854, 1.567, 1.301,
        2.044, 1.573, 1.696, 1.670, 1.752, 1.370, 1.728, 1.599, 1.545, 1.993,
        1.088, 1.503, 1.838, 2.076, 1.765, 1.711, 1.664, 2.231, 1.921, 1.572,
        1.477, 1.511, 1.680, 1.286, 2.042, 1.889, 1.399, 2.021, 1.680, 1.936,
        1.248, 2.032, 1.567, 1.892, 1.539, 1.645, 1.641, 2.237, 2.015, 1.732,
        1.631, 1.484, 1.490, 2.384, 2.112, 2.117, 1.747, 1.688, 1.162, 1.751,
        1.331, 1.150, 1.424, 2.045, 1.660, 1.686, 1.387, 1.272, 2.042, 1.904,
        1.496, 1.549, 2.105, 1.247, 1.389, 1.640, 1.291, 1.915, 1.647, 1.474,
        1.807, 1.309, 1.667, 1.096, 1.314, 2.002, 1.674, 1.507, 1.479, 1.682,
        2.116, 2.117, 1.700, 1.911, 1.899, 2.088, 1.017, 1.853, 1.637, 1.505,
        1.669, 1.704, 1.666, 1.445, 1.658, 1.365, 1.823, 1.681, 1.780, 1.112],
       device='cuda:0')
b after update for 1 param tensor([113.550, 110.391, 114.806, 103.726,  98.817, 108.621, 116.203, 126.538,
        111.563, 117.383,  90.513, 122.361, 117.194,  97.661, 103.950, 124.031,
        118.427, 108.623, 120.608, 114.829, 119.668, 106.095, 107.189, 118.590,
         95.142, 114.518, 113.922, 106.006, 124.757, 111.939, 102.601,  97.413,
        118.865, 117.241, 119.894, 115.638,  96.091,  98.514, 114.811, 107.873,
        123.169, 115.423, 110.488, 109.942,  92.144, 116.095, 115.526, 105.559,
        110.538, 118.116,  99.005, 115.692, 123.802, 103.318,  99.563, 102.890,
        112.447, 104.174,  96.960,  91.748, 107.587, 111.916,  98.479, 115.020,
        106.442, 113.842, 106.312, 134.569,  92.534, 119.905, 110.794, 116.706,
        108.534, 111.017, 108.367,  89.936, 104.576, 117.647, 131.578, 129.430,
        116.706, 116.480, 119.473, 108.317, 109.073, 109.422, 124.884, 109.155,
        114.594, 108.343, 104.107,  81.344, 112.986, 118.573, 118.289, 101.655,
        118.377, 117.224, 107.749,  98.203, 123.076, 107.958, 112.109, 111.255,
        113.951, 100.772, 113.174, 108.864, 107.009, 121.538,  89.800, 105.553,
        116.728, 124.038, 114.364, 112.605, 111.067, 128.596, 119.331, 107.936,
        104.632, 105.824, 111.568,  97.631, 123.018, 118.306, 101.820, 122.384,
        111.590, 119.787,  96.173, 122.718, 107.753, 118.403, 106.793, 110.400,
        110.272, 128.758, 122.194, 113.313, 109.930, 104.884, 105.082, 132.914,
        125.100, 125.253, 113.776, 111.855,  92.803, 113.929,  99.313,  92.332,
        102.719, 123.104, 110.914, 111.797, 101.384,  97.082, 123.019, 118.803,
        105.299, 107.160, 124.908,  96.136, 101.458, 110.254,  97.799, 119.135,
        110.470, 104.511, 115.729,  98.480, 111.135,  90.119,  98.685, 121.813,
        111.375, 105.675, 104.700, 111.665, 125.232, 125.249, 112.258, 118.992,
        118.639, 124.400,  86.830, 117.199, 110.138, 105.628, 111.204, 112.384,
        111.106, 103.484, 110.836, 100.591, 116.235, 111.603, 114.859,  90.783],
       device='cuda:0')
clipping threshold 1.1609161885824602
a after update for 1 param tensor([[[-0.143],
         [-0.101],
         [-0.001],
         [ 0.327],
         [-0.082],
         [-0.171],
         [ 0.089],
         [-0.177],
         [ 0.021],
         [-0.159]],

        [[-0.196],
         [-0.049],
         [-0.164],
         [-0.271],
         [ 0.234],
         [ 0.084],
         [-0.038],
         [ 0.089],
         [ 0.011],
         [ 0.139]],

        [[ 0.025],
         [-0.003],
         [ 0.041],
         [-0.327],
         [-0.032],
         [ 0.169],
         [ 0.180],
         [ 0.015],
         [ 0.106],
         [-0.114]],

        [[ 0.097],
         [ 0.013],
         [ 0.027],
         [-0.043],
         [ 0.026],
         [ 0.105],
         [-0.114],
         [-0.149],
         [-0.141],
         [-0.073]],

        [[-0.045],
         [ 0.366],
         [-0.166],
         [-0.020],
         [-0.006],
         [ 0.231],
         [ 0.101],
         [-0.098],
         [-0.160],
         [-0.039]],

        [[-0.029],
         [ 0.069],
         [-0.024],
         [ 0.119],
         [-0.244],
         [ 0.195],
         [-0.154],
         [ 0.111],
         [-0.017],
         [-0.093]],

        [[-0.238],
         [ 0.051],
         [ 0.103],
         [ 0.097],
         [-0.075],
         [ 0.029],
         [ 0.221],
         [-0.036],
         [ 0.189],
         [-0.021]],

        [[ 0.175],
         [-0.075],
         [ 0.116],
         [ 0.097],
         [ 0.066],
         [ 0.002],
         [ 0.044],
         [ 0.015],
         [ 0.023],
         [-0.140]],

        [[-0.030],
         [ 0.114],
         [-0.119],
         [-0.038],
         [ 0.051],
         [ 0.133],
         [ 0.357],
         [ 0.016],
         [ 0.056],
         [-0.152]],

        [[ 0.046],
         [-0.049],
         [ 0.086],
         [ 0.168],
         [ 0.063],
         [ 0.105],
         [ 0.027],
         [ 0.120],
         [ 0.035],
         [ 0.143]],

        [[-0.083],
         [ 0.110],
         [-0.003],
         [-0.179],
         [-0.029],
         [-0.014],
         [ 0.186],
         [ 0.157],
         [ 0.075],
         [ 0.020]],

        [[-0.086],
         [ 0.179],
         [-0.022],
         [ 0.055],
         [ 0.034],
         [ 0.139],
         [-0.367],
         [ 0.176],
         [-0.079],
         [-0.019]],

        [[-0.066],
         [ 0.023],
         [ 0.032],
         [ 0.145],
         [ 0.093],
         [-0.319],
         [-0.048],
         [-0.026],
         [ 0.284],
         [-0.089]],

        [[-0.122],
         [ 0.093],
         [ 0.081],
         [-0.168],
         [ 0.052],
         [ 0.057],
         [-0.077],
         [-0.130],
         [ 0.081],
         [-0.111]],

        [[ 0.099],
         [-0.129],
         [ 0.170],
         [ 0.011],
         [ 0.182],
         [ 0.035],
         [-0.241],
         [-0.054],
         [ 0.009],
         [ 0.239]],

        [[-0.024],
         [ 0.105],
         [ 0.044],
         [ 0.063],
         [-0.159],
         [-0.292],
         [ 0.144],
         [ 0.049],
         [ 0.038],
         [ 0.202]],

        [[-0.009],
         [ 0.036],
         [-0.072],
         [-0.062],
         [-0.060],
         [ 0.112],
         [-0.179],
         [ 0.194],
         [-0.140],
         [-0.053]],

        [[-0.115],
         [ 0.284],
         [-0.112],
         [ 0.192],
         [ 0.145],
         [-0.029],
         [ 0.117],
         [ 0.218],
         [-0.012],
         [ 0.295]],

        [[ 0.108],
         [ 0.052],
         [-0.007],
         [-0.086],
         [-0.099],
         [ 0.120],
         [ 0.143],
         [-0.155],
         [ 0.028],
         [ 0.022]],

        [[-0.088],
         [-0.015],
         [ 0.128],
         [ 0.062],
         [ 0.378],
         [ 0.071],
         [ 0.103],
         [ 0.159],
         [-0.053],
         [ 0.134]]], device='cuda:0')
s after update for 1 param tensor([[[1.962],
         [1.125],
         [1.961],
         [1.358],
         [1.476],
         [1.718],
         [1.702],
         [1.422],
         [1.493],
         [2.030]],

        [[1.901],
         [2.059],
         [0.839],
         [1.199],
         [1.645],
         [2.388],
         [2.002],
         [1.215],
         [1.778],
         [1.966]],

        [[1.734],
         [1.477],
         [2.116],
         [1.583],
         [1.719],
         [1.779],
         [1.630],
         [1.888],
         [1.666],
         [1.689]],

        [[1.584],
         [1.947],
         [1.725],
         [1.833],
         [2.014],
         [1.791],
         [2.177],
         [1.606],
         [2.238],
         [1.727]],

        [[1.923],
         [1.800],
         [1.544],
         [1.928],
         [1.493],
         [1.388],
         [1.544],
         [1.631],
         [1.611],
         [1.175]],

        [[1.522],
         [1.709],
         [1.589],
         [1.850],
         [1.842],
         [1.651],
         [1.558],
         [1.985],
         [1.888],
         [1.550]],

        [[2.156],
         [1.408],
         [1.164],
         [1.637],
         [1.349],
         [1.805],
         [1.746],
         [1.413],
         [1.906],
         [1.442]],

        [[1.758],
         [1.893],
         [1.772],
         [1.652],
         [1.579],
         [1.592],
         [2.077],
         [2.420],
         [1.590],
         [1.717]],

        [[1.501],
         [1.785],
         [1.917],
         [2.028],
         [1.777],
         [1.552],
         [1.415],
         [1.415],
         [1.606],
         [1.304]],

        [[1.573],
         [1.611],
         [1.196],
         [1.904],
         [1.695],
         [1.249],
         [0.747],
         [1.760],
         [1.552],
         [1.736]],

        [[1.961],
         [1.266],
         [2.135],
         [1.093],
         [1.825],
         [1.469],
         [1.616],
         [1.965],
         [1.335],
         [1.570]],

        [[1.673],
         [1.144],
         [1.407],
         [1.753],
         [0.988],
         [1.864],
         [2.071],
         [1.475],
         [1.334],
         [1.304]],

        [[1.892],
         [1.891],
         [1.097],
         [1.961],
         [2.057],
         [1.089],
         [1.447],
         [1.393],
         [1.090],
         [1.997]],

        [[1.386],
         [1.920],
         [1.897],
         [1.833],
         [1.906],
         [1.831],
         [1.559],
         [1.725],
         [1.911],
         [2.054]],

        [[1.000],
         [1.266],
         [1.668],
         [1.380],
         [1.416],
         [1.266],
         [1.602],
         [1.381],
         [2.013],
         [1.631]],

        [[1.187],
         [1.961],
         [1.582],
         [1.630],
         [1.622],
         [1.313],
         [1.890],
         [1.802],
         [1.568],
         [2.035]],

        [[1.295],
         [1.503],
         [1.728],
         [1.862],
         [1.762],
         [1.432],
         [2.034],
         [1.850],
         [2.058],
         [1.629]],

        [[1.715],
         [1.673],
         [1.927],
         [1.941],
         [1.874],
         [2.216],
         [1.608],
         [1.465],
         [1.013],
         [1.826]],

        [[1.753],
         [1.777],
         [1.885],
         [1.811],
         [1.594],
         [1.619],
         [1.972],
         [1.436],
         [1.609],
         [1.807]],

        [[1.456],
         [1.676],
         [1.448],
         [1.483],
         [1.866],
         [2.104],
         [1.774],
         [1.942],
         [1.050],
         [1.104]]], device='cuda:0')
b after update for 1 param tensor([[[120.600],
         [ 91.292],
         [120.547],
         [100.320],
         [104.575],
         [112.824],
         [112.320],
         [102.664],
         [105.192],
         [122.658]],

        [[118.685],
         [123.528],
         [ 78.848],
         [ 94.281],
         [110.409],
         [133.036],
         [121.794],
         [ 94.909],
         [114.777],
         [120.696]],

        [[113.360],
         [104.626],
         [125.229],
         [108.312],
         [112.878],
         [114.814],
         [109.895],
         [118.288],
         [111.120],
         [111.874]],

        [[108.338],
         [120.119],
         [113.064],
         [116.569],
         [122.177],
         [115.194],
         [127.032],
         [109.106],
         [128.792],
         [113.140]],

        [[119.390],
         [115.509],
         [106.985],
         [119.535],
         [105.200],
         [101.436],
         [106.961],
         [109.958],
         [109.252],
         [ 93.332]],

        [[106.192],
         [112.551],
         [108.521],
         [117.091],
         [116.831],
         [110.616],
         [107.455],
         [121.287],
         [118.286],
         [107.180]],

        [[126.394],
         [102.137],
         [ 92.885],
         [110.131],
         [ 99.988],
         [115.672],
         [113.747],
         [102.331],
         [118.862],
         [103.362]],

        [[114.143],
         [118.433],
         [114.581],
         [110.664],
         [108.164],
         [108.618],
         [124.069],
         [133.920],
         [108.542],
         [112.814]],

        [[105.464],
         [115.003],
         [119.191],
         [122.603],
         [114.765],
         [107.242],
         [102.404],
         [102.418],
         [109.092],
         [ 98.302]],

        [[107.976],
         [109.268],
         [ 94.165],
         [118.786],
         [112.072],
         [ 96.204],
         [ 74.399],
         [114.219],
         [107.257],
         [113.440]],

        [[120.569],
         [ 96.875],
         [125.789],
         [ 89.987],
         [116.302],
         [104.357],
         [109.442],
         [120.692],
         [ 99.476],
         [107.874]],

        [[111.354],
         [ 92.093],
         [102.132],
         [113.966],
         [ 85.583],
         [117.545],
         [123.895],
         [104.561],
         [ 99.444],
         [ 98.307]],

        [[118.422],
         [118.384],
         [ 90.180],
         [120.543],
         [123.461],
         [ 89.839],
         [103.559],
         [101.590],
         [ 89.867],
         [121.643]],

        [[101.333],
         [119.275],
         [118.567],
         [116.562],
         [118.848],
         [116.492],
         [107.500],
         [113.069],
         [118.995],
         [123.384]],

        [[ 86.106],
         [ 96.852],
         [111.169],
         [101.130],
         [102.442],
         [ 96.870],
         [108.962],
         [101.181],
         [122.137],
         [109.941]],

        [[ 93.792],
         [120.547],
         [108.292],
         [109.912],
         [109.653],
         [ 98.659],
         [118.346],
         [115.572],
         [107.792],
         [122.793]],

        [[ 97.967],
         [105.547],
         [113.172],
         [117.459],
         [114.271],
         [103.027],
         [122.783],
         [117.098],
         [123.488],
         [109.885]],

        [[112.738],
         [111.352],
         [119.508],
         [119.952],
         [117.862],
         [128.149],
         [109.164],
         [104.216],
         [ 86.632],
         [116.322]],

        [[113.979],
         [114.752],
         [118.200],
         [115.859],
         [108.692],
         [109.531],
         [120.902],
         [103.165],
         [109.191],
         [115.738]],

        [[103.866],
         [111.457],
         [103.604],
         [104.849],
         [117.608],
         [124.872],
         [114.677],
         [119.966],
         [ 88.197],
         [ 90.446]]], device='cuda:0')
clipping threshold 1.1609161885824602
a after update for 1 param tensor([[ 0.091],
        [-0.035],
        [ 0.090],
        [-0.020],
        [-0.027],
        [-0.136],
        [ 0.166],
        [-0.065],
        [-0.017],
        [ 0.079],
        [-0.026],
        [ 0.217],
        [ 0.064],
        [ 0.014],
        [-0.136],
        [-0.078],
        [-0.242],
        [-0.007],
        [-0.384],
        [-0.035]], device='cuda:0')
s after update for 1 param tensor([[1.812],
        [1.907],
        [1.824],
        [1.716],
        [0.957],
        [1.818],
        [1.937],
        [0.920],
        [1.672],
        [1.631],
        [0.918],
        [1.834],
        [2.397],
        [1.548],
        [1.377],
        [2.190],
        [1.378],
        [2.063],
        [1.989],
        [2.045]], device='cuda:0')
b after update for 1 param tensor([[115.881],
        [118.879],
        [116.268],
        [112.766],
        [ 84.228],
        [116.089],
        [119.809],
        [ 82.576],
        [111.331],
        [109.945],
        [ 82.499],
        [116.595],
        [133.283],
        [107.104],
        [101.037],
        [127.411],
        [101.043],
        [123.648],
        [121.413],
        [123.113]], device='cuda:0')
clipping threshold 1.1609161885824602
||w||^2 2.463103274443904
exp ma of ||w||^2 2.3116719676891573
||w|| 1.5694276900972226
exp ma of ||w|| 1.4573175415307678
||w||^2 1.1682587324276763
exp ma of ||w||^2 2.1633515743796075
||w|| 1.0808601817199468
exp ma of ||w|| 1.4102509654046553
||w||^2 1.20102627503441
exp ma of ||w||^2 2.0038573812306026
||w|| 1.0959134432218678
exp ma of ||w|| 1.3664517756531926
||w||^2 2.760977431333264
exp ma of ||w||^2 1.9299145399796875
||w|| 1.6616189188057724
exp ma of ||w|| 1.3372714340624827
||w||^2 1.694610172162775
exp ma of ||w||^2 2.042413937198156
||w|| 1.3017719355412356
exp ma of ||w|| 1.3734221953569015
||w||^2 1.9901136240513526
exp ma of ||w||^2 2.0814744285064166
||w|| 1.4107138703689535
exp ma of ||w|| 1.391438069253062
||w||^2 1.141382202052669
exp ma of ||w||^2 2.1376023792437073
||w|| 1.0683549045390623
exp ma of ||w|| 1.408134033302942
cuda
Objective function 36.79 = squared loss an data 27.10 + 0.5*rho*h**2 4.404595 + alpha*h 3.081200 + L2reg 1.96 + L1reg 0.24 ; SHD = 85 ; DAG False
Proportion of microbatches that were clipped  0.7736440337484933
iteration 2 in inner loop, alpha 3.2828569791828244 rho 10.0 h 0.9385728104043842
4420
cuda
Objective function 76.43 = squared loss an data 27.10 + 0.5*rho*h**2 44.045946 + alpha*h 3.081200 + L2reg 1.96 + L1reg 0.24 ; SHD = 85 ; DAG False
||w||^2 74654007.47906119
exp ma of ||w||^2 10334055279.342312
||w|| 8640.255058680918
exp ma of ||w|| 54147.090450066906
||w||^2 2.2654793561376323
exp ma of ||w||^2 64.17644355208778
||w|| 1.5051509413137383
exp ma of ||w|| 1.761950640863686
||w||^2 2.8264347375108168
exp ma of ||w||^2 3.2006190414035918
||w|| 1.6812003858882547
exp ma of ||w|| 1.7221599788993847
||w||^2 5.117270913188957
exp ma of ||w||^2 2.9331591644217876
||w|| 2.2621385707310147
exp ma of ||w|| 1.650621218022484
||w||^2 2.485486349723629
exp ma of ||w||^2 3.208482580921766
||w|| 1.576542530261594
exp ma of ||w|| 1.7133157734264477
||w||^2 3.8177361173745252
exp ma of ||w||^2 3.1623705014522208
||w|| 1.9539027911783444
exp ma of ||w|| 1.7039639320061624
||w||^2 2.5815736830546387
exp ma of ||w||^2 3.054856621142964
||w|| 1.6067276318824666
exp ma of ||w|| 1.6761269178076434
||w||^2 2.947308761752171
exp ma of ||w||^2 3.316799693938715
||w|| 1.7167727752245407
exp ma of ||w|| 1.7608745795556746
cuda
Objective function 40.69 = squared loss an data 30.87 + 0.5*rho*h**2 6.247549 + alpha*h 1.160438 + L2reg 2.20 + L1reg 0.21 ; SHD = 80 ; DAG True
Proportion of microbatches that were clipped  0.7766596331764324
iteration 3 in inner loop, alpha 3.2828569791828244 rho 100.0 h 0.3534840484539927
iteration 2 in outer loop, alpha = 38.6312618245821, rho = 100.0, h = 0.3534840484539927
cuda
4420
cuda
Objective function 53.19 = squared loss an data 30.87 + 0.5*rho*h**2 6.247549 + alpha*h 13.655535 + L2reg 2.20 + L1reg 0.21 ; SHD = 80 ; DAG True
||w||^2 9777565072.862518
exp ma of ||w||^2 106874856208.92892
||w|| 98881.57094657487
exp ma of ||w|| 254067.20836992408
||w||^2 535579.6939743946
exp ma of ||w||^2 1214343157.2412453
||w|| 731.8331052735962
exp ma of ||w|| 8529.414050933703
||w||^2 12.74888906367296
exp ma of ||w||^2 1877587.2475677282
||w|| 3.570558648681318
exp ma of ||w|| 19.56128383692953
||w||^2 2.7252230675875007
exp ma of ||w||^2 107065.0995145287
||w|| 1.6508249657633303
exp ma of ||w|| 3.0592642579107734
||w||^2 1.9951621606300165
exp ma of ||w||^2 3.9639675408601254
||w|| 1.4125020922568634
exp ma of ||w|| 1.8680809326348633
||w||^2 5.8276149659051395
exp ma of ||w||^2 3.6882513563003254
||w|| 2.414045352909746
exp ma of ||w|| 1.857213677853099
||w||^2 2.74909772562952
exp ma of ||w||^2 3.4442136348910717
||w|| 1.6580403269008628
exp ma of ||w|| 1.7987854444313465
||w||^2 6.384630129432333
exp ma of ||w||^2 3.2484005943758567
||w|| 2.5267825647317443
exp ma of ||w|| 1.7459585181305208
||w||^2 1.0834858905529725
exp ma of ||w||^2 3.441614014972137
||w|| 1.0409062832709641
exp ma of ||w|| 1.791629379903603
||w||^2 3.421438639664103
exp ma of ||w||^2 3.4235060442003276
||w|| 1.8497131236124436
exp ma of ||w|| 1.7840104179522942
||w||^2 7.304374612100078
exp ma of ||w||^2 3.621170664911221
||w|| 2.7026606542627727
exp ma of ||w|| 1.8457079631327091
||w||^2 6.015556620889438
exp ma of ||w||^2 3.840923945926381
||w|| 2.4526631690652994
exp ma of ||w|| 1.8910936606373805
||w||^2 4.758349438298305
exp ma of ||w||^2 3.797021290166686
||w|| 2.181364123272019
exp ma of ||w|| 1.8854445741808383
||w||^2 3.901888333158083
exp ma of ||w||^2 3.9740865723334915
||w|| 1.9753198052867498
exp ma of ||w|| 1.9029271066533733
||w||^2 3.1749154208660513
exp ma of ||w||^2 3.2460724442106015
||w|| 1.7818292344851825
exp ma of ||w|| 1.7287103071890744
cuda
Objective function 45.36 = squared loss an data 31.77 + 0.5*rho*h**2 2.458849 + alpha*h 8.566824 + L2reg 2.37 + L1reg 0.20 ; SHD = 78 ; DAG True
Proportion of microbatches that were clipped  0.774073474672277
iteration 1 in inner loop, alpha 38.6312618245821 rho 100.0 h 0.22175884749005803
4420
cuda
Objective function 67.49 = squared loss an data 31.77 + 0.5*rho*h**2 24.588493 + alpha*h 8.566824 + L2reg 2.37 + L1reg 0.20 ; SHD = 78 ; DAG True
||w||^2 2.8131107185604254
exp ma of ||w||^2 2262756.470467539
||w|| 1.6772330543369414
exp ma of ||w|| 19.28334275301817
||w||^2 4.387981424138952
exp ma of ||w||^2 20719.31216064115
||w|| 2.0947509217419986
exp ma of ||w|| 2.2885996281231895
||w||^2 3.070747815368482
exp ma of ||w||^2 3.8572566286594903
||w|| 1.7523549341867024
exp ma of ||w|| 1.895279175097427
||w||^2 2.5596256961331996
exp ma of ||w||^2 3.9152505298415448
||w|| 1.5998830257656962
exp ma of ||w|| 1.8959728616378977
||w||^2 4.787204427428037
exp ma of ||w||^2 4.170251481561858
||w|| 2.1879681047556514
exp ma of ||w|| 1.989229115453941
||w||^2 2.617144145910605
exp ma of ||w||^2 4.17987034712091
||w|| 1.6177589888208332
exp ma of ||w|| 1.9655485474819965
cuda
Objective function 45.33 = squared loss an data 33.03 + 0.5*rho*h**2 5.541692 + alpha*h 4.067008 + L2reg 2.51 + L1reg 0.19 ; SHD = 70 ; DAG True
Proportion of microbatches that were clipped  0.7800047721307564
iteration 2 in inner loop, alpha 38.6312618245821 rho 1000.0 h 0.10527764882342439
4420
cuda
Objective function 95.21 = squared loss an data 33.03 + 0.5*rho*h**2 55.416917 + alpha*h 4.067008 + L2reg 2.51 + L1reg 0.19 ; SHD = 70 ; DAG True
||w||^2 2065159164581.6438
exp ma of ||w||^2 1401754812090.942
||w|| 1437066.1656937178
exp ma of ||w|| 741104.85638844
||w||^2 14445605807.111195
exp ma of ||w||^2 191757730627.94693
||w|| 120189.8739790969
exp ma of ||w|| 301446.93659791804
||w||^2 13948.591554082748
exp ma of ||w||^2 720812311.5638804
||w|| 118.10415553266002
exp ma of ||w|| 3036.1935161243746
||w||^2 5.991298904220825
exp ma of ||w||^2 203826.65886080067
||w|| 2.4477129946586516
exp ma of ||w|| 3.6373795983226174
||w||^2 10.228556292254819
exp ma of ||w||^2 5.375045553272641
||w|| 3.1982114208186454
exp ma of ||w|| 2.223224355093082
||w||^2 3.097428950256858
exp ma of ||w||^2 4.770972477428463
||w|| 1.7599514056521157
exp ma of ||w|| 2.1226656320142965
||w||^2 5.679791125524069
exp ma of ||w||^2 4.625348856828396
||w|| 2.3832312362681196
exp ma of ||w|| 2.095484272103728
||w||^2 3.174575018217474
exp ma of ||w||^2 4.235261170798771
||w|| 1.7817337113658354
exp ma of ||w|| 2.000287801982233
||w||^2 5.036918161293817
exp ma of ||w||^2 4.352587968102378
||w|| 2.2443079470727314
exp ma of ||w|| 2.021512143932878
||w||^2 3.8746787435363355
exp ma of ||w||^2 4.57301790875577
||w|| 1.9684203675882688
exp ma of ||w|| 2.087997405578443
||w||^2 4.196180316592839
exp ma of ||w||^2 4.558005578465203
||w|| 2.048458033886181
exp ma of ||w|| 2.084093999964396
||w||^2 6.011595640931068
exp ma of ||w||^2 4.0252551498781335
||w|| 2.4518555505843054
exp ma of ||w|| 1.948636909796003
cuda
Objective function 44.72 = squared loss an data 34.46 + 0.5*rho*h**2 6.062696 + alpha*h 1.345200 + L2reg 2.66 + L1reg 0.18 ; SHD = 79 ; DAG True
Proportion of microbatches that were clipped  0.780205758034931
iteration 3 in inner loop, alpha 38.6312618245821 rho 10000.0 h 0.03482153401858312
iteration 3 in outer loop, alpha = 386.84660201041333, rho = 10000.0, h = 0.03482153401858312
cuda
4420
cuda
Objective function 56.84 = squared loss an data 34.46 + 0.5*rho*h**2 6.062696 + alpha*h 13.470592 + L2reg 2.66 + L1reg 0.18 ; SHD = 79 ; DAG True
||w||^2 7.078104612177555
exp ma of ||w||^2 102497.95090139478
||w|| 2.6604707501074984
exp ma of ||w|| 3.107484844971561
||w||^2 26.83585884335693
exp ma of ||w||^2 645.97505519165
||w|| 5.180333854430323
exp ma of ||w|| 2.306072725927669
||w||^2 8.459834574299554
exp ma of ||w||^2 6.714789114541663
||w|| 2.908579477047095
exp ma of ||w|| 2.1687457897152402
||w||^2 3.1256721138452757
exp ma of ||w||^2 4.564508998289033
||w|| 1.7679570452489155
exp ma of ||w|| 2.0830608057027367
||w||^2 1.9728613394705332
exp ma of ||w||^2 4.724824178628076
||w|| 1.404585824885946
exp ma of ||w|| 2.118407065352426
||w||^2 2.8587929199290327
exp ma of ||w||^2 4.752344458218185
||w|| 1.6907965341604627
exp ma of ||w|| 2.119652112620085
||w||^2 2.529275153892086
exp ma of ||w||^2 4.824898412399017
||w|| 1.5903695023145048
exp ma of ||w|| 2.1260208842332156
||w||^2 1.950353343485812
exp ma of ||w||^2 4.345899474121625
||w|| 1.3965505159090423
exp ma of ||w|| 2.010729304544526
||w||^2 5.0468601294767526
exp ma of ||w||^2 4.327152197261893
||w|| 2.246521784776803
exp ma of ||w|| 2.017415081779578
||w||^2 3.3355929820734165
exp ma of ||w||^2 4.559749344034877
||w|| 1.8263605838041448
exp ma of ||w|| 2.0737284080125526
||w||^2 6.215263698072806
exp ma of ||w||^2 4.516900983293878
||w|| 2.493043059811203
exp ma of ||w|| 2.082597018678678
||w||^2 7.203639465874093
exp ma of ||w||^2 4.433676655945463
||w|| 2.683959661744955
exp ma of ||w|| 2.0620882886703207
cuda
Objective function 49.49 = squared loss an data 35.01 + 0.5*rho*h**2 2.638555 + alpha*h 8.886624 + L2reg 2.76 + L1reg 0.19 ; SHD = 77 ; DAG True
Proportion of microbatches that were clipped  0.7788216560509554
iteration 1 in inner loop, alpha 386.84660201041333 rho 10000.0 h 0.02297195940509056
4420
cuda
Objective function 73.23 = squared loss an data 35.01 + 0.5*rho*h**2 26.385546 + alpha*h 8.886624 + L2reg 2.76 + L1reg 0.19 ; SHD = 77 ; DAG True
||w||^2 112.32345738737621
exp ma of ||w||^2 706247357.3788319
||w|| 10.598276151685056
exp ma of ||w|| 335.36251538526375
||w||^2 6.899222094471303
exp ma of ||w||^2 1727.897535729451
||w|| 2.626637031352315
exp ma of ||w|| 2.549197316424637
||w||^2 4.115028573883795
exp ma of ||w||^2 24.70935772493735
||w|| 2.0285533204438564
exp ma of ||w|| 2.207668304168945
||w||^2 2.842602188059121
exp ma of ||w||^2 4.900865014469721
||w|| 1.686001835129227
exp ma of ||w|| 2.1565206189757196
||w||^2 10.665668159781125
exp ma of ||w||^2 5.225097202455944
||w|| 3.2658334556099344
exp ma of ||w|| 2.2361136210800914
||w||^2 2.718931033179844
exp ma of ||w||^2 4.978416775862143
||w|| 1.6489181402300856
exp ma of ||w|| 2.1830734922456956
||w||^2 5.803374460846148
exp ma of ||w||^2 5.076948724228672
||w|| 2.4090193981880152
exp ma of ||w|| 2.2085043661699855
||w||^2 2.4992123541077924
exp ma of ||w||^2 5.001635424527833
||w|| 1.580889734961864
exp ma of ||w|| 2.1882393049856157
||w||^2 4.558368482496107
exp ma of ||w||^2 5.0137892351889235
||w|| 2.1350336021936767
exp ma of ||w|| 2.2058133961479687
||w||^2 5.125825188045188
exp ma of ||w||^2 4.832786160936125
||w|| 2.2640285307489365
exp ma of ||w|| 2.1450981942071947
||w||^2 11.178389364801056
exp ma of ||w||^2 5.314931867390399
||w|| 3.3434098409858546
exp ma of ||w|| 2.2568248601078396
cuda
Objective function 48.27 = squared loss an data 35.01 + 0.5*rho*h**2 5.982183 + alpha*h 4.231396 + L2reg 2.86 + L1reg 0.19 ; SHD = 78 ; DAG True
Proportion of microbatches that were clipped  0.7819760430902806
iteration 2 in inner loop, alpha 386.84660201041333 rho 100000.0 h 0.010938174797949785
iteration 4 in outer loop, alpha = 11325.021399960198, rho = 1000000.0, h = 0.010938174797949785
Threshold 0.3
[[0.009 2.432 0.573 0.951 0.901 0.862 0.813 0.839 0.228 0.331 0.408 0.251
  0.473 0.203 0.751 0.994 0.6   0.729 1.022 0.705]
 [0.003 0.008 0.148 0.206 0.363 0.469 0.88  0.126 0.037 0.26  0.091 0.05
  0.087 0.036 0.329 0.361 0.188 0.218 0.214 0.345]
 [0.012 0.044 0.007 0.143 0.3   0.084 0.362 0.144 0.012 0.143 0.035 0.055
  0.042 0.03  0.191 0.389 0.214 0.192 0.067 0.166]
 [0.005 0.042 0.067 0.01  0.236 0.059 0.137 0.078 0.02  0.046 0.036 0.054
  0.041 0.042 0.245 0.237 0.111 0.238 0.048 0.056]
 [0.004 0.02  0.02  0.035 0.006 0.008 0.03  0.007 0.005 0.009 0.011 0.012
  0.014 0.036 0.026 0.051 0.024 0.013 0.015 0.024]
 [0.007 0.019 0.066 0.089 0.643 0.008 0.184 0.181 0.012 0.209 0.025 0.028
  0.033 0.033 0.503 0.882 1.149 0.22  0.106 0.173]
 [0.003 0.013 0.015 0.048 0.24  0.025 0.007 0.028 0.006 0.044 0.006 0.011
  0.016 0.016 0.076 0.277 0.078 0.033 0.018 0.057]
 [0.012 0.042 0.047 0.114 0.662 0.031 0.22  0.007 0.011 0.033 0.061 0.038
  0.027 0.038 0.257 0.28  0.265 0.179 0.114 0.085]
 [0.047 0.122 0.789 0.4   0.884 0.432 0.685 0.46  0.008 0.346 0.358 0.239
  0.773 0.132 0.414 0.828 0.744 0.465 0.798 0.498]
 [0.009 0.023 0.052 0.141 0.8   0.036 0.157 0.141 0.017 0.008 0.039 0.02
  0.076 0.056 0.175 0.233 0.445 0.139 0.073 0.157]
 [0.022 0.12  0.234 0.186 0.411 0.254 1.129 0.109 0.01  0.138 0.006 0.034
  0.016 0.044 0.456 0.828 0.545 0.33  0.062 0.788]
 [0.022 0.185 0.143 0.133 0.261 0.288 0.587 0.168 0.036 0.313 0.182 0.007
  0.252 0.187 0.272 0.451 0.389 0.217 0.14  0.259]
 [0.017 0.058 0.106 0.203 0.595 0.214 0.495 0.262 0.008 0.069 0.367 0.024
  0.004 0.059 0.173 0.59  0.313 0.243 0.08  0.293]
 [0.033 0.15  0.221 0.166 0.163 0.201 0.325 0.196 0.038 0.111 0.19  0.044
  0.133 0.007 0.265 0.557 0.31  0.097 0.136 0.485]
 [0.006 0.024 0.037 0.029 0.329 0.012 0.095 0.024 0.009 0.026 0.006 0.027
  0.03  0.019 0.008 0.204 0.016 0.01  0.028 0.052]
 [0.003 0.016 0.019 0.025 0.136 0.005 0.026 0.02  0.005 0.017 0.007 0.008
  0.012 0.012 0.038 0.006 0.007 0.016 0.008 0.008]
 [0.006 0.019 0.036 0.086 0.324 0.006 0.106 0.028 0.012 0.016 0.02  0.017
  0.016 0.03  0.497 0.687 0.007 0.033 0.081 0.061]
 [0.008 0.048 0.039 0.031 0.523 0.058 0.218 0.047 0.016 0.053 0.025 0.023
  0.028 0.065 0.467 0.517 0.124 0.006 0.058 0.074]
 [0.005 0.033 0.098 0.158 0.352 0.057 0.379 0.032 0.009 0.067 0.099 0.055
  0.09  0.017 0.207 0.96  0.084 0.081 0.006 0.086]
 [0.008 0.019 0.046 0.103 0.241 0.042 0.146 0.066 0.01  0.029 0.009 0.029
  0.015 0.018 0.134 0.965 0.088 0.081 0.068 0.008]]
[[0.    2.432 0.573 0.951 0.901 0.862 0.813 0.839 0.    0.331 0.408 0.
  0.473 0.    0.751 0.994 0.6   0.729 1.022 0.705]
 [0.    0.    0.    0.    0.363 0.469 0.88  0.    0.    0.    0.    0.
  0.    0.    0.329 0.361 0.    0.    0.    0.345]
 [0.    0.    0.    0.    0.    0.    0.362 0.    0.    0.    0.    0.
  0.    0.    0.    0.389 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.643 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.503 0.882 1.149 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.662 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.789 0.4   0.884 0.432 0.685 0.46  0.    0.346 0.358 0.
  0.773 0.    0.414 0.828 0.744 0.465 0.798 0.498]
 [0.    0.    0.    0.    0.8   0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.445 0.    0.    0.   ]
 [0.    0.    0.    0.    0.411 0.    1.129 0.    0.    0.    0.    0.
  0.    0.    0.456 0.828 0.545 0.33  0.    0.788]
 [0.    0.    0.    0.    0.    0.    0.587 0.    0.    0.313 0.    0.
  0.    0.    0.    0.451 0.389 0.    0.    0.   ]
 [0.    0.    0.    0.    0.595 0.    0.495 0.    0.    0.    0.367 0.
  0.    0.    0.    0.59  0.313 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.325 0.    0.    0.    0.    0.
  0.    0.    0.    0.557 0.31  0.    0.    0.485]
 [0.    0.    0.    0.    0.329 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.324 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.497 0.687 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.523 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.467 0.517 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.352 0.    0.379 0.    0.    0.    0.    0.
  0.    0.    0.    0.96  0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.965 0.    0.    0.    0.   ]]
{'fdr': 0.5064935064935064, 'tpr': 0.475, 'fpr': 0.35454545454545455, 'f1': 0.4840764331210191, 'shd': 78, 'npred': 77, 'ntrue': 80}
[2.432 0.573 0.951 0.901 0.862 0.813 0.839 0.228 0.331 0.408 0.251 0.473
 0.203 0.751 0.994 0.6   0.729 1.022 0.705 0.003 0.148 0.206 0.363 0.469
 0.88  0.126 0.037 0.26  0.091 0.05  0.087 0.036 0.329 0.361 0.188 0.218
 0.214 0.345 0.012 0.044 0.143 0.3   0.084 0.362 0.144 0.012 0.143 0.035
 0.055 0.042 0.03  0.191 0.389 0.214 0.192 0.067 0.166 0.005 0.042 0.067
 0.236 0.059 0.137 0.078 0.02  0.046 0.036 0.054 0.041 0.042 0.245 0.237
 0.111 0.238 0.048 0.056 0.004 0.02  0.02  0.035 0.008 0.03  0.007 0.005
 0.009 0.011 0.012 0.014 0.036 0.026 0.051 0.024 0.013 0.015 0.024 0.007
 0.019 0.066 0.089 0.643 0.184 0.181 0.012 0.209 0.025 0.028 0.033 0.033
 0.503 0.882 1.149 0.22  0.106 0.173 0.003 0.013 0.015 0.048 0.24  0.025
 0.028 0.006 0.044 0.006 0.011 0.016 0.016 0.076 0.277 0.078 0.033 0.018
 0.057 0.012 0.042 0.047 0.114 0.662 0.031 0.22  0.011 0.033 0.061 0.038
 0.027 0.038 0.257 0.28  0.265 0.179 0.114 0.085 0.047 0.122 0.789 0.4
 0.884 0.432 0.685 0.46  0.346 0.358 0.239 0.773 0.132 0.414 0.828 0.744
 0.465 0.798 0.498 0.009 0.023 0.052 0.141 0.8   0.036 0.157 0.141 0.017
 0.039 0.02  0.076 0.056 0.175 0.233 0.445 0.139 0.073 0.157 0.022 0.12
 0.234 0.186 0.411 0.254 1.129 0.109 0.01  0.138 0.034 0.016 0.044 0.456
 0.828 0.545 0.33  0.062 0.788 0.022 0.185 0.143 0.133 0.261 0.288 0.587
 0.168 0.036 0.313 0.182 0.252 0.187 0.272 0.451 0.389 0.217 0.14  0.259
 0.017 0.058 0.106 0.203 0.595 0.214 0.495 0.262 0.008 0.069 0.367 0.024
 0.059 0.173 0.59  0.313 0.243 0.08  0.293 0.033 0.15  0.221 0.166 0.163
 0.201 0.325 0.196 0.038 0.111 0.19  0.044 0.133 0.265 0.557 0.31  0.097
 0.136 0.485 0.006 0.024 0.037 0.029 0.329 0.012 0.095 0.024 0.009 0.026
 0.006 0.027 0.03  0.019 0.204 0.016 0.01  0.028 0.052 0.003 0.016 0.019
 0.025 0.136 0.005 0.026 0.02  0.005 0.017 0.007 0.008 0.012 0.012 0.038
 0.007 0.016 0.008 0.008 0.006 0.019 0.036 0.086 0.324 0.006 0.106 0.028
 0.012 0.016 0.02  0.017 0.016 0.03  0.497 0.687 0.033 0.081 0.061 0.008
 0.048 0.039 0.031 0.523 0.058 0.218 0.047 0.016 0.053 0.025 0.023 0.028
 0.065 0.467 0.517 0.124 0.058 0.074 0.005 0.033 0.098 0.158 0.352 0.057
 0.379 0.032 0.009 0.067 0.099 0.055 0.09  0.017 0.207 0.96  0.084 0.081
 0.086 0.008 0.019 0.046 0.103 0.241 0.042 0.146 0.066 0.01  0.029 0.009
 0.029 0.015 0.018 0.134 0.965 0.088 0.081 0.068]
[[0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0.]
 [0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1.]
 [0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0.]
 [0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.]
 [0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.]
 [0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]
 [0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]
[1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1.
 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.
 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.
 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1.
 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
aucroc, aucpr (0.7832916666666667, 0.5443938138670242)
Iterations 2250
Achieves (13.034436291409676, 1e-05)-DP
