samples  5000  graph  30 90 ER mlp  minibatch size  50  noise  0.8  minibatches per NN training  250 quantile adaptive clipping
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 2.115034010050131
iteration 1 in outer loop, alpha = 2.115034010050131, rho = 1.0, h = 2.115034010050131
cuda
iteration 1 in inner loop,alpha 2.115034010050131 rho 1.0 h 1.3374026753201562
iteration 2 in inner loop,alpha 2.115034010050131 rho 10.0 h 0.5699212085785241
iteration 3 in inner loop,alpha 2.115034010050131 rho 100.0 h 0.17981340631291687
iteration 2 in outer loop, alpha = 20.096374641341818, rho = 100.0, h = 0.17981340631291687
cuda
iteration 1 in inner loop,alpha 20.096374641341818 rho 100.0 h 0.0907471250488392
iteration 2 in inner loop,alpha 20.096374641341818 rho 1000.0 h 0.034081539512548886
iteration 3 in outer loop, alpha = 54.177914153890704, rho = 1000.0, h = 0.034081539512548886
cuda
iteration 1 in inner loop,alpha 54.177914153890704 rho 1000.0 h 0.018256885913732646
iteration 2 in inner loop,alpha 54.177914153890704 rho 10000.0 h 0.005750703824816128
iteration 4 in outer loop, alpha = 111.68495240205198, rho = 10000.0, h = 0.005750703824816128
cuda
iteration 1 in inner loop,alpha 111.68495240205198 rho 10000.0 h 0.002708498976250695
iteration 2 in inner loop,alpha 111.68495240205198 rho 100000.0 h 0.0008926837293543599
iteration 5 in outer loop, alpha = 200.95332533748797, rho = 100000.0, h = 0.0008926837293543599
cuda
iteration 1 in inner loop,alpha 200.95332533748797 rho 100000.0 h 0.0004053726146331371
iteration 6 in outer loop, alpha = 606.3259399706251, rho = 1000000.0, h = 0.0004053726146331371
Threshold 0.3
[[0.005 0.001 0.001 2.094 0.001 0.001 0.001 0.001 0.001 0.    0.    0.001
  0.    0.    0.001 0.226 0.    0.    1.047 0.288 0.    0.    1.618 0.
  0.    0.    0.102 0.    0.15  0.   ]
 [1.06  0.003 0.38  0.327 0.    0.157 0.001 0.399 0.001 0.    0.    1.015
  0.    0.    0.002 1.61  0.001 0.001 1.02  0.425 0.001 0.001 0.181 0.002
  0.    0.001 0.569 0.    0.228 0.   ]
 [0.358 0.001 0.002 0.222 0.001 0.12  0.001 0.193 0.    0.    0.    0.305
  0.    0.    0.    0.24  0.    0.001 0.175 0.262 0.    0.    0.17  0.
  0.    0.    0.248 0.001 0.183 0.   ]
 [0.    0.    0.    0.006 0.    0.001 0.001 0.    0.    0.    0.    0.001
  0.    0.    0.    1.722 0.    0.    0.926 1.255 0.    0.    0.258 0.
  0.    0.    0.054 0.    0.109 0.   ]
 [0.195 0.151 0.224 0.219 0.002 0.122 0.009 0.139 0.001 0.    0.    0.377
  0.    0.    0.001 0.236 0.    0.    0.111 0.194 0.    0.    0.109 0.001
  0.    0.    0.132 0.    0.193 0.   ]
 [0.425 0.001 0.001 0.152 0.001 0.002 0.001 0.001 0.    0.    0.    0.001
  0.    0.    0.    0.13  0.    0.    0.915 1.312 0.    0.    0.122 0.
  0.    0.    0.051 0.    1.195 0.   ]
 [0.072 0.235 0.15  0.143 0.061 0.118 0.001 0.08  0.531 0.006 0.028 0.088
  0.    0.004 0.001 0.18  0.    0.    0.729 0.13  0.031 0.03  0.079 0.003
  0.    0.001 0.095 0.    0.056 0.   ]
 [1.034 0.    0.005 0.493 0.001 2.042 0.003 0.002 0.    0.    0.    0.003
  0.    0.    0.001 0.207 0.001 0.    0.132 1.264 0.    0.001 0.112 0.001
  0.    0.    0.025 0.    0.263 0.001]
 [0.158 0.241 0.128 0.157 0.147 0.092 0.001 0.172 0.001 0.006 0.097 0.138
  0.    0.017 0.    0.241 0.    0.001 0.109 1.164 0.106 0.095 0.117 0.014
  0.001 0.004 0.523 0.    0.115 0.001]
 [0.147 0.135 0.207 1.671 0.053 0.348 0.019 2.588 0.016 0.004 0.43  0.604
  0.005 3.401 0.02  0.326 0.003 0.47  0.116 0.183 0.272 0.095 0.378 0.11
  0.001 0.46  0.225 0.003 0.293 0.277]
 [1.07  0.097 0.147 1.953 0.16  0.176 0.034 0.2   0.004 0.001 0.001 0.24
  0.006 0.084 0.005 1.189 0.004 0.071 0.241 0.133 2.848 1.138 1.448 0.078
  0.001 0.266 0.144 0.003 0.094 0.075]
 [0.214 0.    0.002 0.281 0.    0.097 0.002 0.275 0.    0.    0.    0.003
  0.    0.    0.    0.208 0.    0.    0.187 0.393 0.    0.    1.393 0.001
  0.    0.    0.014 0.    0.131 0.   ]
 [1.119 0.92  0.084 0.183 0.005 1.81  0.678 0.098 0.161 0.027 0.058 0.255
  0.001 0.006 0.004 0.11  0.01  0.171 0.662 0.171 0.02  0.014 0.177 0.05
  0.003 3.161 0.111 0.005 1.101 0.448]
 [0.986 2.18  1.864 0.565 0.027 0.291 0.011 1.842 0.006 0.    0.005 1.89
  0.004 0.001 0.007 0.353 0.003 0.2   0.335 0.811 0.131 0.016 0.221 0.005
  0.    0.028 0.117 0.001 0.266 0.066]
 [0.147 0.079 1.669 0.149 0.086 0.151 0.437 0.081 0.002 0.002 0.003 0.085
  0.008 0.034 0.    1.486 0.015 0.061 0.083 0.848 0.022 0.017 0.105 0.012
  0.004 0.075 0.014 0.027 0.042 0.058]
 [0.    0.    0.    0.001 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.002 0.    0.    0.018 0.291 0.    0.    0.004 0.
  0.    0.    0.001 0.    0.08  0.   ]
 [0.161 0.044 1.514 0.132 0.023 0.105 0.722 0.109 0.044 0.021 0.006 0.153
  0.007 0.003 0.004 0.093 0.001 0.038 0.098 0.923 0.056 0.018 0.117 0.03
  0.013 0.016 0.469 0.004 0.12  1.986]
 [0.157 0.124 0.162 1.564 1.391 0.099 0.19  0.282 0.152 0.    0.001 0.303
  0.    0.001 0.002 1.202 0.    0.001 0.153 0.242 0.03  0.002 0.157 0.001
  0.    0.    0.092 0.    1.026 0.   ]
 [0.001 0.    0.    0.003 0.001 0.    0.001 0.    0.    0.    0.    0.001
  0.    0.    0.    0.081 0.    0.    0.008 0.008 0.    0.    0.01  0.
  0.    0.    0.02  0.    0.005 0.   ]
 [0.    0.    0.    0.001 0.001 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.046 0.002 0.    0.    0.006 0.
  0.    0.    0.003 0.    1.231 0.   ]
 [0.913 1.277 1.872 0.312 2.155 0.095 0.005 0.116 0.001 0.    0.    1.399
  0.001 0.001 0.005 0.621 0.001 0.007 0.143 1.055 0.002 0.001 0.19  0.001
  0.    0.004 0.199 0.003 0.1   0.003]
 [0.809 0.234 0.195 0.233 0.118 0.024 0.023 0.137 0.003 0.001 0.    0.286
  0.006 0.023 0.005 0.307 0.006 0.088 0.116 0.124 0.446 0.001 0.058 0.041
  0.    0.138 0.072 0.004 0.075 0.02 ]
 [0.    0.001 0.    0.002 0.001 0.    0.001 0.    0.001 0.    0.    0.001
  0.    0.    0.001 0.149 0.    0.001 0.117 0.088 0.    0.    0.005 0.
  0.    0.    0.003 0.    0.308 0.   ]
 [1.21  0.071 0.092 0.162 0.099 0.039 0.069 0.272 0.003 0.002 0.002 0.126
  0.    0.032 0.005 0.084 0.005 0.194 0.085 0.095 0.074 0.001 0.088 0.001
  0.001 0.    0.023 0.    0.181 0.093]
 [0.052 0.25  0.011 0.271 0.108 0.161 0.058 0.454 0.005 4.134 1.033 0.242
  0.013 0.331 0.005 0.032 0.007 0.181 0.079 0.084 0.099 0.023 0.189 0.004
  0.001 1.688 0.026 0.005 0.714 0.144]
 [0.496 0.408 0.201 0.221 0.1   1.949 0.089 0.125 0.052 0.001 0.001 0.065
  0.    0.012 0.002 0.132 0.005 0.397 0.205 0.189 0.114 0.002 0.054 0.251
  0.001 0.001 0.586 0.015 1.186 1.946]
 [0.004 0.003 0.001 0.023 0.003 0.01  0.002 0.002 0.001 0.    0.    0.055
  0.    0.    0.001 0.265 0.    0.002 0.261 0.148 0.001 0.    1.525 0.001
  0.    0.    0.005 0.    1.175 0.001]
 [0.231 0.024 0.016 0.134 2.225 0.19  0.033 1.735 0.02  0.003 0.012 2.062
  0.004 0.035 0.004 0.156 0.025 1.04  0.126 0.358 0.009 0.034 0.136 1.515
  0.005 0.005 0.039 0.001 0.046 0.079]
 [0.    0.001 0.    0.    0.    0.    0.001 0.    0.    0.    0.    0.
  0.    0.    0.    0.001 0.    0.    0.091 0.    0.    0.    0.001 0.
  0.    0.    0.002 0.    0.003 0.   ]
 [0.21  0.075 1.82  0.161 0.11  0.111 0.06  0.093 0.056 0.    0.    0.12
  0.    0.001 0.001 0.17  0.    1.128 0.126 0.209 0.038 0.001 0.13  0.003
  0.    0.    0.774 0.001 0.302 0.001]]
[[0.    0.    0.    2.094 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    1.047 0.    0.    0.    1.618 0.
  0.    0.    0.    0.    0.    0.   ]
 [1.06  0.    0.38  0.327 0.    0.    0.    0.399 0.    0.    0.    1.015
  0.    0.    0.    1.61  0.    0.    1.02  0.425 0.    0.    0.    0.
  0.    0.    0.569 0.    0.    0.   ]
 [0.358 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.305
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    1.722 0.    0.    0.926 1.255 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.377
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.425 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.915 1.312 0.    0.    0.    0.
  0.    0.    0.    0.    1.195 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.531 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.729 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [1.034 0.    0.    0.493 0.    2.042 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    1.264 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    1.164 0.    0.    0.    0.
  0.    0.    0.523 0.    0.    0.   ]
 [0.    0.    0.    1.671 0.    0.348 0.    2.588 0.    0.    0.43  0.604
  0.    3.401 0.    0.326 0.    0.47  0.    0.    0.    0.    0.378 0.
  0.    0.46  0.    0.    0.    0.   ]
 [1.07  0.    0.    1.953 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    1.189 0.    0.    0.    0.    2.848 1.138 1.448 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.393 0.    0.    1.393 0.
  0.    0.    0.    0.    0.    0.   ]
 [1.119 0.92  0.    0.    0.    1.81  0.678 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.662 0.    0.    0.    0.    0.
  0.    3.161 0.    0.    1.101 0.448]
 [0.986 2.18  1.864 0.565 0.    0.    0.    1.842 0.    0.    0.    1.89
  0.    0.    0.    0.353 0.    0.    0.335 0.811 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    1.669 0.    0.    0.    0.437 0.    0.    0.    0.    0.
  0.    0.    0.    1.486 0.    0.    0.    0.848 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    1.514 0.    0.    0.    0.722 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.923 0.    0.    0.    0.
  0.    0.    0.469 0.    0.    1.986]
 [0.    0.    0.    1.564 1.391 0.    0.    0.    0.    0.    0.    0.303
  0.    0.    0.    1.202 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    1.026 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    1.231 0.   ]
 [0.913 1.277 1.872 0.312 2.155 0.    0.    0.    0.    0.    0.    1.399
  0.    0.    0.    0.621 0.    0.    0.    1.055 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.809 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.307 0.    0.    0.    0.    0.446 0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.308 0.   ]
 [1.21  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.454 0.    4.134 1.033 0.
  0.    0.331 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    1.688 0.    0.    0.714 0.   ]
 [0.496 0.408 0.    0.    0.    1.949 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.397 0.    0.    0.    0.    0.    0.
  0.    0.    0.586 0.    1.186 1.946]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.525 0.
  0.    0.    0.    0.    1.175 0.   ]
 [0.    0.    0.    0.    2.225 0.    0.    1.735 0.    0.    0.    2.062
  0.    0.    0.    0.    0.    1.04  0.    0.358 0.    0.    0.    1.515
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    1.82  0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    1.128 0.    0.    0.    0.    0.    0.
  0.    0.    0.774 0.    0.302 0.   ]]
{'fdr': 0.3050847457627119, 'tpr': 0.9111111111111111, 'fpr': 0.10434782608695652, 'f1': 0.7884615384615384, 'shd': 43, 'npred': 118, 'ntrue': 90}
[9.110e-04 7.081e-04 2.094e+00 9.777e-04 5.834e-04 1.071e-03 5.901e-04
 5.970e-04 2.593e-05 2.833e-05 1.370e-03 4.920e-05 3.501e-05 1.081e-03
 2.257e-01 2.275e-04 2.737e-04 1.047e+00 2.878e-01 4.082e-04 2.135e-04
 1.618e+00 1.450e-04 1.860e-05 3.307e-05 1.018e-01 1.859e-05 1.503e-01
 4.235e-04 1.060e+00 3.801e-01 3.273e-01 4.939e-04 1.565e-01 1.040e-03
 3.993e-01 1.038e-03 7.471e-06 2.242e-05 1.015e+00 2.738e-04 1.928e-05
 1.610e-03 1.610e+00 1.154e-03 1.103e-03 1.020e+00 4.255e-01 6.867e-04
 7.164e-04 1.810e-01 1.746e-03 1.964e-06 5.271e-04 5.693e-01 2.938e-04
 2.276e-01 4.943e-04 3.577e-01 1.147e-03 2.219e-01 1.074e-03 1.198e-01
 5.614e-04 1.927e-01 3.783e-04 1.095e-04 5.120e-06 3.053e-01 1.150e-04
 2.107e-04 3.488e-05 2.402e-01 1.002e-04 1.076e-03 1.752e-01 2.623e-01
 2.417e-04 1.618e-04 1.701e-01 4.844e-04 5.272e-05 7.415e-05 2.483e-01
 8.922e-04 1.831e-01 1.069e-04 1.381e-04 7.929e-05 2.544e-04 2.822e-04
 1.151e-03 1.453e-03 7.115e-05 3.792e-04 4.464e-05 3.488e-05 8.594e-04
 7.368e-06 2.303e-05 3.401e-04 1.722e+00 1.614e-05 7.298e-05 9.256e-01
 1.255e+00 5.810e-05 3.468e-05 2.577e-01 2.938e-05 1.854e-06 3.381e-05
 5.360e-02 1.527e-04 1.092e-01 5.913e-05 1.948e-01 1.514e-01 2.242e-01
 2.186e-01 1.221e-01 8.810e-03 1.387e-01 7.913e-04 8.613e-05 1.644e-05
 3.769e-01 2.954e-05 3.653e-04 7.282e-04 2.362e-01 1.259e-04 2.493e-04
 1.109e-01 1.937e-01 4.848e-04 2.591e-04 1.087e-01 7.630e-04 3.905e-05
 1.166e-04 1.325e-01 7.829e-05 1.929e-01 1.416e-04 4.247e-01 1.080e-03
 1.376e-03 1.518e-01 9.686e-04 1.348e-03 5.591e-04 1.725e-04 7.927e-06
 3.425e-05 1.072e-03 2.244e-05 6.254e-05 1.904e-04 1.296e-01 1.014e-04
 4.941e-04 9.154e-01 1.312e+00 3.387e-05 4.612e-04 1.224e-01 2.401e-04
 1.635e-05 8.656e-05 5.067e-02 5.015e-05 1.195e+00 2.923e-04 7.220e-02
 2.353e-01 1.495e-01 1.426e-01 6.055e-02 1.181e-01 8.032e-02 5.310e-01
 6.388e-03 2.789e-02 8.818e-02 4.243e-04 3.888e-03 5.486e-04 1.805e-01
 3.524e-04 4.279e-04 7.293e-01 1.304e-01 3.116e-02 2.988e-02 7.904e-02
 3.373e-03 1.166e-04 1.437e-03 9.541e-02 7.619e-05 5.578e-02 4.900e-04
 1.034e+00 4.662e-04 4.854e-03 4.933e-01 9.067e-04 2.042e+00 2.649e-03
 4.343e-04 5.007e-06 3.381e-05 2.962e-03 2.949e-04 1.177e-04 9.780e-04
 2.072e-01 8.742e-04 1.957e-04 1.318e-01 1.264e+00 2.858e-04 8.946e-04
 1.123e-01 5.032e-04 5.270e-06 2.386e-04 2.489e-02 7.122e-05 2.630e-01
 6.244e-04 1.579e-01 2.414e-01 1.279e-01 1.569e-01 1.468e-01 9.161e-02
 9.381e-04 1.725e-01 5.583e-03 9.653e-02 1.383e-01 4.041e-04 1.667e-02
 2.444e-04 2.408e-01 4.831e-04 9.582e-04 1.091e-01 1.164e+00 1.064e-01
 9.520e-02 1.170e-01 1.399e-02 6.456e-04 3.579e-03 5.228e-01 2.168e-04
 1.155e-01 7.136e-04 1.465e-01 1.352e-01 2.071e-01 1.671e+00 5.341e-02
 3.482e-01 1.873e-02 2.588e+00 1.581e-02 4.304e-01 6.037e-01 4.590e-03
 3.401e+00 1.982e-02 3.262e-01 3.157e-03 4.704e-01 1.162e-01 1.832e-01
 2.723e-01 9.470e-02 3.784e-01 1.096e-01 5.026e-04 4.603e-01 2.249e-01
 3.377e-03 2.929e-01 2.773e-01 1.070e+00 9.702e-02 1.467e-01 1.953e+00
 1.603e-01 1.758e-01 3.364e-02 2.003e-01 4.113e-03 8.170e-04 2.399e-01
 6.312e-03 8.359e-02 4.752e-03 1.189e+00 3.511e-03 7.094e-02 2.409e-01
 1.325e-01 2.848e+00 1.138e+00 1.448e+00 7.769e-02 1.194e-03 2.665e-01
 1.439e-01 3.284e-03 9.443e-02 7.475e-02 2.145e-01 1.674e-04 1.596e-03
 2.809e-01 3.512e-04 9.651e-02 1.584e-03 2.746e-01 4.866e-04 3.017e-05
 4.898e-05 2.243e-05 7.744e-05 1.790e-04 2.083e-01 3.072e-04 3.538e-04
 1.871e-01 3.928e-01 1.946e-04 9.331e-05 1.393e+00 1.356e-03 2.142e-05
 1.288e-04 1.374e-02 1.579e-04 1.306e-01 1.539e-04 1.119e+00 9.198e-01
 8.435e-02 1.826e-01 4.872e-03 1.810e+00 6.776e-01 9.787e-02 1.614e-01
 2.749e-02 5.833e-02 2.547e-01 5.709e-03 4.189e-03 1.102e-01 9.735e-03
 1.706e-01 6.620e-01 1.706e-01 1.951e-02 1.436e-02 1.770e-01 5.043e-02
 2.628e-03 3.161e+00 1.111e-01 5.174e-03 1.101e+00 4.484e-01 9.861e-01
 2.180e+00 1.864e+00 5.653e-01 2.711e-02 2.914e-01 1.056e-02 1.842e+00
 5.756e-03 2.340e-04 5.177e-03 1.890e+00 3.828e-03 6.575e-03 3.533e-01
 2.681e-03 2.003e-01 3.346e-01 8.113e-01 1.314e-01 1.631e-02 2.207e-01
 4.852e-03 7.312e-05 2.813e-02 1.169e-01 1.152e-03 2.660e-01 6.643e-02
 1.474e-01 7.893e-02 1.669e+00 1.494e-01 8.601e-02 1.506e-01 4.370e-01
 8.086e-02 1.593e-03 2.463e-03 2.998e-03 8.508e-02 7.742e-03 3.426e-02
 1.486e+00 1.518e-02 6.062e-02 8.251e-02 8.482e-01 2.165e-02 1.732e-02
 1.046e-01 1.197e-02 4.435e-03 7.536e-02 1.431e-02 2.656e-02 4.160e-02
 5.810e-02 1.501e-05 1.011e-04 2.921e-04 7.068e-04 2.812e-04 3.783e-04
 1.993e-04 5.752e-05 2.275e-04 1.902e-05 1.354e-05 2.882e-04 1.099e-05
 9.198e-06 4.978e-05 5.664e-05 3.690e-05 1.751e-02 2.907e-01 3.480e-05
 4.449e-05 4.326e-03 7.317e-05 2.447e-05 2.006e-05 9.734e-04 5.965e-06
 7.992e-02 5.698e-05 1.612e-01 4.374e-02 1.514e+00 1.322e-01 2.286e-02
 1.046e-01 7.221e-01 1.085e-01 4.352e-02 2.112e-02 6.404e-03 1.531e-01
 6.670e-03 3.197e-03 4.364e-03 9.292e-02 3.768e-02 9.785e-02 9.227e-01
 5.589e-02 1.762e-02 1.168e-01 2.962e-02 1.347e-02 1.650e-02 4.693e-01
 4.475e-03 1.195e-01 1.986e+00 1.566e-01 1.237e-01 1.621e-01 1.564e+00
 1.391e+00 9.900e-02 1.900e-01 2.821e-01 1.523e-01 7.528e-05 1.306e-03
 3.026e-01 2.123e-05 6.538e-04 1.732e-03 1.202e+00 1.948e-05 1.535e-01
 2.416e-01 3.035e-02 1.846e-03 1.569e-01 5.477e-04 7.359e-05 1.129e-04
 9.161e-02 3.771e-05 1.026e+00 1.810e-04 1.354e-03 1.243e-04 4.907e-04
 2.771e-03 7.804e-04 2.279e-04 7.238e-04 1.925e-04 3.178e-04 3.630e-05
 3.321e-04 7.251e-04 4.587e-05 5.174e-05 4.760e-04 8.091e-02 7.161e-05
 1.119e-04 8.246e-03 8.722e-05 5.368e-05 9.635e-03 2.927e-04 1.094e-05
 1.722e-04 2.014e-02 1.126e-05 4.605e-03 8.954e-05 3.465e-05 7.874e-05
 3.996e-04 6.541e-04 1.163e-03 9.721e-05 7.659e-05 1.747e-05 2.307e-05
 5.119e-06 2.104e-05 2.473e-04 1.887e-05 1.198e-05 5.488e-05 3.584e-04
 5.864e-05 1.022e-04 4.638e-02 4.207e-05 1.776e-05 6.114e-03 2.476e-05
 3.724e-05 9.408e-06 3.157e-03 3.798e-05 1.231e+00 1.705e-04 9.130e-01
 1.277e+00 1.872e+00 3.118e-01 2.155e+00 9.540e-02 5.189e-03 1.163e-01
 9.439e-04 5.231e-05 3.017e-05 1.399e+00 6.690e-04 1.125e-03 5.453e-03
 6.209e-01 1.431e-03 6.583e-03 1.425e-01 1.055e+00 6.286e-04 1.900e-01
 1.480e-03 1.276e-05 4.306e-03 1.986e-01 3.374e-03 9.971e-02 3.120e-03
 8.087e-01 2.341e-01 1.948e-01 2.328e-01 1.177e-01 2.442e-02 2.263e-02
 1.366e-01 3.073e-03 7.089e-04 8.849e-05 2.861e-01 6.002e-03 2.332e-02
 5.252e-03 3.067e-01 5.580e-03 8.752e-02 1.158e-01 1.240e-01 4.459e-01
 5.785e-02 4.060e-02 3.777e-04 1.381e-01 7.215e-02 4.142e-03 7.548e-02
 2.014e-02 8.348e-05 5.606e-04 4.146e-04 2.205e-03 5.799e-04 3.212e-04
 7.644e-04 3.415e-05 1.308e-03 1.759e-05 1.005e-04 9.966e-04 6.243e-05
 7.469e-06 7.115e-04 1.494e-01 2.314e-04 8.854e-04 1.168e-01 8.776e-02
 3.265e-04 3.490e-05 4.639e-05 3.226e-05 1.347e-04 3.210e-03 7.401e-05
 3.079e-01 2.745e-04 1.210e+00 7.081e-02 9.192e-02 1.615e-01 9.912e-02
 3.901e-02 6.948e-02 2.715e-01 3.306e-03 1.503e-03 2.028e-03 1.263e-01
 2.800e-04 3.217e-02 4.863e-03 8.415e-02 4.611e-03 1.945e-01 8.494e-02
 9.527e-02 7.407e-02 1.314e-03 8.774e-02 5.624e-04 4.627e-04 2.315e-02
 1.368e-04 1.813e-01 9.279e-02 5.167e-02 2.505e-01 1.101e-02 2.711e-01
 1.076e-01 1.608e-01 5.791e-02 4.537e-01 4.756e-03 4.134e+00 1.033e+00
 2.417e-01 1.272e-02 3.313e-01 4.723e-03 3.184e-02 7.473e-03 1.809e-01
 7.881e-02 8.380e-02 9.885e-02 2.255e-02 1.894e-01 3.710e-03 1.688e+00
 2.625e-02 5.241e-03 7.137e-01 1.440e-01 4.956e-01 4.080e-01 2.006e-01
 2.213e-01 1.001e-01 1.949e+00 8.911e-02 1.248e-01 5.215e-02 1.209e-03
 6.091e-04 6.527e-02 8.157e-06 1.210e-02 1.680e-03 1.321e-01 5.028e-03
 3.970e-01 2.055e-01 1.887e-01 1.136e-01 2.306e-03 5.363e-02 2.508e-01
 5.179e-04 5.861e-01 1.502e-02 1.186e+00 1.946e+00 4.155e-03 3.282e-03
 8.776e-04 2.284e-02 2.926e-03 1.002e-02 1.773e-03 1.698e-03 6.569e-04
 9.339e-06 1.027e-04 5.499e-02 1.193e-04 5.283e-05 5.919e-04 2.654e-01
 1.726e-04 2.381e-03 2.615e-01 1.478e-01 8.796e-04 2.628e-04 1.525e+00
 1.300e-03 2.174e-05 2.196e-04 1.905e-04 1.175e+00 5.040e-04 2.306e-01
 2.361e-02 1.561e-02 1.345e-01 2.225e+00 1.898e-01 3.304e-02 1.735e+00
 2.035e-02 3.397e-03 1.202e-02 2.062e+00 4.260e-03 3.499e-02 4.000e-03
 1.563e-01 2.547e-02 1.040e+00 1.257e-01 3.576e-01 9.034e-03 3.389e-02
 1.356e-01 1.515e+00 5.497e-03 4.973e-03 3.927e-02 4.643e-02 7.876e-02
 2.120e-04 5.686e-04 4.696e-04 1.752e-04 3.891e-04 5.975e-05 5.583e-04
 3.763e-05 7.471e-05 8.018e-06 5.427e-05 3.985e-04 1.117e-05 2.644e-05
 5.688e-05 5.405e-04 1.372e-05 4.860e-05 9.110e-02 1.384e-04 1.303e-04
 3.453e-04 1.040e-03 1.360e-04 2.049e-05 8.832e-05 1.827e-03 3.033e-05
 3.322e-05 2.097e-01 7.517e-02 1.820e+00 1.612e-01 1.103e-01 1.105e-01
 6.031e-02 9.276e-02 5.616e-02 4.555e-04 4.367e-04 1.204e-01 1.887e-05
 1.498e-03 1.072e-03 1.698e-01 8.526e-05 1.128e+00 1.256e-01 2.090e-01
 3.803e-02 1.118e-03 1.298e-01 2.779e-03 5.892e-05 1.091e-04 7.745e-01
 6.550e-04 3.024e-01]
[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 1. 0. 0. 1. 0.]
 [1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
  0. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 0. 1. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0.]
aucroc, aucpr (0.9797578347578347, 0.9418826524064284)
cuda
noise_multiplier  0.8  noise_multiplier_b  2.5  noise_multiplier_delta  0.8104408984731079
cuda
Objective function 982.29 = squared loss an data 726.28 + 0.5*rho*h**2 254.631624 + alpha*h 0.000000 + L2reg 0.55 + L1reg 0.82 ; SHD = 415 ; DAG False
total norm for a microbatch 129.78114752346173 clip 1.8511579101054196
total norm for a microbatch 86.31383514561621 clip 60.468551121381005
total norm for a microbatch 84.9507900801504 clip 67.05052109874632
total norm for a microbatch 91.0339309644917 clip 70.05933309637611
total norm for a microbatch 82.8830383421642 clip 77.2811418773206
total norm for a microbatch 148.49348968846027 clip 84.25269781582463
total norm for a microbatch 118.63507726153723 clip 80.99892857621715
total norm for a microbatch 65.90261983586824 clip 90.74489129370419
total norm for a microbatch 146.95584591629137 clip 94.37692767027939
total norm for a microbatch 106.96885799395592 clip 97.46397890872434
total norm for a microbatch 118.42346337871284 clip 106.76283858410466
total norm for a microbatch 111.1763891995188 clip 107.76992378348058
cuda
Objective function 65.15 = squared loss an data 47.13 + 0.5*rho*h**2 15.760726 + alpha*h 0.000000 + L2reg 1.65 + L1reg 0.61 ; SHD = 244 ; DAG False
Proportion of microbatches that were clipped  0.8204424350072662
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 5.614396879897541
iteration 1 in outer loop, alpha = 5.614396879897541, rho = 1.0, h = 5.614396879897541
cuda
noise_multiplier  0.8  noise_multiplier_b  2.5  noise_multiplier_delta  0.8104408984731079
cuda
Objective function 96.68 = squared loss an data 47.13 + 0.5*rho*h**2 15.760726 + alpha*h 31.521452 + L2reg 1.65 + L1reg 0.61 ; SHD = 244 ; DAG False
total norm for a microbatch 92.34072449164064 clip 2.9274048785051345
total norm for a microbatch 119.78159913621332 clip 9.827362307325945
total norm for a microbatch 197.6886473460764 clip 12.751562309647179
total norm for a microbatch 298.89094341483076 clip 133.2426436984955
total norm for a microbatch 175.5059268170135 clip 141.6215839704377
total norm for a microbatch 229.32105265011566 clip 138.57459529925404
total norm for a microbatch 130.8627443294156 clip 140.25419654403282
total norm for a microbatch 162.1505342474802 clip 143.45823406160895
cuda
Objective function 70.57 = squared loss an data 41.02 + 0.5*rho*h**2 6.566435 + alpha*h 20.346183 + L2reg 2.07 + L1reg 0.57 ; SHD = 221 ; DAG False
Proportion of microbatches that were clipped  0.8220828922726162
iteration 1 in inner loop, alpha 5.614396879897541 rho 1.0 h 3.6239302596804492
noise_multiplier  0.8  noise_multiplier_b  2.5  noise_multiplier_delta  0.8104408984731079
cuda
Objective function 129.67 = squared loss an data 41.02 + 0.5*rho*h**2 65.664353 + alpha*h 20.346183 + L2reg 2.07 + L1reg 0.57 ; SHD = 221 ; DAG False
total norm for a microbatch 198.64723649088975 clip 3.259756890234208
total norm for a microbatch 259.86986792159763 clip 182.05305604973225
total norm for a microbatch 306.5113073542741 clip 194.12099256750543
total norm for a microbatch 473.7580104073546 clip 181.30833606137472
total norm for a microbatch 234.6899162506242 clip 180.1052738055064
total norm for a microbatch 208.75412700248665 clip 179.14225395408712
total norm for a microbatch 187.12146324398523 clip 183.97799953270555
total norm for a microbatch 171.18920599646108 clip 178.73406867166835
total norm for a microbatch 189.13713531565685 clip 169.41370932450639
total norm for a microbatch 241.29665316432354 clip 184.1551930892398
total norm for a microbatch 329.91184204026035 clip 175.09179069867287
total norm for a microbatch 231.53958399827806 clip 172.9941816960575
total norm for a microbatch 199.67219090581224 clip 186.5681494536217
cuda
Objective function 71.32 = squared loss an data 43.77 + 0.5*rho*h**2 15.009380 + alpha*h 9.727461 + L2reg 2.30 + L1reg 0.52 ; SHD = 178 ; DAG True
Proportion of microbatches that were clipped  0.827705418877633
iteration 2 in inner loop, alpha 5.614396879897541 rho 10.0 h 1.7325922916883343
noise_multiplier  0.8  noise_multiplier_b  2.5  noise_multiplier_delta  0.8104408984731079
cuda
Objective function 206.40 = squared loss an data 43.77 + 0.5*rho*h**2 150.093802 + alpha*h 9.727461 + L2reg 2.30 + L1reg 0.52 ; SHD = 178 ; DAG True
total norm for a microbatch 359.67134477406063 clip 1.0
total norm for a microbatch 241.19656249326158 clip 6.895783329617075
total norm for a microbatch 199.9403012621241 clip 6.895783329617075
total norm for a microbatch 175.11638040137336 clip 18.477762008719147
total norm for a microbatch 237.31302024617432 clip 31.29476782379229
total norm for a microbatch 163.68703499317328 clip 131.53104764267604
total norm for a microbatch 250.09378394837694 clip 238.34020548396853
total norm for a microbatch 198.72539990817478 clip 228.860078862382
total norm for a microbatch 318.6206237499222 clip 226.34014011359022
total norm for a microbatch 219.80566944875332 clip 214.39708580588777
total norm for a microbatch 346.1674732475585 clip 223.3541338394294
total norm for a microbatch 311.42199796785826 clip 225.2271341048937
total norm for a microbatch 290.7935031143701 clip 207.721022891398
total norm for a microbatch 222.7228769690843 clip 213.25692659126227
total norm for a microbatch 194.57772526808756 clip 213.86110990152613
total norm for a microbatch 323.44488757612385 clip 206.52282238042784
total norm for a microbatch 199.9914033054734 clip 206.48797765350204
cuda
Objective function 75.77 = squared loss an data 46.03 + 0.5*rho*h**2 22.999839 + alpha*h 3.807856 + L2reg 2.49 + L1reg 0.45 ; SHD = 149 ; DAG True
Proportion of microbatches that were clipped  0.8284182305630027
iteration 3 in inner loop, alpha 5.614396879897541 rho 100.0 h 0.678230631849928
iteration 2 in outer loop, alpha = 73.43746006489035, rho = 100.0, h = 0.678230631849928
cuda
noise_multiplier  0.8  noise_multiplier_b  2.5  noise_multiplier_delta  0.8104408984731079
cuda
Objective function 121.77 = squared loss an data 46.03 + 0.5*rho*h**2 22.999839 + alpha*h 49.807535 + L2reg 2.49 + L1reg 0.45 ; SHD = 149 ; DAG True
total norm for a microbatch 347.7875628516591 clip 1.2929899128129856
total norm for a microbatch 351.78179434150246 clip 2.2065959255337204
total norm for a microbatch 334.55512343650764 clip 2.883073826190332
total norm for a microbatch 273.18106438797895 clip 9.253742714706249
total norm for a microbatch 281.6719173940292 clip 46.044480722296804
total norm for a microbatch 297.57248110172816 clip 261.5851081200333
total norm for a microbatch 257.26218849890967 clip 252.86327096167892
total norm for a microbatch 233.291157472769 clip 242.04926809168603
total norm for a microbatch 198.30328035485073 clip 238.03180147147748
total norm for a microbatch 214.65772119942284 clip 246.38673170475005
total norm for a microbatch 238.6930441265023 clip 253.07876804725453
total norm for a microbatch 365.63060434441655 clip 240.79117634872367
total norm for a microbatch 350.7509144477082 clip 227.27936266279755
total norm for a microbatch 272.39679297702565 clip 227.8302824496072
total norm for a microbatch 269.29368613267184 clip 232.84037126367335
cuda
Objective function 88.18 = squared loss an data 45.78 + 0.5*rho*h**2 8.695567 + alpha*h 30.625388 + L2reg 2.65 + L1reg 0.43 ; SHD = 171 ; DAG True
Proportion of microbatches that were clipped  0.8265405143134401
iteration 1 in inner loop, alpha 73.43746006489035 rho 100.0 h 0.4170267917515531
noise_multiplier  0.8  noise_multiplier_b  2.5  noise_multiplier_delta  0.8104408984731079
cuda
Objective function 166.44 = squared loss an data 45.78 + 0.5*rho*h**2 86.955673 + alpha*h 30.625388 + L2reg 2.65 + L1reg 0.43 ; SHD = 171 ; DAG True
total norm for a microbatch 280.97625103408825 clip 1.6994152444932447
total norm for a microbatch 294.0559384401381 clip 3.737997185022944
total norm for a microbatch 253.14403964739572 clip 299.75126348433895
total norm for a microbatch 347.508755204689 clip 299.75126348433895
total norm for a microbatch 398.2168165930216 clip 312.8020536307952
total norm for a microbatch 316.5866020732888 clip 330.4312605578103
total norm for a microbatch 279.7743471961912 clip 319.1553141101846
total norm for a microbatch 295.4887701992399 clip 352.0803023212912
total norm for a microbatch 265.05409141584835 clip 296.13487246243733
total norm for a microbatch 497.2313541623338 clip 282.00091676320966
total norm for a microbatch 298.3922845565193 clip 281.63690070362736
total norm for a microbatch 294.86061487901105 clip 281.63690070362736
total norm for a microbatch 288.4657335050575 clip 278.1705436743855
total norm for a microbatch 342.22742732259013 clip 273.07572910318913
cuda
Objective function 91.71 = squared loss an data 51.53 + 0.5*rho*h**2 21.623276 + alpha*h 15.271911 + L2reg 2.86 + L1reg 0.42 ; SHD = 173 ; DAG True
Proportion of microbatches that were clipped  0.832815611310235
iteration 2 in inner loop, alpha 73.43746006489035 rho 1000.0 h 0.20795805393838052
noise_multiplier  0.8  noise_multiplier_b  2.5  noise_multiplier_delta  0.8104408984731079
cuda
Objective function 286.32 = squared loss an data 51.53 + 0.5*rho*h**2 216.232761 + alpha*h 15.271911 + L2reg 2.86 + L1reg 0.42 ; SHD = 173 ; DAG True
total norm for a microbatch 567.8775814555107 clip 1.3285360296189497
total norm for a microbatch 391.61436907121896 clip 2.342497264749504
total norm for a microbatch 471.46043272873743 clip 87.65018397465717
total norm for a microbatch 556.6570654263762 clip 114.91415144227943
total norm for a microbatch 549.2540234481091 clip 124.55547421293674
total norm for a microbatch 556.1421086611491 clip 514.3930864205687
total norm for a microbatch 383.5317731682298 clip 401.684636954148
total norm for a microbatch 470.26963993022963 clip 351.07740458899997
total norm for a microbatch 321.4050571168031 clip 312.31112859009613
total norm for a microbatch 360.0235338149974 clip 316.3390394297482
total norm for a microbatch 347.4221589071149 clip 322.2165439757832
total norm for a microbatch 267.33843163449063 clip 322.2165439757832
cuda
Objective function 85.22 = squared loss an data 50.54 + 0.5*rho*h**2 25.966323 + alpha*h 5.292220 + L2reg 3.02 + L1reg 0.40 ; SHD = 182 ; DAG True
Proportion of microbatches that were clipped  0.8338250538234591
iteration 3 in inner loop, alpha 73.43746006489035 rho 10000.0 h 0.07206430870029124
iteration 3 in outer loop, alpha = 794.0805470678027, rho = 10000.0, h = 0.07206430870029124
cuda
noise_multiplier  0.8  noise_multiplier_b  2.5  noise_multiplier_delta  0.8104408984731079
cuda
Objective function 137.15 = squared loss an data 50.54 + 0.5*rho*h**2 25.966323 + alpha*h 57.224866 + L2reg 3.02 + L1reg 0.40 ; SHD = 182 ; DAG True
total norm for a microbatch 505.4322806939868 clip 1.0
total norm for a microbatch 644.1505440213355 clip 64.33751086047766
total norm for a microbatch 725.6825704510413 clip 640.959362234784
total norm for a microbatch 827.3316779456936 clip 726.9901704364
total norm for a microbatch 467.77183111016444 clip 424.4749648046942
total norm for a microbatch 440.79864917584126 clip 376.3209070330482
total norm for a microbatch 529.6545728515407 clip 331.06784782990223
total norm for a microbatch 387.16959864083736 clip 355.1822913310827
total norm for a microbatch 393.68885156964325 clip 353.5004312762858
total norm for a microbatch 539.0665980493258 clip 340.1435867373803
total norm for a microbatch 323.95677514702277 clip 356.8316899083882
cuda
Objective function 93.33 = squared loss an data 49.90 + 0.5*rho*h**2 8.015007 + alpha*h 31.792999 + L2reg 3.22 + L1reg 0.41 ; SHD = 197 ; DAG True
Proportion of microbatches that were clipped  0.8336378803527449
iteration 1 in inner loop, alpha 794.0805470678027 rho 10000.0 h 0.04003749915701604
noise_multiplier  0.8  noise_multiplier_b  2.5  noise_multiplier_delta  0.8104408984731079
cuda
Objective function 165.47 = squared loss an data 49.90 + 0.5*rho*h**2 80.150067 + alpha*h 31.792999 + L2reg 3.22 + L1reg 0.41 ; SHD = 197 ; DAG True
total norm for a microbatch 1272.9160510018999 clip 35.839554808996
total norm for a microbatch 1784.0007066391545 clip 125.24951506921897
total norm for a microbatch 3184.3709014553215 clip 959.7479506671381
total norm for a microbatch 3918.0172780762964 clip 1058.3237124612149
total norm for a microbatch 3991.900722863666 clip 1058.3237124612149
total norm for a microbatch 8767.239229135621 clip 7798.507719263981
total norm for a microbatch 5189.857792890557 clip 4575.46657680801
total norm for a microbatch 549.8674300247382 clip 445.2171532610651
total norm for a microbatch 517.9705152100663 clip 313.53945907777427
total norm for a microbatch 404.1278573158299 clip 321.288080001986
total norm for a microbatch 331.2809191644312 clip 315.9969618462194
total norm for a microbatch 398.80495767372906 clip 301.82796495983655
total norm for a microbatch 324.67844246201656 clip 308.39103553754904
cuda
Objective function 71.09 = squared loss an data 59.83 + 0.5*rho*h**2 2.186919 + alpha*h 5.251651 + L2reg 3.43 + L1reg 0.40 ; SHD = 188 ; DAG True
Proportion of microbatches that were clipped  0.8322772118392556
iteration 2 in inner loop, alpha 794.0805470678027 rho 100000.0 h 0.006613499451386673
iteration 4 in outer loop, alpha = 1455.43049220647, rho = 100000.0, h = 0.006613499451386673
cuda
noise_multiplier  0.8  noise_multiplier_b  2.5  noise_multiplier_delta  0.8104408984731079
cuda
Objective function 75.47 = squared loss an data 59.83 + 0.5*rho*h**2 2.186919 + alpha*h 9.625489 + L2reg 3.43 + L1reg 0.40 ; SHD = 188 ; DAG True
total norm for a microbatch 5159.670856354838 clip 1.5800104281720568
total norm for a microbatch 4032.538221614814 clip 2.0639977664832068
total norm for a microbatch 2045.4846854987059 clip 3.2480238231413754
total norm for a microbatch 4196.123412716774 clip 1102.0409157606516
total norm for a microbatch 7041.972617326173 clip 5438.335963975698
total norm for a microbatch 10204.605716493656 clip 9220.769772781332
total norm for a microbatch 9649.720415917416 clip 8149.167978528044
total norm for a microbatch 9615.532824717004 clip 9797.473055802744
total norm for a microbatch 6542.174683182569 clip 6689.616666710004
total norm for a microbatch 4978.6992641782 clip 4638.399660180824
total norm for a microbatch 4709.776163746304 clip 5040.5807089329255
total norm for a microbatch 689.0399802102692 clip 644.800779078467
total norm for a microbatch 322.6373103174259 clip 313.60710749335954
total norm for a microbatch 416.3073318554243 clip 328.9322287650567
cuda
Objective function 76.65 = squared loss an data 63.99 + 0.5*rho*h**2 1.269547 + alpha*h 7.333829 + L2reg 3.63 + L1reg 0.42 ; SHD = 194 ; DAG True
Proportion of microbatches that were clipped  0.8301220295439948
iteration 1 in inner loop, alpha 1455.43049220647 rho 100000.0 h 0.005038941438598954
iteration 5 in outer loop, alpha = 6494.371930805424, rho = 1000000.0, h = 0.005038941438598954
Threshold 0.3
[[0.003 0.989 0.648 0.6   0.871 0.443 0.834 0.009 0.881 0.127 0.008 0.225
  0.011 0.266 0.265 0.201 0.045 0.275 0.172 0.252 0.019 0.586 0.278 0.634
  0.364 0.037 0.022 0.014 0.295 0.182]
 [0.002 0.003 0.232 0.013 0.041 0.1   0.062 0.003 0.195 0.015 0.001 0.018
  0.002 0.013 0.004 0.023 0.002 0.035 0.006 0.008 0.003 0.01  0.021 0.021
  0.039 0.005 0.002 0.004 0.012 0.007]
 [0.004 0.014 0.003 0.008 0.036 0.035 0.024 0.002 0.033 0.009 0.001 0.004
  0.002 0.004 0.004 0.004 0.003 0.011 0.005 0.016 0.002 0.008 0.014 0.006
  0.009 0.002 0.001 0.002 0.004 0.004]
 [0.006 0.196 0.337 0.003 0.083 0.204 0.218 0.002 0.203 0.014 0.002 0.034
  0.005 0.179 0.017 0.071 0.015 0.128 0.011 0.091 0.006 0.078 0.06  0.1
  0.221 0.008 0.006 0.01  0.027 0.02 ]
 [0.002 0.117 0.096 0.045 0.002 0.031 0.097 0.003 0.09  0.007 0.002 0.01
  0.002 0.006 0.005 0.011 0.003 0.005 0.011 0.008 0.002 0.029 0.04  0.013
  0.014 0.002 0.002 0.003 0.007 0.008]
 [0.004 0.044 0.113 0.015 0.124 0.002 0.164 0.003 0.231 0.005 0.001 0.012
  0.001 0.079 0.015 0.007 0.004 0.063 0.004 0.016 0.003 0.055 0.02  0.02
  0.173 0.007 0.004 0.003 0.015 0.008]
 [0.003 0.081 0.142 0.012 0.039 0.022 0.002 0.001 0.083 0.004 0.001 0.01
  0.002 0.003 0.008 0.005 0.002 0.008 0.018 0.005 0.001 0.008 0.021 0.011
  0.014 0.008 0.001 0.003 0.018 0.005]
 [0.26  0.57  0.952 0.902 0.762 0.787 0.817 0.003 0.556 0.171 0.019 0.669
  0.125 0.45  0.235 0.309 0.161 0.652 0.248 0.278 0.116 0.499 0.709 0.407
  0.682 0.128 0.014 0.173 0.465 0.509]
 [0.003 0.018 0.119 0.018 0.046 0.01  0.056 0.003 0.002 0.003 0.002 0.008
  0.002 0.003 0.005 0.01  0.003 0.011 0.009 0.01  0.002 0.015 0.014 0.01
  0.011 0.002 0.002 0.005 0.007 0.004]
 [0.075 0.264 0.589 0.322 0.442 0.538 0.716 0.015 0.818 0.005 0.006 0.146
  0.005 0.329 0.062 0.168 0.059 0.148 0.051 0.21  0.01  0.176 0.159 0.284
  0.383 0.049 0.009 0.015 0.119 0.055]
 [0.286 1.083 1.377 0.709 0.724 1.114 1.446 0.175 1.166 0.763 0.002 0.737
  0.253 0.419 0.405 0.756 0.409 0.812 0.812 0.48  0.242 0.865 1.062 0.661
  0.902 0.184 0.193 0.387 0.307 0.439]
 [0.014 0.127 0.603 0.163 0.222 0.194 0.286 0.003 0.364 0.057 0.005 0.002
  0.007 0.066 0.022 0.118 0.011 0.049 0.148 0.134 0.005 0.177 0.239 0.25
  0.166 0.013 0.008 0.011 0.084 0.027]
 [0.222 1.268 1.493 0.529 0.915 1.123 0.845 0.025 0.955 0.454 0.012 0.436
  0.002 0.548 0.277 0.327 0.466 0.744 0.588 0.499 0.283 0.641 0.783 0.445
  0.521 0.336 0.089 0.339 0.612 0.405]
 [0.021 0.264 0.83  0.027 0.373 0.055 0.58  0.005 0.568 0.037 0.008 0.112
  0.002 0.004 0.039 0.19  0.023 0.085 0.018 0.141 0.013 0.087 0.209 0.13
  0.231 0.032 0.008 0.005 0.036 0.071]
 [0.012 0.389 0.787 0.141 0.451 0.209 0.334 0.007 0.478 0.069 0.006 0.165
  0.008 0.135 0.003 0.254 0.012 0.206 0.184 0.189 0.005 0.17  0.313 0.323
  0.392 0.013 0.012 0.015 0.049 0.087]
 [0.023 0.116 0.51  0.056 0.314 0.326 0.48  0.006 0.295 0.034 0.004 0.04
  0.008 0.018 0.013 0.002 0.011 0.129 0.092 0.211 0.008 0.082 0.198 0.104
  0.212 0.009 0.003 0.013 0.025 0.021]
 [0.104 0.568 0.509 0.242 0.696 0.528 1.06  0.013 0.639 0.061 0.006 0.212
  0.006 0.156 0.18  0.187 0.002 0.313 0.117 0.229 0.013 0.3   0.256 0.64
  0.277 0.088 0.007 0.03  0.293 0.352]
 [0.009 0.131 0.222 0.025 0.348 0.062 0.309 0.005 0.259 0.034 0.003 0.063
  0.002 0.048 0.011 0.026 0.005 0.002 0.012 0.017 0.006 0.081 0.06  0.041
  0.159 0.004 0.004 0.007 0.012 0.01 ]
 [0.029 0.44  0.431 0.288 0.309 0.505 0.155 0.008 0.333 0.079 0.002 0.018
  0.004 0.146 0.019 0.047 0.028 0.209 0.003 0.107 0.008 0.211 0.176 0.161
  0.346 0.006 0.005 0.014 0.088 0.058]
 [0.009 0.225 0.286 0.034 0.261 0.206 0.358 0.009 0.237 0.027 0.005 0.026
  0.004 0.03  0.014 0.01  0.01  0.182 0.03  0.002 0.003 0.047 0.085 0.024
  0.243 0.006 0.005 0.01  0.012 0.026]
 [0.152 0.733 0.962 0.461 1.239 0.905 1.186 0.03  1.018 0.287 0.01  0.339
  0.008 0.186 0.457 0.379 0.236 0.404 0.338 0.778 0.002 0.442 0.432 0.532
  0.68  0.125 0.017 0.107 0.124 0.458]
 [0.002 0.214 0.279 0.062 0.135 0.083 0.235 0.004 0.233 0.024 0.003 0.008
  0.004 0.064 0.017 0.061 0.01  0.039 0.014 0.082 0.007 0.002 0.195 0.03
  0.141 0.012 0.005 0.008 0.016 0.018]
 [0.013 0.192 0.242 0.067 0.104 0.123 0.158 0.002 0.243 0.048 0.002 0.025
  0.003 0.026 0.011 0.014 0.011 0.072 0.027 0.058 0.007 0.017 0.002 0.014
  0.086 0.006 0.001 0.006 0.006 0.018]
 [0.004 0.132 0.338 0.035 0.277 0.183 0.242 0.003 0.24  0.006 0.001 0.014
  0.005 0.026 0.007 0.028 0.003 0.102 0.018 0.121 0.003 0.117 0.181 0.002
  0.18  0.005 0.004 0.007 0.012 0.053]
 [0.008 0.075 0.322 0.01  0.167 0.024 0.183 0.002 0.264 0.007 0.003 0.021
  0.002 0.011 0.006 0.019 0.009 0.021 0.009 0.007 0.002 0.019 0.062 0.016
  0.001 0.005 0.003 0.006 0.011 0.003]
 [0.102 0.525 0.824 0.311 0.5   0.366 0.234 0.022 0.816 0.179 0.01  0.185
  0.005 0.162 0.226 0.279 0.04  0.46  0.492 0.475 0.039 0.268 0.402 0.363
  0.454 0.002 0.033 0.045 0.457 0.291]
 [0.133 0.96  1.42  0.396 0.744 0.62  0.886 0.222 0.911 0.239 0.011 0.366
  0.05  0.234 0.21  0.535 0.27  0.573 0.444 0.272 0.152 0.546 1.487 0.498
  0.788 0.111 0.002 0.068 0.568 0.342]
 [0.189 0.587 1.021 0.296 0.642 0.313 0.651 0.019 0.564 0.198 0.007 0.242
  0.01  0.348 0.2   0.263 0.136 0.347 0.199 0.313 0.044 0.264 0.406 0.379
  0.505 0.076 0.055 0.002 0.248 0.248]
 [0.01  0.266 0.534 0.119 0.507 0.137 0.121 0.006 0.371 0.07  0.006 0.067
  0.003 0.134 0.065 0.15  0.008 0.193 0.051 0.2   0.03  0.2   0.241 0.239
  0.271 0.004 0.005 0.017 0.003 0.035]
 [0.015 0.316 0.724 0.168 0.289 0.331 0.41  0.004 0.422 0.082 0.007 0.136
  0.006 0.056 0.053 0.109 0.009 0.31  0.094 0.147 0.008 0.181 0.219 0.086
  0.526 0.012 0.008 0.015 0.13  0.002]]
[[0.    0.989 0.648 0.6   0.871 0.443 0.834 0.    0.881 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.586 0.    0.634
  0.364 0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.337 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.57  0.952 0.902 0.762 0.787 0.817 0.    0.556 0.    0.    0.669
  0.    0.45  0.    0.309 0.    0.652 0.    0.    0.    0.499 0.709 0.407
  0.682 0.    0.    0.    0.465 0.509]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.589 0.322 0.442 0.538 0.716 0.    0.818 0.    0.    0.
  0.    0.329 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.383 0.    0.    0.    0.    0.   ]
 [0.    1.083 1.377 0.709 0.724 1.114 1.446 0.    1.166 0.763 0.    0.737
  0.    0.419 0.405 0.756 0.409 0.812 0.812 0.48  0.    0.865 1.062 0.661
  0.902 0.    0.    0.387 0.307 0.439]
 [0.    0.    0.603 0.    0.    0.    0.    0.    0.364 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    1.268 1.493 0.529 0.915 1.123 0.845 0.    0.955 0.454 0.    0.436
  0.    0.548 0.    0.327 0.466 0.744 0.588 0.499 0.    0.641 0.783 0.445
  0.521 0.336 0.    0.339 0.612 0.405]
 [0.    0.    0.83  0.    0.373 0.    0.58  0.    0.568 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.389 0.787 0.    0.451 0.    0.334 0.    0.478 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.313 0.323
  0.392 0.    0.    0.    0.    0.   ]
 [0.    0.    0.51  0.    0.314 0.326 0.48  0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.568 0.509 0.    0.696 0.528 1.06  0.    0.639 0.    0.    0.
  0.    0.    0.    0.    0.    0.313 0.    0.    0.    0.3   0.    0.64
  0.    0.    0.    0.    0.    0.352]
 [0.    0.    0.    0.    0.348 0.    0.309 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.44  0.431 0.    0.309 0.505 0.    0.    0.333 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.346 0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.358 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.733 0.962 0.461 1.239 0.905 1.186 0.    1.018 0.    0.    0.339
  0.    0.    0.457 0.379 0.    0.404 0.338 0.778 0.    0.442 0.432 0.532
  0.68  0.    0.    0.    0.    0.458]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.338 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.322 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.525 0.824 0.311 0.5   0.366 0.    0.    0.816 0.    0.    0.
  0.    0.    0.    0.    0.    0.46  0.492 0.475 0.    0.    0.402 0.363
  0.454 0.    0.    0.    0.457 0.   ]
 [0.    0.96  1.42  0.396 0.744 0.62  0.886 0.    0.911 0.    0.    0.366
  0.    0.    0.    0.535 0.    0.573 0.444 0.    0.    0.546 1.487 0.498
  0.788 0.    0.    0.    0.568 0.342]
 [0.    0.587 1.021 0.    0.642 0.313 0.651 0.    0.564 0.    0.    0.
  0.    0.348 0.    0.    0.    0.347 0.    0.313 0.    0.    0.406 0.379
  0.505 0.    0.    0.    0.    0.   ]
 [0.    0.    0.534 0.    0.507 0.    0.    0.    0.371 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.316 0.724 0.    0.    0.331 0.41  0.    0.422 0.    0.    0.
  0.    0.    0.    0.    0.    0.31  0.    0.    0.    0.    0.    0.
  0.526 0.    0.    0.    0.    0.   ]]
{'fdr': 0.806282722513089, 'tpr': 0.4111111111111111, 'fpr': 0.4463768115942029, 'f1': 0.26334519572953735, 'shd': 194, 'npred': 191, 'ntrue': 90}
[9.885e-01 6.476e-01 6.001e-01 8.713e-01 4.431e-01 8.338e-01 9.026e-03
 8.812e-01 1.267e-01 7.906e-03 2.252e-01 1.140e-02 2.662e-01 2.648e-01
 2.008e-01 4.528e-02 2.748e-01 1.723e-01 2.520e-01 1.871e-02 5.856e-01
 2.777e-01 6.344e-01 3.641e-01 3.651e-02 2.180e-02 1.405e-02 2.946e-01
 1.819e-01 2.318e-03 2.321e-01 1.336e-02 4.102e-02 9.995e-02 6.167e-02
 3.499e-03 1.948e-01 1.493e-02 1.050e-03 1.768e-02 1.585e-03 1.319e-02
 4.371e-03 2.277e-02 2.353e-03 3.470e-02 6.074e-03 8.127e-03 2.535e-03
 1.033e-02 2.060e-02 2.079e-02 3.866e-02 4.559e-03 1.569e-03 3.895e-03
 1.158e-02 7.186e-03 4.054e-03 1.350e-02 8.206e-03 3.578e-02 3.515e-02
 2.378e-02 1.907e-03 3.307e-02 8.622e-03 1.157e-03 4.218e-03 1.504e-03
 4.464e-03 3.951e-03 3.688e-03 3.349e-03 1.057e-02 4.925e-03 1.599e-02
 1.828e-03 7.872e-03 1.372e-02 6.477e-03 9.155e-03 2.264e-03 9.925e-04
 1.643e-03 4.339e-03 3.883e-03 5.576e-03 1.958e-01 3.370e-01 8.266e-02
 2.038e-01 2.182e-01 1.778e-03 2.034e-01 1.443e-02 1.996e-03 3.413e-02
 4.994e-03 1.785e-01 1.694e-02 7.051e-02 1.456e-02 1.279e-01 1.086e-02
 9.116e-02 5.814e-03 7.775e-02 6.042e-02 9.974e-02 2.211e-01 7.903e-03
 5.591e-03 9.817e-03 2.684e-02 1.989e-02 2.487e-03 1.171e-01 9.646e-02
 4.482e-02 3.129e-02 9.742e-02 3.027e-03 8.951e-02 6.641e-03 1.788e-03
 1.025e-02 1.864e-03 5.633e-03 4.992e-03 1.061e-02 2.549e-03 4.740e-03
 1.143e-02 8.368e-03 2.165e-03 2.929e-02 4.029e-02 1.322e-02 1.429e-02
 2.377e-03 2.086e-03 2.889e-03 7.035e-03 7.974e-03 4.348e-03 4.417e-02
 1.129e-01 1.497e-02 1.237e-01 1.638e-01 2.535e-03 2.307e-01 4.909e-03
 1.102e-03 1.205e-02 1.200e-03 7.941e-02 1.471e-02 7.195e-03 4.476e-03
 6.262e-02 3.859e-03 1.565e-02 2.730e-03 5.520e-02 1.960e-02 1.987e-02
 1.725e-01 7.050e-03 3.513e-03 2.542e-03 1.549e-02 7.597e-03 2.976e-03
 8.142e-02 1.419e-01 1.162e-02 3.862e-02 2.211e-02 1.305e-03 8.298e-02
 3.551e-03 1.113e-03 1.022e-02 2.324e-03 3.349e-03 7.759e-03 5.302e-03
 2.476e-03 8.392e-03 1.808e-02 5.359e-03 1.130e-03 8.415e-03 2.123e-02
 1.128e-02 1.434e-02 7.763e-03 1.138e-03 2.757e-03 1.774e-02 4.553e-03
 2.603e-01 5.699e-01 9.522e-01 9.022e-01 7.619e-01 7.871e-01 8.169e-01
 5.562e-01 1.714e-01 1.873e-02 6.689e-01 1.252e-01 4.503e-01 2.354e-01
 3.085e-01 1.608e-01 6.522e-01 2.484e-01 2.782e-01 1.157e-01 4.988e-01
 7.088e-01 4.068e-01 6.821e-01 1.285e-01 1.421e-02 1.725e-01 4.652e-01
 5.095e-01 2.539e-03 1.782e-02 1.188e-01 1.792e-02 4.594e-02 1.017e-02
 5.587e-02 2.846e-03 3.263e-03 1.850e-03 8.175e-03 1.809e-03 2.923e-03
 5.020e-03 1.024e-02 3.391e-03 1.145e-02 9.074e-03 1.025e-02 1.992e-03
 1.538e-02 1.415e-02 1.029e-02 1.057e-02 2.243e-03 2.059e-03 5.064e-03
 7.140e-03 3.575e-03 7.492e-02 2.644e-01 5.889e-01 3.222e-01 4.424e-01
 5.378e-01 7.160e-01 1.543e-02 8.178e-01 5.611e-03 1.463e-01 4.651e-03
 3.294e-01 6.207e-02 1.676e-01 5.915e-02 1.485e-01 5.064e-02 2.100e-01
 9.700e-03 1.762e-01 1.595e-01 2.840e-01 3.832e-01 4.947e-02 9.201e-03
 1.474e-02 1.193e-01 5.536e-02 2.857e-01 1.083e+00 1.377e+00 7.092e-01
 7.243e-01 1.114e+00 1.446e+00 1.753e-01 1.166e+00 7.626e-01 7.366e-01
 2.525e-01 4.191e-01 4.048e-01 7.562e-01 4.089e-01 8.120e-01 8.124e-01
 4.800e-01 2.423e-01 8.655e-01 1.062e+00 6.614e-01 9.022e-01 1.839e-01
 1.930e-01 3.868e-01 3.070e-01 4.393e-01 1.354e-02 1.266e-01 6.029e-01
 1.632e-01 2.219e-01 1.939e-01 2.861e-01 3.226e-03 3.639e-01 5.737e-02
 5.351e-03 7.041e-03 6.583e-02 2.242e-02 1.176e-01 1.117e-02 4.885e-02
 1.481e-01 1.345e-01 4.781e-03 1.767e-01 2.388e-01 2.498e-01 1.657e-01
 1.331e-02 7.648e-03 1.066e-02 8.366e-02 2.725e-02 2.223e-01 1.268e+00
 1.493e+00 5.288e-01 9.151e-01 1.123e+00 8.450e-01 2.509e-02 9.550e-01
 4.535e-01 1.178e-02 4.356e-01 5.481e-01 2.765e-01 3.268e-01 4.658e-01
 7.436e-01 5.884e-01 4.989e-01 2.828e-01 6.410e-01 7.827e-01 4.445e-01
 5.213e-01 3.358e-01 8.869e-02 3.392e-01 6.121e-01 4.051e-01 2.118e-02
 2.636e-01 8.303e-01 2.746e-02 3.729e-01 5.525e-02 5.799e-01 5.074e-03
 5.676e-01 3.705e-02 8.356e-03 1.116e-01 2.014e-03 3.906e-02 1.904e-01
 2.268e-02 8.526e-02 1.847e-02 1.408e-01 1.318e-02 8.705e-02 2.089e-01
 1.300e-01 2.309e-01 3.247e-02 8.254e-03 5.180e-03 3.590e-02 7.132e-02
 1.171e-02 3.888e-01 7.869e-01 1.407e-01 4.513e-01 2.087e-01 3.343e-01
 7.237e-03 4.776e-01 6.916e-02 5.551e-03 1.653e-01 7.915e-03 1.345e-01
 2.537e-01 1.162e-02 2.060e-01 1.842e-01 1.891e-01 5.167e-03 1.699e-01
 3.126e-01 3.225e-01 3.916e-01 1.320e-02 1.196e-02 1.467e-02 4.906e-02
 8.711e-02 2.256e-02 1.156e-01 5.100e-01 5.643e-02 3.138e-01 3.261e-01
 4.801e-01 6.169e-03 2.949e-01 3.356e-02 3.714e-03 4.049e-02 7.511e-03
 1.831e-02 1.343e-02 1.097e-02 1.289e-01 9.246e-02 2.114e-01 7.599e-03
 8.214e-02 1.981e-01 1.037e-01 2.117e-01 8.771e-03 3.113e-03 1.260e-02
 2.462e-02 2.101e-02 1.039e-01 5.677e-01 5.089e-01 2.416e-01 6.960e-01
 5.285e-01 1.060e+00 1.255e-02 6.392e-01 6.075e-02 5.805e-03 2.122e-01
 5.677e-03 1.564e-01 1.795e-01 1.875e-01 3.133e-01 1.168e-01 2.290e-01
 1.327e-02 3.001e-01 2.564e-01 6.405e-01 2.771e-01 8.750e-02 6.888e-03
 2.950e-02 2.932e-01 3.517e-01 8.898e-03 1.312e-01 2.223e-01 2.462e-02
 3.484e-01 6.160e-02 3.091e-01 4.943e-03 2.586e-01 3.384e-02 2.768e-03
 6.295e-02 2.498e-03 4.807e-02 1.124e-02 2.632e-02 5.486e-03 1.218e-02
 1.672e-02 5.895e-03 8.053e-02 5.955e-02 4.126e-02 1.595e-01 3.878e-03
 4.040e-03 7.467e-03 1.217e-02 1.048e-02 2.947e-02 4.395e-01 4.314e-01
 2.885e-01 3.085e-01 5.048e-01 1.553e-01 8.287e-03 3.330e-01 7.858e-02
 1.971e-03 1.847e-02 4.386e-03 1.458e-01 1.894e-02 4.665e-02 2.813e-02
 2.093e-01 1.070e-01 7.933e-03 2.105e-01 1.756e-01 1.611e-01 3.460e-01
 5.547e-03 5.203e-03 1.389e-02 8.802e-02 5.755e-02 9.067e-03 2.246e-01
 2.864e-01 3.375e-02 2.609e-01 2.060e-01 3.578e-01 9.093e-03 2.370e-01
 2.721e-02 5.032e-03 2.650e-02 4.475e-03 2.968e-02 1.377e-02 1.027e-02
 9.966e-03 1.823e-01 2.991e-02 3.114e-03 4.731e-02 8.514e-02 2.359e-02
 2.429e-01 6.038e-03 5.471e-03 1.036e-02 1.171e-02 2.578e-02 1.520e-01
 7.331e-01 9.624e-01 4.607e-01 1.239e+00 9.045e-01 1.186e+00 2.972e-02
 1.018e+00 2.875e-01 1.010e-02 3.394e-01 8.355e-03 1.858e-01 4.572e-01
 3.788e-01 2.357e-01 4.041e-01 3.376e-01 7.783e-01 4.424e-01 4.323e-01
 5.319e-01 6.803e-01 1.251e-01 1.714e-02 1.067e-01 1.235e-01 4.578e-01
 2.492e-03 2.144e-01 2.787e-01 6.212e-02 1.346e-01 8.292e-02 2.350e-01
 3.534e-03 2.332e-01 2.387e-02 2.912e-03 7.923e-03 4.322e-03 6.434e-02
 1.740e-02 6.144e-02 1.000e-02 3.938e-02 1.444e-02 8.173e-02 6.673e-03
 1.952e-01 2.962e-02 1.408e-01 1.193e-02 4.728e-03 8.211e-03 1.628e-02
 1.802e-02 1.319e-02 1.917e-01 2.416e-01 6.744e-02 1.044e-01 1.227e-01
 1.584e-01 2.245e-03 2.428e-01 4.779e-02 1.958e-03 2.475e-02 3.038e-03
 2.554e-02 1.057e-02 1.437e-02 1.070e-02 7.225e-02 2.743e-02 5.838e-02
 7.150e-03 1.654e-02 1.394e-02 8.621e-02 6.268e-03 1.182e-03 6.271e-03
 6.473e-03 1.806e-02 4.423e-03 1.319e-01 3.378e-01 3.484e-02 2.769e-01
 1.834e-01 2.417e-01 3.290e-03 2.400e-01 6.271e-03 1.247e-03 1.412e-02
 5.118e-03 2.602e-02 6.510e-03 2.754e-02 3.337e-03 1.019e-01 1.826e-02
 1.207e-01 3.132e-03 1.168e-01 1.808e-01 1.803e-01 4.593e-03 3.556e-03
 7.351e-03 1.190e-02 5.259e-02 8.438e-03 7.526e-02 3.218e-01 1.042e-02
 1.673e-01 2.445e-02 1.833e-01 1.989e-03 2.642e-01 7.479e-03 2.641e-03
 2.105e-02 1.636e-03 1.147e-02 6.082e-03 1.937e-02 8.639e-03 2.118e-02
 9.461e-03 7.267e-03 1.657e-03 1.898e-02 6.161e-02 1.581e-02 5.053e-03
 3.071e-03 5.661e-03 1.054e-02 2.624e-03 1.020e-01 5.252e-01 8.240e-01
 3.107e-01 4.995e-01 3.657e-01 2.340e-01 2.195e-02 8.162e-01 1.791e-01
 1.025e-02 1.847e-01 5.263e-03 1.619e-01 2.258e-01 2.786e-01 3.989e-02
 4.601e-01 4.920e-01 4.751e-01 3.890e-02 2.678e-01 4.022e-01 3.629e-01
 4.540e-01 3.290e-02 4.477e-02 4.569e-01 2.914e-01 1.331e-01 9.604e-01
 1.420e+00 3.960e-01 7.439e-01 6.197e-01 8.861e-01 2.224e-01 9.111e-01
 2.392e-01 1.102e-02 3.659e-01 5.017e-02 2.338e-01 2.099e-01 5.352e-01
 2.702e-01 5.729e-01 4.438e-01 2.723e-01 1.519e-01 5.463e-01 1.487e+00
 4.984e-01 7.884e-01 1.108e-01 6.785e-02 5.682e-01 3.418e-01 1.887e-01
 5.869e-01 1.021e+00 2.961e-01 6.424e-01 3.133e-01 6.512e-01 1.917e-02
 5.644e-01 1.980e-01 6.985e-03 2.420e-01 1.041e-02 3.475e-01 1.996e-01
 2.631e-01 1.359e-01 3.474e-01 1.986e-01 3.131e-01 4.415e-02 2.643e-01
 4.063e-01 3.791e-01 5.053e-01 7.595e-02 5.527e-02 2.479e-01 2.484e-01
 1.019e-02 2.658e-01 5.343e-01 1.193e-01 5.071e-01 1.371e-01 1.212e-01
 6.149e-03 3.712e-01 6.976e-02 6.485e-03 6.689e-02 2.650e-03 1.339e-01
 6.480e-02 1.499e-01 8.260e-03 1.927e-01 5.075e-02 2.001e-01 2.992e-02
 2.000e-01 2.407e-01 2.394e-01 2.705e-01 4.133e-03 5.166e-03 1.745e-02
 3.475e-02 1.536e-02 3.159e-01 7.244e-01 1.683e-01 2.891e-01 3.313e-01
 4.096e-01 4.465e-03 4.216e-01 8.230e-02 6.702e-03 1.358e-01 6.186e-03
 5.630e-02 5.321e-02 1.094e-01 9.411e-03 3.103e-01 9.412e-02 1.470e-01
 8.050e-03 1.812e-01 2.187e-01 8.592e-02 5.260e-01 1.172e-02 7.799e-03
 1.481e-02 1.303e-01]
[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 1. 0. 0. 1. 0.]
 [1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
  0. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 0. 1. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0.]
aucroc, aucpr (0.6298717948717949, 0.19394225369965762)
Iterations 2500
Achieves (6.086687062773559, 1e-05)-DP
