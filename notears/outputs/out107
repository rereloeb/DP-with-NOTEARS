samples  5000  graph  10 20 ER mim  minibatch size  100  noise  1.0  minibatches per NN training  63 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.2478778610411254
iteration 1 in outer loop, alpha = 1.2478778610411254, rho = 1.0, h = 1.2478778610411254
cuda
iteration 1 in inner loop,alpha 1.2478778610411254 rho 1.0 h 0.8084888745241194
iteration 2 in inner loop,alpha 1.2478778610411254 rho 10.0 h 0.33057833071344156
iteration 3 in inner loop,alpha 1.2478778610411254 rho 100.0 h 0.08917599829296385
iteration 2 in outer loop, alpha = 10.16547769033751, rho = 100.0, h = 0.08917599829296385
cuda
iteration 1 in inner loop,alpha 10.16547769033751 rho 100.0 h 0.04477612329798397
iteration 2 in inner loop,alpha 10.16547769033751 rho 1000.0 h 0.01475614729775998
iteration 3 in outer loop, alpha = 24.92162498809749, rho = 1000.0, h = 0.01475614729775998
cuda
iteration 1 in inner loop,alpha 24.92162498809749 rho 1000.0 h 0.006747604373583016
iteration 2 in inner loop,alpha 24.92162498809749 rho 10000.0 h 0.0009845269108446075
iteration 4 in outer loop, alpha = 34.76689409654357, rho = 10000.0, h = 0.0009845269108446075
cuda
iteration 1 in inner loop,alpha 34.76689409654357 rho 10000.0 h 0.0006367139972880409
iteration 2 in inner loop,alpha 34.76689409654357 rho 100000.0 h 0.0002659665090032348
iteration 5 in outer loop, alpha = 300.7334030997784, rho = 1000000.0, h = 0.0002659665090032348
Threshold 0.3
[[0.006 0.    0.    0.    0.497 0.    0.08  0.    0.    1.78 ]
 [2.764 0.006 0.577 0.    0.104 0.003 1.103 0.004 0.    0.993]
 [0.294 0.005 0.007 0.    0.075 0.004 1.208 0.011 0.    0.21 ]
 [1.782 2.985 1.099 0.    0.008 2.619 0.198 2.692 0.003 0.151]
 [0.    0.    0.001 0.    0.005 0.    0.002 0.    0.    0.002]
 [0.388 0.281 0.722 0.    0.043 0.005 0.959 1.04  0.004 0.132]
 [0.009 0.001 0.002 0.    0.983 0.001 0.005 0.001 0.    0.019]
 [0.247 0.252 0.02  0.    0.007 0.001 0.236 0.002 0.008 0.036]
 [0.247 2.116 0.013 0.008 1.483 0.074 0.527 0.043 0.    0.041]
 [0.001 0.    0.002 0.    0.89  0.    0.055 0.001 0.    0.005]]
[[0.    0.    0.    0.    0.497 0.    0.    0.    0.    1.78 ]
 [2.764 0.    0.577 0.    0.    0.    1.103 0.    0.    0.993]
 [0.    0.    0.    0.    0.    0.    1.208 0.    0.    0.   ]
 [1.782 2.985 1.099 0.    0.    2.619 0.    2.692 0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.388 0.    0.722 0.    0.    0.    0.959 1.04  0.    0.   ]
 [0.    0.    0.    0.    0.983 0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    2.116 0.    0.    1.483 0.    0.527 0.    0.    0.   ]
 [0.    0.    0.    0.    0.89  0.    0.    0.    0.    0.   ]]
{'fdr': 0.09523809523809523, 'tpr': 0.95, 'fpr': 0.08, 'f1': 0.9268292682926829, 'shd': 2, 'npred': 21, 'ntrue': 20}
[2.171e-04 2.542e-04 2.300e-05 4.968e-01 3.873e-04 7.987e-02 4.451e-04
 4.830e-06 1.780e+00 2.764e+00 5.767e-01 7.075e-06 1.041e-01 3.219e-03
 1.103e+00 3.582e-03 3.383e-05 9.934e-01 2.938e-01 5.236e-03 3.577e-05
 7.537e-02 3.724e-03 1.208e+00 1.112e-02 1.032e-04 2.100e-01 1.782e+00
 2.985e+00 1.099e+00 7.782e-03 2.619e+00 1.983e-01 2.692e+00 3.356e-03
 1.509e-01 1.818e-04 1.041e-04 9.311e-04 5.426e-06 4.511e-04 1.769e-03
 4.062e-04 1.140e-05 1.845e-03 3.883e-01 2.813e-01 7.218e-01 1.448e-05
 4.333e-02 9.593e-01 1.040e+00 4.466e-03 1.322e-01 8.833e-03 1.071e-03
 1.816e-03 1.383e-05 9.827e-01 7.567e-04 9.749e-04 7.131e-05 1.913e-02
 2.470e-01 2.522e-01 2.039e-02 5.639e-06 6.898e-03 1.284e-03 2.361e-01
 7.577e-03 3.593e-02 2.469e-01 2.116e+00 1.302e-02 7.793e-03 1.483e+00
 7.386e-02 5.273e-01 4.265e-02 4.053e-02 9.944e-04 1.665e-04 2.056e-03
 6.416e-06 8.901e-01 3.087e-04 5.540e-02 6.418e-04 8.262e-06]
[[0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 1. 1. 0. 0. 1. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9657142857142857, 0.9419402177200167)
cuda
1210
cuda
Objective function 188.58 = squared loss an data 11.52 + 0.5*rho*h**2 176.710652 + alpha*h 0.000000 + L2reg 0.19 + L1reg 0.16 ; SHD = 55 ; DAG False
||w||^2 0.08186132131195513
exp ma of ||w||^2 497.9516452513079
||w|| 0.28611417530761235
exp ma of ||w|| 0.23524896665264985
||w||^2 0.19991758379333874
exp ma of ||w||^2 0.10359823888243162
||w|| 0.44712144188501934
exp ma of ||w|| 0.3097781200736852
||w||^2 0.25993154045688904
exp ma of ||w||^2 0.24769408403726328
||w|| 0.5098348168347167
exp ma of ||w|| 0.4746415732665329
cuda
Objective function 9.48 = squared loss an data 9.06 + 0.5*rho*h**2 0.280701 + alpha*h 0.000000 + L2reg 0.07 + L1reg 0.07 ; SHD = 28 ; DAG False
Proportion of microbatches that were clipped  0.7351024948355316
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 0.7492679714925732
iteration 1 in outer loop, alpha = 0.7492679714925732, rho = 1.0, h = 0.7492679714925732
cuda
1210
cuda
Objective function 10.04 = squared loss an data 9.06 + 0.5*rho*h**2 0.280701 + alpha*h 0.561402 + L2reg 0.07 + L1reg 0.07 ; SHD = 28 ; DAG False
||w||^2 0.14647737194599558
exp ma of ||w||^2 86.1056332420467
||w|| 0.3827236234490831
exp ma of ||w|| 1.400603054883992
||w||^2 0.037965310814422525
exp ma of ||w||^2 0.39259432474406875
||w|| 0.1948468906973435
exp ma of ||w|| 0.21759098203052327
||w||^2 0.03482087383387305
exp ma of ||w||^2 0.07805056943591988
||w|| 0.18660352042197126
exp ma of ||w|| 0.2672391432203518
||w||^2 0.20703720405510875
exp ma of ||w||^2 0.1352378215919285
||w|| 0.45501341085193164
exp ma of ||w|| 0.34948869238622016
||w||^2 0.06407951595465454
exp ma of ||w||^2 0.13498680161946253
||w|| 0.2531393212336924
exp ma of ||w|| 0.34988103030604556
cuda
Objective function 9.13 = squared loss an data 8.41 + 0.5*rho*h**2 0.144441 + alpha*h 0.402715 + L2reg 0.11 + L1reg 0.07 ; SHD = 23 ; DAG False
Proportion of microbatches that were clipped  0.7244285945858324
iteration 1 in inner loop, alpha 0.7492679714925732 rho 1.0 h 0.5374780925539877
1210
cuda
Objective function 10.43 = squared loss an data 8.41 + 0.5*rho*h**2 1.444413 + alpha*h 0.402715 + L2reg 0.11 + L1reg 0.07 ; SHD = 23 ; DAG False
||w||^2 23797378.793139674
exp ma of ||w||^2 161316126.72685122
||w|| 4878.255712151596
exp ma of ||w|| 10871.68053560842
||w||^2 4415292.999773084
exp ma of ||w||^2 17389819.27867586
||w|| 2101.2598601251307
exp ma of ||w|| 3302.631753739438
||w||^2 2.0216279053961275
exp ma of ||w||^2 1558.6699883829467
||w|| 1.4218396201386876
exp ma of ||w|| 12.177685399707812
||w||^2 0.04109742781798218
exp ma of ||w||^2 0.46796952202865305
||w|| 0.202725005408761
exp ma of ||w|| 0.2347228718519707
||w||^2 0.05647680309715284
exp ma of ||w||^2 0.06851883756812413
||w|| 0.2376484864188132
exp ma of ||w|| 0.24840158286065195
||w||^2 0.07360911345854788
exp ma of ||w||^2 0.1326564797987386
||w|| 0.27130999513204057
exp ma of ||w|| 0.34732975804368993
||w||^2 0.25610657111250806
exp ma of ||w||^2 0.16397175218918522
||w|| 0.5060697294963492
exp ma of ||w|| 0.3833932285595389
||w||^2 0.4013420373400806
exp ma of ||w||^2 0.1736208935933492
||w|| 0.6335156172819109
exp ma of ||w|| 0.39774917938934096
||w||^2 0.19703424947295942
exp ma of ||w||^2 0.17561226803100247
||w|| 0.44388540128388926
exp ma of ||w|| 0.39690222593459
||w||^2 0.04738222206983283
exp ma of ||w||^2 0.20606154268704416
||w|| 0.21767457837292997
exp ma of ||w|| 0.42875454107011207
cuda
Objective function 9.01 = squared loss an data 8.43 + 0.5*rho*h**2 0.230841 + alpha*h 0.160993 + L2reg 0.14 + L1reg 0.06 ; SHD = 22 ; DAG False
Proportion of microbatches that were clipped  0.728765393116514
iteration 2 in inner loop, alpha 0.7492679714925732 rho 10.0 h 0.21486767880414348
1210
cuda
Objective function 11.09 = squared loss an data 8.43 + 0.5*rho*h**2 2.308406 + alpha*h 0.160993 + L2reg 0.14 + L1reg 0.06 ; SHD = 22 ; DAG False
||w||^2 312217509.7074833
exp ma of ||w||^2 1995959867.0241127
||w|| 17669.677691103574
exp ma of ||w|| 39358.89854654995
||w||^2 11787084.360241063
exp ma of ||w||^2 92418081.667079
||w|| 3433.2323487117883
exp ma of ||w|| 8135.042201206797
||w||^2 3148.2423179321054
exp ma of ||w||^2 76289.14668603957
||w|| 56.10919994022465
exp ma of ||w|| 146.31479684806285
||w||^2 0.05316400851670934
exp ma of ||w||^2 0.3111951050215855
||w|| 0.2305732172580097
exp ma of ||w|| 0.24290267208294591
||w||^2 0.046337271137174604
exp ma of ||w||^2 0.12248747766399115
||w|| 0.2152609373229955
exp ma of ||w|| 0.3279396812050863
||w||^2 0.11325628660382818
exp ma of ||w||^2 0.15761089160604072
||w|| 0.3365357137122718
exp ma of ||w|| 0.3767370596116306
||w||^2 0.2072300669030614
exp ma of ||w||^2 0.21733791502339167
||w|| 0.455225292468533
exp ma of ||w|| 0.44140369007151137
cuda
Objective function 9.14 = squared loss an data 8.71 + 0.5*rho*h**2 0.187656 + alpha*h 0.045902 + L2reg 0.15 + L1reg 0.05 ; SHD = 18 ; DAG True
Proportion of microbatches that were clipped  0.7328149300155521
iteration 3 in inner loop, alpha 0.7492679714925732 rho 100.0 h 0.06126273823788253
iteration 2 in outer loop, alpha = 6.875541795280826, rho = 100.0, h = 0.06126273823788253
cuda
1210
cuda
Objective function 9.52 = squared loss an data 8.71 + 0.5*rho*h**2 0.187656 + alpha*h 0.421215 + L2reg 0.15 + L1reg 0.05 ; SHD = 18 ; DAG True
||w||^2 1313311588.2718966
exp ma of ||w||^2 1346037148.0012789
||w|| 36239.641116764615
exp ma of ||w|| 33498.127856778694
||w||^2 34127196.69424189
exp ma of ||w||^2 184604529.86854836
||w|| 5841.848739418189
exp ma of ||w|| 11272.579617857256
||w||^2 10375548.360743288
exp ma of ||w||^2 129535555.5683929
||w|| 3221.109802652385
exp ma of ||w|| 9356.68667081923
||w||^2 3740912.279034411
exp ma of ||w||^2 17629915.166329898
||w|| 1934.1438103291107
exp ma of ||w|| 3279.322323912169
||w||^2 0.05570231324867098
exp ma of ||w||^2 0.8848508669704523
||w|| 0.23601337514783136
exp ma of ||w|| 0.3049239023652141
v before min max tensor([[ 7.425e+00,  4.662e-01, -1.298e+00,  5.466e-01,  2.833e+00, -6.858e-01,
         -1.740e+00,  2.498e+00,  8.953e-03, -2.472e+00],
        [-1.688e+00,  1.112e+01,  2.985e-02, -2.090e-02, -1.911e+00,  5.386e-01,
         -1.575e+00,  3.381e+00,  1.861e+00, -2.255e+00],
        [ 5.457e+00, -2.129e-01, -1.825e+00, -1.174e+00,  6.852e-01,  1.391e+00,
         -1.877e+00, -6.231e-01, -1.625e-01, -5.416e-01],
        [-3.091e-01, -3.206e-01, -3.121e-02,  8.792e-01, -2.545e+00,  1.817e-01,
          1.574e-01,  1.490e+00, -1.313e+00,  7.433e+00],
        [ 4.428e+01,  2.271e+01, -1.202e+00, -1.802e+00,  1.126e+00,  1.880e+00,
         -5.369e-01, -1.647e+00,  1.574e-01, -1.138e+00],
        [ 2.161e+01,  1.211e+01, -5.751e-01, -1.896e+00, -2.031e+00, -1.393e+00,
         -6.574e-01, -2.063e+00, -1.936e-01,  5.226e-01],
        [-2.466e+00, -2.224e+00,  5.607e+00, -1.184e+00, -1.040e+00, -2.309e+00,
          3.424e-01,  2.512e+00,  2.685e-01, -7.773e-01],
        [ 7.377e+00,  7.130e-01,  2.305e+00, -3.969e-01,  1.358e+01,  1.792e+01,
          2.105e+00, -1.749e+00, -1.595e+00,  4.938e+00],
        [ 2.764e+01, -9.547e-01, -1.723e+00, -2.469e+00,  7.244e+00, -1.749e+00,
          4.592e-01, -1.572e+00, -1.868e+00, -1.622e+00],
        [-2.329e+00,  1.443e+01, -1.646e+00, -1.674e+00, -1.735e+00, -1.336e+00,
          1.587e+00, -1.883e+00,  4.284e+00,  3.698e+00],
        [-1.464e+00,  1.728e+01, -2.467e+00, -6.476e-01, -1.485e+00, -1.316e+00,
         -1.300e-01, -2.481e+00, -3.989e-01, -1.013e+00],
        [-1.212e+00, -1.744e+00, -1.534e+00,  4.931e+00,  2.651e+01, -1.155e+00,
          8.070e-01,  1.279e+00, -1.093e-01,  1.367e+00],
        [ 9.766e-01,  4.274e+01, -1.569e+00, -1.118e-01, -5.551e-01, -1.086e+00,
         -3.767e-01, -1.683e+00, -1.389e+00,  4.210e+00],
        [ 2.277e+00, -1.455e+00,  1.246e+00, -2.001e-01,  9.635e+00, -1.377e+00,
          9.558e-01,  1.560e+00, -1.421e+00,  2.583e+00],
        [-1.061e+00,  3.331e+01,  1.950e+00,  3.248e+00, -1.748e+00,  3.688e+00,
         -1.069e+00, -3.069e-01, -1.614e+00,  3.638e+00],
        [ 2.498e+00,  3.076e+01, -1.523e+00,  5.690e+00,  1.512e+01,  8.532e-01,
         -7.522e-01, -1.257e+00, -1.865e+00, -2.182e+00],
        [ 7.275e+00,  3.555e+01,  8.412e+00, -5.845e-01,  1.343e+00,  8.100e-01,
          1.573e+00,  6.655e+00,  3.029e-01,  1.597e+01],
        [-1.534e+00, -1.630e+00,  1.047e+00, -8.672e-01,  4.675e+00, -1.723e+00,
         -1.830e+00,  3.436e+00, -1.446e+00, -1.537e+00],
        [ 3.300e-01, -4.495e-01, -2.449e+00,  1.829e-02,  1.867e+01, -1.586e+00,
         -1.621e+00, -1.682e+00,  7.954e+00,  2.327e+00],
        [ 6.133e+00,  1.614e+01, -4.553e-01,  1.427e+01, -2.850e-01,  5.724e+00,
         -2.171e+00,  1.183e+00,  1.161e+00,  2.470e-01],
        [ 2.446e+00, -7.543e-01,  1.083e+01, -1.072e+00,  2.142e-01, -3.133e-01,
         -1.934e+00,  1.404e+01, -2.350e-01, -1.386e+00],
        [ 3.302e-01,  5.723e-01,  1.569e+01, -1.595e+00,  6.899e+00,  1.614e+00,
          5.988e+00, -1.340e+00,  2.204e-01,  3.025e+01],
        [ 6.644e-01,  3.913e+00,  1.072e+01,  1.307e+01,  1.429e+00,  5.606e+00,
         -2.376e+00,  8.955e-01, -7.238e-01, -2.711e-01],
        [-1.660e-01,  1.041e+01,  1.265e+02,  7.364e+00,  1.541e+01,  5.226e+00,
          8.479e+00, -1.102e+00,  9.486e-01,  4.888e+00],
        [-3.389e-01, -2.222e+00,  1.904e+01,  1.438e+00,  6.978e-01, -1.099e+00,
          1.183e+00,  3.128e-02, -1.181e+00, -1.201e-01],
        [ 5.542e+00,  8.336e+00, -1.138e+00,  4.319e+00, -1.478e+00,  1.155e+01,
          1.317e+00,  2.094e+00,  9.337e-01, -1.448e+00],
        [ 4.492e+00,  4.860e-01,  4.091e+00, -2.229e+00,  1.877e+01,  2.205e+00,
         -1.326e+00,  5.974e-01, -1.031e+00, -2.089e+00],
        [-1.573e-01, -1.677e+00,  7.465e+01, -1.316e+00, -1.047e+00, -1.774e+00,
          6.378e-01, -1.605e+00, -1.328e+00, -1.454e+00],
        [-1.535e+00, -5.352e-01, -1.557e+00, -1.216e+00, -8.165e-01,  1.044e+01,
          9.010e+00,  2.606e-01,  1.212e+00, -2.405e+00],
        [ 1.279e+00, -1.312e+00,  3.808e+00,  1.576e+01, -1.604e+00, -1.048e+00,
         -1.425e+00, -1.314e-01, -1.741e+00, -1.466e+00],
        [ 3.446e+00,  3.837e+00,  1.484e+00,  2.797e+01,  5.519e+00, -1.385e+00,
         -1.127e+00,  2.310e+01, -3.605e-01,  2.681e+00],
        [ 8.651e+00, -1.551e+00,  4.405e+00,  1.110e+01,  2.059e+01,  4.690e-01,
          4.073e+01,  3.659e+00,  1.341e+00, -1.279e+00],
        [-2.008e+00, -1.184e+00, -1.116e+00,  7.525e+00,  4.965e+00, -1.220e+00,
         -7.457e-01,  4.234e-01,  2.600e+00,  1.064e+00],
        [-8.683e-01, -1.360e+00, -1.031e+00,  6.498e+01, -1.093e+00,  2.051e+01,
          1.119e+01, -1.838e+00, -2.384e-01, -4.014e-01],
        [ 5.839e-01, -1.093e+00,  2.446e+00, -1.569e+00,  1.130e-01, -1.169e+00,
         -1.859e+00,  2.647e+00, -4.077e-01, -1.554e-01],
        [-2.565e+00,  4.561e+00,  3.915e+00,  4.634e-01,  5.911e+01,  1.250e+00,
          3.541e-01,  2.028e+00, -1.524e+00, -1.909e+00],
        [ 8.408e-01,  2.754e+00,  2.471e+01, -1.171e+00, -7.448e-01,  7.807e+00,
         -7.753e-02, -1.781e+00, -2.972e-01,  2.656e-01],
        [ 7.072e-01, -1.879e+00,  1.020e+01, -1.168e+00, -2.165e+00,  2.903e+01,
         -1.400e+00, -2.632e+00,  5.416e+00, -1.773e+00],
        [-1.272e+00,  3.946e+00,  2.475e+00, -2.436e+00, -7.165e-01,  1.292e+00,
          1.773e+00, -1.125e+00,  1.206e+00,  3.207e+00],
        [ 2.155e+00,  2.284e+01,  1.562e+01, -1.995e+00,  5.398e-01,  9.325e-02,
          1.674e+00, -2.233e+00,  2.049e+00, -2.219e+00],
        [-1.571e+00, -1.306e+00, -7.953e-01, -1.289e+00, -3.201e-01,  4.891e+00,
         -1.083e-01, -4.185e-01,  9.433e-01, -1.491e+00],
        [ 7.275e+00, -1.604e+00, -1.876e-01,  1.514e+00,  1.151e+02,  2.242e+00,
          3.075e+00, -9.709e-01, -1.318e+00, -1.190e+00],
        [-4.613e-02,  3.877e+00, -1.482e+00,  1.225e+00,  4.589e+01, -1.511e+00,
         -6.339e-01, -1.606e+00,  1.042e+00,  1.898e+00],
        [ 4.762e+00, -1.305e+00, -9.184e-01, -1.960e+00,  1.697e+01,  2.522e+00,
         -1.500e+00, -1.901e+00, -4.916e-01,  1.096e+01],
        [-1.435e+00, -7.282e-01,  5.425e-01,  5.862e+00, -2.379e+00, -1.638e+00,
          3.374e+00,  1.415e-01, -1.755e+00, -8.823e-01],
        [-1.131e+00,  4.315e+00, -2.042e+00, -1.858e+00,  2.048e+00,  1.795e+00,
          2.444e+00,  6.056e+00,  5.217e-01,  8.189e-01],
        [ 4.932e+00, -1.774e+00, -1.448e+00, -1.752e+00,  3.208e+00, -2.738e+00,
         -8.169e-03, -5.143e-01,  1.222e+00,  6.643e+00],
        [-2.296e+00, -8.565e-01,  5.024e-02, -4.250e-01,  2.952e+00, -9.186e-02,
          4.945e-01, -2.400e+00,  1.545e+00,  2.096e+00],
        [-1.362e+00, -1.806e+00, -6.875e-01, -1.631e+00, -1.537e+00,  3.541e-01,
         -1.099e+00, -1.284e+00, -5.617e-01,  9.566e+00],
        [ 1.816e-01, -8.727e-01, -1.930e+00, -1.105e+00,  1.055e+01, -1.715e+00,
         -8.282e-01,  8.095e+00, -9.485e-01, -1.409e+00],
        [-1.772e+00, -1.550e-01, -1.670e+00,  6.371e+00,  1.600e+00,  7.534e-01,
         -1.606e+00, -1.825e+00, -4.657e-01,  5.809e-03],
        [-7.636e-02, -2.997e-01,  1.816e+01,  8.504e+00,  1.090e+01,  9.683e-01,
         -1.212e+00, -1.364e+00, -3.280e-01, -1.666e+00],
        [-8.993e-01,  2.395e+00, -1.250e+00, -1.296e+00,  1.027e+00, -3.479e-01,
         -1.167e+00, -1.251e+00, -1.461e+00, -1.059e+00],
        [-1.624e+00,  6.100e-01,  1.153e+00, -1.386e+00,  1.600e+01, -1.817e+00,
         -2.033e+00, -5.962e-01, -1.067e+00,  1.960e+00],
        [-1.016e+00,  3.556e+00, -3.766e-01,  1.755e+00,  2.426e+00,  2.433e+00,
         -1.180e+00, -1.675e-01, -4.108e-01, -1.071e+00],
        [-1.976e+00, -1.755e+00,  2.895e+00,  2.167e+00, -5.673e-01,  2.336e+01,
         -2.008e+00, -1.728e+00,  8.860e-01,  1.079e+01],
        [-7.795e-01,  1.942e+00,  2.618e+00, -1.326e+00,  3.320e-01,  9.330e+01,
         -2.406e+00,  1.789e+01, -8.284e-01, -7.569e-01],
        [ 9.072e-01, -8.260e-01,  1.826e+01,  3.113e+00, -3.265e-01, -1.629e+00,
          9.624e-01,  3.568e+00, -9.155e-01, -1.405e+00],
        [-1.481e+00,  5.333e+00,  1.024e+00,  6.104e-01,  2.969e-01,  1.936e+01,
         -2.426e+00,  5.701e-01,  1.390e+01,  5.629e+00],
        [-5.638e-01,  1.574e-01,  1.741e+00, -7.107e-01,  2.543e+00,  1.270e+00,
          3.352e+00,  4.426e+00, -1.815e+00,  3.481e+00],
        [ 1.076e+00,  9.300e-01, -8.940e-01,  1.253e+00,  3.245e+00,  1.246e-01,
          3.020e+00, -1.294e+00,  1.475e+01,  3.675e+00],
        [ 3.579e+00, -4.816e-01,  1.306e+01,  4.643e+00,  1.352e+01,  1.669e+00,
          7.550e+00, -1.153e+00, -1.918e-01,  7.498e+00],
        [-1.207e+00,  1.175e-01, -2.318e+00, -1.229e+00, -7.569e-01, -7.116e-01,
          3.717e+01, -1.093e+00,  4.658e+00,  5.302e+00],
        [-2.712e+00,  1.873e+00, -8.983e-01,  1.588e+00,  1.615e+00, -6.999e-02,
          6.094e-01, -1.032e+00,  6.590e-01,  4.360e+00],
        [-1.229e+00,  1.285e+00, -1.560e-01, -1.393e+00,  5.568e+00, -1.588e+00,
          3.774e+00, -2.197e+00, -5.414e-01,  5.009e+00],
        [-2.066e+00, -9.745e-01, -7.588e-01, -5.875e-01, -1.996e+00,  2.636e+00,
          9.142e+01,  1.017e+01,  5.015e-01, -7.911e-01],
        [-2.227e-01, -1.629e+00,  3.304e+00,  8.031e+00,  1.338e+01,  6.819e+00,
          1.407e+00, -1.856e+00, -1.550e+00, -1.531e+00],
        [-2.036e+00,  3.976e+00, -1.797e+00,  2.524e+00, -1.938e+00,  1.208e-01,
          4.293e+00, -1.595e+00, -4.442e-01,  1.546e+01],
        [ 2.626e+00,  4.702e+00, -1.389e+00,  5.081e+00,  1.129e+01,  4.258e+00,
          3.015e-01,  3.541e+00, -1.587e+00,  5.649e-01],
        [-1.840e+00, -5.835e-01, -1.636e+00, -1.661e+00, -1.284e+00,  6.222e+00,
          1.997e+01, -1.917e+00, -9.898e-01,  5.790e-01],
        [-1.080e+00,  5.961e+00,  2.391e+00,  4.243e-01, -1.091e-01,  2.276e+01,
         -1.095e-01,  6.649e+00, -1.710e+00, -1.370e+00],
        [-6.040e-01, -1.443e-01,  1.219e+00, -1.824e+00, -1.509e+00,  1.249e+01,
          3.102e+00,  2.165e+00,  6.308e+00, -1.360e+00],
        [-1.658e+00, -1.597e+00,  6.856e-01, -1.422e+00, -1.723e+00, -1.536e+00,
          8.082e+00, -4.325e-01,  1.579e+00, -4.618e-01],
        [-2.556e+00, -1.017e+00, -1.232e+00,  1.113e+00,  1.895e+00, -2.746e+00,
          3.074e-01,  7.870e+00,  3.226e+00, -2.094e+00],
        [ 2.486e-01,  9.366e-02, -2.085e+00, -1.074e+00,  1.102e+00,  1.354e+01,
         -6.522e-01,  1.185e+01, -2.102e+00,  3.528e+00],
        [-2.551e+00, -1.294e+00,  4.500e+00,  9.197e-02,  1.413e+00,  1.756e+01,
          3.945e+00,  4.348e+01, -2.243e+00,  1.055e-01],
        [-7.217e-01, -1.587e+00,  5.719e+00, -7.952e-01,  3.076e+00, -2.104e+00,
          1.297e+00, -1.249e+00,  1.149e+00, -3.441e-01],
        [-1.615e+00, -5.012e-01, -1.893e+00, -1.713e+00, -1.761e+00, -1.525e+00,
          1.556e+00,  6.423e+00,  1.919e-01, -3.183e-01],
        [ 1.998e-01, -1.790e+00, -1.760e+00, -1.645e+00, -2.085e+00,  6.083e+00,
         -1.920e-01, -1.168e+00,  5.218e+00, -6.295e-01],
        [-2.143e+00, -7.692e-01, -1.979e-01,  1.183e+01, -9.075e-01, -1.897e+00,
         -2.846e-01,  9.554e+01,  5.265e+00, -1.493e+00],
        [-8.115e-01,  5.847e+00,  6.025e-01, -6.117e-01,  7.392e-01,  3.843e+00,
          9.795e-01, -1.138e+00,  1.372e-01,  9.857e+00],
        [ 8.641e+00,  6.279e+01, -2.519e+00, -1.251e+00, -1.919e+00,  2.453e+00,
         -2.077e-01,  3.155e+00,  3.661e+01,  1.138e+00],
        [ 3.559e+00,  5.668e+00, -8.395e-01,  3.342e+00,  7.769e+00,  1.200e+01,
          1.011e+01,  1.190e-01,  1.647e+01,  8.336e+00],
        [ 1.479e+01,  6.060e-01, -2.397e-01,  7.343e+00,  2.298e+01, -1.342e+00,
         -1.964e+00,  3.650e+00, -2.001e+00, -6.410e-01],
        [-1.924e+00,  3.192e+01, -1.933e+00,  4.604e+00,  6.740e-01, -1.818e+00,
         -7.741e-01, -2.106e+00,  3.394e+01,  1.245e+00],
        [-7.328e-01,  1.169e+01, -2.274e+00, -4.316e-01, -1.779e+00, -1.044e+00,
         -1.866e+00,  1.962e+00,  4.848e+01,  1.684e+01],
        [ 2.693e+00, -1.338e+00,  3.007e+01, -9.498e-01,  1.560e+01,  2.117e-01,
         -3.251e-01, -2.236e+00,  1.006e+00,  1.900e+00],
        [ 4.748e+00,  6.282e+01,  7.672e-01,  6.065e+00,  1.155e+00,  4.053e+00,
          3.819e-01,  1.388e+01,  2.500e+01,  2.841e+00],
        [-1.359e+00,  1.378e+01, -1.187e+00, -1.584e+00,  9.802e-01,  2.671e+01,
          7.680e+00,  1.236e+00,  8.979e+00, -2.196e+00],
        [-8.217e-01, -1.484e+00,  2.845e+00, -1.034e+00,  3.301e+00, -9.146e-01,
          6.055e+00, -2.520e+00,  4.774e+00,  3.748e+00],
        [-1.570e+00,  9.338e+00, -1.800e+00, -2.274e+00,  5.468e-02,  2.973e+00,
          8.228e-01,  6.265e-02, -1.260e+00,  1.028e-01],
        [-2.295e+00, -1.156e+00, -1.346e+00,  1.178e+00,  1.075e+01,  1.862e+00,
         -9.791e-01, -2.124e+00, -2.036e+00,  6.515e+01],
        [-9.784e-01, -1.409e+00,  5.021e+00, -3.322e-01,  1.058e-01,  7.903e-01,
         -1.480e+00, -1.938e+00,  8.127e+00,  1.129e+00],
        [-1.360e+00,  2.115e+00, -1.511e+00,  4.125e+00,  1.605e+00, -1.099e+00,
          1.932e+00, -4.486e-02,  8.860e+00, -6.977e-01],
        [-3.818e-01,  2.306e+00, -7.566e-01,  7.646e+00,  2.042e+00, -1.886e+00,
         -1.094e+00,  3.505e+00, -6.898e-01, -8.040e-01],
        [ 5.661e-01,  2.839e+01, -1.336e+00, -2.160e-01, -2.024e+00,  1.679e+00,
         -5.988e-01, -1.421e+00,  8.333e-02,  6.210e+00],
        [ 1.119e+01, -9.811e-01,  3.171e+00,  8.981e-02,  3.054e-01, -1.743e+00,
          1.352e+01, -5.423e-02,  3.289e-01,  1.076e+01],
        [-1.911e+00,  1.273e+00, -1.375e+00, -1.354e+00,  7.925e-01,  1.596e+01,
          7.550e+00, -8.759e-01,  9.426e-01,  1.139e+01],
        [ 1.127e+00,  2.420e+00, -1.459e+00,  1.444e+00, -1.267e+00, -1.704e+00,
          1.143e+01,  5.013e-01,  2.536e+00, -7.135e-01],
        [-2.407e+00, -1.102e+00,  8.806e-01,  2.258e+00,  1.374e+00,  3.413e+00,
         -2.019e+00, -1.011e+00, -2.132e+00,  2.486e+01]], device='cuda:0')
v tensor([[7.425e+00, 4.662e-01, 1.000e-12, 5.466e-01, 2.833e+00, 1.000e-12,
         1.000e-12, 2.498e+00, 8.953e-03, 1.000e-12],
        [1.000e-12, 1.000e+01, 2.985e-02, 1.000e-12, 1.000e-12, 5.386e-01,
         1.000e-12, 3.381e+00, 1.861e+00, 1.000e-12],
        [5.457e+00, 1.000e-12, 1.000e-12, 1.000e-12, 6.852e-01, 1.391e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 8.792e-01, 1.000e-12, 1.817e-01,
         1.574e-01, 1.490e+00, 1.000e-12, 7.433e+00],
        [1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.126e+00, 1.880e+00,
         1.000e-12, 1.000e-12, 1.574e-01, 1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 5.226e-01],
        [1.000e-12, 1.000e-12, 5.607e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         3.424e-01, 2.512e+00, 2.685e-01, 1.000e-12],
        [7.377e+00, 7.130e-01, 2.305e+00, 1.000e-12, 1.000e+01, 1.000e+01,
         2.105e+00, 1.000e-12, 1.000e-12, 4.938e+00],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 7.244e+00, 1.000e-12,
         4.592e-01, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.587e+00, 1.000e-12, 4.284e+00, 3.698e+00],
        [1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 4.931e+00, 1.000e+01, 1.000e-12,
         8.070e-01, 1.279e+00, 1.000e-12, 1.367e+00],
        [9.766e-01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 4.210e+00],
        [2.277e+00, 1.000e-12, 1.246e+00, 1.000e-12, 9.635e+00, 1.000e-12,
         9.558e-01, 1.560e+00, 1.000e-12, 2.583e+00],
        [1.000e-12, 1.000e+01, 1.950e+00, 3.248e+00, 1.000e-12, 3.688e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 3.638e+00],
        [2.498e+00, 1.000e+01, 1.000e-12, 5.690e+00, 1.000e+01, 8.532e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [7.275e+00, 1.000e+01, 8.412e+00, 1.000e-12, 1.343e+00, 8.100e-01,
         1.573e+00, 6.655e+00, 3.029e-01, 1.000e+01],
        [1.000e-12, 1.000e-12, 1.047e+00, 1.000e-12, 4.675e+00, 1.000e-12,
         1.000e-12, 3.436e+00, 1.000e-12, 1.000e-12],
        [3.300e-01, 1.000e-12, 1.000e-12, 1.829e-02, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 7.954e+00, 2.327e+00],
        [6.133e+00, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 5.724e+00,
         1.000e-12, 1.183e+00, 1.161e+00, 2.470e-01],
        [2.446e+00, 1.000e-12, 1.000e+01, 1.000e-12, 2.142e-01, 1.000e-12,
         1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12],
        [3.302e-01, 5.723e-01, 1.000e+01, 1.000e-12, 6.899e+00, 1.614e+00,
         5.988e+00, 1.000e-12, 2.204e-01, 1.000e+01],
        [6.644e-01, 3.913e+00, 1.000e+01, 1.000e+01, 1.429e+00, 5.606e+00,
         1.000e-12, 8.955e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e+01, 7.364e+00, 1.000e+01, 5.226e+00,
         8.479e+00, 1.000e-12, 9.486e-01, 4.888e+00],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.438e+00, 6.978e-01, 1.000e-12,
         1.183e+00, 3.128e-02, 1.000e-12, 1.000e-12],
        [5.542e+00, 8.336e+00, 1.000e-12, 4.319e+00, 1.000e-12, 1.000e+01,
         1.317e+00, 2.094e+00, 9.337e-01, 1.000e-12],
        [4.492e+00, 4.860e-01, 4.091e+00, 1.000e-12, 1.000e+01, 2.205e+00,
         1.000e-12, 5.974e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
         6.378e-01, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
         9.010e+00, 2.606e-01, 1.212e+00, 1.000e-12],
        [1.279e+00, 1.000e-12, 3.808e+00, 1.000e+01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [3.446e+00, 3.837e+00, 1.484e+00, 1.000e+01, 5.519e+00, 1.000e-12,
         1.000e-12, 1.000e+01, 1.000e-12, 2.681e+00],
        [8.651e+00, 1.000e-12, 4.405e+00, 1.000e+01, 1.000e+01, 4.690e-01,
         1.000e+01, 3.659e+00, 1.341e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 7.525e+00, 4.965e+00, 1.000e-12,
         1.000e-12, 4.234e-01, 2.600e+00, 1.064e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
         1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12],
        [5.839e-01, 1.000e-12, 2.446e+00, 1.000e-12, 1.130e-01, 1.000e-12,
         1.000e-12, 2.647e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 4.561e+00, 3.915e+00, 4.634e-01, 1.000e+01, 1.250e+00,
         3.541e-01, 2.028e+00, 1.000e-12, 1.000e-12],
        [8.408e-01, 2.754e+00, 1.000e+01, 1.000e-12, 1.000e-12, 7.807e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 2.656e-01],
        [7.072e-01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
         1.000e-12, 1.000e-12, 5.416e+00, 1.000e-12],
        [1.000e-12, 3.946e+00, 2.475e+00, 1.000e-12, 1.000e-12, 1.292e+00,
         1.773e+00, 1.000e-12, 1.206e+00, 3.207e+00],
        [2.155e+00, 1.000e+01, 1.000e+01, 1.000e-12, 5.398e-01, 9.325e-02,
         1.674e+00, 1.000e-12, 2.049e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 4.891e+00,
         1.000e-12, 1.000e-12, 9.433e-01, 1.000e-12],
        [7.275e+00, 1.000e-12, 1.000e-12, 1.514e+00, 1.000e+01, 2.242e+00,
         3.075e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 3.877e+00, 1.000e-12, 1.225e+00, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.042e+00, 1.898e+00],
        [4.762e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 2.522e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e-12, 1.000e-12, 5.425e-01, 5.862e+00, 1.000e-12, 1.000e-12,
         3.374e+00, 1.415e-01, 1.000e-12, 1.000e-12],
        [1.000e-12, 4.315e+00, 1.000e-12, 1.000e-12, 2.048e+00, 1.795e+00,
         2.444e+00, 6.056e+00, 5.217e-01, 8.189e-01],
        [4.932e+00, 1.000e-12, 1.000e-12, 1.000e-12, 3.208e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.222e+00, 6.643e+00],
        [1.000e-12, 1.000e-12, 5.024e-02, 1.000e-12, 2.952e+00, 1.000e-12,
         4.945e-01, 1.000e-12, 1.545e+00, 2.096e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.541e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 9.566e+00],
        [1.816e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 8.095e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 6.371e+00, 1.600e+00, 7.534e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 5.809e-03],
        [1.000e-12, 1.000e-12, 1.000e+01, 8.504e+00, 1.000e+01, 9.683e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 2.395e+00, 1.000e-12, 1.000e-12, 1.027e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 6.100e-01, 1.153e+00, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.960e+00],
        [1.000e-12, 3.556e+00, 1.000e-12, 1.755e+00, 2.426e+00, 2.433e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 2.895e+00, 2.167e+00, 1.000e-12, 1.000e+01,
         1.000e-12, 1.000e-12, 8.860e-01, 1.000e+01],
        [1.000e-12, 1.942e+00, 2.618e+00, 1.000e-12, 3.320e-01, 1.000e+01,
         1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12],
        [9.072e-01, 1.000e-12, 1.000e+01, 3.113e+00, 1.000e-12, 1.000e-12,
         9.624e-01, 3.568e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 5.333e+00, 1.024e+00, 6.104e-01, 2.969e-01, 1.000e+01,
         1.000e-12, 5.701e-01, 1.000e+01, 5.629e+00],
        [1.000e-12, 1.574e-01, 1.741e+00, 1.000e-12, 2.543e+00, 1.270e+00,
         3.352e+00, 4.426e+00, 1.000e-12, 3.481e+00],
        [1.076e+00, 9.300e-01, 1.000e-12, 1.253e+00, 3.245e+00, 1.246e-01,
         3.020e+00, 1.000e-12, 1.000e+01, 3.675e+00],
        [3.579e+00, 1.000e-12, 1.000e+01, 4.643e+00, 1.000e+01, 1.669e+00,
         7.550e+00, 1.000e-12, 1.000e-12, 7.498e+00],
        [1.000e-12, 1.175e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e-12, 4.658e+00, 5.302e+00],
        [1.000e-12, 1.873e+00, 1.000e-12, 1.588e+00, 1.615e+00, 1.000e-12,
         6.094e-01, 1.000e-12, 6.590e-01, 4.360e+00],
        [1.000e-12, 1.285e+00, 1.000e-12, 1.000e-12, 5.568e+00, 1.000e-12,
         3.774e+00, 1.000e-12, 1.000e-12, 5.009e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.636e+00,
         1.000e+01, 1.000e+01, 5.015e-01, 1.000e-12],
        [1.000e-12, 1.000e-12, 3.304e+00, 8.031e+00, 1.000e+01, 6.819e+00,
         1.407e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 3.976e+00, 1.000e-12, 2.524e+00, 1.000e-12, 1.208e-01,
         4.293e+00, 1.000e-12, 1.000e-12, 1.000e+01],
        [2.626e+00, 4.702e+00, 1.000e-12, 5.081e+00, 1.000e+01, 4.258e+00,
         3.015e-01, 3.541e+00, 1.000e-12, 5.649e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 6.222e+00,
         1.000e+01, 1.000e-12, 1.000e-12, 5.790e-01],
        [1.000e-12, 5.961e+00, 2.391e+00, 4.243e-01, 1.000e-12, 1.000e+01,
         1.000e-12, 6.649e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.219e+00, 1.000e-12, 1.000e-12, 1.000e+01,
         3.102e+00, 2.165e+00, 6.308e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 6.856e-01, 1.000e-12, 1.000e-12, 1.000e-12,
         8.082e+00, 1.000e-12, 1.579e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.113e+00, 1.895e+00, 1.000e-12,
         3.074e-01, 7.870e+00, 3.226e+00, 1.000e-12],
        [2.486e-01, 9.366e-02, 1.000e-12, 1.000e-12, 1.102e+00, 1.000e+01,
         1.000e-12, 1.000e+01, 1.000e-12, 3.528e+00],
        [1.000e-12, 1.000e-12, 4.500e+00, 9.197e-02, 1.413e+00, 1.000e+01,
         3.945e+00, 1.000e+01, 1.000e-12, 1.055e-01],
        [1.000e-12, 1.000e-12, 5.719e+00, 1.000e-12, 3.076e+00, 1.000e-12,
         1.297e+00, 1.000e-12, 1.149e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.556e+00, 6.423e+00, 1.919e-01, 1.000e-12],
        [1.998e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 6.083e+00,
         1.000e-12, 1.000e-12, 5.218e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e+01, 5.265e+00, 1.000e-12],
        [1.000e-12, 5.847e+00, 6.025e-01, 1.000e-12, 7.392e-01, 3.843e+00,
         9.795e-01, 1.000e-12, 1.372e-01, 9.857e+00],
        [8.641e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 2.453e+00,
         1.000e-12, 3.155e+00, 1.000e+01, 1.138e+00],
        [3.559e+00, 5.668e+00, 1.000e-12, 3.342e+00, 7.769e+00, 1.000e+01,
         1.000e+01, 1.190e-01, 1.000e+01, 8.336e+00],
        [1.000e+01, 6.060e-01, 1.000e-12, 7.343e+00, 1.000e+01, 1.000e-12,
         1.000e-12, 3.650e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12, 4.604e+00, 6.740e-01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e+01, 1.245e+00],
        [1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.962e+00, 1.000e+01, 1.000e+01],
        [2.693e+00, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 2.117e-01,
         1.000e-12, 1.000e-12, 1.006e+00, 1.900e+00],
        [4.748e+00, 1.000e+01, 7.672e-01, 6.065e+00, 1.155e+00, 4.053e+00,
         3.819e-01, 1.000e+01, 1.000e+01, 2.841e+00],
        [1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 9.802e-01, 1.000e+01,
         7.680e+00, 1.236e+00, 8.979e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 2.845e+00, 1.000e-12, 3.301e+00, 1.000e-12,
         6.055e+00, 1.000e-12, 4.774e+00, 3.748e+00],
        [1.000e-12, 9.338e+00, 1.000e-12, 1.000e-12, 5.468e-02, 2.973e+00,
         8.228e-01, 6.265e-02, 1.000e-12, 1.028e-01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.178e+00, 1.000e+01, 1.862e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e-12, 1.000e-12, 5.021e+00, 1.000e-12, 1.058e-01, 7.903e-01,
         1.000e-12, 1.000e-12, 8.127e+00, 1.129e+00],
        [1.000e-12, 2.115e+00, 1.000e-12, 4.125e+00, 1.605e+00, 1.000e-12,
         1.932e+00, 1.000e-12, 8.860e+00, 1.000e-12],
        [1.000e-12, 2.306e+00, 1.000e-12, 7.646e+00, 2.042e+00, 1.000e-12,
         1.000e-12, 3.505e+00, 1.000e-12, 1.000e-12],
        [5.661e-01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.679e+00,
         1.000e-12, 1.000e-12, 8.333e-02, 6.210e+00],
        [1.000e+01, 1.000e-12, 3.171e+00, 8.981e-02, 3.054e-01, 1.000e-12,
         1.000e+01, 1.000e-12, 3.289e-01, 1.000e+01],
        [1.000e-12, 1.273e+00, 1.000e-12, 1.000e-12, 7.925e-01, 1.000e+01,
         7.550e+00, 1.000e-12, 9.426e-01, 1.000e+01],
        [1.127e+00, 2.420e+00, 1.000e-12, 1.444e+00, 1.000e-12, 1.000e-12,
         1.000e+01, 5.013e-01, 2.536e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 8.806e-01, 2.258e+00, 1.374e+00, 3.413e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01]], device='cuda:0')
v before min max tensor([-2.078, -1.049,  6.620, -1.019,  1.024, -1.150,  0.472, -0.611,  5.025,
        -1.409, -1.279,  9.437, -1.311, -0.468, -2.058, -0.768,  0.359, -0.113,
        -1.393, -0.823,  4.220,  1.500, -0.779, -2.347, -2.297,  0.637, -1.279,
         0.648, -1.525,  2.199, -1.949, -1.449, -1.839, -2.197, -0.160,  0.266,
         1.971,  1.316, 10.679, -1.224, -0.267, -0.903, -0.551,  0.375, -2.165,
        26.643, -0.803, -0.744, -1.302, -0.500,  2.506, -0.303, -0.576, -0.112,
        -1.983, -1.778,  0.718, -1.047,  5.127, -1.558, -0.566,  1.107, -1.776,
         8.770, -2.693,  4.522,  0.617,  0.865, -1.167, 10.116, -1.889, -1.300,
        -0.344, -2.186,  0.442, -0.819, -1.743,  1.342, 11.099, -1.496, -0.807,
        -1.288, -0.468, -0.521, -0.181, -1.175,  0.340, -0.673, -1.222, -0.489,
         9.080,  1.762, -1.381,  0.550, -1.437,  4.470, 11.841,  1.249,  1.115,
         4.190], device='cuda:0')
v tensor([1.000e-12, 1.000e-12, 6.620e+00, 1.000e-12, 1.024e+00, 1.000e-12,
        4.724e-01, 1.000e-12, 5.025e+00, 1.000e-12, 1.000e-12, 9.437e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.588e-01, 1.000e-12,
        1.000e-12, 1.000e-12, 4.220e+00, 1.500e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 6.374e-01, 1.000e-12, 6.475e-01, 1.000e-12, 2.199e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.655e-01,
        1.971e+00, 1.316e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 3.753e-01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 2.506e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 7.179e-01, 1.000e-12, 5.127e+00, 1.000e-12,
        1.000e-12, 1.107e+00, 1.000e-12, 8.770e+00, 1.000e-12, 4.522e+00,
        6.170e-01, 8.650e-01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 4.419e-01, 1.000e-12, 1.000e-12, 1.342e+00,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 3.403e-01, 1.000e-12, 1.000e-12, 1.000e-12,
        9.080e+00, 1.762e+00, 1.000e-12, 5.504e-01, 1.000e-12, 4.470e+00,
        1.000e+01, 1.249e+00, 1.115e+00, 4.190e+00], device='cuda:0')
v before min max tensor([[[ 0.286],
         [-1.357],
         [18.750],
         [-2.085],
         [ 1.030],
         [ 5.492],
         [ 4.542],
         [ 3.452],
         [ 0.741],
         [ 6.440]],

        [[12.848],
         [-1.508],
         [-0.701],
         [ 5.647],
         [-1.697],
         [18.252],
         [22.123],
         [11.502],
         [ 3.084],
         [-2.464]],

        [[-1.881],
         [-1.299],
         [23.563],
         [ 0.413],
         [-0.642],
         [18.366],
         [-1.644],
         [ 4.345],
         [-1.695],
         [-2.195]],

        [[ 4.810],
         [ 1.212],
         [-0.986],
         [ 0.565],
         [-0.724],
         [-1.057],
         [-0.394],
         [-1.323],
         [ 5.527],
         [13.644]],

        [[-1.932],
         [ 3.494],
         [-2.178],
         [-1.737],
         [-1.613],
         [ 3.750],
         [-1.577],
         [-0.146],
         [-0.900],
         [-1.361]],

        [[-2.292],
         [ 3.797],
         [ 0.881],
         [ 3.034],
         [-0.746],
         [ 4.902],
         [-1.723],
         [-1.171],
         [ 4.809],
         [ 9.537]],

        [[ 0.258],
         [ 0.332],
         [ 2.363],
         [-2.086],
         [-1.746],
         [-1.590],
         [-2.336],
         [-0.772],
         [-1.598],
         [11.065]],

        [[ 6.274],
         [10.728],
         [-2.099],
         [ 0.934],
         [-1.686],
         [ 7.652],
         [ 0.075],
         [ 2.417],
         [ 1.318],
         [ 3.780]],

        [[ 0.366],
         [ 0.091],
         [ 3.598],
         [ 0.037],
         [-2.126],
         [-0.493],
         [-1.006],
         [ 1.529],
         [ 0.089],
         [-1.623]],

        [[12.778],
         [-0.685],
         [ 9.642],
         [ 2.249],
         [-2.474],
         [ 8.236],
         [ 4.766],
         [19.953],
         [ 7.487],
         [20.184]]], device='cuda:0')
v tensor([[[2.857e-01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.030e+00],
         [5.492e+00],
         [4.542e+00],
         [3.452e+00],
         [7.407e-01],
         [6.440e+00]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [5.647e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [3.084e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [4.129e-01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [4.345e+00],
         [1.000e-12],
         [1.000e-12]],

        [[4.810e+00],
         [1.212e+00],
         [1.000e-12],
         [5.650e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.527e+00],
         [1.000e+01]],

        [[1.000e-12],
         [3.494e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.750e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [3.797e+00],
         [8.807e-01],
         [3.034e+00],
         [1.000e-12],
         [4.902e+00],
         [1.000e-12],
         [1.000e-12],
         [4.809e+00],
         [9.537e+00]],

        [[2.575e-01],
         [3.324e-01],
         [2.363e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[6.274e+00],
         [1.000e+01],
         [1.000e-12],
         [9.338e-01],
         [1.000e-12],
         [7.652e+00],
         [7.492e-02],
         [2.417e+00],
         [1.318e+00],
         [3.780e+00]],

        [[3.665e-01],
         [9.064e-02],
         [3.598e+00],
         [3.746e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.529e+00],
         [8.894e-02],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [9.642e+00],
         [2.249e+00],
         [1.000e-12],
         [8.236e+00],
         [4.766e+00],
         [1.000e+01],
         [7.487e+00],
         [1.000e+01]]], device='cuda:0')
v before min max tensor([[-0.387],
        [18.628],
        [-0.615],
        [-0.393],
        [-2.276],
        [ 2.980],
        [-2.145],
        [ 1.315],
        [ 5.945],
        [63.932]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [2.980e+00],
        [1.000e-12],
        [1.315e+00],
        [5.945e+00],
        [1.000e+01]], device='cuda:0')
a after update for 1 param tensor([[-8.267e-03, -6.450e-03, -5.240e-02, -5.145e-03, -1.042e-02,  3.222e-03,
         -5.318e-02,  9.059e-03,  3.159e-04, -3.699e-02],
        [ 1.251e-02,  3.804e-02, -2.926e-02,  4.641e-03, -6.176e-03, -5.067e-03,
          1.741e-02, -3.932e-02, -6.106e-03,  1.154e-02],
        [ 1.412e-02, -5.050e-03, -1.798e-03, -4.387e-03,  3.284e-03, -9.799e-03,
         -2.373e-02,  6.309e-02,  5.365e-03,  2.989e-03],
        [ 4.187e-04,  4.425e-03,  2.674e-03,  6.128e-03,  3.173e-03, -1.673e-02,
          3.249e-03, -6.087e-03,  1.500e-02,  1.773e-02],
        [ 7.639e-03, -3.508e-02,  1.469e-02,  2.610e-02, -1.203e-02, -7.860e-03,
         -3.930e-02,  2.654e-02,  9.778e-03, -7.593e-03],
        [ 1.760e-02,  1.651e-02,  3.089e-02,  3.333e-02, -1.915e-02, -9.487e-03,
         -4.758e-03, -1.242e-02,  1.763e-02, -1.193e-02],
        [-7.391e-03, -1.840e-02,  2.052e-02,  1.033e-02, -3.298e-02, -1.491e-02,
         -4.653e-03, -5.019e-03, -1.112e-03,  4.002e-04],
        [ 2.202e-02, -1.890e-02,  6.385e-03,  7.945e-03, -4.927e-02, -2.989e-03,
          1.630e-02,  1.236e-03, -2.058e-02, -8.218e-03],
        [-3.110e-03, -1.197e-02,  2.706e-02, -3.389e-02,  1.406e-02,  2.358e-02,
         -3.884e-02,  6.747e-03, -1.601e-02,  1.103e-02],
        [ 8.532e-03,  1.568e-02,  2.436e-02, -1.049e-02,  1.839e-02,  1.151e-02,
         -2.156e-03, -3.088e-02, -1.912e-03,  2.704e-03],
        [ 8.494e-03, -3.793e-02,  7.117e-02,  4.857e-03,  1.656e-02, -6.421e-02,
         -1.680e-03,  1.348e-02, -1.687e-02,  1.838e-02],
        [-3.247e-03, -3.028e-03,  1.734e-02,  2.503e-02,  9.792e-03, -7.133e-03,
         -3.974e-02,  1.996e-02,  2.191e-02, -5.950e-03],
        [ 6.451e-03, -2.014e-02,  1.251e-02, -1.065e-03,  1.287e-02, -7.243e-03,
         -1.307e-02,  1.189e-02, -6.755e-03, -1.921e-03],
        [ 1.483e-02, -8.175e-03,  2.015e-02,  1.383e-02, -1.075e-02, -1.743e-03,
         -1.072e-02,  2.026e-02, -1.034e-02,  2.181e-03],
        [-5.062e-03, -7.159e-03,  1.573e-02,  3.372e-02,  5.472e-03,  4.698e-03,
         -4.750e-03, -1.164e-02,  1.925e-02, -2.283e-02],
        [-1.537e-02,  1.563e-03, -5.306e-03,  1.111e-02,  1.403e-02,  2.029e-02,
         -1.757e-03,  9.564e-03,  9.918e-04,  1.755e-02],
        [ 4.004e-03, -6.099e-03, -3.374e-03, -1.049e-02, -1.183e-02,  1.322e-03,
          7.016e-03, -1.954e-04, -9.769e-03, -2.707e-03],
        [-1.300e-02, -2.756e-03,  3.362e-03,  1.108e-02,  8.870e-03,  1.992e-03,
          6.648e-03,  8.926e-03,  3.223e-03, -2.165e-02],
        [ 1.110e-02,  1.409e-02,  1.461e-03,  2.500e-04, -4.192e-02,  4.521e-03,
         -1.397e-02, -5.240e-02,  4.192e-02,  1.162e-02],
        [ 1.991e-03,  9.781e-03,  1.552e-03,  1.783e-02,  5.865e-04,  3.390e-02,
         -2.860e-02,  1.846e-02, -1.898e-02,  3.976e-03],
        [-6.516e-03,  2.714e-03, -6.613e-03, -1.248e-02, -2.577e-03, -9.393e-03,
         -1.544e-02,  2.747e-02,  4.709e-02, -9.981e-03],
        [-5.757e-02,  2.016e-02,  5.125e-05,  2.475e-02, -2.142e-02, -7.074e-03,
         -7.247e-03,  2.969e-04,  1.028e-02, -3.287e-02],
        [ 9.867e-03,  1.607e-02,  3.064e-03, -1.923e-02, -7.015e-03,  1.927e-03,
         -7.072e-03,  1.303e-02,  1.133e-02,  5.022e-03],
        [ 1.610e-03,  1.405e-02, -2.527e-02, -2.398e-02, -2.696e-03, -8.166e-03,
          5.528e-03, -3.522e-02, -8.428e-03,  6.471e-03],
        [ 3.516e-03, -1.229e-02, -6.411e-03,  7.585e-03,  4.890e-03,  1.696e-02,
          1.508e-03,  1.816e-03,  3.994e-03, -1.674e-02],
        [-4.524e-03, -6.214e-03,  2.267e-03,  2.474e-02,  2.912e-03, -7.577e-03,
          2.096e-04,  1.885e-02,  1.619e-02,  7.910e-04],
        [ 1.888e-02,  2.684e-03,  1.057e-02,  4.824e-03,  1.743e-02,  1.008e-02,
         -1.094e-02, -1.241e-02,  3.689e-02,  1.540e-03],
        [-3.677e-02,  2.150e-02,  1.383e-02,  9.405e-03,  2.008e-02,  1.871e-02,
          1.485e-02, -9.288e-03,  3.930e-02,  1.866e-02],
        [ 9.434e-03, -2.798e-03, -1.199e-02, -2.120e-02,  1.468e-02,  1.754e-02,
         -1.476e-02, -7.439e-03,  1.144e-04,  2.893e-02],
        [ 2.976e-03,  7.136e-03, -5.689e-02,  1.253e-02,  2.144e-02, -3.487e-03,
         -4.913e-03, -9.299e-03, -1.258e-02, -2.597e-02],
        [ 4.916e-03, -1.444e-02, -1.296e-02, -1.799e-02,  3.103e-02,  2.355e-03,
         -1.541e-02, -1.092e-03, -8.680e-03,  1.794e-03],
        [-1.070e-02,  9.586e-03, -4.024e-03, -4.176e-03, -9.275e-03,  9.297e-03,
         -4.144e-02, -2.135e-02, -3.634e-03,  2.039e-03],
        [-4.805e-03,  3.051e-02, -7.965e-03, -2.814e-02,  8.609e-03,  3.487e-03,
         -2.061e-02, -6.651e-03,  1.328e-02, -1.654e-03],
        [-5.195e-03,  3.280e-02,  1.204e-02,  7.968e-04, -6.685e-03,  4.109e-02,
          2.805e-02,  1.706e-02,  1.094e-02,  9.548e-03],
        [-2.625e-03,  1.329e-02, -1.195e-02,  1.099e-02, -1.757e-02, -1.059e-02,
         -7.093e-03, -1.634e-02, -4.232e-02, -7.498e-03],
        [ 3.176e-02, -5.093e-03,  6.025e-03,  4.401e-03,  2.996e-02, -5.134e-03,
          3.566e-04,  3.133e-03, -9.265e-03, -2.479e-02],
        [ 1.068e-02, -2.292e-02,  4.893e-02, -2.703e-02,  2.633e-02, -1.702e-02,
          3.416e-02, -2.467e-03,  4.176e-02, -1.602e-02],
        [-2.090e-02, -2.164e-02,  4.707e-02,  1.108e-02,  1.149e-02,  1.485e-02,
         -5.764e-03,  2.188e-02, -5.811e-03, -1.515e-02],
        [-1.895e-02, -5.621e-03,  1.108e-02,  2.031e-02,  4.609e-02,  3.770e-03,
          8.345e-03, -4.618e-03, -2.961e-02, -1.166e-02],
        [-9.834e-03,  2.780e-03,  3.237e-03,  3.132e-02, -7.736e-04, -1.511e-02,
         -1.572e-03, -4.449e-02,  2.590e-02, -2.060e-03],
        [-2.309e-02,  3.150e-04, -1.523e-02, -6.044e-03,  4.118e-02, -3.958e-02,
          1.492e-02, -1.865e-02,  1.793e-02,  3.132e-02],
        [-4.994e-03,  5.567e-03,  1.095e-02,  2.024e-02, -3.087e-03, -2.749e-02,
         -1.620e-03,  4.396e-02,  3.997e-03, -1.209e-02],
        [-3.886e-03, -1.568e-02, -8.353e-04, -1.586e-03,  8.198e-03,  4.632e-02,
         -2.803e-03, -2.067e-03, -3.644e-02,  3.188e-03],
        [ 8.199e-03, -1.338e-02,  1.309e-02, -3.347e-03,  3.745e-02, -1.433e-03,
          1.104e-01,  5.039e-03,  8.930e-03, -9.263e-03],
        [ 5.602e-02, -6.883e-03, -2.792e-02,  4.510e-03, -3.644e-02,  7.198e-03,
         -2.139e-02,  4.543e-03,  3.171e-02, -1.599e-02],
        [-3.304e-02,  1.341e-02, -1.382e-02, -3.224e-02,  1.877e-03,  9.667e-03,
         -1.775e-02,  3.418e-03,  3.009e-02, -9.194e-04],
        [-3.503e-02,  1.876e-02,  1.737e-03,  4.406e-03,  1.230e-02, -1.469e-03,
         -1.278e-02, -6.769e-03,  2.729e-02, -7.579e-03],
        [ 4.038e-02,  1.001e-03,  9.337e-04,  1.674e-02,  1.860e-03, -5.889e-03,
         -3.317e-03, -1.504e-02, -4.349e-02, -1.017e-03],
        [-1.795e-02,  2.940e-02,  1.118e-02, -4.730e-03, -1.141e-02, -3.943e-03,
         -3.371e-02,  1.928e-02, -3.233e-02, -1.454e-02],
        [-8.206e-03,  1.427e-02,  4.392e-02, -6.806e-03,  7.442e-04, -4.222e-02,
         -2.371e-02, -8.435e-03,  9.759e-03, -1.582e-02],
        [-1.229e-02, -3.398e-03,  1.515e-03, -3.472e-02,  3.694e-03, -2.890e-02,
         -2.273e-03,  5.270e-02, -5.753e-03,  1.567e-03],
        [ 5.919e-03, -2.322e-02,  7.019e-02, -5.539e-02, -1.814e-02, -1.536e-02,
          3.187e-03, -2.471e-02, -7.724e-04,  1.788e-02],
        [-5.325e-03, -3.595e-02,  8.510e-03,  4.689e-03, -1.559e-02, -1.732e-03,
         -2.259e-02,  6.789e-03, -1.646e-02,  1.608e-02],
        [-2.416e-02, -4.655e-02,  1.742e-03,  2.996e-02,  1.046e-02,  9.633e-03,
         -9.741e-03,  2.083e-02, -4.913e-03, -2.912e-02],
        [-3.382e-02,  1.765e-02, -1.865e-02, -1.474e-03, -1.116e-02,  1.635e-04,
         -3.108e-02,  1.937e-02,  8.802e-03, -5.675e-03],
        [-2.042e-02, -6.551e-03, -2.529e-02, -4.265e-02,  4.931e-03,  1.862e-03,
         -9.401e-02, -2.951e-02,  1.242e-02,  6.652e-02],
        [ 1.139e-02,  1.031e-02,  2.482e-03, -1.589e-02,  4.755e-03,  1.236e-02,
         -1.205e-02, -6.545e-03, -1.412e-02,  2.028e-02],
        [ 7.640e-04,  1.833e-03,  3.288e-02, -1.124e-02, -1.608e-03, -3.386e-02,
         -7.002e-03, -1.729e-02,  3.086e-03,  1.761e-02],
        [-3.964e-02, -3.187e-02, -1.871e-02, -1.098e-02, -1.235e-02,  1.780e-03,
          1.964e-02, -1.168e-02,  2.859e-03, -2.457e-02],
        [-5.717e-03,  1.337e-02, -3.454e-03, -4.458e-03, -4.713e-03, -3.419e-03,
         -1.296e-02,  2.201e-03,  2.884e-02, -2.089e-02],
        [-3.172e-03, -1.506e-03,  2.196e-03,  5.028e-03, -2.522e-02,  5.232e-03,
          2.097e-02, -1.699e-02, -8.480e-03, -4.427e-02],
        [-7.073e-03,  8.911e-03, -3.089e-02,  1.610e-03, -1.203e-02, -5.397e-03,
          3.180e-02, -4.122e-02, -2.405e-02,  2.275e-02],
        [ 1.058e-02, -1.205e-02, -4.967e-02,  1.603e-02,  1.371e-02, -9.798e-03,
         -2.246e-04, -3.181e-02, -1.497e-02, -1.851e-03],
        [ 1.952e-02,  2.150e-02,  1.764e-02, -7.050e-03,  8.649e-03, -1.321e-03,
          2.297e-02,  8.387e-05, -1.324e-02, -2.894e-03],
        [ 8.292e-03, -5.295e-03,  7.811e-03, -6.047e-03,  1.690e-02, -3.615e-03,
         -1.546e-02, -4.807e-03,  2.852e-03,  7.713e-03],
        [ 6.318e-03, -5.298e-03,  7.822e-03,  6.243e-03,  1.691e-02,  4.264e-03,
         -2.745e-02, -2.776e-02,  1.611e-02,  1.705e-02],
        [-1.355e-02, -2.309e-03, -6.724e-03, -2.780e-03, -5.488e-03, -2.634e-02,
          1.279e-03,  3.557e-02,  2.991e-02, -1.404e-02],
        [ 5.724e-03,  4.591e-02,  6.789e-02,  5.535e-02,  2.078e-03,  1.563e-03,
          1.114e-02,  7.490e-04, -4.659e-03, -1.301e-02],
        [ 3.535e-03,  1.466e-02, -1.117e-02, -1.624e-02,  1.107e-02,  4.972e-03,
         -2.015e-03, -4.662e-02, -6.610e-03,  1.066e-02],
        [ 5.321e-03, -1.245e-02,  1.263e-02,  5.777e-03,  4.367e-03,  1.462e-02,
         -2.055e-02, -1.218e-02, -4.500e-03, -2.259e-02],
        [ 3.546e-03,  2.943e-05, -1.711e-02, -1.291e-02, -1.351e-03,  4.767e-02,
         -1.088e-03,  1.630e-02, -1.326e-02, -4.316e-02],
        [ 7.726e-03, -1.200e-02, -2.126e-02, -7.967e-04, -5.717e-04,  3.523e-03,
          7.877e-03, -2.434e-02,  3.677e-02, -1.954e-02],
        [-6.030e-03, -1.047e-02, -2.173e-02, -1.711e-02, -3.850e-03,  6.566e-03,
          3.457e-02, -5.122e-03, -1.612e-02,  9.233e-04],
        [ 1.499e-02, -1.504e-03, -2.048e-02, -1.269e-02,  2.135e-02, -9.310e-03,
          6.890e-03,  3.999e-03,  8.630e-03, -3.451e-02],
        [ 1.894e-02, -2.427e-02,  2.116e-02, -8.495e-03,  2.190e-03, -1.743e-02,
         -2.827e-03, -1.097e-02, -5.536e-04,  5.358e-03],
        [ 8.280e-03,  8.565e-03,  4.493e-02, -2.717e-03,  1.199e-04,  2.591e-02,
          2.566e-02,  1.659e-02, -6.343e-04,  7.816e-03],
        [-4.646e-03,  4.377e-02, -2.271e-02,  1.545e-02, -5.359e-03, -4.980e-03,
          1.363e-03,  3.498e-03,  1.746e-02,  1.613e-02],
        [-1.770e-02,  2.512e-02,  1.125e-03,  1.202e-02,  1.664e-02, -2.741e-02,
          9.066e-03,  2.202e-02, -1.101e-03, -1.425e-02],
        [-9.230e-05, -6.180e-03,  5.586e-03,  6.802e-03, -4.529e-02,  2.270e-02,
         -1.092e-02, -1.507e-03,  1.919e-02,  1.901e-03],
        [-2.865e-02, -6.095e-03, -1.037e-03,  1.641e-02, -1.539e-02,  2.098e-03,
          4.514e-02,  2.513e-02,  9.164e-05, -4.611e-02],
        [-1.540e-02,  1.512e-02, -1.373e-02,  5.520e-03,  7.049e-03, -1.558e-02,
          5.109e-03, -1.020e-03,  6.328e-03,  1.053e-02],
        [ 6.060e-03,  6.990e-03, -4.295e-03,  4.527e-03, -6.974e-03,  2.370e-02,
          6.214e-03, -1.197e-02,  2.361e-02,  6.396e-03],
        [-4.366e-03,  1.153e-02, -1.467e-02,  7.295e-03, -1.341e-03, -8.106e-03,
          7.872e-03,  1.142e-02,  2.538e-02,  3.640e-03],
        [ 1.508e-02, -4.511e-03,  1.599e-02, -4.364e-03,  8.249e-03,  1.662e-02,
          1.286e-03, -1.877e-02,  2.677e-02,  1.778e-02],
        [ 1.602e-02,  1.494e-02, -1.663e-02, -1.123e-03,  6.969e-03,  1.767e-02,
         -4.792e-03,  1.954e-03, -1.310e-02, -8.029e-03],
        [-7.096e-03, -3.299e-04,  2.180e-02,  3.087e-03, -2.549e-03,  7.954e-03,
         -1.027e-02,  4.129e-03, -8.524e-03,  1.202e-02],
        [-1.650e-02, -3.313e-03, -8.464e-03, -2.041e-02,  8.278e-03, -2.947e-05,
         -3.681e-03,  1.323e-02,  7.422e-03, -2.034e-02],
        [ 1.009e-03,  3.366e-02, -9.333e-03, -2.933e-02, -5.066e-03,  1.146e-03,
         -8.589e-03, -3.872e-02, -9.131e-03, -3.589e-02],
        [ 6.262e-03,  2.725e-02,  4.072e-02, -6.876e-03, -2.395e-03, -1.340e-02,
         -5.298e-02, -4.772e-02,  2.303e-02, -3.759e-03],
        [ 5.678e-03, -1.831e-02, -1.771e-02, -6.561e-03, -1.596e-02,  8.253e-03,
          9.684e-04, -4.513e-02,  5.647e-03,  2.002e-03],
        [ 1.437e-02, -4.532e-03,  3.406e-04,  8.617e-03, -2.251e-03, -6.006e-02,
         -1.975e-02, -1.230e-03,  3.253e-02,  9.836e-03],
        [-1.026e-02,  5.731e-03, -2.317e-02, -7.993e-03, -2.807e-02,  3.292e-02,
         -6.891e-03, -1.066e-02, -3.008e-02,  1.484e-02],
        [ 1.018e-02, -1.322e-02,  2.934e-03, -2.666e-02, -5.304e-03,  4.769e-02,
         -2.585e-03, -3.948e-02,  2.035e-02, -1.789e-02],
        [-3.504e-03, -5.660e-03, -1.250e-02,  1.149e-02, -8.111e-03, -1.608e-02,
         -7.457e-03,  1.655e-03, -8.168e-03, -3.943e-03],
        [ 1.632e-02,  8.057e-03,  5.569e-03,  1.015e-02,  1.993e-02,  1.752e-02,
          2.880e-03, -4.693e-03, -3.671e-02,  5.269e-03],
        [ 1.891e-02,  7.576e-05,  1.214e-03,  2.574e-02, -2.982e-03, -5.815e-02,
          3.072e-04, -4.651e-03,  9.018e-03,  1.315e-02],
        [-9.264e-03,  6.602e-03, -2.505e-03, -2.977e-03,  2.314e-03,  1.056e-02,
          1.320e-02,  1.328e-02, -5.655e-03, -5.815e-05],
        [-1.921e-02,  3.449e-02, -1.083e-02, -5.875e-03,  6.129e-03,  8.699e-03,
         -2.091e-02, -9.457e-03,  9.051e-03,  1.611e-02],
        [-1.368e-02, -1.571e-02, -1.095e-02,  4.327e-04,  1.989e-02,  1.277e-02,
         -1.867e-02,  3.245e-03, -2.559e-03, -5.155e-04],
        [-5.447e-03,  2.264e-02,  6.064e-03, -1.715e-02, -2.260e-02, -1.920e-02,
          6.320e-03,  1.779e-03,  3.455e-02, -2.869e-02]], device='cuda:0')
s after update for 1 param tensor([[1.577, 0.842, 1.288, 0.519, 1.247, 1.970, 1.882, 1.671, 0.187, 1.912],
        [1.615, 1.885, 0.698, 1.174, 1.571, 1.327, 1.382, 1.413, 0.632, 1.889],
        [1.914, 0.621, 1.492, 1.277, 1.892, 1.551, 1.518, 1.397, 0.126, 1.655],
        [1.244, 0.435, 0.124, 1.872, 1.978, 1.752, 0.846, 0.909, 1.268, 1.824],
        [2.349, 2.060, 1.736, 1.395, 1.738, 1.622, 1.659, 1.437, 1.290, 1.700],
        [2.297, 1.738, 1.689, 1.508, 1.604, 1.554, 1.122, 1.596, 1.151, 1.222],
        [2.084, 1.808, 1.498, 0.964, 1.476, 1.813, 1.241, 2.161, 1.206, 1.712],
        [2.001, 1.684, 1.415, 1.260, 1.788, 1.823, 1.443, 1.753, 1.322, 1.321],
        [2.222, 1.420, 1.790, 1.925, 1.849, 1.507, 1.719, 1.521, 1.445, 1.360],
        [1.832, 2.045, 1.518, 1.304, 1.512, 1.851, 0.914, 1.498, 1.738, 1.958],
        [1.489, 2.360, 1.914, 1.937, 1.555, 1.467, 1.586, 1.926, 1.269, 1.402],
        [0.939, 1.907, 1.186, 2.246, 2.130, 1.250, 1.568, 1.767, 1.546, 1.146],
        [1.497, 1.728, 1.310, 0.121, 0.996, 1.200, 1.210, 1.314, 1.113, 1.378],
        [1.888, 1.717, 1.522, 1.787, 1.804, 1.628, 1.992, 1.457, 1.260, 1.472],
        [1.256, 2.053, 1.344, 1.339, 1.721, 2.130, 1.667, 1.290, 1.461, 1.353],
        [1.557, 1.563, 1.238, 1.037, 1.542, 1.120, 0.614, 1.462, 1.458, 1.724],
        [1.909, 1.797, 1.633, 1.221, 1.326, 0.938, 0.807, 1.777, 1.373, 1.357],
        [1.271, 1.417, 1.589, 1.243, 1.795, 1.592, 1.490, 1.781, 1.119, 1.221],
        [1.629, 1.997, 1.927, 0.070, 1.736, 1.258, 1.493, 1.302, 1.650, 1.362],
        [1.627, 2.276, 1.481, 1.814, 1.572, 1.724, 2.033, 1.567, 1.599, 1.129],
        [1.448, 0.759, 2.197, 0.892, 1.312, 1.480, 1.501, 1.940, 1.333, 1.706],
        [2.141, 1.145, 2.099, 1.277, 1.772, 1.264, 1.847, 1.222, 1.769, 1.737],
        [1.542, 1.828, 1.554, 1.377, 1.685, 1.444, 1.876, 1.654, 1.271, 0.282],
        [1.622, 2.133, 2.326, 1.950, 1.784, 1.460, 1.996, 1.366, 0.957, 1.249],
        [1.778, 2.094, 2.471, 1.460, 1.494, 1.640, 0.906, 1.480, 1.048, 1.734],
        [1.107, 2.110, 1.360, 1.960, 1.670, 1.860, 0.949, 1.795, 1.114, 1.325],
        [1.648, 1.270, 1.696, 1.725, 1.762, 1.884, 1.589, 1.715, 1.512, 1.676],
        [1.923, 1.445, 2.184, 1.043, 1.314, 1.502, 1.240, 1.261, 1.535, 1.566],
        [1.231, 0.848, 1.204, 1.397, 2.199, 2.119, 1.710, 1.262, 0.979, 2.033],
        [1.660, 1.188, 2.301, 1.497, 2.035, 0.838, 1.653, 1.049, 1.460, 1.918],
        [1.372, 1.657, 1.594, 2.012, 1.812, 1.075, 1.276, 1.869, 1.398, 1.827],
        [1.599, 1.325, 1.756, 1.506, 1.905, 1.698, 2.289, 1.374, 1.254, 1.047],
        [1.554, 2.088, 1.371, 2.378, 1.417, 1.697, 1.741, 1.794, 1.444, 0.747],
        [1.804, 1.285, 1.218, 2.401, 1.141, 2.053, 1.990, 1.826, 1.288, 1.858],
        [0.633, 1.258, 1.794, 1.415, 1.416, 1.402, 1.861, 1.401, 2.248, 0.809],
        [1.998, 1.633, 0.886, 1.428, 2.037, 0.980, 0.432, 1.185, 1.383, 1.477],
        [1.632, 0.901, 2.037, 1.818, 1.811, 1.834, 1.785, 1.381, 1.495, 1.653],
        [1.765, 1.702, 1.934, 1.393, 1.684, 2.078, 1.091, 2.112, 1.413, 1.928],
        [1.343, 1.859, 1.524, 1.923, 2.137, 1.846, 2.170, 1.418, 1.719, 1.648],
        [1.745, 2.181, 2.090, 1.573, 1.206, 1.702, 0.654, 1.846, 1.368, 1.755],
        [1.414, 1.166, 1.114, 1.076, 2.281, 1.592, 1.442, 1.244, 1.656, 1.577],
        [1.150, 1.492, 0.321, 0.997, 2.478, 1.894, 1.821, 1.454, 1.259, 1.125],
        [0.886, 1.808, 1.150, 1.367, 2.048, 2.263, 1.012, 1.247, 1.624, 2.016],
        [1.650, 1.834, 1.891, 1.905, 2.055, 1.608, 1.685, 1.602, 1.439, 1.466],
        [1.228, 1.276, 1.438, 1.617, 1.842, 1.325, 2.149, 1.061, 1.573, 1.270],
        [1.461, 1.866, 1.629, 1.683, 1.908, 1.182, 1.589, 1.891, 1.806, 1.332],
        [1.532, 1.378, 1.452, 1.361, 2.110, 2.121, 1.595, 0.842, 1.325, 2.030],
        [1.812, 0.695, 0.076, 1.543, 1.945, 0.567, 0.953, 1.993, 1.600, 1.437],
        [1.528, 1.411, 2.120, 1.542, 1.582, 0.569, 1.557, 1.721, 1.244, 1.787],
        [1.587, 0.696, 1.699, 1.021, 1.223, 1.550, 1.583, 1.426, 1.274, 1.442],
        [1.551, 0.131, 1.311, 2.163, 2.017, 1.845, 1.242, 1.538, 1.077, 0.769],
        [1.528, 1.412, 2.243, 1.564, 1.603, 1.566, 1.662, 1.229, 0.766, 2.077],
        [1.578, 1.653, 0.967, 1.825, 1.369, 0.871, 1.312, 0.969, 1.772, 1.476],
        [1.332, 1.619, 0.410, 1.533, 1.971, 1.631, 1.693, 1.047, 1.592, 1.630],
        [1.334, 1.089, 1.402, 0.973, 1.421, 1.652, 1.181, 1.273, 0.386, 0.969],
        [1.529, 1.559, 1.675, 1.484, 1.047, 1.433, 1.561, 1.724, 0.925, 2.017],
        [1.563, 1.555, 2.027, 1.113, 1.126, 2.041, 1.891, 1.530, 0.929, 1.440],
        [0.802, 0.795, 2.190, 1.536, 1.481, 2.068, 1.800, 1.380, 1.336, 1.145],
        [1.985, 1.959, 1.454, 1.498, 1.803, 1.816, 1.881, 1.512, 1.991, 1.584],
        [0.462, 1.685, 0.857, 1.484, 1.424, 1.651, 1.438, 1.265, 1.843, 1.129],
        [0.994, 1.197, 1.190, 1.810, 1.930, 1.344, 1.761, 1.657, 2.074, 1.714],
        [1.260, 1.351, 1.458, 1.803, 2.253, 1.202, 1.891, 1.265, 1.353, 1.603],
        [0.962, 1.428, 1.795, 0.962, 1.771, 1.036, 1.743, 1.339, 1.768, 1.880],
        [2.121, 1.653, 0.786, 0.723, 1.442, 1.275, 2.053, 1.712, 1.825, 1.961],
        [1.150, 1.567, 1.531, 1.172, 1.845, 1.882, 1.802, 1.704, 0.719, 1.357],
        [1.664, 1.599, 1.209, 0.680, 2.236, 1.522, 2.266, 2.293, 1.545, 1.514],
        [1.519, 1.546, 1.499, 1.512, 1.707, 1.923, 2.121, 1.916, 1.532, 1.675],
        [1.591, 2.136, 1.537, 1.156, 1.537, 1.320, 1.671, 1.596, 1.516, 1.944],
        [1.311, 1.818, 1.353, 1.734, 1.767, 1.080, 1.130, 2.008, 1.240, 1.741],
        [1.423, 1.062, 1.465, 1.393, 1.636, 1.728, 2.308, 1.842, 1.658, 1.539],
        [1.472, 1.869, 1.355, 1.308, 0.108, 2.389, 0.713, 2.185, 1.384, 1.652],
        [0.909, 1.310, 1.657, 1.506, 1.682, 1.232, 1.468, 1.706, 1.590, 1.456],
        [1.313, 1.324, 1.722, 1.630, 1.900, 1.226, 1.558, 1.486, 1.941, 0.410],
        [2.115, 1.483, 1.695, 1.110, 1.306, 2.132, 1.308, 2.100, 1.445, 1.636],
        [1.170, 1.915, 1.637, 1.484, 1.592, 1.835, 1.168, 2.427, 2.001, 1.443],
        [1.975, 1.006, 2.085, 1.378, 0.953, 1.934, 1.325, 2.321, 1.994, 1.179],
        [1.218, 1.582, 1.271, 1.034, 1.525, 2.011, 0.855, 1.352, 1.692, 2.175],
        [1.390, 1.646, 1.505, 1.603, 1.854, 1.180, 1.593, 2.043, 0.260, 0.734],
        [1.668, 1.783, 1.379, 1.434, 1.650, 1.715, 1.641, 1.194, 1.837, 0.960],
        [1.679, 0.907, 1.347, 1.923, 0.863, 1.867, 1.468, 2.383, 1.028, 1.653],
        [1.943, 2.420, 1.539, 1.861, 1.496, 1.297, 1.201, 1.147, 1.488, 2.131],
        [1.601, 1.932, 1.997, 0.969, 1.724, 1.523, 1.446, 1.372, 2.550, 1.842],
        [1.882, 1.777, 1.581, 1.069, 1.972, 1.537, 1.851, 1.707, 2.127, 1.525],
        [2.136, 1.687, 1.550, 1.892, 1.937, 1.394, 1.581, 2.106, 1.831, 2.008],
        [1.494, 2.056, 1.565, 1.398, 1.341, 1.578, 1.831, 1.843, 2.435, 1.615],
        [1.283, 2.155, 1.798, 1.331, 1.706, 0.894, 1.454, 1.314, 2.345, 1.642],
        [2.007, 1.715, 1.573, 1.166, 1.977, 1.614, 1.165, 1.745, 2.131, 1.741],
        [1.569, 2.339, 1.622, 1.726, 1.433, 1.229, 1.932, 1.901, 1.983, 1.189],
        [1.064, 2.052, 1.118, 1.529, 1.079, 1.754, 1.883, 1.611, 2.245, 1.700],
        [0.857, 1.802, 1.849, 1.379, 1.847, 1.409, 1.803, 1.951, 2.172, 1.397],
        [1.453, 1.994, 1.570, 1.872, 0.180, 1.925, 1.252, 1.595, 1.151, 1.501],
        [1.776, 1.368, 1.152, 0.977, 2.118, 1.261, 1.364, 1.683, 1.644, 2.188],
        [2.161, 1.658, 1.704, 1.309, 0.436, 1.899, 1.453, 1.703, 2.038, 1.805],
        [1.359, 1.902, 1.407, 1.679, 1.439, 1.171, 1.216, 0.390, 1.822, 2.030],
        [1.877, 1.765, 0.779, 1.838, 1.618, 1.770, 1.117, 1.948, 1.347, 1.809],
        [1.622, 1.492, 1.403, 1.393, 1.698, 1.648, 2.132, 1.250, 1.648, 2.030],
        [1.731, 1.337, 1.544, 1.032, 1.713, 1.802, 1.764, 1.696, 1.050, 2.041],
        [1.536, 1.929, 1.183, 2.027, 1.012, 1.928, 2.305, 1.553, 1.265, 2.148],
        [0.741, 1.636, 1.922, 1.677, 1.389, 1.777, 2.048, 1.567, 1.557, 0.666],
        [2.079, 1.153, 1.231, 1.398, 1.228, 1.348, 1.718, 1.682, 1.778, 1.949]],
       device='cuda:0')
b after update for 1 param tensor([[54.170, 39.582, 48.954, 31.061, 48.156, 60.530, 59.161, 55.747, 18.647,
         59.630],
        [54.810, 59.221, 36.041, 46.736, 54.060, 49.690, 50.701, 51.262, 34.298,
         59.275],
        [59.675, 33.979, 52.681, 48.730, 59.317, 53.718, 53.137, 50.984, 15.320,
         55.487],
        [48.097, 28.439, 15.182, 59.018, 60.658, 57.085, 39.671, 41.127, 48.566,
         58.255],
        [66.105, 61.907, 56.824, 50.943, 56.852, 54.925, 55.559, 51.695, 48.977,
         56.240],
        [65.364, 56.860, 56.050, 52.962, 54.618, 53.757, 45.676, 54.494, 46.268,
         47.676],
        [62.256, 57.989, 52.788, 42.335, 52.402, 58.071, 48.046, 63.404, 47.355,
         56.430],
        [61.006, 55.977, 51.310, 48.411, 57.671, 58.237, 51.804, 57.098, 49.597,
         49.567],
        [64.286, 51.399, 57.699, 59.846, 58.640, 52.955, 56.544, 53.188, 51.848,
         50.303],
        [58.377, 61.680, 53.138, 49.250, 53.039, 58.675, 41.231, 52.791, 56.864,
         60.351],
        [52.637, 66.258, 59.667, 60.019, 53.790, 52.243, 54.308, 59.862, 48.588,
         51.060],
        [41.800, 59.564, 46.974, 64.639, 62.949, 48.211, 54.003, 57.337, 53.623,
         46.170],
        [52.762, 56.696, 49.356, 14.993, 43.051, 47.255, 47.451, 49.440, 45.509,
         50.631],
        [59.268, 56.520, 53.210, 57.649, 57.922, 55.025, 60.867, 52.060, 48.411,
         52.329],
        [48.329, 61.801, 49.998, 49.909, 56.586, 62.953, 55.685, 48.993, 52.138,
         50.166],
        [53.821, 53.915, 47.980, 43.920, 53.557, 45.635, 33.793, 52.151, 52.070,
         56.635],
        [59.593, 57.813, 55.113, 47.656, 49.660, 41.779, 38.736, 57.493, 50.534,
         50.240],
        [48.630, 51.333, 54.376, 48.091, 57.786, 54.419, 52.647, 57.557, 45.617,
         47.666],
        [55.047, 60.943, 59.870, 11.427, 56.820, 48.380, 52.702, 49.211, 55.399,
         50.337],
        [55.008, 65.067, 52.489, 58.081, 54.083, 56.625, 61.492, 53.986, 54.540,
         45.835],
        [51.902, 37.586, 63.922, 40.736, 49.399, 52.475, 52.837, 60.078, 49.804,
         56.335],
        [63.110, 46.143, 62.482, 48.737, 57.406, 48.489, 58.618, 47.678, 57.365,
         56.845],
        [53.557, 58.309, 53.771, 50.614, 55.985, 51.829, 59.074, 55.470, 48.627,
         22.909],
        [54.927, 62.994, 65.778, 60.227, 57.599, 52.106, 60.930, 50.402, 42.198,
         48.192],
        [57.512, 62.408, 67.791, 52.116, 52.724, 55.231, 41.050, 52.465, 44.148,
         56.794],
        [45.375, 62.651, 50.304, 60.376, 55.735, 58.824, 42.020, 57.784, 45.523,
         49.654],
        [55.372, 48.604, 56.171, 56.650, 57.258, 59.192, 54.365, 56.474, 53.034,
         55.830],
        [59.815, 51.841, 63.735, 44.053, 49.440, 52.862, 48.020, 48.441, 53.443,
         53.978],
        [47.859, 39.709, 47.328, 50.975, 63.962, 62.782, 56.405, 48.450, 42.685,
         61.491],
        [55.562, 47.000, 65.419, 52.766, 61.531, 39.488, 55.456, 44.181, 52.105,
         59.726],
        [50.510, 55.521, 54.450, 61.176, 58.061, 44.714, 48.726, 58.957, 50.995,
         58.298],
        [54.538, 49.642, 57.146, 52.934, 59.532, 56.208, 65.249, 50.554, 48.301,
         44.133],
        [53.762, 62.322, 50.495, 66.515, 51.340, 56.181, 56.911, 57.767, 51.834,
         37.266],
        [57.932, 48.889, 47.602, 66.828, 46.072, 61.791, 60.841, 58.276, 48.941,
         58.793],
        [34.304, 48.372, 57.773, 51.310, 51.321, 51.077, 58.841, 51.044, 64.665,
         38.785],
        [60.970, 55.113, 40.587, 51.537, 61.562, 42.704, 28.345, 46.943, 50.727,
         52.417],
        [55.102, 40.937, 61.558, 58.158, 58.047, 58.407, 57.624, 50.685, 52.743,
         55.458],
        [57.307, 56.271, 59.974, 50.909, 55.969, 62.175, 45.058, 62.681, 51.266,
         59.886],
        [49.989, 58.809, 53.238, 59.805, 63.043, 58.595, 63.533, 51.354, 56.552,
         55.371],
        [56.972, 63.701, 62.357, 54.092, 47.357, 56.271, 34.869, 58.595, 50.451,
         57.141],
        [51.295, 46.567, 45.530, 44.728, 65.144, 54.417, 51.783, 48.114, 55.501,
         54.164],
        [46.250, 52.673, 24.435, 43.075, 67.896, 59.359, 58.207, 52.015, 48.387,
         45.738],
        [40.598, 57.999, 46.247, 50.429, 61.718, 64.885, 43.398, 48.171, 54.969,
         61.240],
        [55.398, 58.403, 59.310, 59.527, 61.831, 54.691, 55.981, 54.596, 51.746,
         52.223],
        [47.801, 48.728, 51.715, 54.852, 58.529, 49.655, 63.225, 44.432, 54.084,
         48.612],
        [52.138, 58.920, 55.042, 55.944, 59.572, 46.893, 54.363, 59.310, 57.962,
         49.774],
        [53.382, 50.628, 51.978, 50.324, 62.650, 62.816, 54.466, 39.587, 49.653,
         61.457],
        [58.056, 35.954, 11.871, 53.582, 60.150, 32.466, 42.099, 60.882, 54.554,
         51.706],
        [53.307, 51.226, 62.799, 53.558, 54.249, 32.524, 53.826, 56.587, 48.108,
         57.653],
        [54.329, 35.982, 56.215, 43.572, 47.691, 53.697, 54.263, 51.496, 48.674,
         51.786],
        [53.708, 15.612, 49.384, 63.438, 61.248, 58.591, 48.061, 53.484, 44.755,
         37.832],
        [53.310, 51.244, 64.590, 53.938, 54.598, 53.971, 55.598, 47.815, 37.749,
         62.155],
        [54.180, 55.459, 42.409, 58.271, 50.465, 40.250, 49.395, 42.449, 57.406,
         52.402],
        [49.772, 54.883, 27.609, 53.406, 60.554, 55.084, 56.119, 44.122, 54.414,
         55.065],
        [49.813, 45.014, 51.070, 42.553, 51.408, 55.427, 46.871, 48.660, 26.805,
         42.454],
        [53.336, 53.854, 55.824, 52.545, 44.124, 51.628, 53.881, 56.623, 41.473,
         61.251],
        [53.923, 53.787, 61.408, 45.494, 45.776, 61.622, 59.315, 53.349, 41.580,
         51.764],
        [38.635, 38.448, 63.825, 53.453, 52.490, 62.019, 57.865, 50.666, 49.843,
         46.144],
        [60.766, 60.368, 52.009, 52.791, 57.905, 58.117, 59.146, 53.026, 60.853,
         54.284],
        [29.325, 55.980, 39.924, 52.547, 51.459, 55.419, 51.723, 48.512, 58.545,
         45.827],
        [42.990, 47.190, 47.046, 58.017, 59.916, 49.993, 57.235, 55.513, 62.117,
         56.463],
        [48.422, 50.130, 52.081, 57.910, 64.732, 47.284, 59.311, 48.501, 50.174,
         54.614],
        [42.307, 51.542, 57.781, 42.306, 57.396, 43.889, 56.940, 49.900, 57.345,
         59.129],
        [62.814, 55.454, 38.236, 36.666, 51.784, 48.708, 61.800, 56.427, 58.261,
         60.395],
        [46.251, 53.989, 53.364, 46.684, 58.588, 59.162, 57.895, 56.299, 36.571,
         50.240],
        [55.630, 54.531, 47.416, 35.569, 64.488, 53.210, 64.920, 65.305, 53.612,
         53.062],
        [53.164, 53.630, 52.809, 53.027, 56.345, 59.802, 62.815, 59.706, 53.383,
         55.820],
        [54.402, 63.039, 53.474, 46.366, 53.468, 49.556, 55.750, 54.480, 53.102,
         60.129],
        [49.386, 58.155, 50.159, 56.801, 57.338, 44.820, 45.845, 61.117, 48.033,
         56.913],
        [51.455, 44.452, 52.194, 50.902, 55.164, 56.695, 65.528, 58.532, 55.535,
         53.502],
        [52.326, 58.970, 50.213, 49.332, 14.203, 66.659, 36.426, 63.747, 50.747,
         55.428],
        [41.130, 49.364, 55.513, 52.930, 55.936, 47.864, 52.259, 56.327, 54.392,
         52.044],
        [49.428, 49.621, 56.598, 55.061, 59.456, 47.762, 53.835, 52.581, 60.088,
         27.603],
        [62.718, 52.520, 56.158, 45.437, 49.298, 62.978, 49.329, 62.498, 51.853,
         55.168],
        [46.657, 59.687, 55.184, 52.537, 54.415, 58.431, 46.618, 67.186, 61.004,
         51.805],
        [60.607, 43.261, 62.281, 50.625, 42.097, 59.979, 49.655, 65.705, 60.905,
         46.822],
        [47.604, 54.249, 48.633, 43.859, 53.267, 61.167, 39.881, 50.143, 56.099,
         63.614],
        [50.852, 55.340, 52.915, 54.609, 58.728, 46.853, 54.435, 61.647, 21.982,
         36.950],
        [55.705, 57.592, 50.654, 51.643, 55.404, 56.488, 55.249, 47.137, 58.461,
         42.264],
        [55.892, 41.078, 50.057, 59.809, 40.075, 58.939, 52.248, 66.573, 43.731,
         55.444],
        [60.115, 67.100, 53.510, 58.842, 52.760, 49.113, 47.276, 46.193, 52.607,
         62.955],
        [54.568, 59.943, 60.946, 42.463, 56.628, 53.233, 51.866, 50.514, 68.878,
         58.530],
        [59.166, 57.489, 54.231, 44.586, 60.565, 53.467, 58.685, 56.346, 62.895,
         53.259],
        [63.040, 56.023, 53.696, 59.322, 60.027, 50.927, 54.238, 62.595, 58.361,
         61.119],
        [52.711, 61.840, 53.963, 50.989, 49.947, 54.171, 58.364, 58.557, 67.307,
         54.817],
        [48.854, 63.309, 57.839, 49.767, 56.338, 40.783, 52.015, 49.432, 66.048,
         55.262],
        [61.094, 56.485, 54.089, 46.565, 60.635, 54.792, 46.556, 56.971, 62.964,
         56.912],
        [54.016, 65.956, 54.924, 56.664, 51.631, 47.816, 59.954, 59.467, 60.739,
         47.025],
        [44.497, 61.779, 45.610, 53.324, 44.793, 57.127, 59.178, 54.738, 64.615,
         56.236],
        [39.920, 57.890, 58.650, 50.639, 58.617, 51.201, 57.914, 60.242, 63.559,
         50.977],
        [51.990, 60.899, 54.038, 59.003, 18.323, 59.843, 48.268, 54.465, 46.276,
         52.847],
        [57.485, 50.437, 46.301, 42.635, 62.762, 48.425, 50.379, 55.952, 55.308,
         63.804],
        [63.397, 55.527, 56.303, 49.346, 28.494, 59.434, 51.991, 56.284, 61.565,
         57.937],
        [50.285, 59.480, 51.152, 55.879, 51.740, 46.675, 47.563, 26.934, 58.221,
         61.455],
        [59.088, 57.301, 38.068, 58.471, 54.855, 57.377, 45.584, 60.199, 50.056,
         58.005],
        [54.925, 52.684, 51.078, 50.902, 56.208, 55.360, 62.980, 48.228, 55.373,
         61.444],
        [56.745, 49.879, 53.597, 43.815, 56.442, 57.898, 57.282, 56.172, 44.203,
         61.612],
        [53.448, 59.901, 46.903, 61.403, 43.390, 59.888, 65.481, 53.753, 48.510,
         63.213],
        [37.132, 55.158, 59.793, 55.853, 50.830, 57.492, 61.723, 53.996, 53.824,
         35.195],
        [62.185, 46.302, 47.859, 50.995, 47.797, 50.079, 56.532, 55.931, 57.504,
         60.210]], device='cuda:0')
clipping threshold 0.2546207414716664
a after update for 1 param tensor([-0.005,  0.001,  0.022,  0.012,  0.012, -0.012,  0.015, -0.017,  0.038,
        -0.005, -0.014, -0.014,  0.029, -0.047, -0.010, -0.028, -0.034,  0.003,
         0.032, -0.008,  0.021,  0.004, -0.033,  0.051,  0.052,  0.006, -0.008,
         0.027,  0.027, -0.028, -0.037, -0.021, -0.035,  0.013, -0.010, -0.001,
         0.050, -0.013, -0.012, -0.000, -0.043,  0.001, -0.003,  0.019,  0.030,
         0.003,  0.002,  0.005, -0.029, -0.023, -0.020,  0.000,  0.017, -0.002,
        -0.016, -0.014,  0.052,  0.019, -0.033, -0.033, -0.008,  0.014, -0.007,
         0.006,  0.001, -0.027, -0.006,  0.033,  0.017, -0.033,  0.053, -0.025,
         0.004, -0.028,  0.003, -0.025, -0.036, -0.003, -0.034,  0.012,  0.010,
         0.008,  0.005,  0.006, -0.022, -0.007,  0.014,  0.058,  0.017,  0.007,
        -0.033,  0.003, -0.021,  0.002, -0.029,  0.002, -0.017,  0.006,  0.016,
        -0.042], device='cuda:0')
s after update for 1 param tensor([1.648, 0.812, 1.623, 0.872, 1.385, 1.384, 0.892, 1.159, 1.813, 1.283,
        1.500, 1.972, 1.692, 1.985, 1.818, 1.922, 1.478, 1.086, 1.577, 1.142,
        1.421, 1.280, 1.117, 1.998, 1.865, 1.152, 0.997, 1.134, 1.301, 1.318,
        1.679, 1.326, 1.745, 1.827, 2.355, 0.799, 1.902, 1.688, 1.407, 1.641,
        1.434, 0.963, 0.428, 1.693, 1.684, 1.865, 1.236, 0.580, 1.409, 1.577,
        1.416, 0.339, 1.788, 0.695, 1.636, 1.393, 1.224, 1.966, 1.715, 1.453,
        1.716, 1.059, 1.397, 1.745, 2.114, 1.923, 1.108, 1.274, 1.221, 1.422,
        1.468, 1.235, 0.337, 1.731, 1.315, 1.497, 1.348, 1.605, 1.996, 1.515,
        1.801, 1.447, 0.881, 1.659, 1.555, 1.444, 1.300, 1.624, 1.149, 2.154,
        1.851, 1.285, 2.037, 1.323, 1.825, 1.431, 1.778, 1.329, 1.344, 1.366],
       device='cuda:0')
b after update for 1 param tensor([55.371, 38.855, 54.938, 40.265, 50.761, 50.734, 40.734, 46.424, 58.077,
        48.858, 52.829, 60.568, 56.099, 60.761, 58.157, 59.800, 52.434, 44.939,
        54.164, 46.083, 51.421, 48.792, 45.586, 60.958, 58.895, 46.290, 43.066,
        45.931, 49.185, 49.507, 55.888, 49.673, 56.976, 58.295, 66.181, 38.564,
        59.486, 56.028, 51.166, 55.249, 51.645, 42.324, 28.218, 56.112, 55.968,
        58.903, 47.944, 32.837, 51.196, 54.153, 51.328, 25.109, 57.673, 35.956,
        55.159, 50.905, 47.718, 60.467, 56.489, 51.986, 56.497, 44.380, 50.970,
        56.981, 62.706, 59.809, 45.389, 48.689, 47.665, 51.436, 52.260, 47.921,
        25.046, 56.749, 49.463, 52.778, 50.067, 54.637, 60.937, 53.085, 57.884,
        51.872, 40.480, 55.546, 53.789, 51.826, 49.173, 54.969, 46.239, 63.303,
        58.679, 48.899, 61.560, 49.608, 58.272, 51.587, 57.506, 49.712, 49.999,
        50.414], device='cuda:0')
clipping threshold 0.2546207414716664
a after update for 1 param tensor([[[-0.037],
         [ 0.001],
         [ 0.009],
         [-0.004],
         [-0.026],
         [-0.005],
         [-0.002],
         [-0.037],
         [ 0.017],
         [ 0.004]],

        [[-0.000],
         [ 0.013],
         [ 0.008],
         [-0.007],
         [-0.024],
         [-0.014],
         [-0.014],
         [ 0.006],
         [ 0.008],
         [-0.026]],

        [[-0.012],
         [-0.004],
         [ 0.014],
         [-0.033],
         [-0.012],
         [ 0.001],
         [ 0.019],
         [ 0.015],
         [-0.010],
         [-0.043]],

        [[ 0.018],
         [ 0.027],
         [-0.026],
         [-0.021],
         [-0.003],
         [-0.010],
         [-0.040],
         [-0.005],
         [ 0.000],
         [ 0.003]],

        [[ 0.013],
         [-0.009],
         [-0.027],
         [-0.014],
         [ 0.022],
         [ 0.056],
         [ 0.009],
         [-0.016],
         [-0.058],
         [ 0.008]],

        [[-0.004],
         [-0.004],
         [ 0.011],
         [ 0.005],
         [-0.015],
         [ 0.036],
         [-0.023],
         [ 0.015],
         [-0.016],
         [ 0.000]],

        [[-0.002],
         [ 0.019],
         [ 0.058],
         [ 0.030],
         [ 0.001],
         [ 0.006],
         [ 0.004],
         [ 0.021],
         [-0.022],
         [-0.020]],

        [[-0.019],
         [ 0.001],
         [-0.041],
         [ 0.026],
         [-0.002],
         [-0.009],
         [ 0.061],
         [ 0.010],
         [ 0.023],
         [-0.011]],

        [[-0.001],
         [-0.001],
         [-0.001],
         [-0.009],
         [ 0.031],
         [ 0.022],
         [ 0.019],
         [ 0.060],
         [ 0.012],
         [-0.027]],

        [[ 0.011],
         [-0.005],
         [-0.021],
         [-0.011],
         [-0.045],
         [ 0.018],
         [-0.035],
         [ 0.010],
         [-0.017],
         [-0.008]]], device='cuda:0')
s after update for 1 param tensor([[[1.684],
         [1.600],
         [2.081],
         [1.724],
         [1.308],
         [1.477],
         [1.590],
         [1.984],
         [1.218],
         [2.098]],

        [[1.548],
         [1.455],
         [1.414],
         [1.428],
         [1.398],
         [2.077],
         [1.846],
         [1.429],
         [1.780],
         [2.174]],

        [[1.463],
         [1.354],
         [1.766],
         [1.784],
         [1.661],
         [1.782],
         [1.341],
         [1.618],
         [1.365],
         [1.783]],

        [[1.712],
         [1.779],
         [1.435],
         [1.591],
         [0.565],
         [1.109],
         [2.064],
         [1.634],
         [1.285],
         [1.512]],

        [[1.580],
         [1.777],
         [1.921],
         [1.830],
         [1.423],
         [1.788],
         [1.358],
         [1.568],
         [1.488],
         [1.097]],

        [[1.775],
         [1.064],
         [1.064],
         [1.408],
         [1.862],
         [1.570],
         [1.544],
         [2.082],
         [1.627],
         [1.583]],

        [[0.915],
         [1.440],
         [1.650],
         [1.662],
         [1.375],
         [1.784],
         [1.897],
         [0.716],
         [1.612],
         [1.926]],

        [[1.729],
         [2.193],
         [2.099],
         [1.699],
         [1.594],
         [1.643],
         [2.014],
         [1.645],
         [1.319],
         [1.439]],

        [[0.575],
         [0.773],
         [1.595],
         [1.698],
         [1.717],
         [1.357],
         [0.783],
         [1.688],
         [1.390],
         [2.303]],

        [[1.882],
         [1.379],
         [1.640],
         [1.223],
         [2.009],
         [1.967],
         [1.246],
         [1.628],
         [1.803],
         [1.433]]], device='cuda:0')
b after update for 1 param tensor([[[55.969],
         [54.552],
         [62.213],
         [56.623],
         [49.334],
         [52.411],
         [54.381],
         [60.747],
         [47.593],
         [62.474]],

        [[53.662],
         [52.031],
         [51.284],
         [51.541],
         [51.002],
         [62.160],
         [58.604],
         [51.553],
         [57.544],
         [63.586]],

        [[52.161],
         [50.178],
         [57.311],
         [57.613],
         [55.587],
         [57.577],
         [49.942],
         [54.859],
         [50.381],
         [57.588]],

        [[56.439],
         [57.522],
         [51.662],
         [54.401],
         [32.417],
         [45.418],
         [61.959],
         [55.125],
         [48.888],
         [53.040]],

        [[54.208],
         [57.495],
         [59.785],
         [58.340],
         [51.452],
         [57.675],
         [50.258],
         [54.008],
         [52.609],
         [45.173]],

        [[57.458],
         [44.498],
         [44.482],
         [51.177],
         [58.860],
         [54.041],
         [53.587],
         [62.229],
         [55.007],
         [54.260]],

        [[41.249],
         [51.764],
         [55.401],
         [55.597],
         [50.574],
         [57.603],
         [59.398],
         [36.492],
         [54.766],
         [59.858]],

        [[56.716],
         [63.869],
         [62.490],
         [56.212],
         [54.454],
         [55.286],
         [61.204],
         [55.324],
         [49.535],
         [51.735]],

        [[32.696],
         [37.919],
         [54.464],
         [56.197],
         [56.511],
         [50.233],
         [38.161],
         [56.036],
         [50.846],
         [65.455]],

        [[59.173],
         [50.649],
         [55.233],
         [47.694],
         [61.136],
         [60.494],
         [48.151],
         [55.033],
         [57.906],
         [51.624]]], device='cuda:0')
clipping threshold 0.2546207414716664
a after update for 1 param tensor([[ 0.017],
        [ 0.007],
        [-0.009],
        [ 0.012],
        [-0.043],
        [-0.003],
        [ 0.025],
        [ 0.042],
        [-0.008],
        [ 0.012]], device='cuda:0')
s after update for 1 param tensor([[1.553],
        [1.825],
        [0.645],
        [1.545],
        [2.170],
        [1.737],
        [1.826],
        [1.645],
        [1.764],
        [2.019]], device='cuda:0')
b after update for 1 param tensor([[53.753],
        [58.271],
        [34.638],
        [53.605],
        [63.534],
        [56.843],
        [58.284],
        [55.313],
        [57.283],
        [61.277]], device='cuda:0')
clipping threshold 0.2546207414716664
||w||^2 0.03936427601778593
exp ma of ||w||^2 0.06521934793552595
||w|| 0.19840432459446525
exp ma of ||w|| 0.24054109815400704
||w||^2 0.10826847914072935
exp ma of ||w||^2 0.11804582131513945
||w|| 0.32904175896188215
exp ma of ||w|| 0.32676699110679824
cuda
Objective function 9.13 = squared loss an data 8.60 + 0.5*rho*h**2 0.060305 + alpha*h 0.238780 + L2reg 0.19 + L1reg 0.05 ; SHD = 16 ; DAG True
Proportion of microbatches that were clipped  0.7230543796808857
iteration 1 in inner loop, alpha 6.875541795280826 rho 100.0 h 0.034728905096290674
1210
cuda
Objective function 9.67 = squared loss an data 8.60 + 0.5*rho*h**2 0.603048 + alpha*h 0.238780 + L2reg 0.19 + L1reg 0.05 ; SHD = 16 ; DAG True
||w||^2 1212560685.756382
exp ma of ||w||^2 1236021956.7312834
||w|| 34821.842078735324
exp ma of ||w|| 30854.91478072418
||w||^2 2625.870216429006
exp ma of ||w||^2 100084.32724951975
||w|| 51.24324556884552
exp ma of ||w|| 135.76768017203634
||w||^2 10.996075831441694
exp ma of ||w||^2 4432.064112943269
||w|| 3.3160331469154065
exp ma of ||w|| 16.269282368365285
||w||^2 0.18824030448707765
exp ma of ||w||^2 0.20031010737459176
||w|| 0.4338666897643534
exp ma of ||w|| 0.4221342916848235
cuda
Objective function 9.01 = squared loss an data 8.58 + 0.5*rho*h**2 0.078620 + alpha*h 0.086216 + L2reg 0.21 + L1reg 0.05 ; SHD = 13 ; DAG True
Proportion of microbatches that were clipped  0.7254464285714286
iteration 2 in inner loop, alpha 6.875541795280826 rho 1000.0 h 0.012539559641913556
iteration 3 in outer loop, alpha = 19.41510143719438, rho = 1000.0, h = 0.012539559641913556
cuda
1210
cuda
Objective function 9.16 = squared loss an data 8.58 + 0.5*rho*h**2 0.078620 + alpha*h 0.243457 + L2reg 0.21 + L1reg 0.05 ; SHD = 13 ; DAG True
||w||^2 678187633.6547818
exp ma of ||w||^2 1361628361.773322
||w|| 26042.03589688759
exp ma of ||w|| 33170.922129312145
||w||^2 100403342.14798723
exp ma of ||w||^2 280726219.0138701
||w|| 10020.14681269627
exp ma of ||w|| 14246.599500670789
||w||^2 0.08575387727896827
exp ma of ||w||^2 0.13723730467236975
||w|| 0.2928376295474478
exp ma of ||w|| 0.27335216212528296
||w||^2 0.05279186671451409
exp ma of ||w||^2 0.07815318592907877
||w|| 0.22976480738902136
exp ma of ||w|| 0.2639071937851825
||w||^2 0.18663882840671217
exp ma of ||w||^2 0.12159415370457245
||w|| 0.432017162166866
exp ma of ||w|| 0.33137443483674583
cuda
Objective function 9.09 = squared loss an data 8.63 + 0.5*rho*h**2 0.030616 + alpha*h 0.151924 + L2reg 0.23 + L1reg 0.05 ; SHD = 18 ; DAG True
Proportion of microbatches that were clipped  0.7238095238095238
iteration 1 in inner loop, alpha 19.41510143719438 rho 1000.0 h 0.007825061250944287
1210
cuda
Objective function 9.37 = squared loss an data 8.63 + 0.5*rho*h**2 0.306158 + alpha*h 0.151924 + L2reg 0.23 + L1reg 0.05 ; SHD = 18 ; DAG True
||w||^2 34470514967.81942
exp ma of ||w||^2 17654514725.506752
||w|| 185662.36820588986
exp ma of ||w|| 109263.12489588105
||w||^2 605316.575605839
exp ma of ||w||^2 2961385.50758516
||w|| 778.0209351976584
exp ma of ||w|| 1136.1619420438187
||w||^2 32946.19816771079
exp ma of ||w||^2 340119.49059852393
||w|| 181.51087616920037
exp ma of ||w|| 322.3280642672972
||w||^2 998.109457254101
exp ma of ||w||^2 92967.8036130341
||w|| 31.592870354782598
exp ma of ||w|| 141.45960235369478
||w||^2 301.9972377608738
exp ma of ||w||^2 14048.9194428891
||w|| 17.378067722300827
exp ma of ||w|| 41.34974582768221
||w||^2 32.66740408546688
exp ma of ||w||^2 5686.808456824864
||w|| 5.715540576836707
exp ma of ||w|| 21.781046399224156
||w||^2 0.21408610415711546
exp ma of ||w||^2 0.08254313079174809
||w|| 0.4626943960727377
exp ma of ||w|| 0.2771005572640777
||w||^2 0.08613488553281656
exp ma of ||w||^2 0.09874468732212502
||w|| 0.2934874537911571
exp ma of ||w|| 0.30209811605504955
||w||^2 0.16392499022391985
exp ma of ||w||^2 0.10527574864777363
||w|| 0.4048765123144585
exp ma of ||w|| 0.3070604245477494
cuda
Objective function 9.07 = squared loss an data 8.68 + 0.5*rho*h**2 0.046039 + alpha*h 0.058914 + L2reg 0.24 + L1reg 0.04 ; SHD = 16 ; DAG True
Proportion of microbatches that were clipped  0.7271714922048997
iteration 2 in inner loop, alpha 19.41510143719438 rho 10000.0 h 0.0030344486625999423
iteration 4 in outer loop, alpha = 49.7595880631938, rho = 10000.0, h = 0.0030344486625999423
cuda
1210
cuda
Objective function 9.16 = squared loss an data 8.68 + 0.5*rho*h**2 0.046039 + alpha*h 0.150993 + L2reg 0.24 + L1reg 0.04 ; SHD = 16 ; DAG True
||w||^2 12664.82678857563
exp ma of ||w||^2 887964.9590633205
||w|| 112.53811260446672
exp ma of ||w|| 486.2415799393841
||w||^2 9911.825321281263
exp ma of ||w||^2 453219.9987970864
||w|| 99.55815045128783
exp ma of ||w|| 319.2187378232314
||w||^2 1.2186162473195168
exp ma of ||w||^2 215.3547948191578
||w|| 1.103909528593497
exp ma of ||w|| 1.875913637420251
||w||^2 0.15370193517862543
exp ma of ||w||^2 11.541751862480572
||w|| 0.39204838372148076
exp ma of ||w|| 0.6327532457142447
||w||^2 0.08310857789425946
exp ma of ||w||^2 0.09839641347703976
||w|| 0.2882855839168158
exp ma of ||w|| 0.3018513345940622
||w||^2 0.14279248677117876
exp ma of ||w||^2 0.1348913249680165
||w|| 0.37787893136714934
exp ma of ||w|| 0.3457777312265247
||w||^2 0.24815609911927727
exp ma of ||w||^2 0.17400350356282798
||w|| 0.4981526865523032
exp ma of ||w|| 0.39755373830932705
cuda
Objective function 9.13 = squared loss an data 8.70 + 0.5*rho*h**2 0.025553 + alpha*h 0.112489 + L2reg 0.25 + L1reg 0.04 ; SHD = 15 ; DAG True
Proportion of microbatches that were clipped  0.7193296452977547
iteration 1 in inner loop, alpha 49.7595880631938 rho 10000.0 h 0.002260643947202823
1210
cuda
Objective function 9.36 = squared loss an data 8.70 + 0.5*rho*h**2 0.255526 + alpha*h 0.112489 + L2reg 0.25 + L1reg 0.04 ; SHD = 15 ; DAG True
||w||^2 675664040.4601363
exp ma of ||w||^2 154698451439.88193
||w|| 25993.53843669877
exp ma of ||w|| 139101.01057969846
||w||^2 171.19091991124893
exp ma of ||w||^2 718602.93643092
||w|| 13.083994799419974
exp ma of ||w|| 35.3784722830089
||w||^2 0.17568262845252514
exp ma of ||w||^2 0.09358163231679889
||w|| 0.4191451162217271
exp ma of ||w|| 0.2992457600975324
cuda
Objective function 9.12 = squared loss an data 8.75 + 0.5*rho*h**2 0.038616 + alpha*h 0.043729 + L2reg 0.25 + L1reg 0.04 ; SHD = 13 ; DAG True
Proportion of microbatches that were clipped  0.7212694342041994
iteration 2 in inner loop, alpha 49.7595880631938 rho 100000.0 h 0.0008788141005489081
iteration 5 in outer loop, alpha = 928.5736886121019, rho = 1000000.0, h = 0.0008788141005489081
Threshold 0.3
[[0.004 0.038 0.026 0.004 0.212 0.082 0.062 0.1   0.019 0.925]
 [0.193 0.006 0.014 0.008 0.154 0.032 0.257 0.043 0.004 0.149]
 [0.06  0.323 0.006 0.095 0.134 0.464 0.366 0.03  0.023 0.122]
 [0.846 0.509 0.055 0.003 0.243 1.412 0.6   0.321 0.068 0.504]
 [0.015 0.023 0.013 0.01  0.005 0.016 0.006 0.013 0.004 0.017]
 [0.053 0.068 0.008 0.003 0.184 0.005 0.027 0.012 0.006 0.159]
 [0.053 0.024 0.008 0.005 0.607 0.211 0.005 0.012 0.015 0.089]
 [0.034 0.104 0.071 0.01  0.251 0.327 0.146 0.003 0.022 0.048]
 [0.162 1.089 0.121 0.048 0.793 0.48  0.104 0.134 0.002 0.277]
 [0.004 0.039 0.017 0.005 0.278 0.021 0.057 0.077 0.012 0.006]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.925]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.323 0.    0.    0.    0.464 0.366 0.    0.    0.   ]
 [0.846 0.509 0.    0.    0.    1.412 0.6   0.321 0.    0.504]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.607 0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.327 0.    0.    0.    0.   ]
 [0.    1.089 0.    0.    0.793 0.48  0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]]
{'fdr': 0.3333333333333333, 'tpr': 0.5, 'fpr': 0.2, 'f1': 0.5714285714285715, 'shd': 13, 'npred': 15, 'ntrue': 20}
[0.038 0.026 0.004 0.212 0.082 0.062 0.1   0.019 0.925 0.193 0.014 0.008
 0.154 0.032 0.257 0.043 0.004 0.149 0.06  0.323 0.095 0.134 0.464 0.366
 0.03  0.023 0.122 0.846 0.509 0.055 0.243 1.412 0.6   0.321 0.068 0.504
 0.015 0.023 0.013 0.01  0.016 0.006 0.013 0.004 0.017 0.053 0.068 0.008
 0.003 0.184 0.027 0.012 0.006 0.159 0.053 0.024 0.008 0.005 0.607 0.211
 0.012 0.015 0.089 0.034 0.104 0.071 0.01  0.251 0.327 0.146 0.022 0.048
 0.162 1.089 0.121 0.048 0.793 0.48  0.104 0.134 0.277 0.004 0.039 0.017
 0.005 0.278 0.021 0.057 0.077 0.012]
[[0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [1. 0. 1. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 1. 1. 0. 0. 1. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.8171428571428572, 0.6832530347717483)
Iterations 630
Achieves (4.040438258977602, 1e-05)-DP
