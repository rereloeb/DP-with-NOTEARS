samples  5000  graph  30 90 ER mlp  minibatch size  50  noise  0.8  minibatches per NN training  250 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 2.115034010050131
iteration 1 in outer loop, alpha = 2.115034010050131, rho = 1.0, h = 2.115034010050131
cuda
iteration 1 in inner loop,alpha 2.115034010050131 rho 1.0 h 1.3374026753201562
iteration 2 in inner loop,alpha 2.115034010050131 rho 10.0 h 0.5764720350935555
iteration 3 in inner loop,alpha 2.115034010050131 rho 100.0 h 0.178132227686838
iteration 2 in outer loop, alpha = 19.92825677873393, rho = 100.0, h = 0.178132227686838
cuda
iteration 1 in inner loop,alpha 19.92825677873393 rho 100.0 h 0.09416000652536383
iteration 2 in inner loop,alpha 19.92825677873393 rho 1000.0 h 0.03401268589539086
iteration 3 in outer loop, alpha = 53.94094267412479, rho = 1000.0, h = 0.03401268589539086
cuda
iteration 1 in inner loop,alpha 53.94094267412479 rho 1000.0 h 0.01695311788501641
iteration 2 in inner loop,alpha 53.94094267412479 rho 10000.0 h 0.005504773905784077
iteration 4 in outer loop, alpha = 108.98868173196556, rho = 10000.0, h = 0.005504773905784077
cuda
iteration 1 in inner loop,alpha 108.98868173196556 rho 10000.0 h 0.002518950920688212
iteration 2 in inner loop,alpha 108.98868173196556 rho 100000.0 h 0.0009010595095730878
iteration 5 in outer loop, alpha = 199.09463268927433, rho = 100000.0, h = 0.0009010595095730878
cuda
iteration 1 in inner loop,alpha 199.09463268927433 rho 100000.0 h 0.00039961009292355243
iteration 6 in outer loop, alpha = 598.7047256128268, rho = 1000000.0, h = 0.00039961009292355243
Threshold 0.3
[[0.006 0.001 0.001 2.137 0.001 0.001 0.002 0.001 0.001 0.    0.    0.001
  0.    0.    0.002 0.234 0.    0.    1.031 0.268 0.    0.    1.661 0.
  0.    0.    0.083 0.    0.114 0.001]
 [1.039 0.003 0.366 0.451 0.001 0.13  0.001 0.421 0.001 0.    0.    1.06
  0.    0.    0.001 1.591 0.001 0.001 0.985 0.408 0.001 0.001 0.086 0.001
  0.    0.001 0.558 0.003 0.202 0.001]
 [0.354 0.002 0.003 0.28  0.001 0.102 0.    0.232 0.    0.    0.    0.284
  0.    0.    0.    0.247 0.    0.001 0.155 0.239 0.    0.    0.134 0.001
  0.    0.    0.286 0.001 0.197 0.   ]
 [0.    0.    0.    0.004 0.    0.    0.001 0.    0.    0.    0.    0.001
  0.    0.    0.    1.718 0.    0.    0.943 1.141 0.    0.    0.247 0.
  0.    0.    0.046 0.    0.137 0.   ]
 [0.205 0.163 0.23  0.226 0.001 0.124 0.01  0.142 0.001 0.    0.    0.253
  0.    0.001 0.001 0.261 0.    0.    0.117 0.251 0.    0.    0.1   0.001
  0.    0.    0.104 0.    0.192 0.   ]
 [0.405 0.001 0.001 0.186 0.001 0.002 0.001 0.001 0.    0.    0.    0.001
  0.    0.    0.    0.128 0.    0.002 0.909 1.24  0.    0.    0.087 0.001
  0.    0.    0.033 0.    1.2   0.   ]
 [0.074 0.213 0.152 0.139 0.053 0.118 0.001 0.074 0.581 0.006 0.03  0.095
  0.    0.004 0.    0.148 0.    0.001 0.718 0.074 0.03  0.06  0.068 0.
  0.003 0.002 0.114 0.001 0.053 0.001]
 [1.01  0.    0.005 0.509 0.001 2.024 0.003 0.002 0.    0.    0.    0.003
  0.    0.    0.002 0.161 0.001 0.    0.142 1.184 0.    0.001 0.09  0.002
  0.    0.    0.03  0.    0.203 0.001]
 [0.147 0.243 0.113 0.179 0.134 0.092 0.001 0.169 0.001 0.005 0.094 0.114
  0.    0.017 0.001 0.252 0.002 0.001 0.125 1.157 0.105 0.16  0.096 0.012
  0.002 0.004 0.484 0.001 0.112 0.001]
 [0.152 0.132 0.165 1.665 0.055 0.339 0.022 2.594 0.017 0.003 0.427 0.574
  0.002 3.397 0.018 0.285 0.002 0.471 0.124 0.322 0.282 0.1   0.39  0.11
  0.001 0.455 0.243 0.002 0.275 0.284]
 [1.039 0.107 0.119 2.087 0.143 0.178 0.033 0.215 0.004 0.001 0.001 0.245
  0.006 0.085 0.002 1.12  0.002 0.076 0.228 0.17  2.825 1.136 1.5   0.076
  0.001 0.281 0.136 0.002 0.097 0.08 ]
 [0.204 0.    0.002 0.308 0.003 0.115 0.002 0.291 0.001 0.    0.    0.003
  0.    0.    0.    0.187 0.    0.    0.178 0.334 0.    0.    1.391 0.001
  0.    0.    0.011 0.    0.142 0.001]
 [1.091 0.865 0.068 0.147 0.007 1.827 0.646 0.099 0.172 0.027 0.058 0.251
  0.001 0.002 0.003 0.108 0.01  0.165 0.641 0.118 0.025 0.023 0.182 0.047
  0.003 3.166 0.134 0.004 1.056 0.461]
 [0.952 2.175 1.874 0.607 0.031 0.28  0.011 1.858 0.002 0.    0.005 1.895
  0.004 0.001 0.001 0.352 0.001 0.2   0.341 0.8   0.127 0.013 0.243 0.004
  0.    0.027 0.105 0.001 0.275 0.072]
 [0.149 0.075 1.63  0.155 0.092 0.147 0.42  0.083 0.001 0.001 0.004 0.078
  0.008 0.037 0.    1.426 0.016 0.063 0.091 0.732 0.025 0.017 0.125 0.012
  0.005 0.08  0.014 0.028 0.05  0.059]
 [0.    0.    0.    0.001 0.    0.    0.    0.    0.    0.    0.    0.001
  0.    0.    0.    0.002 0.    0.    0.019 0.267 0.    0.    0.005 0.
  0.    0.    0.005 0.    0.076 0.   ]
 [0.153 0.045 1.44  0.127 0.018 0.109 0.7   0.122 0.045 0.022 0.004 0.152
  0.006 0.001 0.002 0.1   0.001 0.04  0.091 0.838 0.054 0.022 0.08  0.028
  0.012 0.016 0.461 0.005 0.175 1.981]
 [0.143 0.137 0.163 1.631 1.369 0.097 0.19  0.295 0.154 0.    0.001 0.315
  0.    0.001 0.001 1.191 0.    0.001 0.137 0.244 0.023 0.003 0.179 0.002
  0.    0.    0.124 0.    0.996 0.   ]
 [0.001 0.    0.    0.003 0.001 0.    0.001 0.    0.    0.    0.    0.001
  0.    0.    0.001 0.08  0.    0.    0.007 0.012 0.    0.    0.009 0.
  0.    0.    0.02  0.    0.005 0.   ]
 [0.    0.    0.001 0.001 0.001 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.001 0.    0.    0.047 0.003 0.    0.    0.006 0.
  0.    0.    0.003 0.    1.213 0.   ]
 [0.912 1.252 1.841 0.305 2.134 0.097 0.005 0.12  0.001 0.    0.    1.3
  0.002 0.001 0.002 0.634 0.001 0.01  0.148 1.033 0.002 0.    0.168 0.001
  0.    0.004 0.246 0.001 0.134 0.003]
 [0.781 0.243 0.195 0.238 0.13  0.014 0.01  0.136 0.001 0.001 0.    0.258
  0.004 0.027 0.003 0.31  0.001 0.053 0.124 0.13  0.458 0.001 0.079 0.037
  0.    0.112 0.098 0.001 0.101 0.025]
 [0.    0.001 0.    0.002 0.001 0.001 0.001 0.    0.001 0.    0.    0.001
  0.    0.    0.001 0.14  0.    0.    0.121 0.103 0.    0.    0.004 0.
  0.    0.    0.003 0.    0.241 0.   ]
 [1.202 0.077 0.084 0.149 0.109 0.036 0.071 0.291 0.005 0.002 0.001 0.112
  0.001 0.038 0.002 0.087 0.005 0.194 0.098 0.09  0.08  0.002 0.092 0.001
  0.001 0.001 0.011 0.    0.175 0.094]
 [0.055 0.253 0.024 0.281 0.105 0.16  0.071 0.429 0.    4.112 1.056 0.227
  0.012 0.329 0.002 0.034 0.011 0.176 0.082 0.08  0.106 0.019 0.206 0.003
  0.001 1.681 0.037 0.002 0.744 0.154]
 [0.486 0.396 0.203 0.247 0.093 1.988 0.087 0.141 0.05  0.001 0.001 0.066
  0.    0.012 0.    0.121 0.001 0.396 0.196 0.239 0.116 0.003 0.049 0.251
  0.    0.001 0.649 0.014 1.236 1.919]
 [0.005 0.003 0.001 0.026 0.004 0.017 0.002 0.003 0.001 0.    0.    0.077
  0.    0.    0.003 0.265 0.    0.002 0.286 0.202 0.001 0.    1.606 0.001
  0.    0.    0.005 0.001 1.18  0.001]
 [0.223 0.024 0.011 0.106 2.211 0.185 0.034 1.717 0.023 0.001 0.012 2.046
  0.002 0.038 0.002 0.154 0.023 1.039 0.124 0.368 0.006 0.038 0.101 1.502
  0.006 0.002 0.048 0.001 0.127 0.078]
 [0.    0.    0.001 0.001 0.    0.    0.001 0.    0.    0.    0.    0.001
  0.    0.    0.    0.001 0.    0.    0.1   0.    0.    0.    0.002 0.
  0.    0.    0.002 0.    0.003 0.   ]
 [0.217 0.078 1.82  0.172 0.114 0.102 0.06  0.085 0.055 0.    0.    0.118
  0.    0.001 0.001 0.182 0.    1.121 0.128 0.191 0.035 0.001 0.102 0.003
  0.    0.    0.714 0.001 0.356 0.001]]
[[0.    0.    0.    2.137 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    1.031 0.    0.    0.    1.661 0.
  0.    0.    0.    0.    0.    0.   ]
 [1.039 0.    0.366 0.451 0.    0.    0.    0.421 0.    0.    0.    1.06
  0.    0.    0.    1.591 0.    0.    0.985 0.408 0.    0.    0.    0.
  0.    0.    0.558 0.    0.    0.   ]
 [0.354 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    1.718 0.    0.    0.943 1.141 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.405 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.909 1.24  0.    0.    0.    0.
  0.    0.    0.    0.    1.2   0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.581 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.718 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [1.01  0.    0.    0.509 0.    2.024 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    1.184 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    1.157 0.    0.    0.    0.
  0.    0.    0.484 0.    0.    0.   ]
 [0.    0.    0.    1.665 0.    0.339 0.    2.594 0.    0.    0.427 0.574
  0.    3.397 0.    0.    0.    0.471 0.    0.322 0.    0.    0.39  0.
  0.    0.455 0.    0.    0.    0.   ]
 [1.039 0.    0.    2.087 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    1.12  0.    0.    0.    0.    2.825 1.136 1.5   0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.308 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.334 0.    0.    1.391 0.
  0.    0.    0.    0.    0.    0.   ]
 [1.091 0.865 0.    0.    0.    1.827 0.646 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.641 0.    0.    0.    0.    0.
  0.    3.166 0.    0.    1.056 0.461]
 [0.952 2.175 1.874 0.607 0.    0.    0.    1.858 0.    0.    0.    1.895
  0.    0.    0.    0.352 0.    0.    0.341 0.8   0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    1.63  0.    0.    0.    0.42  0.    0.    0.    0.    0.
  0.    0.    0.    1.426 0.    0.    0.    0.732 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    1.44  0.    0.    0.    0.7   0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.838 0.    0.    0.    0.
  0.    0.    0.461 0.    0.    1.981]
 [0.    0.    0.    1.631 1.369 0.    0.    0.    0.    0.    0.    0.315
  0.    0.    0.    1.191 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.996 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    1.213 0.   ]
 [0.912 1.252 1.841 0.305 2.134 0.    0.    0.    0.    0.    0.    1.3
  0.    0.    0.    0.634 0.    0.    0.    1.033 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.781 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.31  0.    0.    0.    0.    0.458 0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [1.202 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.429 0.    4.112 1.056 0.
  0.    0.329 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    1.681 0.    0.    0.744 0.   ]
 [0.486 0.396 0.    0.    0.    1.988 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.396 0.    0.    0.    0.    0.    0.
  0.    0.    0.649 0.    1.236 1.919]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.606 0.
  0.    0.    0.    0.    1.18  0.   ]
 [0.    0.    0.    0.    2.211 0.    0.    1.717 0.    0.    0.    2.046
  0.    0.    0.    0.    0.    1.039 0.    0.368 0.    0.    0.    1.502
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    1.82  0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    1.121 0.    0.    0.    0.    0.    0.
  0.    0.    0.714 0.    0.356 0.   ]]
{'fdr': 0.29310344827586204, 'tpr': 0.9111111111111111, 'fpr': 0.09855072463768116, 'f1': 0.7961165048543689, 'shd': 41, 'npred': 116, 'ntrue': 90}
[8.541e-04 7.417e-04 2.137e+00 1.499e-03 5.173e-04 1.794e-03 7.138e-04
 6.196e-04 1.612e-05 4.823e-05 1.113e-03 9.818e-05 1.955e-05 1.628e-03
 2.342e-01 5.279e-05 3.364e-04 1.031e+00 2.677e-01 4.352e-04 1.182e-04
 1.661e+00 3.016e-05 1.921e-05 4.226e-05 8.276e-02 2.600e-05 1.136e-01
 6.161e-04 1.039e+00 3.659e-01 4.510e-01 7.052e-04 1.300e-01 1.353e-03
 4.215e-01 9.919e-04 7.773e-06 2.206e-05 1.060e+00 3.227e-04 1.604e-05
 1.282e-03 1.591e+00 1.231e-03 1.305e-03 9.848e-01 4.077e-01 7.201e-04
 5.968e-04 8.622e-02 1.392e-03 2.413e-06 5.962e-04 5.585e-01 2.665e-03
 2.018e-01 5.978e-04 3.537e-01 1.501e-03 2.800e-01 8.106e-04 1.021e-01
 4.564e-04 2.321e-01 3.777e-04 2.222e-04 5.527e-05 2.838e-01 1.298e-04
 2.273e-04 1.500e-05 2.473e-01 8.620e-05 1.022e-03 1.547e-01 2.394e-01
 2.827e-04 2.043e-04 1.341e-01 6.634e-04 5.246e-05 9.505e-05 2.856e-01
 6.785e-04 1.974e-01 1.033e-04 3.548e-04 9.863e-05 1.525e-04 4.997e-04
 2.244e-04 1.224e-03 7.729e-05 2.865e-04 4.272e-05 5.361e-05 8.708e-04
 4.051e-05 2.147e-05 2.279e-05 1.718e+00 2.726e-05 9.788e-05 9.432e-01
 1.141e+00 9.310e-05 4.167e-05 2.466e-01 7.046e-06 4.331e-06 3.126e-05
 4.641e-02 2.103e-05 1.367e-01 3.557e-05 2.050e-01 1.629e-01 2.302e-01
 2.258e-01 1.244e-01 9.573e-03 1.422e-01 8.309e-04 4.601e-05 3.114e-05
 2.531e-01 1.695e-05 6.059e-04 9.596e-04 2.607e-01 1.027e-04 2.739e-04
 1.171e-01 2.509e-01 2.695e-04 2.033e-04 9.958e-02 7.337e-04 2.196e-05
 1.183e-04 1.044e-01 4.921e-05 1.921e-01 1.331e-04 4.053e-01 5.080e-04
 1.454e-03 1.856e-01 1.148e-03 1.447e-03 6.100e-04 8.498e-05 8.034e-06
 5.401e-05 8.747e-04 2.375e-05 7.995e-05 1.856e-04 1.280e-01 7.400e-05
 1.942e-03 9.090e-01 1.240e+00 3.280e-05 4.787e-04 8.741e-02 5.409e-04
 1.010e-05 7.803e-05 3.324e-02 4.457e-05 1.200e+00 1.995e-04 7.376e-02
 2.131e-01 1.525e-01 1.394e-01 5.302e-02 1.179e-01 7.446e-02 5.810e-01
 5.881e-03 3.049e-02 9.479e-02 3.650e-04 4.325e-03 2.492e-04 1.481e-01
 4.085e-04 7.178e-04 7.181e-01 7.365e-02 2.991e-02 5.956e-02 6.772e-02
 3.802e-04 3.325e-03 1.833e-03 1.137e-01 7.175e-04 5.314e-02 5.722e-04
 1.010e+00 4.939e-04 4.787e-03 5.094e-01 1.104e-03 2.024e+00 2.805e-03
 3.942e-04 8.550e-06 1.057e-04 2.963e-03 1.011e-04 1.133e-04 1.767e-03
 1.608e-01 1.202e-03 3.762e-04 1.422e-01 1.184e+00 2.174e-04 9.699e-04
 9.045e-02 1.586e-03 5.020e-06 2.637e-04 2.958e-02 7.117e-05 2.030e-01
 5.337e-04 1.473e-01 2.425e-01 1.129e-01 1.792e-01 1.337e-01 9.192e-02
 8.707e-04 1.686e-01 4.778e-03 9.376e-02 1.143e-01 4.658e-04 1.685e-02
 1.060e-03 2.522e-01 1.950e-03 1.280e-03 1.247e-01 1.157e+00 1.053e-01
 1.598e-01 9.575e-02 1.168e-02 1.567e-03 4.236e-03 4.845e-01 6.917e-04
 1.120e-01 7.878e-04 1.516e-01 1.321e-01 1.648e-01 1.665e+00 5.539e-02
 3.394e-01 2.167e-02 2.594e+00 1.671e-02 4.273e-01 5.742e-01 1.596e-03
 3.397e+00 1.777e-02 2.854e-01 1.895e-03 4.710e-01 1.241e-01 3.215e-01
 2.818e-01 1.003e-01 3.897e-01 1.103e-01 5.246e-04 4.551e-01 2.430e-01
 1.948e-03 2.748e-01 2.841e-01 1.039e+00 1.069e-01 1.186e-01 2.087e+00
 1.433e-01 1.778e-01 3.260e-02 2.149e-01 4.480e-03 7.084e-04 2.449e-01
 6.096e-03 8.453e-02 2.344e-03 1.120e+00 2.050e-03 7.593e-02 2.279e-01
 1.701e-01 2.825e+00 1.136e+00 1.500e+00 7.635e-02 1.154e-03 2.805e-01
 1.359e-01 1.794e-03 9.699e-02 7.959e-02 2.040e-01 1.800e-04 1.859e-03
 3.080e-01 2.543e-03 1.147e-01 1.726e-03 2.905e-01 5.818e-04 3.061e-05
 2.960e-05 5.297e-05 5.779e-05 3.069e-04 1.873e-01 3.645e-05 4.161e-04
 1.781e-01 3.345e-01 2.321e-04 1.008e-04 1.391e+00 1.366e-03 1.775e-05
 1.862e-04 1.089e-02 9.334e-05 1.423e-01 1.290e-03 1.091e+00 8.646e-01
 6.793e-02 1.467e-01 7.065e-03 1.827e+00 6.462e-01 9.920e-02 1.718e-01
 2.705e-02 5.774e-02 2.508e-01 1.859e-03 2.553e-03 1.076e-01 9.595e-03
 1.652e-01 6.406e-01 1.184e-01 2.534e-02 2.307e-02 1.818e-01 4.667e-02
 2.627e-03 3.166e+00 1.342e-01 3.552e-03 1.056e+00 4.608e-01 9.521e-01
 2.175e+00 1.874e+00 6.074e-01 3.050e-02 2.797e-01 1.099e-02 1.858e+00
 2.149e-03 2.456e-04 5.343e-03 1.895e+00 4.338e-03 1.087e-03 3.518e-01
 6.471e-04 2.002e-01 3.411e-01 7.999e-01 1.265e-01 1.335e-02 2.432e-01
 3.940e-03 7.282e-05 2.742e-02 1.046e-01 8.149e-04 2.747e-01 7.229e-02
 1.489e-01 7.539e-02 1.630e+00 1.549e-01 9.178e-02 1.475e-01 4.202e-01
 8.255e-02 1.192e-03 1.282e-03 3.800e-03 7.762e-02 7.578e-03 3.687e-02
 1.426e+00 1.626e-02 6.261e-02 9.138e-02 7.321e-01 2.523e-02 1.712e-02
 1.251e-01 1.201e-02 4.831e-03 7.963e-02 1.386e-02 2.819e-02 5.046e-02
 5.944e-02 2.108e-05 1.836e-04 9.096e-05 5.664e-04 3.186e-04 8.021e-05
 2.172e-04 6.487e-05 2.412e-05 1.934e-05 7.031e-05 8.183e-04 1.373e-05
 1.204e-05 3.232e-05 1.753e-05 3.198e-05 1.872e-02 2.673e-01 2.615e-05
 4.379e-05 4.558e-03 1.752e-05 1.509e-05 3.807e-05 4.887e-03 4.568e-06
 7.645e-02 3.599e-05 1.527e-01 4.493e-02 1.440e+00 1.267e-01 1.795e-02
 1.090e-01 7.001e-01 1.216e-01 4.464e-02 2.159e-02 4.427e-03 1.519e-01
 5.926e-03 1.485e-03 1.882e-03 1.004e-01 3.960e-02 9.070e-02 8.383e-01
 5.422e-02 2.174e-02 8.010e-02 2.775e-02 1.226e-02 1.584e-02 4.608e-01
 4.798e-03 1.747e-01 1.981e+00 1.432e-01 1.367e-01 1.628e-01 1.631e+00
 1.369e+00 9.662e-02 1.903e-01 2.947e-01 1.535e-01 1.191e-04 1.429e-03
 3.151e-01 4.069e-05 8.466e-04 9.404e-04 1.191e+00 2.230e-05 1.367e-01
 2.441e-01 2.316e-02 2.798e-03 1.787e-01 1.919e-03 3.717e-05 8.837e-05
 1.237e-01 6.566e-05 9.959e-01 2.051e-04 1.359e-03 1.833e-04 1.434e-04
 3.269e-03 6.785e-04 1.669e-04 6.448e-04 2.305e-04 2.878e-04 1.656e-05
 1.257e-04 7.465e-04 6.164e-05 1.976e-05 8.802e-04 7.970e-02 7.434e-05
 1.051e-04 1.176e-02 8.818e-05 1.159e-04 9.123e-03 8.781e-05 1.115e-05
 2.085e-05 1.961e-02 1.165e-04 4.938e-03 8.533e-05 3.858e-05 6.613e-05
 1.360e-03 6.885e-04 1.091e-03 1.293e-04 4.871e-04 3.015e-05 2.085e-05
 5.838e-06 2.427e-05 2.173e-04 4.891e-05 1.608e-05 4.230e-05 1.333e-03
 6.979e-05 1.602e-05 4.710e-02 2.031e-05 1.849e-05 5.508e-03 3.432e-05
 1.210e-05 5.698e-06 2.986e-03 4.150e-06 1.213e+00 7.098e-05 9.116e-01
 1.252e+00 1.841e+00 3.053e-01 2.134e+00 9.676e-02 5.334e-03 1.204e-01
 8.698e-04 1.943e-04 2.611e-05 1.300e+00 1.574e-03 1.450e-03 1.577e-03
 6.336e-01 1.461e-03 1.008e-02 1.482e-01 1.033e+00 4.377e-04 1.678e-01
 7.981e-04 2.173e-05 4.204e-03 2.463e-01 1.140e-03 1.336e-01 3.012e-03
 7.808e-01 2.426e-01 1.949e-01 2.379e-01 1.300e-01 1.355e-02 1.035e-02
 1.361e-01 1.372e-03 5.581e-04 7.904e-05 2.581e-01 3.513e-03 2.732e-02
 2.798e-03 3.103e-01 1.238e-03 5.347e-02 1.243e-01 1.305e-01 4.582e-01
 7.916e-02 3.731e-02 3.663e-04 1.121e-01 9.808e-02 1.195e-03 1.010e-01
 2.468e-02 1.777e-04 5.837e-04 3.188e-04 2.150e-03 8.056e-04 6.967e-04
 7.658e-04 5.796e-05 5.493e-04 1.361e-05 3.436e-05 1.081e-03 4.825e-05
 1.763e-05 1.325e-03 1.396e-01 2.735e-04 2.600e-04 1.213e-01 1.028e-01
 2.774e-04 1.293e-04 4.650e-05 3.220e-05 1.789e-04 3.057e-03 7.279e-05
 2.411e-01 2.937e-04 1.202e+00 7.749e-02 8.419e-02 1.495e-01 1.093e-01
 3.583e-02 7.074e-02 2.911e-01 4.703e-03 1.751e-03 1.211e-03 1.120e-01
 1.257e-03 3.796e-02 1.521e-03 8.749e-02 5.475e-03 1.944e-01 9.832e-02
 9.046e-02 7.997e-02 1.547e-03 9.234e-02 9.021e-04 5.573e-04 1.103e-02
 1.387e-04 1.746e-01 9.388e-02 5.540e-02 2.527e-01 2.354e-02 2.808e-01
 1.046e-01 1.605e-01 7.124e-02 4.288e-01 1.489e-04 4.112e+00 1.056e+00
 2.268e-01 1.224e-02 3.292e-01 2.385e-03 3.430e-02 1.138e-02 1.758e-01
 8.164e-02 7.989e-02 1.059e-01 1.876e-02 2.059e-01 2.707e-03 1.681e+00
 3.745e-02 2.283e-03 7.435e-01 1.544e-01 4.860e-01 3.964e-01 2.034e-01
 2.474e-01 9.312e-02 1.988e+00 8.683e-02 1.412e-01 4.963e-02 6.992e-04
 1.470e-03 6.591e-02 3.321e-05 1.217e-02 4.249e-04 1.206e-01 1.465e-03
 3.956e-01 1.959e-01 2.390e-01 1.157e-01 2.939e-03 4.881e-02 2.511e-01
 3.113e-04 6.490e-01 1.430e-02 1.236e+00 1.919e+00 5.383e-03 3.488e-03
 7.590e-04 2.550e-02 4.104e-03 1.691e-02 1.887e-03 3.220e-03 5.152e-04
 3.517e-04 6.495e-05 7.697e-02 7.603e-05 5.316e-05 2.843e-03 2.652e-01
 1.600e-04 2.269e-03 2.855e-01 2.019e-01 6.381e-04 4.134e-04 1.606e+00
 1.483e-03 9.172e-06 1.826e-04 1.114e-03 1.180e+00 5.534e-04 2.229e-01
 2.412e-02 1.115e-02 1.061e-01 2.211e+00 1.848e-01 3.423e-02 1.717e+00
 2.273e-02 1.494e-03 1.243e-02 2.046e+00 2.343e-03 3.766e-02 2.170e-03
 1.540e-01 2.337e-02 1.039e+00 1.236e-01 3.676e-01 6.486e-03 3.781e-02
 1.005e-01 1.502e+00 5.886e-03 1.930e-03 4.780e-02 1.268e-01 7.826e-02
 2.944e-04 3.895e-04 6.621e-04 1.126e-03 4.593e-04 6.643e-05 5.551e-04
 3.244e-05 6.627e-05 1.419e-05 1.283e-05 9.093e-04 1.126e-05 9.239e-06
 1.418e-04 1.234e-03 5.687e-05 3.961e-05 9.970e-02 1.617e-04 1.407e-04
 5.335e-05 1.745e-03 7.439e-05 2.162e-05 9.121e-05 2.224e-03 6.488e-06
 6.315e-05 2.170e-01 7.822e-02 1.820e+00 1.719e-01 1.143e-01 1.020e-01
 5.999e-02 8.483e-02 5.461e-02 8.846e-05 4.860e-04 1.176e-01 3.269e-05
 9.439e-04 9.660e-04 1.822e-01 1.005e-04 1.121e+00 1.282e-01 1.912e-01
 3.506e-02 1.457e-03 1.022e-01 2.670e-03 5.463e-05 1.229e-04 7.144e-01
 9.279e-04 3.561e-01]
[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 1. 0. 0. 1. 0.]
 [1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
  0. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 0. 1. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0.]
aucroc, aucpr (0.9797293447293447, 0.9406385268776497)
cuda
9630
cuda
Objective function 982.29 = squared loss an data 726.28 + 0.5*rho*h**2 254.631624 + alpha*h 0.000000 + L2reg 0.55 + L1reg 0.82 ; SHD = 415 ; DAG False
||w||^2 96268773.29568215
exp ma of ||w||^2 42190146631.36338
||w|| 9811.665164266571
exp ma of ||w|| 75096.17486826432
||w||^2 0.1190494460988327
exp ma of ||w||^2 0.10439493167336605
||w|| 0.34503542730976583
exp ma of ||w|| 0.31260595512647327
||w||^2 0.04216796575180811
exp ma of ||w||^2 0.12827173270428713
||w|| 0.20534840089907716
exp ma of ||w|| 0.34525220243858407
||w||^2 0.10113991942349454
exp ma of ||w||^2 0.14502624721695145
||w|| 0.31802502955505646
exp ma of ||w|| 0.36493701204819934
||w||^2 0.11517139905505994
exp ma of ||w||^2 0.147768310026302
||w|| 0.33936911918302165
exp ma of ||w|| 0.36975355428436896
||w||^2 0.41228298174942224
exp ma of ||w||^2 0.1499161496517671
||w|| 0.6420926582273171
exp ma of ||w|| 0.37428334999647056
||w||^2 0.2812249534670736
exp ma of ||w||^2 0.18633279978794579
||w|| 0.5303064712664495
exp ma of ||w|| 0.41331437517851577
||w||^2 0.07469578449405338
exp ma of ||w||^2 0.19077949237108904
||w|| 0.27330529540068077
exp ma of ||w|| 0.41930864397001777
||w||^2 0.45381288099601713
exp ma of ||w||^2 0.2848924317930444
||w|| 0.673656352301392
exp ma of ||w|| 0.5076500325586397
||w||^2 0.22151119613423328
exp ma of ||w||^2 0.3003754961077956
||w|| 0.4706497595178747
exp ma of ||w|| 0.523526056886094
||w||^2 0.2342773312413143
exp ma of ||w||^2 0.31569194802219486
||w|| 0.48402203590468307
exp ma of ||w|| 0.5367898268464709
||w||^2 0.20141154005199444
exp ma of ||w||^2 0.34182161034055275
||w|| 0.4487889705106337
exp ma of ||w|| 0.5576942277352959
cuda
Objective function 66.96 = squared loss an data 55.09 + 0.5*rho*h**2 9.840613 + alpha*h 0.000000 + L2reg 1.45 + L1reg 0.58 ; SHD = 197 ; DAG False
Proportion of microbatches that were clipped  0.7661068948813177
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 4.436352855831075
iteration 1 in outer loop, alpha = 4.436352855831075, rho = 1.0, h = 4.436352855831075
cuda
9630
cuda
Objective function 86.64 = squared loss an data 55.09 + 0.5*rho*h**2 9.840613 + alpha*h 19.681227 + L2reg 1.45 + L1reg 0.58 ; SHD = 197 ; DAG False
||w||^2 303446.81249320344
exp ma of ||w||^2 759288747.0193369
||w|| 550.8600661630896
exp ma of ||w|| 8140.746639623677
||w||^2 2.0652090066780495
exp ma of ||w||^2 1407165.897134063
||w|| 1.4370835072041046
exp ma of ||w|| 21.729559778369005
||w||^2 1.2797592863488325
exp ma of ||w||^2 475277.33668068855
||w|| 1.1312644634871338
exp ma of ||w|| 8.062829112956729
||w||^2 2.977437672409904
exp ma of ||w||^2 0.8428951024712913
||w|| 1.7255253323002546
exp ma of ||w|| 0.8836327184009828
||w||^2 0.5452789621167147
exp ma of ||w||^2 0.6704474780518811
||w|| 0.7384300658266256
exp ma of ||w|| 0.7904665512814095
||w||^2 1.849494826835058
exp ma of ||w||^2 0.6896465403625387
||w|| 1.3599613328455549
exp ma of ||w|| 0.8011733006818089
||w||^2 0.5960271740379197
exp ma of ||w||^2 0.6295084225296929
||w|| 0.7720279619533995
exp ma of ||w|| 0.7717745994916448
||w||^2 0.4382772821247859
exp ma of ||w||^2 0.8014915839572507
||w|| 0.6620251370792395
exp ma of ||w|| 0.8654168190042743
cuda
Objective function 65.71 = squared loss an data 42.73 + 0.5*rho*h**2 5.670780 + alpha*h 14.940408 + L2reg 1.81 + L1reg 0.56 ; SHD = 186 ; DAG False
Proportion of microbatches that were clipped  0.7678527807181825
iteration 1 in inner loop, alpha 4.436352855831075 rho 1.0 h 3.3677231658247777
9630
cuda
Objective function 116.75 = squared loss an data 42.73 + 0.5*rho*h**2 56.707797 + alpha*h 14.940408 + L2reg 1.81 + L1reg 0.56 ; SHD = 186 ; DAG False
||w||^2 142565.85955599032
exp ma of ||w||^2 923959555.241896
||w|| 377.5789447996145
exp ma of ||w|| 6524.552603356902
||w||^2 1.9541396042801096
exp ma of ||w||^2 1.4348534985584778
||w|| 1.3979054346700672
exp ma of ||w|| 1.155039417178504
||w||^2 1.964300525555057
exp ma of ||w||^2 1.3326047267526004
||w|| 1.401535060408785
exp ma of ||w|| 1.1190491752197804
||w||^2 5.060268384354234
exp ma of ||w||^2 1.3994135369517753
||w|| 2.249504030748608
exp ma of ||w|| 1.140624809006874
||w||^2 1.2510434567342936
exp ma of ||w||^2 1.3111735767242836
||w|| 1.1185005394430052
exp ma of ||w|| 1.1108573909778474
||w||^2 1.2370910912361721
exp ma of ||w||^2 1.330154184348783
||w|| 1.1122459670577243
exp ma of ||w|| 1.117874986362642
||w||^2 1.057312883885816
exp ma of ||w||^2 1.186382985146873
||w|| 1.0282572070672862
exp ma of ||w|| 1.0621689621426984
||w||^2 0.8857726331884023
exp ma of ||w||^2 1.2286555172653988
||w|| 0.9411549464293338
exp ma of ||w|| 1.0766146242661825
||w||^2 1.049472769496582
exp ma of ||w||^2 1.192630659918961
||w|| 1.0244377821500834
exp ma of ||w|| 1.059288360150838
||w||^2 1.3122416415981784
exp ma of ||w||^2 1.3341945306879597
||w|| 1.145531161338782
exp ma of ||w|| 1.1174185138361807
||w||^2 2.8944277382096173
exp ma of ||w||^2 1.3920126101732915
||w|| 1.7013017775249684
exp ma of ||w|| 1.145794436095776
||w||^2 1.9082076755187174
exp ma of ||w||^2 1.3939599309480495
||w|| 1.3813789036751347
exp ma of ||w|| 1.1436569620068344
||w||^2 0.9007808484060291
exp ma of ||w||^2 1.3614267879623791
||w|| 0.9490947520695862
exp ma of ||w|| 1.136849508914112
cuda
Objective function 67.14 = squared loss an data 44.01 + 0.5*rho*h**2 13.358272 + alpha*h 7.251306 + L2reg 2.03 + L1reg 0.50 ; SHD = 162 ; DAG True
Proportion of microbatches that were clipped  0.7743206303264191
iteration 2 in inner loop, alpha 4.436352855831075 rho 10.0 h 1.6345196517618952
9630
cuda
Objective function 187.37 = squared loss an data 44.01 + 0.5*rho*h**2 133.582725 + alpha*h 7.251306 + L2reg 2.03 + L1reg 0.50 ; SHD = 162 ; DAG True
||w||^2 980967655577.1853
exp ma of ||w||^2 320318730927.1585
||w|| 990438.1129465814
exp ma of ||w|| 299539.35263753904
||w||^2 35.15777777918083
exp ma of ||w||^2 33081413.849456545
||w|| 5.929399445068685
exp ma of ||w|| 166.77058210524953
||w||^2 24.10258440731159
exp ma of ||w||^2 32423094.191895142
||w|| 4.909438298554285
exp ma of ||w|| 163.54938225671046
||w||^2 1.7970078368105018
exp ma of ||w||^2 126326.73721811037
||w|| 1.340525209315551
exp ma of ||w|| 2.5188977133857815
||w||^2 2.068640115178498
exp ma of ||w||^2 6323.38037184185
||w|| 1.4382767867064037
exp ma of ||w|| 1.6153600662911884
||w||^2 0.7020905030823397
exp ma of ||w||^2 4.881692987730494
||w|| 0.8379084097216949
exp ma of ||w|| 1.3633756286370984
||w||^2 1.981799832258333
exp ma of ||w||^2 2.0642336594037354
||w|| 1.4077641252206752
exp ma of ||w|| 1.39102588309139
||w||^2 1.1024138684463822
exp ma of ||w||^2 1.9869091181719327
||w|| 1.0499589841733734
exp ma of ||w|| 1.3702848618014871
||w||^2 1.4688349472048077
exp ma of ||w||^2 2.2682543803639725
||w|| 1.2119550103880952
exp ma of ||w|| 1.4646430904036258
||w||^2 0.8933879121801458
exp ma of ||w||^2 2.0115768994537384
||w|| 0.9451919975222737
exp ma of ||w|| 1.3799588259073328
||w||^2 1.6845036701842373
exp ma of ||w||^2 2.0771358006100433
||w|| 1.297884305392525
exp ma of ||w|| 1.4018782446590279
||w||^2 2.821019313179699
exp ma of ||w||^2 2.055731765329034
||w|| 1.6795890310369672
exp ma of ||w|| 1.3950208201796008
||w||^2 2.913091719543586
exp ma of ||w||^2 2.040830810951874
||w|| 1.706778169400929
exp ma of ||w|| 1.3926834060451803
||w||^2 1.1284095211137324
exp ma of ||w||^2 1.9239167479040367
||w|| 1.0622662195107837
exp ma of ||w|| 1.3543480291176595
||w||^2 1.4375693603714665
exp ma of ||w||^2 2.154462911080869
||w|| 1.1989868057537023
exp ma of ||w|| 1.424542754504155
||w||^2 2.8749401524112645
exp ma of ||w||^2 2.09864118266144
||w|| 1.6955648475983645
exp ma of ||w|| 1.4149994049597134
||w||^2 1.0826229104974798
exp ma of ||w||^2 2.1024355724910526
||w|| 1.0404916676732592
exp ma of ||w|| 1.4051887868097597
cuda
Objective function 71.64 = squared loss an data 47.92 + 0.5*rho*h**2 18.419288 + alpha*h 2.692635 + L2reg 2.17 + L1reg 0.43 ; SHD = 141 ; DAG True
Proportion of microbatches that were clipped  0.7741489966691039
iteration 3 in inner loop, alpha 4.436352855831075 rho 100.0 h 0.6069479079197961
iteration 2 in outer loop, alpha = 65.13114364781069, rho = 100.0, h = 0.6069479079197961
cuda
9630
cuda
Objective function 108.47 = squared loss an data 47.92 + 0.5*rho*h**2 18.419288 + alpha*h 39.531211 + L2reg 2.17 + L1reg 0.43 ; SHD = 141 ; DAG True
||w||^2 66587670352.31504
exp ma of ||w||^2 189617097026.26498
||w|| 258045.8686984061
exp ma of ||w|| 361248.2630280777
||w||^2 138740952.1248539
exp ma of ||w||^2 11138622102.972116
||w|| 11778.834922217644
exp ma of ||w|| 46960.80343555561
||w||^2 1402621.2214896658
exp ma of ||w||^2 2216856953.508326
||w|| 1184.3231068799028
exp ma of ||w|| 11365.592139459031
||w||^2 5.0121247505712665
exp ma of ||w||^2 4024648.4408165268
||w|| 2.238777512521346
exp ma of ||w|| 27.93778121223824
||w||^2 1.445653721767887
exp ma of ||w||^2 436.2097760347103
||w|| 1.2023534096794866
exp ma of ||w|| 1.5756746365155443
v before min max tensor([[-734.327,  429.110,  687.349,  ..., -132.930, -574.443, -349.194],
        [-431.180, -331.366,   16.510,  ..., -360.242, -735.427, -629.289],
        [-383.387, -646.051, -528.402,  ..., -659.795, -449.125,  106.331],
        ...,
        [-496.145,  351.078, -796.420,  ..., -463.334, -458.757, -768.916],
        [-106.522, -629.769, -517.852,  ..., -515.694, -521.851,  121.061],
        [-371.797, -703.363, -680.096,  ..., -244.313,  733.640, -694.535]],
       device='cuda:0')
v tensor([[1.000e-12, 1.000e+01, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e+01],
        ...,
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         1.000e-12]], device='cuda:0')
v before min max tensor([ 4.970e+02, -7.668e+02, -4.116e+02, -4.634e+02,  3.726e+01,  1.176e+01,
        -7.328e+02, -6.544e+01,  4.264e+02, -9.078e+02, -6.378e+02, -7.641e+02,
        -6.711e+02,  1.494e+02,  5.867e+02, -6.865e+02,  3.427e+02, -5.278e+02,
        -5.287e+02, -7.266e+02,  6.557e+01, -6.404e+02,  7.292e+02,  3.882e+02,
        -4.970e+02, -2.885e+02,  6.903e+02, -3.924e+02,  1.442e+03,  6.230e-01,
        -4.371e+02,  2.643e+03,  9.439e+02, -4.473e+02, -4.675e+02, -7.691e+02,
         6.641e+02, -3.885e+02, -2.561e+02, -7.298e+02, -3.748e+02,  2.435e+02,
        -2.284e+02, -3.029e+02, -3.071e+02, -5.719e+02, -4.910e+02, -1.785e+02,
        -4.433e+02, -4.969e+02,  5.787e+02,  2.626e+03, -4.718e+02, -4.991e+02,
        -3.752e+02, -4.902e+02, -7.508e+02,  1.052e+02,  2.132e+03, -2.674e+02,
        -4.914e+02,  7.174e+01, -5.607e+02, -7.677e+02, -1.889e+02, -2.158e+02,
        -4.489e+02,  1.932e+03, -5.212e+01, -4.220e+02, -3.790e+02, -1.123e+02,
        -5.040e+02, -2.909e+02,  2.574e+02, -5.052e+02, -7.057e+01, -8.348e+02,
        -1.806e+02,  1.255e+03, -4.058e+02, -5.914e+02, -4.379e+02, -4.602e+02,
        -6.126e+02, -6.221e+02,  3.078e+02,  7.079e+02,  8.587e+02, -5.455e+02,
        -6.254e+02, -5.916e+02, -6.626e+02, -6.121e+02,  5.852e+02, -5.555e+02,
        -5.284e+02, -4.570e+02, -9.152e+01, -6.156e+02, -1.945e+02, -6.606e+02,
         1.238e+03, -6.654e+02, -8.685e+02, -5.304e+02, -5.319e+02, -2.124e+02,
        -6.509e+02, -4.782e+02, -7.216e+02, -2.292e+02,  1.666e+02, -6.451e+02,
        -5.614e+02,  2.777e+02, -6.488e+02,  2.453e+03, -5.374e+02, -7.601e+02,
        -4.470e+02, -3.800e+02, -2.033e+02, -7.857e+01, -6.361e+02, -5.522e+02,
        -3.970e+02, -4.126e+02, -5.729e+02, -1.722e+02,  1.066e+03, -1.336e+02,
         1.379e+02,  3.054e+00,  4.936e+02, -5.449e+02, -7.400e+02, -2.702e+01,
         3.004e+02,  1.077e+03, -5.512e+02, -4.618e+02,  1.913e+03,  1.663e+03,
         1.889e+02, -7.395e+01, -6.463e+02,  3.794e+02, -4.423e+02, -6.231e+02,
        -2.383e+02, -4.642e+02, -6.322e+02, -4.348e+02,  5.395e+01,  8.658e+01,
        -3.231e+02, -5.609e+02,  1.082e+03,  4.250e+02, -4.159e+02, -6.251e+02,
         3.497e+00, -3.213e+02, -5.273e+02, -6.777e+02, -6.796e+02, -8.862e+02,
        -3.502e+02,  1.301e+03, -5.521e+02,  2.655e+02,  2.013e+03, -8.025e+02,
        -4.668e+02, -6.570e+02,  1.060e+02, -2.647e+02, -5.580e+02, -4.889e+02,
        -5.512e+02,  5.372e+02, -4.388e+02, -2.381e+02, -3.233e+02,  5.493e+02,
        -6.281e+02,  4.643e+02, -6.977e+02, -6.095e+02,  1.392e+02,  4.526e+02,
         1.920e+03, -5.110e+02, -5.259e+02, -3.437e+02, -8.834e+02,  1.399e+02,
        -7.728e+02, -4.483e+02, -4.908e+02,  6.100e+02, -8.419e+02, -4.916e+02,
        -3.638e+02, -6.234e+02, -1.951e+02,  8.042e+01, -6.843e+02, -5.761e+02,
        -1.022e+01, -2.123e+02, -6.811e+02, -5.206e+02, -5.418e+02, -5.737e+02,
        -4.997e+02, -1.693e+02, -6.334e+02,  1.292e+02, -1.373e+02, -6.654e+02,
        -7.564e+02,  2.906e+02, -7.513e+02, -4.623e+02,  2.476e+02, -5.768e+02,
        -8.105e+01, -2.770e+02,  9.092e+02, -5.373e+02, -2.950e+02, -3.242e+01,
        -1.626e+02,  1.664e+02, -4.912e+02, -6.190e+02,  1.552e+03, -1.303e+02,
        -6.968e+02,  6.471e+02, -7.199e+02, -3.219e+02, -4.621e+02, -3.845e+02,
        -7.033e+02, -6.347e+01, -3.312e+02, -3.752e+02, -3.623e+02, -5.997e+02,
        -3.495e+02,  2.487e+03,  1.279e+02,  2.824e+01, -7.410e+02, -6.108e+02,
         7.336e+01, -5.814e+02, -6.568e+02, -5.426e+02, -8.599e+02, -7.268e+02,
        -6.953e+02, -5.526e+02,  1.956e+02, -3.991e+02, -6.547e+02, -5.865e+02,
        -3.298e+02, -6.534e+02,  2.457e+03, -4.954e+02, -6.381e+02, -5.110e+02,
        -7.030e+02, -5.670e+02,  3.197e+02,  5.129e+02,  6.077e+02, -6.703e+02,
        -5.888e+02, -2.603e+02, -4.154e+02, -7.297e+02, -3.899e+02,  3.924e+03,
         1.585e+02, -5.086e+02,  5.522e+02, -4.500e+02, -1.509e+02, -5.320e+02,
        -7.079e+02,  2.366e+02, -4.254e+02, -6.733e+02, -1.887e+02, -5.302e+02],
       device='cuda:0')
v tensor([1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 6.230e-01,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 3.054e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        3.497e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-4.793e+02],
         [-7.073e+02],
         [ 7.758e+02],
         [-6.525e+02],
         [-5.095e+02],
         [-1.617e+02],
         [ 3.373e+02],
         [ 5.458e+02],
         [-4.530e+02],
         [-1.938e+02]],

        [[ 1.084e+03],
         [-4.871e+02],
         [-1.784e+01],
         [-8.109e+02],
         [-1.116e+02],
         [-5.435e+02],
         [ 8.457e+02],
         [-8.035e+02],
         [-1.016e+01],
         [ 9.861e+01]],

        [[ 3.438e+02],
         [-2.418e+02],
         [-8.027e+02],
         [-4.296e+02],
         [ 1.211e+03],
         [ 6.998e+02],
         [-5.058e+02],
         [-6.900e+02],
         [-3.507e+02],
         [ 1.128e+03]],

        [[-3.175e+02],
         [-1.680e+02],
         [ 2.584e+02],
         [-5.563e+02],
         [-7.329e+01],
         [-5.519e+02],
         [-2.819e+02],
         [ 8.104e+02],
         [-5.657e+02],
         [-4.701e+02]],

        [[-1.228e+02],
         [-1.633e+02],
         [ 1.088e+03],
         [-5.569e+02],
         [ 3.478e+03],
         [-5.416e+02],
         [-7.245e+02],
         [ 2.128e+03],
         [ 8.142e+01],
         [ 2.276e+03]],

        [[-2.957e+02],
         [ 8.984e+02],
         [-6.587e+02],
         [-3.438e+02],
         [-3.612e+02],
         [ 3.343e+02],
         [-6.514e+02],
         [-7.838e+02],
         [ 5.392e+01],
         [-4.494e+02]],

        [[-7.821e+02],
         [-3.605e+02],
         [-3.057e+02],
         [-5.919e+02],
         [-5.193e+02],
         [-5.465e+01],
         [-7.801e+02],
         [-5.582e+02],
         [-3.258e+02],
         [-2.656e+02]],

        [[-7.015e+02],
         [-6.368e+02],
         [-7.351e+02],
         [-8.842e+02],
         [ 1.424e+03],
         [-7.980e+02],
         [-7.858e+02],
         [ 2.151e+02],
         [-7.042e+02],
         [-8.122e+02]],

        [[-6.078e+02],
         [ 1.856e+02],
         [ 1.915e+02],
         [-7.736e+02],
         [ 1.046e+03],
         [ 6.586e+02],
         [-4.626e+02],
         [-5.805e+02],
         [-6.593e+02],
         [-3.336e+02]],

        [[-5.188e+02],
         [-5.414e+02],
         [-5.835e+02],
         [-3.906e+02],
         [-5.528e+02],
         [ 2.343e+02],
         [-7.424e+02],
         [-1.042e+02],
         [-3.906e+02],
         [-7.332e+02]],

        [[-6.836e+02],
         [-1.422e+02],
         [-5.370e+02],
         [-4.304e+02],
         [-6.438e+02],
         [ 4.618e+02],
         [-7.158e+02],
         [-5.175e+02],
         [-6.969e+02],
         [ 8.796e+02]],

        [[-1.605e+02],
         [-2.961e+02],
         [-7.104e+02],
         [ 1.815e+02],
         [ 3.449e+03],
         [ 2.364e+03],
         [-3.998e+02],
         [-3.508e+01],
         [-5.488e+02],
         [ 5.785e+03]],

        [[-4.868e+02],
         [ 1.785e+01],
         [-5.991e+02],
         [ 3.115e+01],
         [-5.372e+02],
         [ 8.697e+02],
         [-6.987e+02],
         [-2.065e+02],
         [ 4.737e+00],
         [-7.100e+02]],

        [[ 1.265e+01],
         [ 2.667e+03],
         [ 6.098e+02],
         [-7.321e+02],
         [-6.803e+02],
         [-2.818e+01],
         [-7.020e+02],
         [-3.437e+02],
         [-6.162e+02],
         [-2.459e+02]],

        [[-5.072e+02],
         [-5.194e+02],
         [-7.747e+02],
         [-3.304e+02],
         [ 2.230e+02],
         [ 2.021e+03],
         [-5.555e+02],
         [-6.360e+02],
         [-7.300e+02],
         [ 2.770e+01]],

        [[-3.778e+02],
         [-4.325e+02],
         [ 1.566e+02],
         [ 1.454e+03],
         [-4.792e+02],
         [-4.476e+02],
         [-6.834e+02],
         [-5.509e+02],
         [-7.330e+02],
         [ 1.832e+02]],

        [[-5.854e+02],
         [-6.248e+02],
         [-4.313e+02],
         [-4.239e+02],
         [-1.834e+02],
         [ 4.761e+02],
         [-6.877e+02],
         [-2.070e+02],
         [-4.378e+02],
         [ 5.723e+02]],

        [[-3.656e+02],
         [ 1.557e+03],
         [ 8.914e+02],
         [-7.967e+02],
         [-6.469e+02],
         [-5.675e+02],
         [ 1.011e+02],
         [-5.699e+02],
         [ 1.027e+03],
         [-6.739e+02]],

        [[-4.170e+02],
         [ 8.593e+01],
         [-5.111e+02],
         [ 7.276e+02],
         [-6.156e+02],
         [-4.712e+02],
         [-3.715e+02],
         [-4.569e+02],
         [-2.073e+02],
         [ 8.461e+01]],

        [[-7.607e+02],
         [-4.730e+02],
         [-5.108e+02],
         [-3.426e+02],
         [-4.960e+02],
         [ 2.498e+02],
         [-6.993e+02],
         [ 1.104e+03],
         [ 1.368e+02],
         [-7.062e+02]],

        [[ 1.380e+02],
         [-5.262e+02],
         [-4.502e+02],
         [-2.381e+02],
         [-3.505e+02],
         [-6.660e+02],
         [-3.347e+02],
         [-6.479e+02],
         [ 6.586e+02],
         [ 2.380e+00]],

        [[-7.902e+01],
         [-4.358e+02],
         [-7.651e+02],
         [-6.393e+02],
         [ 6.286e+02],
         [ 9.700e+01],
         [ 7.169e+00],
         [-6.273e+02],
         [-2.313e+02],
         [-2.307e+02]],

        [[-5.970e+02],
         [ 4.588e+02],
         [-8.154e+02],
         [ 2.025e+03],
         [-5.021e+02],
         [ 7.910e+02],
         [ 9.442e+02],
         [-6.536e+02],
         [ 2.146e+01],
         [-6.712e+02]],

        [[-6.702e+02],
         [-4.571e+02],
         [-5.450e+02],
         [-6.411e+02],
         [ 1.789e+03],
         [-7.290e+02],
         [ 2.029e+03],
         [-4.597e+02],
         [-2.872e+01],
         [-5.270e+02]],

        [[-3.104e+02],
         [-4.840e+02],
         [ 3.393e+03],
         [-5.769e+02],
         [ 5.447e+02],
         [-9.954e+01],
         [-5.786e+02],
         [ 2.441e+03],
         [-4.986e+02],
         [ 1.753e+03]],

        [[-7.819e+02],
         [-7.381e+02],
         [-8.196e+01],
         [-4.328e+02],
         [-3.487e+02],
         [-4.814e+02],
         [-5.549e+02],
         [-8.564e+02],
         [-2.348e+01],
         [-4.632e+02]],

        [[-4.793e+02],
         [-2.679e+02],
         [-6.779e+02],
         [-5.160e+02],
         [ 6.141e+03],
         [-7.600e+01],
         [ 4.386e+03],
         [-1.069e+02],
         [-5.211e+02],
         [-1.118e+02]],

        [[-8.479e+00],
         [-4.448e+02],
         [-2.540e+02],
         [-6.670e+02],
         [ 2.764e+03],
         [-7.672e+02],
         [-2.246e+02],
         [-7.457e+02],
         [-2.487e+02],
         [ 3.044e+02]],

        [[ 8.317e+01],
         [-9.464e+01],
         [ 6.245e+02],
         [ 1.603e+03],
         [ 5.752e+02],
         [-4.280e+02],
         [ 2.446e+03],
         [ 1.402e+03],
         [ 1.101e+03],
         [-4.528e+02]],

        [[-6.102e+02],
         [-5.919e+01],
         [ 2.021e+03],
         [-4.703e+02],
         [-6.168e+02],
         [-4.924e+02],
         [-6.093e+02],
         [-3.558e+02],
         [ 6.640e+02],
         [-1.218e+02]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [4.737e+00],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [2.380e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [7.169e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[-837.139],
        [ 831.003],
        [-844.787],
        [-667.397],
        [ 351.554],
        [-503.786],
        [-143.833],
        [-246.941],
        [ 762.894],
        [-787.451],
        [-579.112],
        [ 611.442],
        [-441.028],
        [-777.278],
        [-635.685],
        [-644.355],
        [-736.265],
        [-417.396],
        [ 855.091],
        [-679.159],
        [-218.260],
        [ 619.949],
        [ 141.070],
        [-376.682],
        [-419.865],
        [-745.364],
        [-253.904],
        [ 304.746],
        [-592.173],
        [-561.286]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-0.013,  0.064, -0.013,  ..., -0.233,  0.020,  0.382],
        [-0.004,  0.054,  0.311,  ..., -0.026,  0.079, -0.371],
        [ 0.023, -0.158, -0.279,  ..., -0.036, -0.125, -0.026],
        ...,
        [-0.154,  0.143, -0.428,  ...,  0.099,  0.086,  0.100],
        [-0.232,  0.257, -0.035,  ..., -0.028,  1.039, -0.165],
        [ 0.078,  0.150, -0.230,  ...,  0.121, -0.569,  0.103]],
       device='cuda:0')
s after update for 1 param tensor([[1.815, 1.871, 2.146,  ..., 1.916, 1.641, 0.969],
        [1.274, 1.498, 1.641,  ..., 1.837, 1.828, 1.556],
        [1.299, 1.577, 1.730,  ..., 1.792, 1.098, 1.740],
        ...,
        [1.375, 2.184, 1.967,  ..., 1.388, 1.149, 2.071],
        [1.231, 1.588, 1.478,  ..., 1.276, 1.337, 2.035],
        [1.453, 1.765, 1.817,  ..., 1.965, 1.573, 2.154]], device='cuda:0')
b after update for 1 param tensor([[174.785, 177.445, 190.041,  ..., 179.595, 166.206, 127.711],
        [146.459, 158.797, 166.204,  ..., 175.846, 175.431, 161.822],
        [147.865, 162.902, 170.640,  ..., 173.683, 135.935, 171.151],
        ...,
        [152.140, 191.752, 181.947,  ..., 152.856, 139.042, 186.702],
        [143.971, 163.496, 157.738,  ..., 146.534, 150.044, 185.085],
        [156.385, 172.376, 174.873,  ..., 181.883, 162.701, 190.400]],
       device='cuda:0')
clipping threshold 1.320954866444353
a after update for 1 param tensor([ 1.269e-01, -1.868e-02, -1.954e-01,  5.901e-02,  3.449e-01,  1.512e-01,
        -2.985e-01, -5.509e-01, -5.120e-02,  3.686e-01, -3.561e-01,  1.186e-01,
        -2.851e-01,  9.631e-03,  2.295e-01,  4.006e-01,  3.581e-01,  1.168e-01,
        -3.435e-01,  2.008e-01,  1.625e-01,  1.722e-01, -4.643e-01, -1.645e-01,
        -1.273e-01, -3.686e-01,  1.258e-01, -4.263e-02, -7.267e-04,  3.231e-01,
        -5.066e-02,  1.650e-01,  1.247e-01, -2.784e-02, -4.710e-01, -3.682e-01,
         1.736e-01,  9.231e-02, -2.657e-01,  1.447e-01,  8.101e-02, -2.509e-01,
         4.102e-01, -4.150e-02,  1.319e-01,  3.402e-02, -1.395e-01,  7.089e-03,
         1.918e-01,  2.207e-01, -3.491e-01,  2.511e-01,  2.428e-01, -1.995e-01,
        -1.806e-01,  1.875e-01, -1.847e-01,  4.121e-02,  1.496e-01, -2.470e-01,
        -3.370e-01, -4.410e-01, -1.432e-01, -3.323e-02, -7.149e-02, -2.548e-02,
         3.058e-01,  1.414e-01, -1.892e-01,  6.498e-02,  1.993e-01,  6.088e-02,
        -1.661e-01,  2.260e-02, -3.173e-01,  2.406e-01,  3.612e-02,  2.223e-01,
        -7.198e-01, -2.292e-02, -2.493e-01, -7.377e-01,  5.592e-02, -2.490e-01,
        -7.641e-02, -2.692e-03, -2.511e-01,  4.904e-02,  3.325e-01, -4.190e-01,
         2.917e-01,  1.809e-01, -1.823e-01,  1.211e-01, -8.635e-03,  2.155e-02,
         1.092e-01, -4.357e-01,  4.082e-02, -1.095e-01,  9.744e-02, -1.458e-02,
        -3.114e-01, -1.491e-01,  2.186e-01, -5.602e-01, -2.916e-01, -4.106e-02,
         7.795e-02,  2.099e-01,  6.482e-02,  7.985e-02,  1.743e-01,  1.477e-01,
        -2.003e-01,  3.854e-01, -2.405e-02, -5.957e-02, -1.727e-01, -1.463e-02,
         1.626e-01, -1.811e-01,  1.110e-01,  6.035e-02, -2.676e-02,  6.405e-01,
         4.959e-02, -1.120e-01, -5.698e-01, -1.069e-01, -9.134e-02,  2.309e-01,
        -5.728e-01, -5.288e-02, -2.616e-01, -2.528e-01,  9.315e-02,  5.949e-02,
         2.539e-01,  1.197e-01,  2.984e-04,  9.722e-02,  1.192e-01,  7.043e-02,
        -1.618e-01, -5.528e-02, -4.469e-01,  4.815e-01,  1.926e-01,  6.702e-02,
        -3.617e-02, -1.066e-01,  5.326e-01, -2.718e-02,  5.759e-01,  2.224e-01,
         6.270e-01, -5.101e-02,  8.137e-02, -2.018e-01, -1.140e-01, -2.877e-01,
         6.696e-01,  3.964e-01, -4.179e-02, -5.761e-02, -4.477e-02,  1.736e-01,
         3.892e-01,  9.202e-02,  1.400e-03,  2.213e-01,  4.061e-01, -1.589e-01,
        -6.668e-02, -9.423e-03,  9.397e-02, -3.828e-01,  3.750e-02, -3.463e-02,
        -5.074e-01, -1.970e-02,  2.684e-02,  9.653e-02,  8.965e-02,  1.996e-01,
         8.079e-02,  2.604e-01, -2.587e-01, -9.899e-02, -6.044e-01, -9.404e-02,
         4.431e-01,  3.354e-01,  3.403e-02, -3.410e-02,  2.831e-01, -2.562e-01,
         1.108e-01, -6.597e-01, -8.782e-02,  1.310e-01, -4.158e-01, -3.857e-01,
         4.076e-01,  1.233e-01, -6.029e-02, -9.259e-02,  1.976e-01, -6.018e-02,
        -1.084e-01, -2.151e-01,  2.070e-01, -1.461e-01,  2.419e-01, -1.727e-01,
         3.181e-01, -4.226e-01, -2.374e-01, -2.866e-01, -3.871e-02,  8.778e-02,
         6.709e-01, -5.014e-01,  6.415e-01, -2.350e-01, -2.953e-01,  2.519e-01,
         1.689e-01, -1.192e-01,  1.548e-01,  2.307e-01, -2.059e-01,  1.389e-01,
        -1.727e-01, -1.766e-01,  1.759e-01,  4.798e-02, -2.017e-01,  1.896e-01,
         4.591e-01, -3.728e-02,  1.370e-01, -4.667e-01, -4.241e-01, -1.176e-01,
        -3.321e-01,  1.392e-01, -1.153e-01, -1.649e-01, -1.239e-01, -1.059e-01,
         2.575e-01,  3.733e-01,  2.070e-01, -1.704e-01, -2.073e-01, -3.077e-01,
        -4.190e-02, -3.288e-01,  1.854e-02,  6.108e-02,  1.406e-01, -1.702e-01,
         9.857e-02,  6.577e-02, -1.561e-01, -2.530e-01, -1.593e-01,  5.483e-02,
         2.637e-02, -2.701e-01,  6.708e-01, -2.283e-01, -7.692e-02,  4.728e-01,
        -1.575e-02, -9.402e-02, -6.725e-01,  3.005e-01, -2.567e-01, -2.328e-01,
        -2.072e-01,  3.961e-01, -1.905e-01, -6.350e-01, -2.024e-01,  9.559e-01,
        -4.550e-01,  6.058e-01,  1.384e-01, -8.815e-02,  2.015e-01,  6.046e-02,
        -1.108e-01, -5.879e-01,  6.477e-01, -3.272e-01, -2.505e-01, -2.339e-01],
       device='cuda:0')
s after update for 1 param tensor([1.747, 1.961, 1.751, 1.169, 1.151, 2.041, 1.929, 1.569, 1.939, 2.217,
        1.578, 1.979, 1.652, 1.552, 2.176, 1.686, 1.453, 1.812, 1.584, 1.778,
        2.143, 1.734, 1.529, 2.082, 1.718, 2.183, 2.129, 1.507, 1.901, 1.974,
        1.586, 2.355, 1.574, 1.246, 1.629, 2.064, 1.940, 1.475, 1.800, 2.084,
        1.189, 1.655, 1.849, 1.825, 1.684, 2.099, 1.197, 1.300, 1.305, 1.804,
        1.837, 1.834, 1.820, 1.777, 1.883, 1.515, 1.840, 2.273, 2.104, 1.853,
        1.918, 1.730, 1.825, 1.903, 1.261, 1.658, 1.625, 2.210, 1.848, 1.598,
        1.799, 1.600, 1.464, 1.867, 2.188, 1.536, 1.417, 2.036, 1.480, 1.333,
        2.343, 1.459, 1.937, 1.138, 1.567, 1.596, 1.548, 1.751, 1.853, 1.447,
        1.525, 1.690, 1.626, 1.539, 1.890, 1.411, 1.892, 1.487, 1.816, 1.591,
        0.784, 1.942, 1.977, 1.678, 2.125, 1.525, 1.301, 1.281, 1.602, 1.372,
        2.194, 2.205, 1.895, 1.636, 1.515, 1.713, 1.715, 1.785, 1.339, 1.900,
        1.776, 1.873, 1.913, 1.184, 1.570, 1.706, 1.265, 1.953, 1.776, 1.521,
        2.519, 1.814, 2.026, 1.728, 1.753, 1.396, 2.098, 1.471, 2.061, 1.664,
        1.371, 1.493, 1.934, 1.599, 2.152, 1.378, 1.840, 1.894, 1.091, 1.526,
        1.805, 1.677, 2.137, 1.067, 1.505, 2.102, 1.179, 1.788, 1.927, 2.126,
        1.318, 1.587, 1.768, 2.090, 1.488, 1.826, 1.661, 2.191, 1.425, 1.752,
        1.348, 1.569, 1.849, 1.966, 1.787, 1.609, 2.165, 1.827, 1.704, 1.213,
        1.857, 1.667, 1.229, 1.555, 2.050, 2.005, 2.398, 1.766, 1.805, 1.815,
        1.877, 1.647, 2.147, 1.381, 1.420, 1.551, 2.232, 2.098, 1.893, 1.850,
        1.703, 1.929, 2.055, 1.657, 1.433, 1.593, 1.273, 1.953, 1.719, 1.450,
        1.417, 1.392, 1.689, 1.273, 1.742, 1.591, 2.194, 1.644, 1.586, 1.939,
        2.168, 1.721, 1.931, 2.112, 2.098, 1.336, 1.881, 1.488, 1.269, 1.310,
        1.967, 1.413, 1.544, 1.640, 1.301, 1.944, 1.858, 1.850, 1.829, 1.789,
        2.045, 2.044, 1.773, 1.117, 1.540, 1.341, 2.049, 1.430, 0.838, 1.466,
        1.487, 1.468, 1.611, 1.985, 1.575, 1.891, 1.940, 2.161, 1.855, 1.514,
        1.611, 1.371, 2.163, 1.774, 1.718, 1.410, 1.695, 1.741, 1.601, 1.465,
        1.360, 1.789, 1.785, 1.299, 1.714, 1.401, 1.850, 1.384, 1.887, 2.029,
        1.711, 1.703, 1.791, 0.896, 1.401, 1.794, 1.414, 1.927, 1.779, 1.629,
        1.647, 1.599, 1.640, 1.840, 1.855, 2.219, 1.526, 1.867, 0.965, 2.034],
       device='cuda:0')
b after update for 1 param tensor([171.501, 181.701, 171.686, 140.254, 139.173, 185.331, 180.182, 162.498,
        180.671, 193.200, 162.987, 182.533, 166.765, 161.649, 191.399, 168.447,
        156.412, 174.657, 163.311, 172.987, 189.927, 170.864, 160.420, 187.188,
        170.057, 191.713, 189.305, 159.259, 178.888, 182.288, 163.371, 199.090,
        162.778, 144.851, 165.577, 186.409, 180.693, 157.552, 174.065, 187.273,
        141.443, 166.922, 176.414, 175.270, 168.357, 187.990, 141.969, 147.927,
        148.185, 174.240, 175.824, 175.724, 175.041, 172.963, 178.031, 159.678,
        175.990, 195.622, 188.172, 176.602, 179.662, 170.626, 175.257, 178.984,
        145.682, 167.048, 165.391, 192.877, 176.380, 164.032, 174.033, 164.101,
        157.002, 177.268, 191.910, 160.784, 154.455, 185.146, 157.826, 149.767,
        198.585, 156.720, 180.581, 138.415, 162.427, 163.886, 161.400, 171.665,
        176.591, 156.076, 160.224, 168.674, 165.418, 160.941, 178.363, 154.109,
        178.451, 158.207, 174.845, 163.627, 114.858, 180.814, 182.431, 168.087,
        189.146, 160.203, 147.960, 146.852, 164.213, 151.995, 192.173, 192.642,
        178.613, 165.941, 159.667, 169.811, 169.909, 173.318, 150.110, 178.838,
        172.887, 177.539, 179.459, 141.161, 162.542, 169.479, 145.924, 181.336,
        172.906, 159.983, 205.903, 174.727, 184.674, 170.560, 171.764, 153.295,
        187.917, 157.340, 186.262, 167.352, 151.906, 158.551, 180.447, 164.045,
        190.333, 152.301, 175.988, 178.540, 135.496, 160.295, 174.330, 168.004,
        189.667, 133.992, 159.148, 188.117, 140.884, 173.491, 180.091, 189.188,
        148.933, 163.418, 172.497, 187.566, 158.239, 175.309, 167.209, 192.043,
        154.871, 171.748, 150.647, 162.533, 176.435, 181.919, 173.447, 164.580,
        190.882, 175.352, 169.350, 142.895, 176.817, 167.503, 143.815, 161.764,
        185.763, 183.712, 200.896, 172.402, 174.290, 174.795, 177.748, 166.509,
        190.096, 152.480, 154.617, 161.564, 193.839, 187.923, 178.510, 176.464,
        169.302, 180.175, 185.993, 167.023, 155.314, 163.766, 146.365, 181.332,
        170.098, 156.230, 154.452, 153.084, 168.635, 146.360, 171.233, 163.661,
        192.196, 166.347, 163.396, 180.663, 191.018, 170.205, 180.312, 188.541,
        187.922, 149.959, 177.920, 158.241, 146.149, 148.512, 181.943, 154.203,
        161.205, 166.131, 147.989, 180.875, 176.857, 176.457, 175.460, 173.516,
        185.541, 185.483, 172.757, 137.146, 161.008, 150.251, 185.736, 155.126,
        118.781, 157.093, 158.220, 157.222, 164.676, 182.776, 162.802, 178.420,
        180.700, 190.707, 176.727, 159.639, 164.653, 151.940, 190.831, 172.824,
        170.045, 154.050, 168.898, 171.195, 164.179, 157.009, 151.278, 173.542,
        173.360, 147.850, 169.869, 153.576, 176.456, 152.641, 178.211, 184.814,
        169.700, 169.313, 173.633, 122.835, 153.585, 173.755, 154.258, 180.112,
        173.051, 165.607, 166.494, 164.041, 166.156, 176.014, 176.689, 193.260,
        160.276, 177.255, 127.457, 185.022], device='cuda:0')
clipping threshold 1.320954866444353
a after update for 1 param tensor([[[ 0.195],
         [-0.383],
         [-0.299],
         [-0.160],
         [-0.320],
         [ 0.382],
         [-0.201],
         [-0.047],
         [-0.023],
         [ 0.224]],

        [[-0.274],
         [ 0.349],
         [-0.191],
         [-0.188],
         [ 0.167],
         [ 0.489],
         [ 0.233],
         [-0.196],
         [-0.145],
         [-0.116]],

        [[-0.160],
         [-0.380],
         [-0.078],
         [-0.482],
         [ 0.351],
         [ 0.118],
         [-0.209],
         [-0.331],
         [ 0.472],
         [-0.232]],

        [[ 0.367],
         [ 0.053],
         [ 0.255],
         [ 0.107],
         [ 0.413],
         [ 0.297],
         [ 0.060],
         [ 0.152],
         [ 0.191],
         [-0.187]],

        [[ 0.246],
         [ 0.111],
         [-0.004],
         [-0.012],
         [ 0.038],
         [-0.293],
         [ 0.094],
         [-0.039],
         [ 0.024],
         [ 0.413]],

        [[ 0.373],
         [-0.142],
         [-0.069],
         [-0.377],
         [-0.063],
         [-0.471],
         [-0.165],
         [ 0.421],
         [-0.174],
         [ 0.630]],

        [[ 0.138],
         [ 0.238],
         [-0.277],
         [-0.073],
         [-0.319],
         [ 0.407],
         [ 0.122],
         [ 0.369],
         [-0.349],
         [-0.039]],

        [[ 0.035],
         [-0.004],
         [ 0.373],
         [ 0.331],
         [-0.313],
         [ 0.436],
         [-0.528],
         [-0.230],
         [-0.085],
         [ 0.124]],

        [[-0.165],
         [ 0.018],
         [-0.090],
         [ 0.068],
         [ 0.274],
         [ 0.175],
         [-0.104],
         [ 0.674],
         [ 0.299],
         [ 0.204]],

        [[-0.228],
         [-0.371],
         [ 0.210],
         [ 0.001],
         [ 0.109],
         [ 0.136],
         [ 0.244],
         [ 0.080],
         [-0.068],
         [-0.216]],

        [[ 0.444],
         [-0.005],
         [ 0.200],
         [ 0.194],
         [-0.167],
         [-0.227],
         [ 0.186],
         [-0.210],
         [-0.329],
         [-0.238]],

        [[ 0.479],
         [ 0.555],
         [ 0.185],
         [ 0.388],
         [-0.070],
         [ 0.398],
         [ 0.170],
         [-0.134],
         [ 0.159],
         [ 0.025]],

        [[ 0.151],
         [ 0.414],
         [ 0.169],
         [ 0.257],
         [ 0.007],
         [-0.158],
         [-0.153],
         [ 0.242],
         [-0.110],
         [ 0.088]],

        [[-0.194],
         [ 0.221],
         [ 0.490],
         [ 0.167],
         [-0.311],
         [-0.459],
         [ 0.202],
         [ 0.094],
         [ 0.008],
         [-0.241]],

        [[ 0.431],
         [ 0.078],
         [ 0.136],
         [ 0.048],
         [ 0.175],
         [ 0.509],
         [-0.075],
         [-0.103],
         [ 0.365],
         [ 0.103]],

        [[ 0.027],
         [-0.558],
         [ 0.379],
         [ 0.494],
         [-0.015],
         [ 0.123],
         [-0.413],
         [ 0.345],
         [ 0.236],
         [ 0.004]],

        [[-0.823],
         [ 0.258],
         [-0.206],
         [ 0.103],
         [ 0.159],
         [ 0.107],
         [ 0.547],
         [-0.019],
         [ 0.034],
         [ 0.455]],

        [[-0.003],
         [ 0.099],
         [-0.075],
         [-0.286],
         [ 0.305],
         [ 0.383],
         [ 0.285],
         [-0.051],
         [ 0.100],
         [-0.058]],

        [[ 0.001],
         [-0.534],
         [ 0.182],
         [ 0.155],
         [ 0.096],
         [-0.513],
         [ 0.349],
         [-0.336],
         [ 0.182],
         [ 0.339]],

        [[ 0.707],
         [ 0.062],
         [-0.192],
         [-0.439],
         [-0.075],
         [-0.237],
         [ 0.115],
         [-0.034],
         [-0.046],
         [ 0.149]],

        [[-0.322],
         [-0.369],
         [ 0.113],
         [ 0.089],
         [ 0.221],
         [-0.197],
         [-0.203],
         [-0.358],
         [-0.141],
         [-0.067]],

        [[ 0.084],
         [ 0.033],
         [ 0.240],
         [ 0.061],
         [-0.398],
         [-0.560],
         [ 0.106],
         [-0.291],
         [ 0.158],
         [-0.059]],

        [[ 0.132],
         [ 0.477],
         [ 0.400],
         [ 0.245],
         [ 0.179],
         [ 0.134],
         [ 0.152],
         [ 0.243],
         [-0.498],
         [ 0.094]],

        [[-0.051],
         [-0.215],
         [ 0.046],
         [ 0.047],
         [-0.003],
         [-0.095],
         [ 0.366],
         [-0.158],
         [-0.067],
         [ 0.296]],

        [[-0.262],
         [ 0.012],
         [ 0.333],
         [-0.180],
         [-0.052],
         [-0.253],
         [ 0.181],
         [-0.048],
         [ 0.208],
         [ 0.081]],

        [[-0.195],
         [-0.435],
         [-0.075],
         [ 0.351],
         [-0.203],
         [ 0.208],
         [-0.015],
         [-0.378],
         [ 0.235],
         [ 0.185]],

        [[ 0.083],
         [ 0.277],
         [-0.016],
         [ 0.154],
         [-0.257],
         [-0.800],
         [ 0.303],
         [ 0.138],
         [-0.450],
         [-0.097]],

        [[ 0.223],
         [ 0.361],
         [ 0.035],
         [ 0.227],
         [ 0.166],
         [ 0.005],
         [ 0.105],
         [ 0.251],
         [-0.048],
         [ 0.028]],

        [[ 0.044],
         [ 0.368],
         [-0.047],
         [-0.284],
         [-0.194],
         [-0.025],
         [-0.126],
         [ 0.155],
         [-0.315],
         [ 0.278]],

        [[ 0.077],
         [-0.289],
         [-0.275],
         [-0.005],
         [ 0.235],
         [ 0.086],
         [-0.116],
         [ 0.483],
         [ 0.625],
         [-0.471]]], device='cuda:0')
s after update for 1 param tensor([[[1.624],
         [1.725],
         [2.053],
         [1.594],
         [1.280],
         [1.326],
         [2.163],
         [1.261],
         [1.308],
         [0.965]],

        [[2.333],
         [1.377],
         [1.056],
         [1.977],
         [1.392],
         [1.594],
         [2.270],
         [1.966],
         [1.046],
         [1.977]],

        [[1.782],
         [1.508],
         [1.959],
         [1.048],
         [1.501],
         [1.691],
         [1.371],
         [1.687],
         [1.437],
         [2.253]],

        [[1.160],
         [1.637],
         [2.306],
         [1.402],
         [1.540],
         [1.661],
         [0.940],
         [2.381],
         [1.715],
         [1.223]],

        [[1.792],
         [1.505],
         [1.958],
         [1.478],
         [1.823],
         [1.323],
         [1.787],
         [1.761],
         [1.907],
         [1.898]],

        [[1.622],
         [1.789],
         [1.626],
         [2.084],
         [1.669],
         [1.602],
         [1.831],
         [1.968],
         [1.964],
         [1.742]],

        [[1.912],
         [1.318],
         [1.196],
         [1.897],
         [1.267],
         [1.303],
         [1.977],
         [1.651],
         [0.989],
         [1.718]],

        [[1.720],
         [1.624],
         [1.958],
         [2.164],
         [2.132],
         [1.953],
         [2.029],
         [2.064],
         [1.740],
         [2.090]],

        [[1.601],
         [1.500],
         [2.055],
         [1.946],
         [2.149],
         [1.669],
         [1.417],
         [1.458],
         [1.682],
         [1.619]],

        [[1.308],
         [2.185],
         [1.674],
         [1.451],
         [1.748],
         [2.285],
         [2.199],
         [1.865],
         [1.648],
         [1.793]],

        [[1.669],
         [1.378],
         [1.655],
         [1.352],
         [1.747],
         [2.358],
         [1.830],
         [1.576],
         [1.699],
         [2.081]],

        [[1.711],
         [1.552],
         [2.238],
         [1.749],
         [2.053],
         [1.705],
         [1.407],
         [1.963],
         [1.369],
         [1.885]],

        [[1.434],
         [1.859],
         [2.230],
         [2.376],
         [1.312],
         [1.611],
         [1.706],
         [1.324],
         [1.758],
         [1.832]],

        [[1.446],
         [1.763],
         [1.914],
         [1.801],
         [1.809],
         [1.474],
         [1.839],
         [1.482],
         [1.663],
         [1.522]],

        [[1.606],
         [1.731],
         [1.892],
         [1.553],
         [1.812],
         [1.922],
         [1.879],
         [1.597],
         [1.793],
         [2.111]],

        [[1.839],
         [1.400],
         [1.651],
         [2.102],
         [1.626],
         [1.645],
         [1.674],
         [1.645],
         [1.809],
         [1.611]],

        [[1.615],
         [1.524],
         [1.799],
         [1.475],
         [1.722],
         [1.930],
         [1.677],
         [1.494],
         [1.831],
         [1.750]],

        [[1.564],
         [2.135],
         [1.877],
         [1.956],
         [1.755],
         [1.562],
         [1.602],
         [1.402],
         [2.359],
         [1.759]],

        [[1.020],
         [2.162],
         [1.763],
         [1.586],
         [1.839],
         [2.281],
         [1.415],
         [1.274],
         [2.105],
         [2.031]],

        [[2.044],
         [1.567],
         [1.503],
         [1.904],
         [1.277],
         [1.861],
         [1.718],
         [1.572],
         [1.910],
         [1.724]],

        [[1.849],
         [1.896],
         [1.584],
         [1.756],
         [1.841],
         [1.665],
         [1.683],
         [1.770],
         [1.554],
         [1.860]],

        [[1.599],
         [1.972],
         [1.892],
         [1.593],
         [2.165],
         [2.137],
         [2.459],
         [1.760],
         [1.029],
         [2.210]],

        [[1.918],
         [2.055],
         [2.054],
         [2.113],
         [1.648],
         [2.015],
         [1.900],
         [1.809],
         [1.774],
         [1.968]],

        [[1.642],
         [1.202],
         [1.867],
         [1.913],
         [1.472],
         [1.777],
         [2.001],
         [1.198],
         [1.650],
         [1.338]],

        [[1.201],
         [1.186],
         [1.970],
         [1.579],
         [1.681],
         [1.760],
         [1.411],
         [2.388],
         [1.633],
         [2.165]],

        [[1.992],
         [1.802],
         [1.060],
         [1.522],
         [1.268],
         [1.781],
         [1.414],
         [2.177],
         [1.602],
         [1.785]],

        [[1.668],
         [1.100],
         [1.832],
         [1.594],
         [2.243],
         [1.253],
         [2.346],
         [1.911],
         [1.553],
         [1.602]],

        [[1.337],
         [1.600],
         [1.134],
         [1.629],
         [2.158],
         [1.871],
         [1.849],
         [1.846],
         [1.228],
         [1.501]],

        [[1.602],
         [1.238],
         [1.646],
         [1.872],
         [2.032],
         [1.977],
         [1.676],
         [2.007],
         [2.010],
         [1.244]],

        [[1.488],
         [1.527],
         [2.277],
         [1.358],
         [1.791],
         [1.201],
         [1.840],
         [1.979],
         [1.600],
         [2.088]]], device='cuda:0')
b after update for 1 param tensor([[[165.321],
         [170.402],
         [185.918],
         [163.779],
         [146.761],
         [149.377],
         [190.824],
         [145.706],
         [148.388],
         [127.426]],

        [[198.190],
         [152.229],
         [133.314],
         [182.421],
         [153.091],
         [163.782],
         [195.489],
         [181.893],
         [132.689],
         [182.444]],

        [[173.203],
         [159.316],
         [181.613],
         [132.816],
         [158.930],
         [168.734],
         [151.915],
         [168.499],
         [155.519],
         [194.741]],

        [[139.735],
         [165.985],
         [197.000],
         [153.619],
         [161.000],
         [167.215],
         [125.757],
         [200.200],
         [169.916],
         [143.472]],

        [[173.657],
         [159.155],
         [181.528],
         [157.745],
         [175.163],
         [149.241],
         [173.435],
         [172.167],
         [179.179],
         [178.734]],

        [[165.212],
         [173.520],
         [165.439],
         [187.292],
         [167.630],
         [164.191],
         [175.550],
         [182.020],
         [181.838],
         [171.240]],

        [[179.410],
         [148.976],
         [141.910],
         [178.711],
         [146.023],
         [148.074],
         [182.422],
         [166.687],
         [129.049],
         [170.037]],

        [[170.137],
         [165.353],
         [181.529],
         [190.857],
         [189.446],
         [181.329],
         [184.805],
         [186.407],
         [171.160],
         [187.550]],

        [[164.144],
         [158.888],
         [186.000],
         [180.992],
         [190.184],
         [167.637],
         [154.461],
         [156.668],
         [168.260],
         [165.062]],

        [[148.389],
         [191.801],
         [167.857],
         [156.276],
         [171.556],
         [196.099],
         [192.394],
         [177.177],
         [166.549],
         [173.710]],

        [[167.620],
         [152.301],
         [166.894],
         [150.833],
         [171.477],
         [199.248],
         [175.494],
         [162.872],
         [169.129],
         [187.175]],

        [[169.711],
         [161.617],
         [194.085],
         [171.580],
         [185.894],
         [169.395],
         [153.895],
         [181.793],
         [151.803],
         [178.122]],

        [[155.342],
         [176.911],
         [193.755],
         [199.968],
         [148.609],
         [164.665],
         [169.438],
         [149.291],
         [172.001],
         [175.608]],

        [[155.992],
         [172.253],
         [179.501],
         [174.128],
         [174.493],
         [157.526],
         [175.935],
         [157.932],
         [167.304],
         [160.055]],

        [[164.399],
         [170.711],
         [178.471],
         [161.703],
         [174.652],
         [179.871],
         [177.850],
         [163.937],
         [173.724],
         [188.519]],

        [[175.932],
         [153.523],
         [166.683],
         [188.089],
         [165.461],
         [166.414],
         [167.875],
         [166.402],
         [174.507],
         [164.679]],

        [[164.882],
         [160.164],
         [174.011],
         [157.558],
         [170.248],
         [180.228],
         [167.995],
         [158.568],
         [175.550],
         [171.621]],

        [[162.262],
         [189.571],
         [177.769],
         [181.446],
         [171.856],
         [162.156],
         [164.211],
         [153.614],
         [199.267],
         [172.086]],

        [[131.023],
         [190.772],
         [172.269],
         [163.378],
         [175.933],
         [195.944],
         [154.314],
         [146.458],
         [188.231],
         [184.878]],

        [[185.486],
         [162.434],
         [159.043],
         [179.015],
         [146.627],
         [176.977],
         [170.076],
         [162.675],
         [179.294],
         [170.365]],

        [[176.444],
         [178.668],
         [163.288],
         [171.909],
         [176.014],
         [167.430],
         [168.302],
         [172.633],
         [161.757],
         [176.933]],

        [[164.082],
         [182.181],
         [178.440],
         [163.749],
         [190.917],
         [189.680],
         [203.466],
         [172.117],
         [131.588],
         [192.866]],

        [[179.671],
         [186.005],
         [185.929],
         [188.605],
         [166.550],
         [184.188],
         [178.845],
         [174.512],
         [172.815],
         [182.001]],

        [[166.247],
         [142.241],
         [177.286],
         [179.444],
         [157.392],
         [172.967],
         [183.539],
         [142.021],
         [166.672],
         [150.101]],

        [[142.155],
         [141.268],
         [182.081],
         [163.043],
         [168.222],
         [172.134],
         [154.100],
         [200.505],
         [165.819],
         [190.893]],

        [[183.124],
         [174.174],
         [133.583],
         [160.035],
         [146.079],
         [173.155],
         [154.302],
         [191.448],
         [164.217],
         [173.323]],

        [[167.569],
         [136.070],
         [175.609],
         [163.781],
         [194.292],
         [145.212],
         [198.724],
         [179.370],
         [161.664],
         [164.221]],

        [[150.016],
         [164.127],
         [138.185],
         [165.578],
         [190.598],
         [177.446],
         [176.408],
         [176.293],
         [143.773],
         [158.967]],

        [[164.196],
         [144.379],
         [166.447],
         [177.527],
         [184.957],
         [182.406],
         [167.969],
         [183.805],
         [183.924],
         [144.719]],

        [[158.251],
         [160.313],
         [195.793],
         [151.170],
         [173.652],
         [142.179],
         [175.989],
         [182.530],
         [164.113],
         [187.481]]], device='cuda:0')
clipping threshold 1.320954866444353
a after update for 1 param tensor([[ 0.225],
        [-0.558],
        [ 0.003],
        [ 0.176],
        [ 0.201],
        [-0.175],
        [-0.121],
        [ 0.039],
        [ 0.323],
        [-0.492],
        [ 0.040],
        [ 0.618],
        [ 0.116],
        [-0.020],
        [-0.026],
        [ 0.113],
        [ 0.038],
        [ 0.344],
        [ 0.056],
        [-0.135],
        [ 0.726],
        [ 0.448],
        [-0.088],
        [-0.303],
        [ 0.046],
        [ 0.110],
        [-0.238],
        [ 0.208],
        [ 0.054],
        [ 0.298]], device='cuda:0')
s after update for 1 param tensor([[2.218],
        [1.807],
        [2.066],
        [1.627],
        [1.346],
        [1.949],
        [1.665],
        [1.411],
        [1.749],
        [1.920],
        [1.926],
        [2.007],
        [1.601],
        [2.146],
        [1.790],
        [1.691],
        [1.987],
        [1.567],
        [1.935],
        [1.827],
        [1.334],
        [1.759],
        [2.197],
        [1.681],
        [1.537],
        [1.976],
        [1.543],
        [1.868],
        [1.506],
        [1.403]], device='cuda:0')
b after update for 1 param tensor([[193.206],
        [174.391],
        [186.468],
        [165.510],
        [150.545],
        [181.136],
        [167.403],
        [154.115],
        [171.591],
        [179.792],
        [180.075],
        [183.814],
        [164.174],
        [190.059],
        [173.599],
        [168.699],
        [182.896],
        [162.398],
        [180.499],
        [175.352],
        [149.823],
        [172.083],
        [192.319],
        [168.237],
        [160.862],
        [182.382],
        [161.149],
        [177.336],
        [159.231],
        [153.662]], device='cuda:0')
clipping threshold 1.320954866444353
||w||^2 2.659013294072601
exp ma of ||w||^2 2.4419078459846726
||w|| 1.6306481208625607
exp ma of ||w|| 1.5195357833764025
||w||^2 2.17358735097467
exp ma of ||w||^2 2.518263755071737
||w|| 1.4743091097102636
exp ma of ||w|| 1.5503905406308052
||w||^2 1.3742586974574413
exp ma of ||w||^2 2.5045580569536474
||w|| 1.1722878048744863
exp ma of ||w|| 1.5442678304807536
||w||^2 1.0468358100231547
exp ma of ||w||^2 2.5175083246718035
||w|| 1.0231499450340378
exp ma of ||w|| 1.54167222438844
||w||^2 1.0192861852475905
exp ma of ||w||^2 2.6017887571307154
||w|| 1.009597041025572
exp ma of ||w|| 1.5705779420139823
||w||^2 1.9447977665740543
exp ma of ||w||^2 2.3808790053377917
||w|| 1.3945600620174285
exp ma of ||w|| 1.5101379876830923
||w||^2 4.68853601759475
exp ma of ||w||^2 2.608441888719931
||w|| 2.1653027542574157
exp ma of ||w|| 1.5752362795016301
||w||^2 2.2030078092972123
exp ma of ||w||^2 2.3932336438250017
||w|| 1.4842532834045583
exp ma of ||w|| 1.5049714218686248
||w||^2 3.9007847975360552
exp ma of ||w||^2 2.682934797666776
||w|| 1.975040454658095
exp ma of ||w|| 1.6008750653796804
||w||^2 2.3421955508436803
exp ma of ||w||^2 2.3834452987866968
||w|| 1.5304233240654954
exp ma of ||w|| 1.505182526837973
cuda
Objective function 87.76 = squared loss an data 49.09 + 0.5*rho*h**2 8.735489 + alpha*h 27.223711 + L2reg 2.30 + L1reg 0.41 ; SHD = 150 ; DAG True
Proportion of microbatches that were clipped  0.7749474365194889
iteration 1 in inner loop, alpha 65.13114364781069 rho 100.0 h 0.41798299729367017
9630
cuda
Objective function 166.38 = squared loss an data 49.09 + 0.5*rho*h**2 87.354893 + alpha*h 27.223711 + L2reg 2.30 + L1reg 0.41 ; SHD = 150 ; DAG True
||w||^2 1943930737.1589506
exp ma of ||w||^2 98643021819.52838
||w|| 44090.02990653273
exp ma of ||w|| 199025.54116322869
||w||^2 6317.937091452185
exp ma of ||w||^2 810535776.407544
||w|| 79.48545207427699
exp ma of ||w|| 2674.413633990439
||w||^2 1.8308576217917079
exp ma of ||w||^2 2.934716781350723
||w|| 1.353091874852446
exp ma of ||w|| 1.6772056172268122
||w||^2 2.2848052860280395
exp ma of ||w||^2 2.9152384573365766
||w|| 1.5115572387534781
exp ma of ||w|| 1.673366060954985
||w||^2 4.790775287541115
exp ma of ||w||^2 2.9694436691178017
||w|| 2.188783974617211
exp ma of ||w|| 1.686478048996786
||w||^2 1.518496897770769
exp ma of ||w||^2 3.0208770732463357
||w|| 1.232273061366988
exp ma of ||w|| 1.6989240866558515
||w||^2 1.4099125846435796
exp ma of ||w||^2 2.9537106524233296
||w|| 1.1873973996281024
exp ma of ||w|| 1.6797775829807233
||w||^2 1.2257795254441421
exp ma of ||w||^2 3.019485308663086
||w|| 1.1071492787533856
exp ma of ||w|| 1.6966878795868043
||w||^2 1.1252942514688271
exp ma of ||w||^2 2.7466444513787405
||w|| 1.0607988741834273
exp ma of ||w|| 1.6147014921598077
||w||^2 3.6482882648182113
exp ma of ||w||^2 2.7811268130666513
||w|| 1.9100492833480007
exp ma of ||w|| 1.6303984019856137
||w||^2 3.2359366000734613
exp ma of ||w||^2 2.852117985620873
||w|| 1.7988709236833702
exp ma of ||w|| 1.6573895918843846
||w||^2 2.2820127890942232
exp ma of ||w||^2 2.700387807731243
||w|| 1.510633241092696
exp ma of ||w|| 1.6130930869316769
||w||^2 2.410250613004969
exp ma of ||w||^2 2.912673532738272
||w|| 1.5524981845416017
exp ma of ||w|| 1.667911345914787
||w||^2 4.175788646874211
exp ma of ||w||^2 2.895915814908543
||w|| 2.0434746504114534
exp ma of ||w|| 1.6593053019582655
cuda
Objective function 84.51 = squared loss an data 48.67 + 0.5*rho*h**2 19.951769 + alpha*h 13.010513 + L2reg 2.49 + L1reg 0.38 ; SHD = 150 ; DAG True
Proportion of microbatches that were clipped  0.7793707686180804
iteration 2 in inner loop, alpha 65.13114364781069 rho 1000.0 h 0.19975869896219933
9630
cuda
Objective function 264.08 = squared loss an data 48.67 + 0.5*rho*h**2 199.517689 + alpha*h 13.010513 + L2reg 2.49 + L1reg 0.38 ; SHD = 150 ; DAG True
||w||^2 88795136716.98761
exp ma of ||w||^2 1375886595135.9941
||w|| 297985.12834869395
exp ma of ||w|| 826526.0738526374
||w||^2 51540219.93494193
exp ma of ||w||^2 45647236733.89703
||w|| 7179.151755948744
exp ma of ||w|| 53550.78230717796
||w||^2 3.8865356625297944
exp ma of ||w||^2 168.16441281468212
||w|| 1.971429852297513
exp ma of ||w|| 2.114334731140104
||w||^2 4.7026421775266805
exp ma of ||w||^2 57.74758366501715
||w|| 2.1685576260562414
exp ma of ||w|| 2.13049762798162
||w||^2 5.785774315157975
exp ma of ||w||^2 30.680666325494652
||w|| 2.4053636554911972
exp ma of ||w|| 2.1349588899725074
||w||^2 3.195694771969246
exp ma of ||w||^2 3.6821773645812295
||w|| 1.7876506291692584
exp ma of ||w|| 1.8658070823072752
||w||^2 3.012606843950317
exp ma of ||w||^2 3.552026383651007
||w|| 1.7356862746332693
exp ma of ||w|| 1.8635490008679647
||w||^2 4.039375039957424
exp ma of ||w||^2 3.5387863019748407
||w|| 2.009819653590198
exp ma of ||w|| 1.852974316530917
||w||^2 3.6196955888289004
exp ma of ||w||^2 3.4633355157152828
||w|| 1.9025497598824848
exp ma of ||w|| 1.8291991445694256
||w||^2 2.9905067027115595
exp ma of ||w||^2 3.7707958458746766
||w|| 1.7293081572442661
exp ma of ||w|| 1.9054865536326828
||w||^2 3.75043687495027
exp ma of ||w||^2 3.8694032631991937
||w|| 1.9366044704457
exp ma of ||w|| 1.9300821403968935
||w||^2 2.572854269552288
exp ma of ||w||^2 3.6746774189947473
||w|| 1.6040119293672002
exp ma of ||w|| 1.8794020023734654
v before min max tensor([[ 1156.155,  -488.602,   300.244,  ...,  -456.578,  -328.886,
           -34.142],
        [ -673.287,   568.233,  -324.751,  ...,  -581.628, -1276.695,
          -867.098],
        [-1123.854,  1009.797,  -700.077,  ..., 11480.691, -1121.826,
         -1017.741],
        ...,
        [ 2493.345,  -909.561, -1053.575,  ...,  -924.193,  -828.137,
         -1055.453],
        [-1088.555,  2535.287, -1039.480,  ...,  1515.760,  -964.271,
          1288.568],
        [  294.636,  1591.102, -1145.712,  ...,  -616.746,   245.970,
          -478.825]], device='cuda:0')
v tensor([[1.000e+01, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e+01, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e+01, 1.000e-12,
         1.000e+01],
        [1.000e+01, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         1.000e-12]], device='cuda:0')
v before min max tensor([ 9.272e+01,  3.827e+02, -1.200e+03, -1.034e+03, -1.305e+02, -1.150e+02,
         4.008e+02, -1.079e+03, -1.020e+03,  1.229e+03,  1.001e+03,  6.837e+02,
        -4.044e+02, -6.818e+02, -1.043e+03,  2.211e+03, -9.250e+02, -6.462e+02,
         4.648e+02,  2.561e+03,  5.378e+02, -6.954e+02, -3.199e+02, -1.238e+03,
         9.170e+02,  8.092e+02, -1.072e+03, -1.545e+02,  2.849e+02, -9.996e+02,
         9.515e+02, -4.027e+02, -4.373e+02, -8.851e+02,  1.073e+03, -1.826e+02,
        -7.630e+02, -8.234e+02, -7.409e+02,  1.494e+03, -3.853e+02,  2.312e+02,
        -5.079e+02, -6.117e+02,  1.185e+03,  8.974e+02,  5.565e+03, -6.665e+02,
         6.385e+03, -3.088e+02, -4.085e+02,  6.069e+02, -6.474e+02, -1.073e+03,
         4.678e+02, -6.587e+02,  7.304e+02, -1.158e+03, -1.084e+03, -1.320e+03,
        -6.981e+02, -1.072e+03, -3.273e+02, -2.237e+02, -7.659e+02, -8.825e+02,
         3.281e+02, -8.029e+02,  2.492e+03, -4.864e+02,  2.617e+03, -1.018e+03,
        -6.464e+02, -6.764e+02, -6.407e+02, -7.402e+02,  1.228e+03, -8.282e+02,
        -1.132e+03, -7.574e+02, -1.006e+03, -1.089e+03, -1.041e+03,  1.313e+03,
        -8.635e+02, -7.247e+02, -4.126e+02,  6.282e+02, -7.578e+02, -3.099e+02,
        -3.483e+02,  5.871e+02, -1.122e+02, -4.710e+02,  5.132e+01, -1.037e+03,
        -7.803e+02, -9.048e+02, -6.200e+02, -6.140e+02,  3.130e+01,  4.434e+03,
        -7.926e+02,  2.696e+02, -6.905e+02, -9.947e+02, -1.193e+03, -5.005e+02,
        -1.135e+03,  4.541e+02, -8.247e+02, -4.615e+02, -2.102e+02,  1.051e+03,
        -2.337e+02,  1.773e+03,  9.361e+02,  5.674e+02, -8.416e+02, -7.746e+02,
        -7.296e+02,  1.035e+03, -1.023e+03, -1.128e+03, -9.534e+02, -2.818e+02,
        -5.459e+02, -5.625e+02,  2.626e+03, -5.170e+02,  7.027e+02,  1.687e+03,
        -1.101e+03, -5.738e+02,  8.669e+02, -8.887e+02, -9.701e+02, -5.441e+02,
        -5.823e+02, -1.029e+03, -7.410e+02, -4.276e+02, -6.525e+02,  6.389e+02,
        -2.954e+02, -7.108e+02, -5.404e+02, -1.193e+03, -6.251e+02, -1.084e+03,
        -7.873e+02, -4.602e+02,  4.902e+03, -8.648e+02, -9.374e+02,  2.090e+01,
         1.105e+03, -1.333e+03,  2.703e+02, -1.041e+03, -7.107e+01, -8.441e+02,
        -2.970e+02, -7.377e+02, -5.892e+02, -7.073e+02, -3.618e+02, -1.200e+03,
        -1.072e+03, -7.637e+02,  5.649e+03, -1.089e+03,  1.696e+03, -8.328e+02,
        -6.822e+02, -6.189e+02, -4.997e+02, -7.596e+02,  2.836e+02, -7.102e+02,
        -1.053e+03,  1.808e+02, -9.891e+02, -8.320e+02, -8.081e+02, -8.327e+02,
        -4.774e+02, -6.299e+02, -8.187e+02, -9.460e+02,  2.373e+03, -5.084e+02,
         2.854e+03, -9.875e+02,  1.397e+02,  3.665e+01, -1.032e+03,  1.140e+03,
        -3.870e+02, -6.420e+02, -7.981e+02,  7.165e+01, -1.105e+03,  2.808e-01,
         3.935e+02, -4.034e+02, -7.059e+02,  3.182e+03,  6.051e+02, -7.579e+02,
        -7.340e+02, -7.569e+02, -6.352e+02,  9.133e+01,  6.518e+01, -3.142e+02,
        -9.127e+02, -2.421e+02, -6.883e+02,  5.176e+02,  1.992e+03, -8.094e+02,
        -9.241e+02, -3.233e+02,  3.025e+03,  7.973e+02, -1.013e+03, -4.545e+02,
        -1.008e+03, -7.802e+02, -8.968e+02, -8.347e+02, -6.952e+02,  1.724e+03,
         3.475e+02, -7.973e+02,  2.350e+03, -9.153e+02, -1.007e+03,  3.379e+03,
         2.760e+03,  1.404e+03, -8.707e+02, -1.156e+03, -3.045e+02,  8.117e+01,
        -1.369e+03, -4.523e+02, -1.094e+03, -1.205e+03,  4.715e+02, -9.469e+02,
        -1.329e+02, -8.762e+02, -1.034e+03, -1.014e+03, -1.039e+03,  9.015e+02,
        -9.632e+02, -7.220e+02,  1.560e+02, -7.935e+02,  1.459e+03, -4.604e+02,
        -7.365e+02, -7.653e+02,  6.764e+01, -3.699e+02,  3.952e+02, -7.762e+02,
        -9.266e+02, -5.802e+02, -5.353e+02,  1.633e+03, -8.910e+02,  7.466e+02,
        -9.457e+02, -5.222e+02, -3.715e+02, -9.846e+02,  2.949e+02, -7.365e+02,
        -1.067e+03, -9.181e+02,  1.220e+01,  6.403e+02,  4.144e+01, -3.871e+02,
        -6.149e+02,  1.321e+03, -1.059e+03, -9.186e+02,  6.437e+01,  2.423e+03,
        -9.554e+02, -4.958e+02, -5.857e+02, -7.941e+01,  1.388e+03, -3.048e+02],
       device='cuda:0')
v tensor([1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 2.808e-01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[ -801.701],
         [ -892.017],
         [ -730.273],
         [ -415.883],
         [  478.422],
         [ 1146.641],
         [ -743.359],
         [ -884.880],
         [ -952.256],
         [ 1469.978]],

        [[ -943.257],
         [ -461.752],
         [ 1011.401],
         [ -856.055],
         [ -438.973],
         [ 1468.538],
         [ 4626.268],
         [-1192.883],
         [-1138.988],
         [ -847.430]],

        [[  159.055],
         [ -729.655],
         [ -782.002],
         [ -929.907],
         [ -925.825],
         [ 4080.142],
         [ -824.984],
         [ -149.934],
         [ -603.140],
         [ 1975.213]],

        [[  -60.490],
         [ -810.208],
         [ -569.550],
         [ -705.261],
         [  793.927],
         [ -600.279],
         [ 2512.268],
         [  688.684],
         [ -973.336],
         [ -679.138]],

        [[ -474.193],
         [ -730.031],
         [  714.405],
         [ -955.124],
         [ -528.131],
         [ -901.123],
         [-1038.696],
         [  424.817],
         [ -951.758],
         [ -414.419]],

        [[10567.446],
         [ -612.738],
         [ 3615.746],
         [ -845.767],
         [-1131.583],
         [ 3699.609],
         [ -928.424],
         [ -150.598],
         [ 1823.120],
         [ -493.979]],

        [[  750.218],
         [ -967.974],
         [  -92.890],
         [ 7908.511],
         [ 1987.260],
         [ -765.214],
         [ -704.217],
         [ -306.591],
         [  518.666],
         [ -474.168]],

        [[ -422.770],
         [ -466.482],
         [ -738.938],
         [ -837.828],
         [ -459.771],
         [  217.750],
         [-1061.409],
         [  187.064],
         [ -890.476],
         [  481.168]],

        [[ 2648.193],
         [  165.729],
         [ -806.569],
         [-1193.929],
         [  138.894],
         [-1268.661],
         [ -994.982],
         [ -838.450],
         [ -806.916],
         [ 2450.668]],

        [[  487.064],
         [  226.191],
         [ -898.675],
         [ -249.147],
         [ -851.161],
         [ -462.939],
         [ -961.966],
         [ -847.399],
         [ -664.196],
         [ 9354.984]],

        [[-1202.465],
         [ -796.661],
         [ -893.492],
         [  -92.834],
         [ -944.494],
         [-1024.549],
         [  780.760],
         [ -438.419],
         [  726.347],
         [ 1297.791]],

        [[ 3776.861],
         [ -689.613],
         [ -577.122],
         [ -658.642],
         [ -453.888],
         [-1181.469],
         [ 3296.714],
         [ -975.450],
         [ 2400.397],
         [  226.298]],

        [[ -587.938],
         [ -178.953],
         [  829.005],
         [ -626.428],
         [ -515.686],
         [ -223.198],
         [ -625.125],
         [ 2165.647],
         [ -575.768],
         [  652.418]],

        [[ -892.250],
         [ -385.290],
         [ -871.844],
         [-1039.418],
         [ -713.701],
         [  382.535],
         [ 1518.992],
         [ -716.295],
         [ -183.342],
         [ -690.452]],

        [[ -163.163],
         [ -872.204],
         [  699.666],
         [  224.476],
         [  264.467],
         [-1235.016],
         [ -626.752],
         [  352.929],
         [ -928.157],
         [ 2999.382]],

        [[ -948.042],
         [ 2244.555],
         [ -230.833],
         [ -817.547],
         [ -281.867],
         [ -767.566],
         [ -911.258],
         [ -627.025],
         [ 3256.532],
         [   68.498]],

        [[ -701.828],
         [ -737.324],
         [ -770.158],
         [ -689.295],
         [-1092.168],
         [ -839.734],
         [  340.717],
         [-1077.971],
         [ 1140.406],
         [ 5401.604]],

        [[ -600.818],
         [  -82.203],
         [ 1072.184],
         [ -219.656],
         [ -573.943],
         [-1130.881],
         [-1296.054],
         [ -693.981],
         [ 1429.856],
         [  444.472]],

        [[ -661.737],
         [ -857.048],
         [ -950.933],
         [  797.871],
         [  216.267],
         [  136.565],
         [-1068.079],
         [ -203.691],
         [ -899.635],
         [ -967.774]],

        [[ -662.332],
         [  914.703],
         [ -946.976],
         [-1225.594],
         [ -455.405],
         [ -735.528],
         [ -435.415],
         [ -360.754],
         [ -452.981],
         [ -304.250]],

        [[  221.628],
         [ -676.778],
         [  610.645],
         [ 5388.015],
         [  811.797],
         [ -920.477],
         [ 2575.163],
         [ -588.077],
         [ -116.375],
         [ 1291.784]],

        [[ -893.002],
         [ 1216.418],
         [-1018.167],
         [ -768.324],
         [-1241.399],
         [ 1144.542],
         [  289.919],
         [ -537.449],
         [ 5368.044],
         [ -642.499]],

        [[  644.826],
         [ -381.241],
         [ -689.927],
         [ -447.068],
         [ -881.381],
         [ -899.077],
         [-1034.599],
         [ -513.228],
         [ 1081.708],
         [  259.625]],

        [[ -878.113],
         [ -439.140],
         [ -913.279],
         [ 2076.017],
         [ 2132.475],
         [ -888.897],
         [ -780.398],
         [-1035.327],
         [ -438.007],
         [ 1017.576]],

        [[ -203.116],
         [ -986.004],
         [ -459.348],
         [ 3543.970],
         [  355.438],
         [ -783.085],
         [-1217.000],
         [ -654.586],
         [ 3065.650],
         [  151.685]],

        [[ -941.807],
         [-1152.909],
         [ -215.491],
         [ -370.037],
         [-1093.388],
         [ -789.034],
         [ -725.407],
         [ 8163.378],
         [  -41.407],
         [ 2757.765]],

        [[-1123.698],
         [ -801.499],
         [ 3428.330],
         [ 1400.925],
         [ -915.397],
         [-1147.106],
         [ -676.309],
         [ -532.333],
         [-1044.643],
         [  981.211]],

        [[  208.968],
         [ -153.556],
         [ -660.730],
         [ -169.600],
         [ 3786.965],
         [ 3367.534],
         [ -482.234],
         [  104.629],
         [  182.103],
         [   13.063]],

        [[-1029.834],
         [ -438.105],
         [ 1041.113],
         [  394.662],
         [ 4844.282],
         [-1165.155],
         [ 1454.309],
         [ 1030.914],
         [ -779.564],
         [ -244.642]],

        [[ 3590.579],
         [ 2975.481],
         [ -470.605],
         [ -985.595],
         [ -481.846],
         [  655.965],
         [ 4962.903],
         [ -927.978],
         [ -474.222],
         [ -306.132]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[ 1016.988],
        [  468.876],
        [ -165.780],
        [ 1007.767],
        [ 8992.180],
        [ -486.198],
        [ -817.358],
        [ -943.452],
        [-1047.921],
        [  627.655],
        [ -534.023],
        [  396.451],
        [ -452.484],
        [ -902.909],
        [-1087.882],
        [  356.783],
        [ -762.952],
        [ -605.479],
        [-1067.683],
        [ -176.912],
        [ -163.234],
        [ -632.138],
        [-1031.632],
        [-1084.607],
        [  944.321],
        [ -692.151],
        [-1052.980],
        [  326.940],
        [ -412.310],
        [ -192.858]], device='cuda:0')
v tensor([[1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-0.053, -0.178,  0.109,  ..., -0.266,  0.134, -0.158],
        [ 0.095,  0.427,  0.274,  ..., -0.418,  0.064,  0.176],
        [ 0.080, -0.299,  0.305,  ..., -0.302, -0.096,  0.289],
        ...,
        [ 0.034,  0.114, -0.145,  ...,  0.444, -0.047,  0.022],
        [ 0.244,  0.095,  0.295,  ..., -0.087, -0.068, -0.008],
        [-0.039,  0.127,  0.072,  ...,  0.517,  0.117, -0.156]],
       device='cuda:0')
s after update for 1 param tensor([[1.546, 0.910, 1.802,  ..., 1.871, 1.820, 1.711],
        [2.339, 1.866, 1.158,  ..., 1.517, 2.239, 1.470],
        [2.296, 1.753, 1.704,  ..., 2.464, 1.893, 1.872],
        ...,
        [1.843, 1.938, 1.848,  ..., 1.961, 1.569, 1.798],
        [1.941, 1.578, 1.982,  ..., 1.631, 1.770, 1.529],
        [2.238, 1.937, 1.974,  ..., 1.737, 1.804, 2.245]], device='cuda:0')
b after update for 1 param tensor([[164.867, 126.471, 178.018,  ..., 181.381, 178.899, 173.475],
        [202.821, 181.134, 142.667,  ..., 163.338, 198.428, 160.753],
        [200.911, 175.555, 173.081,  ..., 208.128, 182.431, 181.413],
        ...,
        [180.030, 184.586, 180.252,  ..., 185.676, 166.111, 177.788],
        [184.735, 166.590, 186.669,  ..., 169.343, 176.424, 163.974],
        [198.385, 184.536, 186.323,  ..., 174.761, 178.091, 198.683]],
       device='cuda:0')
clipping threshold 1.5596184836847127
a after update for 1 param tensor([-2.030e-01,  3.406e-01, -2.174e-01, -1.181e-01, -3.402e-01,  1.100e-01,
        -1.793e-01,  4.741e-01,  2.183e-01, -1.039e-01,  5.290e-02,  1.943e-01,
        -6.295e-01,  6.291e-01,  2.989e-01,  1.302e-01,  3.328e-02,  5.069e-02,
         4.875e-01,  2.244e-02, -2.019e-01,  1.338e-01,  8.454e-01,  6.580e-01,
         5.327e-01, -2.573e-02, -4.534e-01, -9.185e-02,  1.360e-01,  3.315e-01,
        -5.207e-01,  5.663e-01, -3.349e-01,  9.381e-03,  3.525e-01, -1.223e-01,
         2.133e-01, -6.415e-01, -4.780e-01,  2.154e-01, -1.808e-01, -3.044e-01,
        -3.989e-01, -5.021e-01,  9.926e-02,  2.896e-01,  4.744e-01, -3.923e-02,
        -5.078e-01,  6.592e-02, -2.307e-02,  6.067e-01, -1.174e-01,  7.426e-02,
        -5.078e-01,  3.183e-01, -3.348e-01,  2.953e-01,  8.874e-02,  2.650e-01,
        -3.800e-01,  4.694e-02, -2.926e-01, -3.923e-01, -8.769e-01,  8.610e-01,
        -7.619e-04, -1.204e-01,  5.319e-01, -4.988e-02, -3.430e-02, -4.911e-01,
         3.213e-01,  1.941e-01,  1.538e-01,  4.481e-01, -3.111e-02,  3.995e-01,
        -2.438e-01, -4.008e-02, -8.149e-02,  1.552e-01, -8.594e-02,  5.067e-01,
        -3.731e-01, -5.835e-01,  1.467e-01, -2.216e-01, -3.756e-01, -7.315e-01,
         1.141e-01,  3.351e-01, -9.326e-03,  2.486e-02, -2.008e-01, -1.588e-01,
         8.982e-02, -2.574e-01, -8.263e-02,  4.205e-01,  3.068e-02,  1.019e+00,
        -6.314e-02, -4.306e-01,  1.763e-01,  6.669e-03, -2.436e-01,  2.987e-01,
         2.408e-01, -4.461e-01,  2.140e-01,  1.825e-01, -6.362e-01, -3.749e-01,
        -3.026e-01,  2.063e-01,  4.230e-01, -1.955e-01,  2.667e-01, -1.944e-01,
        -3.408e-01, -4.096e-02, -1.726e-01,  4.276e-03,  3.397e-02,  8.242e-01,
         8.344e-02,  6.734e-02, -1.576e-02, -1.087e-01, -5.808e-02,  3.184e-02,
         5.284e-02,  4.279e-01,  7.662e-02, -3.671e-01, -5.064e-02,  5.472e-01,
         3.058e-02, -1.455e-01, -3.281e-01, -1.475e-01, -4.372e-01,  3.013e-01,
         7.105e-03, -1.073e-01,  3.426e-01, -1.654e-01,  1.692e-02,  2.925e-01,
         2.001e-01, -2.012e-02,  5.123e-01, -1.511e-01,  1.417e-01, -2.608e-02,
         1.413e-01, -1.593e-01, -5.774e-01, -4.464e-01,  3.360e-02,  9.118e-02,
         1.959e-01,  1.373e-01,  3.487e-02,  3.147e-02, -2.928e-01, -1.174e-01,
        -1.354e-02,  2.508e-01, -8.902e-02, -6.866e-02, -1.027e-01, -5.790e-01,
        -5.371e-02,  4.561e-01,  1.530e-01, -5.754e-02,  1.546e-01,  2.760e-01,
        -1.924e-02, -9.589e-02,  1.798e-01,  1.541e-01, -2.525e-01, -3.455e-01,
        -2.447e-01,  5.974e-01, -2.615e-01,  3.766e-01,  9.133e-02,  3.389e-01,
         1.450e-01, -2.706e-01, -2.535e-01,  4.723e-01,  4.576e-01,  4.161e-01,
         2.457e-01,  4.074e-01,  3.832e-01, -2.949e-01,  4.519e-01, -1.121e-01,
         7.502e-01,  5.864e-01,  3.282e-01, -2.169e-01, -3.498e-02,  1.820e-01,
         1.001e-01,  6.809e-01,  3.725e-01, -2.875e-01,  2.377e-01,  7.005e-02,
        -3.698e-01, -3.308e-01,  2.893e-01, -3.130e-01, -3.387e-01, -1.644e-01,
         4.398e-01, -7.665e-02,  1.117e-02,  2.883e-01,  3.275e-01,  1.597e-01,
         1.250e-01,  4.215e-01,  3.620e-02, -2.580e-01, -3.055e-01,  9.301e-02,
        -1.601e-01, -5.016e-01,  1.185e-01, -2.230e-01, -4.968e-02,  2.357e-01,
         5.339e-01,  3.106e-01,  1.304e-01,  3.447e-01, -5.003e-01,  2.525e-01,
         2.694e-01,  3.810e-01, -8.248e-01,  7.950e-02, -5.071e-01, -1.264e-01,
         7.856e-01,  1.518e-01, -1.202e-01,  3.578e-01,  1.855e-02,  6.223e-01,
         4.044e-01, -2.723e-01,  3.290e-02, -1.688e-01,  2.873e-03, -1.026e-01,
        -5.060e-01, -6.844e-01, -4.174e-01,  1.291e-01,  5.640e-02, -3.715e-01,
         2.190e-01,  9.445e-03, -6.835e-01, -1.722e-01,  5.402e-02, -4.784e-01,
         2.017e-01,  2.164e-02, -5.795e-02, -7.551e-01,  1.354e-01, -3.301e-01,
        -1.482e-01, -2.875e-02,  1.888e-01, -4.221e-01,  1.650e-01,  3.429e-01,
         2.218e-01, -6.129e-01,  3.759e-02, -6.250e-01, -8.946e-01, -6.381e-02,
        -6.166e-02,  3.190e-01, -5.436e-01,  2.048e-01,  7.234e-01,  4.122e-01],
       device='cuda:0')
s after update for 1 param tensor([1.884, 1.834, 2.028, 1.768, 1.388, 1.611, 2.298, 1.826, 1.767, 2.159,
        2.272, 1.644, 1.435, 1.365, 1.941, 1.639, 1.564, 1.952, 1.842, 1.770,
        2.110, 1.244, 1.753, 2.123, 1.798, 2.016, 2.056, 1.855, 1.741, 1.916,
        2.008, 1.523, 0.873, 1.523, 2.037, 2.210, 1.426, 1.816, 1.324, 2.165,
        1.663, 1.932, 1.820, 1.318, 2.365, 1.665, 1.870, 2.316, 2.109, 1.529,
        2.097, 1.794, 1.684, 2.121, 1.942, 2.169, 2.000, 1.991, 2.039, 2.242,
        1.479, 1.952, 1.195, 1.846, 1.530, 1.667, 2.072, 1.368, 2.115, 1.645,
        1.909, 1.723, 1.295, 1.752, 1.572, 1.526, 2.306, 1.440, 1.918, 1.984,
        1.739, 1.948, 1.827, 2.079, 1.829, 1.531, 1.692, 2.016, 1.319, 1.549,
        1.870, 1.980, 1.183, 1.144, 1.687, 1.750, 1.480, 1.775, 1.770, 1.812,
        2.322, 2.070, 1.422, 1.727, 1.347, 1.865, 2.015, 1.867, 1.930, 2.474,
        1.958, 1.378, 1.316, 2.392, 1.199, 2.252, 2.304, 1.587, 1.747, 1.616,
        1.680, 2.056, 1.756, 1.904, 1.609, 1.641, 1.431, 1.772, 1.988, 1.324,
        1.779, 2.187, 1.865, 2.010, 1.852, 1.614, 1.717, 1.635, 0.983, 1.740,
        2.160, 1.538, 1.681, 1.706, 2.073, 2.122, 1.311, 2.030, 1.689, 1.872,
        1.860, 1.631, 2.171, 1.667, 1.607, 1.813, 2.187, 2.329, 1.600, 1.758,
        1.379, 1.523, 1.268, 1.607, 0.994, 1.687, 1.502, 2.066, 1.872, 1.596,
        1.939, 1.940, 1.799, 1.423, 1.275, 1.856, 1.491, 1.429, 1.649, 1.355,
        1.816, 1.829, 2.256, 1.404, 1.723, 1.460, 1.365, 1.214, 1.887, 1.757,
        1.961, 1.634, 2.465, 1.997, 1.978, 2.324, 1.746, 1.521, 1.600, 1.681,
        1.794, 2.157, 1.997, 1.807, 2.011, 1.663, 1.784, 1.673, 1.773, 1.279,
        1.382, 2.032, 1.694, 2.040, 1.300, 1.324, 1.634, 0.765, 1.346, 2.230,
        2.064, 2.334, 2.225, 1.787, 1.979, 1.916, 1.857, 1.698, 1.763, 1.765,
        1.743, 1.678, 1.507, 1.543, 1.965, 1.481, 2.148, 1.690, 2.014, 2.071,
        2.164, 2.124, 1.470, 1.952, 1.975, 1.903, 2.310, 1.517, 1.858, 2.115,
        1.819, 1.768, 1.667, 1.775, 1.751, 2.014, 1.910, 1.720, 1.634, 1.599,
        1.789, 1.339, 2.010, 1.936, 1.419, 1.502, 1.805, 0.861, 2.331, 1.566,
        1.730, 1.931, 1.191, 2.095, 1.669, 1.653, 1.755, 1.133, 1.395, 1.904,
        1.689, 1.388, 1.915, 1.550, 2.452, 1.398, 1.785, 1.445, 1.498, 2.056,
        1.842, 1.560, 1.881, 2.031, 1.615, 1.195, 1.730, 1.483, 1.856, 1.385],
       device='cuda:0')
b after update for 1 param tensor([182.003, 179.572, 188.848, 176.322, 156.225, 168.296, 201.029, 179.189,
        176.283, 194.837, 199.875, 170.024, 158.852, 154.929, 184.725, 169.739,
        165.812, 185.274, 179.963, 176.409, 192.620, 147.914, 175.562, 193.197,
        177.826, 188.300, 190.131, 180.583, 174.974, 183.553, 187.921, 163.634,
        123.909, 163.636, 189.258, 197.137, 158.353, 178.712, 152.601, 195.093,
        170.998, 184.334, 178.869, 152.221, 203.935, 171.096, 181.348, 201.805,
        192.564, 163.991, 192.038, 177.599, 172.079, 193.101, 184.797, 195.272,
        187.530, 187.128, 189.354, 198.568, 161.279, 185.265, 144.932, 180.140,
        164.020, 171.206, 190.868, 155.117, 192.858, 170.083, 183.203, 174.043,
        150.883, 175.542, 166.239, 163.784, 201.380, 159.120, 183.659, 186.794,
        174.851, 185.062, 179.214, 191.198, 179.319, 164.098, 172.508, 188.268,
        152.265, 165.026, 181.326, 186.577, 144.245, 141.858, 172.210, 175.426,
        161.328, 176.655, 176.395, 178.513, 202.055, 190.765, 158.132, 174.286,
        153.922, 181.082, 188.210, 181.209, 184.198, 208.572, 185.553, 155.670,
        152.096, 205.084, 145.197, 198.987, 201.259, 167.070, 175.274, 168.579,
        171.888, 190.132, 175.715, 182.978, 168.188, 169.849, 158.649, 176.536,
        186.944, 152.571, 176.884, 196.095, 181.088, 188.005, 180.446, 168.475,
        173.748, 169.540, 131.492, 174.896, 194.864, 164.446, 171.914, 173.193,
        190.901, 193.162, 151.858, 188.921, 172.352, 181.432, 180.856, 169.365,
        195.371, 171.207, 168.093, 178.570, 196.082, 202.355, 167.711, 175.795,
        155.698, 163.661, 149.296, 168.115, 132.209, 172.208, 162.488, 190.619,
        181.443, 167.500, 184.634, 184.718, 177.834, 158.165, 149.737, 180.635,
        161.918, 158.532, 170.284, 154.333, 178.696, 179.314, 199.189, 157.114,
        174.054, 160.232, 154.924, 146.091, 182.138, 175.753, 185.683, 169.507,
        208.175, 187.378, 186.517, 202.143, 175.227, 163.551, 167.726, 171.934,
        177.594, 194.755, 187.391, 178.238, 188.024, 170.991, 177.111, 171.498,
        176.584, 149.994, 155.906, 189.001, 172.572, 189.403, 151.199, 152.556,
        169.478, 116.012, 153.826, 198.005, 190.517, 202.602, 197.798, 177.255,
        186.527, 183.538, 180.686, 172.782, 176.088, 176.163, 175.049, 171.759,
        162.803, 164.712, 185.862, 161.369, 194.333, 172.360, 188.196, 190.832,
        195.059, 193.271, 160.746, 185.280, 186.373, 182.942, 201.528, 163.336,
        180.741, 192.825, 178.828, 176.308, 171.188, 176.663, 175.488, 188.166,
        183.252, 173.930, 169.497, 167.669, 177.383, 153.433, 188.012, 184.503,
        157.987, 162.489, 178.155, 123.048, 202.452, 165.937, 174.434, 184.258,
        144.723, 191.944, 171.307, 170.469, 175.651, 141.152, 156.638, 182.968,
        172.356, 156.244, 183.511, 165.078, 207.658, 156.800, 177.182, 159.387,
        162.323, 190.150, 179.955, 165.609, 181.846, 188.978, 168.523, 144.979,
        174.399, 161.482, 180.639, 156.040], device='cuda:0')
clipping threshold 1.5596184836847127
a after update for 1 param tensor([[[ 0.043],
         [ 0.602],
         [-0.060],
         [ 0.163],
         [ 0.075],
         [-0.070],
         [-0.443],
         [ 0.009],
         [ 0.110],
         [ 0.431]],

        [[ 0.050],
         [-0.504],
         [ 0.953],
         [-0.413],
         [ 0.266],
         [-0.069],
         [ 0.082],
         [-0.226],
         [-0.505],
         [ 0.386]],

        [[-0.449],
         [ 0.085],
         [ 0.469],
         [ 0.456],
         [ 0.058],
         [ 0.179],
         [ 0.099],
         [ 0.053],
         [-0.472],
         [-0.187]],

        [[ 0.076],
         [-0.566],
         [-0.472],
         [ 0.559],
         [-0.016],
         [ 0.652],
         [-0.003],
         [ 0.229],
         [ 0.398],
         [ 0.218]],

        [[ 0.407],
         [-0.718],
         [ 0.261],
         [ 0.119],
         [ 0.377],
         [ 0.514],
         [-0.130],
         [-0.079],
         [ 0.386],
         [ 0.307]],

        [[-0.129],
         [-0.446],
         [-0.131],
         [-0.042],
         [-0.322],
         [-0.573],
         [-0.239],
         [-0.325],
         [-0.129],
         [-0.210]],

        [[-0.332],
         [ 0.179],
         [-0.304],
         [-0.334],
         [ 0.525],
         [ 0.207],
         [ 0.389],
         [-0.163],
         [-0.235],
         [ 0.136]],

        [[ 0.024],
         [ 0.425],
         [ 0.206],
         [-0.391],
         [ 0.184],
         [-0.366],
         [-0.159],
         [ 0.350],
         [-0.434],
         [ 0.238]],

        [[-0.008],
         [ 0.261],
         [-0.444],
         [-0.009],
         [ 0.309],
         [ 1.051],
         [ 0.139],
         [ 0.363],
         [-0.046],
         [-0.119]],

        [[ 0.345],
         [ 0.057],
         [ 0.021],
         [ 0.267],
         [ 0.254],
         [ 0.174],
         [ 0.238],
         [ 0.242],
         [ 0.331],
         [ 0.531]],

        [[ 0.651],
         [-0.356],
         [ 0.699],
         [-0.149],
         [-0.146],
         [ 0.371],
         [ 0.330],
         [-0.174],
         [ 0.276],
         [ 0.598]],

        [[-0.469],
         [-0.296],
         [ 0.146],
         [ 0.175],
         [-0.378],
         [-0.037],
         [-0.104],
         [ 0.627],
         [ 0.709],
         [-0.501]],

        [[-0.095],
         [ 0.512],
         [-0.268],
         [ 0.557],
         [ 0.323],
         [-0.314],
         [-0.149],
         [ 0.554],
         [ 0.411],
         [-0.244]],

        [[ 0.312],
         [ 0.292],
         [ 0.095],
         [ 0.143],
         [ 0.384],
         [ 0.095],
         [ 0.515],
         [ 0.182],
         [-0.068],
         [-0.414]],

        [[-0.411],
         [ 0.098],
         [-0.318],
         [-0.449],
         [-0.091],
         [-0.133],
         [ 0.378],
         [ 0.636],
         [ 0.148],
         [-0.152]],

        [[ 0.534],
         [-0.129],
         [-0.010],
         [ 0.189],
         [-0.548],
         [ 0.303],
         [-0.358],
         [ 0.278],
         [ 0.012],
         [-0.100]],

        [[ 1.275],
         [-0.155],
         [-0.254],
         [ 0.132],
         [ 0.613],
         [ 0.543],
         [ 0.165],
         [ 0.071],
         [-0.460],
         [ 0.109]],

        [[-0.021],
         [ 0.035],
         [ 0.043],
         [-0.248],
         [-0.113],
         [ 0.316],
         [ 0.646],
         [-0.487],
         [ 0.391],
         [-0.557]],

        [[-0.152],
         [ 0.166],
         [-0.320],
         [-0.257],
         [ 0.098],
         [ 0.440],
         [ 0.817],
         [-0.028],
         [ 0.004],
         [ 0.520]],

        [[ 0.207],
         [ 0.152],
         [-0.026],
         [ 0.425],
         [ 0.029],
         [ 0.058],
         [ 0.214],
         [-0.079],
         [-0.346],
         [ 0.366]],

        [[-0.138],
         [ 0.291],
         [ 0.510],
         [-0.094],
         [ 0.254],
         [ 0.317],
         [-0.112],
         [ 0.099],
         [ 0.001],
         [ 0.432]],

        [[-0.708],
         [ 0.208],
         [ 0.293],
         [-0.333],
         [ 0.121],
         [-0.306],
         [-0.112],
         [-0.163],
         [ 0.024],
         [-0.512]],

        [[-0.111],
         [ 0.586],
         [ 0.173],
         [ 0.091],
         [ 0.023],
         [-0.276],
         [-0.155],
         [-0.072],
         [ 0.547],
         [ 0.161]],

        [[ 0.760],
         [ 0.252],
         [ 0.052],
         [ 0.413],
         [-0.301],
         [-0.291],
         [-0.340],
         [-0.296],
         [-0.641],
         [ 0.568]],

        [[-0.288],
         [ 0.139],
         [ 0.279],
         [ 0.309],
         [ 0.238],
         [ 0.009],
         [-0.283],
         [-0.399],
         [ 0.053],
         [-0.106]],

        [[-0.078],
         [ 0.134],
         [-0.637],
         [-0.194],
         [ 0.196],
         [-0.404],
         [ 0.228],
         [-0.205],
         [ 0.166],
         [ 0.521]],

        [[-0.052],
         [ 0.056],
         [-0.144],
         [-0.492],
         [-0.021],
         [-0.353],
         [-0.017],
         [-0.610],
         [-0.634],
         [ 0.478]],

        [[-0.244],
         [ 0.032],
         [-0.936],
         [ 0.596],
         [-0.095],
         [-0.514],
         [-0.420],
         [ 0.138],
         [-0.417],
         [ 0.888]],

        [[-0.460],
         [-0.022],
         [-0.256],
         [-0.142],
         [ 0.057],
         [-0.340],
         [-0.468],
         [ 0.115],
         [-0.048],
         [ 0.167]],

        [[-0.149],
         [-0.219],
         [-0.025],
         [ 0.238],
         [ 0.523],
         [-0.298],
         [ 0.751],
         [ 0.172],
         [ 0.101],
         [ 0.089]]], device='cuda:0')
s after update for 1 param tensor([[[1.777],
         [1.537],
         [1.524],
         [1.917],
         [1.893],
         [2.160],
         [1.411],
         [1.624],
         [1.694],
         [1.719]],

        [[1.637],
         [1.784],
         [1.994],
         [1.518],
         [1.550],
         [2.172],
         [2.078],
         [2.018],
         [1.973],
         [1.620]],

        [[1.527],
         [1.249],
         [1.963],
         [1.706],
         [1.777],
         [1.808],
         [1.678],
         [2.001],
         [1.101],
         [1.890]],

        [[1.914],
         [1.600],
         [1.176],
         [1.190],
         [1.928],
         [1.182],
         [1.731],
         [1.939],
         [1.730],
         [1.307]],

        [[1.576],
         [1.466],
         [1.891],
         [1.898],
         [1.437],
         [1.753],
         [1.753],
         [2.043],
         [1.803],
         [1.545]],

        [[2.199],
         [1.095],
         [2.028],
         [1.504],
         [1.961],
         [2.117],
         [2.064],
         [1.659],
         [1.885],
         [1.923]],

        [[1.859],
         [1.635],
         [1.791],
         [2.230],
         [1.976],
         [1.515],
         [1.817],
         [1.187],
         [1.818],
         [0.860]],

        [[1.046],
         [1.535],
         [1.491],
         [1.699],
         [1.523],
         [1.839],
         [1.834],
         [2.021],
         [1.516],
         [1.752]],

        [[2.100],
         [1.666],
         [1.605],
         [2.254],
         [1.818],
         [2.190],
         [1.741],
         [1.856],
         [1.671],
         [2.073]],

        [[1.549],
         [1.929],
         [1.633],
         [0.929],
         [1.652],
         [1.734],
         [1.891],
         [1.859],
         [1.972],
         [2.123]],

        [[2.214],
         [1.442],
         [1.889],
         [1.143],
         [1.599],
         [1.729],
         [2.258],
         [2.119],
         [2.385],
         [1.734]],

        [[2.428],
         [1.164],
         [1.436],
         [1.222],
         [1.560],
         [2.092],
         [1.589],
         [1.728],
         [1.952],
         [1.585]],

        [[1.179],
         [1.445],
         [2.070],
         [1.556],
         [1.693],
         [1.162],
         [1.276],
         [1.921],
         [2.142],
         [2.012]],

        [[1.505],
         [1.559],
         [1.519],
         [1.813],
         [1.972],
         [2.372],
         [1.919],
         [1.308],
         [1.999],
         [1.753]],

        [[2.152],
         [1.573],
         [2.229],
         [2.113],
         [1.215],
         [2.263],
         [1.329],
         [1.653],
         [1.942],
         [1.919]],

        [[1.679],
         [2.025],
         [1.670],
         [2.010],
         [1.709],
         [1.456],
         [1.632],
         [1.165],
         [2.137],
         [1.523]],

        [[1.194],
         [1.773],
         [1.680],
         [1.391],
         [2.166],
         [1.999],
         [1.610],
         [1.866],
         [2.580],
         [2.235]],

        [[1.418],
         [1.592],
         [1.805],
         [1.959],
         [1.311],
         [1.910],
         [2.246],
         [1.677],
         [2.082],
         [1.963]],

        [[1.134],
         [2.079],
         [1.679],
         [2.182],
         [2.051],
         [1.902],
         [1.802],
         [0.921],
         [1.532],
         [1.806]],

        [[1.379],
         [1.755],
         [1.800],
         [2.073],
         [1.992],
         [1.682],
         [1.980],
         [1.209],
         [0.808],
         [1.007]],

        [[1.979],
         [1.935],
         [2.067],
         [2.001],
         [2.301],
         [1.644],
         [1.771],
         [1.239],
         [1.447],
         [2.108]],

        [[1.616],
         [1.749],
         [2.131],
         [1.745],
         [2.096],
         [2.066],
         [1.698],
         [1.267],
         [1.848],
         [1.777]],

        [[1.608],
         [1.875],
         [1.259],
         [1.402],
         [1.505],
         [1.686],
         [1.767],
         [1.189],
         [2.138],
         [1.866]],

        [[1.605],
         [2.118],
         [1.548],
         [2.098],
         [2.244],
         [2.358],
         [1.397],
         [2.019],
         [0.981],
         [1.707]],

        [[1.852],
         [1.821],
         [0.841],
         [1.557],
         [2.009],
         [1.325],
         [2.053],
         [1.598],
         [1.754],
         [1.862]],

        [[1.632],
         [2.201],
         [1.495],
         [1.319],
         [1.871],
         [1.647],
         [1.224],
         [2.075],
         [1.320],
         [2.110]],

        [[1.982],
         [1.381],
         [2.066],
         [2.323],
         [1.556],
         [2.076],
         [1.725],
         [1.325],
         [2.135],
         [2.029]],

        [[1.645],
         [1.646],
         [1.985],
         [1.869],
         [1.749],
         [2.299],
         [1.662],
         [2.040],
         [1.669],
         [2.122]],

        [[1.774],
         [1.096],
         [1.913],
         [2.063],
         [2.262],
         [1.968],
         [1.823],
         [1.508],
         [1.771],
         [1.599]],

        [[2.003],
         [2.324],
         [2.024],
         [1.666],
         [1.505],
         [1.500],
         [1.736],
         [2.118],
         [1.585],
         [1.245]]], device='cuda:0')
b after update for 1 param tensor([[[176.762],
         [164.407],
         [163.712],
         [183.588],
         [182.432],
         [194.869],
         [157.508],
         [168.966],
         [172.606],
         [173.843]],

        [[169.654],
         [177.091],
         [187.239],
         [163.373],
         [165.109],
         [195.406],
         [191.158],
         [188.352],
         [186.258],
         [168.784]],

        [[163.842],
         [148.206],
         [185.793],
         [173.209],
         [176.766],
         [178.285],
         [171.764],
         [187.597],
         [139.151],
         [182.314]],

        [[183.457],
         [167.714],
         [143.795],
         [144.650],
         [184.123],
         [144.140],
         [174.447],
         [184.656],
         [174.426],
         [151.609]],

        [[166.488],
         [160.537],
         [182.332],
         [182.688],
         [158.983],
         [175.561],
         [175.578],
         [189.512],
         [178.057],
         [164.837]],

        [[196.621],
         [138.774],
         [188.835],
         [162.613],
         [185.670],
         [192.917],
         [190.516],
         [170.807],
         [182.052],
         [183.871]],

        [[180.817],
         [169.536],
         [177.439],
         [198.013],
         [186.393],
         [163.221],
         [178.754],
         [144.450],
         [178.783],
         [123.000]],

        [[135.597],
         [164.304],
         [161.931],
         [172.864],
         [163.664],
         [179.831],
         [179.572],
         [188.502],
         [163.272],
         [175.512]],

        [[192.177],
         [171.173],
         [167.986],
         [199.068],
         [178.800],
         [196.235],
         [174.965],
         [180.636],
         [171.395],
         [190.908]],

        [[165.045],
         [184.164],
         [169.475],
         [127.799],
         [170.427],
         [174.624],
         [182.325],
         [180.787],
         [186.205],
         [193.193]],

        [[197.306],
         [159.211],
         [182.231],
         [141.781],
         [167.657],
         [174.355],
         [199.265],
         [193.031],
         [204.798],
         [174.591]],

        [[206.602],
         [143.056],
         [158.885],
         [146.603],
         [165.647],
         [191.776],
         [167.136],
         [174.299],
         [185.264],
         [166.926]],

        [[143.987],
         [159.407],
         [190.776],
         [165.395],
         [172.548],
         [142.939],
         [149.812],
         [183.775],
         [194.066],
         [188.074]],

        [[162.698],
         [165.562],
         [163.429],
         [178.567],
         [186.234],
         [204.231],
         [183.704],
         [151.673],
         [187.492],
         [175.571]],

        [[194.541],
         [166.307],
         [197.986],
         [192.768],
         [146.136],
         [199.492],
         [152.863],
         [170.505],
         [184.777],
         [183.679]],

        [[171.799],
         [188.678],
         [171.338],
         [187.983],
         [173.351],
         [160.008],
         [169.415],
         [143.126],
         [193.862],
         [163.667]],

        [[144.888],
         [176.560],
         [171.884],
         [156.398],
         [195.157],
         [187.493],
         [168.244],
         [181.139],
         [212.997],
         [198.228]],

        [[157.892],
         [167.292],
         [178.130],
         [185.590],
         [151.846],
         [183.273],
         [198.746],
         [171.726],
         [191.336],
         [185.783]],

        [[141.212],
         [191.177],
         [171.838],
         [195.871],
         [189.900],
         [182.854],
         [178.015],
         [127.261],
         [164.144],
         [178.226]],

        [[155.732],
         [175.653],
         [177.900],
         [190.942],
         [187.156],
         [171.985],
         [186.572],
         [145.833],
         [119.192],
         [133.045]],

        [[186.520],
         [184.436],
         [190.652],
         [187.596],
         [201.142],
         [169.996],
         [176.452],
         [147.604],
         [159.511],
         [192.519]],

        [[168.581],
         [175.388],
         [193.577],
         [175.185],
         [191.965],
         [190.584],
         [172.797],
         [149.276],
         [180.252],
         [176.781]],

        [[168.148],
         [181.550],
         [148.777],
         [156.997],
         [162.689],
         [172.193],
         [176.272],
         [144.593],
         [193.879],
         [181.128]],

        [[167.967],
         [192.993],
         [164.960],
         [192.053],
         [198.631],
         [203.618],
         [156.731],
         [188.427],
         [131.311],
         [173.270]],

        [[180.439],
         [178.952],
         [121.589],
         [165.449],
         [187.951],
         [152.610],
         [190.013],
         [167.638],
         [175.631],
         [180.941]],

        [[169.381],
         [196.744],
         [162.154],
         [152.298],
         [181.376],
         [170.173],
         [146.705],
         [190.996],
         [152.326],
         [192.616]],

        [[186.692],
         [155.856],
         [190.578],
         [202.119],
         [165.395],
         [191.055],
         [174.185],
         [152.651],
         [193.739],
         [188.904]],

        [[170.069],
         [170.151],
         [186.826],
         [181.284],
         [175.367],
         [201.038],
         [170.928],
         [189.397],
         [171.326],
         [193.181]],

        [[176.623],
         [138.819],
         [183.405],
         [190.466],
         [199.441],
         [186.041],
         [179.026],
         [162.817],
         [176.482],
         [167.688]],

        [[187.667],
         [202.152],
         [188.638],
         [171.177],
         [162.685],
         [162.403],
         [174.689],
         [193.004],
         [166.927],
         [147.965]]], device='cuda:0')
clipping threshold 1.5596184836847127
a after update for 1 param tensor([[-0.166],
        [-0.301],
        [-0.594],
        [-0.142],
        [ 0.179],
        [ 0.146],
        [ 0.312],
        [ 0.063],
        [ 0.125],
        [ 0.144],
        [-0.440],
        [ 0.340],
        [-0.235],
        [ 0.003],
        [-0.059],
        [-0.192],
        [-0.477],
        [-0.057],
        [ 0.117],
        [ 0.286],
        [ 0.303],
        [ 0.497],
        [ 0.385],
        [-0.080],
        [-0.068],
        [ 0.276],
        [-0.289],
        [-0.382],
        [ 0.663],
        [-0.059]], device='cuda:0')
s after update for 1 param tensor([[2.102],
        [2.056],
        [1.567],
        [2.126],
        [2.383],
        [1.639],
        [1.455],
        [1.641],
        [1.812],
        [1.763],
        [1.184],
        [1.753],
        [1.778],
        [1.899],
        [1.837],
        [2.005],
        [1.331],
        [1.643],
        [1.845],
        [1.883],
        [1.592],
        [1.616],
        [1.776],
        [1.843],
        [2.281],
        [1.298],
        [1.917],
        [1.761],
        [1.672],
        [2.059]], device='cuda:0')
b after update for 1 param tensor([[192.264],
        [190.125],
        [166.007],
        [193.345],
        [204.678],
        [169.763],
        [159.959],
        [169.890],
        [178.503],
        [176.049],
        [144.282],
        [175.571],
        [176.797],
        [182.751],
        [179.708],
        [187.753],
        [152.976],
        [169.956],
        [180.107],
        [181.938],
        [167.335],
        [168.563],
        [176.695],
        [180.019],
        [200.251],
        [151.090],
        [183.594],
        [175.952],
        [171.474],
        [190.271]], device='cuda:0')
clipping threshold 1.5596184836847127
cuda
Objective function 82.11 = squared loss an data 49.92 + 0.5*rho*h**2 24.642752 + alpha*h 4.572443 + L2reg 2.63 + L1reg 0.35 ; SHD = 146 ; DAG True
Proportion of microbatches that were clipped  0.7802408101427318
iteration 3 in inner loop, alpha 65.13114364781069 rho 10000.0 h 0.0702036347868642
iteration 3 in outer loop, alpha = 767.1674915164526, rho = 10000.0, h = 0.0702036347868642
cuda
9630
cuda
Objective function 131.40 = squared loss an data 49.92 + 0.5*rho*h**2 24.642752 + alpha*h 53.857946 + L2reg 2.63 + L1reg 0.35 ; SHD = 146 ; DAG True
||w||^2 2342113334266.3296
exp ma of ||w||^2 470231164570.2303
||w|| 1530396.463099131
exp ma of ||w|| 332075.39529049286
||w||^2 8.834268957432213
exp ma of ||w||^2 471.3870099984663
||w|| 2.9722498141024776
exp ma of ||w|| 2.4625085595767393
||w||^2 3.3277227416940818
exp ma of ||w||^2 4.458034237684864
||w|| 1.8242046874443891
exp ma of ||w|| 2.086546030728973
||w||^2 7.792958367502182
exp ma of ||w||^2 4.7260365387411705
||w|| 2.7915870696616616
exp ma of ||w|| 2.1414431044178976
||w||^2 3.470306525006678
exp ma of ||w||^2 4.213904334099301
||w|| 1.862875874825448
exp ma of ||w|| 2.020985255761646
||w||^2 5.459476754875552
exp ma of ||w||^2 4.440232512831592
||w|| 2.3365523223064257
exp ma of ||w|| 2.0710750226670007
||w||^2 6.192705505459091
exp ma of ||w||^2 4.478509715349304
||w|| 2.488514718754762
exp ma of ||w|| 2.0773071160017635
||w||^2 3.666473038625613
exp ma of ||w||^2 4.673499435709354
||w|| 1.9148036553719059
exp ma of ||w|| 2.1229646812689693
||w||^2 3.8057287916643308
exp ma of ||w||^2 4.615328365505689
||w|| 1.9508277196268078
exp ma of ||w|| 2.116843371521715
||w||^2 8.668656179329956
exp ma of ||w||^2 4.509102334239163
||w|| 2.9442581713107217
exp ma of ||w|| 2.091599535333122
||w||^2 3.3623813559137017
exp ma of ||w||^2 4.775395844300121
||w|| 1.8336797310091262
exp ma of ||w|| 2.1658404757904077
cuda
Objective function 105.19 = squared loss an data 50.74 + 0.5*rho*h**2 12.688236 + alpha*h 38.646112 + L2reg 2.76 + L1reg 0.35 ; SHD = 153 ; DAG True
Proportion of microbatches that were clipped  0.7834273456741082
iteration 1 in inner loop, alpha 767.1674915164526 rho 10000.0 h 0.05037506480999454
9630
cuda
Objective function 219.38 = squared loss an data 50.74 + 0.5*rho*h**2 126.882358 + alpha*h 38.646112 + L2reg 2.76 + L1reg 0.35 ; SHD = 153 ; DAG True
||w||^2 28.246646648561313
exp ma of ||w||^2 57667.68379925893
||w|| 5.314757440237637
exp ma of ||w|| 5.3917609687950225
||w||^2 13.434038249239226
exp ma of ||w||^2 65.49601260582277
||w|| 3.665247365354653
exp ma of ||w|| 3.5413061288972245
||w||^2 6.868314862143135
exp ma of ||w||^2 6.4383093440822226
||w|| 2.6207470046044383
exp ma of ||w|| 2.5151001052601645
||w||^2 6.831337119256301
exp ma of ||w||^2 6.418797728400612
||w|| 2.613682673787371
exp ma of ||w|| 2.5110624281054266
||w||^2 11.33373177791819
exp ma of ||w||^2 6.461552303345256
||w|| 3.366560823439581
exp ma of ||w|| 2.518225350748608
v before min max tensor([[ 9238.877,  2650.309, -1193.933,  ..., -1981.727,   -17.997,
         -1083.355],
        [ 9276.974, -2017.163,  2863.382,  ..., -1927.296,  -977.392,
          2626.589],
        [16380.070,  -160.077, -1236.743,  ...,  -808.477,  1906.540,
          -223.179],
        ...,
        [  663.951,  6644.246,  7358.699,  ..., -1414.587, -1032.100,
          -820.043],
        [-1709.876, -1628.947,  1049.664,  ..., -1153.809,  5966.947,
         12296.669],
        [ 7509.350, -1929.520, 11856.771,  ...,  4378.615, -1703.943,
         -1540.540]], device='cuda:0')
v tensor([[1.000e+01, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e+01],
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         1.000e-12],
        ...,
        [1.000e+01, 1.000e+01, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e+01,
         1.000e+01],
        [1.000e+01, 1.000e-12, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([ 2.269e+03, -1.525e+03,  6.366e+02, -1.025e+03,  1.006e+03, -1.782e+03,
        -1.362e+03, -1.188e+03, -1.701e+03,  4.094e+03,  8.959e+02, -1.470e+03,
         3.519e+03, -1.586e+03,  2.720e+03,  6.993e+02, -1.221e+03, -1.162e+03,
         5.284e+03, -3.668e+02, -9.272e+02, -2.057e+02, -4.064e+02, -1.449e+03,
        -8.201e+02, -1.429e+03, -8.527e+02,  1.219e+03, -5.592e+01,  5.739e+02,
         2.234e+04, -9.208e+02, -4.120e+02,  2.473e+03, -1.025e+03, -6.428e+02,
         1.069e+04, -2.350e+03, -1.120e+03,  1.844e+04,  2.864e+02,  8.715e+03,
        -2.177e+03, -1.513e+03,  1.333e+01, -1.552e+03,  5.080e+03,  4.281e+02,
        -3.455e+02, -1.006e+03, -2.842e+02, -1.907e+03, -2.305e+03, -2.423e+03,
        -1.900e+03, -1.253e+03,  3.345e+02,  5.960e+03,  5.323e+03, -2.122e+03,
        -6.101e+02,  6.551e+03,  3.411e+03, -1.351e+03, -1.902e+03, -1.930e+03,
         6.059e+02, -1.624e+03, -1.312e+03, -1.949e+03, -4.779e+02, -1.372e+03,
        -2.193e+02, -1.733e+03,  8.792e+03, -1.648e+03,  3.175e+03, -1.331e+03,
        -1.369e+03, -1.292e+03, -1.486e+03, -1.666e+03, -6.248e+02,  1.434e+02,
         1.401e+04,  2.726e+02,  1.758e+04,  9.083e+02, -1.404e+03, -5.493e+02,
        -1.974e+03, -1.593e+03, -1.359e+03, -1.471e+03, -1.445e+03, -1.566e+03,
         3.597e+03, -1.710e+03,  2.790e+04, -1.798e+03, -1.813e+03, -1.721e+03,
         6.227e+03,  7.642e+02,  6.112e+02, -6.251e+01,  2.349e+02, -1.849e+03,
         2.584e+03, -9.080e+02, -6.068e+02,  6.590e+03, -1.450e+03,  6.467e+02,
        -4.679e+02, -1.568e+03, -4.996e+02, -1.553e+03, -1.348e+03, -1.382e+03,
         1.552e+04, -5.936e+02,  2.819e+03,  6.101e+03, -1.347e+03, -1.804e+03,
        -1.494e+03, -6.274e+02, -1.606e+03, -1.950e+03, -9.307e+01,  9.080e+02,
        -2.143e+03, -1.495e+03,  1.074e+04,  7.354e+02, -2.151e+03, -1.675e+03,
        -1.664e+03, -7.441e+02,  2.605e+03, -1.382e+03, -1.572e+03, -1.696e+03,
         2.520e+03, -1.744e+03,  2.276e+03, -1.477e+03, -1.038e+03, -1.868e+03,
        -1.213e+03, -1.583e+03, -1.686e+03,  3.192e+03, -2.467e+02, -9.826e+02,
         4.221e+02, -1.867e+03, -1.042e+03, -1.846e+03, -1.651e+03, -8.089e+02,
         2.688e+03, -9.851e+02,  1.942e+03, -1.640e+03, -1.706e+03,  5.754e+02,
         1.464e+03, -8.173e+02,  4.223e+02, -1.584e+03,  2.850e+03, -1.747e+03,
        -1.908e+03,  2.119e+02, -1.627e+03,  1.790e+03, -1.618e+03, -1.002e+03,
        -1.388e+03,  1.013e+03, -3.314e+02, -1.276e+03, -1.602e+03,  4.226e+03,
        -1.170e+03, -1.031e+03,  1.043e+03,  6.497e+03, -8.819e+02, -1.716e+03,
        -1.384e+03, -1.655e+03, -1.480e+03,  1.525e+04, -1.515e+03, -1.075e+03,
        -6.692e+02,  4.971e+03,  6.710e+02, -7.126e+02,  1.623e+03,  1.257e+03,
         7.241e+03, -1.893e+03,  3.844e+03, -1.698e+03, -1.021e+02,  4.523e+03,
         8.461e+02, -5.083e+02,  8.457e+03,  3.563e+03, -1.387e+03,  7.694e+03,
        -1.945e+03, -1.662e+03, -7.857e+02,  5.653e+03,  2.907e+03, -2.591e+02,
        -1.779e+03, -9.374e+02,  9.353e+03,  1.008e+04, -1.501e+03, -1.928e+03,
         4.337e+03, -1.632e+03,  5.932e+03, -9.008e+02, -9.822e+02, -1.322e+03,
        -2.840e+02,  3.065e+03,  2.989e+01,  7.765e+02,  2.002e+03,  6.131e+02,
        -2.136e+03, -1.419e+03, -6.381e+02,  1.689e+04,  3.121e+03,  5.263e+02,
        -6.985e+02,  3.694e+02, -8.152e+02,  1.211e+02, -1.243e+03,  2.327e+03,
        -1.084e+03, -1.372e+03,  5.054e+02,  2.958e+03, -1.656e+03, -7.634e-01,
        -1.061e+03, -2.185e+03,  1.717e+03, -1.012e+02,  1.298e+03, -1.472e+03,
         4.004e+03, -1.271e+03,  4.545e+03, -2.221e+03,  5.952e+02,  1.671e+03,
        -1.526e+03, -1.512e+03,  5.434e+03,  4.197e+02,  1.627e+02,  3.242e+03,
        -1.698e+03,  2.293e+03, -3.897e+02, -1.540e+03, -8.577e+02,  1.711e+03,
         4.275e+03,  9.084e+03, -4.557e+02, -2.045e+03,  3.392e+03, -1.484e+03,
        -7.706e+02, -1.587e+03, -1.500e+03, -1.988e+03, -1.685e+03, -1.575e+03,
        -1.345e+03,  5.299e+02, -8.298e+02, -1.939e+03,  1.238e+03, -1.612e+03],
       device='cuda:0')
v tensor([1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-1.608e+03],
         [ 3.008e+03],
         [ 6.549e+03],
         [ 6.764e+01],
         [-2.275e+03],
         [-1.421e+03],
         [-9.344e+02],
         [ 2.286e+02],
         [ 1.238e+02],
         [-6.411e+02]],

        [[-1.336e+02],
         [ 2.823e+02],
         [-1.423e+03],
         [-5.664e+02],
         [-5.901e+02],
         [ 2.070e+02],
         [ 1.826e+03],
         [ 1.094e+04],
         [ 4.983e+03],
         [-3.110e+02]],

        [[ 1.187e+03],
         [-1.541e+03],
         [-1.371e+03],
         [ 4.603e+03],
         [ 3.073e+03],
         [ 3.415e+03],
         [-2.109e+03],
         [-9.821e+02],
         [-5.257e+02],
         [ 2.130e+03]],

        [[-1.655e+03],
         [-1.672e+03],
         [ 6.591e+03],
         [ 5.543e+03],
         [-1.028e+03],
         [-1.248e+03],
         [-1.883e+03],
         [ 8.147e+02],
         [-1.287e+03],
         [-9.711e+02]],

        [[ 6.323e+03],
         [-1.629e+03],
         [-3.716e+02],
         [-2.023e+03],
         [-2.185e+03],
         [-1.410e+03],
         [-1.236e+03],
         [-1.881e+03],
         [-1.839e+03],
         [-5.503e+02]],

        [[ 1.859e+04],
         [ 3.276e+03],
         [ 1.152e+02],
         [ 2.159e+03],
         [-1.172e+03],
         [ 5.162e+03],
         [ 9.788e+02],
         [-1.141e+01],
         [ 2.951e+03],
         [ 5.377e+03]],

        [[-1.145e+03],
         [-2.133e+03],
         [-1.018e+03],
         [-1.840e+03],
         [ 3.966e+03],
         [ 8.969e+01],
         [-1.289e+03],
         [ 2.607e+03],
         [ 3.619e+03],
         [-1.014e+03]],

        [[ 2.404e+03],
         [ 3.735e+03],
         [-1.170e+03],
         [ 5.681e+03],
         [-1.666e+02],
         [-1.014e+03],
         [-1.443e+03],
         [-6.568e+02],
         [-1.607e+03],
         [ 1.099e+03]],

        [[-1.546e+03],
         [-1.741e+03],
         [-1.385e+03],
         [ 1.393e+03],
         [ 1.626e+03],
         [-1.232e+03],
         [-1.727e+03],
         [ 1.492e+02],
         [-1.398e+03],
         [-3.594e+02]],

        [[-1.526e+03],
         [-1.621e+03],
         [ 7.274e+03],
         [ 5.475e+03],
         [ 4.507e+02],
         [ 9.888e+03],
         [-1.252e+02],
         [ 1.169e+04],
         [-1.359e+03],
         [ 7.616e+03]],

        [[ 3.163e+03],
         [ 2.177e+03],
         [-1.784e+03],
         [ 3.039e+03],
         [-1.937e+03],
         [-1.592e+03],
         [ 3.266e+03],
         [-3.096e+02],
         [-1.050e+03],
         [-1.440e+03]],

        [[-1.598e+03],
         [-9.386e+02],
         [-1.853e+03],
         [ 2.795e+03],
         [ 2.624e+02],
         [-8.805e+02],
         [-1.134e+03],
         [-1.601e+03],
         [ 2.037e+03],
         [-8.888e+02]],

        [[ 5.985e+03],
         [ 1.873e+02],
         [ 2.295e+03],
         [-1.820e+03],
         [ 3.374e+02],
         [ 6.412e+02],
         [-1.498e+03],
         [-1.262e+03],
         [ 1.382e+03],
         [-2.496e+02]],

        [[-5.520e+02],
         [ 3.735e+03],
         [ 6.006e+02],
         [-1.114e+03],
         [-1.590e+03],
         [-4.347e+02],
         [-8.745e+02],
         [ 1.890e+03],
         [ 3.560e+03],
         [ 2.028e+03]],

        [[-1.747e+03],
         [-1.656e+03],
         [-1.858e+03],
         [-5.066e+02],
         [ 8.965e+03],
         [ 1.024e+04],
         [-1.452e+03],
         [-1.280e+03],
         [ 4.470e+03],
         [ 4.064e+03]],

        [[-1.949e+03],
         [ 1.459e+03],
         [ 1.882e+03],
         [ 1.501e+02],
         [ 1.756e+03],
         [-1.602e+03],
         [ 3.895e+03],
         [-1.851e+03],
         [-6.667e+02],
         [ 5.831e+03]],

        [[ 2.675e+03],
         [ 7.946e+02],
         [-1.010e+03],
         [-2.084e+03],
         [-1.818e+03],
         [ 6.536e+03],
         [-1.809e+03],
         [-4.074e+02],
         [-5.147e+02],
         [-7.243e+02]],

        [[ 1.754e+03],
         [ 5.067e+03],
         [ 7.200e+02],
         [-3.843e+02],
         [-7.072e+02],
         [-1.129e+03],
         [ 4.297e+02],
         [ 7.336e+02],
         [ 1.387e+03],
         [-1.854e+03]],

        [[-9.765e+02],
         [-9.931e+02],
         [-1.231e+03],
         [ 1.062e+04],
         [-1.587e+03],
         [ 2.423e+03],
         [-5.934e+02],
         [ 4.426e+03],
         [-9.330e+02],
         [-1.851e+03]],

        [[ 9.635e+02],
         [-8.678e+02],
         [-5.888e+02],
         [-1.738e+03],
         [-1.356e+03],
         [ 8.176e+02],
         [-1.234e+03],
         [-1.508e+03],
         [ 3.179e+02],
         [ 4.100e+03]],

        [[-2.007e+03],
         [-6.076e+02],
         [-1.935e+03],
         [-1.964e+03],
         [-1.773e+03],
         [-1.113e+03],
         [-1.141e+03],
         [-1.841e+03],
         [ 1.249e+02],
         [ 3.626e+03]],

        [[-6.824e+02],
         [-1.964e+03],
         [ 1.602e+03],
         [-1.977e+03],
         [-1.466e+02],
         [ 7.040e+02],
         [ 3.932e+03],
         [-1.630e+03],
         [-1.274e+03],
         [ 4.034e+03]],

        [[-9.414e+02],
         [-1.210e+03],
         [-1.635e+03],
         [-1.569e+03],
         [-1.041e+03],
         [-1.168e+03],
         [ 4.772e+03],
         [-4.085e+01],
         [-2.241e+03],
         [-5.549e+02]],

        [[-1.723e+03],
         [ 2.274e+03],
         [-1.319e+03],
         [-1.007e+03],
         [-1.798e+03],
         [-5.806e+02],
         [-6.874e+02],
         [ 1.658e+03],
         [ 2.690e+02],
         [ 2.878e+03]],

        [[-1.053e+03],
         [-1.268e+03],
         [-1.134e+03],
         [-1.333e+03],
         [-8.688e+02],
         [ 1.126e+03],
         [ 6.342e+02],
         [-1.713e+03],
         [-1.355e+03],
         [ 1.367e+03]],

        [[-1.686e+03],
         [-1.861e+03],
         [-1.865e+03],
         [ 1.601e+03],
         [-1.821e+03],
         [-1.581e+03],
         [-9.712e+02],
         [ 2.174e+03],
         [-5.857e+02],
         [ 2.567e+03]],

        [[-9.638e+02],
         [-1.083e+03],
         [ 4.574e+02],
         [ 4.291e+03],
         [-1.158e+02],
         [-3.523e+02],
         [ 1.024e+04],
         [-2.054e+03],
         [ 4.675e+03],
         [-5.022e+02]],

        [[-1.012e+03],
         [-1.522e+03],
         [-1.547e+03],
         [-1.702e+03],
         [-1.928e+03],
         [ 9.552e+03],
         [ 1.292e+03],
         [-1.423e+03],
         [ 2.075e+02],
         [ 1.760e+03]],

        [[ 3.713e+03],
         [-1.692e+03],
         [-1.883e+03],
         [ 1.211e+02],
         [-2.134e+03],
         [-2.134e+03],
         [-1.229e+03],
         [-2.258e+03],
         [ 8.339e+02],
         [ 2.088e+03]],

        [[ 1.778e+03],
         [-7.670e+01],
         [-4.628e+02],
         [ 6.722e+01],
         [ 3.439e+03],
         [-7.004e+02],
         [-1.669e+03],
         [ 4.820e+03],
         [-2.110e+03],
         [-1.219e+03]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[ -766.071],
        [ -826.133],
        [ -483.719],
        [  748.038],
        [ 3464.736],
        [-1233.784],
        [-1647.716],
        [ 1793.946],
        [-1468.136],
        [ -361.217],
        [ -435.793],
        [ 2237.969],
        [-1579.554],
        [-1575.474],
        [-1420.079],
        [  858.340],
        [-1743.702],
        [-1078.846],
        [ 3872.691],
        [-1374.384],
        [ 4910.221],
        [ -155.384],
        [  293.419],
        [ 4269.546],
        [ 3064.216],
        [ -746.724],
        [   66.390],
        [-1056.378],
        [ -270.621],
        [-2089.173]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-0.062,  1.165,  0.304,  ..., -1.041, -0.202, -0.433],
        [-0.019, -0.254, -0.300,  ...,  0.010,  0.161, -0.298],
        [-0.277, -0.274,  0.095,  ..., -0.588, -0.204,  0.477],
        ...,
        [-0.399, -0.131,  0.093,  ...,  0.667,  0.174,  0.031],
        [-0.264,  0.014, -0.100,  ..., -1.478,  0.054,  0.194],
        [-0.041, -0.184,  0.049,  ..., -1.058,  0.135, -0.094]],
       device='cuda:0')
s after update for 1 param tensor([[2.740, 1.518, 2.171,  ..., 1.964, 1.280, 1.477],
        [1.575, 1.992, 1.883,  ..., 1.867, 1.028, 1.721],
        [2.853, 1.354, 1.579,  ..., 1.319, 1.310, 1.595],
        ...,
        [2.046, 1.845, 1.871,  ..., 1.613, 1.732, 1.821],
        [1.712, 1.566, 1.700,  ..., 1.971, 2.160, 2.840],
        [2.166, 1.900, 1.723,  ..., 1.809, 1.763, 2.403]], device='cuda:0')
b after update for 1 param tensor([[221.242, 164.679, 196.952,  ..., 187.292, 151.235, 162.410],
        [167.738, 188.620, 183.403,  ..., 182.613, 135.540, 175.331],
        [225.771, 155.537, 167.975,  ..., 153.506, 152.963, 168.790],
        ...,
        [191.191, 181.573, 182.830,  ..., 169.769, 175.923, 180.364],
        [174.878, 167.273, 174.290,  ..., 187.660, 196.444, 225.234],
        [196.700, 184.252, 175.422,  ..., 179.781, 177.466, 207.207]],
       device='cuda:0')
clipping threshold 2.0608825993151707
a after update for 1 param tensor([ 1.950e-01,  3.177e-01,  9.558e-01, -7.212e-01, -3.634e-01, -2.578e-02,
        -4.663e-02,  9.200e-02, -2.535e-01,  6.252e-02, -1.612e+00, -2.533e-01,
         6.877e-01,  1.298e-01,  3.870e-02,  3.895e-01, -1.291e+00,  2.051e-01,
         6.927e-01,  6.686e-01,  1.479e+00,  2.184e-01,  2.986e-03,  2.689e-01,
        -4.036e-01, -2.650e-01, -6.139e-01,  4.967e-01, -4.221e-01,  8.332e-01,
        -2.532e-01,  1.062e+00, -4.015e-02, -1.224e-01, -4.410e-01, -1.155e+00,
        -4.038e-01,  1.106e-01,  3.780e-01,  1.250e-01, -3.689e-01, -3.041e-01,
         7.888e-01,  1.027e+00,  2.759e-01, -6.339e-01,  1.131e+00,  2.087e+00,
        -7.516e-01, -7.412e-01, -8.820e-02, -3.739e-01, -2.544e-02, -3.819e-01,
         4.380e-02,  4.525e-01, -7.503e-01, -3.826e-02,  3.549e-01, -2.556e-02,
        -6.400e-04, -7.173e-01,  8.608e-01,  5.289e-01,  6.181e-01, -2.798e-01,
         1.593e-01,  5.446e-02,  6.182e-01,  1.183e-02,  9.559e-02,  2.270e-01,
         1.113e+00,  2.651e-01, -1.944e-02,  2.702e-01,  1.076e-01,  8.481e-01,
        -5.398e-01,  8.743e-01,  8.907e-01, -5.007e-01, -1.976e-01, -1.428e+00,
        -1.153e+00,  9.571e-01, -6.100e-02, -4.711e-01,  2.220e-01,  1.170e+00,
         1.266e-02, -7.475e-01,  1.808e-01, -8.153e-01,  7.257e-01, -9.034e-01,
         1.332e-01,  7.151e-01, -8.861e-01,  6.487e-01,  2.484e-01, -3.143e-02,
        -6.940e-02,  2.066e-01, -8.859e-01,  1.261e-01, -6.366e-03, -5.335e-01,
         1.357e-01, -9.699e-01, -1.128e-01,  7.919e-02,  7.162e-01, -3.752e-01,
         5.427e-01,  7.141e-01, -6.027e-01,  1.832e-01,  4.468e-01,  2.202e-01,
         4.142e-01, -6.950e-01,  1.065e+00,  2.579e-01,  9.230e-01,  2.566e-01,
         3.519e-02,  1.012e+00, -1.385e-01, -4.863e-01, -2.686e+00,  1.375e-01,
        -6.685e-01,  2.402e-01, -1.566e-01, -6.395e-01,  6.673e-01, -9.859e-01,
         3.675e-01,  7.879e-01, -5.275e-01,  1.026e-01, -5.677e-02, -4.300e-01,
         5.122e-01, -4.177e-01,  7.154e-01, -1.171e-01,  8.800e-01,  1.191e+00,
        -3.714e-01, -1.777e-01, -2.942e-01, -5.134e-01, -4.532e-01, -4.916e-01,
        -1.870e-01, -5.087e-01, -3.011e-01,  4.610e-01, -8.925e-02, -1.502e-02,
         4.810e-01,  6.264e-01, -4.578e-02,  2.568e-01,  9.591e-01,  1.628e-01,
         1.433e-01, -3.883e-01,  3.364e-02,  3.023e-01,  3.117e-01,  4.925e-02,
        -3.230e-01, -7.238e-01, -8.317e-03,  1.138e+00, -1.011e+00,  3.274e-01,
         7.863e-01,  9.188e-01, -2.584e-02, -3.854e-02, -2.494e-01, -6.548e-01,
        -3.272e-01,  6.267e-02,  5.583e-01, -3.575e-01, -5.290e-01,  7.455e-01,
        -3.335e-01, -1.124e+00,  5.986e-01,  1.949e-01, -1.775e-01,  3.145e-01,
         6.750e-01, -3.927e-01, -2.878e-01,  3.526e-01, -7.216e-01, -9.409e-01,
         1.321e-01, -8.220e-01,  1.070e+00,  4.074e-01, -4.021e-01,  2.018e-01,
        -2.290e-01, -8.925e-03,  2.982e-01, -4.972e-01, -7.647e-01,  4.384e-01,
         7.543e-02,  5.056e-01,  6.040e-02, -3.262e-01, -6.542e-01, -3.642e-01,
         5.421e-01, -4.470e-01,  1.171e+00,  8.134e-01,  3.200e-01,  7.467e-02,
         8.781e-01, -1.085e+00, -6.732e-01,  2.170e-01, -1.164e+00, -2.087e-01,
        -8.816e-01,  8.951e-01, -1.535e-02,  1.014e+00,  8.138e-01, -8.798e-02,
        -2.810e-01, -6.544e-01, -1.476e-01, -4.526e-01, -1.597e-01,  2.430e-02,
         2.039e-01,  1.724e-01, -4.505e-01, -8.649e-01, -2.231e-01,  3.157e-01,
         8.424e-01, -3.839e-01, -1.525e+00,  4.830e-01, -1.225e+00, -7.436e-01,
        -1.252e+00,  3.938e-01,  1.290e+00, -4.268e-01, -1.887e-01,  1.546e-01,
         3.159e-01, -4.917e-02, -5.108e-01,  6.647e-01, -8.089e-01, -7.353e-01,
         1.372e+00,  2.287e-02,  3.664e-01,  1.894e-02, -2.977e-01,  2.744e-01,
         9.086e-01, -4.246e-01, -9.496e-02, -4.560e-01,  1.550e-01, -1.129e+00,
        -9.410e-01, -6.798e-02,  5.336e-01,  3.436e-01,  6.622e-01, -9.111e-01,
         8.502e-01,  4.064e-01, -5.627e-01, -8.303e-01,  5.185e-01, -1.189e-01,
         1.491e-01,  7.060e-01, -1.550e-01,  4.818e-01,  4.937e-01,  6.621e-01],
       device='cuda:0')
s after update for 1 param tensor([1.928, 1.795, 2.001, 1.861, 1.734, 1.892, 1.503, 2.069, 2.331, 2.045,
        1.534, 1.425, 1.662, 1.769, 1.811, 2.133, 1.310, 1.609, 1.814, 1.107,
        1.516, 1.810, 1.942, 1.697, 1.279, 1.516, 1.162, 1.602, 1.677, 2.116,
        2.288, 1.492, 1.613, 1.741, 1.736, 1.615, 1.840, 2.275, 1.539, 2.142,
        1.798, 1.887, 2.165, 1.985, 1.871, 1.514, 2.155, 1.595, 1.695, 1.796,
        2.040, 1.965, 2.237, 2.333, 1.899, 1.749, 1.852, 2.118, 2.136, 2.063,
        1.199, 1.976, 1.624, 1.523, 1.916, 1.857, 1.745, 2.022, 1.272, 2.023,
        0.948, 2.084, 1.544, 1.688, 2.039, 1.590, 2.306, 1.636, 1.618, 1.280,
        1.785, 1.931, 1.708, 1.739, 2.221, 1.614, 2.637, 2.087, 1.547, 1.149,
        1.926, 1.836, 1.821, 1.725, 1.563, 1.554, 2.001, 1.687, 2.622, 1.777,
        1.742, 1.708, 2.019, 1.642, 2.193, 1.571, 1.797, 1.788, 2.623, 1.441,
        1.285, 1.626, 1.398, 1.907, 1.782, 1.528, 1.412, 1.562, 1.338, 1.396,
        2.259, 1.491, 1.912, 1.748, 1.645, 1.762, 1.595, 1.397, 1.853, 1.924,
        2.216, 1.950, 2.127, 1.517, 1.981, 2.226, 2.073, 1.744, 1.803, 1.609,
        1.736, 1.467, 1.585, 1.694, 2.208, 1.686, 2.207, 1.428, 1.995, 1.798,
        1.577, 1.885, 1.621, 2.254, 1.466, 1.795, 2.168, 1.869, 1.870, 1.785,
        1.633, 1.364, 1.954, 1.778, 1.520, 1.760, 1.844, 2.336, 1.330, 1.866,
        2.199, 1.742, 1.232, 1.795, 1.838, 1.637, 1.564, 2.164, 1.588, 1.581,
        1.342, 2.186, 1.687, 1.226, 1.577, 1.926, 1.851, 1.970, 2.396, 1.910,
        1.535, 1.933, 1.728, 1.790, 1.528, 1.587, 1.501, 1.505, 1.443, 1.948,
        2.076, 1.505, 1.878, 2.008, 1.833, 1.890, 1.759, 1.857, 1.728, 1.921,
        1.588, 1.839, 2.081, 1.862, 1.604, 1.890, 1.947, 1.657, 2.067, 1.827,
        2.053, 2.125, 1.711, 1.837, 1.834, 2.162, 1.445, 1.855, 1.665, 1.571,
        1.993, 1.264, 1.840, 1.537, 1.390, 2.343, 1.696, 2.174, 1.870, 2.040,
        2.097, 1.793, 1.177, 1.976, 1.971, 2.235, 2.132, 1.488, 1.316, 1.831,
        1.531, 2.063, 1.237, 1.345, 1.730, 2.283, 1.636, 1.903, 1.334, 2.108,
        1.741, 1.640, 2.618, 2.290, 1.776, 1.227, 2.165, 2.240, 1.868, 1.926,
        1.469, 1.658, 1.870, 1.714, 2.256, 2.292, 1.637, 2.050, 1.106, 1.519,
        2.072, 1.961, 1.667, 2.318, 1.484, 1.971, 2.268, 1.965, 1.114, 1.568,
        1.471, 1.963, 1.787, 1.806, 1.452, 1.600, 1.524, 2.042, 2.088, 1.941],
       device='cuda:0')
b after update for 1 param tensor([185.604, 179.049, 189.048, 182.358, 175.995, 183.863, 163.865, 192.256,
        204.052, 191.139, 165.532, 159.552, 172.293, 177.780, 179.853, 195.209,
        152.977, 169.521, 180.041, 140.627, 164.556, 179.834, 186.280, 174.120,
        151.158, 164.550, 144.050, 169.197, 173.081, 194.433, 202.153, 163.277,
        169.734, 176.337, 176.085, 169.851, 181.290, 201.582, 165.808, 195.639,
        179.219, 183.607, 196.676, 188.327, 182.834, 164.464, 196.205, 168.796,
        173.991, 179.118, 190.887, 187.365, 199.910, 204.166, 184.201, 176.776,
        181.896, 194.505, 195.327, 191.964, 146.335, 187.906, 170.304, 164.971,
        185.008, 182.124, 176.546, 190.069, 150.727, 190.089, 130.126, 192.947,
        166.059, 173.631, 190.872, 168.559, 202.973, 170.950, 169.995, 151.245,
        178.569, 185.755, 174.655, 176.257, 199.181, 169.817, 217.042, 193.081,
        166.250, 143.292, 185.479, 181.093, 180.341, 175.524, 167.113, 166.636,
        189.079, 173.626, 216.435, 178.191, 176.414, 174.686, 189.934, 171.291,
        197.926, 167.522, 179.193, 178.733, 216.461, 160.422, 151.490, 170.459,
        158.027, 184.553, 178.444, 165.220, 158.806, 167.064, 154.581, 157.919,
        200.905, 163.187, 184.819, 176.729, 171.427, 177.420, 168.790, 157.998,
        181.930, 185.419, 198.960, 186.659, 194.908, 164.601, 188.142, 199.435,
        192.446, 176.486, 179.475, 169.531, 176.118, 161.901, 168.256, 173.967,
        198.587, 173.532, 198.574, 159.736, 188.794, 179.232, 167.845, 183.506,
        170.196, 200.661, 161.833, 179.066, 196.798, 182.748, 182.764, 178.582,
        170.798, 156.076, 186.829, 178.208, 164.799, 177.298, 181.522, 204.262,
        154.166, 182.558, 198.222, 176.405, 148.336, 179.068, 181.228, 171.008,
        167.168, 196.614, 168.426, 168.073, 154.822, 197.633, 173.602, 148.017,
        167.871, 185.500, 181.827, 187.596, 206.887, 184.702, 165.587, 185.840,
        175.675, 178.834, 165.195, 168.367, 163.764, 163.949, 160.561, 186.536,
        192.558, 163.954, 183.160, 189.398, 180.961, 183.734, 177.290, 182.159,
        175.712, 185.265, 168.442, 181.237, 192.792, 182.387, 169.290, 183.768,
        186.487, 172.066, 192.138, 180.650, 191.491, 194.817, 174.845, 181.147,
        181.010, 196.545, 160.653, 182.037, 172.440, 167.547, 188.670, 150.261,
        181.306, 165.678, 157.577, 204.590, 174.080, 197.078, 182.764, 190.891,
        193.570, 178.981, 145.011, 187.890, 187.642, 199.831, 195.150, 163.064,
        153.338, 180.845, 165.390, 191.994, 148.643, 154.993, 175.807, 201.941,
        170.974, 184.373, 154.380, 194.039, 176.367, 171.154, 216.263, 202.278,
        178.100, 148.046, 196.641, 200.040, 182.668, 185.480, 162.016, 172.114,
        182.774, 174.983, 200.757, 202.352, 171.000, 191.369, 140.595, 164.751,
        192.416, 187.157, 172.592, 203.502, 162.825, 187.634, 201.290, 187.371,
        141.092, 167.370, 162.106, 187.257, 178.648, 179.601, 161.059, 169.055,
        164.998, 190.983, 193.118, 186.217], device='cuda:0')
clipping threshold 2.0608825993151707
a after update for 1 param tensor([[[ 2.560e-01],
         [ 7.047e-01],
         [-5.178e-01],
         [ 2.381e-01],
         [-3.671e-01],
         [ 9.468e-02],
         [ 5.862e-02],
         [ 3.846e-01],
         [ 9.311e-01],
         [ 2.225e-01]],

        [[-1.906e-01],
         [ 1.335e-01],
         [ 7.244e-01],
         [-5.897e-01],
         [ 7.779e-01],
         [ 4.442e-01],
         [ 3.571e-01],
         [ 4.564e-01],
         [-1.008e+00],
         [ 2.817e-01]],

        [[-1.915e-01],
         [-4.096e-02],
         [-1.268e+00],
         [ 8.829e-01],
         [ 1.054e-01],
         [ 6.442e-01],
         [ 2.711e-01],
         [ 6.109e-01],
         [ 1.551e-01],
         [-2.066e-01]],

        [[-6.274e-01],
         [-3.245e-01],
         [ 2.314e-01],
         [ 1.023e+00],
         [-7.870e-01],
         [-1.276e-01],
         [ 1.439e-01],
         [-1.031e+00],
         [ 5.980e-02],
         [ 2.590e-01]],

        [[-6.344e-01],
         [-2.624e-01],
         [ 6.961e-01],
         [ 4.784e-02],
         [ 3.995e-01],
         [ 1.196e-01],
         [-4.630e-01],
         [ 1.033e+00],
         [-1.613e-01],
         [ 1.012e+00]],

        [[-1.121e+00],
         [-1.675e+00],
         [-2.454e-01],
         [ 5.013e-01],
         [-2.135e-01],
         [ 6.214e-02],
         [-3.261e-01],
         [-1.664e-01],
         [-2.784e-01],
         [-2.713e-01]],

        [[ 2.739e-01],
         [ 7.394e-01],
         [-2.676e-01],
         [ 6.438e-02],
         [-9.518e-02],
         [ 6.977e-01],
         [ 2.338e-01],
         [-1.510e+00],
         [-2.162e-01],
         [ 6.822e-01]],

        [[ 2.520e-01],
         [ 1.008e+00],
         [ 7.182e-01],
         [-6.635e-01],
         [-5.426e-02],
         [-7.243e-02],
         [-5.634e-01],
         [ 1.050e+00],
         [ 2.645e-01],
         [ 2.656e-01]],

        [[-9.068e-01],
         [-3.923e-02],
         [ 1.265e-01],
         [ 3.140e-01],
         [-2.643e-01],
         [ 3.111e-01],
         [ 6.152e-01],
         [ 2.638e-01],
         [-1.073e+00],
         [ 2.037e-01]],

        [[-3.027e-01],
         [-2.630e-01],
         [-4.112e-01],
         [ 2.729e-01],
         [ 3.308e-02],
         [ 9.322e-02],
         [ 5.900e-01],
         [-9.055e-01],
         [-3.563e-01],
         [-7.103e-02]],

        [[ 3.174e-01],
         [ 1.233e+00],
         [-1.832e-01],
         [-5.072e-01],
         [ 1.641e-01],
         [ 1.072e-01],
         [ 4.634e-02],
         [-2.877e-01],
         [-7.752e-01],
         [-1.950e-01]],

        [[-9.984e-01],
         [-7.481e-01],
         [ 1.025e+00],
         [ 7.607e-01],
         [-2.039e-01],
         [-2.052e-01],
         [ 5.089e-01],
         [ 6.047e-01],
         [-4.138e-01],
         [ 1.076e-01]],

        [[ 7.377e-01],
         [-3.588e-01],
         [-7.989e-01],
         [ 8.346e-01],
         [ 2.041e-01],
         [-8.018e-01],
         [-2.560e-01],
         [ 1.366e+00],
         [-3.457e-01],
         [ 6.381e-01]],

        [[-1.328e+00],
         [ 7.568e-01],
         [ 3.093e-01],
         [-8.307e-01],
         [ 8.387e-01],
         [-3.779e-01],
         [ 2.354e-01],
         [-8.333e-01],
         [-8.406e-01],
         [-3.982e-01]],

        [[-8.142e-01],
         [ 1.300e-01],
         [ 9.904e-01],
         [ 7.038e-02],
         [ 3.219e-01],
         [ 1.141e+00],
         [ 2.446e-01],
         [ 2.215e-01],
         [ 1.074e+00],
         [ 6.186e-02]],

        [[ 4.983e-01],
         [ 1.857e-01],
         [-6.060e-01],
         [-4.837e-01],
         [ 8.178e-01],
         [-7.631e-01],
         [-3.915e-01],
         [-6.369e-01],
         [-1.808e-01],
         [-5.509e-01]],

        [[ 1.070e+00],
         [-2.021e-02],
         [-1.295e-02],
         [-4.623e-01],
         [ 7.339e-01],
         [ 2.129e-01],
         [ 3.895e-01],
         [ 9.414e-01],
         [ 1.429e-03],
         [ 3.663e-01]],

        [[ 4.613e-01],
         [-5.545e-01],
         [ 6.184e-01],
         [ 6.009e-02],
         [-5.204e-01],
         [ 2.999e-01],
         [-2.309e-01],
         [ 8.084e-01],
         [-3.841e-02],
         [ 2.159e-01]],

        [[-3.276e-02],
         [-5.297e-01],
         [ 9.320e-01],
         [-1.328e-01],
         [ 3.531e-01],
         [ 4.436e-01],
         [ 6.031e-01],
         [ 2.176e-01],
         [-5.747e-01],
         [-1.004e+00]],

        [[-3.122e-01],
         [ 1.365e-01],
         [ 6.509e-02],
         [-6.912e-01],
         [-2.383e-01],
         [ 1.374e-01],
         [-2.917e-01],
         [-6.170e-01],
         [ 8.375e-01],
         [-1.121e+00]],

        [[ 1.500e+00],
         [-2.427e-01],
         [ 4.137e-01],
         [-7.269e-01],
         [ 1.374e-01],
         [-3.323e-01],
         [-1.003e+00],
         [-1.210e-01],
         [ 5.714e-01],
         [ 1.779e-02]],

        [[ 5.491e-01],
         [ 8.570e-01],
         [ 7.979e-01],
         [ 6.260e-01],
         [-1.897e-01],
         [ 1.017e-01],
         [-4.539e-01],
         [-8.115e-01],
         [-2.249e-01],
         [-1.137e+00]],

        [[-6.158e-01],
         [-6.113e-01],
         [-1.081e+00],
         [-1.390e+00],
         [-1.481e-01],
         [ 1.127e-01],
         [ 7.497e-01],
         [ 4.429e-01],
         [ 5.320e-01],
         [ 3.935e-01]],

        [[-4.001e-01],
         [-8.712e-01],
         [-2.448e-01],
         [ 7.820e-02],
         [-1.330e-01],
         [-9.391e-01],
         [ 3.546e-01],
         [ 4.966e-02],
         [-5.202e-01],
         [ 1.366e+00]],

        [[ 5.526e-01],
         [-4.126e-02],
         [-2.223e-01],
         [ 9.626e-01],
         [ 4.540e-01],
         [ 2.274e-01],
         [-1.271e-01],
         [ 5.265e-01],
         [ 1.310e-01],
         [-2.177e-02]],

        [[ 1.075e+00],
         [ 4.287e-02],
         [-9.412e-01],
         [ 7.200e-01],
         [-3.431e-01],
         [-2.734e-01],
         [-7.830e-02],
         [-4.537e-02],
         [ 6.518e-01],
         [ 3.943e-01]],

        [[-4.837e-01],
         [ 3.607e-01],
         [-2.040e-01],
         [-4.280e-02],
         [-5.565e-01],
         [ 3.562e-01],
         [ 3.442e-01],
         [ 1.821e-02],
         [-5.861e-01],
         [ 9.781e-02]],

        [[-5.055e-01],
         [-1.409e-01],
         [-2.796e+00],
         [ 2.828e-01],
         [-3.089e-01],
         [ 6.717e-01],
         [ 1.627e-01],
         [ 3.979e-01],
         [ 2.313e-01],
         [ 8.454e-03]],

        [[-7.206e-01],
         [ 2.706e-02],
         [-1.232e+00],
         [ 3.003e-01],
         [ 1.184e+00],
         [-4.324e-01],
         [ 1.125e-01],
         [-3.459e-01],
         [-7.757e-01],
         [ 4.977e-03]],

        [[ 3.979e-01],
         [-3.831e-01],
         [ 6.641e-01],
         [ 4.789e-01],
         [-1.000e+00],
         [-3.654e-01],
         [-1.054e-01],
         [-2.761e-02],
         [ 1.123e-02],
         [ 9.329e-01]]], device='cuda:0')
s after update for 1 param tensor([[[1.602],
         [1.775],
         [2.019],
         [1.863],
         [2.246],
         [1.786],
         [1.480],
         [1.681],
         [1.677],
         [1.498]],

        [[1.753],
         [2.085],
         [1.496],
         [1.536],
         [1.566],
         [1.720],
         [1.905],
         [1.899],
         [1.957],
         [2.044]],

        [[1.683],
         [1.797],
         [1.523],
         [2.296],
         [2.039],
         [1.771],
         [2.034],
         [1.045],
         [1.060],
         [2.168]],

        [[1.696],
         [1.625],
         [1.975],
         [2.073],
         [1.879],
         [1.759],
         [2.043],
         [1.577],
         [1.663],
         [1.326]],

        [[2.308],
         [1.569],
         [2.046],
         [1.968],
         [2.102],
         [1.612],
         [1.411],
         [1.964],
         [1.804],
         [1.716]],

        [[2.393],
         [1.611],
         [2.123],
         [1.415],
         [1.727],
         [1.651],
         [1.805],
         [2.032],
         [2.423],
         [2.097]],

        [[1.653],
         [2.063],
         [1.111],
         [1.888],
         [2.080],
         [2.244],
         [1.453],
         [1.261],
         [1.935],
         [1.850]],

        [[2.379],
         [2.225],
         [1.259],
         [2.046],
         [1.168],
         [1.785],
         [1.649],
         [0.914],
         [1.609],
         [2.081]],

        [[1.677],
         [1.682],
         [1.542],
         [1.921],
         [1.936],
         [1.622],
         [1.710],
         [2.083],
         [1.426],
         [1.875]],

        [[2.106],
         [1.613],
         [1.627],
         [2.029],
         [2.173],
         [1.696],
         [1.595],
         [1.861],
         [2.013],
         [1.554]],

        [[2.259],
         [1.991],
         [1.724],
         [2.258],
         [1.883],
         [1.847],
         [1.732],
         [1.224],
         [1.622],
         [1.648]],

        [[2.185],
         [1.621],
         [1.811],
         [1.951],
         [1.885],
         [1.511],
         [1.983],
         [1.871],
         [2.109],
         [1.652]],

        [[1.969],
         [1.179],
         [2.323],
         [1.751],
         [1.859],
         [1.992],
         [1.460],
         [1.426],
         [2.502],
         [1.731]],

        [[1.460],
         [2.148],
         [1.693],
         [1.804],
         [1.633],
         [1.446],
         [1.969],
         [1.940],
         [2.088],
         [2.093]],

        [[1.749],
         [1.599],
         [1.847],
         [1.508],
         [2.241],
         [2.149],
         [1.542],
         [1.647],
         [1.816],
         [2.096]],

        [[1.925],
         [2.424],
         [2.033],
         [1.996],
         [1.781],
         [1.539],
         [1.756],
         [1.779],
         [2.033],
         [1.894]],

        [[2.175],
         [2.074],
         [1.157],
         [2.137],
         [1.839],
         [2.280],
         [1.753],
         [2.010],
         [1.538],
         [1.591]],

        [[2.333],
         [2.251],
         [1.605],
         [1.189],
         [1.793],
         [1.219],
         [1.716],
         [1.595],
         [1.864],
         [1.882]],

        [[1.186],
         [1.310],
         [2.164],
         [2.066],
         [1.947],
         [2.322],
         [1.564],
         [1.863],
         [1.158],
         [1.849]],

        [[2.094],
         [1.861],
         [2.193],
         [1.932],
         [1.831],
         [2.105],
         [1.904],
         [1.530],
         [1.853],
         [2.246]],

        [[1.948],
         [1.903],
         [1.860],
         [2.025],
         [1.997],
         [1.538],
         [1.643],
         [1.771],
         [2.046],
         [1.933]],

        [[1.862],
         [1.889],
         [2.078],
         [1.937],
         [1.661],
         [1.980],
         [1.911],
         [1.574],
         [1.814],
         [2.076]],

        [[1.026],
         [1.261],
         [1.715],
         [1.586],
         [1.376],
         [1.678],
         [1.609],
         [1.041],
         [2.159],
         [1.959]],

        [[1.703],
         [2.214],
         [1.394],
         [1.892],
         [1.791],
         [1.170],
         [1.656],
         [2.259],
         [1.487],
         [1.831]],

        [[1.439],
         [1.396],
         [1.775],
         [1.366],
         [1.794],
         [2.124],
         [2.318],
         [1.665],
         [1.354],
         [1.671]],

        [[1.834],
         [1.961],
         [1.946],
         [1.945],
         [1.846],
         [1.636],
         [0.935],
         [1.969],
         [1.388],
         [1.912]],

        [[1.384],
         [1.339],
         [2.064],
         [2.286],
         [1.565],
         [1.428],
         [2.186],
         [2.001],
         [1.841],
         [1.601]],

        [[1.791],
         [1.880],
         [1.494],
         [1.640],
         [1.899],
         [2.091],
         [1.822],
         [1.665],
         [2.103],
         [1.392]],

        [[1.612],
         [1.962],
         [1.877],
         [1.945],
         [2.052],
         [2.053],
         [1.692],
         [2.200],
         [2.405],
         [1.749]],

        [[1.993],
         [1.783],
         [1.163],
         [2.172],
         [2.071],
         [1.631],
         [1.612],
         [2.401],
         [2.096],
         [1.177]]], device='cuda:0')
b after update for 1 param tensor([[[169.194],
         [178.076],
         [189.906],
         [182.427],
         [200.322],
         [178.606],
         [162.584],
         [173.311],
         [173.077],
         [163.570]],

        [[176.982],
         [192.990],
         [163.460],
         [165.677],
         [167.270],
         [175.274],
         [184.466],
         [184.209],
         [186.972],
         [191.094]],

        [[173.374],
         [179.179],
         [164.970],
         [202.528],
         [190.876],
         [177.874],
         [190.613],
         [136.662],
         [137.613],
         [196.794]],

        [[174.077],
         [170.379],
         [187.841],
         [192.452],
         [183.222],
         [177.291],
         [191.019],
         [167.830],
         [172.370],
         [153.936]],

        [[203.052],
         [167.393],
         [191.164],
         [187.518],
         [193.763],
         [169.673],
         [158.794],
         [187.328],
         [179.519],
         [175.069]],

        [[206.768],
         [169.640],
         [194.760],
         [158.987],
         [175.671],
         [171.717],
         [179.555],
         [190.546],
         [208.056],
         [193.546]],

        [[171.868],
         [191.956],
         [140.894],
         [183.655],
         [192.757],
         [200.221],
         [161.124],
         [150.097],
         [185.901],
         [181.809]],

        [[206.173],
         [199.363],
         [149.996],
         [191.174],
         [144.475],
         [178.560],
         [171.627],
         [127.787],
         [169.564],
         [192.818]],

        [[173.073],
         [173.358],
         [165.967],
         [185.229],
         [185.994],
         [170.235],
         [174.759],
         [192.881],
         [159.617],
         [182.999]],

        [[193.943],
         [169.731],
         [170.509],
         [190.381],
         [197.045],
         [174.042],
         [168.810],
         [182.349],
         [189.650],
         [166.639]],

        [[200.884],
         [188.572],
         [175.509],
         [200.832],
         [183.400],
         [181.625],
         [175.907],
         [147.857],
         [170.203],
         [171.564]],

        [[197.590],
         [170.170],
         [179.873],
         [186.714],
         [183.515],
         [164.278],
         [188.194],
         [182.838],
         [194.119],
         [171.794]],

        [[187.551],
         [145.115],
         [203.718],
         [176.872],
         [182.238],
         [188.634],
         [161.505],
         [159.597],
         [211.432],
         [175.828]],

        [[161.497],
         [195.878],
         [173.894],
         [179.503],
         [170.809],
         [160.743],
         [187.536],
         [186.172],
         [193.158],
         [193.380]],

        [[176.788],
         [169.000],
         [181.664],
         [164.120],
         [200.070],
         [195.958],
         [165.984],
         [171.505],
         [180.106],
         [193.487]],

        [[185.461],
         [208.116],
         [190.564],
         [188.839],
         [178.348],
         [165.829],
         [177.140],
         [178.259],
         [190.556],
         [183.932]],

        [[197.134],
         [192.464],
         [143.754],
         [195.383],
         [181.250],
         [201.810],
         [176.956],
         [189.471],
         [165.746],
         [168.615]],

        [[204.161],
         [200.545],
         [169.330],
         [145.742],
         [178.980],
         [147.552],
         [175.067],
         [168.783],
         [182.484],
         [183.341]],

        [[145.528],
         [152.951],
         [196.628],
         [192.097],
         [186.522],
         [203.665],
         [167.178],
         [182.413],
         [143.800],
         [181.766]],

        [[193.390],
         [182.333],
         [197.931],
         [185.792],
         [180.835],
         [193.929],
         [184.443],
         [165.339],
         [181.965],
         [200.318]],

        [[186.540],
         [184.382],
         [182.283],
         [190.207],
         [188.866],
         [165.770],
         [171.322],
         [177.864],
         [191.197],
         [185.833]],

        [[182.405],
         [183.700],
         [192.671],
         [186.005],
         [172.267],
         [188.073],
         [184.790],
         [167.701],
         [180.028],
         [192.583]],

        [[135.393],
         [150.080],
         [175.022],
         [168.339],
         [156.809],
         [173.133],
         [169.526],
         [136.393],
         [196.393],
         [187.055]],

        [[174.444],
         [198.880],
         [157.801],
         [183.828],
         [178.886],
         [144.597],
         [171.997],
         [200.887],
         [162.977],
         [180.854]],

        [[160.357],
         [157.900],
         [178.074],
         [156.214],
         [179.002],
         [194.795],
         [203.501],
         [172.460],
         [155.510],
         [172.785]],

        [[181.006],
         [187.156],
         [186.428],
         [186.398],
         [181.590],
         [170.943],
         [129.275],
         [187.537],
         [157.476],
         [184.794]],

        [[157.262],
         [154.651],
         [192.017],
         [202.079],
         [167.189],
         [159.721],
         [197.600],
         [189.047],
         [181.360],
         [169.108]],

        [[178.853],
         [183.268],
         [163.357],
         [171.185],
         [184.187],
         [193.277],
         [180.429],
         [172.489],
         [193.818],
         [157.685]],

        [[169.700],
         [187.225],
         [183.101],
         [186.417],
         [191.476],
         [191.499],
         [173.846],
         [198.243],
         [207.267],
         [176.745]],

        [[188.696],
         [178.455],
         [144.146],
         [197.003],
         [192.334],
         [170.709],
         [169.723],
         [207.122],
         [193.501],
         [144.984]]], device='cuda:0')
clipping threshold 2.0608825993151707
a after update for 1 param tensor([[-0.152],
        [-0.587],
        [-0.280],
        [-0.540],
        [ 0.167],
        [-1.181],
        [ 0.267],
        [-0.877],
        [-0.129],
        [ 0.325],
        [-0.434],
        [-0.276],
        [ 0.839],
        [ 0.336],
        [-1.082],
        [ 0.396],
        [-0.529],
        [-0.423],
        [-0.428],
        [-0.410],
        [-1.223],
        [-0.233],
        [ 0.271],
        [ 0.045],
        [ 1.526],
        [-0.262],
        [ 0.720],
        [-1.036],
        [ 0.058],
        [-0.214]], device='cuda:0')
s after update for 1 param tensor([[1.790],
        [1.922],
        [1.376],
        [2.266],
        [1.987],
        [1.552],
        [2.122],
        [2.009],
        [2.016],
        [1.376],
        [1.771],
        [1.752],
        [1.537],
        [1.569],
        [1.511],
        [1.966],
        [1.981],
        [1.294],
        [1.744],
        [1.363],
        [2.507],
        [1.379],
        [1.336],
        [2.404],
        [1.989],
        [1.569],
        [1.811],
        [1.198],
        [1.423],
        [2.216]], device='cuda:0')
b after update for 1 param tensor([[178.835],
        [185.277],
        [156.807],
        [201.221],
        [188.424],
        [166.533],
        [194.702],
        [189.455],
        [189.766],
        [156.801],
        [177.893],
        [176.928],
        [165.692],
        [167.418],
        [164.318],
        [187.419],
        [188.109],
        [152.071],
        [176.530],
        [156.061],
        [211.635],
        [156.974],
        [154.512],
        [207.226],
        [188.482],
        [167.397],
        [179.853],
        [146.315],
        [159.450],
        [198.949]], device='cuda:0')
clipping threshold 2.0608825993151707
||w||^2 8.250691989500021
exp ma of ||w||^2 5.970179787454524
||w|| 2.8724017806532602
exp ma of ||w|| 2.4060972389266255
||w||^2 6.36705843384612
exp ma of ||w||^2 5.336718408113404
||w|| 2.5233030800611567
exp ma of ||w|| 2.266462386868148
||w||^2 7.0107636840618115
exp ma of ||w||^2 5.931018623404939
||w|| 2.6477846747917044
exp ma of ||w|| 2.4100906882491118
||w||^2 6.258883988669284
exp ma of ||w||^2 6.447771588709889
||w|| 2.5017761667801706
exp ma of ||w|| 2.5168388519887372
||w||^2 6.22407031468402
exp ma of ||w||^2 6.261412930737411
||w|| 2.49480867296152
exp ma of ||w|| 2.4781458920496076
||w||^2 6.37143878733963
exp ma of ||w||^2 6.853832688489975
||w|| 2.524170910881359
exp ma of ||w|| 2.5989385154581695
||w||^2 6.635111533727795
exp ma of ||w||^2 7.28796171122527
||w|| 2.575871024280485
exp ma of ||w|| 2.682183003305836
||w||^2 7.150612569710511
exp ma of ||w||^2 8.395436093886989
||w|| 2.674062933012331
exp ma of ||w|| 2.881145270074094
cuda
Objective function 99.46 = squared loss an data 52.21 + 0.5*rho*h**2 26.411225 + alpha*h 17.631914 + L2reg 2.87 + L1reg 0.34 ; SHD = 160 ; DAG True
Proportion of microbatches that were clipped  0.7811823213283068
iteration 2 in inner loop, alpha 767.1674915164526 rho 100000.0 h 0.02298313514614847
iteration 4 in outer loop, alpha = 23750.30263766492, rho = 1000000.0, h = 0.02298313514614847
Threshold 0.3
[[0.005 0.046 0.129 0.146 0.112 0.126 0.09  0.032 0.056 0.068 0.018 0.044
  0.278 0.04  0.054 0.043 0.135 0.144 0.861 0.264 0.122 0.026 0.133 0.195
  0.031 0.032 0.043 0.029 0.093 0.057]
 [0.165 0.004 0.18  0.259 0.04  0.263 0.275 0.031 0.051 0.109 0.031 0.044
  0.211 0.078 0.056 0.076 0.364 0.224 0.47  0.148 0.449 0.094 0.258 0.294
  0.065 0.11  0.03  0.021 0.26  0.056]
 [0.037 0.038 0.007 0.042 0.028 0.046 0.029 0.01  0.02  0.013 0.007 0.037
  0.113 0.007 0.027 0.041 0.031 0.047 0.115 0.043 0.075 0.022 0.069 0.046
  0.016 0.013 0.026 0.016 0.045 0.007]
 [0.04  0.018 0.114 0.006 0.058 0.099 0.054 0.015 0.045 0.037 0.005 0.02
  0.117 0.025 0.016 0.021 0.17  0.095 0.547 0.083 0.085 0.025 0.167 0.136
  0.022 0.023 0.021 0.01  0.059 0.021]
 [0.066 0.125 0.256 0.133 0.006 0.113 0.07  0.015 0.077 0.049 0.019 0.069
  0.184 0.168 0.085 0.074 0.236 0.072 0.342 0.381 0.145 0.054 0.25  0.256
  0.064 0.089 0.02  0.04  0.141 0.069]
 [0.055 0.022 0.129 0.107 0.056 0.006 0.051 0.005 0.033 0.056 0.012 0.02
  0.062 0.08  0.063 0.06  0.193 0.105 0.363 0.18  0.137 0.044 0.238 0.129
  0.061 0.02  0.022 0.009 0.13  0.067]
 [0.093 0.03  0.259 0.128 0.079 0.118 0.005 0.017 0.028 0.047 0.011 0.067
  0.183 0.061 0.059 0.046 0.208 0.185 0.343 0.117 0.095 0.049 0.148 0.285
  0.056 0.048 0.033 0.025 0.112 0.013]
 [0.272 0.279 0.844 0.43  0.299 0.846 0.437 0.004 0.123 0.187 0.019 0.258
  0.29  0.368 0.125 0.221 0.537 0.619 0.759 0.296 0.378 0.228 0.443 0.485
  0.261 0.139 0.076 0.059 0.321 0.287]
 [0.185 0.099 0.298 0.169 0.11  0.183 0.225 0.063 0.005 0.23  0.011 0.067
  0.525 0.175 0.072 0.137 0.369 0.084 0.363 0.349 0.264 0.04  0.309 0.255
  0.063 0.092 0.053 0.022 0.148 0.098]
 [0.089 0.051 0.419 0.223 0.175 0.141 0.107 0.032 0.043 0.006 0.005 0.1
  0.353 0.68  0.06  0.134 0.277 0.17  0.429 0.342 0.208 0.071 0.308 0.288
  0.028 0.031 0.065 0.018 0.178 0.06 ]
 [0.413 0.322 0.617 0.964 0.516 0.506 0.467 0.317 0.323 1.322 0.007 0.511
  0.498 0.851 0.275 0.519 0.642 0.305 0.957 0.677 0.49  0.397 0.879 0.713
  0.247 0.467 0.16  0.107 0.472 0.327]
 [0.141 0.169 0.149 0.321 0.09  0.401 0.095 0.017 0.06  0.065 0.01  0.004
  0.401 0.056 0.07  0.093 0.253 0.536 0.325 0.178 0.459 0.102 0.459 0.226
  0.049 0.115 0.081 0.015 0.099 0.1  ]
 [0.033 0.017 0.056 0.055 0.073 0.098 0.039 0.014 0.011 0.018 0.009 0.023
  0.007 0.024 0.011 0.023 0.043 0.091 0.231 0.066 0.107 0.01  0.073 0.101
  0.018 0.02  0.01  0.016 0.023 0.027]
 [0.136 0.074 0.698 0.231 0.036 0.07  0.093 0.014 0.042 0.014 0.006 0.185
  0.23  0.003 0.054 0.324 0.136 0.179 0.588 0.29  0.19  0.032 0.139 0.167
  0.024 0.016 0.023 0.027 0.156 0.065]
 [0.126 0.092 0.256 0.345 0.091 0.156 0.115 0.038 0.105 0.094 0.016 0.089
  0.275 0.158 0.004 0.275 0.286 0.277 0.789 0.249 0.248 0.08  0.267 0.231
  0.072 0.069 0.026 0.103 0.259 0.074]
 [0.192 0.071 0.166 0.267 0.07  0.067 0.104 0.026 0.033 0.04  0.011 0.049
  0.312 0.03  0.023 0.004 0.274 0.06  0.372 0.155 0.359 0.078 0.128 0.243
  0.033 0.049 0.026 0.033 0.162 0.034]
 [0.059 0.016 0.167 0.025 0.035 0.053 0.033 0.008 0.015 0.024 0.007 0.038
  0.152 0.045 0.016 0.028 0.006 0.088 0.45  0.044 0.072 0.018 0.148 0.117
  0.013 0.024 0.013 0.02  0.093 0.031]
 [0.042 0.046 0.072 0.075 0.057 0.061 0.043 0.006 0.075 0.044 0.017 0.011
  0.088 0.034 0.035 0.102 0.082 0.007 0.249 0.185 0.071 0.026 0.064 0.149
  0.032 0.025 0.008 0.013 0.147 0.055]
 [0.006 0.011 0.064 0.016 0.026 0.015 0.019 0.009 0.011 0.018 0.005 0.016
  0.022 0.01  0.005 0.011 0.018 0.022 0.005 0.025 0.024 0.011 0.038 0.018
  0.009 0.014 0.004 0.004 0.01  0.014]
 [0.019 0.041 0.144 0.084 0.031 0.032 0.051 0.019 0.018 0.02  0.008 0.041
  0.096 0.031 0.036 0.043 0.142 0.034 0.278 0.007 0.134 0.01  0.074 0.21
  0.024 0.014 0.013 0.012 0.062 0.021]
 [0.072 0.014 0.14  0.074 0.028 0.05  0.057 0.014 0.032 0.021 0.016 0.013
  0.063 0.027 0.03  0.023 0.09  0.075 0.26  0.043 0.004 0.022 0.048 0.067
  0.019 0.024 0.01  0.019 0.137 0.037]
 [0.304 0.091 0.152 0.217 0.203 0.134 0.172 0.014 0.197 0.095 0.021 0.067
  0.458 0.164 0.08  0.08  0.37  0.181 0.649 0.456 0.286 0.005 0.328 0.368
  0.043 0.069 0.035 0.021 0.281 0.081]
 [0.039 0.019 0.091 0.059 0.032 0.024 0.036 0.008 0.022 0.022 0.004 0.009
  0.157 0.033 0.028 0.045 0.035 0.086 0.167 0.076 0.121 0.022 0.007 0.104
  0.025 0.016 0.007 0.013 0.077 0.024]
 [0.055 0.022 0.118 0.059 0.02  0.063 0.016 0.006 0.029 0.019 0.007 0.029
  0.073 0.03  0.028 0.031 0.042 0.058 0.472 0.026 0.074 0.02  0.054 0.004
  0.043 0.022 0.02  0.009 0.049 0.014]
 [0.261 0.125 0.438 0.322 0.085 0.13  0.098 0.025 0.127 0.329 0.029 0.179
  0.341 0.135 0.077 0.282 0.328 0.234 0.594 0.197 0.272 0.186 0.217 0.165
  0.004 0.044 0.038 0.031 0.215 0.123]
 [0.205 0.053 0.38  0.399 0.041 0.388 0.083 0.045 0.076 0.329 0.019 0.08
  0.3   0.199 0.095 0.134 0.364 0.25  0.43  0.497 0.233 0.105 0.346 0.323
  0.125 0.006 0.061 0.027 0.291 0.099]
 [0.173 0.214 0.223 0.241 0.311 0.244 0.183 0.065 0.119 0.085 0.026 0.109
  0.558 0.133 0.195 0.199 0.52  0.655 1.18  0.42  0.6   0.308 1.097 0.316
  0.14  0.115 0.007 0.04  0.359 0.156]
 [0.348 0.339 0.267 0.609 0.205 0.477 0.181 0.105 0.195 0.272 0.064 0.541
  0.464 0.241 0.08  0.198 0.448 0.506 0.649 0.566 0.254 0.306 0.625 0.61
  0.167 0.268 0.202 0.004 0.336 0.245]
 [0.064 0.016 0.15  0.096 0.053 0.051 0.088 0.017 0.029 0.034 0.007 0.047
  0.172 0.051 0.03  0.041 0.064 0.052 0.47  0.105 0.063 0.026 0.09  0.159
  0.028 0.033 0.018 0.019 0.005 0.032]
 [0.139 0.135 0.399 0.282 0.099 0.083 0.574 0.03  0.061 0.114 0.019 0.065
  0.315 0.121 0.093 0.179 0.203 0.137 0.563 0.27  0.2   0.09  0.304 0.421
  0.072 0.061 0.046 0.031 0.244 0.004]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.861 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.364 0.    0.47  0.    0.449 0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.547 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.342 0.381 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.363 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.343 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.844 0.43  0.    0.846 0.437 0.    0.    0.    0.    0.
  0.    0.368 0.    0.    0.537 0.619 0.759 0.    0.378 0.    0.443 0.485
  0.    0.    0.    0.    0.321 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.525 0.    0.    0.    0.369 0.    0.363 0.349 0.    0.    0.309 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.419 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.353 0.68  0.    0.    0.    0.    0.429 0.342 0.    0.    0.308 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.413 0.322 0.617 0.964 0.516 0.506 0.467 0.317 0.323 1.322 0.    0.511
  0.498 0.851 0.    0.519 0.642 0.305 0.957 0.677 0.49  0.397 0.879 0.713
  0.    0.467 0.    0.    0.472 0.327]
 [0.    0.    0.    0.321 0.    0.401 0.    0.    0.    0.    0.    0.
  0.401 0.    0.    0.    0.    0.536 0.325 0.    0.459 0.    0.459 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.698 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.324 0.    0.    0.588 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.345 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.789 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.312 0.    0.    0.    0.    0.    0.372 0.    0.359 0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.45  0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.304 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.458 0.    0.    0.    0.37  0.    0.649 0.456 0.    0.    0.328 0.368
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.472 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.438 0.322 0.    0.    0.    0.    0.    0.329 0.    0.
  0.341 0.    0.    0.    0.328 0.    0.594 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.38  0.399 0.    0.388 0.    0.    0.    0.329 0.    0.
  0.    0.    0.    0.    0.364 0.    0.43  0.497 0.    0.    0.346 0.323
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.311 0.    0.    0.    0.    0.    0.    0.
  0.558 0.    0.    0.    0.52  0.655 1.18  0.42  0.6   0.308 1.097 0.316
  0.    0.    0.    0.    0.359 0.   ]
 [0.348 0.339 0.    0.609 0.    0.477 0.    0.    0.    0.    0.    0.541
  0.464 0.    0.    0.    0.448 0.506 0.649 0.566 0.    0.306 0.625 0.61
  0.    0.    0.    0.    0.336 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.47  0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.399 0.    0.    0.    0.574 0.    0.    0.    0.    0.
  0.315 0.    0.    0.    0.    0.    0.563 0.    0.    0.    0.304 0.421
  0.    0.    0.    0.    0.    0.   ]]
{'fdr': 0.7890625, 'tpr': 0.3, 'fpr': 0.2927536231884058, 'f1': 0.24770642201834858, 'shd': 160, 'npred': 128, 'ntrue': 90}
[0.046 0.129 0.146 0.112 0.126 0.09  0.032 0.056 0.068 0.018 0.044 0.278
 0.04  0.054 0.043 0.135 0.144 0.861 0.264 0.122 0.026 0.133 0.195 0.031
 0.032 0.043 0.029 0.093 0.057 0.165 0.18  0.259 0.04  0.263 0.275 0.031
 0.051 0.109 0.031 0.044 0.211 0.078 0.056 0.076 0.364 0.224 0.47  0.148
 0.449 0.094 0.258 0.294 0.065 0.11  0.03  0.021 0.26  0.056 0.037 0.038
 0.042 0.028 0.046 0.029 0.01  0.02  0.013 0.007 0.037 0.113 0.007 0.027
 0.041 0.031 0.047 0.115 0.043 0.075 0.022 0.069 0.046 0.016 0.013 0.026
 0.016 0.045 0.007 0.04  0.018 0.114 0.058 0.099 0.054 0.015 0.045 0.037
 0.005 0.02  0.117 0.025 0.016 0.021 0.17  0.095 0.547 0.083 0.085 0.025
 0.167 0.136 0.022 0.023 0.021 0.01  0.059 0.021 0.066 0.125 0.256 0.133
 0.113 0.07  0.015 0.077 0.049 0.019 0.069 0.184 0.168 0.085 0.074 0.236
 0.072 0.342 0.381 0.145 0.054 0.25  0.256 0.064 0.089 0.02  0.04  0.141
 0.069 0.055 0.022 0.129 0.107 0.056 0.051 0.005 0.033 0.056 0.012 0.02
 0.062 0.08  0.063 0.06  0.193 0.105 0.363 0.18  0.137 0.044 0.238 0.129
 0.061 0.02  0.022 0.009 0.13  0.067 0.093 0.03  0.259 0.128 0.079 0.118
 0.017 0.028 0.047 0.011 0.067 0.183 0.061 0.059 0.046 0.208 0.185 0.343
 0.117 0.095 0.049 0.148 0.285 0.056 0.048 0.033 0.025 0.112 0.013 0.272
 0.279 0.844 0.43  0.299 0.846 0.437 0.123 0.187 0.019 0.258 0.29  0.368
 0.125 0.221 0.537 0.619 0.759 0.296 0.378 0.228 0.443 0.485 0.261 0.139
 0.076 0.059 0.321 0.287 0.185 0.099 0.298 0.169 0.11  0.183 0.225 0.063
 0.23  0.011 0.067 0.525 0.175 0.072 0.137 0.369 0.084 0.363 0.349 0.264
 0.04  0.309 0.255 0.063 0.092 0.053 0.022 0.148 0.098 0.089 0.051 0.419
 0.223 0.175 0.141 0.107 0.032 0.043 0.005 0.1   0.353 0.68  0.06  0.134
 0.277 0.17  0.429 0.342 0.208 0.071 0.308 0.288 0.028 0.031 0.065 0.018
 0.178 0.06  0.413 0.322 0.617 0.964 0.516 0.506 0.467 0.317 0.323 1.322
 0.511 0.498 0.851 0.275 0.519 0.642 0.305 0.957 0.677 0.49  0.397 0.879
 0.713 0.247 0.467 0.16  0.107 0.472 0.327 0.141 0.169 0.149 0.321 0.09
 0.401 0.095 0.017 0.06  0.065 0.01  0.401 0.056 0.07  0.093 0.253 0.536
 0.325 0.178 0.459 0.102 0.459 0.226 0.049 0.115 0.081 0.015 0.099 0.1
 0.033 0.017 0.056 0.055 0.073 0.098 0.039 0.014 0.011 0.018 0.009 0.023
 0.024 0.011 0.023 0.043 0.091 0.231 0.066 0.107 0.01  0.073 0.101 0.018
 0.02  0.01  0.016 0.023 0.027 0.136 0.074 0.698 0.231 0.036 0.07  0.093
 0.014 0.042 0.014 0.006 0.185 0.23  0.054 0.324 0.136 0.179 0.588 0.29
 0.19  0.032 0.139 0.167 0.024 0.016 0.023 0.027 0.156 0.065 0.126 0.092
 0.256 0.345 0.091 0.156 0.115 0.038 0.105 0.094 0.016 0.089 0.275 0.158
 0.275 0.286 0.277 0.789 0.249 0.248 0.08  0.267 0.231 0.072 0.069 0.026
 0.103 0.259 0.074 0.192 0.071 0.166 0.267 0.07  0.067 0.104 0.026 0.033
 0.04  0.011 0.049 0.312 0.03  0.023 0.274 0.06  0.372 0.155 0.359 0.078
 0.128 0.243 0.033 0.049 0.026 0.033 0.162 0.034 0.059 0.016 0.167 0.025
 0.035 0.053 0.033 0.008 0.015 0.024 0.007 0.038 0.152 0.045 0.016 0.028
 0.088 0.45  0.044 0.072 0.018 0.148 0.117 0.013 0.024 0.013 0.02  0.093
 0.031 0.042 0.046 0.072 0.075 0.057 0.061 0.043 0.006 0.075 0.044 0.017
 0.011 0.088 0.034 0.035 0.102 0.082 0.249 0.185 0.071 0.026 0.064 0.149
 0.032 0.025 0.008 0.013 0.147 0.055 0.006 0.011 0.064 0.016 0.026 0.015
 0.019 0.009 0.011 0.018 0.005 0.016 0.022 0.01  0.005 0.011 0.018 0.022
 0.025 0.024 0.011 0.038 0.018 0.009 0.014 0.004 0.004 0.01  0.014 0.019
 0.041 0.144 0.084 0.031 0.032 0.051 0.019 0.018 0.02  0.008 0.041 0.096
 0.031 0.036 0.043 0.142 0.034 0.278 0.134 0.01  0.074 0.21  0.024 0.014
 0.013 0.012 0.062 0.021 0.072 0.014 0.14  0.074 0.028 0.05  0.057 0.014
 0.032 0.021 0.016 0.013 0.063 0.027 0.03  0.023 0.09  0.075 0.26  0.043
 0.022 0.048 0.067 0.019 0.024 0.01  0.019 0.137 0.037 0.304 0.091 0.152
 0.217 0.203 0.134 0.172 0.014 0.197 0.095 0.021 0.067 0.458 0.164 0.08
 0.08  0.37  0.181 0.649 0.456 0.286 0.328 0.368 0.043 0.069 0.035 0.021
 0.281 0.081 0.039 0.019 0.091 0.059 0.032 0.024 0.036 0.008 0.022 0.022
 0.004 0.009 0.157 0.033 0.028 0.045 0.035 0.086 0.167 0.076 0.121 0.022
 0.104 0.025 0.016 0.007 0.013 0.077 0.024 0.055 0.022 0.118 0.059 0.02
 0.063 0.016 0.006 0.029 0.019 0.007 0.029 0.073 0.03  0.028 0.031 0.042
 0.058 0.472 0.026 0.074 0.02  0.054 0.043 0.022 0.02  0.009 0.049 0.014
 0.261 0.125 0.438 0.322 0.085 0.13  0.098 0.025 0.127 0.329 0.029 0.179
 0.341 0.135 0.077 0.282 0.328 0.234 0.594 0.197 0.272 0.186 0.217 0.165
 0.044 0.038 0.031 0.215 0.123 0.205 0.053 0.38  0.399 0.041 0.388 0.083
 0.045 0.076 0.329 0.019 0.08  0.3   0.199 0.095 0.134 0.364 0.25  0.43
 0.497 0.233 0.105 0.346 0.323 0.125 0.061 0.027 0.291 0.099 0.173 0.214
 0.223 0.241 0.311 0.244 0.183 0.065 0.119 0.085 0.026 0.109 0.558 0.133
 0.195 0.199 0.52  0.655 1.18  0.42  0.6   0.308 1.097 0.316 0.14  0.115
 0.04  0.359 0.156 0.348 0.339 0.267 0.609 0.205 0.477 0.181 0.105 0.195
 0.272 0.064 0.541 0.464 0.241 0.08  0.198 0.448 0.506 0.649 0.566 0.254
 0.306 0.625 0.61  0.167 0.268 0.202 0.336 0.245 0.064 0.016 0.15  0.096
 0.053 0.051 0.088 0.017 0.029 0.034 0.007 0.047 0.172 0.051 0.03  0.041
 0.064 0.052 0.47  0.105 0.063 0.026 0.09  0.159 0.028 0.033 0.018 0.019
 0.032 0.139 0.135 0.399 0.282 0.099 0.083 0.574 0.03  0.061 0.114 0.019
 0.065 0.315 0.121 0.093 0.179 0.203 0.137 0.563 0.27  0.2   0.09  0.304
 0.421 0.072 0.061 0.046 0.031 0.244]
[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 1. 0. 0. 1. 0.]
 [1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
  0. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 0. 1. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0.]
aucroc, aucpr (0.650868945868946, 0.21799404827119367)
Iterations 2250
Achieves (5.825547298234785, 1e-05)-DP
