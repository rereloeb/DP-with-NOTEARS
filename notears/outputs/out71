samples  5000  graph  15 30 ER mlp  minibatch size  100  noise  0.5  minibatches per NN training  63 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.3401316691164595
iteration 1 in outer loop, alpha = 1.3401316691164595, rho = 1.0, h = 1.3401316691164595
cuda
iteration 1 in inner loop,alpha 1.3401316691164595 rho 1.0 h 0.8741315174292428
iteration 2 in inner loop,alpha 1.3401316691164595 rho 10.0 h 0.38347274229216843
iteration 3 in inner loop,alpha 1.3401316691164595 rho 100.0 h 0.13357487921889089
iteration 2 in outer loop, alpha = 14.697619591005548, rho = 100.0, h = 0.13357487921889089
cuda
iteration 1 in inner loop,alpha 14.697619591005548 rho 100.0 h 0.0699292469565016
iteration 2 in inner loop,alpha 14.697619591005548 rho 1000.0 h 0.026161639587870766
iteration 3 in outer loop, alpha = 40.859259178876314, rho = 1000.0, h = 0.026161639587870766
cuda
iteration 1 in inner loop,alpha 40.859259178876314 rho 1000.0 h 0.016216779441247553
iteration 2 in inner loop,alpha 40.859259178876314 rho 10000.0 h 0.006600539849799247
iteration 3 in inner loop,alpha 40.859259178876314 rho 100000.0 h 0.0012858846152354886
iteration 4 in outer loop, alpha = 169.44772070242516, rho = 100000.0, h = 0.0012858846152354886
cuda
iteration 1 in inner loop,alpha 169.44772070242516 rho 100000.0 h 0.00029719191308785753
iteration 5 in outer loop, alpha = 199.1669120112109, rho = 100000.0, h = 0.00029719191308785753
cuda
iteration 1 in inner loop,alpha 199.1669120112109 rho 100000.0 h 0.00014458178339182837
iteration 6 in outer loop, alpha = 343.7486954030393, rho = 1000000.0, h = 0.00014458178339182837
Threshold 0.3
[[0.002 0.    0.    0.004 0.139 0.    0.    0.    0.    2.71  0.234 0.
  0.    0.    0.004]
 [2.533 0.001 0.002 0.267 0.157 0.012 0.009 0.001 0.001 2.201 0.248 1.357
  0.    0.001 0.098]
 [0.051 0.072 0.001 0.141 0.143 0.039 0.124 0.001 0.068 0.144 0.143 0.156
  0.004 0.003 0.004]
 [0.149 0.    0.001 0.001 0.18  0.    0.001 0.    0.    0.244 0.419 0.001
  0.    0.    1.022]
 [0.    0.    0.    0.    0.004 0.    0.    0.    0.    0.    0.001 0.
  0.    0.    0.001]
 [2.656 0.029 0.001 0.977 0.313 0.001 1.34  0.    0.051 1.735 1.222 1.484
  0.012 0.001 1.92 ]
 [0.411 0.044 0.    0.338 0.262 0.    0.001 0.    0.056 0.201 1.541 0.091
  0.002 0.002 0.162]
 [2.688 0.003 0.003 2.082 0.152 0.579 0.045 0.    0.007 0.347 0.175 0.06
  0.02  0.023 0.121]
 [0.087 0.377 0.002 0.647 0.517 0.002 0.001 0.002 0.003 2.279 2.03  1.056
  0.    0.    0.368]
 [0.    0.    0.001 0.001 2.791 0.    0.    0.    0.    0.002 0.403 0.
  0.    0.    0.002]
 [0.    0.    0.    0.001 3.309 0.    0.001 0.    0.001 0.001 0.009 0.
  0.    0.    0.002]
 [0.362 0.    0.    0.187 0.116 0.    0.004 0.    0.001 0.446 0.536 0.001
  0.    0.001 0.035]
 [0.041 0.073 0.004 0.106 3.224 0.016 0.006 0.002 1.112 0.118 1.813 0.031
  0.001 0.016 0.016]
 [0.125 1.424 0.002 1.113 1.207 0.006 0.007 0.    3.433 0.367 0.481 0.156
  0.012 0.002 0.563]
 [0.102 0.    0.    0.    0.101 0.    0.    0.    0.    0.12  0.119 0.002
  0.    0.    0.001]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    2.71  0.    0.
  0.    0.    0.   ]
 [2.533 0.    0.    0.    0.    0.    0.    0.    0.    2.201 0.    1.357
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.419 0.
  0.    0.    1.022]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [2.656 0.    0.    0.977 0.313 0.    1.34  0.    0.    1.735 1.222 1.484
  0.    0.    1.92 ]
 [0.411 0.    0.    0.338 0.    0.    0.    0.    0.    0.    1.541 0.
  0.    0.    0.   ]
 [2.688 0.    0.    2.082 0.    0.579 0.    0.    0.    0.347 0.    0.
  0.    0.    0.   ]
 [0.    0.377 0.    0.647 0.517 0.    0.    0.    0.    2.279 2.03  1.056
  0.    0.    0.368]
 [0.    0.    0.    0.    2.791 0.    0.    0.    0.    0.    0.403 0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    3.309 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.362 0.    0.    0.    0.    0.    0.    0.    0.    0.446 0.536 0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    3.224 0.    0.    0.    1.112 0.    1.813 0.
  0.    0.    0.   ]
 [0.    1.424 0.    1.113 1.207 0.    0.    0.    3.433 0.367 0.481 0.
  0.    0.    0.563]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]]
{'fdr': 0.3409090909090909, 'tpr': 0.9666666666666667, 'fpr': 0.2, 'f1': 0.7837837837837838, 'shd': 16, 'npred': 44, 'ntrue': 30}
[5.894e-05 1.536e-04 4.407e-03 1.390e-01 5.819e-05 1.131e-04 3.940e-05
 2.214e-04 2.710e+00 2.344e-01 4.983e-04 1.693e-04 1.021e-04 3.945e-03
 2.533e+00 2.150e-03 2.667e-01 1.569e-01 1.150e-02 9.185e-03 7.204e-04
 1.411e-03 2.201e+00 2.475e-01 1.357e+00 4.703e-04 7.863e-04 9.833e-02
 5.112e-02 7.180e-02 1.409e-01 1.430e-01 3.897e-02 1.238e-01 8.844e-04
 6.796e-02 1.441e-01 1.433e-01 1.560e-01 4.067e-03 3.399e-03 4.008e-03
 1.488e-01 3.111e-04 7.405e-04 1.800e-01 2.359e-05 1.082e-03 4.282e-05
 1.406e-04 2.444e-01 4.186e-01 9.372e-04 6.479e-05 1.077e-04 1.022e+00
 5.199e-05 4.130e-06 1.575e-05 1.471e-04 9.771e-06 9.727e-05 4.775e-06
 1.511e-04 3.123e-04 8.062e-04 4.027e-05 2.089e-05 5.822e-05 6.525e-04
 2.656e+00 2.913e-02 5.121e-04 9.771e-01 3.132e-01 1.340e+00 1.625e-04
 5.108e-02 1.735e+00 1.222e+00 1.484e+00 1.187e-02 1.089e-03 1.920e+00
 4.114e-01 4.390e-02 1.235e-04 3.381e-01 2.619e-01 2.436e-04 8.573e-05
 5.566e-02 2.006e-01 1.541e+00 9.059e-02 2.194e-03 1.942e-03 1.624e-01
 2.688e+00 3.185e-03 3.348e-03 2.082e+00 1.520e-01 5.794e-01 4.454e-02
 7.237e-03 3.468e-01 1.745e-01 5.975e-02 2.039e-02 2.278e-02 1.206e-01
 8.705e-02 3.772e-01 1.995e-03 6.470e-01 5.172e-01 2.256e-03 1.315e-03
 1.792e-03 2.279e+00 2.030e+00 1.056e+00 8.051e-05 4.205e-04 3.685e-01
 1.696e-04 4.127e-06 1.016e-03 5.845e-04 2.791e+00 5.958e-06 1.474e-04
 1.074e-05 4.761e-04 4.028e-01 1.481e-04 2.534e-05 9.760e-05 1.604e-03
 3.571e-04 4.917e-05 2.904e-04 6.584e-04 3.309e+00 1.057e-04 6.027e-04
 2.129e-05 6.416e-04 9.216e-04 1.867e-04 1.632e-04 2.028e-04 2.444e-03
 3.620e-01 3.360e-04 7.512e-05 1.874e-01 1.164e-01 2.462e-04 3.634e-03
 8.218e-05 1.404e-03 4.463e-01 5.360e-01 6.850e-05 5.227e-04 3.455e-02
 4.082e-02 7.272e-02 3.583e-03 1.060e-01 3.224e+00 1.557e-02 5.568e-03
 2.009e-03 1.112e+00 1.176e-01 1.813e+00 3.089e-02 1.640e-02 1.639e-02
 1.252e-01 1.424e+00 2.037e-03 1.113e+00 1.207e+00 6.360e-03 7.322e-03
 1.882e-04 3.433e+00 3.674e-01 4.808e-01 1.558e-01 1.177e-02 5.629e-01
 1.016e-01 4.313e-04 1.684e-05 6.667e-05 1.013e-01 1.230e-05 3.484e-04
 1.335e-05 2.851e-04 1.201e-01 1.188e-01 1.657e-03 4.795e-04 7.857e-05]
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.]
 [0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.98, 0.9717590714446698)
cuda
2565
cuda
Objective function 454.76 = squared loss an data 233.99 + 0.5*rho*h**2 220.188202 + alpha*h 0.000000 + L2reg 0.28 + L1reg 0.30 ; SHD = 120 ; DAG False
||w||^2 4781.528405973686
exp ma of ||w||^2 1107630522.4299123
||w|| 69.148596558236
exp ma of ||w|| 1184.2652085957307
||w||^2 2.4920474658866385
exp ma of ||w||^2 9546490.731349612
||w|| 1.5786220148872365
exp ma of ||w|| 13.667948934505555
||w||^2 0.1842623978640739
exp ma of ||w||^2 0.2273053637325801
||w|| 0.42925796191110294
exp ma of ||w|| 0.46615076846740494
||w||^2 0.19882640026682985
exp ma of ||w||^2 0.22187792040197024
||w|| 0.4458995405546297
exp ma of ||w|| 0.4598986328933869
||w||^2 0.22716113359704715
exp ma of ||w||^2 0.2378862023154105
||w|| 0.4766142398177452
exp ma of ||w|| 0.47456704922765536
||w||^2 0.12901829045698734
exp ma of ||w||^2 0.3356046509063207
||w|| 0.3591911614405167
exp ma of ||w|| 0.5377178577917475
cuda
Objective function 47.18 = squared loss an data 45.54 + 0.5*rho*h**2 1.229987 + alpha*h 0.000000 + L2reg 0.27 + L1reg 0.14 ; SHD = 49 ; DAG False
Proportion of microbatches that were clipped  0.7381104372805618
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 1.5684305868255706
iteration 1 in outer loop, alpha = 1.5684305868255706, rho = 1.0, h = 1.5684305868255706
cuda
2565
cuda
Objective function 49.64 = squared loss an data 45.54 + 0.5*rho*h**2 1.229987 + alpha*h 2.459975 + L2reg 0.27 + L1reg 0.14 ; SHD = 49 ; DAG False
||w||^2 165907.481429757
exp ma of ||w||^2 1399804.4267824998
||w|| 407.31742097503883
exp ma of ||w|| 771.0650503315838
||w||^2 19547.75622640634
exp ma of ||w||^2 195658.22928660887
||w|| 139.81329059287012
exp ma of ||w|| 230.23185014408713
||w||^2 134426.59707432057
exp ma of ||w||^2 137347.149129957
||w|| 366.64232853602783
exp ma of ||w|| 186.97509115395906
||w||^2 112.20677070633988
exp ma of ||w||^2 12895.792786280908
||w|| 10.592769737247188
exp ma of ||w|| 41.2538627080881
||w||^2 0.26511321274184163
exp ma of ||w||^2 0.4521158029719474
||w|| 0.5148914572430209
exp ma of ||w|| 0.4892091254420396
||w||^2 0.10990075143674558
exp ma of ||w||^2 0.3994881785083534
||w|| 0.3315128224318715
exp ma of ||w|| 0.5861841219365749
||w||^2 0.1941923784334317
exp ma of ||w||^2 0.429396138287669
||w|| 0.4406726431643241
exp ma of ||w|| 0.6032975024027867
cuda
Objective function 20.48 = squared loss an data 17.76 + 0.5*rho*h**2 0.496345 + alpha*h 1.562688 + L2reg 0.52 + L1reg 0.14 ; SHD = 42 ; DAG False
Proportion of microbatches that were clipped  0.7445563860903477
iteration 1 in inner loop, alpha 1.5684305868255706 rho 1.0 h 0.9963384774548842
2565
cuda
Objective function 24.95 = squared loss an data 17.76 + 0.5*rho*h**2 4.963452 + alpha*h 1.562688 + L2reg 0.52 + L1reg 0.14 ; SHD = 42 ; DAG False
||w||^2 4390617992.344776
exp ma of ||w||^2 17192104399.247776
||w|| 66261.73852491932
exp ma of ||w|| 114064.23284094706
||w||^2 1762714.7596425351
exp ma of ||w||^2 32952406.590420514
||w|| 1327.6726854321194
exp ma of ||w|| 4195.328027440704
||w||^2 0.8859232893917373
exp ma of ||w||^2 6.3365829466877495
||w|| 0.9412349809647628
exp ma of ||w|| 0.8051903175419326
||w||^2 0.45812376511700476
exp ma of ||w||^2 0.5576540285023603
||w|| 0.6768484063045467
exp ma of ||w|| 0.6846486345454176
||w||^2 0.13190505647387657
exp ma of ||w||^2 0.6144164968734972
||w|| 0.3631873572605145
exp ma of ||w|| 0.7215025862745956
||w||^2 0.26445005466164634
exp ma of ||w||^2 0.6303560192840979
||w|| 0.5142470755013064
exp ma of ||w|| 0.7349247868624075
cuda
Objective function 16.16 = squared loss an data 13.87 + 0.5*rho*h**2 0.808911 + alpha*h 0.630856 + L2reg 0.72 + L1reg 0.13 ; SHD = 35 ; DAG True
Proportion of microbatches that were clipped  0.7505093245572795
iteration 2 in inner loop, alpha 1.5684305868255706 rho 10.0 h 0.40222148922578427
2565
cuda
Objective function 23.44 = squared loss an data 13.87 + 0.5*rho*h**2 8.089106 + alpha*h 0.630856 + L2reg 0.72 + L1reg 0.13 ; SHD = 35 ; DAG True
||w||^2 2.0912083647083217
exp ma of ||w||^2 30.13969940688572
||w|| 1.446101090763824
exp ma of ||w|| 1.2417444919542002
||w||^2 0.1043398329746026
exp ma of ||w||^2 0.8084456379154659
||w|| 0.32301676887524366
exp ma of ||w|| 0.8185310263751969
||w||^2 1.7902352548384917
exp ma of ||w||^2 0.9344136777048908
||w|| 1.337996731998435
exp ma of ||w|| 0.8563794301490895
cuda
Objective function 16.25 = squared loss an data 14.38 + 0.5*rho*h**2 0.713230 + alpha*h 0.187325 + L2reg 0.86 + L1reg 0.11 ; SHD = 29 ; DAG True
Proportion of microbatches that were clipped  0.7544628875665519
iteration 3 in inner loop, alpha 1.5684305868255706 rho 100.0 h 0.11943446066213781
iteration 2 in outer loop, alpha = 13.511876653039351, rho = 100.0, h = 0.11943446066213781
cuda
2565
cuda
Objective function 17.68 = squared loss an data 14.38 + 0.5*rho*h**2 0.713230 + alpha*h 1.613784 + L2reg 0.86 + L1reg 0.11 ; SHD = 29 ; DAG True
||w||^2 329980546.6959858
exp ma of ||w||^2 1171685261.5473332
||w|| 18165.36668212304
exp ma of ||w|| 28228.12978472629
||w||^2 2289277.5873853327
exp ma of ||w||^2 14681971.39833265
||w|| 1513.0358843680253
exp ma of ||w|| 2625.030795265631
||w||^2 18.33512532179431
exp ma of ||w||^2 2456.752244556366
||w|| 4.28195344694385
exp ma of ||w|| 8.701822544771556
||w||^2 0.9507182370053532
exp ma of ||w||^2 73.09190189629203
||w|| 0.9750478126765647
exp ma of ||w|| 1.6273372919584714
||w||^2 0.43471072427836366
exp ma of ||w||^2 2.2699324550332656
||w|| 0.6593259620842817
exp ma of ||w|| 0.9436459344985372
||w||^2 0.26897252410385625
exp ma of ||w||^2 1.0688300303159268
||w|| 0.5186256107288342
exp ma of ||w|| 0.9211797757733853
cuda
Objective function 16.58 = squared loss an data 14.24 + 0.5*rho*h**2 0.270155 + alpha*h 0.993201 + L2reg 0.96 + L1reg 0.11 ; SHD = 30 ; DAG True
Proportion of microbatches that were clipped  0.7456910569105691
iteration 1 in inner loop, alpha 13.511876653039351 rho 100.0 h 0.07350577396948665
2565
cuda
Objective function 19.01 = squared loss an data 14.24 + 0.5*rho*h**2 2.701549 + alpha*h 0.993201 + L2reg 0.96 + L1reg 0.11 ; SHD = 30 ; DAG True
||w||^2 141620614404.54813
exp ma of ||w||^2 161077871729.9798
||w|| 376325.14452870155
exp ma of ||w|| 253601.1846603413
||w||^2 7494326435.961303
exp ma of ||w||^2 26823555394.304005
||w|| 86569.77784401033
exp ma of ||w|| 143704.6157078135
||w||^2 82783649.0022456
exp ma of ||w||^2 171406924.21176073
||w|| 9098.552027781432
exp ma of ||w|| 10105.06888317763
||w||^2 26.608323572636188
exp ma of ||w||^2 12430.409270632399
||w|| 5.15832565593102
exp ma of ||w|| 22.891949272537747
||w||^2 10.571706074367603
exp ma of ||w||^2 1799.2869983846456
||w|| 3.2514160106586796
exp ma of ||w|| 6.06460394266164
cuda
Objective function 16.42 = squared loss an data 14.41 + 0.5*rho*h**2 0.457517 + alpha*h 0.408728 + L2reg 1.03 + L1reg 0.11 ; SHD = 26 ; DAG True
Proportion of microbatches that were clipped  0.7568127490039841
iteration 2 in inner loop, alpha 13.511876653039351 rho 1000.0 h 0.030249526064118015
2565
cuda
Objective function 20.54 = squared loss an data 14.41 + 0.5*rho*h**2 4.575169 + alpha*h 0.408728 + L2reg 1.03 + L1reg 0.11 ; SHD = 26 ; DAG True
||w||^2 2089642374.086559
exp ma of ||w||^2 8429024928.928393
||w|| 45712.60629286586
exp ma of ||w|| 72817.62518151801
||w||^2 4737543.565067408
exp ma of ||w||^2 118077050.02083439
||w|| 2176.589893633481
exp ma of ||w|| 7665.91377093736
||w||^2 14262802.916497646
exp ma of ||w||^2 113810470.4985279
||w|| 3776.6126246277427
exp ma of ||w|| 7484.520070520164
||w||^2 0.41013922005639597
exp ma of ||w||^2 1.014499809651882
||w|| 0.640421127115897
exp ma of ||w|| 0.931499411253581
||w||^2 1.5267974841641259
exp ma of ||w||^2 0.8661674909206758
||w|| 1.2356364692595172
exp ma of ||w|| 0.8735506142794651
cuda
Objective function 16.25 = squared loss an data 14.42 + 0.5*rho*h**2 0.468361 + alpha*h 0.130774 + L2reg 1.11 + L1reg 0.11 ; SHD = 24 ; DAG True
Proportion of microbatches that were clipped  0.7540745522026787
iteration 3 in inner loop, alpha 13.511876653039351 rho 10000.0 h 0.009678443936156356
iteration 3 in outer loop, alpha = 110.29631601460291, rho = 10000.0, h = 0.009678443936156356
cuda
2565
cuda
Objective function 17.19 = squared loss an data 14.42 + 0.5*rho*h**2 0.468361 + alpha*h 1.067497 + L2reg 1.11 + L1reg 0.11 ; SHD = 24 ; DAG True
||w||^2 36596225952.132706
exp ma of ||w||^2 493405775280.8844
||w|| 191301.40081069115
exp ma of ||w|| 515197.75315442454
||w||^2 23060528600.544144
exp ma of ||w||^2 107418281407.5055
||w|| 151856.93464752982
exp ma of ||w|| 207591.9474133603
||w||^2 804.2525781065289
exp ma of ||w||^2 260968.65114230238
||w|| 28.359347279275116
exp ma of ||w|| 164.9417944657427
||w||^2 3.1113715670036988
exp ma of ||w||^2 63.735877654209396
||w|| 1.7639080381368237
exp ma of ||w|| 1.6069472649271765
||w||^2 0.7980095693119977
exp ma of ||w||^2 15.850289592263136
||w|| 0.8933138134563898
exp ma of ||w|| 1.3189438155774313
||w||^2 0.36428280177148087
exp ma of ||w||^2 0.9225841106649433
||w|| 0.6035584493414708
exp ma of ||w|| 0.9025883006424495
||w||^2 0.581135113339221
exp ma of ||w||^2 0.7789975500046913
||w|| 0.7623221847350509
exp ma of ||w|| 0.8330912058680753
||w||^2 0.6637376963236626
exp ma of ||w||^2 0.9481198897930603
||w|| 0.8147009858369282
exp ma of ||w|| 0.9024853326899916
||w||^2 0.5772944919582975
exp ma of ||w||^2 0.9770989010913338
||w|| 0.7597989812827453
exp ma of ||w|| 0.8940967402240539
||w||^2 2.1037667835532563
exp ma of ||w||^2 0.8879705929048478
||w|| 1.4504367561370115
exp ma of ||w|| 0.8849247238706718
||w||^2 0.4868694388080762
exp ma of ||w||^2 0.8587497665760054
||w|| 0.6977603018286983
exp ma of ||w|| 0.8736949592119008
cuda
Objective function 16.40 = squared loss an data 14.43 + 0.5*rho*h**2 0.132456 + alpha*h 0.567691 + L2reg 1.16 + L1reg 0.11 ; SHD = 24 ; DAG True
Proportion of microbatches that were clipped  0.7565726955970858
iteration 1 in inner loop, alpha 110.29631601460291 rho 10000.0 h 0.005146960829128133
2565
cuda
Objective function 17.59 = squared loss an data 14.43 + 0.5*rho*h**2 1.324560 + alpha*h 0.567691 + L2reg 1.16 + L1reg 0.11 ; SHD = 24 ; DAG True
||w||^2 6402.336747397677
exp ma of ||w||^2 133939710.52027273
||w|| 80.01460333837616
exp ma of ||w|| 319.82966930813393
||w||^2 2.220752383801738
exp ma of ||w||^2 1335.7054616648543
||w|| 1.4902189046585532
exp ma of ||w|| 1.5259037038516328
||w||^2 0.5936242186420605
exp ma of ||w||^2 0.9881540992375079
||w|| 0.7704701283255961
exp ma of ||w|| 0.9319501204084302
||w||^2 2.1949349520333725
exp ma of ||w||^2 0.9884486402199363
||w|| 1.4815312862148313
exp ma of ||w|| 0.9300715808866613
cuda
Objective function 16.49 = squared loss an data 14.49 + 0.5*rho*h**2 0.369674 + alpha*h 0.299906 + L2reg 1.22 + L1reg 0.11 ; SHD = 23 ; DAG True
Proportion of microbatches that were clipped  0.750284137035233
iteration 2 in inner loop, alpha 110.29631601460291 rho 100000.0 h 0.002719097029071804
iteration 4 in outer loop, alpha = 2829.393345086407, rho = 1000000.0, h = 0.002719097029071804
Threshold 0.3
[[0.003 0.027 0.058 0.234 0.222 0.009 0.023 0.002 0.032 0.905 0.099 0.064
  0.053 0.009 0.052]
 [0.171 0.005 0.238 0.299 0.284 0.131 0.066 0.054 0.205 0.312 0.258 0.978
  0.063 0.003 0.106]
 [0.094 0.022 0.004 0.055 0.327 0.036 0.048 0.023 0.053 0.105 0.089 0.064
  0.044 0.009 0.104]
 [0.033 0.017 0.05  0.005 0.196 0.015 0.015 0.003 0.039 0.182 0.108 0.088
  0.032 0.013 0.215]
 [0.004 0.004 0.014 0.015 0.007 0.003 0.003 0.002 0.004 0.002 0.002 0.019
  0.001 0.002 0.012]
 [0.42  0.03  0.137 0.181 0.541 0.003 0.023 0.035 0.149 0.466 0.477 0.608
  0.059 0.013 0.134]
 [0.173 0.092 0.107 0.366 0.506 0.196 0.003 0.039 0.226 0.152 1.121 0.229
  0.025 0.04  0.066]
 [1.383 0.102 0.174 0.663 0.571 0.089 0.145 0.003 0.204 0.483 0.225 0.271
  0.115 0.015 0.108]
 [0.163 0.019 0.058 0.104 0.42  0.019 0.022 0.028 0.005 0.981 0.841 0.022
  0.028 0.001 0.055]
 [0.007 0.012 0.043 0.033 1.919 0.005 0.019 0.005 0.006 0.007 0.147 0.031
  0.028 0.002 0.039]
 [0.024 0.022 0.045 0.051 1.916 0.011 0.003 0.01  0.005 0.053 0.007 0.038
  0.002 0.003 0.049]
 [0.089 0.004 0.054 0.063 0.233 0.009 0.02  0.018 0.275 0.174 0.157 0.005
  0.026 0.003 0.033]
 [0.102 0.05  0.122 0.109 0.712 0.053 0.104 0.052 0.104 0.164 1.327 0.176
  0.004 0.048 0.202]
 [0.32  1.227 0.273 0.369 0.354 0.37  0.139 0.152 2.14  0.888 0.816 1.3
  0.1   0.005 0.127]
 [0.068 0.032 0.058 0.025 0.355 0.028 0.058 0.024 0.067 0.117 0.105 0.095
  0.015 0.021 0.003]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.905 0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.312 0.    0.978
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.327 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.42  0.    0.    0.    0.541 0.    0.    0.    0.    0.466 0.477 0.608
  0.    0.    0.   ]
 [0.    0.    0.    0.366 0.506 0.    0.    0.    0.    0.    1.121 0.
  0.    0.    0.   ]
 [1.383 0.    0.    0.663 0.571 0.    0.    0.    0.    0.483 0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.42  0.    0.    0.    0.    0.981 0.841 0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    1.919 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    1.916 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.712 0.    0.    0.    0.    0.    1.327 0.
  0.    0.    0.   ]
 [0.32  1.227 0.    0.369 0.354 0.37  0.    0.    2.14  0.888 0.816 1.3
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.355 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]]
{'fdr': 0.3939393939393939, 'tpr': 0.6666666666666666, 'fpr': 0.17333333333333334, 'f1': 0.6349206349206349, 'shd': 23, 'npred': 33, 'ntrue': 30}
[2.732e-02 5.798e-02 2.336e-01 2.220e-01 8.513e-03 2.347e-02 1.914e-03
 3.203e-02 9.054e-01 9.908e-02 6.437e-02 5.326e-02 8.835e-03 5.152e-02
 1.714e-01 2.379e-01 2.987e-01 2.836e-01 1.312e-01 6.593e-02 5.427e-02
 2.055e-01 3.123e-01 2.585e-01 9.778e-01 6.311e-02 2.516e-03 1.058e-01
 9.360e-02 2.241e-02 5.514e-02 3.272e-01 3.624e-02 4.789e-02 2.342e-02
 5.261e-02 1.048e-01 8.908e-02 6.399e-02 4.389e-02 9.446e-03 1.042e-01
 3.311e-02 1.711e-02 4.958e-02 1.962e-01 1.503e-02 1.481e-02 3.334e-03
 3.876e-02 1.816e-01 1.079e-01 8.835e-02 3.203e-02 1.320e-02 2.153e-01
 4.105e-03 4.109e-03 1.369e-02 1.461e-02 2.662e-03 2.606e-03 2.367e-03
 4.241e-03 2.008e-03 1.900e-03 1.862e-02 9.928e-04 2.432e-03 1.198e-02
 4.199e-01 2.994e-02 1.373e-01 1.812e-01 5.406e-01 2.309e-02 3.532e-02
 1.492e-01 4.660e-01 4.767e-01 6.080e-01 5.935e-02 1.325e-02 1.343e-01
 1.726e-01 9.245e-02 1.070e-01 3.664e-01 5.060e-01 1.961e-01 3.884e-02
 2.258e-01 1.518e-01 1.121e+00 2.287e-01 2.545e-02 4.044e-02 6.598e-02
 1.383e+00 1.023e-01 1.736e-01 6.631e-01 5.712e-01 8.876e-02 1.450e-01
 2.041e-01 4.830e-01 2.255e-01 2.713e-01 1.154e-01 1.477e-02 1.083e-01
 1.627e-01 1.950e-02 5.817e-02 1.039e-01 4.196e-01 1.948e-02 2.190e-02
 2.830e-02 9.814e-01 8.407e-01 2.159e-02 2.796e-02 1.476e-03 5.491e-02
 6.719e-03 1.246e-02 4.312e-02 3.336e-02 1.919e+00 5.306e-03 1.886e-02
 4.803e-03 5.961e-03 1.469e-01 3.071e-02 2.785e-02 1.942e-03 3.916e-02
 2.407e-02 2.224e-02 4.499e-02 5.053e-02 1.916e+00 1.129e-02 3.249e-03
 1.027e-02 5.427e-03 5.284e-02 3.796e-02 1.935e-03 3.065e-03 4.894e-02
 8.908e-02 4.049e-03 5.431e-02 6.251e-02 2.332e-01 9.264e-03 1.957e-02
 1.782e-02 2.751e-01 1.737e-01 1.572e-01 2.622e-02 3.080e-03 3.350e-02
 1.021e-01 5.043e-02 1.215e-01 1.087e-01 7.116e-01 5.262e-02 1.044e-01
 5.195e-02 1.039e-01 1.645e-01 1.327e+00 1.759e-01 4.778e-02 2.018e-01
 3.198e-01 1.227e+00 2.731e-01 3.690e-01 3.544e-01 3.699e-01 1.394e-01
 1.521e-01 2.140e+00 8.882e-01 8.158e-01 1.300e+00 1.003e-01 1.266e-01
 6.817e-02 3.176e-02 5.777e-02 2.537e-02 3.552e-01 2.816e-02 5.762e-02
 2.365e-02 6.703e-02 1.172e-01 1.054e-01 9.533e-02 1.542e-02 2.102e-02]
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.]
 [0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.862962962962963, 0.6606854212369005)
Iterations 567
Achieves (22.649084728085, 1e-05)-DP
