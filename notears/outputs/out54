samples  5000  graph  13 26 ER mlp  minibatch size  25  noise  0.5  minibatches per NN training  1000 quantile adaptive clipping
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.3261408551088962
iteration 1 in outer loop, alpha = 1.3261408551088962, rho = 1.0, h = 1.3261408551088962
cuda
iteration 1 in inner loop,alpha 1.3261408551088962 rho 1.0 h 0.8833914671458967
iteration 2 in inner loop,alpha 1.3261408551088962 rho 10.0 h 0.3985408322410535
iteration 3 in inner loop,alpha 1.3261408551088962 rho 100.0 h 0.14495160298766763
iteration 2 in outer loop, alpha = 15.821301153875659, rho = 100.0, h = 0.14495160298766763
cuda
iteration 1 in inner loop,alpha 15.821301153875659 rho 100.0 h 0.09258309915011509
iteration 2 in inner loop,alpha 15.821301153875659 rho 1000.0 h 0.0361757714290718
iteration 3 in outer loop, alpha = 51.99707258294746, rho = 1000.0, h = 0.0361757714290718
cuda
iteration 1 in inner loop,alpha 51.99707258294746 rho 1000.0 h 0.022655508097344068
iteration 2 in inner loop,alpha 51.99707258294746 rho 10000.0 h 0.007171526456872357
iteration 4 in outer loop, alpha = 123.71233715167102, rho = 10000.0, h = 0.007171526456872357
cuda
iteration 1 in inner loop,alpha 123.71233715167102 rho 10000.0 h 0.003795039111576415
iteration 2 in inner loop,alpha 123.71233715167102 rho 100000.0 h 0.0014367259662844134
iteration 5 in outer loop, alpha = 267.38493378011236, rho = 100000.0, h = 0.0014367259662844134
cuda
iteration 1 in inner loop,alpha 267.38493378011236 rho 100000.0 h 0.0007749773161158657
iteration 6 in outer loop, alpha = 1042.362249895978, rho = 1000000.0, h = 0.0007749773161158657
Threshold 0.3
[[0.001 0.    0.181 2.53  0.582 0.001 0.02  0.    0.    0.355 0.    1.892
  0.   ]
 [0.645 0.001 0.307 0.052 0.187 0.002 0.037 0.    0.    2.132 0.005 0.221
  0.   ]
 [0.    0.    0.002 0.    0.    0.    0.001 0.    0.    0.    0.    0.
  0.   ]
 [0.    0.    2.69  0.001 0.09  0.001 0.087 0.    0.    1.603 0.    0.275
  0.   ]
 [0.    0.    0.257 0.    0.001 0.    0.002 0.    0.    0.    0.    0.
  0.   ]
 [0.086 0.038 0.332 0.075 0.506 0.001 0.014 0.    0.11  2.278 0.003 0.125
  0.002]
 [0.01  0.015 1.091 0.026 0.098 0.041 0.027 0.001 0.002 1.064 0.001 0.293
  0.003]
 [0.015 0.01  0.009 0.021 1.431 3.724 0.078 0.001 0.647 0.421 0.005 0.079
  0.005]
 [0.017 1.545 2.238 0.029 0.102 0.004 0.353 0.    0.    1.442 0.003 0.196
  0.023]
 [0.    0.    1.114 0.    0.224 0.    0.001 0.    0.    0.004 0.    2.354
  0.   ]
 [1.745 0.006 2.561 0.076 0.34  0.008 0.011 0.019 0.002 1.006 0.    0.101
  0.003]
 [0.    0.    0.946 0.    0.823 0.    0.001 0.    0.    0.    0.    0.001
  0.   ]
 [0.006 1.026 2.336 0.01  0.335 0.003 0.09  0.013 0.004 2.252 0.002 0.422
  0.   ]]
[[0.    0.    0.    2.53  0.582 0.    0.    0.    0.    0.355 0.    1.892
  0.   ]
 [0.645 0.    0.307 0.    0.    0.    0.    0.    0.    2.132 0.    0.
  0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.   ]
 [0.    0.    2.69  0.    0.    0.    0.    0.    0.    1.603 0.    0.
  0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.   ]
 [0.    0.    0.332 0.    0.506 0.    0.    0.    0.    2.278 0.    0.
  0.   ]
 [0.    0.    1.091 0.    0.    0.    0.    0.    0.    1.064 0.    0.
  0.   ]
 [0.    0.    0.    0.    1.431 3.724 0.    0.    0.647 0.421 0.    0.
  0.   ]
 [0.    1.545 2.238 0.    0.    0.    0.353 0.    0.    1.442 0.    0.
  0.   ]
 [0.    0.    1.114 0.    0.    0.    0.    0.    0.    0.    0.    2.354
  0.   ]
 [1.745 0.    2.561 0.    0.34  0.    0.    0.    0.    1.006 0.    0.
  0.   ]
 [0.    0.    0.946 0.    0.823 0.    0.    0.    0.    0.    0.    0.
  0.   ]
 [0.    1.026 2.336 0.    0.335 0.    0.    0.    0.    2.252 0.    0.422
  0.   ]]
{'fdr': 0.42857142857142855, 'tpr': 0.7692307692307693, 'fpr': 0.28846153846153844, 'f1': 0.6557377049180327, 'shd': 17, 'npred': 35, 'ntrue': 26}
[2.549e-04 1.808e-01 2.530e+00 5.823e-01 6.063e-04 2.002e-02 1.080e-04
 9.867e-05 3.554e-01 5.934e-05 1.892e+00 2.942e-04 6.451e-01 3.075e-01
 5.223e-02 1.866e-01 1.947e-03 3.737e-02 3.189e-04 1.404e-04 2.132e+00
 5.454e-03 2.208e-01 1.067e-04 3.569e-05 1.373e-05 1.038e-04 1.520e-04
 1.071e-05 9.132e-04 5.347e-06 2.099e-05 1.893e-04 3.280e-07 7.893e-05
 1.487e-05 1.236e-04 6.873e-05 2.690e+00 8.990e-02 5.420e-04 8.712e-02
 1.835e-04 4.968e-05 1.603e+00 8.936e-06 2.747e-01 3.152e-05 2.965e-05
 6.044e-05 2.569e-01 2.542e-04 7.130e-06 2.181e-03 1.078e-05 2.751e-05
 2.442e-04 2.398e-05 4.561e-04 7.538e-06 8.566e-02 3.836e-02 3.316e-01
 7.515e-02 5.058e-01 1.409e-02 1.137e-04 1.095e-01 2.278e+00 2.694e-03
 1.246e-01 2.368e-03 9.809e-03 1.455e-02 1.091e+00 2.613e-02 9.848e-02
 4.145e-02 1.016e-03 1.988e-03 1.064e+00 1.244e-03 2.930e-01 3.122e-03
 1.476e-02 1.014e-02 9.205e-03 2.143e-02 1.431e+00 3.724e+00 7.783e-02
 6.468e-01 4.212e-01 5.319e-03 7.937e-02 5.439e-03 1.681e-02 1.545e+00
 2.238e+00 2.894e-02 1.022e-01 4.219e-03 3.527e-01 3.620e-04 1.442e+00
 3.076e-03 1.963e-01 2.273e-02 4.524e-05 9.540e-05 1.114e+00 1.094e-04
 2.237e-01 2.069e-04 8.551e-04 4.317e-05 1.253e-05 1.729e-05 2.354e+00
 3.131e-05 1.745e+00 5.543e-03 2.561e+00 7.573e-02 3.402e-01 7.754e-03
 1.065e-02 1.923e-02 2.249e-03 1.006e+00 1.010e-01 3.039e-03 2.234e-06
 7.028e-06 9.458e-01 2.852e-05 8.228e-01 7.114e-06 9.121e-04 7.354e-06
 5.422e-06 5.389e-05 3.615e-06 1.385e-06 6.332e-03 1.026e+00 2.336e+00
 1.029e-02 3.345e-01 2.771e-03 9.016e-02 1.299e-02 3.999e-03 2.252e+00
 1.728e-03 4.223e-01]
[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]
 [1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0.]
aucroc, aucpr (0.8609467455621302, 0.7543274291345048)
cuda
noise_multiplier  0.5  noise_multiplier_b  1.25  noise_multiplier_delta  0.5103103630798288
cuda
Objective function 480.43 = squared loss an data 285.64 + 0.5*rho*h**2 194.315677 + alpha*h 0.000000 + L2reg 0.24 + L1reg 0.24 ; SHD = 91 ; DAG False
total norm for a microbatch 43.92361471839687 clip 31.49482124640394
total norm for a microbatch 42.73878791083315 clip 30.21431388761334
total norm for a microbatch 33.454841749998586 clip 28.54156082702483
total norm for a microbatch 38.70220002600134 clip 27.835635680818854
total norm for a microbatch 50.640400499678215 clip 32.721874755183066
total norm for a microbatch 22.30163032942393 clip 32.84423595285044
total norm for a microbatch 36.59480928226185 clip 34.21323762847458
total norm for a microbatch 42.13899871119897 clip 37.11389104375686
total norm for a microbatch 43.731002101969395 clip 39.933328291718794
total norm for a microbatch 63.780342085869876 clip 37.75155438344282
total norm for a microbatch 64.11977891282724 clip 45.90122875927911
total norm for a microbatch 18.891031433367885 clip 40.916950525946994
total norm for a microbatch 70.57777925711842 clip 45.94041754204024
total norm for a microbatch 53.39616466392542 clip 48.815292816308435
total norm for a microbatch 34.22682359329621 clip 44.617570921215645
total norm for a microbatch 47.754020996609825 clip 45.5732157902051
total norm for a microbatch 71.45017370083266 clip 44.449192543572586
total norm for a microbatch 80.49070492391344 clip 47.633999510731705
total norm for a microbatch 47.26313165216062 clip 46.79193782685067
total norm for a microbatch 94.58213367746787 clip 51.87383118286775
total norm for a microbatch 60.05782798955169 clip 47.514101504085815
total norm for a microbatch 66.98442457015908 clip 61.32708432411401
total norm for a microbatch 61.242489166085186 clip 51.67703070555362
total norm for a microbatch 116.3289544161017 clip 55.47095167298052
cuda
Objective function 11.77 = squared loss an data 8.14 + 0.5*rho*h**2 2.464193 + alpha*h 0.000000 + L2reg 1.02 + L1reg 0.15 ; SHD = 64 ; DAG False
Proportion of microbatches that were clipped  0.7816381199772708
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 2.2199968098999427
iteration 1 in outer loop, alpha = 2.2199968098999427, rho = 1.0, h = 2.2199968098999427
cuda
noise_multiplier  0.5  noise_multiplier_b  1.25  noise_multiplier_delta  0.5103103630798288
cuda
Objective function 16.69 = squared loss an data 8.14 + 0.5*rho*h**2 2.464193 + alpha*h 4.928386 + L2reg 1.02 + L1reg 0.15 ; SHD = 64 ; DAG False
total norm for a microbatch 31.638139806214916 clip 1.0
total norm for a microbatch 88.58207984528511 clip 2.751562921369173
total norm for a microbatch 78.31870837724438 clip 64.82171397143738
total norm for a microbatch 97.92223502839616 clip 64.05407218101577
total norm for a microbatch 69.1064015774582 clip 56.04894601954196
total norm for a microbatch 93.99556428736452 clip 56.361375247625844
total norm for a microbatch 51.18211145664517 clip 61.59782119509024
total norm for a microbatch 69.04988223361225 clip 60.01509515672676
total norm for a microbatch 70.55633057697214 clip 64.99732002005683
total norm for a microbatch 77.3587343348655 clip 63.06893556321077
total norm for a microbatch 58.35815439146511 clip 62.64186576372161
total norm for a microbatch 63.82700618048171 clip 61.17187826705163
total norm for a microbatch 80.87397968187544 clip 57.453739963808296
total norm for a microbatch 86.65387286254969 clip 60.93695187146433
total norm for a microbatch 59.34809561190696 clip 56.172075031309795
total norm for a microbatch 44.02336179159094 clip 62.83226064832641
total norm for a microbatch 59.70871207286257 clip 58.745631459532994
total norm for a microbatch 55.2454594587446 clip 62.488363199003
total norm for a microbatch 69.65887535000262 clip 57.486520711959855
total norm for a microbatch 78.48222348831652 clip 59.80472932786964
total norm for a microbatch 88.46046179359035 clip 57.576587181271464
total norm for a microbatch 63.25940658826953 clip 58.16314032229274
total norm for a microbatch 54.085192029519426 clip 62.47378284458284
total norm for a microbatch 68.80328549684067 clip 63.37275150763532
total norm for a microbatch 57.5758966352429 clip 56.05681928423214
cuda
Objective function 13.48 = squared loss an data 8.13 + 0.5*rho*h**2 0.920574 + alpha*h 3.012289 + L2reg 1.29 + L1reg 0.14 ; SHD = 56 ; DAG False
Proportion of microbatches that were clipped  0.7858675780939512
iteration 1 in inner loop, alpha 2.2199968098999427 rho 1.0 h 1.356888939209826
noise_multiplier  0.5  noise_multiplier_b  1.25  noise_multiplier_delta  0.5103103630798288
cuda
Objective function 21.77 = squared loss an data 8.13 + 0.5*rho*h**2 9.205738 + alpha*h 3.012289 + L2reg 1.29 + L1reg 0.14 ; SHD = 56 ; DAG False
total norm for a microbatch 122.36331002919349 clip 1.5629173511824708
total norm for a microbatch 131.8345880488075 clip 18.87800415151592
total norm for a microbatch 73.01973863753163 clip 77.15332838751529
total norm for a microbatch 98.61844269843856 clip 76.65322886354316
total norm for a microbatch 106.77876069846717 clip 80.89800168786986
total norm for a microbatch 123.21311433628439 clip 86.24060503912283
total norm for a microbatch 120.35867169196864 clip 78.03695209619418
total norm for a microbatch 86.76845087907594 clip 78.03695209619418
total norm for a microbatch 56.947715970266415 clip 77.65408585164543
total norm for a microbatch 79.11260900397937 clip 79.04609034149979
total norm for a microbatch 108.52492672867764 clip 81.97276187608146
total norm for a microbatch 79.11622191304774 clip 78.15013283714825
total norm for a microbatch 48.65802294086321 clip 79.56163739070504
total norm for a microbatch 88.12256221095251 clip 74.27939151484577
total norm for a microbatch 107.27856018767044 clip 83.24439101913602
total norm for a microbatch 143.27524171717758 clip 75.74978069428825
total norm for a microbatch 111.41528164709062 clip 80.50720491341129
total norm for a microbatch 88.75282675755442 clip 76.97041619896625
total norm for a microbatch 134.5069496351684 clip 80.61167777108
total norm for a microbatch 123.75450715223327 clip 86.20905473288192
total norm for a microbatch 132.1546207488596 clip 80.76593626338136
total norm for a microbatch 100.22600396916854 clip 84.53569186723347
total norm for a microbatch 137.63444641058803 clip 80.31785719825398
total norm for a microbatch 146.5291727192958 clip 76.76569593146148
total norm for a microbatch 75.03898909819122 clip 79.40593201967737
total norm for a microbatch 112.88635888418285 clip 73.07228813291854
total norm for a microbatch 97.19161228832007 clip 80.77595619801967
cuda
Objective function 14.92 = squared loss an data 9.57 + 0.5*rho*h**2 2.132659 + alpha*h 1.449867 + L2reg 1.64 + L1reg 0.13 ; SHD = 50 ; DAG False
Proportion of microbatches that were clipped  0.7844256037288544
iteration 2 in inner loop, alpha 2.2199968098999427 rho 10.0 h 0.6530939689145807
noise_multiplier  0.5  noise_multiplier_b  1.25  noise_multiplier_delta  0.5103103630798288
cuda
Objective function 34.12 = squared loss an data 9.57 + 0.5*rho*h**2 21.326587 + alpha*h 1.449867 + L2reg 1.64 + L1reg 0.13 ; SHD = 50 ; DAG False
total norm for a microbatch 200.04614286823116 clip 109.32694258911668
total norm for a microbatch 221.07768413805178 clip 94.47765603025664
total norm for a microbatch 141.83886043595848 clip 106.54672627870605
total norm for a microbatch 204.176009167754 clip 101.9250942144983
total norm for a microbatch 130.11402788831145 clip 103.42530403143996
total norm for a microbatch 86.49586218822523 clip 101.85166473344411
total norm for a microbatch 171.13136137314382 clip 110.02906838721316
total norm for a microbatch 187.7642680544084 clip 110.99785172682859
total norm for a microbatch 186.04918455915745 clip 114.72209178178989
total norm for a microbatch 143.04588795224095 clip 103.46815183527681
total norm for a microbatch 86.20880343595189 clip 101.43106854720315
total norm for a microbatch 135.86833142650386 clip 98.61970775459992
total norm for a microbatch 118.16064242983185 clip 99.6491869175862
total norm for a microbatch 116.56668310512806 clip 98.28862813403542
total norm for a microbatch 145.5957498301687 clip 97.56957314015268
total norm for a microbatch 169.79763274643904 clip 104.9895027473494
total norm for a microbatch 173.98447613878815 clip 105.63043218892845
total norm for a microbatch 126.78088883478635 clip 109.37080017818741
total norm for a microbatch 119.616421574286 clip 96.87428417427614
total norm for a microbatch 123.61862732249367 clip 98.93940220614246
total norm for a microbatch 204.1155884525537 clip 99.71387086492584
total norm for a microbatch 117.30225924550834 clip 98.17428004566935
total norm for a microbatch 88.38227176904346 clip 100.83873232705832
total norm for a microbatch 138.42877595059335 clip 98.22057543701521
total norm for a microbatch 135.1308634900745 clip 95.62914034141642
cuda
Objective function 18.11 = squared loss an data 12.93 + 0.5*rho*h**2 2.847630 + alpha*h 0.529797 + L2reg 1.68 + L1reg 0.12 ; SHD = 41 ; DAG True
Proportion of microbatches that were clipped  0.7866981660927365
iteration 3 in inner loop, alpha 2.2199968098999427 rho 100.0 h 0.2386474385295969
iteration 2 in outer loop, alpha = 26.084740662859634, rho = 100.0, h = 0.2386474385295969
cuda
noise_multiplier  0.5  noise_multiplier_b  1.25  noise_multiplier_delta  0.5103103630798288
cuda
Objective function 23.80 = squared loss an data 12.93 + 0.5*rho*h**2 2.847630 + alpha*h 6.225057 + L2reg 1.68 + L1reg 0.12 ; SHD = 41 ; DAG True
total norm for a microbatch 81.19098464344715 clip 54.0857523237594
total norm for a microbatch 126.0822688650224 clip 102.90202107122086
total norm for a microbatch 221.0279029221206 clip 108.29433417798262
total norm for a microbatch 219.9306143780283 clip 110.57329571659396
total norm for a microbatch 157.02456551337144 clip 107.55537597507987
total norm for a microbatch 134.07507332604885 clip 114.85348563954932
total norm for a microbatch 216.28971200415063 clip 104.56388492683936
total norm for a microbatch 141.53912965547372 clip 107.44730437128281
total norm for a microbatch 84.35376064561551 clip 107.42977922547024
total norm for a microbatch 197.7240973846434 clip 108.33900515595045
total norm for a microbatch 111.28900288987852 clip 112.03437643031864
total norm for a microbatch 189.3579845507498 clip 107.15500353963641
total norm for a microbatch 162.8209733103834 clip 108.55203552932663
total norm for a microbatch 90.13011905172607 clip 108.55203552932663
total norm for a microbatch 194.51397258484704 clip 98.03792655861692
total norm for a microbatch 264.38134505830095 clip 108.4384405254303
total norm for a microbatch 139.45961274675375 clip 116.40645761111269
total norm for a microbatch 156.0064442655883 clip 115.20657270448498
total norm for a microbatch 125.58801490070643 clip 114.94188679492366
total norm for a microbatch 161.56701256397702 clip 99.21226859437398
total norm for a microbatch 133.98289204698008 clip 114.41809467189194
total norm for a microbatch 78.77965599601526 clip 115.1666230527889
total norm for a microbatch 77.11215517497479 clip 104.8089153491788
cuda
Objective function 20.01 = squared loss an data 13.02 + 0.5*rho*h**2 1.126305 + alpha*h 3.914980 + L2reg 1.82 + L1reg 0.12 ; SHD = 45 ; DAG True
Proportion of microbatches that were clipped  0.7865741112270284
iteration 1 in inner loop, alpha 26.084740662859634 rho 100.0 h 0.15008699218039112
noise_multiplier  0.5  noise_multiplier_b  1.25  noise_multiplier_delta  0.5103103630798288
cuda
Objective function 30.14 = squared loss an data 13.02 + 0.5*rho*h**2 11.263053 + alpha*h 3.914980 + L2reg 1.82 + L1reg 0.12 ; SHD = 45 ; DAG True
total norm for a microbatch 211.57819166669947 clip 116.81580273081426
total norm for a microbatch 82.32888882322402 clip 110.33660704610801
total norm for a microbatch 79.3330354181013 clip 124.67465321313452
total norm for a microbatch 190.60893670925532 clip 112.30544957618832
total norm for a microbatch 87.80742742201201 clip 116.55711696453521
total norm for a microbatch 152.30220973106105 clip 109.98019655982489
total norm for a microbatch 72.88593432462166 clip 116.13944528131563
total norm for a microbatch 106.8826457452566 clip 117.39691059340493
total norm for a microbatch 67.46689114053456 clip 108.0721075143787
total norm for a microbatch 213.50169016690302 clip 104.87723993603312
total norm for a microbatch 72.62332411040707 clip 108.45849717509223
total norm for a microbatch 121.57087859278164 clip 122.40872922209161
total norm for a microbatch 127.5215806277678 clip 111.02439285792597
total norm for a microbatch 270.2205377976036 clip 110.0315657044423
total norm for a microbatch 243.09764199059757 clip 121.32997146027293
total norm for a microbatch 116.03969593523877 clip 108.9495319145437
total norm for a microbatch 160.24303818672038 clip 122.40861254773434
total norm for a microbatch 89.5606795978579 clip 114.5680471094336
total norm for a microbatch 160.46984261870693 clip 106.77276428222729
total norm for a microbatch 128.7715475979698 clip 116.63573440547144
total norm for a microbatch 102.45370923739348 clip 107.36421801059858
cuda
Objective function 20.36 = squared loss an data 13.77 + 0.5*rho*h**2 2.565423 + alpha*h 1.868448 + L2reg 2.02 + L1reg 0.13 ; SHD = 40 ; DAG True
Proportion of microbatches that were clipped  0.788986819120216
iteration 2 in inner loop, alpha 26.084740662859634 rho 1000.0 h 0.07162991846337974
noise_multiplier  0.5  noise_multiplier_b  1.25  noise_multiplier_delta  0.5103103630798288
cuda
Objective function 43.45 = squared loss an data 13.77 + 0.5*rho*h**2 25.654226 + alpha*h 1.868448 + L2reg 2.02 + L1reg 0.13 ; SHD = 40 ; DAG True
total norm for a microbatch 195.87150358743398 clip 206.05405128157125
total norm for a microbatch 331.9811003126046 clip 150.3665718541422
total norm for a microbatch 282.2594082759995 clip 134.42860841494843
total norm for a microbatch 172.12636858504027 clip 132.30234371006043
total norm for a microbatch 246.62368810709185 clip 122.72871802312083
total norm for a microbatch 110.47564232918504 clip 125.0589467486303
total norm for a microbatch 145.6471478177524 clip 126.97883515715716
total norm for a microbatch 331.99326125304736 clip 133.34787579109343
total norm for a microbatch 116.39859252499642 clip 133.03435481407487
total norm for a microbatch 194.16441459978645 clip 141.89113272355232
total norm for a microbatch 168.1904884613983 clip 143.71463459361635
total norm for a microbatch 187.8500494005053 clip 142.77450189893943
total norm for a microbatch 149.61916675011932 clip 114.68619334854567
total norm for a microbatch 117.02336586880794 clip 113.47895614873698
total norm for a microbatch 186.3420166173154 clip 120.82638222815268
total norm for a microbatch 182.89933462652763 clip 129.4535190708901
total norm for a microbatch 221.44774307508797 clip 145.76565241607767
total norm for a microbatch 189.11279782209027 clip 109.31192399929625
total norm for a microbatch 132.17312102115807 clip 126.32918649931186
total norm for a microbatch 90.92016771597135 clip 118.98611647880502
total norm for a microbatch 184.17385089161107 clip 128.26806578679333
total norm for a microbatch 229.05761367294934 clip 135.42474126791393
total norm for a microbatch 119.45744699005634 clip 135.13783881345046
total norm for a microbatch 253.87182318548997 clip 132.94328863122834
total norm for a microbatch 124.06397723693026 clip 128.0573615299773
cuda
Objective function 20.43 = squared loss an data 14.71 + 0.5*rho*h**2 2.804480 + alpha*h 0.617771 + L2reg 2.16 + L1reg 0.14 ; SHD = 39 ; DAG True
Proportion of microbatches that were clipped  0.7883743136786823
iteration 3 in inner loop, alpha 26.084740662859634 rho 10000.0 h 0.023683242505036617
iteration 3 in outer loop, alpha = 262.9171657132258, rho = 10000.0, h = 0.023683242505036617
cuda
noise_multiplier  0.5  noise_multiplier_b  1.25  noise_multiplier_delta  0.5103103630798288
cuda
Objective function 26.04 = squared loss an data 14.71 + 0.5*rho*h**2 2.804480 + alpha*h 6.226731 + L2reg 2.16 + L1reg 0.14 ; SHD = 39 ; DAG True
total norm for a microbatch 237.7096153091368 clip 16.127952371243293
total norm for a microbatch 317.48988372031937 clip 60.69947341409699
total norm for a microbatch 215.99834991744112 clip 214.15999574524568
total norm for a microbatch 228.259473816652 clip 118.93919326031168
total norm for a microbatch 145.48128837256223 clip 144.4566237364423
total norm for a microbatch 209.59336643426062 clip 138.34824814290945
total norm for a microbatch 176.656314104932 clip 136.4565001606232
total norm for a microbatch 334.24155034610425 clip 147.43836730065468
total norm for a microbatch 206.6175919950763 clip 161.22470305301115
total norm for a microbatch 190.14344874435199 clip 145.05115197839288
total norm for a microbatch 158.7166889460744 clip 130.115578150939
total norm for a microbatch 187.77257924744222 clip 134.96838046829822
total norm for a microbatch 146.3451774243279 clip 142.87308951841112
total norm for a microbatch 214.6519564963182 clip 137.3725634259229
total norm for a microbatch 166.01951877254734 clip 164.6047304365215
total norm for a microbatch 127.71589666420317 clip 143.85174521668762
total norm for a microbatch 105.46025092088207 clip 127.0500630818062
total norm for a microbatch 150.8849086646232 clip 148.61365832570962
total norm for a microbatch 247.92706668493236 clip 144.66712361925494
total norm for a microbatch 208.47170110709652 clip 140.62878918366658
total norm for a microbatch 293.204100214522 clip 160.79471026563226
cuda
Objective function 23.70 = squared loss an data 14.90 + 0.5*rho*h**2 1.640415 + alpha*h 4.762235 + L2reg 2.25 + L1reg 0.14 ; SHD = 36 ; DAG True
Proportion of microbatches that were clipped  0.7872825434913018
iteration 1 in inner loop, alpha 262.9171657132258 rho 10000.0 h 0.018113062712192374
noise_multiplier  0.5  noise_multiplier_b  1.25  noise_multiplier_delta  0.5103103630798288
cuda
Objective function 38.46 = squared loss an data 14.90 + 0.5*rho*h**2 16.404152 + alpha*h 4.762235 + L2reg 2.25 + L1reg 0.14 ; SHD = 36 ; DAG True
total norm for a microbatch 490.4044970155457 clip 47.05883449454356
total norm for a microbatch 1594.125968183422 clip 772.1796817871258
total norm for a microbatch 275.6885071075056 clip 298.51039283603876
total norm for a microbatch 230.9295380024908 clip 210.4127127987573
total norm for a microbatch 139.68486666799893 clip 143.52939955961153
total norm for a microbatch 199.18537825327002 clip 120.85953395284295
total norm for a microbatch 132.73090186409772 clip 117.50249516356538
total norm for a microbatch 171.31226513818532 clip 125.63442912833081
total norm for a microbatch 174.60925707592486 clip 122.1861548039116
total norm for a microbatch 234.5995138469561 clip 107.46096896812256
total norm for a microbatch 239.62749834881197 clip 117.2992546940476
total norm for a microbatch 186.08659303276596 clip 119.68447006804129
total norm for a microbatch 165.51608173418674 clip 120.98889055362467
total norm for a microbatch 136.7120050630037 clip 123.94760336263653
total norm for a microbatch 173.5508732404431 clip 122.49153426556359
total norm for a microbatch 275.50199501901494 clip 127.69077926248474
total norm for a microbatch 171.40485761635668 clip 140.51365406421468
total norm for a microbatch 168.86667607654263 clip 115.76852648106977
total norm for a microbatch 269.0124388305557 clip 128.83786857950668
total norm for a microbatch 182.75503176773375 clip 123.29578954018343
total norm for a microbatch 194.65419364403823 clip 170.33999384154774
total norm for a microbatch 145.93270607081666 clip 138.39283177114018
total norm for a microbatch 206.59624393755288 clip 171.91784621643552
total norm for a microbatch 231.83210137497298 clip 172.52337813565825
total norm for a microbatch 15366.087700688047 clip 4329.747113674606
total norm for a microbatch 50339.034779145695 clip 38137.61800443229
total norm for a microbatch 11065.833221310697 clip 9803.318840981761
cuda
Objective function 352.17 = squared loss an data 40.20 + 0.5*rho*h**2 289.340348 + alpha*h 20.000389 + L2reg 2.45 + L1reg 0.17 ; SHD = 43 ; DAG True
Proportion of microbatches that were clipped  0.7983998732572877
iteration 2 in inner loop, alpha 262.9171657132258 rho 100000.0 h 0.07607106525405172
iteration 4 in outer loop, alpha = 76333.98241976494, rho = 1000000.0, h = 0.07607106525405172
Threshold 0.3
[[0.03  0.586 0.876 1.353 1.209 0.494 0.542 0.038 0.132 1.461 1.099 0.957
  0.081]
 [0.023 0.032 0.321 0.191 0.37  0.109 0.112 0.018 0.027 0.774 0.143 0.081
  0.037]
 [0.019 0.111 0.032 0.106 0.208 0.142 0.051 0.016 0.016 0.361 0.055 0.151
  0.022]
 [0.02  0.173 0.299 0.031 0.572 0.129 0.175 0.012 0.036 0.754 0.136 0.197
  0.034]
 [0.016 0.061 0.164 0.046 0.031 0.032 0.051 0.014 0.017 0.339 0.034 0.162
  0.016]
 [0.054 0.224 0.175 0.19  0.522 0.022 0.238 0.008 0.032 1.101 0.276 0.148
  0.027]
 [0.049 0.177 0.356 0.19  0.594 0.14  0.032 0.011 0.02  0.928 0.13  0.279
  0.04 ]
 [0.625 0.701 1.893 2.025 1.631 2.794 2.034 0.031 0.392 2.758 0.586 1.98
  0.58 ]
 [0.189 1.147 2.018 0.653 1.411 0.923 1.355 0.078 0.027 1.511 0.816 0.773
  0.152]
 [0.018 0.028 0.087 0.03  0.107 0.024 0.04  0.008 0.016 0.02  0.041 0.081
  0.012]
 [0.022 0.236 0.524 0.233 0.801 0.122 0.27  0.027 0.042 0.619 0.032 0.515
  0.032]
 [0.027 0.218 0.158 0.129 0.244 0.181 0.156 0.012 0.023 0.523 0.073 0.02
  0.03 ]
 [0.401 0.764 1.462 0.788 1.955 0.952 0.602 0.032 0.133 2.028 0.822 0.975
  0.026]]
[[0.    0.586 0.876 1.353 1.209 0.494 0.542 0.    0.    1.461 1.099 0.957
  0.   ]
 [0.    0.    0.321 0.    0.37  0.    0.    0.    0.    0.774 0.    0.
  0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.361 0.    0.
  0.   ]
 [0.    0.    0.    0.    0.572 0.    0.    0.    0.    0.754 0.    0.
  0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.339 0.    0.
  0.   ]
 [0.    0.    0.    0.    0.522 0.    0.    0.    0.    1.101 0.    0.
  0.   ]
 [0.    0.    0.356 0.    0.594 0.    0.    0.    0.    0.928 0.    0.
  0.   ]
 [0.625 0.701 1.893 2.025 1.631 2.794 2.034 0.    0.392 2.758 0.586 1.98
  0.58 ]
 [0.    1.147 2.018 0.653 1.411 0.923 1.355 0.    0.    1.511 0.816 0.773
  0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.   ]
 [0.    0.    0.524 0.    0.801 0.    0.    0.    0.    0.619 0.    0.515
  0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.523 0.    0.
  0.   ]
 [0.401 0.764 1.462 0.788 1.955 0.952 0.602 0.    0.    2.028 0.822 0.975
  0.   ]]
{'fdr': 0.7017543859649122, 'tpr': 0.6538461538461539, 'fpr': 0.7692307692307693, 'f1': 0.4096385542168675, 'shd': 43, 'npred': 57, 'ntrue': 26}
[0.586 0.876 1.353 1.209 0.494 0.542 0.038 0.132 1.461 1.099 0.957 0.081
 0.023 0.321 0.191 0.37  0.109 0.112 0.018 0.027 0.774 0.143 0.081 0.037
 0.019 0.111 0.106 0.208 0.142 0.051 0.016 0.016 0.361 0.055 0.151 0.022
 0.02  0.173 0.299 0.572 0.129 0.175 0.012 0.036 0.754 0.136 0.197 0.034
 0.016 0.061 0.164 0.046 0.032 0.051 0.014 0.017 0.339 0.034 0.162 0.016
 0.054 0.224 0.175 0.19  0.522 0.238 0.008 0.032 1.101 0.276 0.148 0.027
 0.049 0.177 0.356 0.19  0.594 0.14  0.011 0.02  0.928 0.13  0.279 0.04
 0.625 0.701 1.893 2.025 1.631 2.794 2.034 0.392 2.758 0.586 1.98  0.58
 0.189 1.147 2.018 0.653 1.411 0.923 1.355 0.078 1.511 0.816 0.773 0.152
 0.018 0.028 0.087 0.03  0.107 0.024 0.04  0.008 0.016 0.041 0.081 0.012
 0.022 0.236 0.524 0.233 0.801 0.122 0.27  0.027 0.042 0.619 0.515 0.032
 0.027 0.218 0.158 0.129 0.244 0.181 0.156 0.012 0.023 0.523 0.073 0.03
 0.401 0.764 1.462 0.788 1.955 0.952 0.602 0.032 0.133 2.028 0.822 0.975]
[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]
 [1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0.]
aucroc, aucpr (0.7183431952662722, 0.3717184277917651)
Iterations 9000
Achieves (23.393661989406446, 1e-05)-DP
