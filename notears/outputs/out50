samples  5000  graph  12 24 ER mim  minibatch size  75  noise  0.5  minibatches per NN training  111 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.3536956427375415
iteration 1 in outer loop, alpha = 1.3536956427375415, rho = 1.0, h = 1.3536956427375415
cuda
iteration 1 in inner loop,alpha 1.3536956427375415 rho 1.0 h 0.8335379713592665
iteration 2 in inner loop,alpha 1.3536956427375415 rho 10.0 h 0.3388201984790129
iteration 3 in inner loop,alpha 1.3536956427375415 rho 100.0 h 0.09250531307033327
iteration 2 in outer loop, alpha = 10.604226949770869, rho = 100.0, h = 0.09250531307033327
cuda
iteration 1 in inner loop,alpha 10.604226949770869 rho 100.0 h 0.046884493079115686
iteration 2 in inner loop,alpha 10.604226949770869 rho 1000.0 h 0.013197249740372285
iteration 3 in outer loop, alpha = 23.801476690143154, rho = 1000.0, h = 0.013197249740372285
cuda
iteration 1 in inner loop,alpha 23.801476690143154 rho 1000.0 h 0.006837825842605838
iteration 2 in inner loop,alpha 23.801476690143154 rho 10000.0 h 0.002149716197429541
iteration 4 in outer loop, alpha = 45.29863866443856, rho = 10000.0, h = 0.002149716197429541
cuda
iteration 1 in inner loop,alpha 45.29863866443856 rho 10000.0 h 0.0008018698783267553
iteration 2 in inner loop,alpha 45.29863866443856 rho 100000.0 h 0.00028843971308489813
iteration 5 in outer loop, alpha = 74.14260997292837, rho = 100000.0, h = 0.00028843971308489813
cuda
iteration 1 in inner loop,alpha 74.14260997292837 rho 100000.0 h 0.00016790775399400104
iteration 6 in outer loop, alpha = 242.0503639669294, rho = 1000000.0, h = 0.00016790775399400104
Threshold 0.3
[[0.005 0.    0.684 0.004 0.557 0.    0.066 0.    0.    0.139 0.    0.003]
 [2.082 0.002 0.449 0.157 0.108 0.    0.087 0.003 0.    0.775 0.272 1.277]
 [0.004 0.001 0.005 0.011 0.455 0.    0.048 0.    0.    0.576 0.002 0.003]
 [0.044 0.001 0.055 0.002 0.155 0.    0.809 0.    0.    0.928 0.    0.328]
 [0.005 0.001 0.005 0.005 0.004 0.    0.815 0.    0.    0.624 0.002 0.   ]
 [0.046 0.042 0.651 0.036 0.023 0.    0.058 0.009 0.008 0.018 0.008 0.085]
 [0.004 0.001 0.002 0.001 0.001 0.    0.003 0.    0.    0.014 0.    0.001]
 [3.16  0.033 0.727 0.026 0.071 0.01  0.858 0.    0.002 0.016 0.023 0.083]
 [0.167 2.38  0.039 2.097 0.164 0.018 0.81  0.016 0.    0.986 3.474 0.04 ]
 [0.002 0.001 0.002 0.001 0.003 0.    0.017 0.    0.    0.005 0.    0.001]
 [0.171 0.005 0.018 2.475 0.029 0.001 0.076 0.008 0.    0.117 0.003 0.906]
 [0.222 0.001 0.018 0.002 0.027 0.001 1.06  0.    0.    0.099 0.001 0.004]]
[[0.    0.    0.684 0.    0.557 0.    0.    0.    0.    0.    0.    0.   ]
 [2.082 0.    0.449 0.    0.    0.    0.    0.    0.    0.775 0.    1.277]
 [0.    0.    0.    0.    0.455 0.    0.    0.    0.    0.576 0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.809 0.    0.    0.928 0.    0.328]
 [0.    0.    0.    0.    0.    0.    0.815 0.    0.    0.624 0.    0.   ]
 [0.    0.    0.651 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [3.16  0.    0.727 0.    0.    0.    0.858 0.    0.    0.    0.    0.   ]
 [0.    2.38  0.    2.097 0.    0.    0.81  0.    0.    0.986 3.474 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    2.475 0.    0.    0.    0.    0.    0.    0.    0.906]
 [0.    0.    0.    0.    0.    0.    1.06  0.    0.    0.    0.    0.   ]]
{'fdr': 0.08, 'tpr': 0.9583333333333334, 'fpr': 0.047619047619047616, 'f1': 0.9387755102040817, 'shd': 2, 'npred': 25, 'ntrue': 24}
[3.999e-04 6.835e-01 3.859e-03 5.566e-01 4.931e-04 6.621e-02 1.868e-06
 4.383e-06 1.388e-01 1.240e-04 3.101e-03 2.082e+00 4.491e-01 1.567e-01
 1.075e-01 2.118e-04 8.716e-02 3.411e-03 4.638e-05 7.752e-01 2.717e-01
 1.277e+00 3.574e-03 9.781e-04 1.096e-02 4.547e-01 3.415e-05 4.772e-02
 6.219e-05 9.171e-05 5.763e-01 2.308e-03 3.376e-03 4.408e-02 9.571e-04
 5.541e-02 1.553e-01 2.528e-04 8.092e-01 4.333e-04 8.635e-06 9.284e-01
 2.818e-04 3.284e-01 4.525e-03 1.094e-03 4.692e-03 5.218e-03 2.816e-04
 8.147e-01 2.210e-05 3.706e-05 6.238e-01 1.735e-03 2.773e-04 4.577e-02
 4.170e-02 6.513e-01 3.605e-02 2.330e-02 5.757e-02 8.538e-03 7.637e-03
 1.771e-02 8.499e-03 8.463e-02 3.547e-03 5.270e-04 2.160e-03 6.536e-04
 1.153e-03 4.679e-04 1.924e-05 5.657e-06 1.381e-02 2.691e-04 1.130e-03
 3.160e+00 3.255e-02 7.271e-01 2.599e-02 7.142e-02 9.965e-03 8.580e-01
 2.383e-03 1.634e-02 2.284e-02 8.275e-02 1.665e-01 2.380e+00 3.939e-02
 2.097e+00 1.637e-01 1.850e-02 8.099e-01 1.575e-02 9.859e-01 3.474e+00
 4.021e-02 1.741e-03 7.646e-04 2.168e-03 7.961e-04 2.876e-03 2.607e-04
 1.681e-02 2.831e-05 3.467e-06 2.780e-04 1.147e-03 1.711e-01 4.772e-03
 1.836e-02 2.475e+00 2.947e-02 6.905e-04 7.568e-02 8.447e-03 7.280e-06
 1.166e-01 9.064e-01 2.223e-01 6.758e-04 1.846e-02 1.925e-03 2.721e-02
 5.889e-04 1.060e+00 3.132e-04 5.189e-06 9.850e-02 1.229e-03]
[[0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0.
 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9760802469135802, 0.9631026835924767)
cuda
1692
cuda
Objective function 178.80 = squared loss an data 15.69 + 0.5*rho*h**2 162.682537 + alpha*h 0.000000 + L2reg 0.22 + L1reg 0.21 ; SHD = 78 ; DAG False
||w||^2 9695527860.71928
exp ma of ||w||^2 762248157195.8009
||w|| 98465.87155313906
exp ma of ||w|| 480459.9695708638
||w||^2 2870.1630405894584
exp ma of ||w||^2 1894993732.5611498
||w|| 53.57390260742126
exp ma of ||w|| 1524.9620789188082
||w||^2 0.11660052516531884
exp ma of ||w||^2 209.12017711170148
||w|| 0.3414681905614619
exp ma of ||w|| 0.3598458526584148
||w||^2 0.19078827999612769
exp ma of ||w||^2 5.145493996936631
||w|| 0.4367931775979653
exp ma of ||w|| 0.4036863033683862
||w||^2 0.4362014170471512
exp ma of ||w||^2 0.34696599680920565
||w|| 0.6604554618194562
exp ma of ||w|| 0.47323538122753395
||w||^2 0.28633365044306913
exp ma of ||w||^2 0.2827885520041657
||w|| 0.5351015328356564
exp ma of ||w|| 0.507386370942474
||w||^2 0.3498833708361414
exp ma of ||w||^2 0.35927291345669776
||w|| 0.5915094004630369
exp ma of ||w|| 0.5716615060183896
||w||^2 0.2112471544549479
exp ma of ||w||^2 0.46093351195423826
||w|| 0.4596163122159046
exp ma of ||w|| 0.6494663456921235
||w||^2 1.1987545133801125
exp ma of ||w||^2 0.584957907786441
||w|| 1.0948764831615083
exp ma of ||w|| 0.7314925563555119
||w||^2 0.2921735181398383
exp ma of ||w||^2 0.6707257824633286
||w|| 0.5405307744613976
exp ma of ||w|| 0.7790371537238676
||w||^2 0.2790342527180307
exp ma of ||w||^2 0.652254115385671
||w|| 0.5282369285822704
exp ma of ||w|| 0.7688062342328951
||w||^2 0.9388206394019862
exp ma of ||w||^2 0.6762764579732156
||w|| 0.9689275718039951
exp ma of ||w|| 0.7771968680227331
||w||^2 0.29626456790899636
exp ma of ||w||^2 0.7299661245934798
||w|| 0.5443019087868389
exp ma of ||w|| 0.8028384001250515
cuda
Objective function 8.68 = squared loss an data 7.85 + 0.5*rho*h**2 0.546973 + alpha*h 0.000000 + L2reg 0.19 + L1reg 0.09 ; SHD = 25 ; DAG False
Proportion of microbatches that were clipped  0.7585743927743196
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 1.045918567324886
iteration 1 in outer loop, alpha = 1.045918567324886, rho = 1.0, h = 1.045918567324886
cuda
1692
cuda
Objective function 9.77 = squared loss an data 7.85 + 0.5*rho*h**2 0.546973 + alpha*h 1.093946 + L2reg 0.19 + L1reg 0.09 ; SHD = 25 ; DAG False
||w||^2 20525800771.946342
exp ma of ||w||^2 3897660531.1005344
||w|| 143268.28250504835
exp ma of ||w|| 45285.543049552034
||w||^2 601923519.4037855
exp ma of ||w||^2 1194752157.5078278
||w|| 24534.12968506903
exp ma of ||w|| 31650.93196881591
||w||^2 2.0371609983859407
exp ma of ||w||^2 10302.964255019911
||w|| 1.4272914903361333
exp ma of ||w|| 12.13665639394887
||w||^2 0.4565439463891325
exp ma of ||w||^2 0.3766648587795788
||w|| 0.675680358149571
exp ma of ||w|| 0.5866327196559842
||w||^2 0.5955169431614827
exp ma of ||w||^2 0.6412793886654504
||w|| 0.7716974427594553
exp ma of ||w|| 0.7575856689058302
||w||^2 0.3944652804746063
exp ma of ||w||^2 0.6012533317589563
||w|| 0.6280647104197197
exp ma of ||w|| 0.7285785202357451
||w||^2 0.522670392550206
exp ma of ||w||^2 0.6280465962094144
||w|| 0.7229594681240478
exp ma of ||w|| 0.7371156135724823
cuda
Objective function 8.58 = squared loss an data 7.32 + 0.5*rho*h**2 0.199563 + alpha*h 0.660774 + L2reg 0.31 + L1reg 0.08 ; SHD = 14 ; DAG False
Proportion of microbatches that were clipped  0.7609475951184493
iteration 1 in inner loop, alpha 1.045918567324886 rho 1.0 h 0.6317638867176658
1692
cuda
Objective function 10.37 = squared loss an data 7.32 + 0.5*rho*h**2 1.995628 + alpha*h 0.660774 + L2reg 0.31 + L1reg 0.08 ; SHD = 14 ; DAG False
||w||^2 1779811921.9348853
exp ma of ||w||^2 5963978475.434392
||w|| 42187.81722173933
exp ma of ||w|| 68219.45729715626
||w||^2 2031474120.255116
exp ma of ||w||^2 2334191265.4996085
||w|| 45071.87726570878
exp ma of ||w|| 44859.123190684426
||w||^2 181506236.83716944
exp ma of ||w||^2 1357432159.9384804
||w|| 13472.425054056506
exp ma of ||w|| 33838.329220077554
||w||^2 3052950.136481093
exp ma of ||w||^2 48201161.12178569
||w|| 1747.2693371318267
exp ma of ||w|| 5335.696254154799
||w||^2 0.9450576300774941
exp ma of ||w||^2 0.6149543817574552
||w|| 0.9721407460226601
exp ma of ||w|| 0.736893099191953
||w||^2 0.17434422596408128
exp ma of ||w||^2 0.6242759973146591
||w|| 0.4175454777195908
exp ma of ||w|| 0.7452032672938731
||w||^2 0.800722972206342
exp ma of ||w||^2 0.6652624154292214
||w|| 0.8948312534809801
exp ma of ||w|| 0.7672388574550302
||w||^2 0.6203823168748364
exp ma of ||w||^2 0.6920227240701892
||w|| 0.7876435214453531
exp ma of ||w|| 0.7713837482634825
||w||^2 0.08469983820922931
exp ma of ||w||^2 0.6107670873231983
||w|| 0.2910323662571387
exp ma of ||w|| 0.7332071501808365
||w||^2 0.29270875290923104
exp ma of ||w||^2 0.6806845035411291
||w|| 0.5410256490308302
exp ma of ||w|| 0.7780344512879201
||w||^2 0.20587165284004738
exp ma of ||w||^2 0.7009637186468365
||w|| 0.45373081539614146
exp ma of ||w|| 0.7820479830744698
cuda
Objective function 8.86 = squared loss an data 7.81 + 0.5*rho*h**2 0.315201 + alpha*h 0.262607 + L2reg 0.40 + L1reg 0.07 ; SHD = 18 ; DAG True
Proportion of microbatches that were clipped  0.7553948013732221
iteration 2 in inner loop, alpha 1.045918567324886 rho 10.0 h 0.25107815851933246
iteration 2 in outer loop, alpha = 3.5567001525182107, rho = 10.0, h = 0.25107815851933246
cuda
1692
cuda
Objective function 9.49 = squared loss an data 7.81 + 0.5*rho*h**2 0.315201 + alpha*h 0.893010 + L2reg 0.40 + L1reg 0.07 ; SHD = 18 ; DAG True
||w||^2 0.2845000873538711
exp ma of ||w||^2 0.19948521726022023
||w|| 0.533385496010035
exp ma of ||w|| 0.4201356657510418
||w||^2 0.1450408118718678
exp ma of ||w||^2 0.23390062288398508
||w|| 0.3808422401360802
exp ma of ||w|| 0.45350526711177674
v before min max tensor([[-0.118, -0.347, -0.328,  ..., -0.312, -0.286,  4.959],
        [-0.488,  0.074, -0.402,  ...,  0.370, -0.191, -0.135],
        [ 0.539, -0.173,  0.379,  ..., -0.098, -0.353, -0.302],
        ...,
        [-0.313, -0.275, -0.381,  ..., -0.155, -0.070, -0.627],
        [ 0.426,  0.173, -0.339,  ..., -0.263,  0.867, -0.428],
        [-0.285,  0.084,  1.879,  ..., -0.325, -0.296, -0.364]],
       device='cuda:0')
v tensor([[1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         4.959e+00],
        [1.000e-12, 7.417e-02, 1.000e-12,  ..., 3.703e-01, 1.000e-12,
         1.000e-12],
        [5.385e-01, 1.000e-12, 3.795e-01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [4.263e-01, 1.732e-01, 1.000e-12,  ..., 1.000e-12, 8.667e-01,
         1.000e-12],
        [1.000e-12, 8.395e-02, 1.879e+00,  ..., 1.000e-12, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([-0.227, -0.016,  0.567, -0.283, -0.378, -0.279, -0.168, -0.143,  0.161,
         1.065, -0.081, -0.188,  0.363,  0.159,  0.306,  0.354,  1.368, -0.189,
         0.555, -0.089,  0.041, -0.250,  0.221, -0.119, -0.377,  0.047, -0.089,
        -0.102,  0.317,  0.386, -0.323, -0.246, -0.458,  0.287,  1.533, -0.202,
        -0.048, -0.132,  2.300,  0.445,  2.279,  0.375, -0.235, -0.061, -0.349,
         2.227, -0.170, -0.267, -0.342,  0.026, -0.311,  0.237,  0.129,  0.091,
        -0.267,  0.093,  0.563, -0.224, -0.195, -0.016, -0.407, -0.204, -0.048,
         0.045, -0.196,  2.113, -0.124, -0.029, -0.145,  0.285, -0.148, -0.355,
        -0.152, -0.295,  0.174, -0.282, -0.392,  0.081,  0.075, -0.158, -0.193,
         0.027,  1.192, -0.161,  0.088, -0.172,  1.207, -0.399, -0.155,  0.117,
         0.242,  0.724, -0.405,  0.158, -0.386,  1.046,  2.757,  0.172, -0.183,
         0.466, -0.350, -0.288, -0.136, -0.225, -0.349,  0.172, -0.138, -0.215,
        -0.324, -0.357, -0.347, -0.058, -0.272, -0.053, -0.070, -0.088, -0.024,
         0.804, -0.283, -0.357], device='cuda:0')
v tensor([1.000e-12, 1.000e-12, 5.667e-01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.606e-01, 1.065e+00, 1.000e-12, 1.000e-12,
        3.635e-01, 1.586e-01, 3.059e-01, 3.544e-01, 1.368e+00, 1.000e-12,
        5.552e-01, 1.000e-12, 4.064e-02, 1.000e-12, 2.210e-01, 1.000e-12,
        1.000e-12, 4.668e-02, 1.000e-12, 1.000e-12, 3.166e-01, 3.859e-01,
        1.000e-12, 1.000e-12, 1.000e-12, 2.867e-01, 1.533e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 2.300e+00, 4.448e-01, 2.279e+00, 3.748e-01,
        1.000e-12, 1.000e-12, 1.000e-12, 2.227e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 2.624e-02, 1.000e-12, 2.369e-01, 1.292e-01, 9.085e-02,
        1.000e-12, 9.325e-02, 5.631e-01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 4.516e-02, 1.000e-12, 2.113e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 2.855e-01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.738e-01, 1.000e-12, 1.000e-12, 8.073e-02,
        7.460e-02, 1.000e-12, 1.000e-12, 2.667e-02, 1.192e+00, 1.000e-12,
        8.769e-02, 1.000e-12, 1.207e+00, 1.000e-12, 1.000e-12, 1.168e-01,
        2.424e-01, 7.244e-01, 1.000e-12, 1.578e-01, 1.000e-12, 1.046e+00,
        2.757e+00, 1.721e-01, 1.000e-12, 4.660e-01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.720e-01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 8.036e-01, 1.000e-12, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[ 5.229e-01],
         [-3.413e-01],
         [ 3.844e-01],
         [-1.980e-01],
         [ 3.559e-01],
         [-3.809e-01],
         [-2.599e-01],
         [-1.294e-01],
         [ 4.348e-01],
         [-2.941e-01]],

        [[-3.094e-01],
         [ 2.252e+00],
         [ 3.667e-01],
         [ 2.406e-02],
         [-3.793e-01],
         [ 1.362e-01],
         [ 5.003e-01],
         [-1.944e-01],
         [ 4.317e-01],
         [ 1.384e+00]],

        [[-3.478e-01],
         [-3.223e-01],
         [-4.077e-01],
         [-4.496e-01],
         [-4.115e-01],
         [-1.791e-01],
         [-4.420e-01],
         [ 1.077e+00],
         [-1.440e-01],
         [-4.135e-01]],

        [[ 4.533e-01],
         [-2.718e-01],
         [-1.113e-01],
         [-1.841e-01],
         [-3.821e-03],
         [ 1.268e+00],
         [ 1.254e+00],
         [-2.036e-01],
         [-4.109e-01],
         [ 2.277e-01]],

        [[-3.710e-01],
         [-4.111e-01],
         [-3.809e-01],
         [-2.026e-01],
         [-3.295e-01],
         [-4.254e-01],
         [-2.795e-01],
         [-1.485e-01],
         [ 1.005e+00],
         [ 3.663e-01]],

        [[-3.437e-01],
         [-1.864e-01],
         [-4.821e-02],
         [-2.819e-01],
         [ 2.740e+00],
         [ 7.049e-01],
         [-1.643e-01],
         [ 3.038e-01],
         [-3.824e-01],
         [-1.866e-01]],

        [[ 3.237e-01],
         [ 4.467e-02],
         [-4.832e-01],
         [ 2.700e-02],
         [ 3.602e-01],
         [ 7.195e-02],
         [-3.982e-01],
         [-3.565e-01],
         [-3.817e-01],
         [ 7.870e-01]],

        [[-2.139e-01],
         [-2.866e-01],
         [ 1.850e-01],
         [-4.035e-01],
         [-3.882e-01],
         [-4.241e-01],
         [ 5.268e-02],
         [-3.273e-01],
         [-1.947e-01],
         [ 7.815e-01]],

        [[-5.700e-02],
         [ 6.292e-02],
         [-2.199e-01],
         [ 9.865e-01],
         [-4.205e-01],
         [-1.687e-01],
         [-1.437e-01],
         [-6.374e-02],
         [ 3.435e-01],
         [ 1.512e-01]],

        [[ 3.270e-02],
         [ 1.117e-01],
         [ 1.029e+00],
         [-1.291e-01],
         [-6.212e-02],
         [-2.295e-01],
         [ 1.030e+00],
         [-2.649e-01],
         [ 8.759e-01],
         [ 5.782e+00]],

        [[-2.183e-01],
         [ 4.084e-01],
         [-3.587e-01],
         [ 6.386e-03],
         [-3.711e-01],
         [ 2.005e+00],
         [ 1.357e+00],
         [ 5.720e+00],
         [ 1.779e+00],
         [ 5.620e-01]],

        [[-3.374e-01],
         [-3.137e-01],
         [-3.814e-01],
         [-2.899e-01],
         [ 8.313e-02],
         [ 7.106e-01],
         [ 3.832e-01],
         [-2.983e-01],
         [-3.210e-01],
         [ 1.180e-01]]], device='cuda:0')
v tensor([[[5.229e-01],
         [1.000e-12],
         [3.844e-01],
         [1.000e-12],
         [3.559e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.348e-01],
         [1.000e-12]],

        [[1.000e-12],
         [2.252e+00],
         [3.667e-01],
         [2.406e-02],
         [1.000e-12],
         [1.362e-01],
         [5.003e-01],
         [1.000e-12],
         [4.317e-01],
         [1.384e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.077e+00],
         [1.000e-12],
         [1.000e-12]],

        [[4.533e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.268e+00],
         [1.254e+00],
         [1.000e-12],
         [1.000e-12],
         [2.277e-01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.005e+00],
         [3.663e-01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.740e+00],
         [7.049e-01],
         [1.000e-12],
         [3.038e-01],
         [1.000e-12],
         [1.000e-12]],

        [[3.237e-01],
         [4.467e-02],
         [1.000e-12],
         [2.700e-02],
         [3.602e-01],
         [7.195e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.870e-01]],

        [[1.000e-12],
         [1.000e-12],
         [1.850e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.268e-02],
         [1.000e-12],
         [1.000e-12],
         [7.815e-01]],

        [[1.000e-12],
         [6.292e-02],
         [1.000e-12],
         [9.865e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.435e-01],
         [1.512e-01]],

        [[3.270e-02],
         [1.117e-01],
         [1.029e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.030e+00],
         [1.000e-12],
         [8.759e-01],
         [5.782e+00]],

        [[1.000e-12],
         [4.084e-01],
         [1.000e-12],
         [6.386e-03],
         [1.000e-12],
         [2.005e+00],
         [1.357e+00],
         [5.720e+00],
         [1.779e+00],
         [5.620e-01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [8.313e-02],
         [7.106e-01],
         [3.832e-01],
         [1.000e-12],
         [1.000e-12],
         [1.180e-01]]], device='cuda:0')
v before min max tensor([[-0.436],
        [-0.383],
        [-0.432],
        [ 1.127],
        [-0.420],
        [-0.164],
        [-0.548],
        [ 1.495],
        [ 0.075],
        [ 1.839],
        [ 0.099],
        [ 0.073]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.127e+00],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.495e+00],
        [7.536e-02],
        [1.839e+00],
        [9.873e-02],
        [7.318e-02]], device='cuda:0')
a after update for 1 param tensor([[-2.138e-03,  4.856e-04, -2.215e-04,  ...,  1.268e-03, -6.691e-03,
          2.501e-02],
        [-2.507e-03,  1.154e-02,  3.786e-04,  ..., -2.560e-02,  2.634e-03,
         -7.990e-03],
        [-6.651e-05, -1.326e-02,  8.539e-03,  ...,  7.296e-03,  3.825e-03,
         -1.888e-02],
        ...,
        [-6.174e-03, -8.118e-03,  2.882e-03,  ...,  1.352e-03, -1.255e-02,
         -5.156e-04],
        [ 5.540e-03,  4.704e-03, -3.875e-03,  ...,  2.464e-02,  7.994e-03,
         -3.237e-03],
        [-9.166e-03, -4.505e-03,  3.516e-03,  ...,  7.189e-03, -1.093e-02,
          1.118e-03]], device='cuda:0')
s after update for 1 param tensor([[0.793, 0.728, 0.853,  ..., 0.822, 0.660, 1.209],
        [1.973, 0.508, 0.845,  ..., 0.671, 1.170, 0.695],
        [1.128, 0.508, 0.874,  ..., 0.826, 0.739, 0.860],
        ...,
        [0.668, 0.701, 1.040,  ..., 0.789, 0.689, 1.322],
        [0.650, 0.710, 0.880,  ..., 0.955, 0.665, 0.944],
        [0.687, 0.547, 1.164,  ..., 0.701, 0.728, 1.034]], device='cuda:0')
b after update for 1 param tensor([[32.668, 31.301, 33.862,  ..., 33.248, 29.796, 40.317],
        [51.519, 26.134, 33.703,  ..., 30.052, 39.666, 30.567],
        [38.956, 26.150, 34.290,  ..., 33.327, 31.519, 34.005],
        ...,
        [29.967, 30.704, 37.403,  ..., 32.566, 30.451, 42.173],
        [29.577, 30.895, 34.412,  ..., 35.843, 29.903, 35.637],
        [30.394, 27.116, 39.566,  ..., 30.714, 31.285, 37.284]],
       device='cuda:0')
clipping threshold 0.31299152240770345
a after update for 1 param tensor([-4.914e-03,  5.294e-04,  1.311e-02,  5.671e-03,  1.911e-03,  1.210e-02,
        -1.710e-03,  2.734e-03,  3.677e-04,  1.215e-02, -2.016e-03, -9.740e-03,
         2.949e-03, -1.703e-02,  9.740e-03,  1.072e-02,  2.322e-02,  2.520e-02,
         8.410e-03,  9.909e-03, -2.435e-02,  1.020e-02, -5.342e-03,  2.923e-03,
         1.566e-02,  2.753e-02, -2.206e-03, -2.041e-02,  3.976e-02,  9.965e-03,
         1.786e-02,  6.763e-03, -2.108e-03,  7.780e-03, -1.654e-02,  7.922e-03,
        -3.734e-03, -8.609e-03, -2.127e-02, -2.546e-02,  8.274e-03,  6.297e-03,
        -1.612e-02,  1.006e-02, -5.347e-03, -5.629e-03, -2.107e-02, -6.969e-03,
         1.919e-02,  2.838e-02,  7.304e-03, -4.149e-03,  1.656e-02, -1.215e-02,
        -6.893e-03, -3.039e-04,  8.508e-03, -2.569e-02,  5.638e-03, -1.942e-02,
        -4.491e-03,  4.868e-05, -1.568e-02, -1.605e-02,  2.177e-02, -1.163e-02,
         1.154e-02, -1.902e-02,  2.022e-03, -2.088e-02,  4.298e-03, -1.367e-02,
         2.189e-02,  1.163e-02, -7.351e-03,  2.003e-02,  1.954e-02,  4.340e-04,
        -4.568e-03,  3.393e-02, -2.929e-03,  7.899e-03,  1.377e-02, -1.011e-02,
        -4.499e-02, -1.201e-02, -1.009e-02, -1.039e-02, -5.514e-03,  8.292e-03,
         4.418e-03,  4.110e-02,  5.413e-03, -3.822e-03, -1.353e-02,  6.221e-03,
         7.584e-04,  9.125e-05,  1.103e-02, -1.823e-02, -8.155e-03, -7.675e-03,
        -1.756e-02,  1.226e-02, -1.823e-02,  3.787e-04, -5.349e-03,  5.162e-03,
        -1.077e-02,  1.154e-02, -2.960e-02,  4.349e-03, -1.693e-02, -4.897e-03,
         4.247e-03, -3.016e-02, -1.516e-03, -5.721e-03,  1.258e-02, -1.812e-02],
       device='cuda:0')
s after update for 1 param tensor([0.744, 0.259, 0.502, 0.949, 0.802, 0.592, 0.680, 0.659, 0.666, 0.874,
        0.172, 0.728, 0.241, 0.931, 0.837, 0.993, 0.860, 0.574, 0.467, 0.391,
        0.777, 0.669, 0.693, 0.467, 0.899, 0.731, 0.788, 0.733, 0.748, 0.647,
        0.799, 0.833, 1.310, 0.491, 0.803, 0.455, 1.029, 0.283, 1.010, 0.964,
        1.195, 0.533, 0.493, 0.673, 0.835, 1.152, 0.732, 0.562, 0.723, 0.819,
        0.799, 0.752, 0.737, 0.390, 0.559, 0.138, 0.792, 0.619, 0.579, 0.646,
        0.873, 0.562, 0.698, 0.664, 0.566, 1.003, 0.429, 0.734, 0.312, 0.650,
        0.315, 0.756, 0.691, 0.713, 0.544, 1.014, 0.880, 0.421, 0.372, 0.878,
        0.414, 0.488, 0.703, 0.454, 0.552, 0.948, 0.812, 0.865, 0.836, 0.648,
        0.866, 0.844, 0.856, 0.593, 0.875, 0.488, 0.988, 0.189, 0.415, 0.797,
        0.820, 0.745, 0.563, 0.620, 0.736, 0.768, 0.833, 0.767, 0.739, 0.749,
        0.999, 0.582, 0.570, 0.153, 0.149, 0.821, 0.777, 0.470, 0.658, 0.749],
       device='cuda:0')
b after update for 1 param tensor([31.633, 18.652, 25.984, 35.734, 32.837, 28.227, 30.245, 29.782, 29.927,
        34.282, 15.232, 31.285, 18.016, 35.383, 33.551, 36.546, 34.019, 27.779,
        25.058, 22.944, 32.335, 30.006, 30.536, 25.075, 34.763, 31.346, 32.556,
        31.394, 31.718, 29.494, 32.790, 33.479, 41.976, 25.705, 32.866, 24.733,
        37.206, 19.494, 36.857, 36.013, 40.095, 26.781, 25.757, 30.094, 33.508,
        39.361, 31.381, 27.482, 31.190, 33.193, 32.785, 31.806, 31.480, 22.891,
        27.410, 13.633, 32.638, 28.849, 27.906, 29.478, 34.258, 27.492, 30.629,
        29.893, 27.594, 36.728, 24.013, 31.425, 20.500, 29.563, 20.579, 31.877,
        30.479, 30.958, 27.049, 36.936, 34.397, 23.802, 22.372, 34.356, 23.583,
        25.620, 30.745, 24.702, 27.240, 35.716, 33.056, 34.101, 33.524, 29.517,
        34.124, 33.699, 33.927, 28.242, 34.302, 25.628, 36.446, 15.951, 23.636,
        32.731, 33.217, 31.650, 27.526, 28.886, 31.462, 32.146, 33.463, 32.127,
        31.526, 31.748, 36.654, 27.988, 27.685, 14.344, 14.169, 33.236, 32.333,
        25.141, 29.752, 31.735], device='cuda:0')
clipping threshold 0.31299152240770345
a after update for 1 param tensor([[[-0.021],
         [ 0.004],
         [ 0.011],
         [ 0.023],
         [ 0.004],
         [-0.003],
         [ 0.004],
         [-0.005],
         [ 0.022],
         [-0.004]],

        [[ 0.005],
         [ 0.015],
         [-0.003],
         [-0.007],
         [ 0.012],
         [-0.004],
         [ 0.007],
         [ 0.008],
         [-0.002],
         [ 0.006]],

        [[ 0.022],
         [-0.002],
         [ 0.009],
         [ 0.001],
         [ 0.004],
         [-0.016],
         [-0.001],
         [ 0.002],
         [-0.008],
         [-0.006]],

        [[ 0.005],
         [-0.026],
         [-0.006],
         [ 0.014],
         [-0.003],
         [-0.005],
         [ 0.034],
         [-0.008],
         [ 0.011],
         [ 0.002]],

        [[-0.016],
         [ 0.025],
         [-0.017],
         [ 0.016],
         [ 0.030],
         [-0.015],
         [ 0.003],
         [-0.024],
         [-0.010],
         [-0.054]],

        [[-0.016],
         [ 0.010],
         [-0.018],
         [ 0.006],
         [-0.004],
         [-0.004],
         [-0.010],
         [ 0.059],
         [ 0.014],
         [ 0.018]],

        [[-0.028],
         [ 0.008],
         [-0.028],
         [-0.008],
         [ 0.003],
         [ 0.025],
         [-0.011],
         [ 0.006],
         [ 0.021],
         [-0.005]],

        [[ 0.006],
         [-0.003],
         [ 0.003],
         [ 0.010],
         [ 0.012],
         [ 0.012],
         [-0.007],
         [ 0.008],
         [-0.007],
         [ 0.011]],

        [[-0.002],
         [ 0.004],
         [-0.042],
         [-0.011],
         [ 0.008],
         [ 0.025],
         [ 0.001],
         [ 0.013],
         [ 0.009],
         [-0.010]],

        [[ 0.008],
         [-0.054],
         [-0.008],
         [ 0.031],
         [-0.007],
         [-0.001],
         [ 0.015],
         [-0.001],
         [ 0.003],
         [ 0.008]],

        [[-0.054],
         [-0.010],
         [ 0.018],
         [-0.003],
         [ 0.014],
         [-0.017],
         [ 0.002],
         [ 0.030],
         [ 0.016],
         [ 0.012]],

        [[ 0.027],
         [ 0.016],
         [ 0.002],
         [ 0.011],
         [-0.002],
         [ 0.011],
         [-0.037],
         [-0.005],
         [-0.025],
         [-0.001]]], device='cuda:0')
s after update for 1 param tensor([[[1.085],
         [0.714],
         [0.748],
         [0.905],
         [0.870],
         [0.826],
         [0.675],
         [1.055],
         [0.879],
         [0.875]],

        [[0.661],
         [0.972],
         [0.567],
         [0.478],
         [0.794],
         [0.404],
         [0.942],
         [0.424],
         [0.809],
         [1.076]],

        [[0.727],
         [0.714],
         [1.092],
         [0.989],
         [1.060],
         [0.860],
         [0.939],
         [0.708],
         [1.022],
         [0.903]],

        [[0.703],
         [0.672],
         [0.480],
         [0.624],
         [0.687],
         [0.879],
         [1.069],
         [0.655],
         [0.927],
         [0.969]],

        [[0.830],
         [0.918],
         [0.813],
         [0.823],
         [0.702],
         [0.913],
         [0.772],
         [1.026],
         [0.462],
         [0.928]],

        [[0.773],
         [0.537],
         [0.945],
         [0.657],
         [1.059],
         [0.601],
         [0.701],
         [1.041],
         [0.931],
         [0.935]],

        [[0.748],
         [0.790],
         [1.010],
         [0.763],
         [0.483],
         [0.595],
         [0.887],
         [0.755],
         [0.800],
         [0.845]],

        [[0.808],
         [0.658],
         [0.519],
         [0.899],
         [0.922],
         [0.907],
         [1.079],
         [0.688],
         [0.760],
         [0.660]],

        [[0.201],
         [0.825],
         [0.826],
         [1.065],
         [0.888],
         [0.707],
         [0.394],
         [0.880],
         [0.536],
         [0.685]],

        [[0.656],
         [0.790],
         [1.126],
         [0.911],
         [0.844],
         [0.848],
         [1.128],
         [0.878],
         [0.788],
         [1.120]],

        [[0.849],
         [0.545],
         [0.832],
         [0.492],
         [0.877],
         [1.200],
         [1.023],
         [1.281],
         [1.044],
         [0.724]],

        [[0.859],
         [0.656],
         [1.040],
         [0.664],
         [0.858],
         [0.637],
         [1.016],
         [0.879],
         [0.700],
         [0.430]]], device='cuda:0')
b after update for 1 param tensor([[[38.197],
         [30.984],
         [31.724],
         [34.883],
         [34.214],
         [33.337],
         [30.135],
         [37.677],
         [34.383],
         [34.297]],

        [[29.811],
         [36.154],
         [27.624],
         [25.355],
         [32.688],
         [23.323],
         [35.601],
         [23.889],
         [32.991],
         [38.034]],

        [[31.271],
         [30.998],
         [38.328],
         [36.470],
         [37.758],
         [34.016],
         [35.537],
         [30.866],
         [37.081],
         [34.857]],

        [[30.756],
         [30.068],
         [25.415],
         [28.975],
         [30.397],
         [34.384],
         [37.925],
         [29.683],
         [35.316],
         [36.107]],

        [[33.404],
         [35.141],
         [33.058],
         [33.274],
         [30.722],
         [35.049],
         [32.223],
         [37.152],
         [24.940],
         [35.334]],

        [[32.250],
         [26.872],
         [35.659],
         [29.729],
         [37.737],
         [28.443],
         [30.705],
         [37.418],
         [35.386],
         [35.454]],

        [[31.708],
         [32.593],
         [36.861],
         [32.042],
         [25.489],
         [28.277],
         [34.534],
         [31.869],
         [32.804],
         [33.722]],

        [[32.961],
         [29.742],
         [26.431],
         [34.781],
         [35.215],
         [34.926],
         [38.103],
         [30.422],
         [31.972],
         [29.789]],

        [[16.447],
         [33.308],
         [33.331],
         [37.850],
         [34.562],
         [30.827],
         [23.006],
         [34.397],
         [26.851],
         [30.347]],

        [[29.710],
         [32.606],
         [38.914],
         [34.996],
         [33.698],
         [33.766],
         [38.957],
         [34.369],
         [32.555],
         [38.807]],

        [[33.797],
         [27.062],
         [33.444],
         [25.732],
         [34.346],
         [40.166],
         [37.101],
         [41.510],
         [37.474],
         [31.211]],

        [[33.982],
         [29.708],
         [37.396],
         [29.893],
         [33.968],
         [29.266],
         [36.965],
         [34.387],
         [30.685],
         [24.042]]], device='cuda:0')
clipping threshold 0.31299152240770345
a after update for 1 param tensor([[-0.010],
        [-0.005],
        [-0.011],
        [ 0.016],
        [ 0.012],
        [-0.017],
        [ 0.009],
        [ 0.006],
        [ 0.001],
        [-0.016],
        [-0.003],
        [-0.011]], device='cuda:0')
s after update for 1 param tensor([[1.452],
        [0.939],
        [1.106],
        [0.936],
        [0.909],
        [1.157],
        [1.198],
        [0.975],
        [0.672],
        [1.231],
        [0.898],
        [1.020]], device='cuda:0')
b after update for 1 param tensor([[44.193],
        [35.539],
        [38.577],
        [35.476],
        [34.972],
        [39.456],
        [40.144],
        [36.204],
        [30.057],
        [40.692],
        [34.745],
        [37.047]], device='cuda:0')
clipping threshold 0.31299152240770345
||w||^2 0.7371113517719577
exp ma of ||w||^2 0.43699209773128955
||w|| 0.8585518923000274
exp ma of ||w|| 0.6211779348684654
||w||^2 0.17051419068465534
exp ma of ||w||^2 0.6379125345520937
||w|| 0.4129336395653124
exp ma of ||w|| 0.7470608464286895
cuda
Objective function 9.27 = squared loss an data 8.10 + 0.5*rho*h**2 0.110485 + alpha*h 0.528706 + L2reg 0.47 + L1reg 0.06 ; SHD = 16 ; DAG True
Proportion of microbatches that were clipped  0.7591496557555261
iteration 1 in inner loop, alpha 3.5567001525182107 rho 10.0 h 0.1486507713832168
1692
cuda
Objective function 10.26 = squared loss an data 8.10 + 0.5*rho*h**2 1.104853 + alpha*h 0.528706 + L2reg 0.47 + L1reg 0.06 ; SHD = 16 ; DAG True
||w||^2 19023298054.237587
exp ma of ||w||^2 349307487.49265003
||w|| 137924.97255478278
exp ma of ||w|| 2634.1750694658303
||w||^2 5274602708.295597
exp ma of ||w||^2 8510225530.437241
||w|| 72626.46011128173
exp ma of ||w|| 81064.97236285146
||w||^2 9230.489256665975
exp ma of ||w||^2 561002.4397168343
||w|| 96.07543524057527
exp ma of ||w|| 289.7054023632527
||w||^2 0.25358895697125755
exp ma of ||w||^2 1.0950823471394187
||w|| 0.5035761679937382
exp ma of ||w|| 0.3257167185235515
||w||^2 0.23307902874064557
exp ma of ||w||^2 0.6260309819141979
||w|| 0.48278258951690206
exp ma of ||w|| 0.3386485500661022
||w||^2 0.08944618958236632
exp ma of ||w||^2 0.2113278285655817
||w|| 0.29907555831656707
exp ma of ||w|| 0.38581982665696
||w||^2 0.17887487160463073
exp ma of ||w||^2 0.30004107849179096
||w|| 0.42293601360564076
exp ma of ||w|| 0.5168056443935551
||w||^2 0.5765847263395975
exp ma of ||w||^2 0.4316011953998712
||w|| 0.7593317630256208
exp ma of ||w|| 0.6167414806168231
||w||^2 0.5667591466088073
exp ma of ||w||^2 0.6699489159857498
||w|| 0.7528340764131279
exp ma of ||w|| 0.7738840103538601
cuda
Objective function 9.55 = squared loss an data 8.50 + 0.5*rho*h**2 0.229044 + alpha*h 0.240725 + L2reg 0.53 + L1reg 0.06 ; SHD = 16 ; DAG True
Proportion of microbatches that were clipped  0.7611593493946435
iteration 2 in inner loop, alpha 3.5567001525182107 rho 100.0 h 0.06768220705519923
1692
cuda
Objective function 11.62 = squared loss an data 8.50 + 0.5*rho*h**2 2.290441 + alpha*h 0.240725 + L2reg 0.53 + L1reg 0.06 ; SHD = 16 ; DAG True
||w||^2 50269464534.0906
exp ma of ||w||^2 7287639188.1881275
||w|| 224208.52912877913
exp ma of ||w|| 29731.36820868167
||w||^2 0.2245099378316635
exp ma of ||w||^2 181.9069886688366
||w|| 0.4738247965563469
exp ma of ||w|| 0.725497678582982
||w||^2 0.28843879778847664
exp ma of ||w||^2 34.42583811518868
||w|| 0.5370649846978265
exp ma of ||w|| 0.4402933896787791
||w||^2 0.08625563332562954
exp ma of ||w||^2 9.409889253581163
||w|| 0.2936930937656341
exp ma of ||w|| 0.36221009026144824
||w||^2 0.11806317860274647
exp ma of ||w||^2 0.43934014100496055
||w|| 0.34360322845215885
exp ma of ||w|| 0.3405513891398045
||w||^2 0.05491483493110984
exp ma of ||w||^2 0.17380223164140737
||w|| 0.23433914511047838
exp ma of ||w|| 0.3712807088620286
||w||^2 0.07160140383838003
exp ma of ||w||^2 0.20468746470522745
||w|| 0.2675843863875096
exp ma of ||w|| 0.41894865742381016
||w||^2 0.23410172239638047
exp ma of ||w||^2 0.23959229515313063
||w|| 0.48384059606070723
exp ma of ||w|| 0.4572901229793887
||w||^2 0.22300851224026622
exp ma of ||w||^2 0.2673706650164672
||w|| 0.47223777087423474
exp ma of ||w|| 0.485448686176938
||w||^2 0.24228237284391424
exp ma of ||w||^2 0.3163464255746793
||w|| 0.49222187359351904
exp ma of ||w|| 0.5270574949057986
||w||^2 0.3270737181820894
exp ma of ||w||^2 0.39794545601804693
||w|| 0.5719035916849006
exp ma of ||w|| 0.5910746842921475
||w||^2 0.40258884590471
exp ma of ||w||^2 0.41608672170139166
||w|| 0.6344988935409659
exp ma of ||w|| 0.6084595737338495
||w||^2 0.545909353646313
exp ma of ||w||^2 0.4761039905021747
||w|| 0.7388567883198428
exp ma of ||w|| 0.6487916701879917
||w||^2 0.5794733857786311
exp ma of ||w||^2 0.5043030313089709
||w|| 0.7612314928972862
exp ma of ||w|| 0.6693759732687599
||w||^2 0.3663012846878268
exp ma of ||w||^2 0.7115978521204686
||w|| 0.6052282913808861
exp ma of ||w|| 0.7812795956513986
||w||^2 0.4150242211928633
exp ma of ||w||^2 0.7033990489911566
||w|| 0.6442237353535364
exp ma of ||w|| 0.7850380122032341
||w||^2 0.39725607496924653
exp ma of ||w||^2 0.6936278096316849
||w|| 0.6302825358275814
exp ma of ||w|| 0.7789621781236665
cuda
Objective function 9.94 = squared loss an data 9.12 + 0.5*rho*h**2 0.160125 + alpha*h 0.063649 + L2reg 0.55 + L1reg 0.05 ; SHD = 15 ; DAG True
Proportion of microbatches that were clipped  0.7578219742905651
iteration 3 in inner loop, alpha 3.5567001525182107 rho 1000.0 h 0.017895557723599964
iteration 3 in outer loop, alpha = 21.452257876118175, rho = 1000.0, h = 0.017895557723599964
cuda
1692
cuda
Objective function 10.26 = squared loss an data 9.12 + 0.5*rho*h**2 0.160125 + alpha*h 0.383900 + L2reg 0.55 + L1reg 0.05 ; SHD = 15 ; DAG True
||w||^2 194541.0823544561
exp ma of ||w||^2 3924284.278863668
||w|| 441.0681153228559
exp ma of ||w|| 863.2287697940625
||w||^2 0.23992275421465195
exp ma of ||w||^2 324.05539613746026
||w|| 0.4898191035623784
exp ma of ||w|| 0.7723541019954644
||w||^2 0.1514113086901127
exp ma of ||w||^2 0.19918440114637379
||w|| 0.38911606069412336
exp ma of ||w|| 0.4218421616196212
||w||^2 0.10934047747327238
exp ma of ||w||^2 0.2208406903623749
||w|| 0.3306667166094471
exp ma of ||w|| 0.43656408187223933
||w||^2 0.17073059855816605
exp ma of ||w||^2 0.26468371488454395
||w|| 0.41319559358512775
exp ma of ||w|| 0.4830796350322547
||w||^2 0.6277982526372178
exp ma of ||w||^2 0.295635045505922
||w|| 0.7923372089187897
exp ma of ||w|| 0.511150820041461
||w||^2 0.6073460959500545
exp ma of ||w||^2 0.4117247446918907
||w|| 0.7793241276580974
exp ma of ||w|| 0.5963986249206186
||w||^2 0.7871917491981769
exp ma of ||w||^2 0.6228099691445955
||w|| 0.8872382708146538
exp ma of ||w|| 0.7357819414195337
cuda
Objective function 10.19 = squared loss an data 9.32 + 0.5*rho*h**2 0.048764 + alpha*h 0.211855 + L2reg 0.55 + L1reg 0.05 ; SHD = 11 ; DAG True
Proportion of microbatches that were clipped  0.7576675960722512
iteration 1 in inner loop, alpha 21.452257876118175 rho 1000.0 h 0.00987566807870266
1692
cuda
Objective function 10.63 = squared loss an data 9.32 + 0.5*rho*h**2 0.487644 + alpha*h 0.211855 + L2reg 0.55 + L1reg 0.05 ; SHD = 11 ; DAG True
||w||^2 2675787482.953729
exp ma of ||w||^2 6751793423.198123
||w|| 51728.01448880219
exp ma of ||w|| 69753.62439476878
||w||^2 0.3946449156915965
exp ma of ||w||^2 44.657373892560194
||w|| 0.6282077010763212
exp ma of ||w|| 0.5224386372191707
||w||^2 0.4387567019001247
exp ma of ||w||^2 1.1909635267027843
||w|| 0.6623871238936674
exp ma of ||w|| 0.3837987320344354
||w||^2 0.2072733079074922
exp ma of ||w||^2 0.16850632623187908
||w|| 0.4552727840619206
exp ma of ||w|| 0.3822609572939793
||w||^2 0.06955197733332429
exp ma of ||w||^2 0.195495513379582
||w|| 0.2637270887363001
exp ma of ||w|| 0.41499695342100174
||w||^2 0.5737134134613597
exp ma of ||w||^2 0.28555027030127683
||w|| 0.7574387192779095
exp ma of ||w|| 0.5009847376231037
||w||^2 0.22356361408913153
exp ma of ||w||^2 0.3112165572802669
||w|| 0.4728251411347873
exp ma of ||w|| 0.5234630321998283
||w||^2 0.6076210551725393
exp ma of ||w||^2 0.5225513474033971
||w|| 0.7795005164671408
exp ma of ||w|| 0.6780266791553726
||w||^2 0.45117828244502256
exp ma of ||w||^2 0.5393647093028302
||w|| 0.6716980589856
exp ma of ||w|| 0.6849995294705132
cuda
Objective function 10.24 = squared loss an data 9.49 + 0.5*rho*h**2 0.072045 + alpha*h 0.081431 + L2reg 0.55 + L1reg 0.05 ; SHD = 14 ; DAG True
Proportion of microbatches that were clipped  0.7588522588522588
iteration 2 in inner loop, alpha 21.452257876118175 rho 10000.0 h 0.003795916778082997
iteration 4 in outer loop, alpha = 59.41142565694815, rho = 10000.0, h = 0.003795916778082997
cuda
1692
cuda
Objective function 10.39 = squared loss an data 9.49 + 0.5*rho*h**2 0.072045 + alpha*h 0.225521 + L2reg 0.55 + L1reg 0.05 ; SHD = 14 ; DAG True
||w||^2 8529039074.523877
exp ma of ||w||^2 30539054799.000473
||w|| 92352.79678777399
exp ma of ||w|| 129445.18876067043
||w||^2 188243524.68669713
exp ma of ||w||^2 2821044675.2530646
||w|| 13720.186758448193
exp ma of ||w|| 36871.00583073588
||w||^2 0.14291711215293318
exp ma of ||w||^2 0.16938316749602822
||w|| 0.3780437966068656
exp ma of ||w|| 0.38698364898143456
v before min max tensor([[ 1.200e+01, -1.576e-01,  3.990e-01,  ..., -2.245e-02, -2.738e-01,
         -9.465e-02],
        [-8.808e-01, -7.132e-02, -5.094e-01,  ...,  9.053e-02,  8.722e-01,
         -4.219e-01],
        [-9.005e-01, -2.332e-01, -5.063e-01,  ...,  4.659e-02, -1.947e-01,
         -2.855e-01],
        ...,
        [-2.466e-01, -4.365e-01, -3.448e-01,  ...,  6.200e-02,  6.174e-05,
         -1.444e+00],
        [-6.268e-01, -1.391e-01, -1.886e-01,  ..., -2.552e-01, -2.584e-01,
         -6.662e-01],
        [-3.870e-01, -3.142e-01, -2.359e-01,  ..., -4.144e-01, -1.168e-01,
         -8.816e-01]], device='cuda:0')
v tensor([[1.000e+01, 1.000e-12, 3.990e-01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 9.053e-02, 8.722e-01,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 4.659e-02, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 6.200e-02, 6.174e-05,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([-0.085, -0.098, -0.314,  0.093,  0.641,  0.017, -0.321, -0.382, -0.038,
        -0.263, -0.412,  0.480,  0.757, -0.487, -0.043, -0.187, -0.096, -0.348,
        -0.295, -0.296, -0.348,  2.327,  0.266,  0.830,  0.506, -0.358, -0.128,
        -0.222,  0.295,  0.052, -0.349, -0.241,  0.724, -0.035, -0.422, -0.360,
        -0.066, -0.155, -0.137,  0.180, -0.424, -0.234,  0.179,  0.293, -0.221,
         0.310, -0.118, -0.515,  0.151, -0.264, -0.130,  0.883, -0.339, -0.283,
        -0.381,  1.493,  0.308, -0.089, -0.167, -0.084,  1.100,  0.010, -0.217,
        -0.450,  0.207, -0.188,  0.370, -0.307, -0.477, -0.408,  1.417, -0.199,
        -0.404,  0.175, -0.282, -0.223, -0.417, -0.294, -0.321, -0.248,  0.077,
         0.050,  0.638, -0.353, -0.089, -0.065, -0.168, -0.233, -0.247, -0.030,
        -0.267, -0.374, -0.161,  1.504, -0.080, -0.102, -0.094, -0.316, -0.214,
        -0.232,  0.809,  0.021,  0.128, -0.174, -0.026,  0.171, -0.225, -0.204,
        -0.387, -0.321, -0.509, -0.374, -0.496, -0.014, -0.186, -0.316, -0.203,
        -0.087, -0.241, -0.382], device='cuda:0')
v tensor([1.000e-12, 1.000e-12, 1.000e-12, 9.251e-02, 6.414e-01, 1.743e-02,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 4.799e-01,
        7.568e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 2.327e+00, 2.660e-01, 8.300e-01,
        5.055e-01, 1.000e-12, 1.000e-12, 1.000e-12, 2.950e-01, 5.226e-02,
        1.000e-12, 1.000e-12, 7.235e-01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.803e-01, 1.000e-12, 1.000e-12,
        1.793e-01, 2.934e-01, 1.000e-12, 3.104e-01, 1.000e-12, 1.000e-12,
        1.506e-01, 1.000e-12, 1.000e-12, 8.825e-01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.493e+00, 3.075e-01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.100e+00, 1.041e-02, 1.000e-12, 1.000e-12, 2.068e-01, 1.000e-12,
        3.701e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.417e+00, 1.000e-12,
        1.000e-12, 1.752e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 7.745e-02, 4.985e-02, 6.381e-01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.504e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 8.093e-01, 2.101e-02,
        1.275e-01, 1.000e-12, 1.000e-12, 1.710e-01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-2.315e-01],
         [ 1.101e+00],
         [ 6.225e-01],
         [ 1.621e+00],
         [-4.308e-01],
         [-6.107e-01],
         [ 1.472e+00],
         [ 1.165e+00],
         [ 6.150e-02],
         [-4.014e-01]],

        [[ 1.734e+00],
         [-6.923e-02],
         [ 6.150e-01],
         [ 3.551e-01],
         [-1.961e-01],
         [-1.198e-03],
         [-6.180e-01],
         [ 1.995e+00],
         [-1.352e-01],
         [ 4.868e-01]],

        [[ 3.060e-01],
         [ 7.465e-01],
         [-5.563e-01],
         [ 4.483e-01],
         [ 5.866e-01],
         [ 1.608e+00],
         [-3.205e-01],
         [-2.394e-01],
         [-1.491e-01],
         [ 1.096e+00]],

        [[ 4.406e-03],
         [ 7.331e-02],
         [-3.737e-01],
         [-8.409e-02],
         [-1.395e-01],
         [-3.279e-01],
         [ 2.558e-01],
         [-4.086e-01],
         [ 7.511e-01],
         [-3.439e-01]],

        [[-1.649e-01],
         [-3.922e-01],
         [-3.706e-01],
         [-3.792e-01],
         [ 2.141e-01],
         [-9.177e-01],
         [-1.369e-01],
         [-6.086e-01],
         [-4.098e-01],
         [-3.967e-01]],

        [[-1.582e-01],
         [-3.344e-01],
         [-1.042e-01],
         [-5.184e-01],
         [-1.629e-01],
         [ 1.586e-01],
         [-4.161e-01],
         [-1.253e-01],
         [-1.937e-01],
         [-4.004e-01]],

        [[-5.103e-01],
         [ 8.832e-01],
         [-5.126e-01],
         [ 3.383e-01],
         [-8.383e-02],
         [ 5.843e-01],
         [-2.524e-02],
         [ 4.889e-02],
         [-6.127e-01],
         [-4.178e-01]],

        [[-3.883e-01],
         [-3.790e-02],
         [-1.385e-01],
         [ 8.902e-01],
         [ 4.627e-01],
         [-3.362e-01],
         [-2.904e-01],
         [-6.490e-01],
         [-8.049e-02],
         [-2.373e-01]],

        [[ 4.262e-01],
         [ 8.923e-01],
         [ 1.011e+00],
         [ 5.052e-02],
         [ 9.838e-02],
         [-5.133e-01],
         [-2.777e-01],
         [-2.056e-01],
         [-4.148e-01],
         [-1.954e-01]],

        [[ 5.950e-01],
         [-1.460e-01],
         [-5.593e-01],
         [ 2.956e-01],
         [ 2.177e-01],
         [-4.962e-01],
         [ 5.554e+00],
         [-5.968e-01],
         [ 6.771e-01],
         [-1.341e-01]],

        [[ 5.313e+00],
         [ 8.654e-02],
         [ 1.166e-01],
         [-2.241e-01],
         [ 4.490e-01],
         [-9.085e-02],
         [ 5.320e-01],
         [ 1.428e-01],
         [ 2.962e-02],
         [ 1.577e+00]],

        [[-1.262e-01],
         [-5.612e-01],
         [-4.796e-01],
         [-3.934e-01],
         [-4.520e-01],
         [ 1.385e-01],
         [-4.515e-01],
         [-8.573e-01],
         [-1.911e-02],
         [-2.265e-01]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.101e+00],
         [6.225e-01],
         [1.621e+00],
         [1.000e-12],
         [1.000e-12],
         [1.472e+00],
         [1.165e+00],
         [6.150e-02],
         [1.000e-12]],

        [[1.734e+00],
         [1.000e-12],
         [6.150e-01],
         [3.551e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.995e+00],
         [1.000e-12],
         [4.868e-01]],

        [[3.060e-01],
         [7.465e-01],
         [1.000e-12],
         [4.483e-01],
         [5.866e-01],
         [1.608e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.096e+00]],

        [[4.406e-03],
         [7.331e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.558e-01],
         [1.000e-12],
         [7.511e-01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.141e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.586e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [8.832e-01],
         [1.000e-12],
         [3.383e-01],
         [1.000e-12],
         [5.843e-01],
         [1.000e-12],
         [4.889e-02],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [8.902e-01],
         [4.627e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[4.262e-01],
         [8.923e-01],
         [1.011e+00],
         [5.052e-02],
         [9.838e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[5.950e-01],
         [1.000e-12],
         [1.000e-12],
         [2.956e-01],
         [2.177e-01],
         [1.000e-12],
         [5.554e+00],
         [1.000e-12],
         [6.771e-01],
         [1.000e-12]],

        [[5.313e+00],
         [8.654e-02],
         [1.166e-01],
         [1.000e-12],
         [4.490e-01],
         [1.000e-12],
         [5.320e-01],
         [1.428e-01],
         [2.962e-02],
         [1.577e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.385e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[-0.051],
        [ 1.057],
        [-0.645],
        [-0.477],
        [ 0.801],
        [ 0.736],
        [-0.838],
        [-0.040],
        [ 0.264],
        [ 5.630],
        [ 0.384],
        [-0.751]], device='cuda:0')
v tensor([[1.000e-12],
        [1.057e+00],
        [1.000e-12],
        [1.000e-12],
        [8.014e-01],
        [7.357e-01],
        [1.000e-12],
        [1.000e-12],
        [2.642e-01],
        [5.630e+00],
        [3.838e-01],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 0.000, -0.009, -0.005,  ...,  0.002,  0.038,  0.002],
        [ 0.002, -0.021, -0.005,  ..., -0.007, -0.003,  0.003],
        [ 0.003,  0.012, -0.003,  ..., -0.002,  0.001, -0.002],
        ...,
        [ 0.002, -0.016, -0.006,  ..., -0.002, -0.011, -0.008],
        [ 0.017,  0.005, -0.003,  ...,  0.008, -0.014,  0.006],
        [ 0.001, -0.010,  0.006,  ...,  0.006, -0.001, -0.002]],
       device='cuda:0')
s after update for 1 param tensor([[2.254, 0.496, 0.563,  ..., 0.518, 0.333, 0.296],
        [1.152, 0.418, 0.740,  ..., 0.542, 0.571, 0.517],
        [1.119, 0.493, 0.610,  ..., 0.259, 0.323, 0.367],
        ...,
        [0.559, 0.555, 0.415,  ..., 0.777, 0.608, 2.099],
        [0.754, 0.418, 0.486,  ..., 0.416, 0.392, 1.746],
        [0.565, 0.546, 0.716,  ..., 0.553, 0.335, 1.193]], device='cuda:0')
b after update for 1 param tensor([[49.933, 23.432, 24.947,  ..., 23.949, 19.195, 18.105],
        [35.703, 21.511, 28.617,  ..., 24.485, 25.123, 23.920],
        [35.187, 23.351, 25.984,  ..., 16.915, 18.890, 20.136],
        ...,
        [24.863, 24.778, 21.415,  ..., 29.324, 25.926, 48.187],
        [28.881, 21.515, 23.174,  ..., 21.444, 20.831, 43.943],
        [24.990, 24.570, 28.145,  ..., 24.743, 19.249, 36.324]],
       device='cuda:0')
clipping threshold 0.4559313250212204
a after update for 1 param tensor([ 1.084e-02, -5.023e-03,  1.574e-02, -1.916e-03, -1.025e-02,  8.620e-03,
        -1.905e-02, -2.879e-03, -1.227e-02,  9.713e-04, -2.979e-04, -5.712e-03,
         1.187e-03,  1.111e-02, -4.995e-03, -9.527e-04, -4.126e-03, -9.410e-03,
        -5.857e-03, -9.564e-03, -1.032e-02, -1.139e-02,  8.029e-03,  1.200e-02,
        -2.668e-03,  3.522e-03,  1.045e-02, -5.024e-03,  2.137e-02, -1.568e-03,
        -1.339e-03, -1.320e-02, -4.483e-03, -4.428e-03, -4.710e-03,  7.628e-03,
         1.314e-02, -2.986e-03,  1.218e-02, -2.436e-03,  8.595e-03, -1.850e-02,
        -1.768e-02,  1.370e-02, -1.577e-03, -3.178e-03,  6.394e-05, -1.314e-02,
         4.984e-02,  4.509e-03, -1.465e-02, -1.916e-02,  1.046e-02,  6.374e-04,
         1.066e-02,  2.203e-02, -3.201e-02,  3.176e-03,  7.272e-04, -1.603e-03,
        -2.179e-03,  4.118e-03, -6.534e-03, -2.179e-03, -2.059e-02,  5.514e-04,
        -1.582e-02,  2.271e-02,  4.583e-03,  3.515e-03, -2.166e-02,  3.374e-03,
        -1.042e-02,  7.499e-03, -2.181e-03, -5.792e-03, -2.145e-05,  4.091e-03,
         1.079e-03, -2.854e-04, -2.800e-03,  9.121e-03, -2.511e-02, -1.215e-02,
         5.001e-03,  7.508e-03, -1.893e-03,  1.221e-02,  7.388e-03, -5.635e-03,
        -4.655e-03, -9.348e-03, -3.903e-03, -4.088e-04,  8.244e-03,  5.428e-03,
         1.971e-02, -5.580e-03,  8.654e-03,  1.063e-02, -7.497e-03, -1.145e-02,
        -6.640e-03,  1.600e-02, -1.259e-03,  3.844e-03,  4.601e-03, -1.561e-03,
         5.236e-03, -7.831e-03,  3.206e-03, -4.530e-03, -1.351e-02,  6.572e-03,
        -1.198e-03, -4.975e-03,  1.997e-03, -2.739e-04,  1.496e-02, -6.679e-03],
       device='cuda:0')
s after update for 1 param tensor([0.149, 0.125, 0.391, 0.456, 0.857, 0.550, 0.492, 0.470, 0.323, 0.372,
        0.561, 0.421, 0.484, 0.638, 0.344, 0.276, 0.416, 0.465, 0.395, 0.360,
        0.491, 0.780, 0.524, 0.529, 0.513, 0.434, 0.315, 0.320, 0.536, 0.314,
        0.425, 0.296, 0.321, 0.244, 0.547, 0.537, 0.367, 0.395, 0.408, 0.665,
        0.516, 0.447, 0.420, 0.475, 0.437, 0.370, 0.487, 0.656, 0.454, 0.419,
        0.403, 0.496, 0.436, 0.358, 0.522, 0.483, 0.419, 0.174, 0.221, 0.242,
        0.561, 0.696, 0.273, 0.544, 0.386, 0.274, 0.443, 0.397, 0.588, 0.532,
        0.490, 0.265, 0.532, 0.333, 0.341, 0.309, 0.566, 0.358, 0.387, 0.347,
        0.269, 0.290, 0.495, 0.448, 0.335, 0.538, 0.202, 0.452, 0.297, 0.315,
        0.332, 0.575, 0.210, 0.791, 0.324, 0.199, 0.370, 0.406, 0.505, 0.448,
        0.620, 0.417, 0.364, 0.288, 0.366, 0.348, 0.398, 0.353, 0.477, 0.391,
        0.772, 0.457, 0.627, 0.391, 0.267, 0.381, 0.585, 0.414, 0.418, 0.542],
       device='cuda:0')
b after update for 1 param tensor([12.836, 11.754, 20.790, 22.460, 30.786, 24.671, 23.334, 22.800, 18.888,
        20.272, 24.909, 21.577, 23.139, 26.564, 19.496, 17.472, 21.458, 22.686,
        20.891, 19.947, 23.300, 29.375, 24.083, 24.200, 23.818, 21.903, 18.662,
        18.828, 24.354, 18.622, 21.682, 18.083, 18.850, 16.424, 24.599, 24.366,
        20.156, 20.916, 21.253, 27.112, 23.883, 22.236, 21.564, 22.910, 21.977,
        20.243, 23.213, 26.932, 22.400, 21.523, 21.101, 23.413, 21.959, 19.910,
        24.029, 23.121, 21.539, 13.876, 15.645, 16.366, 24.917, 27.751, 17.371,
        24.533, 20.675, 17.407, 22.144, 20.956, 25.508, 24.259, 23.283, 17.133,
        24.254, 19.179, 19.430, 18.488, 25.016, 19.892, 20.686, 19.591, 17.240,
        17.916, 23.394, 22.270, 19.245, 24.403, 14.956, 22.354, 18.126, 18.666,
        19.159, 25.227, 15.253, 29.580, 18.945, 14.827, 20.230, 21.179, 23.636,
        22.270, 26.185, 21.486, 20.062, 17.861, 20.112, 19.611, 20.987, 19.759,
        22.971, 20.805, 29.220, 22.475, 26.340, 20.796, 17.173, 20.531, 25.444,
        21.402, 21.506, 24.480], device='cuda:0')
clipping threshold 0.4559313250212204
a after update for 1 param tensor([[[-8.695e-03],
         [-7.478e-04],
         [-2.949e-03],
         [ 3.875e-04],
         [ 2.336e-03],
         [ 3.047e-02],
         [ 9.164e-03],
         [-9.366e-03],
         [-6.068e-04],
         [ 7.530e-04]],

        [[-5.961e-03],
         [ 1.056e-02],
         [ 9.172e-04],
         [-1.747e-03],
         [ 1.563e-02],
         [-1.244e-02],
         [ 4.677e-03],
         [ 6.699e-03],
         [-1.203e-02],
         [ 9.810e-03]],

        [[-2.504e-02],
         [ 1.474e-02],
         [-1.539e-02],
         [ 1.639e-02],
         [-8.380e-03],
         [-1.883e-02],
         [ 8.383e-03],
         [ 8.449e-03],
         [ 4.929e-03],
         [ 4.344e-03]],

        [[ 1.214e-02],
         [-3.138e-04],
         [ 4.996e-03],
         [ 5.211e-03],
         [ 2.840e-03],
         [ 4.747e-03],
         [-5.627e-03],
         [ 2.220e-03],
         [ 2.549e-02],
         [ 8.720e-04]],

        [[-9.856e-03],
         [-3.942e-03],
         [-6.039e-03],
         [-1.945e-03],
         [ 1.109e-02],
         [ 3.751e-04],
         [-1.361e-02],
         [ 3.267e-03],
         [ 1.715e-02],
         [ 7.954e-03]],

        [[-2.541e-03],
         [-1.069e-02],
         [ 6.293e-03],
         [-2.428e-04],
         [ 1.227e-03],
         [ 1.901e-02],
         [ 1.735e-03],
         [-9.446e-03],
         [ 4.767e-03],
         [-5.833e-03]],

        [[-3.416e-03],
         [-8.197e-03],
         [-5.181e-03],
         [ 6.558e-05],
         [ 7.180e-03],
         [-5.112e-03],
         [ 2.296e-02],
         [-3.814e-02],
         [ 1.067e-03],
         [-1.324e-03]],

        [[ 9.359e-03],
         [-2.904e-03],
         [-1.693e-03],
         [-3.643e-02],
         [ 1.083e-02],
         [-9.201e-03],
         [ 6.451e-03],
         [-1.042e-02],
         [ 1.012e-03],
         [ 2.876e-03]],

        [[-1.746e-02],
         [-3.437e-03],
         [-5.319e-03],
         [ 2.052e-02],
         [-1.400e-02],
         [ 2.854e-02],
         [-9.242e-05],
         [ 6.870e-03],
         [ 5.213e-03],
         [ 5.931e-04]],

        [[ 2.668e-03],
         [-1.478e-02],
         [-2.981e-03],
         [-2.516e-03],
         [ 4.651e-03],
         [ 1.387e-02],
         [-1.311e-02],
         [ 1.795e-03],
         [ 1.275e-02],
         [ 3.457e-03]],

        [[ 5.168e-03],
         [-8.764e-04],
         [-7.579e-03],
         [-1.624e-03],
         [-4.430e-04],
         [ 1.364e-02],
         [-5.982e-03],
         [ 4.427e-03],
         [-6.013e-03],
         [ 5.374e-03]],

        [[ 1.482e-02],
         [ 1.119e-02],
         [-1.041e-02],
         [ 4.877e-03],
         [ 2.582e-02],
         [ 6.319e-04],
         [-1.405e-03],
         [-5.667e-03],
         [ 6.778e-03],
         [-6.337e-03]]], device='cuda:0')
s after update for 1 param tensor([[[0.784],
         [0.623],
         [0.584],
         [0.709],
         [0.519],
         [0.873],
         [0.709],
         [0.615],
         [0.672],
         [0.489]],

        [[0.588],
         [0.443],
         [0.366],
         [0.310],
         [0.285],
         [0.239],
         [0.744],
         [0.674],
         [0.435],
         [0.612]],

        [[0.764],
         [0.662],
         [0.718],
         [0.618],
         [0.609],
         [0.767],
         [0.746],
         [0.511],
         [0.304],
         [0.665]],

        [[0.991],
         [0.359],
         [0.566],
         [0.527],
         [0.474],
         [0.409],
         [0.575],
         [0.605],
         [0.444],
         [0.414]],

        [[0.410],
         [0.543],
         [0.586],
         [0.456],
         [0.478],
         [1.158],
         [0.619],
         [0.737],
         [0.581],
         [0.702]],

        [[0.489],
         [0.407],
         [0.373],
         [0.623],
         [0.287],
         [0.540],
         [0.500],
         [0.624],
         [0.420],
         [0.484]],

        [[0.722],
         [0.665],
         [0.656],
         [0.580],
         [0.723],
         [0.712],
         [0.618],
         [0.738],
         [0.799],
         [0.669]],

        [[0.489],
         [0.592],
         [0.529],
         [0.660],
         [0.542],
         [0.451],
         [0.564],
         [0.800],
         [0.433],
         [0.429]],

        [[0.465],
         [0.593],
         [0.691],
         [0.388],
         [0.324],
         [0.693],
         [0.409],
         [0.477],
         [0.500],
         [0.557]],

        [[0.551],
         [0.495],
         [1.099],
         [0.444],
         [0.501],
         [0.679],
         [1.259],
         [0.751],
         [0.671],
         [0.420]],

        [[0.954],
         [0.595],
         [0.371],
         [0.308],
         [0.384],
         [0.306],
         [0.595],
         [0.344],
         [0.434],
         [0.735]],

        [[0.538],
         [0.706],
         [0.775],
         [0.482],
         [0.640],
         [0.539],
         [0.638],
         [1.249],
         [0.804],
         [0.533]]], device='cuda:0')
b after update for 1 param tensor([[[29.451],
         [26.260],
         [25.414],
         [28.008],
         [23.953],
         [31.072],
         [27.999],
         [26.085],
         [27.269],
         [23.268]],

        [[25.495],
         [22.147],
         [20.131],
         [18.507],
         [17.767],
         [16.250],
         [28.693],
         [27.312],
         [21.945],
         [26.022]],

        [[29.062],
         [27.066],
         [28.179],
         [26.141],
         [25.954],
         [29.137],
         [28.729],
         [23.786],
         [18.340],
         [27.115]],

        [[33.101],
         [19.927],
         [25.014],
         [24.145],
         [22.908],
         [21.260],
         [25.228],
         [25.870],
         [22.157],
         [21.402]],

        [[21.290],
         [24.511],
         [25.458],
         [22.457],
         [22.989],
         [35.797],
         [26.160],
         [28.548],
         [25.354],
         [27.861]],

        [[23.264],
         [21.227],
         [20.310],
         [26.256],
         [17.819],
         [24.449],
         [23.526],
         [26.274],
         [21.559],
         [23.134]],

        [[28.259],
         [27.119],
         [26.936],
         [25.320],
         [28.282],
         [28.059],
         [26.140],
         [28.578],
         [29.738],
         [27.207]],

        [[23.268],
         [25.591],
         [24.201],
         [27.026],
         [24.477],
         [22.339],
         [24.981],
         [29.756],
         [21.879],
         [21.785]],

        [[22.687],
         [25.603],
         [27.647],
         [20.709],
         [18.940],
         [27.696],
         [21.257],
         [22.972],
         [23.519],
         [24.821]],

        [[24.680],
         [23.398],
         [34.866],
         [22.157],
         [23.546],
         [27.396],
         [37.322],
         [28.815],
         [27.250],
         [21.544]],

        [[32.487],
         [25.646],
         [20.248],
         [18.449],
         [20.612],
         [18.397],
         [25.654],
         [19.519],
         [21.914],
         [28.520]],

        [[24.384],
         [27.940],
         [29.275],
         [23.102],
         [26.604],
         [24.417],
         [26.555],
         [37.176],
         [29.818],
         [24.291]]], device='cuda:0')
clipping threshold 0.4559313250212204
a after update for 1 param tensor([[ 0.002],
        [-0.005],
        [-0.001],
        [ 0.009],
        [ 0.000],
        [ 0.005],
        [ 0.024],
        [ 0.000],
        [ 0.001],
        [ 0.001],
        [-0.024],
        [-0.020]], device='cuda:0')
s after update for 1 param tensor([[1.059],
        [0.672],
        [1.004],
        [0.603],
        [1.061],
        [0.609],
        [1.011],
        [0.656],
        [0.668],
        [1.004],
        [0.749],
        [0.931]], device='cuda:0')
b after update for 1 param tensor([[34.227],
        [27.264],
        [33.329],
        [25.826],
        [34.262],
        [25.954],
        [33.445],
        [26.939],
        [27.182],
        [33.323],
        [28.789],
        [32.090]], device='cuda:0')
clipping threshold 0.4559313250212204
||w||^2 0.5065469217333236
exp ma of ||w||^2 0.5488740419246437
||w|| 0.711721098277495
exp ma of ||w|| 0.6865815860617605
||w||^2 0.6790111892187863
exp ma of ||w||^2 0.4746860374306644
||w|| 0.8240213524046488
exp ma of ||w|| 0.6432180297117782
cuda
Objective function 10.32 = squared loss an data 9.53 + 0.5*rho*h**2 0.032769 + alpha*h 0.152096 + L2reg 0.55 + L1reg 0.05 ; SHD = 15 ; DAG True
Proportion of microbatches that were clipped  0.7590332326283988
iteration 1 in inner loop, alpha 59.41142565694815 rho 10000.0 h 0.002560041706605176
1692
cuda
Objective function 10.61 = squared loss an data 9.53 + 0.5*rho*h**2 0.327691 + alpha*h 0.152096 + L2reg 0.55 + L1reg 0.05 ; SHD = 15 ; DAG True
||w||^2 2204447.6228208463
exp ma of ||w||^2 489840267.99535
||w|| 1484.7382337708038
exp ma of ||w|| 2251.211140104485
||w||^2 68969.81731934908
exp ma of ||w||^2 141057175.41262686
||w|| 262.62105269636913
exp ma of ||w|| 978.901134828171
||w||^2 2157.24974781295
exp ma of ||w||^2 8989645.771264207
||w|| 46.44620272759604
exp ma of ||w|| 118.55897378074353
||w||^2 0.336981696704188
exp ma of ||w||^2 0.48307140293762146
||w|| 0.5805012460832345
exp ma of ||w|| 0.6460585546971814
||w||^2 0.25149249363315196
exp ma of ||w||^2 0.5034973397147726
||w|| 0.5014902727203708
exp ma of ||w|| 0.665927543128978
||w||^2 0.6795518492040685
exp ma of ||w||^2 0.487270323266625
||w|| 0.8243493490044549
exp ma of ||w|| 0.6590929183698092
||w||^2 0.38845565321709563
exp ma of ||w||^2 0.5312881175415802
||w|| 0.6232621063542173
exp ma of ||w|| 0.6771368481606513
cuda
Objective function 10.33 = squared loss an data 9.64 + 0.5*rho*h**2 0.045107 + alpha*h 0.056430 + L2reg 0.53 + L1reg 0.05 ; SHD = 15 ; DAG True
Proportion of microbatches that were clipped  0.757960229352202
iteration 2 in inner loop, alpha 59.41142565694815 rho 100000.0 h 0.0009498114666453006
iteration 5 in outer loop, alpha = 1009.2228923022487, rho = 1000000.0, h = 0.0009498114666453006
Threshold 0.3
[[0.005 0.005 0.265 0.031 0.02  0.041 0.047 0.012 0.004 0.035 0.036 0.035]
 [0.729 0.003 0.299 0.182 0.324 0.066 0.219 0.043 0.002 0.407 0.46  0.686]
 [0.02  0.013 0.005 0.038 0.011 0.005 0.105 0.007 0.004 0.274 0.019 0.049]
 [0.12  0.015 0.091 0.005 0.102 0.034 0.284 0.038 0.003 0.399 0.006 0.133]
 [0.335 0.013 0.369 0.03  0.006 0.018 0.09  0.024 0.007 0.428 0.043 0.132]
 [0.078 0.044 0.365 0.055 0.169 0.001 0.143 0.066 0.019 0.126 0.127 0.147]
 [0.054 0.01  0.023 0.013 0.035 0.018 0.005 0.015 0.004 0.109 0.018 0.275]
 [0.238 0.056 0.411 0.043 0.14  0.029 0.292 0.003 0.022 0.111 0.036 0.223]
 [0.355 1.37  0.265 0.831 0.237 0.15  0.353 0.136 0.002 0.549 1.746 0.401]
 [0.078 0.01  0.022 0.013 0.011 0.021 0.036 0.017 0.004 0.004 0.012 0.129]
 [0.084 0.007 0.176 0.668 0.085 0.016 0.136 0.101 0.001 0.145 0.003 0.451]
 [0.079 0.002 0.051 0.034 0.018 0.011 0.023 0.013 0.002 0.026 0.008 0.003]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.729 0.    0.    0.    0.324 0.    0.    0.    0.    0.407 0.46  0.686]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.399 0.    0.   ]
 [0.335 0.    0.369 0.    0.    0.    0.    0.    0.    0.428 0.    0.   ]
 [0.    0.    0.365 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.411 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.355 1.37  0.    0.831 0.    0.    0.353 0.    0.    0.549 1.746 0.401]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.668 0.    0.    0.    0.    0.    0.    0.    0.451]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]]
{'fdr': 0.35, 'tpr': 0.5416666666666666, 'fpr': 0.16666666666666666, 'f1': 0.5909090909090908, 'shd': 15, 'npred': 20, 'ntrue': 24}
[5.155e-03 2.650e-01 3.136e-02 1.953e-02 4.073e-02 4.670e-02 1.201e-02
 3.813e-03 3.484e-02 3.585e-02 3.531e-02 7.292e-01 2.990e-01 1.823e-01
 3.243e-01 6.629e-02 2.187e-01 4.341e-02 1.967e-03 4.073e-01 4.598e-01
 6.855e-01 1.990e-02 1.307e-02 3.832e-02 1.145e-02 5.493e-03 1.049e-01
 6.729e-03 4.432e-03 2.737e-01 1.942e-02 4.935e-02 1.202e-01 1.471e-02
 9.052e-02 1.017e-01 3.435e-02 2.841e-01 3.788e-02 2.807e-03 3.992e-01
 6.243e-03 1.334e-01 3.351e-01 1.269e-02 3.689e-01 3.047e-02 1.822e-02
 9.033e-02 2.416e-02 6.788e-03 4.282e-01 4.310e-02 1.321e-01 7.784e-02
 4.415e-02 3.647e-01 5.541e-02 1.686e-01 1.434e-01 6.637e-02 1.903e-02
 1.258e-01 1.274e-01 1.466e-01 5.440e-02 9.759e-03 2.340e-02 1.290e-02
 3.503e-02 1.755e-02 1.506e-02 4.398e-03 1.091e-01 1.801e-02 2.751e-01
 2.377e-01 5.639e-02 4.110e-01 4.337e-02 1.404e-01 2.852e-02 2.921e-01
 2.170e-02 1.114e-01 3.597e-02 2.234e-01 3.546e-01 1.370e+00 2.652e-01
 8.306e-01 2.373e-01 1.499e-01 3.525e-01 1.363e-01 5.494e-01 1.746e+00
 4.009e-01 7.826e-02 9.999e-03 2.221e-02 1.323e-02 1.059e-02 2.058e-02
 3.581e-02 1.729e-02 4.228e-03 1.231e-02 1.288e-01 8.423e-02 6.607e-03
 1.763e-01 6.677e-01 8.492e-02 1.600e-02 1.364e-01 1.014e-01 1.215e-03
 1.450e-01 4.510e-01 7.880e-02 1.843e-03 5.146e-02 3.420e-02 1.847e-02
 1.074e-02 2.321e-02 1.347e-02 2.476e-03 2.595e-02 7.772e-03]
[[0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.
 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0.
 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.8391203703703705, 0.7134986293485328)
Iterations 1110
Achieves (23.82233853610087, 1e-05)-DP
