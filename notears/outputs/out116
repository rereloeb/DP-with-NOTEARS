samples  5000  graph  10 30 ER mlp  minibatch size  50  noise  1.0  minibatches per NN training  250 quantile adaptive clipping
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.1229782946562032
iteration 1 in outer loop, alpha = 1.1229782946562032, rho = 1.0, h = 1.1229782946562032
cuda
iteration 1 in inner loop,alpha 1.1229782946562032 rho 1.0 h 0.7586153562268656
iteration 2 in inner loop,alpha 1.1229782946562032 rho 10.0 h 0.35052850700977345
iteration 3 in inner loop,alpha 1.1229782946562032 rho 100.0 h 0.11468940960946838
iteration 2 in outer loop, alpha = 12.591919255603042, rho = 100.0, h = 0.11468940960946838
cuda
iteration 1 in inner loop,alpha 12.591919255603042 rho 100.0 h 0.05177271318199317
iteration 2 in inner loop,alpha 12.591919255603042 rho 1000.0 h 0.015651355822457802
iteration 3 in outer loop, alpha = 28.243275078060844, rho = 1000.0, h = 0.015651355822457802
cuda
iteration 1 in inner loop,alpha 28.243275078060844 rho 1000.0 h 0.0076855114245848455
iteration 2 in inner loop,alpha 28.243275078060844 rho 10000.0 h 0.0014289170876846669
iteration 4 in outer loop, alpha = 42.532445954907516, rho = 10000.0, h = 0.0014289170876846669
cuda
iteration 1 in inner loop,alpha 42.532445954907516 rho 10000.0 h 0.0007810909223238127
iteration 2 in inner loop,alpha 42.532445954907516 rho 100000.0 h 0.0003151968036405606
iteration 5 in outer loop, alpha = 74.05212631896357, rho = 100000.0, h = 0.0003151968036405606
cuda
iteration 1 in inner loop,alpha 74.05212631896357 rho 100000.0 h 0.00018522990915315063
iteration 6 in outer loop, alpha = 259.2820354721142, rho = 1000000.0, h = 0.00018522990915315063
Threshold 0.3
[[0.004 0.    0.364 0.    1.149 0.001 1.808 0.    0.001 0.007]
 [2.231 0.002 1.432 0.    0.876 0.001 0.115 0.107 0.007 2.624]
 [0.003 0.    0.008 0.    2.005 0.    1.923 0.001 0.001 0.   ]
 [1.278 0.405 1.427 0.    0.833 0.433 1.182 0.246 2.708 2.812]
 [0.    0.    0.    0.    0.004 0.    0.    0.    0.    0.   ]
 [0.188 0.005 0.19  0.    0.256 0.001 0.317 0.006 0.01  2.979]
 [0.    0.    0.001 0.    1.625 0.    0.004 0.    0.    0.   ]
 [1.794 0.006 1.34  0.    1.75  0.102 0.282 0.002 0.003 0.104]
 [2.329 0.039 2.28  0.    0.907 0.063 0.591 0.2   0.004 0.308]
 [0.182 0.    2.442 0.    1.743 0.    2.585 0.003 0.004 0.006]]
[[0.    0.    0.364 0.    1.149 0.    1.808 0.    0.    0.   ]
 [2.231 0.    1.432 0.    0.876 0.    0.    0.    0.    2.624]
 [0.    0.    0.    0.    2.005 0.    1.923 0.    0.    0.   ]
 [1.278 0.405 1.427 0.    0.833 0.433 1.182 0.    2.708 2.812]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.317 0.    0.    2.979]
 [0.    0.    0.    0.    1.625 0.    0.    0.    0.    0.   ]
 [1.794 0.    1.34  0.    1.75  0.    0.    0.    0.    0.   ]
 [2.329 0.    2.28  0.    0.907 0.    0.591 0.    0.    0.308]
 [0.    0.    2.442 0.    1.743 0.    2.585 0.    0.    0.   ]]
{'fdr': 0.12903225806451613, 'tpr': 0.9, 'fpr': 0.26666666666666666, 'f1': 0.8852459016393444, 'shd': 7, 'npred': 31, 'ntrue': 30}
[1.795e-04 3.642e-01 4.917e-05 1.149e+00 5.161e-04 1.808e+00 2.461e-04
 6.721e-04 6.706e-03 2.231e+00 1.432e+00 3.532e-04 8.764e-01 1.321e-03
 1.146e-01 1.074e-01 6.766e-03 2.624e+00 3.411e-03 5.099e-05 7.478e-06
 2.005e+00 2.008e-05 1.923e+00 5.668e-04 9.617e-04 3.520e-04 1.278e+00
 4.049e-01 1.427e+00 8.331e-01 4.329e-01 1.182e+00 2.459e-01 2.708e+00
 2.812e+00 1.094e-04 5.460e-06 7.630e-05 1.068e-05 1.073e-05 4.237e-04
 4.310e-05 7.743e-05 1.769e-05 1.880e-01 4.517e-03 1.903e-01 3.254e-04
 2.562e-01 3.170e-01 5.964e-03 1.027e-02 2.979e+00 2.448e-04 4.007e-05
 7.159e-04 3.414e-05 1.625e+00 3.101e-05 8.188e-05 2.185e-05 3.393e-04
 1.794e+00 5.549e-03 1.340e+00 4.765e-04 1.750e+00 1.021e-01 2.817e-01
 3.036e-03 1.036e-01 2.329e+00 3.908e-02 2.280e+00 1.326e-04 9.073e-01
 6.300e-02 5.906e-01 2.004e-01 3.084e-01 1.817e-01 2.283e-04 2.442e+00
 1.453e-04 1.743e+00 1.550e-04 2.585e+00 3.480e-03 4.024e-03]
[[0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [1. 0. 1. 0. 1. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [1. 1. 1. 0. 1. 1. 0. 0. 0. 0.]
 [1. 0. 1. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 1. 0. 1. 0. 0. 0.]]
[0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0.
 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.]
aucroc, aucpr (0.9777777777777779, 0.9684499725816252)
cuda
noise_multiplier  1.0  noise_multiplier_b  2.5  noise_multiplier_delta  1.0206207261596576
cuda
Objective function 461.65 = squared loss an data 284.59 + 0.5*rho*h**2 176.710652 + alpha*h 0.000000 + L2reg 0.19 + L1reg 0.16 ; SHD = 55 ; DAG False
total norm for a microbatch 24.866763195346294 clip 22.175987976330138
total norm for a microbatch 50.68524320208672 clip 29.246005346047827
total norm for a microbatch 61.04986342607678 clip 32.508942099460576
total norm for a microbatch 39.59109503861415 clip 32.1327145610471
total norm for a microbatch 29.910177918253 clip 33.680411464972224
cuda
Objective function 11.13 = squared loss an data 9.21 + 0.5*rho*h**2 1.303324 + alpha*h 0.000000 + L2reg 0.53 + L1reg 0.09 ; SHD = 39 ; DAG False
Proportion of microbatches that were clipped  0.8079064138765631
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 1.6145116534439108
iteration 1 in outer loop, alpha = 1.6145116534439108, rho = 1.0, h = 1.6145116534439108
cuda
noise_multiplier  1.0  noise_multiplier_b  2.5  noise_multiplier_delta  1.0206207261596576
cuda
Objective function 13.74 = squared loss an data 9.21 + 0.5*rho*h**2 1.303324 + alpha*h 2.606648 + L2reg 0.53 + L1reg 0.09 ; SHD = 39 ; DAG False
total norm for a microbatch 69.68518112840472 clip 2.7688643253295933
total norm for a microbatch 60.426038643921665 clip 39.99454064486246
total norm for a microbatch 73.80897596785113 clip 45.15498018832918
total norm for a microbatch 59.24754835626968 clip 43.4042109366524
total norm for a microbatch 28.38340256362464 clip 43.4042109366524
total norm for a microbatch 48.63033840843321 clip 43.620573431070866
total norm for a microbatch 37.717229917103815 clip 44.741330573546506
total norm for a microbatch 41.17454703478849 clip 44.5060704588163
cuda
Objective function 10.98 = squared loss an data 7.27 + 0.5*rho*h**2 0.810838 + alpha*h 2.056000 + L2reg 0.76 + L1reg 0.09 ; SHD = 31 ; DAG False
Proportion of microbatches that were clipped  0.8096708655018285
iteration 1 in inner loop, alpha 1.6145116534439108 rho 1.0 h 1.2734500613481714
noise_multiplier  1.0  noise_multiplier_b  2.5  noise_multiplier_delta  1.0206207261596576
cuda
Objective function 18.28 = squared loss an data 7.27 + 0.5*rho*h**2 8.108375 + alpha*h 2.056000 + L2reg 0.76 + L1reg 0.09 ; SHD = 31 ; DAG False
total norm for a microbatch 114.03946495606836 clip 5.9199640572575865
total norm for a microbatch 59.07163360715992 clip 12.421035186619871
total norm for a microbatch 109.74830410368494 clip 57.5846732614489
total norm for a microbatch 56.541141430079705 clip 61.029125999697854
total norm for a microbatch 62.15208817240123 clip 65.87852458153684
total norm for a microbatch 115.75409848122935 clip 59.80020394198541
total norm for a microbatch 118.97226494713362 clip 60.140664205702166
total norm for a microbatch 74.20693977856541 clip 58.982161836924924
total norm for a microbatch 43.580496155814025 clip 60.8819426016909
total norm for a microbatch 66.8919126989195 clip 62.30591700419327
total norm for a microbatch 48.982058781218875 clip 55.768932880529995
total norm for a microbatch 78.39602482497173 clip 55.5381980947332
cuda
Objective function 11.46 = squared loss an data 8.37 + 0.5*rho*h**2 1.304574 + alpha*h 0.824690 + L2reg 0.89 + L1reg 0.07 ; SHD = 24 ; DAG False
Proportion of microbatches that were clipped  0.8140845070422535
iteration 2 in inner loop, alpha 1.6145116534439108 rho 10.0 h 0.5107982747720747
noise_multiplier  1.0  noise_multiplier_b  2.5  noise_multiplier_delta  1.0206207261596576
cuda
Objective function 23.20 = squared loss an data 8.37 + 0.5*rho*h**2 13.045744 + alpha*h 0.824690 + L2reg 0.89 + L1reg 0.07 ; SHD = 24 ; DAG False
total norm for a microbatch 83.54038235568407 clip 72.13846113154433
total norm for a microbatch 95.49181490256989 clip 71.75232817475657
total norm for a microbatch 37.86641722286724 clip 71.38079748290725
total norm for a microbatch 44.52055679476137 clip 68.22138483820228
total norm for a microbatch 117.73758466531524 clip 66.23871153892294
total norm for a microbatch 71.80989385869611 clip 71.6415450772033
total norm for a microbatch 69.6214352015173 clip 68.9445602428995
total norm for a microbatch 120.22449042258316 clip 72.51723380278236
total norm for a microbatch 86.05900465834426 clip 68.45063152938341
cuda
Objective function 13.32 = squared loss an data 10.47 + 0.5*rho*h**2 1.557259 + alpha*h 0.284929 + L2reg 0.94 + L1reg 0.06 ; SHD = 25 ; DAG False
Proportion of microbatches that were clipped  0.8139723801787165
iteration 3 in inner loop, alpha 1.6145116534439108 rho 100.0 h 0.17647995443030062
iteration 2 in outer loop, alpha = 19.262507096473975, rho = 100.0, h = 0.17647995443030062
cuda
noise_multiplier  1.0  noise_multiplier_b  2.5  noise_multiplier_delta  1.0206207261596576
cuda
Objective function 16.43 = squared loss an data 10.47 + 0.5*rho*h**2 1.557259 + alpha*h 3.399446 + L2reg 0.94 + L1reg 0.06 ; SHD = 25 ; DAG False
total norm for a microbatch 148.6716962181973 clip 6.564687627580317
total norm for a microbatch 87.084713315489 clip 18.164255132124815
total norm for a microbatch 108.11996008656442 clip 50.22478228442539
total norm for a microbatch 73.01701056401396 clip 79.52193432408035
total norm for a microbatch 106.7712907639115 clip 79.52193432408035
total norm for a microbatch 97.31734163504353 clip 72.04422548447128
cuda
Objective function 15.18 = squared loss an data 11.28 + 0.5*rho*h**2 0.629819 + alpha*h 2.161901 + L2reg 1.05 + L1reg 0.06 ; SHD = 13 ; DAG True
Proportion of microbatches that were clipped  0.8152789005658853
iteration 1 in inner loop, alpha 19.262507096473975 rho 100.0 h 0.11223362304574458
noise_multiplier  1.0  noise_multiplier_b  2.5  noise_multiplier_delta  1.0206207261596576
cuda
Objective function 20.85 = squared loss an data 11.28 + 0.5*rho*h**2 6.298193 + alpha*h 2.161901 + L2reg 1.05 + L1reg 0.06 ; SHD = 13 ; DAG True
total norm for a microbatch 96.52353223951877 clip 3.6321249744684736
total norm for a microbatch 82.8240954773756 clip 8.373833671890935
total norm for a microbatch 149.9895464054125 clip 10.839386798130443
total norm for a microbatch 114.3467807277145 clip 88.93687249549158
total norm for a microbatch 115.48662373023019 clip 80.80591157881688
total norm for a microbatch 101.55431116977107 clip 80.90832696858756
total norm for a microbatch 119.01305163589447 clip 83.90844425763242
total norm for a microbatch 80.48122895677974 clip 85.91295706264924
total norm for a microbatch 124.02744132082933 clip 76.77074882520007
total norm for a microbatch 126.96929816970356 clip 82.5258320067373
total norm for a microbatch 125.59679872768798 clip 76.78164819915226
total norm for a microbatch 80.77109467415303 clip 76.78164819915226
total norm for a microbatch 71.0055556169527 clip 78.6813092921571
cuda
Objective function 14.41 = squared loss an data 11.18 + 0.5*rho*h**2 1.129257 + alpha*h 0.915428 + L2reg 1.12 + L1reg 0.06 ; SHD = 16 ; DAG True
Proportion of microbatches that were clipped  0.8180880602935343
iteration 2 in inner loop, alpha 19.262507096473975 rho 1000.0 h 0.04752382285808743
noise_multiplier  1.0  noise_multiplier_b  2.5  noise_multiplier_delta  1.0206207261596576
cuda
Objective function 24.57 = squared loss an data 11.18 + 0.5*rho*h**2 11.292569 + alpha*h 0.915428 + L2reg 1.12 + L1reg 0.06 ; SHD = 16 ; DAG True
total norm for a microbatch 83.71347069897512 clip 16.07818570165579
total norm for a microbatch 93.97745825349313 clip 95.38304582923993
total norm for a microbatch 136.77571843514383 clip 86.47004480339216
total norm for a microbatch 99.85565062822035 clip 90.07614084399661
total norm for a microbatch 99.23339534820556 clip 88.05791884522708
total norm for a microbatch 75.92418909081566 clip 81.71072422130722
total norm for a microbatch 116.34990075480628 clip 87.01724180717368
total norm for a microbatch 130.46974458026733 clip 86.38111060049518
total norm for a microbatch 173.3478040986097 clip 83.95971777398508
total norm for a microbatch 79.74138561329808 clip 84.13728526490411
cuda
Objective function 13.37 = squared loss an data 10.83 + 0.5*rho*h**2 1.042599 + alpha*h 0.278155 + L2reg 1.16 + L1reg 0.07 ; SHD = 22 ; DAG True
Proportion of microbatches that were clipped  0.8206435170436445
iteration 3 in inner loop, alpha 19.262507096473975 rho 10000.0 h 0.014440217758465934
iteration 3 in outer loop, alpha = 163.6646846811333, rho = 10000.0, h = 0.014440217758465934
cuda
noise_multiplier  1.0  noise_multiplier_b  2.5  noise_multiplier_delta  1.0206207261596576
cuda
Objective function 15.46 = squared loss an data 10.83 + 0.5*rho*h**2 1.042599 + alpha*h 2.363354 + L2reg 1.16 + L1reg 0.07 ; SHD = 22 ; DAG True
total norm for a microbatch 123.48075651410603 clip 1.4171834245493617
total norm for a microbatch 112.33269774036934 clip 2.6989633271281956
total norm for a microbatch 101.25589502479728 clip 97.10590993370951
total norm for a microbatch 109.84244259693185 clip 94.39576971076828
total norm for a microbatch 104.02454740878973 clip 89.4657256277673
total norm for a microbatch 170.06390563282503 clip 90.81618096724286
total norm for a microbatch 101.47567379727896 clip 92.84164440877623
total norm for a microbatch 79.39081167959607 clip 80.65587223290802
total norm for a microbatch 138.22088873272347 clip 85.27438342868986
total norm for a microbatch 135.22512381229686 clip 83.76129261277684
total norm for a microbatch 163.25841772715717 clip 79.63588507101746
total norm for a microbatch 111.34341521782483 clip 82.66356283569161
total norm for a microbatch 92.4668810604009 clip 84.8839571249087
cuda
Objective function 14.24 = squared loss an data 10.69 + 0.5*rho*h**2 0.561332 + alpha*h 1.734123 + L2reg 1.18 + L1reg 0.07 ; SHD = 18 ; DAG True
Proportion of microbatches that were clipped  0.8198026106335562
iteration 1 in inner loop, alpha 163.6646846811333 rho 10000.0 h 0.010595587472977286
noise_multiplier  1.0  noise_multiplier_b  2.5  noise_multiplier_delta  1.0206207261596576
cuda
Objective function 19.29 = squared loss an data 10.69 + 0.5*rho*h**2 5.613324 + alpha*h 1.734123 + L2reg 1.18 + L1reg 0.07 ; SHD = 18 ; DAG True
total norm for a microbatch 219.07762518710766 clip 1.840249113357779
total norm for a microbatch 125.84645096836105 clip 2.38210984317952
total norm for a microbatch 189.57541859495797 clip 6.834490206932316
total norm for a microbatch 143.63879218371648 clip 15.686513421710213
total norm for a microbatch 194.41737056632186 clip 31.729833131831846
total norm for a microbatch 167.7829666192138 clip 65.55900525022999
total norm for a microbatch 162.2823914217496 clip 85.77688303304292
total norm for a microbatch 197.9552206443766 clip 144.33933272236894
total norm for a microbatch 170.51552291854316 clip 157.64288643064057
total norm for a microbatch 135.15952300142777 clip 135.84078973214142
total norm for a microbatch 109.92706466448904 clip 107.20985354050285
total norm for a microbatch 138.63112106064372 clip 107.22177180025939
total norm for a microbatch 112.2852829143516 clip 104.73151899192354
total norm for a microbatch 107.96478043383323 clip 103.18480114196457
total norm for a microbatch 162.3736076151936 clip 108.09758495369212
total norm for a microbatch 92.16994739608046 clip 81.24847349085391
total norm for a microbatch 170.7626621130773 clip 89.50492987181782
total norm for a microbatch 85.88383103423085 clip 95.41046865120171
cuda
Objective function 13.01 = squared loss an data 10.29 + 0.5*rho*h**2 0.768724 + alpha*h 0.641734 + L2reg 1.23 + L1reg 0.08 ; SHD = 16 ; DAG True
Proportion of microbatches that were clipped  0.8212196490103374
iteration 2 in inner loop, alpha 163.6646846811333 rho 100000.0 h 0.003921029409795551
iteration 4 in outer loop, alpha = 4084.6940944766843, rho = 1000000.0, h = 0.003921029409795551
Threshold 0.3
[[0.008 0.008 0.078 0.002 0.036 0.013 0.363 0.009 0.004 0.035]
 [0.904 0.01  0.942 0.05  0.887 0.1   0.709 0.683 0.224 0.97 ]
 [0.117 0.007 0.008 0.003 0.045 0.011 0.491 0.026 0.004 0.058]
 [1.266 0.229 1.029 0.007 1.196 0.188 0.97  0.537 1.758 1.519]
 [0.275 0.006 0.155 0.006 0.006 0.018 0.354 0.028 0.007 0.018]
 [0.728 0.043 0.668 0.047 0.348 0.006 0.632 0.341 0.271 0.963]
 [0.024 0.009 0.022 0.006 0.023 0.012 0.006 0.019 0.012 0.013]
 [0.856 0.008 0.412 0.013 0.36  0.025 0.352 0.011 0.104 0.298]
 [1.699 0.028 1.319 0.006 0.911 0.034 0.65  0.086 0.012 0.504]
 [0.219 0.011 0.217 0.008 0.404 0.007 0.714 0.023 0.022 0.01 ]]
[[0.    0.    0.    0.    0.    0.    0.363 0.    0.    0.   ]
 [0.904 0.    0.942 0.    0.887 0.    0.709 0.683 0.    0.97 ]
 [0.    0.    0.    0.    0.    0.    0.491 0.    0.    0.   ]
 [1.266 0.    1.029 0.    1.196 0.    0.97  0.537 1.758 1.519]
 [0.    0.    0.    0.    0.    0.    0.354 0.    0.    0.   ]
 [0.728 0.    0.668 0.    0.348 0.    0.632 0.341 0.    0.963]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.856 0.    0.412 0.    0.36  0.    0.352 0.    0.    0.   ]
 [1.699 0.    1.319 0.    0.911 0.    0.65  0.    0.    0.504]
 [0.    0.    0.    0.    0.404 0.    0.714 0.    0.    0.   ]]
{'fdr': 0.3333333333333333, 'tpr': 0.7333333333333333, 'fpr': 0.7333333333333333, 'f1': 0.6984126984126985, 'shd': 16, 'npred': 33, 'ntrue': 30}
[0.008 0.078 0.002 0.036 0.013 0.363 0.009 0.004 0.035 0.904 0.942 0.05
 0.887 0.1   0.709 0.683 0.224 0.97  0.117 0.007 0.003 0.045 0.011 0.491
 0.026 0.004 0.058 1.266 0.229 1.029 1.196 0.188 0.97  0.537 1.758 1.519
 0.275 0.006 0.155 0.006 0.018 0.354 0.028 0.007 0.018 0.728 0.043 0.668
 0.047 0.348 0.632 0.341 0.271 0.963 0.024 0.009 0.022 0.006 0.023 0.012
 0.019 0.012 0.013 0.856 0.008 0.412 0.013 0.36  0.025 0.352 0.104 0.298
 1.699 0.028 1.319 0.006 0.911 0.034 0.65  0.086 0.504 0.219 0.011 0.217
 0.008 0.404 0.007 0.714 0.023 0.022]
[[0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [1. 0. 1. 0. 1. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [1. 1. 1. 0. 1. 1. 0. 0. 0. 0.]
 [1. 0. 1. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 1. 0. 1. 0. 0. 0.]]
[0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0.
 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.]
aucroc, aucpr (0.8616666666666667, 0.8190216555471256)
Iterations 2250
Achieves (3.524517146579602, 1e-05)-DP
