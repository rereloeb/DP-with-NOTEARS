samples  5000  graph  13 26 ER mlp  minibatch size  100  noise  0.5  minibatches per NN training  63 quantile adaptive clipping
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.3261408551088962
iteration 1 in outer loop, alpha = 1.3261408551088962, rho = 1.0, h = 1.3261408551088962
cuda
iteration 1 in inner loop,alpha 1.3261408551088962 rho 1.0 h 0.8833022561168153
iteration 2 in inner loop,alpha 1.3261408551088962 rho 10.0 h 0.3976662043074768
iteration 3 in inner loop,alpha 1.3261408551088962 rho 100.0 h 0.14473978390051023
iteration 2 in outer loop, alpha = 15.80011924515992, rho = 100.0, h = 0.14473978390051023
cuda
iteration 1 in inner loop,alpha 15.80011924515992 rho 100.0 h 0.09206134723974557
iteration 2 in inner loop,alpha 15.80011924515992 rho 1000.0 h 0.03605103482185257
iteration 3 in outer loop, alpha = 51.85115406701249, rho = 1000.0, h = 0.03605103482185257
cuda
iteration 1 in inner loop,alpha 51.85115406701249 rho 1000.0 h 0.022520091840645406
iteration 2 in inner loop,alpha 51.85115406701249 rho 10000.0 h 0.007430765387507421
iteration 4 in outer loop, alpha = 126.1588079420867, rho = 10000.0, h = 0.007430765387507421
cuda
iteration 1 in inner loop,alpha 126.1588079420867 rho 10000.0 h 0.003776628811836602
iteration 2 in inner loop,alpha 126.1588079420867 rho 100000.0 h 0.0013610307532996302
iteration 5 in outer loop, alpha = 262.2618832720497, rho = 100000.0, h = 0.0013610307532996302
cuda
iteration 1 in inner loop,alpha 262.2618832720497 rho 100000.0 h 0.0007716999804809888
iteration 6 in outer loop, alpha = 1033.9618637530384, rho = 1000000.0, h = 0.0007716999804809888
Threshold 0.3
[[0.001 0.    0.182 2.569 0.635 0.    0.017 0.    0.    0.437 0.    1.888
  0.   ]
 [0.631 0.001 0.321 0.04  0.172 0.002 0.04  0.    0.    2.061 0.001 0.198
  0.   ]
 [0.    0.    0.002 0.    0.    0.    0.001 0.    0.    0.    0.    0.
  0.   ]
 [0.    0.    2.687 0.001 0.109 0.001 0.089 0.    0.    1.627 0.    0.283
  0.   ]
 [0.    0.    0.255 0.    0.001 0.    0.002 0.    0.    0.    0.    0.
  0.   ]
 [0.077 0.029 0.336 0.065 0.609 0.001 0.013 0.    0.114 2.26  0.033 0.126
  0.012]
 [0.009 0.012 1.092 0.025 0.088 0.043 0.027 0.001 0.002 0.973 0.001 0.299
  0.003]
 [0.009 0.007 0.009 0.01  1.505 3.724 0.081 0.001 0.648 0.449 0.002 0.053
  0.   ]
 [0.021 1.541 2.239 0.017 0.092 0.004 0.359 0.    0.    1.386 0.002 0.194
  0.022]
 [0.    0.    1.123 0.    0.242 0.    0.001 0.    0.    0.004 0.    2.362
  0.   ]
 [1.749 0.008 2.559 0.069 0.554 0.    0.012 0.001 0.003 0.986 0.    0.091
  0.001]
 [0.    0.    0.95  0.    0.976 0.    0.001 0.    0.    0.    0.    0.001
  0.   ]
 [0.007 1.023 2.329 0.018 0.272 0.003 0.091 0.    0.006 2.319 0.    0.415
  0.   ]]
[[0.    0.    0.    2.569 0.635 0.    0.    0.    0.    0.437 0.    1.888
  0.   ]
 [0.631 0.    0.321 0.    0.    0.    0.    0.    0.    2.061 0.    0.
  0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.   ]
 [0.    0.    2.687 0.    0.    0.    0.    0.    0.    1.627 0.    0.
  0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.   ]
 [0.    0.    0.336 0.    0.609 0.    0.    0.    0.    2.26  0.    0.
  0.   ]
 [0.    0.    1.092 0.    0.    0.    0.    0.    0.    0.973 0.    0.
  0.   ]
 [0.    0.    0.    0.    1.505 3.724 0.    0.    0.648 0.449 0.    0.
  0.   ]
 [0.    1.541 2.239 0.    0.    0.    0.359 0.    0.    1.386 0.    0.
  0.   ]
 [0.    0.    1.123 0.    0.    0.    0.    0.    0.    0.    0.    2.362
  0.   ]
 [1.749 0.    2.559 0.    0.554 0.    0.    0.    0.    0.986 0.    0.
  0.   ]
 [0.    0.    0.95  0.    0.976 0.    0.    0.    0.    0.    0.    0.
  0.   ]
 [0.    1.023 2.329 0.    0.    0.    0.    0.    0.    2.319 0.    0.415
  0.   ]]
{'fdr': 0.4117647058823529, 'tpr': 0.7692307692307693, 'fpr': 0.2692307692307692, 'f1': 0.6666666666666667, 'shd': 16, 'npred': 34, 'ntrue': 26}
[2.709e-04 1.824e-01 2.569e+00 6.347e-01 4.409e-04 1.688e-02 1.418e-04
 1.314e-04 4.370e-01 2.441e-05 1.888e+00 8.225e-05 6.311e-01 3.206e-01
 3.991e-02 1.718e-01 1.888e-03 4.013e-02 3.257e-04 1.429e-04 2.061e+00
 1.297e-03 1.978e-01 1.038e-04 3.463e-05 1.430e-05 1.019e-04 1.623e-04
 1.429e-05 9.834e-04 5.300e-06 2.169e-05 1.810e-04 1.877e-06 1.476e-05
 1.439e-05 1.233e-04 6.370e-05 2.687e+00 1.093e-01 5.654e-04 8.929e-02
 1.822e-04 4.822e-05 1.627e+00 8.417e-06 2.825e-01 5.350e-05 3.871e-05
 3.550e-05 2.549e-01 1.370e-04 9.870e-06 1.644e-03 7.721e-06 1.615e-05
 1.463e-04 4.828e-06 2.880e-04 1.052e-05 7.735e-02 2.929e-02 3.360e-01
 6.516e-02 6.090e-01 1.331e-02 1.129e-04 1.145e-01 2.260e+00 3.342e-02
 1.261e-01 1.247e-02 9.295e-03 1.173e-02 1.092e+00 2.524e-02 8.756e-02
 4.262e-02 9.732e-04 2.381e-03 9.727e-01 1.082e-03 2.986e-01 2.923e-03
 8.812e-03 6.955e-03 9.492e-03 1.023e-02 1.505e+00 3.724e+00 8.077e-02
 6.482e-01 4.494e-01 1.951e-03 5.338e-02 2.108e-04 2.096e-02 1.541e+00
 2.239e+00 1.656e-02 9.200e-02 4.081e-03 3.586e-01 3.273e-04 1.386e+00
 1.763e-03 1.943e-01 2.219e-02 4.106e-05 8.852e-05 1.123e+00 1.152e-04
 2.416e-01 2.212e-04 1.069e-03 4.351e-05 1.334e-05 6.935e-06 2.362e+00
 3.005e-05 1.749e+00 7.818e-03 2.559e+00 6.923e-02 5.540e-01 3.162e-04
 1.167e-02 8.957e-04 2.919e-03 9.857e-01 9.067e-02 8.555e-04 2.191e-06
 6.270e-06 9.500e-01 2.399e-05 9.764e-01 7.224e-06 1.035e-03 1.079e-06
 2.817e-06 4.822e-05 8.203e-07 9.864e-07 7.113e-03 1.023e+00 2.329e+00
 1.810e-02 2.718e-01 2.717e-03 9.136e-02 2.993e-05 5.610e-03 2.319e+00
 3.833e-04 4.147e-01]
[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]
 [1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0.]
aucroc, aucpr (0.8715976331360946, 0.7667248028902397)
cuda
noise_multiplier  0.5  noise_multiplier_b  5.0  noise_multiplier_delta  0.5006261743217588
cuda
Objective function 480.43 = squared loss an data 285.64 + 0.5*rho*h**2 194.315677 + alpha*h 0.000000 + L2reg 0.24 + L1reg 0.24 ; SHD = 91 ; DAG False
total norm for a microbatch 55.48259060273633 clip 7.977520659355656
total norm for a microbatch 57.73263359136413 clip 9.411851145829523
total norm for a microbatch 56.22078410958411 clip 15.048384837680024
total norm for a microbatch 46.694548437261076 clip 44.36684891335044
total norm for a microbatch 47.084498032598226 clip 45.42037672194243
total norm for a microbatch 60.242680156821486 clip 45.22665139610255
total norm for a microbatch 56.729262837068745 clip 44.84103693221689
total norm for a microbatch 62.27121967845375 clip 41.74719233554481
cuda
Objective function 66.15 = squared loss an data 64.50 + 0.5*rho*h**2 1.291047 + alpha*h 0.000000 + L2reg 0.23 + L1reg 0.12 ; SHD = 42 ; DAG False
Proportion of microbatches that were clipped  0.919565911267156
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 1.6068896560404156
iteration 1 in outer loop, alpha = 1.6068896560404156, rho = 1.0, h = 1.6068896560404156
cuda
noise_multiplier  0.5  noise_multiplier_b  5.0  noise_multiplier_delta  0.5006261743217588
cuda
Objective function 68.73 = squared loss an data 64.50 + 0.5*rho*h**2 1.291047 + alpha*h 2.582094 + L2reg 0.23 + L1reg 0.12 ; SHD = 42 ; DAG False
total norm for a microbatch 45.14481403404115 clip 1.0
total norm for a microbatch 35.07049844676278 clip 4.558357454403234
total norm for a microbatch 46.5058508180207 clip 4.558357454403234
total norm for a microbatch 36.78581587184757 clip 6.607515765247959
total norm for a microbatch 58.81098084613358 clip 39.832688915090216
cuda
Objective function 15.75 = squared loss an data 12.71 + 0.5*rho*h**2 0.622402 + alpha*h 1.792819 + L2reg 0.52 + L1reg 0.11 ; SHD = 34 ; DAG False
Proportion of microbatches that were clipped  0.919773095623987
iteration 1 in inner loop, alpha 1.6068896560404156 rho 1.0 h 1.1157077968663138
noise_multiplier  0.5  noise_multiplier_b  5.0  noise_multiplier_delta  0.5006261743217588
cuda
Objective function 21.36 = squared loss an data 12.71 + 0.5*rho*h**2 6.224019 + alpha*h 1.792819 + L2reg 0.52 + L1reg 0.11 ; SHD = 34 ; DAG False
total norm for a microbatch 93.26632878879417 clip 2.9180007316676178
total norm for a microbatch 62.45644702362281 clip 40.969782810608045
total norm for a microbatch 46.47772960448073 clip 40.969782810608045
total norm for a microbatch 125.73084268816032 clip 42.71150856791888
total norm for a microbatch 81.10443867248968 clip 51.511579928436454
total norm for a microbatch 110.56064739918665 clip 52.04063129514648
total norm for a microbatch 64.9076945255209 clip 53.48294429510829
cuda
Objective function 15.08 = squared loss an data 12.52 + 0.5*rho*h**2 1.053106 + alpha*h 0.737458 + L2reg 0.67 + L1reg 0.10 ; SHD = 26 ; DAG False
Proportion of microbatches that were clipped  0.9364979566174159
iteration 2 in inner loop, alpha 1.6068896560404156 rho 10.0 h 0.4589349577190305
noise_multiplier  0.5  noise_multiplier_b  5.0  noise_multiplier_delta  0.5006261743217588
cuda
Objective function 24.56 = squared loss an data 12.52 + 0.5*rho*h**2 10.531065 + alpha*h 0.737458 + L2reg 0.67 + L1reg 0.10 ; SHD = 26 ; DAG False
total norm for a microbatch 71.6822421737339 clip 1.2058282178776367
total norm for a microbatch 91.51526684540055 clip 2.1259602317677904
total norm for a microbatch 170.67824575532865 clip 14.246772668129513
cuda
Objective function 16.25 = squared loss an data 13.92 + 0.5*rho*h**2 1.204002 + alpha*h 0.249353 + L2reg 0.78 + L1reg 0.10 ; SHD = 27 ; DAG True
Proportion of microbatches that were clipped  0.9398907103825137
iteration 3 in inner loop, alpha 1.6068896560404156 rho 100.0 h 0.1551774693510506
iteration 2 in outer loop, alpha = 17.124636591145475, rho = 100.0, h = 0.1551774693510506
cuda
noise_multiplier  0.5  noise_multiplier_b  5.0  noise_multiplier_delta  0.5006261743217588
cuda
Objective function 18.66 = squared loss an data 13.92 + 0.5*rho*h**2 1.204002 + alpha*h 2.657358 + L2reg 0.78 + L1reg 0.10 ; SHD = 27 ; DAG True
total norm for a microbatch 88.35773352748251 clip 1.329166203505656
total norm for a microbatch 154.9118280247029 clip 2.938155050136164
total norm for a microbatch 116.04565211651708 clip 5.0928496486618196
total norm for a microbatch 49.952440018642704 clip 11.292943720779451
total norm for a microbatch 65.0010573572749 clip 12.417485616881912
total norm for a microbatch 67.6266086855073 clip 12.417485616881912
total norm for a microbatch 88.18635841986298 clip 13.600999177507958
total norm for a microbatch 64.78545182464639 clip 28.012010481390835
total norm for a microbatch 91.98243010063672 clip 28.012010481390835
cuda
Objective function 17.13 = squared loss an data 14.18 + 0.5*rho*h**2 0.418748 + alpha*h 1.567159 + L2reg 0.86 + L1reg 0.10 ; SHD = 30 ; DAG True
Proportion of microbatches that were clipped  0.9423546653639472
iteration 1 in inner loop, alpha 17.124636591145475 rho 100.0 h 0.09151485515791435
noise_multiplier  0.5  noise_multiplier_b  5.0  noise_multiplier_delta  0.5006261743217588
cuda
Objective function 20.90 = squared loss an data 14.18 + 0.5*rho*h**2 4.187484 + alpha*h 1.567159 + L2reg 0.86 + L1reg 0.10 ; SHD = 30 ; DAG True
total norm for a microbatch 86.36298093800666 clip 1.4324737075984693
total norm for a microbatch 106.73214450934246 clip 1.8717867037675826
total norm for a microbatch 42.549989946820595 clip 4.590788699911617
total norm for a microbatch 101.102459520512 clip 20.99714272616408
total norm for a microbatch 109.23960383654618 clip 54.99115531930417
total norm for a microbatch 111.20066859099762 clip 62.95227563807997
cuda
Objective function 16.74 = squared loss an data 14.40 + 0.5*rho*h**2 0.690714 + alpha*h 0.636481 + L2reg 0.92 + L1reg 0.10 ; SHD = 30 ; DAG True
Proportion of microbatches that were clipped  0.9451705451067899
iteration 2 in inner loop, alpha 17.124636591145475 rho 1000.0 h 0.037167553388609775
iteration 3 in outer loop, alpha = 54.29218997975525, rho = 1000.0, h = 0.037167553388609775
cuda
noise_multiplier  0.5  noise_multiplier_b  5.0  noise_multiplier_delta  0.5006261743217588
cuda
Objective function 18.12 = squared loss an data 14.40 + 0.5*rho*h**2 0.690714 + alpha*h 2.017908 + L2reg 0.92 + L1reg 0.10 ; SHD = 30 ; DAG True
total norm for a microbatch 75.34135593865597 clip 1.1912215132842232
total norm for a microbatch 66.6637073155874 clip 1.421726239742066
total norm for a microbatch 166.47170215256216 clip 1.421726239742066
total norm for a microbatch 101.23203735143825 clip 3.451344923538745
total norm for a microbatch 111.28138836011071 clip 7.607073586387231
total norm for a microbatch 212.99483297818497 clip 37.569175248370605
total norm for a microbatch 172.9971924500648 clip 41.38294147189961
total norm for a microbatch 170.08206005656612 clip 69.55019789485584
cuda
Objective function 17.27 = squared loss an data 14.58 + 0.5*rho*h**2 0.303139 + alpha*h 1.336821 + L2reg 0.94 + L1reg 0.11 ; SHD = 31 ; DAG True
Proportion of microbatches that were clipped  0.9482953627403458
iteration 1 in inner loop, alpha 54.29218997975525 rho 1000.0 h 0.024622711829330513
noise_multiplier  0.5  noise_multiplier_b  5.0  noise_multiplier_delta  0.5006261743217588
cuda
Objective function 20.00 = squared loss an data 14.58 + 0.5*rho*h**2 3.031390 + alpha*h 1.336821 + L2reg 0.94 + L1reg 0.11 ; SHD = 31 ; DAG True
total norm for a microbatch 148.78203030890634 clip 1.1903530310335744
total norm for a microbatch 64.95905034457728 clip 1.872483579396993
total norm for a microbatch 146.36578384928066 clip 10.98357904593963
total norm for a microbatch 87.58031290013655 clip 17.36765362534236
total norm for a microbatch 62.458409373783546 clip 33.51270521350228
cuda
Objective function 16.77 = squared loss an data 14.77 + 0.5*rho*h**2 0.423150 + alpha*h 0.499459 + L2reg 0.98 + L1reg 0.10 ; SHD = 27 ; DAG True
Proportion of microbatches that were clipped  0.9447531354183204
iteration 2 in inner loop, alpha 54.29218997975525 rho 10000.0 h 0.009199455896883535
iteration 4 in outer loop, alpha = 146.2867489485906, rho = 10000.0, h = 0.009199455896883535
cuda
noise_multiplier  0.5  noise_multiplier_b  5.0  noise_multiplier_delta  0.5006261743217588
cuda
Objective function 17.61 = squared loss an data 14.77 + 0.5*rho*h**2 0.423150 + alpha*h 1.345758 + L2reg 0.98 + L1reg 0.10 ; SHD = 27 ; DAG True
total norm for a microbatch 140.4276179977617 clip 8.772666698596892
total norm for a microbatch 86.18999023397437 clip 27.77698079844601
total norm for a microbatch 103.97906675485817 clip 65.00595256971789
total norm for a microbatch 175.64572867780228 clip 65.00595256971789
cuda
Objective function 17.01 = squared loss an data 14.68 + 0.5*rho*h**2 0.240933 + alpha*h 1.015472 + L2reg 0.97 + L1reg 0.10 ; SHD = 31 ; DAG True
Proportion of microbatches that were clipped  0.9455550138143994
iteration 1 in inner loop, alpha 146.2867489485906 rho 10000.0 h 0.006941650963979029
noise_multiplier  0.5  noise_multiplier_b  5.0  noise_multiplier_delta  0.5006261743217588
cuda
Objective function 19.18 = squared loss an data 14.68 + 0.5*rho*h**2 2.409326 + alpha*h 1.015472 + L2reg 0.97 + L1reg 0.10 ; SHD = 31 ; DAG True
total norm for a microbatch 173.2624873086552 clip 1.6644574537443348
total norm for a microbatch 96.4935053435859 clip 3.449964606042269
total norm for a microbatch 136.22371075436382 clip 5.4222060496344495
total norm for a microbatch 58.41081377963816 clip 7.082699259298592
total norm for a microbatch 193.9256776254785 clip 84.63167823892539
cuda
Objective function 16.60 = squared loss an data 14.28 + 0.5*rho*h**2 0.661667 + alpha*h 0.532157 + L2reg 1.01 + L1reg 0.10 ; SHD = 30 ; DAG True
Proportion of microbatches that were clipped  0.9515531949138902
iteration 2 in inner loop, alpha 146.2867489485906 rho 100000.0 h 0.0036377652341883504
iteration 5 in outer loop, alpha = 3784.051983136941, rho = 1000000.0, h = 0.0036377652341883504
Threshold 0.3
[[0.006 0.485 0.644 1.444 0.518 0.3   0.516 0.079 0.047 0.458 0.03  0.451
  0.114]
 [0.014 0.006 0.138 0.058 0.338 0.152 0.271 0.01  0.003 0.475 0.03  0.055
  0.005]
 [0.004 0.054 0.008 0.004 0.072 0.057 0.505 0.008 0.005 0.396 0.006 0.045
  0.003]
 [0.004 0.106 1.519 0.005 0.069 0.217 0.374 0.016 0.02  0.425 0.014 0.052
  0.025]
 [0.011 0.036 0.062 0.083 0.008 0.034 0.047 0.007 0.01  0.048 0.005 0.011
  0.009]
 [0.014 0.038 0.142 0.039 0.188 0.006 0.272 0.003 0.017 0.999 0.034 0.042
  0.011]
 [0.006 0.021 0.014 0.01  0.128 0.013 0.008 0.008 0.004 0.434 0.015 0.05
  0.005]
 [0.076 0.561 0.64  0.472 0.513 2.938 0.737 0.006 0.075 0.99  0.166 0.468
  0.169]
 [0.165 1.415 0.786 0.398 0.431 0.369 0.98  0.086 0.004 0.627 0.314 0.324
  0.126]
 [0.006 0.016 0.014 0.011 0.094 0.009 0.016 0.003 0.007 0.006 0.011 0.019
  0.004]
 [0.241 0.205 0.993 0.378 0.973 0.134 0.337 0.04  0.023 0.478 0.006 0.277
  0.018]
 [0.014 0.103 0.133 0.078 0.681 0.155 0.056 0.017 0.011 0.29  0.021 0.007
  0.018]
 [0.042 1.046 1.168 0.265 0.672 0.331 0.889 0.057 0.053 1.62  0.207 0.329
  0.003]]
[[0.    0.485 0.644 1.444 0.518 0.    0.516 0.    0.    0.458 0.    0.451
  0.   ]
 [0.    0.    0.    0.    0.338 0.    0.    0.    0.    0.475 0.    0.
  0.   ]
 [0.    0.    0.    0.    0.    0.    0.505 0.    0.    0.396 0.    0.
  0.   ]
 [0.    0.    1.519 0.    0.    0.    0.374 0.    0.    0.425 0.    0.
  0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.999 0.    0.
  0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.434 0.    0.
  0.   ]
 [0.    0.561 0.64  0.472 0.513 2.938 0.737 0.    0.    0.99  0.    0.468
  0.   ]
 [0.    1.415 0.786 0.398 0.431 0.369 0.98  0.    0.    0.627 0.314 0.324
  0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.   ]
 [0.    0.    0.993 0.378 0.973 0.    0.337 0.    0.    0.478 0.    0.
  0.   ]
 [0.    0.    0.    0.    0.681 0.    0.    0.    0.    0.    0.    0.
  0.   ]
 [0.    1.046 1.168 0.    0.672 0.331 0.889 0.    0.    1.62  0.    0.329
  0.   ]]
{'fdr': 0.5652173913043478, 'tpr': 0.7692307692307693, 'fpr': 0.5, 'f1': 0.5555555555555556, 'shd': 30, 'npred': 46, 'ntrue': 26}
[4.853e-01 6.440e-01 1.444e+00 5.177e-01 2.996e-01 5.162e-01 7.870e-02
 4.669e-02 4.583e-01 3.034e-02 4.514e-01 1.139e-01 1.434e-02 1.379e-01
 5.807e-02 3.376e-01 1.518e-01 2.707e-01 1.020e-02 3.231e-03 4.750e-01
 3.031e-02 5.534e-02 5.004e-03 3.524e-03 5.370e-02 3.862e-03 7.166e-02
 5.720e-02 5.055e-01 7.787e-03 4.812e-03 3.963e-01 5.521e-03 4.461e-02
 3.307e-03 4.335e-03 1.063e-01 1.519e+00 6.922e-02 2.171e-01 3.741e-01
 1.554e-02 2.025e-02 4.251e-01 1.386e-02 5.222e-02 2.477e-02 1.079e-02
 3.617e-02 6.194e-02 8.300e-02 3.419e-02 4.735e-02 7.320e-03 9.971e-03
 4.752e-02 4.851e-03 1.138e-02 9.158e-03 1.401e-02 3.848e-02 1.419e-01
 3.904e-02 1.878e-01 2.715e-01 3.043e-03 1.653e-02 9.987e-01 3.438e-02
 4.173e-02 1.073e-02 6.041e-03 2.116e-02 1.378e-02 9.517e-03 1.275e-01
 1.285e-02 7.717e-03 4.478e-03 4.340e-01 1.476e-02 5.049e-02 4.921e-03
 7.555e-02 5.613e-01 6.397e-01 4.717e-01 5.126e-01 2.938e+00 7.370e-01
 7.462e-02 9.902e-01 1.660e-01 4.685e-01 1.686e-01 1.652e-01 1.415e+00
 7.865e-01 3.981e-01 4.312e-01 3.688e-01 9.805e-01 8.588e-02 6.269e-01
 3.140e-01 3.241e-01 1.257e-01 6.217e-03 1.586e-02 1.360e-02 1.068e-02
 9.365e-02 8.669e-03 1.645e-02 2.748e-03 6.636e-03 1.133e-02 1.851e-02
 3.764e-03 2.412e-01 2.051e-01 9.928e-01 3.782e-01 9.728e-01 1.340e-01
 3.366e-01 3.964e-02 2.296e-02 4.780e-01 2.767e-01 1.789e-02 1.406e-02
 1.026e-01 1.334e-01 7.770e-02 6.810e-01 1.552e-01 5.621e-02 1.713e-02
 1.102e-02 2.896e-01 2.108e-02 1.831e-02 4.239e-02 1.046e+00 1.168e+00
 2.652e-01 6.722e-01 3.307e-01 8.885e-01 5.694e-02 5.337e-02 1.620e+00
 2.071e-01 3.291e-01]
[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]
 [1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]
 [0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.
 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0.]
aucroc, aucpr (0.855621301775148, 0.7248626258201162)
Iterations 630
Achieves (23.639217916927258, 1e-05)-DP
