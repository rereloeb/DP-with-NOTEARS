samples  5000  graph  10 30 ER mlp  minibatch size  100  noise  1.0  minibatches per NN training  63 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.1229782946562032
iteration 1 in outer loop, alpha = 1.1229782946562032, rho = 1.0, h = 1.1229782946562032
cuda
iteration 1 in inner loop,alpha 1.1229782946562032 rho 1.0 h 0.7586153562268656
iteration 2 in inner loop,alpha 1.1229782946562032 rho 10.0 h 0.35052850700977345
iteration 3 in inner loop,alpha 1.1229782946562032 rho 100.0 h 0.11468940960946838
iteration 2 in outer loop, alpha = 12.591919255603042, rho = 100.0, h = 0.11468940960946838
cuda
iteration 1 in inner loop,alpha 12.591919255603042 rho 100.0 h 0.05177271318199317
iteration 2 in inner loop,alpha 12.591919255603042 rho 1000.0 h 0.015651355822457802
iteration 3 in outer loop, alpha = 28.243275078060844, rho = 1000.0, h = 0.015651355822457802
cuda
iteration 1 in inner loop,alpha 28.243275078060844 rho 1000.0 h 0.0076855114245848455
iteration 2 in inner loop,alpha 28.243275078060844 rho 10000.0 h 0.0014289170876846669
iteration 4 in outer loop, alpha = 42.532445954907516, rho = 10000.0, h = 0.0014289170876846669
cuda
iteration 1 in inner loop,alpha 42.532445954907516 rho 10000.0 h 0.0007810909223238127
iteration 2 in inner loop,alpha 42.532445954907516 rho 100000.0 h 0.0003151968036405606
iteration 5 in outer loop, alpha = 74.05212631896357, rho = 100000.0, h = 0.0003151968036405606
cuda
iteration 1 in inner loop,alpha 74.05212631896357 rho 100000.0 h 0.00017956972001975657
iteration 6 in outer loop, alpha = 253.62184633872016, rho = 1000000.0, h = 0.00017956972001975657
Threshold 0.3
[[0.004 0.    0.368 0.    1.15  0.001 1.809 0.    0.001 0.006]
 [2.231 0.002 1.466 0.    0.876 0.016 0.115 0.106 0.005 2.624]
 [0.003 0.    0.007 0.    2.007 0.    1.925 0.    0.001 0.   ]
 [1.277 0.407 1.441 0.    0.834 0.432 1.183 0.248 2.714 2.813]
 [0.    0.    0.    0.    0.004 0.    0.    0.    0.    0.   ]
 [0.186 0.007 0.189 0.    0.256 0.001 0.317 0.005 0.008 2.979]
 [0.    0.    0.001 0.    1.626 0.    0.004 0.    0.    0.   ]
 [1.802 0.006 1.35  0.    1.751 0.109 0.28  0.002 0.003 0.102]
 [2.328 0.039 2.294 0.    0.915 0.063 0.591 0.205 0.004 0.314]
 [0.183 0.    2.462 0.    1.744 0.    2.586 0.003 0.004 0.006]]
[[0.    0.    0.368 0.    1.15  0.    1.809 0.    0.    0.   ]
 [2.231 0.    1.466 0.    0.876 0.    0.    0.    0.    2.624]
 [0.    0.    0.    0.    2.007 0.    1.925 0.    0.    0.   ]
 [1.277 0.407 1.441 0.    0.834 0.432 1.183 0.    2.714 2.813]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.317 0.    0.    2.979]
 [0.    0.    0.    0.    1.626 0.    0.    0.    0.    0.   ]
 [1.802 0.    1.35  0.    1.751 0.    0.    0.    0.    0.   ]
 [2.328 0.    2.294 0.    0.915 0.    0.591 0.    0.    0.314]
 [0.    0.    2.462 0.    1.744 0.    2.586 0.    0.    0.   ]]
{'fdr': 0.12903225806451613, 'tpr': 0.9, 'fpr': 0.26666666666666666, 'f1': 0.8852459016393444, 'shd': 7, 'npred': 31, 'ntrue': 30}
[1.803e-04 3.685e-01 4.657e-05 1.150e+00 7.759e-04 1.809e+00 3.113e-04
 6.473e-04 6.239e-03 2.231e+00 1.466e+00 3.026e-04 8.756e-01 1.629e-02
 1.147e-01 1.060e-01 4.843e-03 2.624e+00 3.457e-03 4.974e-05 6.914e-06
 2.007e+00 1.628e-05 1.925e+00 4.218e-04 9.659e-04 3.474e-04 1.277e+00
 4.067e-01 1.441e+00 8.338e-01 4.317e-01 1.183e+00 2.478e-01 2.714e+00
 2.813e+00 9.493e-05 5.335e-06 1.069e-04 8.132e-06 1.721e-06 4.393e-04
 2.501e-05 7.378e-05 1.776e-05 1.861e-01 6.534e-03 1.893e-01 3.123e-04
 2.558e-01 3.172e-01 5.060e-03 8.206e-03 2.979e+00 2.337e-04 3.950e-05
 6.329e-04 1.201e-05 1.626e+00 2.851e-05 8.471e-05 1.369e-05 3.371e-04
 1.802e+00 5.666e-03 1.350e+00 3.756e-04 1.751e+00 1.090e-01 2.798e-01
 2.746e-03 1.020e-01 2.328e+00 3.940e-02 2.294e+00 1.263e-04 9.154e-01
 6.258e-02 5.911e-01 2.047e-01 3.136e-01 1.828e-01 2.226e-04 2.462e+00
 1.237e-04 1.744e+00 1.853e-04 2.586e+00 2.559e-03 4.399e-03]
[[0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [1. 0. 1. 0. 1. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [1. 1. 1. 0. 1. 1. 0. 0. 0. 0.]
 [1. 0. 1. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 1. 0. 1. 0. 0. 0.]]
[0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0.
 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.]
aucroc, aucpr (0.9788888888888889, 0.969600766232419)
cuda
1210
cuda
Objective function 461.65 = squared loss an data 284.59 + 0.5*rho*h**2 176.710652 + alpha*h 0.000000 + L2reg 0.19 + L1reg 0.16 ; SHD = 55 ; DAG False
||w||^2 0.7657609219673261
exp ma of ||w||^2 524.1078537687589
||w|| 0.8750776662487314
exp ma of ||w|| 0.7072302035570815
||w||^2 0.11246907649422087
exp ma of ||w||^2 0.33241059083841396
||w|| 0.3353640954160431
exp ma of ||w|| 0.5592078970636081
||w||^2 0.18558327719891715
exp ma of ||w||^2 0.22266785175431922
||w|| 0.43079377571979516
exp ma of ||w|| 0.454687544907561
cuda
Objective function 65.63 = squared loss an data 64.63 + 0.5*rho*h**2 0.717994 + alpha*h 0.000000 + L2reg 0.20 + L1reg 0.08 ; SHD = 33 ; DAG False
Proportion of microbatches that were clipped  0.7304941999046559
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 1.198327507398652
iteration 1 in outer loop, alpha = 1.198327507398652, rho = 1.0, h = 1.198327507398652
cuda
1210
cuda
Objective function 67.07 = squared loss an data 64.63 + 0.5*rho*h**2 0.717994 + alpha*h 1.435989 + L2reg 0.20 + L1reg 0.08 ; SHD = 33 ; DAG False
||w||^2 0.5365739705470497
exp ma of ||w||^2 2.696725471138043
||w|| 0.7325120958366829
exp ma of ||w|| 0.6141883408788738
||w||^2 0.7069501866489436
exp ma of ||w||^2 0.28357830834017594
||w|| 0.8408032984289153
exp ma of ||w|| 0.49919668301749776
||w||^2 0.6143961855766714
exp ma of ||w||^2 0.4520350669056288
||w|| 0.7838342845121483
exp ma of ||w|| 0.6363700029915591
||w||^2 0.5115375128351982
exp ma of ||w||^2 0.5176459051701214
||w|| 0.7152185070558494
exp ma of ||w|| 0.6864272358905696
||w||^2 0.20370583558820177
exp ma of ||w||^2 0.5290546356916969
||w|| 0.4513378286696139
exp ma of ||w|| 0.6925788571219726
cuda
Objective function 18.74 = squared loss an data 16.99 + 0.5*rho*h**2 0.332626 + alpha*h 0.977391 + L2reg 0.37 + L1reg 0.08 ; SHD = 32 ; DAG False
Proportion of microbatches that were clipped  0.7467985086723943
iteration 1 in inner loop, alpha 1.198327507398652 rho 1.0 h 0.8156293622093536
1210
cuda
Objective function 21.74 = squared loss an data 16.99 + 0.5*rho*h**2 3.326256 + alpha*h 0.977391 + L2reg 0.37 + L1reg 0.08 ; SHD = 32 ; DAG False
||w||^2 418231753.25344676
exp ma of ||w||^2 1935882370.5455058
||w|| 20450.71522596329
exp ma of ||w|| 36764.60214627709
||w||^2 62098448.96660251
exp ma of ||w||^2 200658311.2280849
||w|| 7880.2569099365355
exp ma of ||w|| 11287.919331544765
||w||^2 73.3535003371317
exp ma of ||w||^2 16317.786230177566
||w|| 8.564665804170744
exp ma of ||w|| 30.49005836317407
||w||^2 0.5671852843840104
exp ma of ||w||^2 5.2871529181552255
||w|| 0.753117045607129
exp ma of ||w|| 0.967150219578137
||w||^2 0.9372423786915819
exp ma of ||w||^2 0.8118615029016037
||w|| 0.9681127923396022
exp ma of ||w|| 0.8648785073549912
||w||^2 1.1285120664115627
exp ma of ||w||^2 0.823756336266402
||w|| 1.0623144856451703
exp ma of ||w|| 0.8585163787302873
||w||^2 1.430690467612735
exp ma of ||w||^2 0.8478720322105215
||w|| 1.1961147384815283
exp ma of ||w|| 0.8632198750148502
||w||^2 0.4184620295143675
exp ma of ||w||^2 0.8604274743053251
||w|| 0.6468864116012698
exp ma of ||w|| 0.8681456537923754
||w||^2 0.21342361346775388
exp ma of ||w||^2 0.8123758476092955
||w|| 0.46197793612655774
exp ma of ||w|| 0.8477533505273029
||w||^2 1.333303467472857
exp ma of ||w||^2 0.932898616998637
||w|| 1.1546876060098925
exp ma of ||w|| 0.9024952531856166
cuda
Objective function 13.71 = squared loss an data 11.92 + 0.5*rho*h**2 0.763353 + alpha*h 0.468224 + L2reg 0.49 + L1reg 0.07 ; SHD = 27 ; DAG False
Proportion of microbatches that were clipped  0.756078307546574
iteration 2 in inner loop, alpha 1.198327507398652 rho 10.0 h 0.39073085063212076
1210
cuda
Objective function 20.58 = squared loss an data 11.92 + 0.5*rho*h**2 7.633530 + alpha*h 0.468224 + L2reg 0.49 + L1reg 0.07 ; SHD = 27 ; DAG False
||w||^2 12763184608.64229
exp ma of ||w||^2 54676045643.47522
||w|| 112974.26524940222
exp ma of ||w|| 208292.5287575423
||w||^2 261829715.38072425
exp ma of ||w||^2 2264104447.678823
||w|| 16181.153091814076
exp ma of ||w|| 39408.32976399998
||w||^2 27820.19562624819
exp ma of ||w||^2 1532348.2333990517
||w|| 166.79387166874025
exp ma of ||w|| 616.1009936084873
||w||^2 2.4666158401251934
exp ma of ||w||^2 6.993047804343725
||w|| 1.570546350836292
exp ma of ||w|| 1.3771280363098946
||w||^2 3.950946420373503
exp ma of ||w||^2 1.2900102687553128
||w|| 1.9876987750596173
exp ma of ||w|| 1.0782112142246847
||w||^2 1.090666212024664
exp ma of ||w||^2 1.4057504258159355
||w|| 1.0443496598480146
exp ma of ||w|| 1.132320266857471
||w||^2 2.4312822714799394
exp ma of ||w||^2 1.352387092306426
||w|| 1.5592569613376557
exp ma of ||w|| 1.1037892192683803
cuda
Objective function 13.78 = squared loss an data 12.15 + 0.5*rho*h**2 0.875595 + alpha*h 0.158578 + L2reg 0.54 + L1reg 0.06 ; SHD = 21 ; DAG True
Proportion of microbatches that were clipped  0.7695178849144635
iteration 3 in inner loop, alpha 1.198327507398652 rho 100.0 h 0.13233252052222966
iteration 2 in outer loop, alpha = 14.431579559621618, rho = 100.0, h = 0.13233252052222966
cuda
1210
cuda
Objective function 15.53 = squared loss an data 12.15 + 0.5*rho*h**2 0.875595 + alpha*h 1.909767 + L2reg 0.54 + L1reg 0.06 ; SHD = 21 ; DAG True
||w||^2 25500029131.71344
exp ma of ||w||^2 36501300302.13986
||w|| 159687.28544162004
exp ma of ||w|| 170603.5793183039
||w||^2 861174497.8089086
exp ma of ||w||^2 5347210330.202675
||w|| 29345.774786311376
exp ma of ||w|| 61506.15619616573
||w||^2 959697818.6623429
exp ma of ||w||^2 3794385856.4141436
||w|| 30978.98995548988
exp ma of ||w|| 51702.84935438165
||w||^2 128827798.525053
exp ma of ||w||^2 499074401.12161154
||w|| 11350.233412800504
exp ma of ||w|| 17046.96666320878
||w||^2 4.407340764531586
exp ma of ||w||^2 20.227993022705324
||w|| 2.099366753221453
exp ma of ||w|| 1.6459446955648878
v before min max tensor([[ 4.658e+01, -1.558e+01, -3.492e+01,  1.731e+01,  3.396e+01,  2.832e+01,
         -4.683e+01,  3.012e+01, -2.789e+01, -7.246e+00],
        [-3.309e+01,  1.222e+02,  3.334e+01, -1.472e+01, -3.702e+01, -2.360e+01,
         -1.479e+01,  8.114e+01,  2.461e+01,  2.286e+01],
        [ 2.031e+02, -1.979e+01, -2.410e+01, -2.770e+01, -4.330e+01, -2.088e+01,
          2.501e+01, -2.696e+01, -1.467e+01, -2.206e+01],
        [ 7.306e+02, -2.922e+00,  5.417e+01, -2.541e+00,  9.172e+01,  5.977e+01,
         -1.753e+01,  3.482e+02, -3.854e+01,  1.343e+02],
        [ 1.327e+02,  2.579e+02, -2.300e+01, -3.294e+01,  2.029e+01,  9.852e+01,
         -3.417e+01, -3.000e+01, -1.625e+01, -3.443e+01],
        [-4.096e+01,  4.952e+01,  4.314e+00, -4.265e+01, -5.425e+00, -2.382e+01,
         -2.942e+01, -4.455e+01, -1.960e+01,  1.132e+02],
        [ 3.788e+02, -3.477e+01,  4.720e+01, -2.363e+01,  4.020e+01, -4.599e+01,
          1.579e+01, -3.307e+01, -2.682e+01,  7.594e+00],
        [-7.217e+00, -4.195e+01,  1.950e+01, -7.661e+00,  4.060e+01,  9.767e+01,
         -1.691e+00, -4.101e+01, -3.139e+01, -3.436e+01],
        [ 1.033e+02,  2.047e+01, -3.064e+01, -4.663e+01,  1.120e+02, -1.742e+01,
          4.350e+00, -4.040e+01, -3.468e+01,  5.306e+00],
        [ 1.922e+02, -4.048e+00, -3.423e+01, -2.969e+01, -1.534e+01, -4.524e+01,
         -2.765e+01,  2.792e+00,  6.320e+01, -3.486e+01],
        [ 6.198e+01, -2.303e+01, -4.381e+01, -3.328e+01,  3.058e+01, -3.350e+01,
         -4.168e+01, -4.634e+01, -2.445e+01, -1.139e+01],
        [-1.513e+01, -1.168e+01, -4.248e+01,  6.208e+01,  1.258e+02, -3.965e+01,
         -3.685e+01,  6.662e+01, -1.017e+01, -1.319e+01],
        [ 3.893e+00, -1.087e+01, -2.986e+01, -8.872e-01, -2.296e+01, -4.194e+01,
         -3.072e+01, -2.673e+01, -4.167e+01, -5.969e+00],
        [-4.269e+01, -4.917e+01,  1.487e+01, -3.263e+01,  1.625e+02, -2.642e+01,
          1.307e+01,  7.146e-01, -2.833e+01,  2.048e+01],
        [ 5.526e+01,  1.852e+02,  1.130e+02,  4.337e+01, -1.964e+01, -1.743e+01,
         -4.882e+01, -2.073e+01, -2.357e+01, -7.567e+00],
        [ 1.286e+01,  2.149e+02, -4.231e+01,  1.096e+02,  8.609e+01, -1.069e+01,
         -4.155e+00, -4.117e+01, -4.090e+01, -4.570e+01],
        [-3.868e+01, -1.042e+01,  3.244e+01, -2.371e+01,  1.880e+01,  1.123e+01,
         -1.074e+01,  1.540e+02,  8.872e+00,  9.530e+01],
        [-4.277e+01, -2.199e+01,  4.681e+01, -2.058e+01,  1.450e+01, -1.267e+01,
          6.743e+00,  1.254e+02, -3.346e+01, -2.395e+01],
        [ 1.473e+02, -4.069e+01, -5.099e+01, -3.872e+00,  1.966e+02, -3.536e+01,
         -3.323e+01, -3.071e+01,  1.096e+02, -6.993e+00],
        [-1.832e+00,  1.995e+01,  9.356e+00,  1.934e+02,  1.517e+01,  3.242e+01,
         -4.670e+01,  2.581e+01,  9.280e+00, -3.524e+01],
        [ 1.529e+01, -2.615e+01, -3.073e+01, -1.427e+01, -2.368e+01, -3.531e+01,
         -1.468e+01,  8.667e+01, -1.170e+01, -2.581e+01],
        [-3.932e+01,  7.220e+01,  1.634e+01, -3.521e+01,  1.131e+02, -1.695e+01,
          1.172e+01, -3.069e+01, -3.200e+01,  2.849e+02],
        [-1.296e+01, -1.840e+01,  2.307e+02,  1.286e+02, -4.137e+00,  3.763e+00,
         -2.622e+01,  8.600e+00, -2.403e+01, -2.431e+01],
        [-2.320e+01,  2.019e+01,  4.612e+02,  2.947e+01,  7.234e+01,  2.104e+01,
         -1.039e+01, -2.215e+01, -1.154e+01,  5.724e+01],
        [-1.590e+01, -4.166e+01,  1.191e+02,  1.356e+01,  3.974e+00,  5.696e-01,
         -1.833e+01, -3.145e+01, -3.519e+01, -3.867e+01],
        [ 3.652e+01,  5.713e+01,  1.650e+01,  8.192e+01, -4.199e+01,  1.357e+02,
         -3.163e+01, -2.657e+01,  3.816e+00, -3.370e+01],
        [ 9.758e+01, -3.484e+01, -3.524e+01, -4.364e+01,  2.084e+02, -4.197e+01,
         -3.904e+01, -3.666e+01, -2.664e+01, -4.161e+01],
        [-3.850e+01, -3.864e+01,  3.944e+02, -1.980e+01, -1.860e+01, -4.103e+01,
         -3.296e+00, -3.785e+01, -5.337e+01, -4.128e+01],
        [-4.185e+01, -2.424e+01, -2.136e+01, -2.197e+01, -1.903e+01, -1.783e+01,
          1.646e+01,  7.287e+01, -6.016e+00, -4.075e+01],
        [-2.699e+01, -2.606e+01, -1.133e+01,  1.555e+02, -3.285e+01, -2.439e+01,
          4.056e+00, -4.208e-02, -1.199e+01, -2.805e+01],
        [-1.572e+01, -2.452e+01, -4.845e+00,  2.659e+02,  2.718e+00, -2.518e+01,
         -7.761e+00,  2.674e+02, -1.606e+01, -4.626e+01],
        [ 5.624e+01, -3.150e+01,  7.421e+01,  5.581e+01,  8.176e+01,  9.653e+01,
          2.654e+02,  3.684e+01,  1.470e+01, -2.617e+01],
        [-2.913e+01,  1.073e+02, -9.686e+00,  2.628e+01, -1.584e+01, -4.072e+01,
         -4.423e+01, -1.727e+01,  3.687e+01,  9.667e+00],
        [-4.371e+01, -2.777e+01, -3.865e+01,  1.062e+02, -2.586e+01,  2.129e+02,
          1.492e+01, -3.490e+01, -1.196e+01, -2.260e+01],
        [-2.957e+01, -3.328e+01,  6.342e+01,  2.254e+01, -3.428e+01,  1.839e+01,
         -4.060e+01,  4.033e+01, -3.308e+01, -3.427e+01],
        [-4.055e+01,  4.376e+01,  4.192e+01, -1.104e+01,  3.403e+02, -1.462e+01,
         -2.112e+01,  1.107e+01, -2.740e+01, -2.397e+01],
        [-1.983e+01,  7.273e+01,  4.496e+02, -4.624e+01, -4.672e+01,  3.305e+01,
         -4.007e+01, -3.438e+01, -1.405e+01,  1.130e+02],
        [-4.034e+01, -2.317e+01,  1.653e+02, -1.448e+00, -4.756e+01,  2.056e+00,
          2.723e+01, -9.657e+00,  7.006e+01, -1.084e+01],
        [-1.688e+01,  5.371e+01,  2.395e+01, -3.039e+01, -4.102e+01, -3.860e+01,
         -1.664e+01, -2.530e+01,  3.996e+01, -2.730e+00],
        [-2.670e+01,  1.214e+02,  2.086e+02, -3.494e+01, -3.058e+01, -3.293e+01,
         -1.376e+01, -4.761e+01,  3.173e+01, -4.599e+01],
        [ 8.405e+01, -2.946e+01, -5.354e+01, -2.834e+01, -2.365e+01,  1.612e+02,
         -3.820e+01, -2.969e+01, -2.967e+01,  1.943e+01],
        [ 4.139e+02, -3.299e+01,  3.600e+01,  1.159e+02,  4.133e+02, -3.785e+01,
          1.752e+02,  3.833e+00, -3.715e+01, -3.016e+01],
        [ 3.090e+01,  2.544e+01, -3.809e+01, -1.048e+01,  1.068e+02, -2.888e+01,
         -1.471e+01, -3.450e+01, -2.451e+01,  1.529e+01],
        [ 7.165e+00, -4.513e+01, -8.231e+00, -4.265e+01,  3.240e+01,  5.973e+01,
         -2.928e+01, -2.868e+01, -1.807e+01,  1.925e+02],
        [-1.753e+01, -2.732e+01,  1.102e+01,  6.179e+01, -3.160e+01, -2.392e+01,
         -1.676e+01, -2.738e+01, -4.282e+01, -3.306e+01],
        [-3.551e+01, -2.370e+01, -3.771e+01, -2.298e+01, -3.779e+01, -3.522e+01,
          1.040e+02,  1.286e+02, -3.271e+00, -2.585e+01],
        [ 7.355e+01, -3.684e+01, -3.077e+01, -3.546e+01,  1.958e+01, -4.925e+01,
         -5.041e+00, -9.138e+00,  3.920e+01,  7.613e+01],
        [ 7.362e-01, -1.778e+00,  1.708e+02, -1.430e+01, -2.505e+01,  3.836e+01,
         -3.318e+01,  3.229e+01, -2.704e+01,  6.461e+01],
        [ 1.061e+02,  1.196e+01,  7.725e+01, -3.913e+01,  3.775e+01,  2.079e+01,
          1.876e+01, -4.752e+01, -2.596e+01,  1.420e+02],
        [-4.769e+01,  2.622e+00, -3.516e+01, -2.413e+01, -2.237e+01, -2.986e+01,
         -1.079e+00,  4.842e+00, -3.284e+01, -3.450e+01],
        [-3.469e+01, -1.880e+01, -3.289e+01,  8.832e+01, -6.244e+00, -2.383e+00,
         -2.633e+01, -4.500e+01, -1.676e+01, -4.371e+00],
        [ 9.942e+00, -1.686e+01,  2.443e+02,  7.706e+01,  1.477e+02, -3.661e+01,
         -1.222e+01, -3.027e+01, -6.417e+00,  1.413e+01],
        [-2.409e+01,  5.016e+01, -3.871e+01, -3.536e+01, -6.838e-01, -1.741e+01,
         -3.181e+01, -3.712e+01, -3.879e+01, -4.131e+01],
        [-3.325e+01, -2.046e+01,  2.798e+01, -3.673e+01,  2.118e+02, -1.359e+01,
         -4.766e+01, -3.447e+00, -2.894e+01, -7.291e+00],
        [-3.946e+01,  5.757e+01, -1.868e+01,  2.158e+01,  2.780e+01, -5.028e+01,
         -2.615e+01, -7.334e+00, -1.417e+01, -2.736e+01],
        [-4.257e+01, -2.999e+01,  7.742e+01,  2.788e+01, -2.730e+01,  2.127e+02,
         -3.635e+01, -4.114e+01, -2.076e+00,  2.778e+01],
        [-3.804e+01, -6.926e+00,  6.263e+01, -1.977e+01, -2.483e+01,  5.576e+02,
         -4.430e+01,  1.410e+02, -3.071e+01, -3.861e+01],
        [-3.254e+01, -2.392e+01,  2.361e+02,  3.626e+01, -1.546e+01, -3.800e+01,
         -2.005e+01,  2.614e+00, -2.042e+01, -3.568e+01],
        [-4.611e+01,  7.319e+01,  5.823e+01, -3.670e+00,  1.984e+01,  6.607e+01,
         -4.633e+01,  2.564e+01,  2.196e+02,  1.269e+01],
        [-2.467e+01, -1.307e+01,  5.503e-02, -1.300e+01,  1.520e+01, -2.514e+01,
          1.224e+01, -1.724e+00, -4.679e+01, -1.977e+01],
        [ 1.269e+03,  4.575e+01,  1.229e+02,  3.017e+00, -1.608e+01, -2.671e+01,
          1.097e+02,  1.851e+02,  2.343e+02,  1.373e+02],
        [ 4.521e+01,  4.697e+01,  4.999e+02,  5.250e+01,  5.746e+01, -4.381e+01,
         -3.256e+01, -2.054e+01, -6.663e-01, -2.202e+01],
        [ 4.805e+01,  2.672e+01,  7.320e+01, -1.997e+01, -5.702e+00, -6.426e+00,
          1.069e+02,  1.946e+02, -2.215e+01, -2.411e+01],
        [ 1.738e+02, -5.299e+01, -3.284e+01,  9.823e-01,  2.021e+01, -2.470e+01,
          4.392e+02, -3.433e+01, -2.730e+01, -2.322e+01],
        [ 1.813e+02, -2.452e+01,  4.170e+01, -2.865e+01, -3.390e+01,  3.300e+01,
         -3.961e+01, -3.447e+01, -3.466e+01,  2.780e+02],
        [ 2.369e+02,  1.057e+02, -4.580e+00, -1.982e+01,  4.262e+01,  1.036e+02,
          1.015e+03,  6.952e+02, -3.266e+01,  2.449e+01],
        [ 3.679e+02, -4.206e+01, -4.732e+01,  1.080e+02,  2.000e+02, -3.460e+01,
          1.550e+02,  1.446e+02, -2.942e+01,  4.778e+01],
        [ 4.886e+02, -5.122e+01, -3.593e+00,  9.613e+01,  4.131e+01,  1.612e+02,
          1.030e+03, -3.717e+01, -3.099e+01,  2.192e+02],
        [-1.977e+01, -2.947e+01, -4.188e+01,  5.019e+01, -2.024e+01,  1.519e+02,
          2.094e+01,  1.199e+01, -3.226e+01, -3.126e+01],
        [ 1.712e+02, -4.234e+01,  3.791e+00, -3.618e+01, -1.353e+01,  8.563e+00,
          5.980e+02,  2.651e+01,  1.154e+01, -4.838e+01],
        [-3.233e+01,  4.790e+01,  6.417e+00,  5.702e+00,  4.060e-01,  2.206e+01,
         -1.305e+01,  2.614e+01, -3.974e+01, -3.733e+01],
        [-8.693e+00, -1.820e+01,  1.281e+00, -4.540e+01, -3.278e+01,  4.965e+01,
          3.298e+01, -3.194e+01,  9.479e+01, -3.448e+01],
        [-3.164e+01, -2.068e+01,  4.637e+00, -3.998e+01, -3.744e+01, -2.868e+01,
          1.474e+02,  4.594e+01,  7.709e+00, -2.839e+01],
        [-5.159e+01, -3.468e+01, -1.259e+01,  1.936e+01,  2.380e+01, -1.093e+01,
         -2.014e+01,  3.821e+01,  2.332e+01, -4.432e+01],
        [-2.016e+01, -1.519e+01, -3.561e+01, -3.252e+01, -8.403e+00, -3.079e+01,
         -2.186e+01, -5.441e+01, -4.757e+01,  5.341e+01],
        [-4.647e+01, -4.033e+01,  2.206e+01, -1.767e+01,  7.471e+00,  3.538e+00,
          9.772e+00,  1.313e+02, -4.899e+01, -1.745e+01],
        [-2.876e+01, -4.281e+01,  7.628e+01, -1.728e+01,  2.220e+01, -4.288e+01,
          1.381e+01, -3.451e+01,  4.418e+00, -9.318e+00],
        [-1.530e+01, -2.789e+01, -3.129e+01, -2.814e+01, -3.106e+01, -2.758e+01,
          8.953e+01,  4.776e+01, -6.619e+00, -2.911e+01],
        [ 6.433e-02, -4.392e+01, -4.566e+01, -3.618e+01, -4.063e+01,  9.142e+01,
         -4.088e+00, -3.493e+01,  5.709e+01, -2.595e+01],
        [-3.400e+01, -2.326e+01, -2.210e+01,  1.701e+02, -1.726e+01,  1.385e+00,
         -1.873e+01,  1.347e+02,  1.170e+02, -4.185e+01],
        [-7.370e+00, -2.005e+01, -1.207e+01, -2.671e+01, -2.877e+01,  2.677e+00,
         -2.466e+01, -2.160e+01, -1.741e+01,  5.953e+01],
        [ 2.888e+02,  3.648e+02, -4.632e+01, -3.609e+01, -4.860e+01, -3.339e+01,
         -3.498e+01, -2.783e+01, -6.836e+00,  6.416e+00],
        [-4.932e+01,  2.283e+01, -3.625e+01,  6.436e+01, -5.445e+01,  1.405e+02,
          1.309e+01, -2.693e+01,  6.766e+01,  4.520e+01],
        [ 3.595e+01, -2.835e+01, -1.772e+01,  1.070e+02,  4.243e+01, -3.632e+00,
          3.303e+00,  2.078e+01, -1.930e+01, -3.756e+01],
        [-3.974e+01,  2.834e+01, -4.224e+01,  3.189e+01, -3.620e+01, -2.024e+01,
         -4.407e+01, -4.562e+01,  5.520e+01, -4.540e+01],
        [-5.224e+01, -2.464e+01, -4.780e+01, -2.182e+01,  2.064e+01, -1.256e+01,
         -2.182e+00, -2.852e+01,  9.708e+01,  1.051e+02],
        [ 4.711e+00,  5.104e+01,  3.892e+02, -2.365e+01,  2.515e+00,  1.107e+01,
         -3.217e+01, -3.854e+01, -2.798e+01,  7.862e+01],
        [-2.244e+01,  1.669e+01, -4.952e+01,  7.976e+01, -2.443e+01,  5.136e+00,
          1.446e+01,  1.125e+02,  1.211e+02,  2.794e+01],
        [-3.441e+01,  3.711e+01, -2.297e+01, -2.102e+01, -2.043e+01,  3.397e+02,
         -3.682e+01,  1.103e+01, -4.730e+01, -9.923e-01],
        [-1.932e+01, -3.756e+01,  1.647e+01, -2.808e+01,  5.994e+01, -2.374e+00,
          9.227e+01, -1.238e+01, -2.656e+01, -2.256e+01],
        [-3.920e+01,  3.410e+01, -3.884e+01, -4.135e+01,  1.923e+00, -2.992e+01,
         -6.135e+00, -2.842e+01, -3.060e+01, -2.576e+01],
        [-3.022e+01, -1.676e+01, -2.584e+01,  2.538e-01,  9.205e+01,  2.962e+00,
         -2.883e+01, -2.903e+01, -3.472e+01,  1.029e+02],
        [ 4.725e+01, -4.155e+01,  9.631e+01, -2.515e+01, -7.109e+00, -4.237e+01,
         -4.488e+01, -4.328e+01,  1.122e+02, -3.507e+01],
        [-4.649e+01,  8.531e+01, -4.193e+01,  2.267e+01, -4.002e+01, -3.307e+01,
          6.835e+01, -1.258e+01,  1.043e+02,  2.162e+02],
        [-4.521e+01, -4.711e+01, -2.246e-01,  6.237e+01, -4.650e+01, -2.933e+01,
          9.366e+00,  5.903e+00, -2.250e+01, -3.294e+01],
        [ 9.809e+01,  4.309e+02, -4.192e+01, -3.481e+01, -8.196e+00, -3.565e+01,
          4.502e+01, -1.341e+00,  6.992e+00, -3.371e+01],
        [ 1.158e+02, -3.368e+01,  1.871e+01,  8.164e+00, -4.185e+01, -4.783e+00,
          2.645e+02,  3.063e+01,  4.168e+00, -2.968e+01],
        [-2.926e+01, -2.209e+01, -4.280e+01, -3.664e+01,  4.825e+01,  1.336e+02,
          5.987e+01, -3.022e+00,  6.421e+00, -3.940e+01],
        [ 5.596e+01,  2.362e+01, -2.782e+01, -1.494e+01, -2.980e+01, -2.798e+01,
          9.759e+01, -2.503e+01, -5.675e+00, -5.539e+00],
        [ 4.184e+01, -2.011e+01,  3.404e+01,  2.787e-01, -2.120e+01,  1.481e+02,
          1.151e+01,  8.352e+01, -4.752e+01,  2.324e+02]], device='cuda:0')
v tensor([[1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
         1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
         1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01],
        [1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e+01, 4.314e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e+01, 1.000e-12, 1.000e-12, 7.594e+00],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
         4.350e+00, 1.000e-12, 1.000e-12, 5.306e+00],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 2.792e+00, 1.000e+01, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12],
        [3.893e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e+01, 7.146e-01, 1.000e-12, 1.000e+01],
        [1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
         1.000e-12, 1.000e+01, 8.872e+00, 1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
         6.743e+00, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12],
        [1.000e-12, 1.000e+01, 9.356e+00, 1.000e+01, 1.000e+01, 1.000e+01,
         1.000e-12, 1.000e+01, 9.280e+00, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 3.763e+00,
         1.000e-12, 8.600e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 3.974e+00, 5.696e-01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01,
         1.000e-12, 1.000e-12, 3.816e+00, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
         4.056e+00, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 2.718e+00, 1.000e-12,
         1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01,
         1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e+01, 9.667e+00],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
         1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01,
         1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 2.056e+00,
         1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
         1.000e+01, 3.833e+00, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01],
        [7.165e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01],
        [7.362e-01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
         1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01],
        [1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
         1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e-12, 2.622e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 4.842e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [9.942e+00, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
         1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
         1.000e-12, 2.614e+00, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
         1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01],
        [1.000e-12, 1.000e-12, 5.503e-02, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e+01, 3.017e+00, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01],
        [1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12, 9.823e-01, 1.000e+01, 1.000e-12,
         1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
         1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
         1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
         1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
         1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e-12, 3.791e+00, 1.000e-12, 1.000e-12, 8.563e+00,
         1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12],
        [1.000e-12, 1.000e+01, 6.417e+00, 5.702e+00, 4.060e-01, 1.000e+01,
         1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.281e+00, 1.000e-12, 1.000e-12, 1.000e+01,
         1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12],
        [1.000e-12, 1.000e-12, 4.637e+00, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e+01, 7.709e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 7.471e+00, 3.538e+00,
         9.772e+00, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e+01, 1.000e-12, 4.418e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12],
        [6.433e-02, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
         1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.385e+00,
         1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.677e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 6.416e+00],
        [1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
         1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01],
        [1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
         3.303e+00, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01],
        [4.711e+00, 1.000e+01, 1.000e+01, 1.000e-12, 2.515e+00, 1.000e+01,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 5.136e+00,
         1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01],
        [1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
         1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
         1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.923e+00, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 2.538e-01, 1.000e+01, 2.962e+00,
         1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01],
        [1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
         9.366e+00, 5.903e+00, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e-12, 6.992e+00, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e+01, 8.164e+00, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e+01, 4.168e+00, 1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
         1.000e+01, 1.000e-12, 6.421e+00, 1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
         1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e+01, 2.787e-01, 1.000e-12, 1.000e+01,
         1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01]], device='cuda:0')
v before min max tensor([-4.698e+01, -3.401e+01,  7.909e+01, -1.365e+01,  1.342e+00, -3.293e+01,
        -1.597e+00, -2.257e+01,  3.637e+01, -3.783e+01, -4.009e+01,  9.793e+01,
        -3.593e+01, -3.027e+01, -2.474e+01, -3.508e+01, -1.909e+01, -1.901e+01,
        -1.112e+01, -1.560e+01,  2.858e+01,  7.203e+00, -1.206e+01, -5.361e+01,
        -4.438e+01,  8.436e+00, -3.367e+01, -6.544e+00, -2.675e+01,  2.638e+01,
        -4.064e+01, -3.587e+01, -2.908e+01, -4.287e+01, -1.235e+01,  1.185e-01,
        -6.882e+00,  2.610e+01,  2.004e+02, -2.786e+01, -1.359e+01, -2.317e+01,
        -3.244e+00, -1.475e+01, -4.516e+01,  4.438e+02, -2.620e+01, -2.720e+01,
        -2.181e+01, -1.946e+01,  2.086e+01, -1.624e+01, -2.440e+01, -2.525e+00,
        -3.954e+01, -3.491e+01,  4.074e+00, -3.718e+01,  2.891e+01, -3.225e+01,
        -3.646e+01, -1.005e+01, -3.648e+01,  8.322e+01, -5.392e+01,  5.401e+01,
        -1.555e+01,  3.939e+01, -1.809e+01,  1.783e+02, -3.023e+01, -3.318e+01,
        -1.401e+01, -4.353e+01,  2.907e-01, -2.743e+01, -3.015e+01,  3.097e+01,
         1.755e+02, -3.196e+01, -2.227e+01, -3.208e+01, -1.511e+01, -2.197e+01,
        -7.913e+00, -2.763e+01, -1.922e+00, -2.592e+01, -3.164e+01, -1.620e+01,
         2.218e+02, -2.643e+01, -3.389e+01,  5.463e+01, -4.612e+01, -7.526e+00,
         1.857e+02,  2.228e+01,  4.117e+01,  5.335e+01], device='cuda:0')
v tensor([1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.342e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 7.203e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 8.436e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.185e-01,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 4.074e+00, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 2.907e-01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01], device='cuda:0')
v before min max tensor([[[-18.481],
         [-22.070],
         [332.933],
         [-44.204],
         [  6.256],
         [ 50.814],
         [ 25.447],
         [ 59.507],
         [ 10.738],
         [103.877]],

        [[  7.432],
         [ 32.759],
         [-43.336],
         [-27.228],
         [-26.456],
         [ 86.952],
         [ 73.591],
         [ 62.825],
         [-47.127],
         [-35.351]],

        [[-31.406],
         [-14.846],
         [331.208],
         [-18.682],
         [-35.906],
         [298.784],
         [-27.673],
         [ 15.305],
         [-43.174],
         [-50.707]],

        [[ 28.819],
         [-12.857],
         [-44.180],
         [-26.643],
         [-20.479],
         [-33.929],
         [ 15.474],
         [-20.735],
         [ 52.654],
         [114.839]],

        [[-21.749],
         [-20.782],
         [ -9.513],
         [-43.368],
         [-33.981],
         [ 51.357],
         [-31.985],
         [-40.448],
         [-11.847],
         [-23.402]],

        [[-30.796],
         [ 28.723],
         [-13.601],
         [ 11.975],
         [-44.315],
         [ 34.375],
         [-17.552],
         [-49.422],
         [  8.905],
         [105.992]],

        [[-39.677],
         [-40.019],
         [-15.248],
         [-11.651],
         [-19.641],
         [-40.360],
         [  4.958],
         [-12.911],
         [-35.855],
         [ 44.698]],

        [[ 13.998],
         [ 11.688],
         [ -0.798],
         [-40.462],
         [  6.977],
         [ 19.045],
         [-52.059],
         [-17.243],
         [-26.959],
         [123.818]],

        [[ -4.131],
         [-11.831],
         [ 57.676],
         [-10.991],
         [-42.559],
         [ -6.924],
         [-25.548],
         [-14.427],
         [-14.440],
         [-33.840]],

        [[  3.549],
         [-20.150],
         [-21.964],
         [-47.890],
         [ 22.443],
         [-43.896],
         [-15.503],
         [ 17.608],
         [-39.425],
         [ 23.686]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [6.256e+00],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[7.432e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [8.905e+00],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.958e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [6.977e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[3.549e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]]], device='cuda:0')
v before min max tensor([[-18.465],
        [-20.801],
        [  4.379],
        [-32.421],
        [-46.446],
        [-30.495],
        [ 70.117],
        [-31.349],
        [ 72.995],
        [ 73.421]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e-12],
        [4.379e+00],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01]], device='cuda:0')
a after update for 1 param tensor([[-1.206e-02, -1.350e-02, -1.257e-01, -2.900e-02, -2.819e-02,  1.156e-02,
         -1.181e-01,  5.981e-02,  4.327e-03, -8.155e-02],
        [ 3.812e-02,  5.603e-02, -8.152e-02,  1.570e-02, -2.547e-02,  1.853e-03,
          1.439e-02, -6.376e-02, -2.401e-02, -4.300e-02],
        [-4.708e-02, -2.043e-02, -3.135e-02, -3.580e-02,  2.336e-02, -2.194e-02,
         -8.315e-02,  1.280e-01,  2.851e-02,  5.428e-02],
        [ 4.865e-02,  2.939e-02,  2.887e-03, -1.493e-02,  1.069e-02,  1.455e-02,
          5.810e-02,  1.259e-02,  3.376e-02, -2.963e-03],
        [ 1.020e-02, -8.732e-02,  2.227e-02,  7.092e-02, -2.268e-02,  3.643e-03,
         -5.761e-02,  5.408e-02,  3.765e-02, -1.269e-03],
        [ 3.601e-02,  4.239e-02,  6.160e-02,  8.844e-02, -5.784e-02, -3.379e-02,
         -7.396e-03, -3.818e-02,  4.891e-02, -4.055e-02],
        [-3.037e-02, -3.936e-02,  3.148e-02,  2.739e-02, -7.100e-02, -5.117e-02,
         -1.158e-02, -1.086e-02, -4.028e-03,  9.077e-03],
        [ 1.565e-02, -3.293e-02,  7.096e-03, -1.516e-02, -3.321e-02,  8.034e-03,
          2.459e-02,  1.123e-02, -2.095e-02, -4.282e-02],
        [-3.491e-02, -8.605e-03,  2.453e-02, -5.801e-02,  3.137e-02,  5.775e-02,
         -3.877e-02,  4.222e-02, -2.132e-02,  7.572e-04],
        [ 3.178e-02, -2.335e-02,  5.111e-02, -4.553e-02, -4.243e-03,  4.044e-02,
         -4.272e-02, -6.480e-02,  1.608e-03,  3.252e-02],
        [-2.040e-04, -5.121e-02,  9.399e-02, -3.001e-03, -2.236e-03, -9.101e-02,
         -3.170e-02,  3.177e-02, -4.054e-02,  4.605e-02],
        [-9.931e-03,  2.346e-02,  4.800e-02,  7.642e-02, -3.113e-02, -2.022e-02,
         -1.046e-01,  3.381e-02,  6.289e-02,  1.620e-02],
        [ 6.224e-02, -8.937e-03,  3.292e-02,  1.113e-03,  3.799e-02, -1.903e-02,
         -7.398e-03,  7.790e-03, -2.455e-02,  1.152e-02],
        [-6.644e-03,  1.012e-02,  3.176e-02,  7.190e-03, -1.466e-02,  3.194e-03,
          3.147e-02,  5.512e-02, -2.532e-02,  6.318e-02],
        [ 1.132e-02,  7.732e-04,  2.691e-02,  5.008e-02,  8.472e-03,  1.379e-02,
         -2.313e-02, -1.471e-02,  5.875e-02, -7.323e-02],
        [ 3.789e-03,  3.996e-03,  6.158e-03,  3.461e-02,  1.386e-02,  5.557e-02,
         -7.029e-03,  3.990e-02,  6.712e-03, -1.697e-02],
        [ 6.828e-03, -3.259e-04, -8.233e-03, -4.056e-02, -4.286e-03,  2.276e-03,
          1.867e-02,  8.871e-03, -4.022e-02, -1.883e-02],
        [-1.069e-02,  9.696e-03, -6.003e-02,  3.352e-02,  1.037e-03, -7.803e-04,
          1.205e-02,  2.184e-02,  2.388e-03, -3.130e-02],
        [-7.654e-03,  2.170e-02,  7.918e-04,  8.109e-04, -1.966e-02,  2.831e-02,
         -4.658e-02, -1.132e-01,  6.887e-02,  4.308e-02],
        [-1.511e-03,  3.616e-02,  1.184e-03,  3.458e-02,  5.184e-03,  6.011e-02,
         -8.220e-02,  7.014e-03, -3.664e-02,  7.047e-03],
        [-6.797e-03,  7.937e-03,  1.677e-03, -3.679e-02, -8.987e-03,  1.639e-03,
         -4.386e-03,  8.875e-02,  9.638e-02, -1.489e-02],
        [-1.530e-01,  5.213e-02, -2.699e-02,  5.691e-02, -4.576e-02, -3.141e-02,
          1.747e-02, -1.460e-03,  1.070e-02, -7.019e-02],
        [-1.392e-02,  4.140e-02,  9.188e-04, -2.176e-02,  2.438e-02,  1.353e-02,
         -3.962e-02,  1.787e-02,  2.919e-02,  2.309e-02],
        [ 4.054e-02,  2.630e-02, -7.058e-02, -3.908e-02,  1.894e-02, -2.629e-02,
         -2.138e-02, -7.832e-02, -2.051e-02,  1.046e-02],
        [-1.810e-03, -6.498e-02, -2.311e-02,  1.195e-02,  1.935e-02,  1.888e-02,
          1.538e-03,  1.921e-02,  2.438e-02, -5.042e-02],
        [-5.135e-02,  8.577e-03,  4.277e-03,  7.732e-02,  6.946e-03, -6.450e-03,
         -3.388e-02,  1.219e-02,  2.849e-02,  2.904e-02],
        [ 6.441e-02,  2.565e-02, -1.006e-02, -1.251e-02,  5.099e-02,  5.355e-02,
         -5.221e-02, -1.733e-02,  3.413e-02,  1.405e-02],
        [-3.446e-02,  1.104e-01,  2.072e-02,  2.112e-02,  2.553e-02,  3.524e-02,
          3.789e-03, -4.332e-03,  9.487e-02,  4.556e-02],
        [ 1.879e-02, -3.937e-03, -3.037e-02, -6.811e-02,  2.239e-02,  6.462e-02,
         -4.524e-02, -2.993e-02,  5.856e-03,  6.159e-02],
        [ 3.081e-02,  3.086e-02, -1.044e-01,  3.322e-02,  5.543e-02, -2.141e-03,
         -3.686e-02, -9.544e-03, -2.421e-02, -5.482e-02],
        [-1.223e-02, -4.962e-02, -3.945e-02, -4.776e-02,  5.705e-02,  1.035e-02,
         -3.176e-02, -1.568e-02, -3.258e-02, -5.552e-02],
        [ 5.285e-03,  1.994e-02, -2.348e-02, -7.344e-03, -2.238e-02, -4.868e-02,
         -7.471e-02, -3.404e-02, -1.979e-02, -3.480e-03],
        [-2.490e-02,  3.861e-02, -2.381e-02, -2.616e-02,  1.023e-02, -3.933e-02,
         -5.647e-02, -1.501e-02,  3.046e-02,  9.232e-03],
        [-1.683e-02,  3.940e-02,  4.991e-03,  1.950e-02, -6.333e-03,  2.409e-02,
          3.281e-02,  2.518e-02,  2.715e-02, -4.774e-02],
        [ 2.288e-02,  4.247e-02, -3.082e-02,  1.724e-02, -6.148e-02, -3.637e-02,
         -4.260e-02, -3.072e-02, -1.160e-01, -1.482e-02],
        [ 1.046e-01, -1.407e-02,  1.565e-02,  3.353e-03,  1.133e-02, -1.127e-02,
          8.772e-03, -2.098e-03, -1.597e-02, -6.227e-02],
        [ 1.196e-02, -2.392e-02,  8.358e-02, -2.543e-02,  3.051e-02, -8.489e-03,
          6.552e-02, -1.044e-02,  1.041e-01, -2.468e-02],
        [-9.142e-02, -8.081e-02,  1.049e-01,  1.180e-02,  2.530e-02, -2.247e-02,
         -4.594e-02,  2.451e-02, -2.139e-02,  5.147e-03],
        [-3.721e-02, -3.496e-02,  1.983e-02,  1.678e-02,  1.074e-01, -7.457e-03,
          2.540e-02,  6.378e-03, -6.682e-02,  3.883e-02],
        [-8.468e-03, -2.013e-03, -8.198e-04,  5.052e-02, -3.809e-03,  4.277e-02,
          7.897e-03, -7.618e-02,  5.613e-02, -1.001e-02],
        [-6.265e-02, -4.968e-03, -7.101e-02, -1.248e-02,  5.225e-02, -5.851e-02,
          3.314e-02, -2.678e-02,  5.501e-02,  9.004e-02],
        [-1.604e-03, -1.969e-04,  2.400e-02,  6.789e-02, -3.050e-02, -5.890e-02,
          2.482e-02,  9.904e-02,  1.114e-02, -2.375e-02],
        [-4.762e-05, -3.662e-02,  6.062e-03, -6.350e-03,  1.176e-02,  1.289e-01,
         -7.346e-03, -5.185e-03, -2.029e-02, -1.803e-03],
        [ 7.804e-02, -2.990e-02,  6.755e-02,  3.080e-04,  5.921e-02,  2.887e-03,
          1.945e-01,  8.721e-03,  2.159e-02, -3.819e-02],
        [ 4.863e-02, -5.292e-03, -7.868e-02,  3.913e-02, -5.161e-02,  1.145e-02,
         -3.951e-02,  3.815e-02,  5.615e-02, -3.995e-02],
        [-6.710e-02,  7.534e-04, -1.924e-02, -9.272e-02,  2.262e-03,  2.783e-02,
         -5.391e-02,  1.890e-02,  8.447e-02,  1.490e-03],
        [-7.472e-02,  8.303e-03,  1.258e-02,  1.047e-02,  2.132e-02,  1.359e-02,
         -2.473e-02, -2.012e-02,  6.274e-02, -3.794e-03],
        [ 1.386e-01,  1.909e-02,  3.976e-02,  3.732e-02, -2.100e-02, -1.255e-02,
         -3.678e-02, -3.360e-02, -8.000e-02, -2.251e-02],
        [-3.833e-02,  6.730e-02,  4.348e-02, -3.680e-03, -2.799e-02, -7.584e-03,
         -1.398e-01,  6.901e-02, -7.717e-02, -9.155e-03],
        [-1.461e-02,  1.617e-02,  6.228e-02, -1.309e-02, -3.110e-02, -7.752e-02,
         -4.343e-02, -6.431e-03,  1.918e-02, -1.883e-02],
        [-7.724e-03, -2.112e-02,  6.347e-03, -7.604e-02,  2.828e-02, -6.763e-02,
         -8.320e-03,  1.016e-01, -3.537e-03, -2.938e-03],
        [ 1.724e-02, -4.638e-02,  1.709e-01, -6.552e-02, -2.491e-02, -2.227e-02,
          1.226e-02, -6.193e-02,  2.827e-03,  5.938e-02],
        [-3.216e-02, -5.701e-02,  5.429e-02,  6.677e-02, -3.208e-02, -9.116e-03,
         -4.284e-02,  2.613e-02, -4.970e-02,  4.813e-03],
        [-3.900e-02, -9.756e-02,  8.527e-03,  6.579e-02, -1.536e-02,  9.087e-03,
         -2.208e-02,  5.042e-02, -1.783e-02, -4.761e-02],
        [-3.021e-02,  5.419e-02, -3.104e-02,  3.132e-03, -1.302e-02, -2.483e-02,
         -6.863e-02,  5.579e-02,  1.372e-02, -7.869e-03],
        [-4.152e-02, -2.390e-02, -5.411e-02, -1.147e-01,  1.046e-02,  7.781e-03,
         -1.357e-01, -5.403e-02,  3.658e-02,  1.239e-01],
        [ 1.873e-02,  1.829e-02, -4.215e-02, -1.615e-03,  6.992e-03, -1.364e-03,
         -4.146e-02,  1.003e-02, -5.407e-02,  6.948e-02],
        [ 1.745e-03,  1.219e-02,  8.514e-02,  5.587e-03, -5.045e-03, -8.012e-02,
          3.425e-03, -3.110e-02, -1.835e-02,  6.087e-02],
        [-5.791e-02, -9.059e-02, -5.109e-02, -2.666e-02, -3.120e-02,  1.509e-02,
          2.068e-02, -4.348e-02,  2.033e-03,  4.482e-02],
        [-9.048e-03, -1.821e-03, -1.111e-02, -2.998e-02, -2.749e-02, -3.448e-03,
         -3.906e-02,  2.315e-02,  7.939e-02, -5.346e-02],
        [-3.280e-02, -3.838e-02, -2.697e-02,  9.453e-03, -4.166e-02,  3.854e-02,
          2.996e-02, -5.042e-02, -4.528e-02, -1.034e-01],
        [-8.223e-02,  1.316e-02,  2.471e-03,  1.719e-02, -5.718e-03, -3.539e-02,
          6.742e-02, -9.965e-02, -3.970e-02,  5.759e-02],
        [-1.281e-02,  1.388e-02, -3.457e-02,  1.974e-02,  1.064e-02, -5.938e-02,
          5.154e-02, -1.403e-01, -5.457e-02, -9.941e-03],
        [ 4.089e-02,  6.502e-02,  4.043e-02, -4.439e-03,  1.479e-02, -3.391e-02,
          7.453e-02, -4.261e-03, -5.292e-02, -1.113e-04],
        [ 9.376e-03, -1.145e-03,  1.965e-02, -3.092e-02,  3.355e-02, -3.255e-02,
          3.579e-02, -3.014e-02, -5.824e-03,  5.036e-02],
        [ 1.802e-02,  2.854e-02,  3.476e-02,  1.760e-02,  6.591e-02,  1.343e-02,
          4.735e-02, -2.610e-02,  3.934e-02,  4.310e-02],
        [-8.164e-02,  2.222e-02,  2.306e-03, -1.817e-02,  1.985e-02, -7.228e-02,
          3.872e-02,  4.932e-02,  1.429e-02, -3.317e-02],
        [-1.673e-02,  5.200e-02,  1.336e-01,  1.058e-01,  1.227e-02, -5.282e-02,
         -3.681e-02, -3.772e-03, -3.982e-03, -1.970e-02],
        [ 1.031e-04,  4.697e-02, -2.834e-02, -4.002e-02,  1.010e-01,  3.160e-02,
          2.748e-02, -9.699e-02, -2.207e-02, -2.592e-02],
        [ 2.994e-02, -2.315e-02,  7.972e-02,  1.516e-02,  2.517e-02,  3.939e-02,
         -4.085e-02, -4.852e-02, -2.357e-02, -1.220e-02],
        [ 5.943e-03,  1.324e-02, -3.542e-02, -4.245e-02, -2.403e-02,  1.405e-01,
         -9.336e-03,  1.868e-02, -3.603e-02, -7.438e-02],
        [ 4.272e-03, -3.189e-02, -2.868e-02, -7.770e-03, -5.535e-03,  7.384e-04,
          3.525e-02, -4.824e-02,  7.858e-02, -5.460e-02],
        [-4.912e-02, -4.768e-02, -3.669e-03, -4.917e-02, -7.094e-03,  1.723e-02,
          7.615e-02,  4.445e-03, -7.525e-02,  2.936e-03],
        [ 2.385e-02, -6.871e-04, -9.189e-02, -3.940e-02,  6.416e-03,  5.041e-03,
         -6.684e-04,  1.304e-02,  3.527e-02, -2.737e-02],
        [ 4.508e-02, -7.263e-02, -3.381e-02, -2.009e-02,  2.173e-02, -4.864e-02,
         -1.756e-02, -1.350e-02, -2.447e-02,  1.927e-03],
        [ 1.620e-02,  3.594e-02,  8.507e-02, -1.453e-02, -6.880e-04,  8.303e-02,
          5.769e-02,  4.927e-02, -5.991e-03,  1.774e-02],
        [ 6.642e-03,  9.330e-02, -2.946e-02,  3.397e-02, -1.912e-02,  5.216e-04,
         -1.014e-02,  1.346e-02,  3.000e-02,  4.265e-02],
        [-8.190e-03,  7.987e-02, -3.351e-02,  2.775e-02,  3.986e-02, -6.209e-02,
         -1.583e-02,  6.032e-02, -1.085e-02, -3.224e-03],
        [ 2.731e-03, -6.677e-03,  1.519e-02,  1.353e-02, -2.890e-02,  4.952e-02,
         -6.157e-02, -3.221e-03,  1.718e-02,  1.222e-02],
        [-8.093e-02, -4.516e-03, -1.200e-02,  3.680e-02, -2.543e-02,  2.288e-02,
          3.190e-02,  9.610e-02, -4.924e-03, -5.829e-02],
        [-7.077e-02, -4.382e-03,  1.178e-02,  1.994e-02,  2.424e-02, -8.509e-03,
         -2.122e-02,  5.377e-03, -1.783e-03, -1.503e-02],
        [ 1.550e-03,  1.833e-02, -1.274e-02,  1.774e-02,  1.162e-02,  6.909e-02,
          2.794e-02, -7.221e-02,  4.985e-02,  2.820e-02],
        [-2.918e-02, -1.876e-02,  4.372e-02,  1.451e-02, -8.632e-02, -2.468e-02,
          6.277e-02, -2.681e-03,  3.387e-02, -5.355e-03],
        [ 8.304e-03,  2.184e-02,  6.107e-02, -4.403e-02, -1.820e-02,  5.524e-02,
          3.981e-02, -6.959e-02,  3.292e-02,  8.462e-02],
        [ 2.553e-02,  8.889e-03, -1.403e-02,  1.935e-03,  1.734e-02,  2.784e-02,
          3.218e-02, -3.573e-02, -2.839e-02,  3.120e-02],
        [-7.250e-02,  8.536e-02,  7.148e-02, -3.077e-03,  1.703e-02,  1.286e-02,
          3.043e-02, -2.898e-02, -4.933e-03,  5.233e-02],
        [ 3.317e-02,  1.376e-02, -5.363e-02, -3.043e-02,  4.619e-02, -8.917e-03,
         -8.341e-03,  3.061e-02,  4.766e-02, -3.282e-04],
        [-7.719e-03, -1.116e-02,  6.454e-02, -6.115e-02,  7.961e-03, -2.039e-02,
         -2.922e-02, -8.611e-02, -2.775e-02, -4.087e-02],
        [ 4.325e-02, -1.745e-02,  6.428e-02, -3.202e-02, -5.550e-03, -3.085e-02,
         -9.287e-02, -1.198e-01,  4.123e-02, -4.031e-02],
        [-1.433e-03,  1.786e-02, -1.632e-02, -1.595e-02, -2.042e-02,  2.018e-02,
          1.363e-03, -8.412e-02,  1.228e-02,  2.909e-02],
        [ 1.333e-02,  1.742e-02, -5.292e-03, -1.066e-02, -6.844e-03, -1.196e-01,
         -4.079e-02, -2.774e-03,  8.476e-02,  1.770e-02],
        [ 5.579e-03, -1.388e-03, -5.796e-02, -2.474e-02, -1.618e-02,  2.991e-02,
         -1.477e-02, -1.226e-02, -6.015e-02,  6.037e-02],
        [ 1.484e-02, -6.911e-04,  2.120e-02, -4.754e-02, -5.460e-02,  9.886e-02,
         -1.923e-02, -8.484e-02,  1.189e-02, -2.942e-02],
        [-3.320e-03,  1.972e-04, -4.406e-03,  2.936e-02, -1.431e-02, -3.831e-02,
         -7.632e-03, -3.079e-02, -3.080e-02,  1.629e-02],
        [ 6.900e-02,  1.541e-02, -3.478e-02,  1.821e-02,  6.397e-02,  3.077e-02,
          1.666e-02,  1.220e-02, -3.298e-02,  1.401e-02],
        [ 4.125e-02, -5.111e-02, -1.744e-02,  7.105e-02,  2.720e-02, -5.412e-02,
          3.522e-02, -8.809e-03,  3.091e-02,  3.242e-02],
        [-1.239e-03,  1.941e-02, -6.310e-03, -7.824e-03,  2.652e-02,  8.055e-03,
         -1.557e-02,  2.894e-02, -1.035e-02, -7.995e-03],
        [ 2.113e-02,  4.713e-02, -5.899e-02,  1.757e-02,  2.246e-02,  1.700e-02,
         -8.478e-02,  5.546e-03,  3.174e-02,  3.891e-02],
        [ 5.897e-03, -4.186e-02, -1.806e-02,  1.045e-02,  2.250e-02,  3.012e-02,
         -5.797e-02,  2.211e-02,  7.181e-03, -4.242e-03],
        [-5.070e-02,  7.775e-02,  4.259e-03, -4.804e-02, -6.327e-02, -5.568e-02,
          4.863e-02,  2.282e-02,  7.471e-02, -1.523e-02]], device='cuda:0')
s after update for 1 param tensor([[1.716, 0.811, 1.366, 1.261, 1.685, 1.984, 2.110, 2.022, 1.160, 1.809],
        [1.780, 1.970, 1.738, 1.332, 1.619, 1.112, 1.318, 1.902, 1.254, 1.869],
        [1.974, 1.135, 1.529, 1.234, 2.009, 1.314, 1.954, 1.419, 0.656, 1.675],
        [2.055, 1.503, 1.847, 1.517, 2.143, 1.701, 2.069, 1.377, 1.685, 1.895],
        [2.355, 2.048, 1.595, 1.385, 2.005, 1.828, 1.615, 1.795, 1.611, 1.414],
        [1.703, 1.451, 1.897, 1.705, 1.788, 1.544, 1.436, 1.806, 1.549, 1.563],
        [2.225, 1.875, 2.060, 0.931, 1.833, 1.813, 1.663, 1.807, 1.279, 1.917],
        [2.001, 1.638, 1.738, 1.767, 1.746, 1.622, 1.499, 1.774, 1.537, 1.384],
        [1.948, 1.637, 1.457, 1.844, 2.103, 1.493, 1.723, 1.774, 1.447, 1.036],
        [2.356, 1.640, 1.950, 1.168, 1.511, 1.770, 1.887, 2.067, 1.991, 1.585],
        [2.367, 1.139, 1.771, 1.702, 1.731, 1.318, 1.716, 1.976, 1.204, 1.299],
        [1.209, 1.644, 1.678, 2.467, 1.946, 1.557, 1.821, 2.230, 1.659, 0.973],
        [2.031, 1.149, 1.394, 0.035, 0.928, 1.653, 1.220, 1.452, 1.629, 1.058],
        [1.761, 1.963, 2.016, 1.776, 1.929, 1.599, 1.826, 1.587, 1.269, 1.662],
        [1.775, 1.616, 1.897, 1.616, 1.694, 2.146, 1.906, 1.354, 1.413, 1.505],
        [1.844, 1.305, 1.656, 1.528, 1.529, 1.106, 1.311, 1.692, 1.603, 1.797],
        [1.512, 0.756, 1.436, 1.509, 1.780, 1.547, 1.264, 1.829, 1.638, 1.283],
        [1.911, 1.240, 1.627, 1.628, 2.147, 1.589, 1.632, 1.944, 1.306, 1.103],
        [1.748, 1.963, 2.019, 0.261, 2.076, 1.406, 1.693, 1.229, 1.605, 1.559],
        [1.559, 2.273, 1.734, 1.874, 1.887, 1.928, 1.937, 1.783, 1.927, 1.504],
        [1.683, 1.091, 1.493, 1.201, 1.136, 1.701, 1.224, 1.869, 1.398, 1.578],
        [1.812, 1.712, 1.936, 1.472, 2.107, 0.811, 2.101, 1.265, 1.730, 1.644],
        [1.941, 1.781, 1.789, 1.460, 1.837, 1.575, 1.842, 1.393, 1.127, 1.067],
        [1.279, 2.033, 2.317, 2.029, 1.709, 1.743, 1.575, 1.481, 1.061, 1.488],
        [1.752, 1.955, 2.389, 1.728, 1.478, 0.813, 0.790, 1.495, 1.498, 1.945],
        [1.846, 2.275, 1.613, 2.275, 1.790, 1.769, 1.825, 1.552, 1.461, 1.343],
        [2.001, 1.435, 1.949, 1.704, 1.960, 1.669, 1.609, 1.905, 1.550, 1.675],
        [2.115, 1.574, 1.912, 1.006, 1.027, 1.637, 1.673, 1.483, 2.086, 1.772],
        [1.635, 0.974, 1.367, 1.519, 2.057, 2.079, 2.057, 2.023, 0.810, 2.039],
        [1.609, 1.081, 2.040, 1.498, 2.039, 0.957, 1.617, 1.043, 1.103, 1.912],
        [1.237, 1.453, 1.549, 1.990, 2.073, 1.014, 1.269, 1.879, 1.363, 1.911],
        [1.458, 1.347, 2.012, 1.458, 1.797, 1.700, 2.162, 1.438, 1.857, 1.082],
        [1.694, 2.012, 1.401, 2.342, 1.107, 1.593, 1.939, 1.782, 1.673, 1.383],
        [1.728, 1.470, 1.515, 2.253, 1.012, 1.571, 1.979, 1.716, 1.346, 1.635],
        [1.280, 1.348, 2.200, 1.602, 1.686, 1.848, 1.674, 1.517, 2.255, 1.339],
        [1.790, 1.943, 1.385, 1.665, 1.842, 0.731, 0.962, 1.487, 1.127, 1.495],
        [1.452, 1.336, 1.995, 1.807, 2.171, 1.731, 1.599, 1.544, 1.586, 1.945],
        [2.028, 2.065, 1.950, 1.200, 1.890, 1.488, 1.881, 1.360, 1.886, 1.033],
        [1.441, 2.021, 1.946, 2.140, 1.850, 1.645, 2.168, 1.418, 2.188, 1.728],
        [1.862, 2.151, 1.993, 1.418, 1.659, 1.295, 0.877, 1.859, 1.448, 1.845],
        [2.064, 1.534, 2.156, 1.225, 1.994, 1.801, 1.661, 1.273, 1.607, 1.878],
        [1.427, 1.729, 1.383, 1.935, 2.315, 2.006, 2.136, 1.596, 1.456, 1.258],
        [1.875, 2.040, 1.565, 1.440, 1.848, 2.192, 0.850, 1.485, 1.536, 2.285],
        [2.134, 1.824, 1.880, 1.796, 2.037, 1.984, 1.929, 1.473, 1.462, 1.739],
        [0.942, 1.071, 1.799, 1.687, 1.383, 1.220, 2.276, 1.323, 1.682, 1.292],
        [1.501, 1.651, 1.501, 1.754, 1.544, 1.526, 1.952, 2.106, 1.795, 1.163],
        [1.971, 1.445, 1.555, 1.386, 2.237, 1.998, 1.595, 0.985, 1.659, 2.113],
        [1.947, 1.052, 1.706, 1.544, 1.720, 1.530, 1.476, 2.151, 1.512, 1.889],
        [1.667, 1.982, 2.095, 1.531, 1.965, 1.440, 2.235, 1.856, 1.143, 1.695],
        [1.936, 0.674, 1.446, 1.195, 1.799, 1.460, 1.621, 1.294, 1.559, 1.659],
        [1.568, 1.327, 1.311, 2.128, 2.026, 1.825, 1.500, 1.778, 1.067, 0.770],
        [2.192, 1.575, 2.155, 1.542, 1.514, 1.558, 1.874, 1.232, 0.657, 2.342],
        [1.589, 1.914, 1.530, 1.805, 1.173, 1.233, 1.323, 1.483, 1.868, 1.713],
        [1.319, 1.813, 1.603, 1.571, 1.969, 1.611, 2.022, 1.004, 1.695, 1.444],
        [1.743, 1.621, 1.514, 1.709, 1.600, 2.000, 1.079, 1.370, 0.594, 1.244],
        [1.824, 1.560, 2.117, 1.689, 1.185, 1.439, 1.425, 1.726, 0.913, 1.787],
        [1.739, 1.473, 2.112, 0.951, 1.190, 1.799, 1.798, 1.594, 1.280, 1.524],
        [1.406, 1.189, 2.143, 1.933, 1.718, 1.977, 1.542, 1.375, 1.193, 1.472],
        [2.019, 2.149, 1.805, 1.346, 2.064, 1.711, 1.934, 1.931, 2.044, 1.635],
        [1.094, 1.463, 0.679, 1.485, 1.993, 1.589, 2.125, 1.517, 1.926, 1.682],
        [2.305, 2.181, 2.047, 1.832, 2.027, 1.803, 2.052, 2.268, 2.050, 2.208],
        [2.145, 2.366, 2.092, 2.054, 2.092, 1.716, 2.029, 2.088, 1.567, 1.829],
        [2.280, 1.841, 2.339, 0.804, 1.863, 1.752, 1.946, 2.085, 1.770, 1.652],
        [2.375, 2.071, 1.636, 0.314, 1.987, 1.343, 2.183, 1.946, 2.013, 1.618],
        [2.120, 0.959, 1.876, 1.308, 1.351, 1.806, 1.653, 1.946, 1.359, 1.850],
        [2.566, 1.864, 2.058, 0.947, 2.614, 2.090, 2.341, 2.551, 1.293, 1.876],
        [2.478, 1.810, 1.936, 1.676, 2.044, 1.637, 2.320, 2.572, 1.545, 2.129],
        [2.389, 2.006, 2.019, 1.718, 2.201, 2.016, 2.553, 1.985, 1.756, 2.049],
        [1.246, 1.618, 1.639, 1.744, 1.706, 1.504, 1.642, 2.265, 1.399, 1.862],
        [2.248, 1.922, 2.064, 1.424, 1.646, 2.170, 2.123, 2.231, 2.100, 1.894],
        [1.748, 1.956, 1.600, 1.547, 1.319, 2.256, 1.155, 2.388, 1.602, 1.771],
        [1.314, 1.398, 1.964, 1.832, 1.636, 1.053, 1.746, 1.620, 1.734, 1.638],
        [1.524, 1.272, 1.718, 1.727, 1.933, 1.427, 2.011, 2.004, 2.017, 1.114],
        [2.248, 1.729, 1.725, 1.719, 1.473, 1.979, 1.629, 2.045, 1.793, 1.740],
        [1.081, 1.911, 1.391, 1.680, 1.581, 1.390, 1.278, 2.125, 1.926, 1.764],
        [1.832, 1.599, 2.229, 1.765, 1.477, 1.795, 1.541, 2.323, 1.956, 1.418],
        [1.469, 1.754, 1.414, 1.034, 1.941, 2.031, 1.114, 1.495, 1.832, 2.116],
        [1.229, 1.777, 1.731, 1.504, 1.870, 1.180, 1.724, 2.114, 1.266, 1.280],
        [1.972, 1.798, 1.791, 1.624, 1.646, 1.788, 1.651, 1.420, 1.796, 1.263],
        [1.796, 0.912, 1.789, 1.859, 0.684, 1.404, 1.570, 2.333, 1.490, 1.779],
        [1.727, 1.360, 1.187, 1.812, 1.872, 1.079, 1.161, 1.002, 1.744, 2.030],
        [1.869, 1.610, 2.022, 1.415, 1.952, 1.638, 1.446, 1.499, 1.871, 2.016],
        [2.024, 1.652, 1.506, 1.666, 2.181, 1.623, 1.945, 1.718, 1.888, 1.500],
        [2.149, 1.306, 1.311, 2.087, 1.916, 1.362, 1.686, 2.332, 1.506, 1.915],
        [1.598, 1.634, 1.696, 1.463, 1.568, 1.160, 1.752, 1.798, 2.157, 1.797],
        [2.134, 1.643, 1.879, 1.478, 1.976, 0.656, 1.718, 1.528, 2.343, 1.752],
        [1.933, 1.640, 1.865, 1.212, 1.700, 1.869, 1.300, 1.718, 1.985, 2.020],
        [1.809, 1.527, 1.972, 1.846, 1.123, 1.036, 1.994, 2.029, 1.927, 1.600],
        [1.959, 1.652, 0.942, 1.264, 1.277, 1.963, 1.789, 2.083, 2.038, 1.456],
        [1.042, 1.606, 2.093, 1.721, 1.822, 1.306, 1.922, 1.837, 2.057, 1.606],
        [1.543, 1.894, 1.702, 1.775, 0.458, 1.733, 1.403, 1.582, 1.203, 1.439],
        [1.806, 1.135, 1.143, 0.712, 2.174, 0.950, 1.379, 1.752, 1.484, 2.228],
        [2.396, 1.635, 1.837, 1.249, 1.466, 2.030, 1.765, 1.747, 1.967, 1.390],
        [1.827, 2.262, 1.946, 1.843, 1.628, 1.292, 1.724, 1.493, 1.991, 2.028],
        [1.826, 1.930, 1.472, 1.780, 1.881, 1.678, 1.944, 1.761, 1.303, 1.750],
        [2.020, 2.018, 2.027, 1.737, 1.795, 1.392, 2.286, 1.511, 1.994, 1.357],
        [1.927, 1.410, 1.823, 1.524, 1.762, 1.813, 1.780, 1.920, 1.025, 1.926],
        [1.478, 1.785, 1.762, 2.058, 1.385, 1.890, 2.307, 1.396, 1.822, 2.074],
        [1.424, 2.098, 1.873, 1.528, 1.173, 1.825, 2.069, 1.500, 1.929, 0.972],
        [2.377, 1.642, 1.967, 1.324, 0.890, 1.944, 2.079, 2.171, 2.107, 1.709]],
       device='cuda:0')
b after update for 1 param tensor([[58.754, 40.406, 52.417, 50.364, 58.227, 63.186, 65.156, 63.788, 48.318,
         60.325],
        [59.850, 62.958, 59.127, 51.761, 57.075, 47.301, 51.499, 61.864, 50.226,
         61.319],
        [63.022, 47.798, 55.461, 49.837, 63.579, 51.418, 62.700, 53.434, 36.336,
         58.050],
        [64.295, 54.997, 60.960, 55.240, 65.659, 58.500, 64.526, 52.637, 58.232,
         61.744],
        [68.836, 64.194, 56.650, 52.788, 63.520, 60.644, 57.010, 60.089, 56.937,
         53.330],
        [58.544, 54.024, 61.776, 58.569, 59.981, 55.739, 53.754, 60.279, 55.826,
         56.072],
        [66.910, 61.425, 64.383, 43.278, 60.728, 60.395, 57.847, 60.293, 50.726,
         62.110],
        [63.452, 57.414, 59.127, 59.621, 59.263, 57.132, 54.918, 59.737, 55.618,
         52.777],
        [62.606, 57.392, 54.149, 60.918, 65.048, 54.807, 58.884, 59.744, 53.949,
         45.651],
        [68.856, 57.449, 62.638, 48.482, 55.147, 59.671, 61.610, 64.490, 63.285,
         56.473],
        [69.017, 47.877, 59.687, 58.521, 59.014, 51.504, 58.755, 63.055, 49.213,
         51.122],
        [49.315, 57.506, 58.106, 70.455, 62.573, 55.962, 60.525, 66.990, 57.772,
         44.235],
        [63.932, 48.075, 52.963,  8.359, 43.210, 57.676, 49.549, 54.056, 57.243,
         46.149],
        [59.532, 62.850, 63.682, 59.772, 62.301, 56.726, 60.611, 56.512, 50.525,
         57.827],
        [59.757, 57.023, 61.775, 57.020, 58.380, 65.710, 61.932, 52.202, 53.328,
         55.036],
        [60.918, 51.234, 57.726, 55.442, 55.464, 47.179, 51.360, 58.347, 56.793,
         60.128],
        [55.156, 39.010, 53.744, 55.097, 59.850, 55.793, 50.440, 60.660, 57.412,
         50.817],
        [62.003, 49.943, 57.222, 57.241, 65.724, 56.541, 57.310, 62.533, 51.271,
         47.104],
        [59.312, 62.845, 63.737, 22.906, 64.627, 53.188, 58.362, 49.719, 56.832,
         55.999],
        [56.011, 67.623, 59.063, 61.411, 61.615, 62.278, 62.423, 59.900, 62.274,
         55.007],
        [58.186, 46.843, 54.813, 49.155, 47.803, 58.508, 49.634, 61.321, 53.040,
         56.353],
        [60.387, 58.697, 62.414, 54.414, 65.115, 40.402, 65.015, 50.459, 59.005,
         57.510],
        [62.501, 59.859, 59.999, 54.198, 60.790, 56.285, 60.879, 52.950, 47.626,
         46.343],
        [50.721, 63.953, 68.272, 63.891, 58.644, 59.228, 56.285, 54.591, 46.207,
         54.722],
        [59.367, 62.724, 69.331, 58.970, 54.528, 40.456, 39.871, 54.851, 54.901,
         62.563],
        [60.945, 67.659, 56.975, 67.660, 60.009, 59.662, 60.596, 55.885, 54.212,
         51.977],
        [63.446, 53.736, 62.617, 58.559, 62.790, 57.949, 56.905, 61.919, 55.836,
         58.052],
        [65.236, 56.274, 62.018, 45.001, 45.453, 57.384, 58.015, 54.630, 64.777,
         59.709],
        [57.357, 44.262, 52.438, 55.283, 64.329, 64.670, 64.337, 63.796, 40.371,
         64.047],
        [56.895, 46.641, 64.059, 54.900, 64.058, 43.882, 57.036, 45.811, 47.117,
         62.031],
        [49.879, 54.077, 55.829, 63.272, 64.579, 45.165, 50.529, 61.481, 52.367,
         62.005],
        [54.163, 52.065, 63.627, 54.157, 60.137, 58.480, 65.954, 53.798, 61.122,
         46.669],
        [58.385, 63.625, 53.097, 68.644, 47.201, 56.620, 62.467, 59.885, 58.020,
         52.751],
        [58.961, 54.383, 55.214, 67.331, 45.127, 56.227, 63.104, 58.762, 52.032,
         57.355],
        [50.744, 52.078, 66.536, 56.766, 58.252, 60.980, 58.029, 55.245, 67.361,
         51.914],
        [60.012, 62.521, 52.795, 57.888, 60.872, 38.363, 44.001, 54.701, 47.612,
         54.851],
        [54.050, 51.850, 63.357, 60.305, 66.098, 59.022, 56.725, 55.734, 56.485,
         62.560],
        [63.885, 64.453, 62.638, 49.127, 61.661, 54.708, 61.518, 52.317, 61.608,
         45.581],
        [53.849, 63.768, 62.577, 65.620, 61.004, 57.528, 66.039, 53.409, 66.344,
         58.965],
        [61.201, 65.780, 63.329, 53.417, 57.769, 51.048, 42.014, 61.159, 53.974,
         60.936],
        [64.438, 55.555, 65.860, 49.649, 63.348, 60.205, 57.802, 50.603, 56.862,
         61.475],
        [53.576, 58.988, 52.749, 62.394, 68.255, 63.534, 65.554, 56.674, 54.127,
         50.307],
        [61.415, 64.060, 56.114, 53.829, 60.977, 66.416, 41.365, 54.669, 55.599,
         67.801],
        [65.524, 60.576, 61.506, 60.112, 64.023, 63.182, 62.305, 54.437, 54.237,
         59.154],
        [43.542, 46.431, 60.159, 58.255, 52.750, 49.540, 67.668, 51.585, 58.175,
         50.982],
        [54.950, 57.642, 54.959, 59.407, 55.741, 55.405, 62.674, 65.096, 60.096,
         48.363],
        [62.972, 53.918, 55.937, 52.808, 67.089, 63.404, 56.646, 44.517, 57.767,
         65.209],
        [62.583, 46.003, 58.596, 55.738, 58.835, 55.488, 54.490, 65.790, 55.154,
         61.646],
        [57.911, 63.148, 64.931, 55.500, 62.872, 53.827, 67.063, 61.105, 47.951,
         58.401],
        [62.419, 36.814, 53.935, 49.029, 60.156, 54.197, 57.109, 51.018, 56.008,
         57.782],
        [56.167, 51.676, 51.351, 65.433, 63.843, 60.605, 54.946, 59.819, 46.334,
         39.352],
        [66.404, 56.302, 65.848, 55.694, 55.184, 55.997, 61.397, 49.781, 36.366,
         68.650],
        [56.546, 62.053, 55.479, 60.266, 48.572, 49.812, 51.589, 54.624, 61.311,
         58.713],
        [51.520, 60.397, 56.798, 56.225, 62.950, 56.928, 63.791, 44.954, 58.399,
         53.909],
        [59.222, 57.111, 55.191, 58.643, 56.732, 63.436, 46.596, 52.505, 34.565,
         50.026],
        [60.584, 56.018, 65.265, 58.293, 48.827, 53.816, 53.542, 58.934, 42.869,
         59.961],
        [59.144, 54.438, 65.194, 43.734, 48.925, 60.168, 60.149, 56.625, 50.751,
         55.381],
        [53.196, 48.907, 65.664, 62.362, 58.794, 63.070, 55.701, 52.599, 49.001,
         54.426],
        [63.731, 65.763, 60.258, 52.032, 64.450, 58.665, 62.381, 62.339, 64.126,
         57.354],
        [46.927, 54.258, 36.971, 54.655, 63.324, 56.537, 65.394, 55.242, 62.249,
         58.174],
        [68.099, 66.239, 64.179, 60.711, 63.867, 60.236, 64.250, 67.546, 64.227,
         66.659],
        [65.697, 68.990, 64.884, 64.289, 64.878, 58.765, 63.896, 64.812, 56.153,
         60.659],
        [67.731, 60.860, 68.601, 40.228, 61.223, 59.364, 62.577, 64.774, 59.671,
         57.653],
        [69.123, 64.552, 57.376, 25.143, 63.224, 51.982, 66.276, 62.573, 63.638,
         57.059],
        [65.318, 43.920, 61.435, 51.298, 52.144, 60.278, 57.663, 62.575, 52.295,
         61.008],
        [71.859, 61.248, 64.354, 43.656, 72.522, 64.850, 68.624, 71.636, 51.009,
         61.430],
        [70.606, 60.345, 62.409, 58.070, 64.132, 57.399, 68.315, 71.932, 55.746,
         65.453],
        [69.338, 63.534, 63.728, 58.788, 66.542, 63.686, 71.678, 63.195, 59.442,
         64.205],
        [50.066, 57.060, 57.418, 59.231, 58.588, 55.006, 57.475, 67.501, 53.051,
         61.202],
        [67.252, 62.184, 64.443, 53.526, 57.545, 66.083, 65.362, 67.006, 65.000,
         61.732],
        [59.310, 62.732, 56.733, 55.798, 51.517, 67.380, 48.198, 69.309, 56.777,
         59.686],
        [51.422, 53.031, 62.857, 60.713, 57.372, 46.039, 59.267, 57.099, 59.067,
         57.411],
        [55.377, 50.591, 58.791, 58.943, 62.359, 53.584, 63.605, 63.500, 63.709,
         47.345],
        [67.254, 58.980, 58.906, 58.805, 54.433, 63.098, 57.245, 64.149, 60.066,
         59.174],
        [46.634, 62.005, 52.898, 58.131, 56.408, 52.889, 50.710, 65.384, 62.256,
         59.583],
        [60.710, 56.727, 66.963, 59.600, 54.510, 60.093, 55.690, 68.366, 62.736,
         53.414],
        [54.357, 59.414, 53.342, 45.615, 62.497, 63.931, 47.336, 54.836, 60.711,
         65.246],
        [49.722, 59.791, 59.016, 55.018, 61.340, 48.728, 58.891, 65.212, 50.462,
         50.742],
        [62.998, 60.150, 60.028, 57.160, 57.548, 59.982, 57.641, 53.460, 60.106,
         50.417],
        [60.114, 42.831, 59.994, 61.152, 37.087, 53.150, 56.210, 68.511, 54.759,
         59.835],
        [58.948, 52.303, 48.863, 60.381, 61.367, 46.584, 48.331, 44.891, 59.229,
         63.915],
        [61.318, 56.916, 63.790, 53.353, 62.672, 57.413, 53.931, 54.920, 61.352,
         63.684],
        [63.815, 57.645, 55.050, 57.905, 66.249, 57.150, 62.550, 58.786, 61.630,
         54.939],
        [65.762, 51.254, 51.368, 64.795, 62.095, 52.343, 58.240, 68.497, 55.042,
         62.080],
        [56.694, 57.335, 58.421, 54.252, 56.176, 48.314, 59.379, 60.154, 65.878,
         60.130],
        [65.524, 57.497, 61.485, 54.529, 63.062, 36.333, 58.787, 55.445, 68.666,
         59.378],
        [62.357, 57.437, 61.254, 49.376, 58.488, 61.328, 51.148, 58.800, 63.197,
         63.757],
        [60.326, 55.434, 62.986, 60.943, 47.529, 45.650, 63.346, 63.893, 62.268,
         56.733],
        [62.786, 57.646, 43.541, 50.422, 50.682, 62.839, 60.003, 64.731, 64.029,
         54.123],
        [45.778, 56.841, 64.886, 58.846, 60.549, 51.262, 62.183, 60.788, 64.339,
         56.838],
        [55.711, 61.738, 58.514, 59.761, 30.341, 59.051, 53.133, 56.417, 49.201,
         53.815],
        [60.276, 47.792, 47.949, 37.851, 66.139, 43.727, 52.682, 59.374, 54.634,
         66.950],
        [69.434, 57.349, 60.798, 50.128, 54.309, 63.917, 59.598, 59.288, 62.913,
         52.891],
        [60.636, 67.461, 62.581, 60.893, 57.227, 50.991, 58.889, 54.806, 63.298,
         63.876],
        [60.621, 62.318, 54.419, 59.852, 61.517, 58.097, 62.539, 59.527, 51.199,
         59.341],
        [63.755, 63.714, 63.860, 59.125, 60.095, 52.925, 67.813, 55.144, 63.345,
         52.259],
        [62.270, 53.266, 60.560, 55.380, 59.545, 60.393, 59.852, 62.158, 45.407,
         62.255],
        [54.534, 59.931, 59.538, 64.346, 52.787, 61.666, 68.133, 52.997, 60.550,
         64.596],
        [53.521, 64.970, 61.396, 55.453, 48.584, 60.601, 64.514, 54.937, 62.298,
         44.218],
        [69.158, 57.485, 62.912, 51.617, 42.321, 62.544, 64.683, 66.092, 65.117,
         58.648]], device='cuda:0')
clipping threshold 1.1007809370850175
a after update for 1 param tensor([ 0.007,  0.004,  0.023,  0.020,  0.067, -0.022,  0.022, -0.030,  0.076,
        -0.021, -0.025, -0.048,  0.043, -0.107, -0.041, -0.021, -0.065,  0.019,
         0.009, -0.017,  0.023,  0.004, -0.055,  0.097,  0.083,  0.016, -0.031,
         0.054,  0.061, -0.079, -0.079, -0.065, -0.032,  0.029, -0.041, -0.003,
         0.089, -0.016, -0.015,  0.014, -0.078, -0.004, -0.001,  0.016,  0.050,
         0.003,  0.014,  0.020, -0.034, -0.041, -0.001, -0.003,  0.031, -0.024,
        -0.037, -0.032,  0.115,  0.071, -0.065, -0.060, -0.031,  0.032, -0.002,
         0.007, -0.005, -0.054, -0.005,  0.039,  0.045, -0.058,  0.080, -0.062,
         0.008, -0.017, -0.001, -0.058, -0.073,  0.002, -0.076,  0.014,  0.018,
         0.022,  0.019,  0.030, -0.040, -0.034,  0.041,  0.107,  0.025, -0.014,
        -0.070,  0.002, -0.025,  0.011, -0.077,  0.010, -0.031,  0.026,  0.030,
        -0.028], device='cuda:0')
s after update for 1 param tensor([1.871, 1.329, 1.479, 0.705, 1.634, 1.467, 0.978, 1.013, 1.932, 1.485,
        1.610, 2.047, 1.565, 2.092, 2.016, 1.825, 1.294, 1.383, 1.436, 1.343,
        1.473, 1.480, 1.035, 2.146, 1.955, 1.411, 1.338, 1.101, 1.266, 1.585,
        1.778, 1.603, 1.544, 1.817, 2.390, 0.800, 1.860, 1.948, 1.643, 1.711,
        1.423, 0.997, 0.127, 1.643, 1.767, 2.138, 1.480, 1.068, 1.137, 1.637,
        1.618, 0.990, 1.877, 0.794, 1.593, 1.364, 1.514, 2.051, 1.772, 1.520,
        1.680, 0.932, 1.455, 1.782, 2.266, 1.956, 0.820, 1.554, 1.142, 1.561,
        1.285, 1.477, 0.563, 1.700, 1.510, 1.566, 1.177, 1.840, 1.989, 1.491,
        1.829, 1.632, 1.152, 1.628, 1.843, 1.567, 1.431, 1.510, 1.501, 2.132,
        2.039, 1.296, 1.957, 1.672, 1.806, 1.115, 1.856, 1.706, 1.791, 1.513],
       device='cuda:0')
b after update for 1 param tensor([61.355, 51.705, 54.559, 37.664, 57.342, 54.324, 44.359, 45.152, 62.349,
        54.666, 56.920, 64.173, 56.123, 64.886, 63.682, 60.591, 51.024, 52.746,
        53.745, 51.978, 54.437, 54.575, 45.636, 65.715, 62.717, 53.278, 51.880,
        47.070, 50.471, 56.471, 59.804, 56.791, 55.735, 60.463, 69.349, 40.133,
        61.168, 62.608, 57.489, 58.677, 53.513, 44.781, 15.965, 57.502, 59.628,
        65.595, 54.574, 46.346, 47.830, 57.397, 57.063, 44.626, 61.460, 39.982,
        56.617, 52.392, 55.186, 64.232, 59.712, 55.305, 58.135, 43.295, 54.103,
        59.876, 67.515, 62.734, 40.614, 55.916, 47.927, 56.037, 50.855, 54.512,
        33.647, 58.483, 55.124, 56.131, 48.672, 60.852, 63.265, 54.774, 60.663,
        57.302, 48.139, 57.236, 60.894, 56.151, 53.658, 55.119, 54.947, 65.493,
        64.047, 51.055, 62.754, 58.008, 60.281, 47.370, 61.105, 58.596, 60.027,
        55.169], device='cuda:0')
clipping threshold 1.1007809370850175
a after update for 1 param tensor([[[-4.302e-02],
         [ 1.686e-02],
         [ 3.831e-02],
         [ 1.009e-02],
         [-5.762e-02],
         [ 9.111e-03],
         [ 1.474e-02],
         [-5.014e-02],
         [ 5.748e-02],
         [ 4.739e-02]],

        [[ 6.786e-03],
         [ 1.077e-02],
         [ 1.329e-02],
         [-1.717e-02],
         [-4.246e-02],
         [-1.837e-02],
         [-1.739e-02],
         [ 8.538e-03],
         [ 2.710e-02],
         [-2.260e-02]],

        [[-1.713e-02],
         [-2.459e-03],
         [ 1.272e-02],
         [-9.730e-02],
         [-2.610e-02],
         [-2.400e-03],
         [-1.650e-02],
         [-2.080e-03],
         [-4.097e-02],
         [-1.791e-02]],

        [[ 5.722e-02],
         [ 3.089e-02],
         [-1.929e-02],
         [-3.857e-02],
         [-1.879e-02],
         [ 1.803e-03],
         [-7.697e-02],
         [-1.953e-05],
         [ 1.406e-03],
         [ 4.833e-03]],

        [[ 6.120e-02],
         [-4.726e-03],
         [-5.887e-02],
         [-3.921e-02],
         [ 2.997e-02],
         [ 1.026e-01],
         [ 8.107e-03],
         [-3.193e-02],
         [-5.072e-02],
         [ 2.719e-02]],

        [[-1.745e-02],
         [-1.424e-02],
         [ 4.382e-02],
         [-4.934e-03],
         [-2.028e-02],
         [ 5.861e-02],
         [-2.382e-02],
         [ 5.725e-02],
         [-2.565e-02],
         [-3.595e-02]],

        [[ 1.576e-02],
         [ 3.747e-02],
         [ 9.927e-02],
         [ 6.474e-02],
         [-2.131e-03],
         [ 1.056e-02],
         [ 1.717e-02],
         [ 5.250e-02],
         [-3.210e-02],
         [-1.920e-02]],

        [[-2.277e-04],
         [-4.560e-03],
         [-7.004e-03],
         [ 4.766e-02],
         [-1.143e-02],
         [-6.765e-03],
         [ 1.432e-01],
         [ 1.467e-02],
         [ 2.486e-02],
         [ 1.419e-02]],

        [[ 1.919e-03],
         [-5.206e-03],
         [ 8.688e-05],
         [-1.031e-02],
         [ 4.964e-02],
         [ 6.102e-02],
         [-4.016e-03],
         [ 9.324e-02],
         [ 2.902e-02],
         [-8.860e-02]],

        [[ 2.175e-02],
         [-1.542e-02],
         [-2.526e-02],
         [-1.435e-02],
         [-7.275e-02],
         [ 6.129e-02],
         [-3.866e-02],
         [ 3.734e-02],
         [-2.815e-02],
         [-1.184e-02]]], device='cuda:0')
s after update for 1 param tensor([[[1.567],
         [1.790],
         [2.107],
         [1.982],
         [1.680],
         [1.727],
         [1.756],
         [1.875],
         [2.096],
         [1.905]],

        [[1.520],
         [1.891],
         [1.702],
         [1.166],
         [1.140],
         [1.888],
         [2.032],
         [1.508],
         [1.877],
         [2.085]],

        [[1.296],
         [1.298],
         [1.970],
         [1.900],
         [1.858],
         [1.881],
         [1.081],
         [1.676],
         [1.740],
         [1.987]],

        [[1.740],
         [1.676],
         [1.790],
         [1.817],
         [1.156],
         [1.337],
         [2.207],
         [1.678],
         [1.455],
         [1.354]],

        [[1.545],
         [1.746],
         [1.855],
         [1.832],
         [1.327],
         [1.874],
         [1.251],
         [1.922],
         [1.450],
         [0.980]],

        [[1.453],
         [1.471],
         [1.344],
         [1.517],
         [2.036],
         [1.863],
         [1.261],
         [2.108],
         [1.651],
         [2.347]],

        [[1.609],
         [1.683],
         [1.513],
         [1.661],
         [1.375],
         [1.646],
         [2.033],
         [0.727],
         [1.400],
         [1.706]],

        [[1.825],
         [2.180],
         [1.801],
         [1.616],
         [2.083],
         [1.628],
         [2.033],
         [1.464],
         [1.100],
         [1.695]],

        [[1.166],
         [0.965],
         [1.815],
         [1.698],
         [1.671],
         [1.715],
         [1.070],
         [1.637],
         [1.453],
         [2.316]],

        [[1.592],
         [1.545],
         [1.207],
         [1.908],
         [2.429],
         [1.827],
         [0.666],
         [1.657],
         [1.760],
         [1.228]]], device='cuda:0')
b after update for 1 param tensor([[[56.149],
         [60.014],
         [65.117],
         [63.142],
         [58.137],
         [58.944],
         [59.436],
         [61.414],
         [64.947],
         [61.908]],

        [[55.308],
         [61.683],
         [58.516],
         [48.430],
         [47.897],
         [61.633],
         [63.938],
         [55.086],
         [61.456],
         [64.772]],

        [[51.059],
         [51.100],
         [62.953],
         [61.827],
         [61.148],
         [61.522],
         [46.631],
         [58.072],
         [59.171],
         [63.225]],

        [[59.173],
         [58.068],
         [60.005],
         [60.458],
         [48.227],
         [51.872],
         [66.632],
         [58.099],
         [54.099],
         [52.188]],

        [[55.761],
         [59.273],
         [61.086],
         [60.716],
         [51.671],
         [61.404],
         [50.177],
         [62.183],
         [54.007],
         [44.400]],

        [[54.077],
         [54.396],
         [52.008],
         [55.254],
         [64.007],
         [61.221],
         [50.370],
         [65.131],
         [57.631],
         [68.716]],

        [[56.898],
         [58.195],
         [55.168],
         [57.815],
         [52.600],
         [57.540],
         [63.956],
         [38.236],
         [53.078],
         [58.584]],

        [[60.592],
         [66.228],
         [60.202],
         [57.022],
         [64.741],
         [57.227],
         [63.959],
         [54.267],
         [47.042],
         [58.396]],

        [[48.434],
         [44.062],
         [60.424],
         [58.448],
         [57.990],
         [58.737],
         [46.402],
         [57.394],
         [54.073],
         [68.266]],

        [[56.593],
         [55.748],
         [49.280],
         [61.958],
         [69.916],
         [60.637],
         [36.608],
         [57.748],
         [59.513],
         [49.702]]], device='cuda:0')
clipping threshold 1.1007809370850175
a after update for 1 param tensor([[ 0.053],
        [-0.012],
        [ 0.008],
        [-0.010],
        [-0.071],
        [-0.022],
        [ 0.058],
        [ 0.060],
        [-0.021],
        [ 0.040]], device='cuda:0')
s after update for 1 param tensor([[1.558],
        [1.540],
        [1.109],
        [1.388],
        [1.853],
        [1.712],
        [2.251],
        [1.441],
        [1.825],
        [2.124]], device='cuda:0')
b after update for 1 param tensor([[55.984],
        [55.669],
        [47.246],
        [52.839],
        [61.055],
        [58.685],
        [67.306],
        [53.854],
        [60.597],
        [65.379]], device='cuda:0')
clipping threshold 1.1007809370850175
||w||^2 0.70033079714464
exp ma of ||w||^2 1.6417254119664542
||w|| 0.8368576922898182
exp ma of ||w|| 1.1942043126977926
||w||^2 5.332806961370808
exp ma of ||w||^2 1.7279684569925227
||w|| 2.3092871110736333
exp ma of ||w|| 1.2347182683074298
cuda
Objective function 14.10 = squared loss an data 11.87 + 0.5*rho*h**2 0.358407 + alpha*h 1.221847 + L2reg 0.59 + L1reg 0.06 ; SHD = 23 ; DAG True
Proportion of microbatches that were clipped  0.7683165092803647
iteration 1 in inner loop, alpha 14.431579559621618 rho 100.0 h 0.08466481389537428
1210
cuda
Objective function 17.32 = squared loss an data 11.87 + 0.5*rho*h**2 3.584065 + alpha*h 1.221847 + L2reg 0.59 + L1reg 0.06 ; SHD = 23 ; DAG True
||w||^2 43244748880.564545
exp ma of ||w||^2 50962008727.93074
||w|| 207953.71812151987
exp ma of ||w|| 199907.24607332516
||w||^2 116952.37173721578
exp ma of ||w||^2 3795036.56729391
||w|| 341.98299919325785
exp ma of ||w|| 937.8373582092917
||w||^2 787.1229462054175
exp ma of ||w||^2 169131.730974045
||w|| 28.055711472094547
exp ma of ||w|| 113.02436470537728
||w||^2 1.8458764647796706
exp ma of ||w||^2 1.7400731189915302
||w|| 1.3586303635572372
exp ma of ||w|| 1.2438204531791488
cuda
Objective function 13.91 = squared loss an data 12.21 + 0.5*rho*h**2 0.528986 + alpha*h 0.469409 + L2reg 0.65 + L1reg 0.05 ; SHD = 21 ; DAG True
Proportion of microbatches that were clipped  0.7704081632653061
iteration 2 in inner loop, alpha 14.431579559621618 rho 1000.0 h 0.03252649508357486
iteration 3 in outer loop, alpha = 46.958074643196476, rho = 1000.0, h = 0.03252649508357486
cuda
1210
cuda
Objective function 14.97 = squared loss an data 12.21 + 0.5*rho*h**2 0.528986 + alpha*h 1.527382 + L2reg 0.65 + L1reg 0.05 ; SHD = 21 ; DAG True
||w||^2 13241277668.63696
exp ma of ||w||^2 41633878735.79271
||w|| 115070.75070858345
exp ma of ||w|| 179798.06814324498
||w||^2 1400503295.549138
exp ma of ||w||^2 7805209932.976229
||w|| 37423.298833068395
exp ma of ||w|| 73426.20967496575
||w||^2 0.6206045786470091
exp ma of ||w||^2 3.9049312081705767
||w|| 0.7877846016818361
exp ma of ||w|| 1.4393411219348042
||w||^2 1.2510072005019741
exp ma of ||w||^2 2.1435050693082984
||w|| 1.1184843318088877
exp ma of ||w|| 1.371804489916463
||w||^2 1.9293395823794242
exp ma of ||w||^2 1.9207773771537462
||w|| 1.3890066891053563
exp ma of ||w|| 1.3261561949610159
cuda
Objective function 14.08 = squared loss an data 12.13 + 0.5*rho*h**2 0.218733 + alpha*h 0.982160 + L2reg 0.69 + L1reg 0.05 ; SHD = 24 ; DAG True
Proportion of microbatches that were clipped  0.7720742534301857
iteration 1 in inner loop, alpha 46.958074643196476 rho 1000.0 h 0.020915679296182432
1210
cuda
Objective function 16.05 = squared loss an data 12.13 + 0.5*rho*h**2 2.187328 + alpha*h 0.982160 + L2reg 0.69 + L1reg 0.05 ; SHD = 24 ; DAG True
||w||^2 820190439633.1439
exp ma of ||w||^2 489645098312.87
||w|| 905643.6604057602
exp ma of ||w|| 565417.5759603934
||w||^2 46980872.81539248
exp ma of ||w||^2 143621968.3711172
||w|| 6854.259465134981
exp ma of ||w|| 8156.931266607438
||w||^2 953521.2249128261
exp ma of ||w||^2 16213941.346995683
||w|| 976.4841140094528
exp ma of ||w|| 2299.34236991759
||w||^2 67565.87051423993
exp ma of ||w||^2 4459810.053524694
||w|| 259.93435808726775
exp ma of ||w|| 1025.2685773795968
||w||^2 25495.714920576414
exp ma of ||w||^2 665959.3831396981
||w|| 159.67377655888401
exp ma of ||w|| 283.3570815416976
||w||^2 1893.6821025961997
exp ma of ||w||^2 269824.7640977557
||w|| 43.516457836044054
exp ma of ||w|| 152.60051420183703
||w||^2 0.867369335273815
exp ma of ||w||^2 2.093188775637182
||w|| 0.9313266533680946
exp ma of ||w|| 1.3755382488355135
||w||^2 1.4012203908110612
exp ma of ||w||^2 1.906610539731183
||w|| 1.1837315535251485
exp ma of ||w|| 1.315833571088639
||w||^2 0.9941031362618534
exp ma of ||w||^2 1.7158395829691002
||w|| 0.9970472086425263
exp ma of ||w|| 1.2628466572033745
cuda
Objective function 13.54 = squared loss an data 11.91 + 0.5*rho*h**2 0.424207 + alpha*h 0.432528 + L2reg 0.72 + L1reg 0.06 ; SHD = 20 ; DAG True
Proportion of microbatches that were clipped  0.7750556792873051
iteration 2 in inner loop, alpha 46.958074643196476 rho 10000.0 h 0.009210941951360851
1210
cuda
Objective function 17.36 = squared loss an data 11.91 + 0.5*rho*h**2 4.242073 + alpha*h 0.432528 + L2reg 0.72 + L1reg 0.06 ; SHD = 20 ; DAG True
||w||^2 178912.4967570986
exp ma of ||w||^2 14353673.51408853
||w|| 422.98049217085486
exp ma of ||w|| 1438.515307744465
||w||^2 60316.801554944956
exp ma of ||w||^2 7201995.496252783
||w|| 245.59479138398876
exp ma of ||w|| 926.0188989237846
||w||^2 12.19083855322169
exp ma of ||w||^2 3255.014437843628
||w|| 3.491538135724954
exp ma of ||w|| 6.355773003953709
||w||^2 5.937261356578724
exp ma of ||w||^2 174.26905461143073
||w|| 2.4366496171133685
exp ma of ||w|| 2.3764863917730543
||w||^2 0.7873042431735455
exp ma of ||w||^2 1.9575173237790962
||w|| 0.8873016641331997
exp ma of ||w|| 1.3365857079359535
||w||^2 0.5323861996102963
exp ma of ||w||^2 2.004842029898153
||w|| 0.7296479970576883
exp ma of ||w|| 1.359582825916799
||w||^2 0.966521557999744
exp ma of ||w||^2 1.730822981887525
||w|| 0.9831182828122688
exp ma of ||w|| 1.2552469265877777
cuda
Objective function 13.21 = squared loss an data 11.81 + 0.5*rho*h**2 0.449355 + alpha*h 0.140773 + L2reg 0.76 + L1reg 0.05 ; SHD = 19 ; DAG True
Proportion of microbatches that were clipped  0.7696062479661568
iteration 3 in inner loop, alpha 46.958074643196476 rho 100000.0 h 0.0029978489219075755
iteration 4 in outer loop, alpha = 346.74296683395403, rho = 100000.0, h = 0.0029978489219075755
cuda
1210
cuda
Objective function 14.11 = squared loss an data 11.81 + 0.5*rho*h**2 0.449355 + alpha*h 1.039483 + L2reg 0.76 + L1reg 0.05 ; SHD = 19 ; DAG True
||w||^2 26582908105.735085
exp ma of ||w||^2 922573839089.4172
||w|| 163042.65731928893
exp ma of ||w|| 464545.5450157731
||w||^2 9329.117952888071
exp ma of ||w||^2 5208506.8067539
||w|| 96.58735917752422
exp ma of ||w|| 357.3362068236948
||w||^2 1.6805006090409962
exp ma of ||w||^2 2.0526647183722635
||w|| 1.2963412394277196
exp ma of ||w|| 1.3934244652540895
cuda
Objective function 13.02 = squared loss an data 11.39 + 0.5*rho*h**2 0.165057 + alpha*h 0.629999 + L2reg 0.79 + L1reg 0.05 ; SHD = 19 ; DAG True
Proportion of microbatches that were clipped  0.771117166212534
iteration 1 in inner loop, alpha 346.74296683395403 rho 100000.0 h 0.0018169059030928025
iteration 5 in outer loop, alpha = 2163.6488699267566, rho = 1000000.0, h = 0.0018169059030928025
Threshold 0.3
[[0.007 0.009 0.014 0.005 0.062 0.011 0.195 0.007 0.005 0.021]
 [0.63  0.004 0.927 0.035 0.264 0.078 0.388 0.473 0.148 0.787]
 [0.248 0.005 0.004 0.005 0.027 0.026 0.086 0.012 0.006 0.031]
 [0.485 0.153 0.394 0.005 0.306 0.192 0.516 0.087 1.311 1.608]
 [0.115 0.019 0.275 0.014 0.006 0.023 0.121 0.021 0.012 0.164]
 [0.521 0.062 0.182 0.045 0.297 0.006 0.473 0.063 0.056 0.958]
 [0.044 0.006 0.126 0.005 0.054 0.009 0.009 0.027 0.01  0.009]
 [0.627 0.011 0.645 0.05  0.168 0.084 0.177 0.006 0.197 0.156]
 [1.195 0.034 1.092 0.004 0.364 0.073 0.552 0.032 0.004 0.503]
 [0.299 0.006 0.228 0.002 0.033 0.005 0.716 0.043 0.005 0.004]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.63  0.    0.927 0.    0.    0.    0.388 0.473 0.    0.787]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.485 0.    0.394 0.    0.306 0.    0.516 0.    1.311 1.608]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.521 0.    0.    0.    0.    0.    0.473 0.    0.    0.958]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.627 0.    0.645 0.    0.    0.    0.    0.    0.    0.   ]
 [1.195 0.    1.092 0.    0.364 0.    0.552 0.    0.    0.503]
 [0.    0.    0.    0.    0.    0.    0.716 0.    0.    0.   ]]
{'fdr': 0.2727272727272727, 'tpr': 0.5333333333333333, 'fpr': 0.4, 'f1': 0.6153846153846153, 'shd': 19, 'npred': 22, 'ntrue': 30}
[0.009 0.014 0.005 0.062 0.011 0.195 0.007 0.005 0.021 0.63  0.927 0.035
 0.264 0.078 0.388 0.473 0.148 0.787 0.248 0.005 0.005 0.027 0.026 0.086
 0.012 0.006 0.031 0.485 0.153 0.394 0.306 0.192 0.516 0.087 1.311 1.608
 0.115 0.019 0.275 0.014 0.023 0.121 0.021 0.012 0.164 0.521 0.062 0.182
 0.045 0.297 0.473 0.063 0.056 0.958 0.044 0.006 0.126 0.005 0.054 0.009
 0.027 0.01  0.009 0.627 0.011 0.645 0.05  0.168 0.084 0.177 0.197 0.156
 1.195 0.034 1.092 0.004 0.364 0.073 0.552 0.032 0.503 0.299 0.006 0.228
 0.002 0.033 0.005 0.716 0.043 0.005]
[[0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [1. 0. 1. 0. 1. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [1. 1. 1. 0. 1. 1. 0. 0. 0. 0.]
 [1. 0. 1. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 1. 0. 1. 0. 0. 0.]]
[0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0.
 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.]
aucroc, aucpr (0.8338888888888889, 0.7582556344213041)
Iterations 630
Achieves (4.040438258977602, 1e-05)-DP
