samples  5000  graph  15 30 ER mlp  minibatch size  75  noise  0.75  minibatches per NN training  111 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.3401316691164595
iteration 1 in outer loop, alpha = 1.3401316691164595, rho = 1.0, h = 1.3401316691164595
cuda
iteration 1 in inner loop,alpha 1.3401316691164595 rho 1.0 h 0.8741315174292428
iteration 2 in inner loop,alpha 1.3401316691164595 rho 10.0 h 0.38347274229216843
iteration 3 in inner loop,alpha 1.3401316691164595 rho 100.0 h 0.13357487921889089
iteration 2 in outer loop, alpha = 14.697619591005548, rho = 100.0, h = 0.13357487921889089
cuda
iteration 1 in inner loop,alpha 14.697619591005548 rho 100.0 h 0.06991993740608571
iteration 2 in inner loop,alpha 14.697619591005548 rho 1000.0 h 0.02592698775515956
iteration 3 in outer loop, alpha = 40.62460734616511, rho = 1000.0, h = 0.02592698775515956
cuda
iteration 1 in inner loop,alpha 40.62460734616511 rho 1000.0 h 0.016465661543334065
iteration 2 in inner loop,alpha 40.62460734616511 rho 10000.0 h 0.006583550827196305
iteration 3 in inner loop,alpha 40.62460734616511 rho 100000.0 h 0.0011537970975332712
iteration 4 in outer loop, alpha = 156.00431709949223, rho = 100000.0, h = 0.0011537970975332712
cuda
iteration 1 in inner loop,alpha 156.00431709949223 rho 100000.0 h 0.00033575511004180214
iteration 5 in outer loop, alpha = 491.7594271412944, rho = 1000000.0, h = 0.00033575511004180214
Threshold 0.3
[[0.002 0.    0.    0.005 0.194 0.    0.    0.    0.    2.734 0.179 0.001
  0.001 0.    0.006]
 [2.52  0.001 0.002 0.262 0.215 0.01  0.01  0.001 0.002 2.189 0.199 1.342
  0.001 0.001 0.098]
 [0.027 0.068 0.001 0.147 0.166 0.035 0.137 0.001 0.067 0.125 0.135 0.162
  0.001 0.001 0.006]
 [0.153 0.    0.001 0.001 0.204 0.    0.    0.    0.    0.214 0.335 0.001
  0.    0.    1.022]
 [0.    0.    0.    0.    0.004 0.    0.    0.    0.    0.    0.002 0.
  0.    0.    0.001]
 [2.646 0.03  0.001 0.968 0.376 0.001 1.377 0.    0.055 1.746 0.956 1.472
  0.012 0.002 1.923]
 [0.414 0.044 0.    0.336 0.408 0.    0.001 0.    0.059 0.139 1.162 0.096
  0.001 0.    0.163]
 [2.69  0.002 0.    2.092 0.137 0.612 0.046 0.    0.003 0.313 0.139 0.061
  0.014 0.022 0.118]
 [0.103 0.383 0.002 0.638 0.415 0.002 0.001 0.001 0.003 2.308 1.722 1.03
  0.    0.    0.367]
 [0.    0.    0.    0.    2.722 0.    0.001 0.    0.    0.002 0.402 0.001
  0.    0.    0.002]
 [0.001 0.    0.    0.001 3.057 0.    0.001 0.    0.001 0.001 0.015 0.
  0.    0.    0.005]
 [0.37  0.    0.    0.18  0.153 0.    0.004 0.    0.002 0.427 0.58  0.001
  0.    0.001 0.032]
 [0.041 0.078 0.    0.112 3.047 0.017 0.008 0.    1.212 0.107 1.585 0.031
  0.001 0.016 0.021]
 [0.126 1.398 0.    1.127 1.231 0.003 0.006 0.    3.368 0.386 0.434 0.158
  0.011 0.002 0.562]
 [0.089 0.    0.    0.    0.111 0.    0.    0.    0.    0.106 0.081 0.002
  0.004 0.    0.001]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    2.734 0.    0.
  0.    0.    0.   ]
 [2.52  0.    0.    0.    0.    0.    0.    0.    0.    2.189 0.    1.342
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.335 0.
  0.    0.    1.022]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [2.646 0.    0.    0.968 0.376 0.    1.377 0.    0.    1.746 0.956 1.472
  0.    0.    1.923]
 [0.414 0.    0.    0.336 0.408 0.    0.    0.    0.    0.    1.162 0.
  0.    0.    0.   ]
 [2.69  0.    0.    2.092 0.    0.612 0.    0.    0.    0.313 0.    0.
  0.    0.    0.   ]
 [0.    0.383 0.    0.638 0.415 0.    0.    0.    0.    2.308 1.722 1.03
  0.    0.    0.367]
 [0.    0.    0.    0.    2.722 0.    0.    0.    0.    0.    0.402 0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    3.057 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.37  0.    0.    0.    0.    0.    0.    0.    0.    0.427 0.58  0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    3.047 0.    0.    0.    1.212 0.    1.585 0.
  0.    0.    0.   ]
 [0.    1.398 0.    1.127 1.231 0.    0.    0.    3.368 0.386 0.434 0.
  0.    0.    0.562]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]]
{'fdr': 0.35555555555555557, 'tpr': 0.9666666666666667, 'fpr': 0.21333333333333335, 'f1': 0.7733333333333333, 'shd': 17, 'npred': 45, 'ntrue': 30}
[7.166e-05 3.031e-04 4.737e-03 1.942e-01 6.655e-05 2.207e-04 4.993e-05
 2.937e-04 2.734e+00 1.793e-01 5.105e-04 1.050e-03 1.242e-04 5.740e-03
 2.520e+00 1.954e-03 2.620e-01 2.147e-01 9.724e-03 9.801e-03 9.328e-04
 1.620e-03 2.189e+00 1.994e-01 1.342e+00 5.488e-04 9.886e-04 9.781e-02
 2.679e-02 6.849e-02 1.472e-01 1.660e-01 3.508e-02 1.368e-01 5.716e-04
 6.687e-02 1.254e-01 1.352e-01 1.619e-01 8.477e-04 1.272e-03 6.092e-03
 1.532e-01 1.509e-04 9.882e-04 2.036e-01 4.044e-05 3.897e-04 2.489e-04
 6.858e-05 2.135e-01 3.353e-01 1.155e-03 4.106e-04 1.293e-04 1.022e+00
 6.064e-05 4.791e-06 5.172e-05 2.471e-04 1.136e-05 1.928e-04 4.191e-06
 2.163e-04 3.383e-04 1.833e-03 1.007e-04 2.631e-05 7.614e-05 1.086e-03
 2.646e+00 3.009e-02 1.478e-03 9.684e-01 3.765e-01 1.377e+00 1.229e-04
 5.513e-02 1.746e+00 9.560e-01 1.472e+00 1.180e-02 1.838e-03 1.923e+00
 4.141e-01 4.437e-02 3.959e-04 3.360e-01 4.079e-01 4.254e-04 5.935e-05
 5.872e-02 1.392e-01 1.162e+00 9.588e-02 6.731e-04 4.063e-04 1.632e-01
 2.690e+00 2.126e-03 4.852e-04 2.092e+00 1.369e-01 6.121e-01 4.646e-02
 3.330e-03 3.125e-01 1.385e-01 6.062e-02 1.448e-02 2.181e-02 1.178e-01
 1.034e-01 3.829e-01 2.017e-03 6.383e-01 4.147e-01 2.074e-03 1.394e-03
 1.328e-03 2.308e+00 1.722e+00 1.030e+00 5.492e-05 3.972e-04 3.674e-01
 1.834e-04 4.607e-06 8.949e-05 4.394e-04 2.722e+00 6.113e-06 8.992e-04
 1.147e-05 4.538e-04 4.020e-01 1.020e-03 1.265e-04 1.194e-04 2.179e-03
 6.634e-04 5.288e-05 3.430e-04 1.176e-03 3.057e+00 1.252e-04 7.885e-04
 1.415e-04 9.900e-04 8.589e-04 1.728e-04 2.153e-04 3.103e-04 5.194e-03
 3.696e-01 4.210e-04 8.175e-05 1.805e-01 1.529e-01 2.371e-04 3.593e-03
 6.136e-05 1.729e-03 4.267e-01 5.799e-01 2.072e-04 6.430e-04 3.169e-02
 4.077e-02 7.764e-02 2.020e-04 1.125e-01 3.047e+00 1.651e-02 8.033e-03
 3.454e-04 1.212e+00 1.069e-01 1.585e+00 3.144e-02 1.628e-02 2.119e-02
 1.264e-01 1.398e+00 2.136e-04 1.127e+00 1.231e+00 3.196e-03 6.293e-03
 3.254e-04 3.368e+00 3.864e-01 4.339e-01 1.576e-01 1.130e-02 5.624e-01
 8.923e-02 3.157e-04 3.306e-04 7.760e-05 1.109e-01 7.500e-05 1.536e-04
 2.248e-04 2.530e-04 1.060e-01 8.126e-02 2.152e-03 4.216e-03 1.418e-04]
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.]
 [0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.9805555555555556, 0.9709424613206593)
cuda
2565
cuda
Objective function 454.76 = squared loss an data 233.99 + 0.5*rho*h**2 220.188202 + alpha*h 0.000000 + L2reg 0.28 + L1reg 0.30 ; SHD = 120 ; DAG False
||w||^2 0.15009488837714657
exp ma of ||w||^2 9521.867620702244
||w|| 0.3874208156219108
exp ma of ||w|| 0.4531108260438149
||w||^2 0.19539778513780262
exp ma of ||w||^2 5004.746030574789
||w|| 0.4420382168294984
exp ma of ||w|| 0.4370445385744274
||w||^2 0.13590544881190125
exp ma of ||w||^2 47.377163908809536
||w|| 0.36865356204965827
exp ma of ||w|| 0.3943396080521289
||w||^2 0.09772515616693309
exp ma of ||w||^2 0.1631658564107306
||w|| 0.3126102304258981
exp ma of ||w|| 0.38633501336556314
||w||^2 0.16951711172910325
exp ma of ||w||^2 0.16030083768793207
||w|| 0.41172455808356057
exp ma of ||w|| 0.38831773956155374
||w||^2 0.11112250894130818
exp ma of ||w||^2 0.1736310714132786
||w|| 0.3333504296402034
exp ma of ||w|| 0.3956743508968922
||w||^2 0.1460138065248367
exp ma of ||w||^2 0.1777301337821835
||w|| 0.382117529727225
exp ma of ||w|| 0.39597784073411757
||w||^2 0.08402604551959432
exp ma of ||w||^2 0.2713444220940541
||w|| 0.2898724642314173
exp ma of ||w|| 0.47733716292966444
||w||^2 0.06626844461481385
exp ma of ||w||^2 0.37317401949783907
||w|| 0.2574265810183825
exp ma of ||w|| 0.5591563874492496
cuda
Objective function 24.43 = squared loss an data 22.59 + 0.5*rho*h**2 1.294951 + alpha*h 0.000000 + L2reg 0.41 + L1reg 0.15 ; SHD = 49 ; DAG False
Proportion of microbatches that were clipped  0.748687904308556
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 1.6093174431710118
iteration 1 in outer loop, alpha = 1.6093174431710118, rho = 1.0, h = 1.6093174431710118
cuda
2565
cuda
Objective function 27.02 = squared loss an data 22.59 + 0.5*rho*h**2 1.294951 + alpha*h 2.589903 + L2reg 0.41 + L1reg 0.15 ; SHD = 49 ; DAG False
||w||^2 8254604682.102936
exp ma of ||w||^2 23332425925.39278
||w|| 90854.85502769203
exp ma of ||w|| 129818.70822255973
||w||^2 62943104028.500084
exp ma of ||w||^2 13880665249.904215
||w|| 250884.6428709818
exp ma of ||w|| 97903.17808753873
||w||^2 2988936305.0665545
exp ma of ||w||^2 11003674777.169992
||w|| 54671.16520677563
exp ma of ||w|| 87589.12923244925
||w||^2 385.2979672960001
exp ma of ||w||^2 699430.4254395567
||w|| 19.629008311578048
exp ma of ||w|| 163.73838880938723
||w||^2 0.7879050173901727
exp ma of ||w||^2 0.4433551031274413
||w|| 0.8876401395780684
exp ma of ||w|| 0.612139731241489
||w||^2 0.14107165091705104
exp ma of ||w||^2 0.4670876580448682
||w|| 0.37559506242368396
exp ma of ||w|| 0.6243233085560764
||w||^2 0.0887799304816368
exp ma of ||w||^2 0.4371244962809693
||w|| 0.29795961216520067
exp ma of ||w|| 0.6142389667625957
||w||^2 0.9951419790292065
exp ma of ||w||^2 0.4558783305677418
||w|| 0.9975680322811105
exp ma of ||w|| 0.6172619138587269
||w||^2 2.306347276129473
exp ma of ||w||^2 0.4964162591871355
||w|| 1.5186662820150691
exp ma of ||w|| 0.6560825261400155
||w||^2 0.14112114251793906
exp ma of ||w||^2 0.4496994934493318
||w|| 0.37566094090008756
exp ma of ||w|| 0.6194684065001639
cuda
Objective function 16.23 = squared loss an data 13.26 + 0.5*rho*h**2 0.524496 + alpha*h 1.648268 + L2reg 0.66 + L1reg 0.14 ; SHD = 48 ; DAG False
Proportion of microbatches that were clipped  0.7549700598802396
iteration 1 in inner loop, alpha 1.6093174431710118 rho 1.0 h 1.0242028978561883
2565
cuda
Objective function 20.95 = squared loss an data 13.26 + 0.5*rho*h**2 5.244958 + alpha*h 1.648268 + L2reg 0.66 + L1reg 0.14 ; SHD = 48 ; DAG False
||w||^2 72049601976.17517
exp ma of ||w||^2 66560612663.36325
||w|| 268420.56921215105
exp ma of ||w|| 199571.46808108586
||w||^2 9.484299347399332
exp ma of ||w||^2 60531.78138546617
||w|| 3.0796589660868836
exp ma of ||w|| 21.636004609479965
||w||^2 0.22247001713877476
exp ma of ||w||^2 5.432216079464436
||w|| 0.4716672737627392
exp ma of ||w|| 0.6630422501423157
||w||^2 0.44717876235831877
exp ma of ||w||^2 2.1064136544775747
||w|| 0.6687142606213201
exp ma of ||w|| 0.6765376393998406
||w||^2 0.2748586213521368
exp ma of ||w||^2 0.5852620816518479
||w|| 0.5242696075037506
exp ma of ||w|| 0.6883286628030277
||w||^2 0.7382431341420557
exp ma of ||w||^2 0.614858190358022
||w|| 0.8592107623523204
exp ma of ||w|| 0.7315636316014444
||w||^2 0.29699274495966965
exp ma of ||w||^2 0.6189531427083849
||w|| 0.5449704074164666
exp ma of ||w|| 0.7193676262747732
||w||^2 0.22799059521688578
exp ma of ||w||^2 0.6685851053495758
||w|| 0.47748360727556477
exp ma of ||w|| 0.7488926947308189
||w||^2 0.1777393249965371
exp ma of ||w||^2 0.5709943902214342
||w|| 0.42159141950060736
exp ma of ||w|| 0.6983460373290622
cuda
Objective function 16.02 = squared loss an data 13.25 + 0.5*rho*h**2 1.080613 + alpha*h 0.748155 + L2reg 0.81 + L1reg 0.13 ; SHD = 38 ; DAG True
Proportion of microbatches that were clipped  0.7528629479128186
iteration 2 in inner loop, alpha 1.6093174431710118 rho 10.0 h 0.4648897785367847
2565
cuda
Objective function 25.75 = squared loss an data 13.25 + 0.5*rho*h**2 10.806125 + alpha*h 0.748155 + L2reg 0.81 + L1reg 0.13 ; SHD = 38 ; DAG True
||w||^2 110955224660.80544
exp ma of ||w||^2 91007319668.55902
||w|| 333099.42158581637
exp ma of ||w|| 258703.57154719354
||w||^2 72326932.37078103
exp ma of ||w||^2 616771659.7971994
||w|| 8504.524229536948
exp ma of ||w|| 15939.868710261808
||w||^2 6569.365898449839
exp ma of ||w||^2 4389356.547174662
||w|| 81.05162489703608
exp ma of ||w|| 532.3497314057443
||w||^2 0.3397742887607913
exp ma of ||w||^2 0.9355796286516839
||w|| 0.5829016115613262
exp ma of ||w|| 0.8638438728675774
||w||^2 2.524052431602992
exp ma of ||w||^2 0.9557423412913999
||w|| 1.58872666988472
exp ma of ||w|| 0.8911240849654849
||w||^2 0.49272012978110596
exp ma of ||w||^2 0.9601727805182743
||w|| 0.7019402608349987
exp ma of ||w|| 0.9068438091944279
||w||^2 0.2614433513829044
exp ma of ||w||^2 0.8770153188189176
||w|| 0.5113153150287055
exp ma of ||w|| 0.8544264511579639
||w||^2 0.769587712127249
exp ma of ||w||^2 0.7656340552792856
||w|| 0.8772614844658626
exp ma of ||w|| 0.8134653373434156
||w||^2 0.9798760705588414
exp ma of ||w||^2 0.8000537867955404
||w|| 0.9898868978619938
exp ma of ||w|| 0.8253846571092778
||w||^2 1.0964782043179686
exp ma of ||w||^2 0.9579665819714522
||w|| 1.0471285519543283
exp ma of ||w|| 0.8805632290251099
||w||^2 0.4254192168373612
exp ma of ||w||^2 0.7951566902317999
||w|| 0.652241685908959
exp ma of ||w|| 0.8245857865148524
cuda
Objective function 17.49 = squared loss an data 14.76 + 0.5*rho*h**2 1.424179 + alpha*h 0.271606 + L2reg 0.92 + L1reg 0.11 ; SHD = 39 ; DAG True
Proportion of microbatches that were clipped  0.7609744331886156
iteration 3 in inner loop, alpha 1.6093174431710118 rho 100.0 h 0.16877076583075734
iteration 2 in outer loop, alpha = 18.486394026246746, rho = 100.0, h = 0.16877076583075734
cuda
2565
cuda
Objective function 20.34 = squared loss an data 14.76 + 0.5*rho*h**2 1.424179 + alpha*h 3.119963 + L2reg 0.92 + L1reg 0.11 ; SHD = 39 ; DAG True
||w||^2 0.6240810062786428
exp ma of ||w||^2 10.589263773422163
||w|| 0.7899879785659037
exp ma of ||w|| 0.9574182867370941
||w||^2 1.1391476613596436
exp ma of ||w||^2 3.6932258450762747
||w|| 1.0673086064300445
exp ma of ||w|| 0.9755078063813927
||w||^2 0.5489576110926464
exp ma of ||w||^2 1.0250908818826587
||w|| 0.7409167369500074
exp ma of ||w|| 0.9403693942458897
||w||^2 2.1337571841770293
exp ma of ||w||^2 1.0721190012604698
||w|| 1.4607385748918351
exp ma of ||w|| 0.941551181753968
||w||^2 0.4891442210571889
exp ma of ||w||^2 1.1141936225937836
||w|| 0.6993884621990764
exp ma of ||w|| 0.944157603483256
||w||^2 1.1595221754570368
exp ma of ||w||^2 1.0718636949423839
||w|| 1.0768111141036003
exp ma of ||w|| 0.9210634840277877
||w||^2 0.6325422639560483
exp ma of ||w||^2 1.1937922589497014
||w|| 0.7953252567069955
exp ma of ||w|| 0.9643730168691094
||w||^2 0.4024459913471723
exp ma of ||w||^2 1.1516961979061429
||w|| 0.6343863108131923
exp ma of ||w|| 0.9692121294332108
||w||^2 0.513699691747933
exp ma of ||w||^2 1.071193776963463
||w|| 0.7167284644465663
exp ma of ||w|| 0.9533913788380263
cuda
Objective function 18.59 = squared loss an data 15.14 + 0.5*rho*h**2 0.494533 + alpha*h 1.838504 + L2reg 1.00 + L1reg 0.11 ; SHD = 41 ; DAG True
Proportion of microbatches that were clipped  0.7592411260709915
iteration 1 in inner loop, alpha 18.486394026246746 rho 100.0 h 0.0994517506282655
2565
cuda
Objective function 23.04 = squared loss an data 15.14 + 0.5*rho*h**2 4.945325 + alpha*h 1.838504 + L2reg 1.00 + L1reg 0.11 ; SHD = 41 ; DAG True
||w||^2 113958522867.93895
exp ma of ||w||^2 128860115572.9007
||w|| 337577.4324032028
exp ma of ||w|| 314731.0262374644
||w||^2 5195836050.100255
exp ma of ||w||^2 61043693360.53548
||w|| 72082.14792929144
exp ma of ||w|| 206380.86569889338
||w||^2 5099238532.015052
exp ma of ||w||^2 46260300819.77434
||w|| 71408.95274414163
exp ma of ||w|| 179357.0553475918
||w||^2 1179937062.0396276
exp ma of ||w||^2 8070743676.308336
||w|| 34350.21196498833
exp ma of ||w|| 64808.984212030184
||w||^2 32.39091635450705
exp ma of ||w||^2 158670.52552493624
||w|| 5.691301815446713
exp ma of ||w|| 26.384903851278846
||w||^2 3.6813426017832342
exp ma of ||w||^2 52011.4808563596
||w|| 1.9186825171933042
exp ma of ||w|| 11.164734643146424
||w||^2 1.1338784343516168
exp ma of ||w||^2 8.831187927987596
||w|| 1.0648372806920392
exp ma of ||w|| 1.1285298268231305
||w||^2 0.6625593197992397
exp ma of ||w||^2 1.0437350746814278
||w|| 0.8139774688523261
exp ma of ||w|| 0.9478656441861453
||w||^2 0.27154169409821177
exp ma of ||w||^2 1.1736438686177626
||w|| 0.5210966264506149
exp ma of ||w|| 0.992572939423501
||w||^2 1.604717086764061
exp ma of ||w||^2 1.0481057122800295
||w|| 1.26677428406329
exp ma of ||w|| 0.9459567989128016
||w||^2 0.5946955951921911
exp ma of ||w||^2 1.211429018107049
||w|| 0.7711650894537375
exp ma of ||w|| 0.9888947512071471
||w||^2 0.6241721752214237
exp ma of ||w||^2 1.1474862340840768
||w|| 0.7900456791992623
exp ma of ||w|| 1.0028632861470173
||w||^2 0.7442470157074937
exp ma of ||w||^2 1.1645103003912989
||w|| 0.8626975227201558
exp ma of ||w|| 0.9680301331863668
cuda
Objective function 18.64 = squared loss an data 15.86 + 0.5*rho*h**2 0.843917 + alpha*h 0.759481 + L2reg 1.07 + L1reg 0.11 ; SHD = 34 ; DAG True
Proportion of microbatches that were clipped  0.7660783365570599
iteration 2 in inner loop, alpha 18.486394026246746 rho 1000.0 h 0.04108325381742617
iteration 3 in outer loop, alpha = 59.56964784367291, rho = 1000.0, h = 0.04108325381742617
cuda
2565
cuda
Objective function 20.33 = squared loss an data 15.86 + 0.5*rho*h**2 0.843917 + alpha*h 2.447315 + L2reg 1.07 + L1reg 0.11 ; SHD = 34 ; DAG True
||w||^2 2.8180932246459225
exp ma of ||w||^2 1.1362486456636542
||w|| 1.6787177322724396
exp ma of ||w|| 0.9802720024814724
||w||^2 1.4519730497281842
exp ma of ||w||^2 1.1704709749637967
||w|| 1.2049784436778046
exp ma of ||w|| 0.9952792209183795
||w||^2 1.556306124892711
exp ma of ||w||^2 1.0609015228082088
||w|| 1.2475199897768015
exp ma of ||w|| 0.970889367738156
||w||^2 0.4660414876552939
exp ma of ||w||^2 1.1125545796722056
||w|| 0.6826723135262583
exp ma of ||w|| 0.9810656360893047
||w||^2 0.23905125882294953
exp ma of ||w||^2 1.060516660938857
||w|| 0.48892868480275276
exp ma of ||w|| 0.9688912545582099
||w||^2 0.7849473301253951
exp ma of ||w||^2 1.219092322775053
||w|| 0.8859725335050715
exp ma of ||w|| 1.0271823277776668
||w||^2 2.0125627292951624
exp ma of ||w||^2 1.0827568082895116
||w|| 1.4186482049102809
exp ma of ||w|| 0.9621224991890323
||w||^2 1.167868019710902
exp ma of ||w||^2 1.1721839785764925
||w|| 1.0806794250428302
exp ma of ||w|| 1.0083762567398034
||w||^2 0.5778398888281002
exp ma of ||w||^2 1.1093542467019832
||w|| 0.7601578052142202
exp ma of ||w|| 0.9778283461356518
||w||^2 1.0907686942644876
exp ma of ||w||^2 1.0861112419703165
||w|| 1.0443987237949344
exp ma of ||w|| 0.9723067969024389
cuda
Objective function 18.74 = squared loss an data 15.76 + 0.5*rho*h**2 0.280033 + alpha*h 1.409757 + L2reg 1.19 + L1reg 0.11 ; SHD = 34 ; DAG True
Proportion of microbatches that were clipped  0.7624651219216305
iteration 1 in inner loop, alpha 59.56964784367291 rho 1000.0 h 0.0236656938785913
2565
cuda
Objective function 21.26 = squared loss an data 15.76 + 0.5*rho*h**2 2.800325 + alpha*h 1.409757 + L2reg 1.19 + L1reg 0.11 ; SHD = 34 ; DAG True
||w||^2 92569734061.93213
exp ma of ||w||^2 97613526701.4104
||w|| 304252.7470080297
exp ma of ||w|| 251703.9283382753
||w||^2 1.0109372984094105
exp ma of ||w||^2 1.1195807150499517
||w|| 1.0054537773609538
exp ma of ||w|| 0.9996405469618993
||w||^2 1.093555839644202
exp ma of ||w||^2 1.0377020154783816
||w|| 1.045732202642819
exp ma of ||w|| 0.9560336140402914
||w||^2 0.8170158816840328
exp ma of ||w||^2 1.2316088080989944
||w|| 0.9038893083138183
exp ma of ||w|| 1.0392204814416202
||w||^2 1.6909725228503583
exp ma of ||w||^2 1.0475183243543291
||w|| 1.3003739934535596
exp ma of ||w|| 0.9792459276196516
||w||^2 0.6317394650504138
exp ma of ||w||^2 1.091218014500811
||w|| 0.7948203979833518
exp ma of ||w|| 0.9885848321692832
||w||^2 0.3841174765703647
exp ma of ||w||^2 1.1513986856285818
||w|| 0.6197721166447913
exp ma of ||w|| 1.009401957043636
||w||^2 1.1302485192851648
exp ma of ||w||^2 1.1153399451158947
||w|| 1.063131468485984
exp ma of ||w|| 0.99742332342644
||w||^2 1.910537962741517
exp ma of ||w||^2 1.1280713797502504
||w|| 1.3822221104950958
exp ma of ||w|| 0.9814069507131404
||w||^2 1.658368362181163
exp ma of ||w||^2 1.1830556243529768
||w|| 1.2877765187256534
exp ma of ||w|| 1.0029506258023229
||w||^2 1.7957719860001982
exp ma of ||w||^2 1.1528854228636962
||w|| 1.3400641723440703
exp ma of ||w|| 1.000473167555249
cuda
Objective function 17.78 = squared loss an data 15.17 + 0.5*rho*h**2 0.595571 + alpha*h 0.650140 + L2reg 1.25 + L1reg 0.11 ; SHD = 40 ; DAG True
Proportion of microbatches that were clipped  0.7611063517317341
iteration 2 in inner loop, alpha 59.56964784367291 rho 10000.0 h 0.010913944473795567
2565
cuda
Objective function 23.14 = squared loss an data 15.17 + 0.5*rho*h**2 5.955709 + alpha*h 0.650140 + L2reg 1.25 + L1reg 0.11 ; SHD = 40 ; DAG True
||w||^2 934489328087.818
exp ma of ||w||^2 552632242170.2969
||w|| 966689.882065504
exp ma of ||w|| 513813.6485030129
||w||^2 32175420.000265054
exp ma of ||w||^2 14823515880.87431
||w|| 5672.338142271232
exp ma of ||w|| 12019.213821530042
||w||^2 1.0935100795632249
exp ma of ||w||^2 1.0901940263936558
||w|| 1.0457103229686626
exp ma of ||w|| 0.9735780448245186
||w||^2 1.6176489526945759
exp ma of ||w||^2 1.1827121048328313
||w|| 1.2718682921963955
exp ma of ||w|| 0.9931047739613614
||w||^2 0.5970558748186554
exp ma of ||w||^2 1.3324601547781685
||w|| 0.7726939075847922
exp ma of ||w|| 1.0397570412163977
||w||^2 0.8550993750656917
exp ma of ||w||^2 1.2507558369619636
||w|| 0.9247158347653033
exp ma of ||w|| 1.0218928688829652
cuda
Objective function 17.26 = squared loss an data 14.93 + 0.5*rho*h**2 0.687417 + alpha*h 0.220877 + L2reg 1.30 + L1reg 0.11 ; SHD = 37 ; DAG True
Proportion of microbatches that were clipped  0.7688684941432194
iteration 3 in inner loop, alpha 59.56964784367291 rho 100000.0 h 0.003707874114846632
iteration 4 in outer loop, alpha = 430.3570593283361, rho = 100000.0, h = 0.003707874114846632
cuda
2565
cuda
Objective function 18.63 = squared loss an data 14.93 + 0.5*rho*h**2 0.687417 + alpha*h 1.595710 + L2reg 1.30 + L1reg 0.11 ; SHD = 37 ; DAG True
||w||^2 2397999690682.558
exp ma of ||w||^2 85786499171130.6
||w|| 1548547.6068505475
exp ma of ||w|| 5702304.415675868
||w||^2 34780.469818015226
exp ma of ||w||^2 22822539218.403328
||w|| 186.49522733307472
exp ma of ||w|| 3565.951192910382
||w||^2 2.3632616028597964
exp ma of ||w||^2 532.0385199817437
||w|| 1.5372903443591248
exp ma of ||w|| 1.3784425073512854
||w||^2 0.6395917395527044
exp ma of ||w||^2 1.265307356954973
||w|| 0.7997447965149285
exp ma of ||w|| 1.0522105306950633
cuda
Objective function 17.39 = squared loss an data 14.68 + 0.5*rho*h**2 0.260516 + alpha*h 0.982338 + L2reg 1.36 + L1reg 0.11 ; SHD = 35 ; DAG True
Proportion of microbatches that were clipped  0.7652375717601075
iteration 1 in inner loop, alpha 430.3570593283361 rho 100000.0 h 0.0022826117389946887
iteration 5 in outer loop, alpha = 2712.9687983230247, rho = 1000000.0, h = 0.0022826117389946887
Threshold 0.3
[[0.002 0.036 0.105 0.243 0.389 0.236 0.02  0.009 0.054 0.903 0.137 0.153
  0.01  0.02  0.182]
 [0.139 0.003 0.066 0.356 0.301 0.615 0.054 0.087 0.03  0.656 0.226 0.711
  0.043 0.004 0.293]
 [0.041 0.074 0.004 0.032 0.176 0.095 0.02  0.023 0.036 0.087 0.068 0.125
  0.016 0.01  0.039]
 [0.02  0.012 0.194 0.003 0.222 0.027 0.009 0.009 0.028 0.191 0.113 0.045
  0.012 0.006 0.138]
 [0.002 0.004 0.026 0.014 0.004 0.022 0.002 0.003 0.003 0.001 0.002 0.018
  0.001 0.001 0.016]
 [0.026 0.008 0.053 0.128 0.227 0.003 0.006 0.019 0.014 0.091 0.073 0.292
  0.01  0.004 0.051]
 [0.266 0.111 0.259 0.482 0.419 0.428 0.004 0.233 0.103 0.364 1.086 0.286
  0.068 0.024 0.429]
 [0.383 0.048 0.174 0.497 0.458 0.274 0.019 0.004 0.157 0.447 0.174 0.425
  0.024 0.018 0.281]
 [0.09  0.207 0.091 0.158 0.477 0.295 0.061 0.025 0.004 1.063 0.874 0.744
  0.033 0.002 0.211]
 [0.005 0.006 0.033 0.024 1.828 0.05  0.011 0.007 0.005 0.003 0.045 0.115
  0.008 0.002 0.076]
 [0.038 0.021 0.061 0.054 2.015 0.06  0.005 0.024 0.004 0.148 0.004 0.019
  0.003 0.003 0.029]
 [0.024 0.006 0.034 0.081 0.204 0.014 0.019 0.009 0.005 0.038 0.175 0.002
  0.013 0.002 0.046]
 [0.404 0.124 0.285 0.283 1.095 0.325 0.058 0.187 0.167 0.311 1.155 0.339
  0.003 0.048 0.345]
 [0.268 0.831 0.34  0.63  0.447 0.41  0.182 0.308 2.246 0.708 0.456 0.624
  0.101 0.002 0.527]
 [0.026 0.017 0.087 0.045 0.268 0.124 0.012 0.013 0.028 0.047 0.099 0.044
  0.01  0.006 0.004]]
[[0.    0.    0.    0.    0.389 0.    0.    0.    0.    0.903 0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.356 0.301 0.615 0.    0.    0.    0.656 0.    0.711
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.482 0.419 0.428 0.    0.    0.    0.364 1.086 0.
  0.    0.    0.429]
 [0.383 0.    0.    0.497 0.458 0.    0.    0.    0.    0.447 0.    0.425
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.477 0.    0.    0.    0.    1.063 0.874 0.744
  0.    0.    0.   ]
 [0.    0.    0.    0.    1.828 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    2.015 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.404 0.    0.    0.    1.095 0.325 0.    0.    0.    0.311 1.155 0.339
  0.    0.    0.345]
 [0.    0.831 0.34  0.63  0.447 0.41  0.    0.308 2.246 0.708 0.456 0.624
  0.    0.    0.527]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]]
{'fdr': 0.5714285714285714, 'tpr': 0.6, 'fpr': 0.32, 'f1': 0.5000000000000001, 'shd': 35, 'npred': 42, 'ntrue': 30}
[3.602e-02 1.046e-01 2.432e-01 3.893e-01 2.362e-01 1.959e-02 9.215e-03
 5.425e-02 9.033e-01 1.370e-01 1.528e-01 9.899e-03 2.033e-02 1.823e-01
 1.393e-01 6.648e-02 3.563e-01 3.010e-01 6.150e-01 5.428e-02 8.715e-02
 3.020e-02 6.557e-01 2.261e-01 7.106e-01 4.303e-02 3.673e-03 2.930e-01
 4.111e-02 7.415e-02 3.165e-02 1.756e-01 9.535e-02 2.041e-02 2.349e-02
 3.593e-02 8.733e-02 6.778e-02 1.253e-01 1.580e-02 9.665e-03 3.879e-02
 2.026e-02 1.223e-02 1.938e-01 2.222e-01 2.724e-02 9.124e-03 9.384e-03
 2.850e-02 1.910e-01 1.135e-01 4.480e-02 1.195e-02 5.997e-03 1.381e-01
 1.671e-03 4.350e-03 2.585e-02 1.414e-02 2.164e-02 1.735e-03 3.415e-03
 2.673e-03 1.202e-03 1.923e-03 1.790e-02 1.184e-03 9.330e-04 1.591e-02
 2.609e-02 8.046e-03 5.301e-02 1.283e-01 2.268e-01 6.263e-03 1.857e-02
 1.440e-02 9.059e-02 7.272e-02 2.919e-01 1.025e-02 4.097e-03 5.050e-02
 2.656e-01 1.112e-01 2.588e-01 4.817e-01 4.186e-01 4.282e-01 2.334e-01
 1.034e-01 3.644e-01 1.086e+00 2.862e-01 6.793e-02 2.449e-02 4.293e-01
 3.831e-01 4.835e-02 1.745e-01 4.971e-01 4.576e-01 2.742e-01 1.926e-02
 1.574e-01 4.466e-01 1.740e-01 4.245e-01 2.384e-02 1.776e-02 2.809e-01
 9.031e-02 2.071e-01 9.077e-02 1.583e-01 4.771e-01 2.946e-01 6.107e-02
 2.484e-02 1.063e+00 8.741e-01 7.443e-01 3.258e-02 1.797e-03 2.113e-01
 4.673e-03 5.879e-03 3.290e-02 2.363e-02 1.828e+00 4.998e-02 1.099e-02
 7.466e-03 5.021e-03 4.459e-02 1.146e-01 8.340e-03 2.418e-03 7.621e-02
 3.798e-02 2.147e-02 6.117e-02 5.437e-02 2.015e+00 6.027e-02 4.698e-03
 2.431e-02 4.029e-03 1.478e-01 1.948e-02 3.486e-03 2.760e-03 2.943e-02
 2.435e-02 5.756e-03 3.431e-02 8.080e-02 2.041e-01 1.351e-02 1.892e-02
 9.136e-03 5.340e-03 3.839e-02 1.753e-01 1.261e-02 2.459e-03 4.622e-02
 4.042e-01 1.241e-01 2.851e-01 2.834e-01 1.095e+00 3.249e-01 5.772e-02
 1.867e-01 1.674e-01 3.108e-01 1.155e+00 3.387e-01 4.795e-02 3.455e-01
 2.683e-01 8.309e-01 3.397e-01 6.304e-01 4.465e-01 4.098e-01 1.821e-01
 3.085e-01 2.246e+00 7.078e-01 4.560e-01 6.242e-01 1.011e-01 5.265e-01
 2.616e-02 1.705e-02 8.746e-02 4.467e-02 2.683e-01 1.242e-01 1.199e-02
 1.329e-02 2.790e-02 4.691e-02 9.868e-02 4.377e-02 1.019e-02 6.001e-03]
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.]
 [0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.8438888888888889, 0.6758859270256747)
Iterations 1110
Achieves (7.5436377211129475, 1e-05)-DP
