samples  5000  graph  30 60 ER mim  minibatch size  50  noise  1.0  minibatches per NN training  250 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 2.144444827137683
iteration 1 in outer loop, alpha = 2.144444827137683, rho = 1.0, h = 2.144444827137683
cuda
iteration 1 in inner loop,alpha 2.144444827137683 rho 1.0 h 1.3256466874605835
iteration 2 in inner loop,alpha 2.144444827137683 rho 10.0 h 0.5131010328032026
iteration 2 in outer loop, alpha = 7.275455155169709, rho = 10.0, h = 0.5131010328032026
cuda
iteration 1 in inner loop,alpha 7.275455155169709 rho 10.0 h 0.28442514981965417
iteration 2 in inner loop,alpha 7.275455155169709 rho 100.0 h 0.09687583592673477
iteration 3 in outer loop, alpha = 16.963038747843186, rho = 100.0, h = 0.09687583592673477
cuda
iteration 1 in inner loop,alpha 16.963038747843186 rho 100.0 h 0.05565872169768937
iteration 2 in inner loop,alpha 16.963038747843186 rho 1000.0 h 0.017246591836673986
iteration 4 in outer loop, alpha = 34.20963058451717, rho = 1000.0, h = 0.017246591836673986
cuda
iteration 1 in inner loop,alpha 34.20963058451717 rho 1000.0 h 0.007536379858688491
iteration 2 in inner loop,alpha 34.20963058451717 rho 10000.0 h 0.0024562545468960195
iteration 5 in outer loop, alpha = 58.77217605347737, rho = 10000.0, h = 0.0024562545468960195
cuda
iteration 1 in inner loop,alpha 58.77217605347737 rho 10000.0 h 0.0010792499674714406
iteration 2 in inner loop,alpha 58.77217605347737 rho 100000.0 h 0.00042229828057926966
iteration 6 in outer loop, alpha = 101.00200411140433, rho = 100000.0, h = 0.00042229828057926966
cuda
iteration 1 in inner loop,alpha 101.00200411140433 rho 100000.0 h 0.00021821221282891656
iteration 7 in outer loop, alpha = 319.2142169403209, rho = 1000000.0, h = 0.00021821221282891656
Threshold 0.3
[[0.    0.001 0.1   0.045 0.058 0.002 0.114 0.022 0.059 0.349 0.003 0.065
  0.001 0.001 0.008 0.03  0.002 0.051 0.055 0.88  0.041 0.005 0.135 0.015
  0.001 0.035 0.024 0.018 0.023 0.022]
 [0.    0.    0.017 0.005 0.011 0.684 1.882 0.087 0.113 0.004 0.    0.034
  0.004 0.002 0.006 0.063 0.005 0.075 0.026 0.052 0.005 0.    0.102 0.055
  0.005 0.013 0.013 0.081 0.085 0.03 ]
 [0.    0.    0.004 0.008 0.109 0.    0.069 0.05  0.001 0.    0.    0.
  0.    0.    0.    0.004 0.    0.015 0.057 0.124 0.001 0.    0.008 0.021
  0.    0.    0.019 0.014 0.022 0.007]
 [0.    0.    0.006 0.002 0.026 0.002 0.021 0.    0.    0.    0.    0.001
  0.    0.    0.    0.001 0.    0.    0.001 0.052 0.    0.    0.001 0.001
  0.    0.    0.    0.    0.06  0.   ]
 [0.    0.    0.002 0.01  0.003 0.01  0.013 0.014 0.001 0.    0.    0.
  0.    0.    0.    0.    0.    0.001 0.001 0.158 0.    0.    0.006 0.001
  0.    0.    0.001 0.009 0.013 0.001]
 [0.    0.    0.05  0.042 0.015 0.003 0.049 0.046 0.081 0.    0.    0.067
  0.    0.    0.    0.002 0.    0.006 0.005 0.835 0.001 0.    0.036 0.008
  0.    0.001 0.013 0.004 0.003 0.001]
 [0.    0.    0.011 0.028 0.027 0.001 0.003 0.021 0.005 0.    0.    0.001
  0.    0.    0.    0.017 0.    0.012 0.007 0.096 0.    0.    0.088 0.044
  0.    0.    0.003 0.009 0.021 0.002]
 [0.    0.    0.01  1.483 0.01  0.013 0.027 0.003 0.    0.    0.    0.001
  0.    0.    0.    0.002 0.    0.    0.001 0.01  0.001 0.    0.005 0.
  0.    0.    0.001 0.    0.041 0.002]
 [0.    0.    0.051 0.003 0.043 0.006 0.043 0.059 0.003 0.001 0.    0.061
  0.    0.    0.    0.102 0.    0.045 0.754 1.092 0.    0.001 1.863 0.08
  0.    0.003 0.054 0.001 0.057 0.009]
 [0.    0.001 0.126 0.139 0.031 1.138 0.055 0.646 0.09  0.    0.006 2.501
  0.    0.007 0.001 0.28  0.003 0.185 0.025 0.096 0.008 0.003 0.063 0.007
  0.    0.012 0.629 0.021 0.011 0.024]
 [0.    0.    0.027 0.188 0.033 0.015 0.09  0.079 0.9   0.014 0.    0.038
  0.002 0.001 0.014 0.027 0.003 0.054 0.064 0.102 0.052 0.009 0.031 0.068
  0.002 0.038 0.096 4.13  0.041 0.015]
 [0.    0.001 4.295 0.009 0.029 0.01  0.019 0.056 0.013 0.    0.    0.002
  0.    0.    0.    0.139 0.    0.091 0.033 0.151 0.002 0.001 0.011 0.069
  0.    0.    0.448 0.024 0.029 0.012]
 [0.004 0.    0.007 0.054 0.047 0.012 1.88  0.012 1.183 0.02  0.001 0.051
  0.    0.    0.002 0.129 0.012 0.096 0.008 0.008 0.024 0.022 0.062 0.425
  0.    0.038 0.485 0.038 0.021 3.059]
 [0.001 0.    0.082 0.002 1.233 0.042 0.021 0.13  0.063 0.01  0.005 0.069
  0.001 0.    0.003 0.121 0.003 0.93  0.032 1.344 0.019 0.004 0.043 0.038
  0.    0.006 0.144 0.068 0.008 0.003]
 [0.006 0.001 0.031 0.057 0.061 0.06  0.039 0.103 0.051 0.004 0.    1.77
  0.    0.001 0.    0.012 0.007 0.189 0.022 0.005 0.015 0.009 0.117 0.764
  0.006 3.171 0.007 0.013 0.122 0.057]
 [0.    0.    0.05  0.006 0.072 0.031 0.021 0.059 0.011 0.    0.    0.004
  0.    0.    0.    0.004 0.    0.094 0.013 0.031 0.003 0.001 0.457 0.011
  0.    0.005 0.829 0.005 0.01  0.074]
 [0.001 0.003 2.544 0.092 0.088 0.018 0.034 0.013 0.46  0.001 0.001 0.005
  0.007 0.007 0.006 0.011 0.    0.121 0.003 0.035 2.867 0.405 0.126 0.011
  0.005 0.005 0.049 0.051 0.073 0.042]
 [0.    0.    0.014 0.06  1.538 0.085 0.017 1.123 0.001 0.    0.    0.
  0.    0.    0.    0.003 0.    0.003 0.002 0.091 0.002 0.    0.013 0.001
  0.    0.001 0.003 0.011 0.206 0.001]
 [0.    0.    0.007 0.025 0.023 0.009 0.006 0.036 0.001 0.    0.    0.
  0.    0.    0.    0.001 0.    0.141 0.002 0.013 0.    0.    0.019 0.001
  0.    0.    0.011 0.006 0.035 0.001]
 [0.    0.    0.004 0.004 0.001 0.001 0.007 0.    0.001 0.    0.    0.
  0.    0.    0.    0.019 0.    0.001 0.012 0.003 0.    0.    0.07  0.01
  0.    0.    0.006 0.003 0.009 0.001]
 [0.    0.001 0.036 0.003 0.006 0.843 0.013 0.03  1.727 0.    0.    0.063
  0.    0.    0.    0.016 0.    0.075 0.024 0.082 0.002 0.001 0.007 0.029
  0.    0.021 0.009 0.013 2.129 0.036]
 [0.001 0.006 0.043 1.345 1.129 0.021 0.052 0.121 0.24  0.001 0.007 0.036
  0.    0.001 0.005 0.062 0.    0.699 0.07  0.07  0.33  0.001 0.098 0.204
  0.    0.03  0.254 0.051 1.581 2.039]
 [0.    0.    0.001 0.119 0.059 0.002 0.002 0.105 0.    0.    0.    0.002
  0.    0.    0.    0.004 0.    0.008 0.027 0.001 0.    0.    0.003 0.
  0.    0.    0.185 0.    0.005 0.   ]
 [0.    0.    0.006 0.621 0.003 0.021 0.013 0.084 0.009 0.    0.    0.004
  0.    0.    0.    0.025 0.    0.129 1.185 0.024 0.004 0.    2.463 0.003
  0.    0.    0.401 0.005 0.179 0.   ]
 [0.    0.004 0.058 0.078 0.017 0.1   1.497 0.026 0.006 0.034 0.    0.017
  0.003 0.    0.005 0.091 0.    0.057 0.057 0.058 0.034 0.068 1.783 0.037
  0.    0.036 0.086 0.061 0.01  0.053]
 [0.    0.001 0.047 0.062 0.179 0.043 0.011 2.529 0.038 0.008 0.    0.299
  0.    0.002 0.    0.171 0.    1.171 0.072 0.036 0.004 0.004 0.171 1.572
  0.    0.002 0.231 0.029 2.219 0.07 ]
 [0.    0.    0.04  0.012 0.184 0.018 0.032 0.066 0.001 0.    0.    0.002
  0.    0.    0.    0.002 0.    0.645 0.058 0.029 0.    0.001 0.009 0.002
  0.    0.    0.004 0.009 0.044 0.002]
 [0.    0.    0.036 0.089 0.002 0.035 0.03  1.366 0.167 0.001 0.    0.007
  0.    0.    0.    0.02  0.    0.034 0.04  0.054 0.043 0.005 0.013 0.019
  0.    0.015 0.002 0.003 0.024 0.015]
 [0.    0.    0.037 0.003 0.051 0.112 0.019 0.007 0.014 0.    0.    0.002
  0.    0.    0.    0.018 0.    0.002 0.008 0.059 0.    0.    0.049 0.001
  0.    0.    0.001 0.    0.002 0.002]
 [0.    0.    0.029 0.079 0.061 0.62  0.201 0.048 0.036 0.001 0.    0.018
  0.    0.    0.    0.001 0.    0.188 1.031 0.037 0.008 0.    0.035 0.402
  0.    0.    0.042 0.016 0.068 0.002]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.349 0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.88  0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.684 1.882 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.835 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    1.483 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.754 1.092 0.    0.    1.863 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    1.138 0.    0.646 0.    0.    0.    2.501
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.629 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.9   0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    4.13  0.    0.   ]
 [0.    0.    4.295 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.448 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    1.88  0.    1.183 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.425
  0.    0.    0.485 0.    0.    3.059]
 [0.    0.    0.    0.    1.233 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.93  0.    1.344 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.77
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.764
  0.    3.171 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.457 0.
  0.    0.    0.829 0.    0.    0.   ]
 [0.    0.    2.544 0.    0.    0.    0.    0.    0.46  0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    2.867 0.405 0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    1.538 0.    0.    1.123 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.843 0.    0.    1.727 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    2.129 0.   ]
 [0.    0.    0.    1.345 1.129 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.699 0.    0.    0.33  0.    0.    0.
  0.    0.    0.    0.    1.581 2.039]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.621 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    1.185 0.    0.    0.    2.463 0.
  0.    0.    0.401 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    1.497 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.783 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    2.529 0.    0.    0.    0.
  0.    0.    0.    0.    0.    1.171 0.    0.    0.    0.    0.    1.572
  0.    0.    0.    0.    2.219 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.645 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    1.366 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.62  0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    1.031 0.    0.    0.    0.    0.402
  0.    0.    0.    0.    0.    0.   ]]
{'fdr': 0.1, 'tpr': 0.9, 'fpr': 0.016, 'f1': 0.9, 'shd': 8, 'npred': 60, 'ntrue': 60}
[5.785e-04 1.001e-01 4.535e-02 5.824e-02 2.016e-03 1.137e-01 2.221e-02
 5.911e-02 3.488e-01 2.660e-03 6.498e-02 7.574e-04 7.078e-04 8.315e-03
 2.978e-02 2.020e-03 5.050e-02 5.539e-02 8.798e-01 4.101e-02 4.560e-03
 1.347e-01 1.453e-02 7.362e-04 3.494e-02 2.407e-02 1.797e-02 2.300e-02
 2.208e-02 3.002e-04 1.705e-02 4.952e-03 1.111e-02 6.841e-01 1.882e+00
 8.695e-02 1.129e-01 3.684e-03 2.942e-04 3.432e-02 3.962e-03 2.158e-03
 5.661e-03 6.348e-02 5.006e-03 7.499e-02 2.593e-02 5.165e-02 5.171e-03
 1.857e-04 1.015e-01 5.464e-02 4.772e-03 1.327e-02 1.288e-02 8.077e-02
 8.503e-02 3.031e-02 4.720e-05 1.365e-04 8.151e-03 1.095e-01 7.757e-05
 6.856e-02 4.971e-02 1.009e-03 1.499e-05 6.638e-06 5.893e-05 2.599e-05
 3.485e-05 2.556e-06 4.105e-03 1.137e-05 1.531e-02 5.719e-02 1.240e-01
 7.232e-04 2.642e-04 8.358e-03 2.139e-02 3.509e-05 4.213e-05 1.853e-02
 1.390e-02 2.197e-02 7.494e-03 3.068e-05 3.416e-05 6.411e-03 2.564e-02
 2.314e-03 2.064e-02 4.425e-04 2.958e-04 1.019e-04 4.313e-06 6.724e-04
 1.280e-04 8.742e-05 1.072e-05 1.248e-03 1.199e-04 6.756e-05 9.301e-04
 5.175e-02 2.379e-04 1.087e-04 1.037e-03 1.086e-03 1.889e-05 3.271e-05
 7.921e-05 5.829e-05 5.954e-02 3.993e-04 5.940e-05 2.968e-04 2.497e-03
 9.778e-03 1.039e-02 1.279e-02 1.426e-02 1.223e-03 5.153e-05 1.329e-04
 2.702e-04 7.630e-05 1.864e-05 2.441e-05 4.730e-04 1.242e-04 6.564e-04
 8.817e-04 1.581e-01 2.757e-04 8.807e-05 5.934e-03 1.005e-03 6.705e-05
 1.546e-04 9.860e-04 9.284e-03 1.277e-02 1.112e-03 9.909e-05 3.307e-05
 4.969e-02 4.237e-02 1.509e-02 4.887e-02 4.596e-02 8.081e-02 1.331e-04
 4.419e-05 6.654e-02 2.617e-05 2.237e-04 2.549e-05 2.100e-03 9.651e-06
 6.433e-03 4.983e-03 8.353e-01 6.203e-04 1.344e-04 3.559e-02 8.029e-03
 3.214e-04 5.491e-04 1.255e-02 4.280e-03 3.096e-03 1.168e-03 1.238e-04
 1.079e-05 1.112e-02 2.763e-02 2.747e-02 8.135e-04 2.086e-02 4.623e-03
 1.597e-04 1.286e-04 5.242e-04 1.162e-05 2.159e-04 3.474e-05 1.713e-02
 2.260e-05 1.167e-02 7.460e-03 9.551e-02 3.410e-04 1.385e-04 8.807e-02
 4.351e-02 1.713e-05 2.918e-04 2.944e-03 9.428e-03 2.144e-02 2.117e-03
 3.022e-05 1.134e-04 9.606e-03 1.483e+00 1.023e-02 1.308e-02 2.735e-02
 4.156e-04 1.136e-04 1.384e-05 1.138e-03 1.974e-05 3.570e-05 1.844e-06
 2.058e-03 4.754e-05 3.451e-04 8.707e-04 9.505e-03 6.847e-04 2.028e-04
 4.772e-03 4.711e-04 2.990e-05 1.065e-04 7.647e-04 3.210e-04 4.127e-02
 1.868e-03 1.533e-04 6.785e-05 5.127e-02 3.322e-03 4.277e-02 6.326e-03
 4.312e-02 5.901e-02 8.760e-04 2.743e-05 6.063e-02 6.359e-06 3.017e-04
 8.599e-05 1.019e-01 4.261e-06 4.488e-02 7.542e-01 1.092e+00 2.247e-04
 5.693e-04 1.863e+00 8.038e-02 2.392e-04 3.101e-03 5.391e-02 1.403e-03
 5.710e-02 9.062e-03 4.340e-05 9.859e-04 1.265e-01 1.395e-01 3.124e-02
 1.138e+00 5.469e-02 6.462e-01 9.047e-02 6.275e-03 2.501e+00 2.159e-04
 7.277e-03 5.212e-04 2.795e-01 3.212e-03 1.846e-01 2.493e-02 9.629e-02
 7.904e-03 2.948e-03 6.260e-02 6.819e-03 3.443e-04 1.219e-02 6.294e-01
 2.068e-02 1.104e-02 2.432e-02 2.476e-04 2.879e-04 2.688e-02 1.877e-01
 3.269e-02 1.518e-02 9.021e-02 7.863e-02 9.004e-01 1.362e-02 3.783e-02
 2.095e-03 5.529e-04 1.405e-02 2.723e-02 2.685e-03 5.448e-02 6.413e-02
 1.020e-01 5.190e-02 8.964e-03 3.126e-02 6.779e-02 2.142e-03 3.827e-02
 9.590e-02 4.130e+00 4.060e-02 1.517e-02 1.285e-04 5.658e-04 4.295e+00
 8.824e-03 2.880e-02 1.012e-02 1.902e-02 5.595e-02 1.288e-02 7.130e-05
 2.802e-04 1.522e-04 1.528e-04 9.611e-06 1.388e-01 2.902e-05 9.100e-02
 3.335e-02 1.509e-01 1.737e-03 7.566e-04 1.068e-02 6.868e-02 1.417e-04
 2.385e-04 4.483e-01 2.448e-02 2.861e-02 1.213e-02 3.741e-03 4.880e-04
 7.187e-03 5.386e-02 4.704e-02 1.151e-02 1.880e+00 1.242e-02 1.183e+00
 1.992e-02 6.554e-04 5.129e-02 2.499e-04 1.874e-03 1.291e-01 1.158e-02
 9.643e-02 8.134e-03 7.759e-03 2.355e-02 2.247e-02 6.207e-02 4.252e-01
 4.900e-04 3.773e-02 4.846e-01 3.797e-02 2.076e-02 3.059e+00 5.468e-04
 4.729e-04 8.219e-02 2.012e-03 1.233e+00 4.229e-02 2.139e-02 1.298e-01
 6.283e-02 1.021e-02 5.195e-03 6.873e-02 1.204e-03 3.126e-03 1.212e-01
 3.276e-03 9.303e-01 3.167e-02 1.344e+00 1.921e-02 4.145e-03 4.295e-02
 3.792e-02 2.064e-04 5.573e-03 1.436e-01 6.807e-02 7.955e-03 2.736e-03
 5.822e-03 9.817e-04 3.128e-02 5.740e-02 6.070e-02 5.988e-02 3.907e-02
 1.031e-01 5.099e-02 3.790e-03 2.581e-04 1.770e+00 2.656e-04 6.589e-04
 1.230e-02 7.305e-03 1.892e-01 2.229e-02 5.030e-03 1.533e-02 8.545e-03
 1.166e-01 7.642e-01 5.560e-03 3.171e+00 7.352e-03 1.300e-02 1.215e-01
 5.689e-02 1.252e-04 1.572e-04 4.951e-02 5.997e-03 7.212e-02 3.123e-02
 2.058e-02 5.938e-02 1.091e-02 4.275e-04 9.708e-05 3.893e-03 3.031e-04
 4.021e-05 4.278e-05 2.615e-05 9.432e-02 1.277e-02 3.095e-02 2.779e-03
 1.346e-03 4.568e-01 1.130e-02 2.966e-04 5.007e-03 8.289e-01 5.216e-03
 9.842e-03 7.412e-02 5.629e-04 2.961e-03 2.544e+00 9.221e-02 8.837e-02
 1.822e-02 3.377e-02 1.329e-02 4.602e-01 5.588e-04 9.093e-04 4.912e-03
 7.459e-03 6.523e-03 5.824e-03 1.106e-02 1.214e-01 3.262e-03 3.457e-02
 2.867e+00 4.055e-01 1.255e-01 1.098e-02 5.367e-03 4.916e-03 4.877e-02
 5.054e-02 7.329e-02 4.150e-02 1.298e-04 1.835e-04 1.417e-02 6.038e-02
 1.538e+00 8.468e-02 1.723e-02 1.123e+00 1.086e-03 1.098e-04 1.518e-04
 2.945e-04 1.224e-04 1.520e-05 1.280e-05 2.601e-03 3.586e-05 2.372e-03
 9.076e-02 1.936e-03 3.670e-04 1.277e-02 6.482e-04 4.392e-05 5.437e-04
 2.868e-03 1.079e-02 2.064e-01 1.366e-03 1.779e-04 2.161e-04 7.166e-03
 2.467e-02 2.294e-02 8.523e-03 5.820e-03 3.573e-02 9.909e-04 1.485e-04
 1.856e-04 1.744e-04 2.277e-05 1.770e-04 2.862e-05 7.813e-04 8.377e-06
 1.407e-01 1.331e-02 1.969e-04 5.929e-05 1.903e-02 6.496e-04 4.612e-05
 1.700e-04 1.081e-02 6.108e-03 3.527e-02 5.448e-04 6.404e-05 4.964e-05
 4.297e-03 3.562e-03 7.260e-04 9.309e-04 6.683e-03 2.464e-04 6.870e-04
 4.468e-05 1.397e-05 4.806e-04 7.285e-05 3.702e-05 1.912e-04 1.921e-02
 1.030e-05 9.871e-04 1.235e-02 1.466e-04 1.431e-04 7.029e-02 9.550e-03
 2.931e-05 4.359e-04 5.842e-03 2.761e-03 9.076e-03 9.399e-04 2.287e-04
 6.328e-04 3.609e-02 2.806e-03 5.850e-03 8.434e-01 1.347e-02 3.013e-02
 1.727e+00 1.714e-04 5.240e-05 6.286e-02 2.805e-04 2.460e-04 2.434e-04
 1.568e-02 8.717e-06 7.504e-02 2.368e-02 8.206e-02 1.474e-03 6.861e-03
 2.851e-02 2.575e-04 2.073e-02 9.014e-03 1.269e-02 2.129e+00 3.621e-02
 5.096e-04 6.366e-03 4.286e-02 1.345e+00 1.129e+00 2.147e-02 5.213e-02
 1.212e-01 2.401e-01 1.287e-03 6.891e-03 3.598e-02 2.512e-04 1.168e-03
 4.819e-03 6.249e-02 3.130e-05 6.990e-01 6.965e-02 6.971e-02 3.301e-01
 9.805e-02 2.039e-01 1.781e-04 2.978e-02 2.538e-01 5.072e-02 1.581e+00
 2.039e+00 3.012e-05 5.035e-05 1.262e-03 1.190e-01 5.942e-02 1.782e-03
 1.882e-03 1.048e-01 1.886e-04 2.178e-04 3.909e-05 1.723e-03 3.137e-05
 4.060e-05 3.301e-06 4.272e-03 6.776e-06 7.813e-03 2.707e-02 6.021e-04
 2.123e-05 3.979e-05 2.044e-04 1.972e-05 5.200e-05 1.846e-01 3.535e-04
 5.343e-03 5.705e-05 2.138e-04 1.246e-04 5.509e-03 6.212e-01 3.400e-03
 2.126e-02 1.304e-02 8.438e-02 8.588e-03 1.955e-04 1.257e-04 3.798e-03
 2.341e-05 2.062e-04 6.876e-06 2.506e-02 2.376e-05 1.287e-01 1.185e+00
 2.433e-02 3.872e-03 5.766e-05 2.463e+00 3.179e-04 3.203e-04 4.013e-01
 5.009e-03 1.789e-01 3.966e-04 4.526e-04 3.565e-03 5.843e-02 7.782e-02
 1.685e-02 1.000e-01 1.497e+00 2.585e-02 6.400e-03 3.417e-02 3.769e-04
 1.682e-02 2.744e-03 4.957e-04 4.593e-03 9.081e-02 1.525e-04 5.706e-02
 5.726e-02 5.841e-02 3.445e-02 6.828e-02 1.783e+00 3.694e-02 3.562e-02
 8.644e-02 6.127e-02 9.887e-03 5.301e-02 2.321e-04 5.488e-04 4.744e-02
 6.247e-02 1.791e-01 4.342e-02 1.105e-02 2.529e+00 3.831e-02 8.053e-03
 1.943e-04 2.991e-01 1.630e-04 2.428e-03 9.355e-06 1.706e-01 2.150e-04
 1.171e+00 7.173e-02 3.590e-02 3.799e-03 3.502e-03 1.712e-01 1.572e+00
 9.395e-05 2.307e-01 2.922e-02 2.219e+00 6.960e-02 3.390e-05 1.263e-04
 4.027e-02 1.224e-02 1.838e-01 1.764e-02 3.237e-02 6.583e-02 1.492e-03
 1.804e-04 2.877e-05 1.949e-03 4.066e-05 6.500e-05 1.754e-05 1.871e-03
 4.342e-05 6.453e-01 5.776e-02 2.928e-02 4.834e-04 7.696e-04 9.471e-03
 2.350e-03 6.524e-05 2.957e-04 9.047e-03 4.439e-02 1.656e-03 2.717e-04
 1.208e-04 3.557e-02 8.859e-02 2.458e-03 3.481e-02 3.014e-02 1.366e+00
 1.673e-01 6.738e-04 8.622e-06 7.022e-03 3.173e-04 2.731e-04 2.044e-04
 2.045e-02 2.353e-04 3.417e-02 3.961e-02 5.395e-02 4.335e-02 4.910e-03
 1.253e-02 1.944e-02 1.704e-04 1.451e-02 1.730e-03 2.424e-02 1.543e-02
 1.862e-04 1.513e-04 3.710e-02 2.677e-03 5.104e-02 1.120e-01 1.892e-02
 6.849e-03 1.354e-02 2.162e-04 7.327e-05 2.080e-03 9.081e-05 3.623e-05
 3.166e-06 1.783e-02 3.166e-06 1.982e-03 8.357e-03 5.948e-02 1.076e-04
 9.086e-05 4.906e-02 1.246e-03 1.079e-04 1.437e-04 5.280e-04 1.676e-04
 1.741e-03 2.577e-04 1.733e-04 2.936e-02 7.916e-02 6.111e-02 6.197e-01
 2.009e-01 4.776e-02 3.618e-02 1.386e-03 2.085e-04 1.763e-02 9.515e-07
 1.903e-04 6.229e-05 1.083e-03 8.938e-05 1.883e-01 1.031e+00 3.652e-02
 7.934e-03 8.289e-05 3.518e-02 4.022e-01 8.114e-05 4.026e-04 4.204e-02
 1.613e-02 6.842e-02]
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 1. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]]
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.9556378600823046, 0.9235446603040477)
cuda
9630
cuda
Objective function 291.21 = squared loss an data 35.20 + 0.5*rho*h**2 254.631624 + alpha*h 0.000000 + L2reg 0.55 + L1reg 0.82 ; SHD = 416 ; DAG False
||w||^2 7123590.592458271
exp ma of ||w||^2 34574690938.56719
||w|| 2669.0055437294004
exp ma of ||w|| 58885.38460489379
||w||^2 0.01641668506912126
exp ma of ||w||^2 0.021264160050098825
||w|| 0.12812761243822995
exp ma of ||w|| 0.142380670557536
||w||^2 0.014222017306304605
exp ma of ||w||^2 0.022590501014844267
||w|| 0.11925609966079137
exp ma of ||w|| 0.14865476957127002
||w||^2 0.022656531572259483
exp ma of ||w||^2 0.02196663868811849
||w|| 0.15052086756413371
exp ma of ||w|| 0.14602025583609324
||w||^2 0.02097571644408661
exp ma of ||w||^2 0.022173464884843567
||w|| 0.14482995699815218
exp ma of ||w|| 0.14719590024441173
||w||^2 0.014756194110664225
exp ma of ||w||^2 0.021741464737263478
||w|| 0.12147507608832449
exp ma of ||w|| 0.1452231006358331
||w||^2 0.031996601547004073
exp ma of ||w||^2 0.021816148528675416
||w|| 0.1788759389828718
exp ma of ||w|| 0.14576403953181175
||w||^2 0.01762730152222072
exp ma of ||w||^2 0.022680586932492044
||w|| 0.1327678482247141
exp ma of ||w|| 0.14887595183199037
||w||^2 0.019425528163564985
exp ma of ||w||^2 0.02266362587329659
||w|| 0.13937549341101896
exp ma of ||w|| 0.14842177118877056
||w||^2 0.010972824210898003
exp ma of ||w||^2 0.02311941757942228
||w|| 0.10475124920924811
exp ma of ||w|| 0.1497735434155945
||w||^2 0.023218412269591128
exp ma of ||w||^2 0.02278528153524089
||w|| 0.15237589136602656
exp ma of ||w|| 0.14864782967106166
||w||^2 0.035355632640165
exp ma of ||w||^2 0.021722004076833324
||w|| 0.18803093532758114
exp ma of ||w|| 0.14562374455546914
cuda
Objective function 30.03 = squared loss an data 28.03 + 0.5*rho*h**2 1.243719 + alpha*h 0.000000 + L2reg 0.29 + L1reg 0.46 ; SHD = 89 ; DAG False
Proportion of microbatches that were clipped  0.7524624576134346
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 1.577161638020975
iteration 1 in outer loop, alpha = 1.577161638020975, rho = 1.0, h = 1.577161638020975
cuda
9630
cuda
Objective function 32.52 = squared loss an data 28.03 + 0.5*rho*h**2 1.243719 + alpha*h 2.487439 + L2reg 0.29 + L1reg 0.46 ; SHD = 89 ; DAG False
||w||^2 9220.949191154205
exp ma of ||w||^2 15091843.639284542
||w|| 96.0257735774839
exp ma of ||w|| 1010.8443847669007
||w||^2 0.08676769922833394
exp ma of ||w||^2 27957.253826531432
||w|| 0.2945635741708977
exp ma of ||w|| 2.59091379379659
||w||^2 0.036475417658281106
exp ma of ||w||^2 9442.709195567319
||w|| 0.1909853859809203
exp ma of ||w|| 0.9980459542119585
||w||^2 0.025998456032936136
exp ma of ||w||^2 0.025882137944322873
||w|| 0.16124036725626786
exp ma of ||w|| 0.15960152199941047
||w||^2 0.02031358489866964
exp ma of ||w||^2 0.023283329629994853
||w|| 0.14252573416288597
exp ma of ||w|| 0.1511022729376131
||w||^2 0.02769261311877679
exp ma of ||w||^2 0.024196613540309057
||w|| 0.16641097655736772
exp ma of ||w|| 0.15387256248963777
||w||^2 0.014223524407513153
exp ma of ||w||^2 0.021529717128403587
||w|| 0.11926241825283082
exp ma of ||w|| 0.14473444386963058
||w||^2 0.019775135796401274
exp ma of ||w||^2 0.02616621257188011
||w|| 0.14062409393984118
exp ma of ||w|| 0.15968684843870573
cuda
Objective function 30.24 = squared loss an data 27.23 + 0.5*rho*h**2 0.570610 + alpha*h 1.684848 + L2reg 0.32 + L1reg 0.43 ; SHD = 75 ; DAG False
Proportion of microbatches that were clipped  0.7505903428059604
iteration 1 in inner loop, alpha 1.577161638020975 rho 1.0 h 1.0682788871544666
9630
cuda
Objective function 35.38 = squared loss an data 27.23 + 0.5*rho*h**2 5.706099 + alpha*h 1.684848 + L2reg 0.32 + L1reg 0.43 ; SHD = 75 ; DAG False
||w||^2 847.5730899204458
exp ma of ||w||^2 13133311.130953519
||w|| 29.113108558181242
exp ma of ||w|| 656.9900236403065
||w||^2 0.019420306959079654
exp ma of ||w||^2 0.026372986857132897
||w|| 0.13935676144012407
exp ma of ||w|| 0.15966560488899265
||w||^2 0.026917896530732052
exp ma of ||w||^2 0.0284256852236913
||w|| 0.1640667441340019
exp ma of ||w|| 0.16623911242125913
||w||^2 0.028212118687490954
exp ma of ||w||^2 0.027912816342041617
||w|| 0.16796463522864255
exp ma of ||w|| 0.16454093738600947
||w||^2 0.019699232255661534
exp ma of ||w||^2 0.028029456399590705
||w|| 0.1403539534735717
exp ma of ||w|| 0.1651748457393677
||w||^2 0.04995947945242623
exp ma of ||w||^2 0.02578993688529839
||w|| 0.22351617268651106
exp ma of ||w|| 0.1581983991264609
||w||^2 0.0221636858749294
exp ma of ||w||^2 0.025982897217094413
||w|| 0.14887473215737249
exp ma of ||w|| 0.1587451895663048
||w||^2 0.02415966426878722
exp ma of ||w||^2 0.02729238184713634
||w|| 0.15543379384415482
exp ma of ||w|| 0.1626456798682719
||w||^2 0.026111319319621032
exp ma of ||w||^2 0.026548299426655254
||w|| 0.16158997283130236
exp ma of ||w|| 0.160067014874908
||w||^2 0.013755633165340507
exp ma of ||w||^2 0.02704512541375083
||w|| 0.117284411433662
exp ma of ||w|| 0.16165656157622718
||w||^2 0.030975328540412475
exp ma of ||w||^2 0.029377798606463147
||w|| 0.1759980924340161
exp ma of ||w|| 0.16874582681665284
||w||^2 0.019594402521050318
exp ma of ||w||^2 0.029742237313915385
||w|| 0.13998000757626183
exp ma of ||w|| 0.16906615668836264
||w||^2 0.03432608749339727
exp ma of ||w||^2 0.028710089158253155
||w|| 0.18527300800007881
exp ma of ||w|| 0.16628492276309298
cuda
Objective function 30.05 = squared loss an data 27.64 + 0.5*rho*h**2 1.007244 + alpha*h 0.707878 + L2reg 0.33 + L1reg 0.37 ; SHD = 71 ; DAG True
Proportion of microbatches that were clipped  0.7547837272873452
iteration 2 in inner loop, alpha 1.577161638020975 rho 10.0 h 0.448830456489798
9630
cuda
Objective function 39.12 = squared loss an data 27.64 + 0.5*rho*h**2 10.072439 + alpha*h 0.707878 + L2reg 0.33 + L1reg 0.37 ; SHD = 71 ; DAG True
||w||^2 13996050808.78735
exp ma of ||w||^2 4010339269.1268177
||w|| 118304.90610616007
exp ma of ||w|| 33588.758356896644
||w||^2 0.4174520100402035
exp ma of ||w||^2 382527.7744718525
||w|| 0.6461052623529725
exp ma of ||w|| 14.401010899271997
||w||^2 0.393304467886915
exp ma of ||w||^2 374915.47886054625
||w|| 0.627139910934486
exp ma of ||w|| 14.126302148046296
||w||^2 0.18409607587922855
exp ma of ||w||^2 1460.9051654847028
||w|| 0.42906418619972064
exp ma of ||w|| 0.5071162394498319
||w||^2 0.08747984695145171
exp ma of ||w||^2 73.19298377657668
||w|| 0.2957699223238423
exp ma of ||w|| 0.32252567690967876
||w||^2 0.02255687188391248
exp ma of ||w||^2 0.06527681549813502
||w|| 0.1501894533045263
exp ma of ||w|| 0.17546651344202469
||w||^2 0.04012781693615823
exp ma of ||w||^2 0.03124985702139943
||w|| 0.2003192874791597
exp ma of ||w|| 0.1735782744525416
||w||^2 0.06660926887078664
exp ma of ||w||^2 0.03183251103638034
||w|| 0.2580877154588855
exp ma of ||w|| 0.17552707120382052
||w||^2 0.03917849183562775
exp ma of ||w||^2 0.032155639788561285
||w|| 0.1979355749622279
exp ma of ||w|| 0.17648409670058862
||w||^2 0.025298299173399
exp ma of ||w||^2 0.03114233615528463
||w|| 0.15905439061339677
exp ma of ||w|| 0.17346937077681973
||w||^2 0.021803648278637094
exp ma of ||w||^2 0.03232779436012391
||w|| 0.14766058471588514
exp ma of ||w|| 0.17623016067084635
||w||^2 0.01741552756335995
exp ma of ||w||^2 0.030003376589043007
||w|| 0.13196790353476087
exp ma of ||w|| 0.17013911410546098
||w||^2 0.020116978824427242
exp ma of ||w||^2 0.03035487255528263
||w|| 0.1418343358444183
exp ma of ||w|| 0.17133392512086065
||w||^2 0.026004236940849548
exp ma of ||w||^2 0.029736562943130908
||w|| 0.1612582926266105
exp ma of ||w|| 0.1693264307949837
||w||^2 0.04264883604514957
exp ma of ||w||^2 0.030740320525083336
||w|| 0.20651594622486072
exp ma of ||w|| 0.17196375494834426
||w||^2 0.016784969975818548
exp ma of ||w||^2 0.030974574613942818
||w|| 0.12955682141754848
exp ma of ||w|| 0.1726060126436303
||w||^2 0.027926922403347782
exp ma of ||w||^2 0.03241697160646836
||w|| 0.16711350155911336
exp ma of ||w|| 0.17618006302710507
cuda
Objective function 30.10 = squared loss an data 28.03 + 0.5*rho*h**2 1.178154 + alpha*h 0.242099 + L2reg 0.34 + L1reg 0.31 ; SHD = 64 ; DAG True
Proportion of microbatches that were clipped  0.7532699650662117
iteration 3 in inner loop, alpha 1.577161638020975 rho 100.0 h 0.15350270758262496
iteration 2 in outer loop, alpha = 16.92743239628347, rho = 100.0, h = 0.15350270758262496
cuda
9630
cuda
Objective function 32.45 = squared loss an data 28.03 + 0.5*rho*h**2 1.178154 + alpha*h 2.598407 + L2reg 0.34 + L1reg 0.31 ; SHD = 64 ; DAG True
||w||^2 432529968.2500452
exp ma of ||w||^2 1660113530.0420406
||w|| 20797.354837816398
exp ma of ||w|| 33258.960078438795
||w||^2 463739.0010929484
exp ma of ||w||^2 90921478.27420793
||w|| 680.9838478943157
exp ma of ||w|| 3713.638482285338
||w||^2 1479.1240712632307
exp ma of ||w||^2 18051698.721913353
||w|| 38.45938209674241
exp ma of ||w|| 840.3586712594797
||w||^2 0.241034598604715
exp ma of ||w||^2 32769.33867862443
||w|| 0.4909527457960847
exp ma of ||w|| 2.3648052468048166
||w||^2 0.042590885062982344
exp ma of ||w||^2 3.599876453508382
||w|| 0.20637559221715718
exp ma of ||w|| 0.26054292290737724
v before min max tensor([[ 25.370,  21.407,  34.104,  ...,   2.938, -16.613, -17.137],
        [  0.613, -13.784,  12.044,  ...,   3.215, -21.139, -18.550],
        [-18.585, -16.915, -19.804,  ..., -17.584, -15.913,   9.061],
        ...,
        [-11.863,  -1.893, -21.367,  ..., -12.709, -15.461, -14.847],
        [-11.161, -17.967, -14.637,  ..., -14.723, -14.757,  -3.508],
        [  2.073, -20.237, -16.454,  ...,   9.770,  37.830, -24.138]],
       device='cuda:0')
v tensor([[1.000e+01, 1.000e+01, 1.000e+01,  ..., 2.938e+00, 1.000e-12,
         1.000e-12],
        [6.126e-01, 1.000e-12, 1.000e+01,  ..., 3.215e+00, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         9.061e+00],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [2.073e+00, 1.000e-12, 1.000e-12,  ..., 9.770e+00, 1.000e+01,
         1.000e-12]], device='cuda:0')
v before min max tensor([ 1.447e+01, -2.098e+01, -3.459e+00, -1.342e+01, -1.585e+00,  6.534e+00,
        -2.043e+01, -1.377e+01,  1.450e+01, -2.629e+01, -1.854e+01, -2.099e+01,
        -1.590e+01,  1.897e+01,  2.713e+01, -1.757e+01,  6.241e+00, -1.332e+01,
        -1.832e+01, -2.013e+01,  8.687e-01, -1.349e+01,  1.889e+01,  1.033e+01,
        -1.806e+01, -4.130e+00,  3.804e+01, -1.114e+01,  3.322e+01,  1.134e+01,
        -1.181e+01,  9.081e+01,  2.594e+01, -8.621e+00, -1.788e+01, -1.710e+01,
         2.273e+01, -1.372e+01,  1.135e+01, -1.947e+01, -9.770e+00,  8.424e+00,
        -1.102e+01, -1.226e+01, -5.242e+00, -1.817e+01, -1.524e+01, -1.063e+01,
        -1.445e+01, -1.494e+01,  2.271e+01,  7.191e+01, -1.620e+01, -1.460e+01,
        -1.541e+01, -1.462e+01, -1.747e+01,  6.140e+00,  5.064e+01, -8.890e+00,
        -1.294e+01,  6.162e+00, -1.784e+01, -2.125e+01, -8.021e+00, -7.665e+00,
        -7.961e+00,  5.328e+01, -7.277e+00, -1.047e+01, -1.485e+01, -4.740e+00,
        -1.062e+01, -1.093e+01,  4.050e+00, -6.390e+00,  2.650e+00, -2.126e+01,
        -1.044e+01,  3.891e+01, -1.083e+01, -1.385e+01, -1.864e+01, -9.631e+00,
        -1.293e+01, -2.033e+01,  2.463e+01,  3.232e+01,  1.694e+01, -1.142e+01,
        -1.585e+01, -2.015e+01, -1.938e+01, -1.500e+01,  8.749e+00, -1.610e+01,
        -1.001e+01, -1.052e+01, -1.150e+00, -1.857e+01, -6.747e+00, -1.966e+01,
         6.188e+01, -2.123e+01, -2.283e+01, -6.075e+00, -1.574e+01, -1.616e+00,
        -1.852e+01, -1.204e+01, -1.927e+01, -6.008e+00,  1.178e-01, -1.642e+01,
        -1.430e+01,  7.226e+00, -1.798e+01,  7.939e+01, -1.294e+01, -2.054e+01,
        -1.431e+01, -8.465e+00, -4.630e-01,  8.355e+00, -1.728e+01, -1.473e+01,
        -1.180e+01, -3.843e+00, -8.901e+00, -2.294e+00,  4.348e+01, -7.773e+00,
        -9.846e+00, -1.515e-01,  9.635e+00, -1.390e+01, -2.124e+01, -2.498e-01,
         1.203e+01,  3.221e+01, -1.729e+01, -1.261e+01,  7.623e+01,  6.476e+01,
        -1.284e+01, -3.509e+00, -1.947e+01,  5.574e+00, -1.126e+01, -1.987e+01,
        -5.482e+00, -8.763e+00, -1.909e+01, -1.585e+01,  1.649e+01, -8.732e+00,
         8.620e-01, -1.443e+01,  3.951e+01,  2.414e+01, -7.990e+00, -1.719e+01,
         4.896e+01, -1.304e+01, -1.595e+01, -1.835e+01, -1.695e+01, -2.584e+01,
        -4.649e+00,  4.058e+01, -1.526e+01,  3.658e+00,  4.843e+01, -2.302e+01,
        -1.182e+01, -2.097e+01, -3.721e+00,  4.284e+00, -1.724e+01, -1.518e+01,
        -2.072e+01,  1.658e+01, -1.030e+01, -1.702e+00, -8.692e+00,  2.593e+01,
        -1.457e+01,  1.942e+01, -1.914e+01, -7.487e+00, -6.046e+00,  1.422e+01,
         7.062e+01, -1.671e+01, -1.912e+01, -1.169e+01, -2.340e+01, -9.448e-02,
        -2.258e+01, -1.583e+01, -1.256e+01,  1.898e+01, -2.087e+01, -1.556e+01,
         4.919e+00, -1.786e+01, -2.807e+00,  3.903e+00, -1.866e+01, -1.475e+01,
         3.386e+00, -1.530e+00, -2.072e+01, -1.546e+01, -1.548e+01, -1.830e+01,
        -1.984e+01, -4.353e-02, -2.081e+01,  1.891e+00, -1.052e+01, -1.779e+01,
        -1.983e+01,  4.045e+00, -2.017e+01, -1.310e+01,  2.158e+00, -1.347e+01,
        -1.128e+00, -8.838e+00,  2.965e+01, -1.136e+01, -2.630e+00,  4.805e+00,
        -1.239e+00,  1.667e+01, -1.525e+01, -1.992e+01,  4.762e+01,  2.846e+00,
        -2.299e+01,  2.892e+01, -1.898e+01, -8.676e+00, -1.231e+01, -1.036e+01,
        -1.920e+01,  2.068e+00, -1.157e+01, -4.056e+00, -1.123e+01, -1.458e+01,
        -2.717e+00,  1.103e+02, -1.931e+00, -1.857e+00, -1.296e+01, -1.165e+01,
        -3.815e+00, -1.821e+01, -1.383e+01, -1.726e+01, -2.503e+01, -2.298e+01,
        -2.112e+01, -1.630e+01,  1.161e+01,  6.650e+00, -2.136e+01, -1.882e+01,
        -1.021e+01, -1.802e+01,  1.094e+02, -1.571e+01, -1.489e+01, -1.243e+01,
        -2.067e+01, -1.696e+01,  1.951e+01,  1.975e+01,  1.512e+01, -1.659e+01,
        -1.728e+01, -2.602e+00, -1.004e+01, -1.907e+01, -1.256e+01,  1.029e+02,
        -6.072e+00, -3.849e+00,  1.418e+01, -1.325e+01, -4.428e+00, -1.397e+01,
        -2.091e+01, -3.365e+00, -5.372e+00, -1.989e+01, -8.858e+00, -1.346e+01],
       device='cuda:0')
v tensor([1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 6.534e+00,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 6.241e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 8.687e-01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 8.424e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 6.140e+00, 1.000e+01, 1.000e-12,
        1.000e-12, 6.162e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 4.050e+00, 1.000e-12, 2.650e+00, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 8.749e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.178e-01, 1.000e-12,
        1.000e-12, 7.226e+00, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 8.355e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 9.635e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 5.574e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        8.620e-01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 3.658e+00, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 4.284e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        4.919e+00, 1.000e-12, 1.000e-12, 3.903e+00, 1.000e-12, 1.000e-12,
        3.386e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.891e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 4.045e+00, 1.000e-12, 1.000e-12, 2.158e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 4.805e+00,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 2.846e+00,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 2.068e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 6.650e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-1.007e+01],
         [-1.668e+01],
         [ 3.614e+01],
         [-2.077e+01],
         [-1.361e+01],
         [-1.133e+01],
         [ 1.739e+01],
         [ 1.213e+01],
         [-1.243e+01],
         [-3.394e+00]],

        [[ 1.980e+01],
         [-1.133e+01],
         [-9.289e+00],
         [-2.187e+01],
         [-5.969e+00],
         [-1.387e+01],
         [ 2.388e+01],
         [-1.996e+01],
         [ 7.092e+00],
         [ 2.206e+01]],

        [[-2.778e+00],
         [-1.054e+01],
         [-2.371e+01],
         [-8.889e+00],
         [ 4.697e+01],
         [ 2.389e+01],
         [-1.370e+01],
         [-2.094e+01],
         [-7.802e+00],
         [ 2.439e+01]],

        [[-1.389e+01],
         [-4.336e+00],
         [ 1.014e+01],
         [-1.848e+01],
         [-5.165e+00],
         [-1.609e+01],
         [-9.365e+00],
         [ 3.404e+01],
         [-1.956e+01],
         [-1.042e+01]],

        [[ 3.333e+00],
         [-7.570e+00],
         [ 4.913e+01],
         [-1.588e+01],
         [ 8.528e+01],
         [-1.945e+01],
         [-1.909e+01],
         [ 4.728e+01],
         [ 1.081e+01],
         [ 3.766e+01]],

        [[-3.968e+00],
         [ 4.741e+01],
         [-1.588e+01],
         [ 3.405e+00],
         [-1.159e+01],
         [ 2.484e+01],
         [-1.096e+01],
         [-2.213e+01],
         [ 7.283e+00],
         [-1.353e+01]],

        [[-1.926e+01],
         [-1.335e+01],
         [-9.081e+00],
         [-1.565e+01],
         [-1.544e+01],
         [ 1.053e+01],
         [-1.613e+01],
         [-1.446e+01],
         [-1.514e+01],
         [-3.930e+00]],

        [[-1.708e+01],
         [-1.989e+01],
         [-2.112e+01],
         [-1.964e+01],
         [ 1.153e+01],
         [-1.873e+01],
         [-2.215e+01],
         [ 1.165e+01],
         [-2.197e+01],
         [-2.345e+01]],

        [[-1.881e+01],
         [ 1.465e+01],
         [ 4.433e+00],
         [-2.256e+01],
         [ 3.041e+01],
         [ 8.169e+00],
         [-1.392e+01],
         [-1.462e+01],
         [-1.714e+01],
         [-1.265e+01]],

        [[-1.351e+01],
         [-8.507e+00],
         [-1.776e+01],
         [-9.104e+00],
         [-1.619e+01],
         [ 2.340e+01],
         [-2.261e+01],
         [-5.362e+00],
         [-1.147e+01],
         [-2.176e+01]],

        [[-1.664e+01],
         [-2.160e+00],
         [-1.087e+01],
         [-1.602e+01],
         [-1.668e+01],
         [ 2.048e+01],
         [-1.887e+01],
         [-1.418e+01],
         [-1.909e+01],
         [ 3.173e+01]],

        [[ 1.532e+01],
         [-1.580e+01],
         [-2.272e+01],
         [ 2.437e+01],
         [ 1.712e+02],
         [ 4.946e+01],
         [-7.569e-01],
         [ 2.201e+00],
         [-1.886e+01],
         [ 1.877e+02]],

        [[-1.252e+01],
         [-1.757e+00],
         [-1.701e+01],
         [ 1.187e+01],
         [-1.638e+01],
         [ 2.974e+01],
         [-2.186e+01],
         [ 8.908e+00],
         [ 3.591e+00],
         [-1.448e+01]],

        [[-3.753e+00],
         [ 8.753e+01],
         [-2.339e+00],
         [-1.797e+01],
         [-1.369e+01],
         [ 9.850e+00],
         [-2.116e+01],
         [-5.746e+00],
         [-1.893e+01],
         [ 7.075e+00]],

        [[-8.619e+00],
         [-1.832e+01],
         [-2.022e+01],
         [-1.276e+01],
         [-4.381e+00],
         [ 9.869e+01],
         [-1.102e+01],
         [-1.650e+01],
         [-1.464e+01],
         [ 1.897e+01]],

        [[-1.422e+01],
         [-1.094e+01],
         [ 6.817e+00],
         [ 6.938e+01],
         [-1.624e+01],
         [-1.385e+01],
         [-2.084e+01],
         [-5.844e+00],
         [-2.247e+01],
         [-4.102e-01]],

        [[-1.721e+01],
         [-1.690e+01],
         [-1.328e+01],
         [-7.466e+00],
         [-3.918e+00],
         [ 1.344e+01],
         [-2.411e+01],
         [-9.876e+00],
         [-1.380e+01],
         [ 2.671e+01]],

        [[-1.170e+01],
         [ 4.195e+01],
         [ 2.275e+01],
         [-2.136e+01],
         [-1.761e+01],
         [-1.857e+01],
         [ 5.729e+00],
         [-1.585e+01],
         [ 3.426e+01],
         [-2.109e+01]],

        [[-1.132e+01],
         [ 2.533e+00],
         [-7.313e+00],
         [ 2.653e+01],
         [-1.603e+01],
         [-1.872e+01],
         [-1.054e+01],
         [-1.290e+01],
         [-5.033e+00],
         [-1.705e-01]],

        [[-1.892e+01],
         [ 7.875e+00],
         [-1.495e+01],
         [-2.130e+01],
         [-9.462e+00],
         [ 6.444e-01],
         [-2.302e+01],
         [ 4.987e+01],
         [ 1.886e+01],
         [-1.969e+01]],

        [[ 2.349e+01],
         [ 5.913e+00],
         [-1.693e+01],
         [-9.206e+00],
         [-1.999e+01],
         [-1.928e+01],
         [-3.211e-01],
         [-2.073e+01],
         [ 9.046e+00],
         [-3.323e+00]],

        [[ 1.017e+01],
         [-2.062e+01],
         [-2.104e+01],
         [-2.013e+01],
         [ 1.557e+01],
         [-1.018e+01],
         [ 1.119e+01],
         [-6.921e+00],
         [-7.710e+00],
         [-1.070e+01]],

        [[-2.073e+01],
         [ 2.720e+01],
         [-1.911e+01],
         [ 5.690e+01],
         [-1.541e+01],
         [ 3.189e+01],
         [ 4.385e+01],
         [-1.907e+01],
         [ 3.375e+00],
         [-2.250e+01]],

        [[-1.847e+01],
         [-1.360e+01],
         [-1.357e+01],
         [-1.681e+01],
         [ 6.722e+01],
         [-1.993e+01],
         [ 4.380e+01],
         [-1.379e+01],
         [ 3.165e+00],
         [-1.546e+01]],

        [[-1.180e+01],
         [-1.471e+01],
         [ 1.306e+02],
         [-1.604e+01],
         [ 1.318e+01],
         [-7.960e+00],
         [-1.602e+01],
         [ 5.960e+01],
         [-1.577e+01],
         [ 4.155e+01]],

        [[-2.354e+01],
         [-1.372e+01],
         [-6.658e+00],
         [-1.571e+01],
         [-1.020e+01],
         [-1.344e+01],
         [-1.364e+01],
         [-2.271e+01],
         [ 1.707e+01],
         [-5.003e+00]],

        [[-1.603e+01],
         [-8.778e+00],
         [-1.142e+01],
         [-1.695e+01],
         [ 1.352e+02],
         [-1.071e+01],
         [ 1.431e+02],
         [-1.155e+01],
         [-2.851e+00],
         [-8.360e+00]],

        [[-3.144e+00],
         [-7.701e+00],
         [-8.072e+00],
         [-1.691e+01],
         [ 1.028e+02],
         [-2.222e+01],
         [-3.657e+00],
         [-1.944e+01],
         [-7.295e+00],
         [ 1.192e+01]],

        [[-6.860e-01],
         [-5.735e+00],
         [ 2.317e+01],
         [ 3.107e+01],
         [ 1.940e+01],
         [-9.250e+00],
         [ 6.356e+01],
         [ 4.744e+01],
         [ 2.593e+01],
         [-1.488e+01]],

        [[-1.776e+01],
         [ 3.545e-02],
         [ 7.440e+01],
         [-1.430e+01],
         [-1.737e+01],
         [-1.204e+01],
         [-1.252e+01],
         [ 1.137e+01],
         [ 1.949e+00],
         [-8.075e+00]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [7.092e+00],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[3.333e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [3.405e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [7.283e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [4.433e+00],
         [1.000e-12],
         [1.000e+01],
         [8.169e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [2.201e+00],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [8.908e+00],
         [3.591e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [9.850e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.075e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [6.817e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.729e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [2.533e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [7.875e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.444e-01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [5.913e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [9.046e+00],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [3.375e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [3.165e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [3.545e-02],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.949e+00],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[-20.681],
        [ 78.433],
        [-20.600],
        [-17.832],
        [ 34.153],
        [ -5.267],
        [ 15.314],
        [-13.386],
        [ 37.644],
        [-21.416],
        [-19.442],
        [-11.611],
        [-23.587],
        [-23.187],
        [-21.694],
        [-15.077],
        [-17.101],
        [-18.427],
        [ 38.452],
        [ -4.865],
        [-12.235],
        [ -2.682],
        [ -0.243],
        [-12.647],
        [-12.425],
        [-17.344],
        [  4.939],
        [ 19.059],
        [-15.839],
        [ -9.129]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [4.939e+00],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 0.067,  0.042,  0.049,  ..., -0.077, -0.005,  0.116],
        [-0.029,  0.056,  0.050,  ..., -0.164,  0.006, -0.084],
        [-0.028, -0.059, -0.105,  ..., -0.100, -0.029,  0.005],
        ...,
        [-0.011, -0.071,  0.118,  ...,  0.042, -0.028, -0.073],
        [-0.036,  0.119, -0.115,  ...,  0.032,  0.373, -0.055],
        [ 0.169,  0.062, -0.193,  ...,  0.255, -0.211,  0.060]],
       device='cuda:0')
s after update for 1 param tensor([[2.263, 1.955, 1.917,  ..., 1.919, 1.704, 1.527],
        [2.350, 1.626, 2.225,  ..., 2.088, 1.841, 1.622],
        [1.816, 1.577, 1.756,  ..., 1.870, 1.379, 2.015],
        ...,
        [1.277, 2.153, 2.031,  ..., 1.840, 1.329, 2.661],
        [1.333, 1.571, 1.268,  ..., 1.283, 1.309, 1.773],
        [1.702, 1.729, 1.846,  ..., 2.224, 1.600, 2.228]], device='cuda:0')
b after update for 1 param tensor([[196.094, 182.275, 180.490,  ..., 180.554, 170.176, 161.058],
        [199.819, 166.198, 194.431,  ..., 188.375, 176.882, 166.023],
        [175.660, 163.665, 172.723,  ..., 178.255, 153.095, 185.017],
        ...,
        [147.289, 191.257, 185.744,  ..., 176.804, 150.252, 212.648],
        [150.518, 163.384, 146.784,  ..., 147.619, 149.148, 173.546],
        [170.066, 171.408, 177.107,  ..., 194.378, 164.904, 194.568]],
       device='cuda:0')
clipping threshold 0.17593421341272578
a after update for 1 param tensor([ 3.388e-02, -2.196e-02,  1.240e-01,  3.273e-02,  1.566e-01,  1.015e-01,
         4.561e-03, -3.911e-01,  2.419e-02,  8.298e-02, -3.249e-01,  1.261e-01,
        -1.423e-01, -1.035e-01,  1.277e-01,  3.397e-01,  1.223e-01,  6.543e-02,
        -1.762e-01,  2.326e-01,  5.769e-02,  1.143e-01, -1.355e-01, -2.756e-02,
        -1.376e-01, -9.626e-02,  1.934e-01,  2.323e-03, -1.404e-01,  1.983e-01,
         5.584e-02,  1.667e-01,  8.508e-02,  7.342e-02, -4.364e-01, -2.671e-01,
         4.782e-02, -9.381e-02, -2.947e-01,  5.798e-02,  3.088e-03, -5.687e-02,
         1.673e-01, -1.307e-01,  7.285e-03,  1.425e-01, -5.750e-02, -1.513e-01,
         1.795e-01,  5.176e-02, -1.405e-01,  1.111e-01,  1.658e-01, -5.018e-02,
         9.497e-02,  4.183e-02, -5.711e-02,  2.766e-02,  6.670e-02, -1.194e-01,
        -6.798e-02, -1.252e-01,  5.383e-02,  1.831e-02, -1.260e-01,  4.010e-02,
         2.127e-01,  7.790e-02, -1.698e-01,  1.050e-02, -5.061e-02,  7.979e-02,
        -1.287e-01,  2.786e-02, -1.114e-01,  2.386e-01,  6.307e-02,  5.651e-02,
        -2.770e-01, -3.821e-02, -8.275e-03, -3.195e-01,  1.858e-01, -2.601e-01,
        -1.325e-01, -1.473e-01, -2.270e-01,  8.428e-02,  1.649e-01, -2.612e-01,
         1.654e-01,  1.218e-01, -6.094e-03,  3.930e-02, -1.262e-01, -1.698e-01,
         8.142e-02, -1.494e-01,  6.838e-03, -3.195e-02,  4.569e-02,  3.605e-02,
        -2.572e-01,  1.300e-01,  1.678e-01, -3.756e-01, -8.192e-02, -7.637e-02,
         5.950e-02,  1.391e-01,  6.034e-02, -1.658e-02,  9.505e-02, -3.825e-02,
         5.586e-02,  8.485e-02, -3.047e-01,  1.408e-02, -1.705e-01, -2.291e-02,
         7.939e-02,  1.176e-02,  9.439e-02, -1.867e-01,  1.170e-02,  5.696e-02,
        -1.843e-02, -1.278e-01, -3.030e-01,  2.432e-02,  6.793e-02,  8.648e-02,
        -3.331e-01,  6.544e-04, -1.041e-01,  1.193e-02,  5.155e-02,  1.820e-02,
         8.060e-02, -1.635e-02,  1.126e-01,  2.852e-02,  1.724e-01,  1.299e-01,
        -3.419e-01,  1.183e-03, -1.642e-01,  1.963e-01,  2.927e-01,  4.792e-02,
        -1.069e-02, -1.038e-01,  1.188e-01, -1.345e-01,  3.206e-01,  2.543e-01,
         3.614e-01, -5.795e-02,  1.043e-01, -1.617e-01, -1.116e-01, -8.164e-02,
         6.457e-01,  1.636e-01,  1.154e-01, -5.352e-02,  1.015e-01,  3.620e-02,
         2.011e-01,  6.632e-02, -9.439e-02,  1.218e-01,  1.622e-01,  2.033e-01,
        -1.458e-02, -2.501e-02,  1.387e-01, -2.447e-01, -4.791e-02, -1.112e-01,
        -2.787e-01,  2.301e-02, -9.557e-03,  9.022e-02,  6.282e-04,  1.176e-01,
        -7.082e-02,  1.168e-01, -3.346e-02, -2.880e-01, -3.070e-01, -3.808e-02,
         1.702e-01,  2.557e-01, -1.586e-01,  5.436e-02, -1.031e-01, -1.249e-01,
         2.047e-02, -1.955e-01,  1.266e-02,  3.787e-02, -2.094e-01, -1.950e-01,
         3.695e-01, -5.123e-02,  7.270e-03, -2.132e-02,  1.021e-01,  3.526e-02,
         1.958e-02, -1.270e-01,  4.455e-02,  3.184e-02,  5.143e-02,  1.620e-01,
         2.005e-01, -1.471e-01, -2.334e-01, -6.915e-02, -1.633e-01,  1.005e-01,
         5.662e-01, -1.412e-01,  2.748e-01, -6.578e-02,  2.850e-02,  1.566e-01,
         1.047e-02, -9.004e-02,  5.390e-03,  1.481e-01, -1.564e-01, -5.739e-02,
         4.043e-02, -1.594e-01,  6.412e-02,  8.308e-02, -5.567e-02, -6.375e-02,
         1.736e-01,  7.781e-02,  5.562e-02, -1.024e-01, -1.401e-01, -4.273e-02,
        -7.095e-02,  7.798e-02, -1.535e-01, -2.042e-01, -6.639e-02, -3.049e-02,
         2.059e-01,  3.447e-01,  9.900e-02, -1.082e-01, -2.415e-01, -9.013e-02,
        -1.418e-01, -2.928e-01,  1.871e-01, -1.069e-02,  4.552e-02,  1.645e-02,
         1.109e-01,  5.060e-02, -3.488e-03, -3.460e-01,  1.306e-01, -2.091e-02,
        -2.437e-02, -1.766e-01,  3.772e-01, -4.496e-02, -1.157e-01,  1.752e-01,
        -4.440e-02, -4.476e-02, -2.217e-01, -2.616e-02, -7.433e-02, -3.322e-01,
        -9.871e-02,  2.591e-01, -9.301e-02, -7.547e-02, -8.985e-02,  3.588e-01,
        -3.045e-01,  3.413e-01,  1.349e-01, -5.310e-02,  4.528e-02,  1.215e-02,
        -4.653e-02, -2.792e-01,  2.942e-01,  1.766e-02, -1.421e-01,  1.452e-02],
       device='cuda:0')
s after update for 1 param tensor([1.723, 1.861, 1.668, 1.176, 0.729, 2.083, 1.854, 1.511, 1.889, 2.250,
        1.705, 1.810, 1.463, 2.203, 2.232, 1.664, 1.339, 1.770, 1.682, 1.794,
        1.786, 1.541, 1.567, 1.921, 1.762, 2.104, 1.972, 1.478, 1.925, 2.099,
        1.358, 2.148, 1.384, 0.761, 1.529, 2.262, 1.884, 1.412, 2.168, 1.947,
        1.127, 1.657, 1.863, 1.701, 1.285, 1.827, 1.303, 1.470, 1.288, 1.857,
        1.807, 1.843, 1.754, 1.807, 2.033, 1.530, 1.510, 2.082, 1.789, 1.696,
        1.944, 1.587, 1.830, 1.839, 1.186, 1.788, 1.869, 2.208, 1.766, 1.367,
        1.952, 1.614, 1.464, 1.810, 1.904, 1.570, 1.578, 1.817, 1.332, 1.337,
        2.124, 1.443, 2.007, 1.143, 1.347, 1.738, 1.589, 1.985, 1.816, 1.544,
        1.423, 1.884, 1.662, 1.337, 1.857, 1.382, 1.693, 1.401, 1.818, 1.632,
        0.879, 1.955, 1.948, 1.816, 1.973, 1.654, 1.345, 1.149, 1.624, 1.521,
        2.131, 2.135, 1.824, 1.497, 1.446, 1.416, 1.608, 1.658, 1.340, 1.879,
        1.776, 1.785, 1.740, 1.301, 1.507, 1.801, 1.259, 1.645, 1.892, 1.636,
        2.506, 1.840, 1.849, 1.519, 1.743, 1.378, 1.980, 1.494, 2.072, 1.565,
        1.479, 1.494, 1.949, 1.617, 2.088, 1.487, 1.777, 1.777, 1.506, 1.699,
        1.735, 1.647, 2.209, 1.371, 1.525, 1.853, 1.352, 1.702, 1.778, 2.190,
        1.200, 1.502, 2.263, 2.025, 1.410, 1.838, 1.470, 2.240, 1.562, 1.623,
        1.363, 1.441, 1.788, 2.264, 1.692, 1.814, 1.990, 1.837, 1.700, 1.302,
        1.901, 1.684, 1.056, 1.538, 2.097, 2.083, 2.365, 1.794, 1.720, 1.973,
        1.359, 1.652, 2.149, 1.432, 1.651, 1.628, 2.317, 1.424, 1.930, 1.788,
        1.681, 2.034, 1.898, 1.476, 1.540, 1.701, 0.820, 1.694, 1.602, 1.268,
        1.548, 1.592, 1.803, 1.347, 1.683, 1.565, 2.138, 1.644, 1.785, 1.357,
        2.177, 1.771, 1.977, 1.659, 1.740, 1.422, 1.595, 1.410, 1.400, 1.082,
        1.948, 1.290, 1.642, 1.785, 1.464, 2.118, 1.896, 1.941, 1.765, 1.765,
        2.150, 2.107, 1.664, 1.177, 1.735, 1.385, 1.931, 1.148, 1.216, 1.693,
        1.352, 1.252, 1.688, 2.056, 1.251, 1.526, 1.689, 1.931, 1.561, 1.558,
        1.392, 1.551, 2.248, 1.965, 1.805, 1.414, 1.714, 2.031, 2.078, 1.680,
        1.369, 1.565, 1.744, 1.439, 1.643, 1.433, 1.864, 1.459, 1.887, 1.819,
        1.693, 1.518, 2.026, 1.196, 1.429, 1.631, 1.398, 2.112, 1.639, 1.455,
        1.802, 1.491, 1.647, 1.735, 2.012, 1.683, 1.618, 1.802, 1.049, 2.073],
       device='cuda:0')
b after update for 1 param tensor([171.091, 177.797, 168.322, 141.330, 111.312, 188.144, 177.488, 160.247,
        179.166, 195.522, 170.222, 175.389, 157.660, 193.474, 194.729, 168.140,
        150.829, 173.404, 169.036, 174.596, 174.197, 161.793, 163.194, 180.649,
        173.039, 189.053, 183.050, 158.460, 180.868, 188.862, 151.894, 191.048,
        153.344, 113.743, 161.157, 196.046, 178.893, 154.895, 191.942, 181.899,
        138.386, 167.777, 177.922, 170.005, 147.743, 176.202, 148.780, 158.061,
        147.926, 177.617, 175.212, 176.978, 172.617, 175.225, 185.843, 161.256,
        160.150, 188.102, 174.361, 169.752, 181.720, 164.193, 176.354, 176.780,
        141.939, 174.315, 178.219, 193.689, 173.219, 152.384, 182.107, 165.622,
        157.737, 175.384, 179.877, 163.347, 163.744, 175.688, 150.462, 150.745,
        189.973, 156.594, 184.685, 139.354, 151.299, 171.854, 164.324, 183.626,
        175.672, 161.950, 155.517, 178.891, 168.059, 150.732, 177.651, 153.211,
        169.614, 154.259, 175.758, 166.498, 122.196, 182.252, 181.944, 175.670,
        183.075, 167.622, 151.166, 139.740, 166.124, 160.770, 190.303, 190.444,
        176.035, 159.483, 156.740, 155.089, 165.269, 167.836, 150.880, 178.688,
        173.696, 174.173, 171.943, 148.697, 160.015, 174.938, 146.285, 167.170,
        179.290, 166.746, 206.333, 176.795, 177.244, 160.630, 172.080, 153.040,
        183.412, 159.310, 187.612, 163.057, 158.529, 159.305, 181.983, 165.734,
        188.332, 158.959, 173.763, 173.774, 159.948, 169.923, 171.685, 167.294,
        193.730, 152.649, 160.945, 177.457, 151.535, 170.078, 173.817, 192.884,
        142.812, 159.758, 196.091, 185.488, 154.763, 176.718, 158.034, 195.078,
        162.932, 166.040, 152.186, 156.475, 174.307, 196.114, 169.544, 175.553,
        183.900, 176.649, 169.957, 148.719, 179.705, 169.147, 133.968, 161.673,
        188.750, 188.113, 200.442, 174.613, 170.969, 183.115, 151.949, 167.559,
        191.066, 155.959, 167.483, 166.318, 198.403, 155.519, 181.067, 174.274,
        169.009, 185.878, 179.572, 158.380, 161.737, 169.987, 118.027, 169.631,
        164.999, 146.804, 162.183, 164.462, 175.034, 151.264, 169.080, 163.074,
        190.592, 167.129, 174.148, 151.820, 192.333, 173.459, 183.270, 167.881,
        171.917, 155.458, 164.610, 154.770, 154.236, 135.607, 181.913, 148.051,
        167.045, 174.138, 157.717, 189.688, 179.486, 181.616, 173.163, 173.171,
        191.150, 189.204, 168.123, 141.430, 171.678, 153.396, 181.134, 139.689,
        143.715, 169.585, 151.543, 145.827, 169.336, 186.923, 145.819, 161.023,
        169.388, 181.141, 162.842, 162.686, 153.802, 162.340, 195.452, 182.706,
        175.118, 155.010, 170.636, 185.766, 187.892, 168.931, 152.509, 163.056,
        172.126, 156.373, 167.080, 156.043, 177.956, 157.467, 179.045, 175.795,
        169.615, 160.590, 185.545, 142.578, 155.832, 166.461, 154.107, 189.446,
        166.871, 157.206, 174.965, 159.172, 167.275, 171.682, 184.912, 169.102,
        165.804, 174.981, 133.522, 187.664], device='cuda:0')
clipping threshold 0.17593421341272578
a after update for 1 param tensor([[[ 0.100],
         [-0.138],
         [-0.153],
         [-0.108],
         [-0.208],
         [ 0.180],
         [-0.115],
         [-0.110],
         [-0.091],
         [ 0.067]],

        [[-0.073],
         [ 0.200],
         [-0.112],
         [-0.052],
         [ 0.025],
         [ 0.245],
         [ 0.129],
         [ 0.006],
         [-0.044],
         [-0.134]],

        [[-0.109],
         [-0.162],
         [ 0.100],
         [-0.135],
         [ 0.080],
         [ 0.036],
         [-0.132],
         [-0.027],
         [ 0.158],
         [-0.059]],

        [[ 0.095],
         [ 0.045],
         [ 0.095],
         [ 0.070],
         [ 0.155],
         [ 0.085],
         [ 0.108],
         [-0.012],
         [ 0.064],
         [-0.100]],

        [[ 0.046],
         [ 0.019],
         [-0.109],
         [ 0.024],
         [ 0.001],
         [-0.024],
         [-0.047],
         [-0.033],
         [ 0.006],
         [ 0.217]],

        [[ 0.035],
         [-0.089],
         [ 0.054],
         [-0.180],
         [-0.012],
         [-0.164],
         [-0.186],
         [ 0.155],
         [-0.013],
         [ 0.116]],

        [[-0.101],
         [ 0.042],
         [-0.189],
         [-0.056],
         [-0.063],
         [ 0.146],
         [ 0.109],
         [ 0.049],
         [-0.302],
         [-0.016]],

        [[ 0.288],
         [-0.063],
         [ 0.145],
         [-0.020],
         [-0.272],
         [ 0.156],
         [-0.356],
         [ 0.012],
         [-0.001],
         [ 0.045]],

        [[-0.068],
         [-0.065],
         [ 0.062],
         [-0.003],
         [ 0.069],
         [ 0.145],
         [-0.033],
         [ 0.282],
         [ 0.037],
         [-0.070]],

        [[-0.138],
         [-0.122],
         [ 0.374],
         [ 0.029],
         [ 0.036],
         [ 0.183],
         [-0.036],
         [ 0.056],
         [-0.016],
         [-0.107]],

        [[ 0.211],
         [ 0.011],
         [ 0.094],
         [ 0.182],
         [-0.164],
         [-0.130],
         [ 0.071],
         [-0.084],
         [-0.183],
         [-0.094]],

        [[ 0.162],
         [ 0.243],
         [ 0.050],
         [ 0.205],
         [ 0.059],
         [ 0.106],
         [ 0.130],
         [-0.129],
         [-0.032],
         [-0.024]],

        [[ 0.073],
         [ 0.053],
         [ 0.044],
         [ 0.140],
         [ 0.018],
         [-0.067],
         [-0.016],
         [ 0.280],
         [-0.089],
         [ 0.104]],

        [[-0.062],
         [ 0.083],
         [ 0.333],
         [ 0.289],
         [-0.258],
         [-0.183],
         [ 0.141],
         [-0.055],
         [-0.120],
         [-0.220]],

        [[ 0.177],
         [ 0.018],
         [ 0.003],
         [-0.019],
         [ 0.068],
         [ 0.250],
         [-0.100],
         [-0.034],
         [ 0.319],
         [ 0.116]],

        [[-0.017],
         [-0.334],
         [ 0.007],
         [ 0.255],
         [ 0.074],
         [-0.072],
         [-0.345],
         [ 0.268],
         [ 0.089],
         [ 0.075]],

        [[-0.316],
         [ 0.262],
         [-0.046],
         [ 0.150],
         [-0.013],
         [ 0.053],
         [ 0.193],
         [-0.091],
         [-0.006],
         [ 0.189]],

        [[-0.030],
         [-0.038],
         [-0.021],
         [-0.170],
         [ 0.223],
         [ 0.081],
         [-0.001],
         [-0.032],
         [ 0.063],
         [-0.009]],

        [[-0.111],
         [-0.010],
         [ 0.006],
         [ 0.006],
         [ 0.017],
         [-0.165],
         [ 0.196],
         [-0.118],
         [ 0.065],
         [ 0.141]],

        [[ 0.266],
         [-0.201],
         [-0.113],
         [-0.266],
         [-0.052],
         [-0.041],
         [ 0.069],
         [-0.042],
         [-0.005],
         [-0.093]],

        [[-0.254],
         [-0.364],
         [-0.094],
         [ 0.117],
         [ 0.286],
         [ 0.003],
         [-0.169],
         [ 0.123],
         [-0.154],
         [-0.060]],

        [[ 0.088],
         [ 0.128],
         [ 0.260],
         [-0.116],
         [-0.216],
         [-0.440],
         [ 0.048],
         [ 0.120],
         [ 0.040],
         [-0.047]],

        [[ 0.052],
         [ 0.179],
         [ 0.160],
         [ 0.040],
         [ 0.085],
         [ 0.032],
         [ 0.112],
         [ 0.036],
         [-0.194],
         [ 0.137]],

        [[ 0.138],
         [ 0.015],
         [ 0.025],
         [ 0.052],
         [ 0.024],
         [-0.084],
         [ 0.114],
         [-0.170],
         [ 0.015],
         [ 0.209]],

        [[-0.088],
         [ 0.019],
         [ 0.221],
         [-0.005],
         [-0.048],
         [-0.144],
         [ 0.149],
         [-0.105],
         [ 0.103],
         [ 0.061]],

        [[ 0.053],
         [-0.202],
         [-0.002],
         [ 0.101],
         [ 0.028],
         [ 0.125],
         [ 0.111],
         [-0.050],
         [ 0.388],
         [-0.006]],

        [[ 0.064],
         [ 0.218],
         [-0.141],
         [ 0.016],
         [-0.031],
         [-0.204],
         [ 0.186],
         [ 0.298],
         [-0.253],
         [-0.002]],

        [[ 0.130],
         [ 0.240],
         [ 0.052],
         [ 0.213],
         [-0.059],
         [-0.066],
         [ 0.076],
         [ 0.215],
         [ 0.063],
         [ 0.014]],

        [[-0.044],
         [ 0.169],
         [ 0.020],
         [-0.187],
         [ 0.022],
         [ 0.011],
         [-0.065],
         [ 0.038],
         [-0.073],
         [ 0.158]],

        [[ 0.227],
         [-0.150],
         [-0.114],
         [-0.063],
         [-0.118],
         [ 0.022],
         [-0.027],
         [ 0.337],
         [ 0.193],
         [-0.169]]], device='cuda:0')
s after update for 1 param tensor([[[1.457],
         [1.436],
         [2.172],
         [1.776],
         [1.399],
         [1.512],
         [2.305],
         [1.275],
         [1.475],
         [1.059]],

        [[2.356],
         [1.350],
         [1.513],
         [1.952],
         [1.341],
         [1.630],
         [2.167],
         [1.706],
         [1.563],
         [2.076]],

        [[1.276],
         [1.509],
         [2.026],
         [0.825],
         [1.681],
         [1.769],
         [1.418],
         [1.790],
         [1.281],
         [2.326]],

        [[1.567],
         [1.628],
         [2.306],
         [1.607],
         [1.776],
         [1.716],
         [1.030],
         [2.467],
         [2.010],
         [1.144]],

        [[1.787],
         [1.542],
         [1.704],
         [1.727],
         [1.758],
         [1.692],
         [1.782],
         [1.732],
         [1.957],
         [1.458]],

        [[1.824],
         [1.951],
         [1.366],
         [1.945],
         [1.532],
         [1.586],
         [1.730],
         [1.979],
         [1.880],
         [1.844]],

        [[1.648],
         [1.425],
         [1.402],
         [1.646],
         [1.359],
         [1.678],
         [1.736],
         [1.385],
         [1.325],
         [1.821]],

        [[1.585],
         [1.707],
         [1.899],
         [1.929],
         [2.219],
         [1.603],
         [2.116],
         [2.089],
         [1.899],
         [2.007]],

        [[1.699],
         [1.553],
         [2.021],
         [1.962],
         [1.873],
         [1.417],
         [1.468],
         [1.599],
         [1.557],
         [1.638]],

        [[1.275],
         [2.291],
         [1.527],
         [1.438],
         [1.648],
         [2.198],
         [2.221],
         [1.837],
         [1.656],
         [1.893]],

        [[1.587],
         [1.380],
         [1.519],
         [1.435],
         [1.464],
         [2.223],
         [1.844],
         [1.687],
         [1.688],
         [2.204]],

        [[1.957],
         [1.400],
         [2.028],
         [1.902],
         [2.307],
         [1.775],
         [1.640],
         [2.035],
         [1.618],
         [1.762]],

        [[1.133],
         [1.574],
         [2.127],
         [2.371],
         [1.421],
         [1.611],
         [1.868],
         [1.826],
         [1.766],
         [1.534]],

        [[1.101],
         [1.884],
         [1.713],
         [2.051],
         [1.735],
         [1.513],
         [1.855],
         [1.129],
         [1.656],
         [1.654]],

        [[2.005],
         [1.763],
         [1.794],
         [1.599],
         [1.331],
         [1.847],
         [1.763],
         [1.597],
         [1.748],
         [2.186]],

        [[1.819],
         [1.757],
         [1.478],
         [1.947],
         [1.587],
         [1.608],
         [1.851],
         [1.606],
         [1.920],
         [1.331]],

        [[1.470],
         [1.566],
         [1.832],
         [1.493],
         [1.477],
         [1.916],
         [2.092],
         [1.499],
         [1.844],
         [1.838]],

        [[1.566],
         [2.151],
         [1.814],
         [1.834],
         [1.505],
         [1.654],
         [1.559],
         [1.363],
         [2.120],
         [1.983]],

        [[1.064],
         [2.065],
         [1.536],
         [1.492],
         [1.611],
         [2.194],
         [1.282],
         [1.121],
         [1.959],
         [1.772]],

        [[1.804],
         [1.373],
         [1.280],
         [1.946],
         [1.505],
         [1.729],
         [2.017],
         [1.546],
         [1.892],
         [1.882]],

        [[2.081],
         [1.868],
         [1.620],
         [1.812],
         [2.257],
         [1.679],
         [1.908],
         [1.812],
         [1.456],
         [2.070]],

        [[2.087],
         [2.049],
         [1.980],
         [1.812],
         [2.145],
         [2.010],
         [2.526],
         [1.821],
         [0.790],
         [2.109]],

        [[1.987],
         [1.853],
         [1.870],
         [2.128],
         [1.503],
         [2.162],
         [1.918],
         [1.711],
         [1.588],
         [1.950]],

        [[1.722],
         [1.268],
         [1.935],
         [2.048],
         [1.660],
         [1.715],
         [1.813],
         [1.331],
         [1.745],
         [1.340]],

        [[1.363],
         [1.265],
         [1.999],
         [1.566],
         [1.613],
         [1.571],
         [1.409],
         [2.353],
         [1.645],
         [2.011]],

        [[2.026],
         [1.511],
         [1.077],
         [1.724],
         [1.189],
         [1.668],
         [1.199],
         [2.190],
         [1.871],
         [1.683]],

        [[1.677],
         [1.382],
         [1.834],
         [1.569],
         [2.008],
         [1.611],
         [2.423],
         [1.904],
         [1.728],
         [1.547]],

        [[1.421],
         [1.828],
         [1.162],
         [1.598],
         [2.202],
         [1.983],
         [1.784],
         [1.882],
         [1.482],
         [1.498]],

        [[1.109],
         [1.260],
         [1.584],
         [1.919],
         [2.066],
         [1.689],
         [1.649],
         [2.041],
         [2.146],
         [1.402]],

        [[1.949],
         [1.525],
         [2.215],
         [1.283],
         [1.823],
         [1.131],
         [1.892],
         [1.906],
         [1.303],
         [2.064]]], device='cuda:0')
b after update for 1 param tensor([[[157.324],
         [156.182],
         [192.115],
         [173.701],
         [154.192],
         [160.294],
         [197.877],
         [147.178],
         [158.301],
         [134.165]],

        [[200.078],
         [151.453],
         [160.332],
         [182.135],
         [150.965],
         [166.417],
         [191.887],
         [170.245],
         [162.959],
         [187.793]],

        [[147.225],
         [160.117],
         [185.551],
         [118.426],
         [169.009],
         [173.371],
         [155.226],
         [174.374],
         [147.533],
         [198.811]],

        [[163.155],
         [166.336],
         [197.926],
         [165.243],
         [173.693],
         [170.746],
         [132.307],
         [204.727],
         [184.817],
         [139.406]],

        [[174.252],
         [161.885],
         [170.145],
         [171.312],
         [172.851],
         [169.554],
         [174.028],
         [171.529],
         [182.332],
         [157.410]],

        [[176.031],
         [182.056],
         [152.333],
         [181.793],
         [161.337],
         [164.158],
         [171.424],
         [183.377],
         [178.704],
         [177.013]],

        [[167.310],
         [155.595],
         [154.365],
         [167.215],
         [151.938],
         [168.867],
         [171.763],
         [153.395],
         [150.022],
         [175.921]],

        [[164.097],
         [170.287],
         [179.639],
         [181.039],
         [194.172],
         [165.043],
         [189.630],
         [188.387],
         [179.608],
         [184.655]],

        [[169.894],
         [162.416],
         [185.323],
         [182.566],
         [178.375],
         [155.148],
         [157.930],
         [164.815],
         [162.634],
         [166.834]],

        [[147.185],
         [197.317],
         [161.084],
         [156.324],
         [167.318],
         [193.253],
         [194.274],
         [176.689],
         [167.740],
         [179.334]],

        [[164.197],
         [153.119],
         [160.633],
         [156.132],
         [157.719],
         [194.346],
         [177.029],
         [169.321],
         [169.343],
         [193.505]],

        [[182.366],
         [154.219],
         [185.616],
         [179.767],
         [197.989],
         [173.655],
         [166.909],
         [185.935],
         [165.814],
         [173.027]],

        [[138.728],
         [163.512],
         [190.118],
         [200.718],
         [155.376],
         [165.428],
         [178.176],
         [176.151],
         [173.207],
         [161.448]],

        [[136.760],
         [178.929],
         [170.582],
         [186.690],
         [171.709],
         [160.328],
         [177.525],
         [138.506],
         [167.762],
         [167.625]],

        [[184.564],
         [173.080],
         [174.565],
         [164.814],
         [150.389],
         [177.155],
         [173.082],
         [164.712],
         [172.331],
         [192.717]],

        [[175.781],
         [172.798],
         [158.444],
         [181.896],
         [164.209],
         [165.299],
         [177.327],
         [165.187],
         [180.611],
         [150.376]],

        [[158.048],
         [163.140],
         [176.445],
         [159.254],
         [158.409],
         [180.441],
         [188.555],
         [159.594],
         [177.016],
         [176.699]],

        [[163.093],
         [191.179],
         [175.546],
         [176.537],
         [159.898],
         [167.639],
         [162.752],
         [152.160],
         [189.791],
         [183.572]],

        [[134.481],
         [187.316],
         [161.556],
         [159.241],
         [165.442],
         [193.071],
         [147.606],
         [138.033],
         [182.433],
         [173.515]],

        [[175.090],
         [152.741],
         [147.478],
         [181.814],
         [159.897],
         [171.397],
         [185.104],
         [162.069],
         [179.286],
         [178.836]],

        [[188.030],
         [178.134],
         [165.886],
         [175.439],
         [195.835],
         [168.882],
         [180.056],
         [175.465],
         [157.265],
         [187.536]],

        [[188.293],
         [186.573],
         [183.406],
         [175.470],
         [190.890],
         [184.784],
         [207.180],
         [175.880],
         [115.824],
         [189.297]],

        [[183.728],
         [177.416],
         [178.267],
         [190.165],
         [159.820],
         [191.675],
         [180.514],
         [170.492],
         [164.249],
         [182.014]],

        [[171.072],
         [146.797],
         [181.299],
         [186.542],
         [167.952],
         [170.722],
         [175.505],
         [150.391],
         [172.169],
         [150.916]],

        [[152.153],
         [146.580],
         [184.299],
         [163.110],
         [165.527],
         [163.370],
         [154.709],
         [199.963],
         [167.167],
         [184.869]],

        [[185.525],
         [160.230],
         [135.302],
         [171.136],
         [142.162],
         [168.366],
         [142.746],
         [192.907],
         [178.291],
         [169.120]],

        [[168.819],
         [153.251],
         [176.527],
         [163.250],
         [184.708],
         [165.425],
         [202.890],
         [179.860],
         [171.346],
         [162.103]],

        [[155.408],
         [176.242],
         [140.510],
         [164.789],
         [193.419],
         [183.565],
         [174.118],
         [178.813],
         [158.660],
         [159.549]],

        [[137.267],
         [146.287],
         [164.045],
         [180.550],
         [187.363],
         [169.398],
         [167.372],
         [186.199],
         [190.966],
         [154.324]],

        [[181.984],
         [160.994],
         [193.998],
         [147.666],
         [175.973],
         [138.601],
         [179.283],
         [179.979],
         [148.785],
         [187.282]]], device='cuda:0')
clipping threshold 0.17593421341272578
a after update for 1 param tensor([[ 0.110],
        [-0.298],
        [ 0.088],
        [ 0.048],
        [ 0.003],
        [-0.038],
        [ 0.097],
        [ 0.094],
        [ 0.152],
        [-0.168],
        [ 0.013],
        [ 0.251],
        [ 0.165],
        [ 0.107],
        [-0.031],
        [ 0.000],
        [-0.042],
        [ 0.152],
        [ 0.056],
        [-0.112],
        [ 0.332],
        [ 0.213],
        [-0.050],
        [-0.176],
        [ 0.055],
        [ 0.109],
        [ 0.024],
        [-0.009],
        [ 0.098],
        [ 0.043]], device='cuda:0')
s after update for 1 param tensor([[1.816],
        [2.107],
        [1.818],
        [1.548],
        [1.630],
        [1.837],
        [1.998],
        [1.540],
        [1.920],
        [1.920],
        [2.125],
        [1.954],
        [2.258],
        [2.095],
        [1.854],
        [1.590],
        [1.816],
        [1.795],
        [1.975],
        [2.043],
        [1.556],
        [1.472],
        [1.842],
        [1.469],
        [1.575],
        [2.046],
        [1.785],
        [1.880],
        [1.430],
        [1.150]], device='cuda:0')
b after update for 1 param tensor([[175.670],
        [189.188],
        [175.729],
        [162.188],
        [166.407],
        [176.690],
        [184.241],
        [161.756],
        [180.600],
        [180.639],
        [190.024],
        [182.222],
        [195.876],
        [188.681],
        [177.465],
        [164.363],
        [175.646],
        [174.627],
        [183.187],
        [186.334],
        [162.577],
        [158.130],
        [176.913],
        [157.961],
        [163.605],
        [186.456],
        [174.158],
        [178.745],
        [155.887],
        [139.804]], device='cuda:0')
clipping threshold 0.17593421341272578
||w||^2 0.025409210810347516
exp ma of ||w||^2 0.0320906427478981
||w|| 0.15940266876795858
exp ma of ||w|| 0.17678647271596326
||w||^2 0.039334098699753656
exp ma of ||w||^2 0.034758215456779144
||w|| 0.1983282599625017
exp ma of ||w|| 0.18357810931716606
||w||^2 0.04892778103347795
exp ma of ||w||^2 0.03437695915929276
||w|| 0.2211962500438874
exp ma of ||w|| 0.18259196888294002
||w||^2 0.029820399008233432
exp ma of ||w||^2 0.033211781958871915
||w|| 0.17268583904951046
exp ma of ||w|| 0.17943750499928451
||w||^2 0.021716989812748923
exp ma of ||w||^2 0.030410959141857714
||w|| 0.1473668545255307
exp ma of ||w|| 0.17145434351658392
||w||^2 0.04042878082135261
exp ma of ||w||^2 0.03459908044221513
||w|| 0.2010690946449817
exp ma of ||w|| 0.18248937630341752
||w||^2 0.017493232870093727
exp ma of ||w||^2 0.03635254954312283
||w|| 0.13226198573321712
exp ma of ||w|| 0.18719544398770155
||w||^2 0.045508217208211514
exp ma of ||w||^2 0.036555009566602466
||w|| 0.21332655064058836
exp ma of ||w|| 0.1876097999481307
||w||^2 0.03379125128242734
exp ma of ||w||^2 0.033150720992009636
||w|| 0.18382396819356103
exp ma of ||w|| 0.1782559946310267
||w||^2 0.03887645837759979
exp ma of ||w||^2 0.03281790967841956
||w|| 0.19717113981919307
exp ma of ||w|| 0.17794390438272242
cuda
Objective function 30.79 = squared loss an data 28.04 + 0.5*rho*h**2 0.468334 + alpha*h 1.638264 + L2reg 0.36 + L1reg 0.29 ; SHD = 65 ; DAG True
Proportion of microbatches that were clipped  0.7534368429564936
iteration 1 in inner loop, alpha 16.92743239628347 rho 100.0 h 0.09678160081954701
9630
cuda
Objective function 35.01 = squared loss an data 28.04 + 0.5*rho*h**2 4.683339 + alpha*h 1.638264 + L2reg 0.36 + L1reg 0.29 ; SHD = 65 ; DAG True
||w||^2 6675155.650606536
exp ma of ||w||^2 942050448.718149
||w|| 2583.632259166644
exp ma of ||w|| 18118.14460412276
||w||^2 143.72497717418867
exp ma of ||w||^2 7656027.867940659
||w|| 11.988535238893393
exp ma of ||w|| 222.33655042645574
||w||^2 0.046244379867885266
exp ma of ||w||^2 0.033955008899234175
||w|| 0.21504506473733653
exp ma of ||w|| 0.18214801091614594
||w||^2 0.03751030937726288
exp ma of ||w||^2 0.0338237251788589
||w|| 0.19367578417877357
exp ma of ||w|| 0.18189785748252105
||w||^2 0.0335626571904685
exp ma of ||w||^2 0.03431952648228768
||w|| 0.18320113861673595
exp ma of ||w|| 0.18306402501827745
||w||^2 0.03129190348539031
exp ma of ||w||^2 0.036171643239523314
||w|| 0.17689517654642342
exp ma of ||w|| 0.1875521163860451
||w||^2 0.03718946153512014
exp ma of ||w||^2 0.03591511668547988
||w|| 0.19284569358717904
exp ma of ||w|| 0.18723784613776015
||w||^2 0.023646156498991693
exp ma of ||w||^2 0.03556255124947809
||w|| 0.1537730681848798
exp ma of ||w|| 0.18538774498076882
||w||^2 0.024435485753749014
exp ma of ||w||^2 0.0320655674865125
||w|| 0.1563185393795279
exp ma of ||w|| 0.17616022580068572
||w||^2 0.03266053412329409
exp ma of ||w||^2 0.032350349303497866
||w|| 0.18072225685646492
exp ma of ||w|| 0.17710331984138256
||w||^2 0.01860622410388472
exp ma of ||w||^2 0.03221109388146695
||w|| 0.13640463373318637
exp ma of ||w|| 0.17582461462885746
||w||^2 0.01978967341523295
exp ma of ||w||^2 0.03291354225074236
||w|| 0.14067577408791093
exp ma of ||w|| 0.1779085366542262
||w||^2 0.027683862633627168
exp ma of ||w||^2 0.03255591641731067
||w|| 0.1663846826893244
exp ma of ||w|| 0.17756099454278895
||w||^2 0.029296398671793705
exp ma of ||w||^2 0.03298269494832822
||w|| 0.17116190777095733
exp ma of ||w|| 0.17839573067146977
cuda
Objective function 30.60 = squared loss an data 28.23 + 0.5*rho*h**2 0.974434 + alpha*h 0.747278 + L2reg 0.38 + L1reg 0.27 ; SHD = 66 ; DAG True
Proportion of microbatches that were clipped  0.7575467941059338
iteration 2 in inner loop, alpha 16.92743239628347 rho 1000.0 h 0.04414598979590423
9630
cuda
Objective function 39.37 = squared loss an data 28.23 + 0.5*rho*h**2 9.744342 + alpha*h 0.747278 + L2reg 0.38 + L1reg 0.27 ; SHD = 66 ; DAG True
||w||^2 3041514159.567243
exp ma of ||w||^2 31437548542.730175
||w|| 55149.92438405735
exp ma of ||w|| 134882.27607853606
||w||^2 172829.14200889564
exp ma of ||w||^2 1025933774.5049294
||w|| 415.72724472771284
exp ma of ||w|| 6921.555140324835
||w||^2 0.12127974525299698
exp ma of ||w||^2 3.8326198740707134
||w|| 0.3482524160045368
exp ma of ||w|| 0.3932237552352312
||w||^2 0.11643075668350855
exp ma of ||w||^2 1.3200341562606033
||w|| 0.3412195139254327
exp ma of ||w|| 0.3547062896035217
||w||^2 0.07786867353762567
exp ma of ||w||^2 0.6955799871519224
||w|| 0.2790495897463848
exp ma of ||w|| 0.33149252714284283
||w||^2 0.02440141521493786
exp ma of ||w||^2 0.03774513107230255
||w|| 0.15620952344507635
exp ma of ||w|| 0.19117923624400918
||w||^2 0.025867243226383126
exp ma of ||w||^2 0.03617989898992434
||w|| 0.16083296685189616
exp ma of ||w|| 0.18702610421334556
||w||^2 0.05843728707697001
exp ma of ||w||^2 0.038670255601093995
||w|| 0.24173805467275938
exp ma of ||w|| 0.193595864916503
||w||^2 0.024895778387438394
exp ma of ||w||^2 0.03672409218124279
||w|| 0.15778396112228388
exp ma of ||w|| 0.1882957787291744
||w||^2 0.034794600383739584
exp ma of ||w||^2 0.03883030116291388
||w|| 0.18653310800964953
exp ma of ||w|| 0.19349976454774437
||w||^2 0.0666621497626205
exp ma of ||w||^2 0.03864747016712059
||w|| 0.2581901426519233
exp ma of ||w|| 0.19332680571196842
||w||^2 0.02734271710636747
exp ma of ||w||^2 0.03809682488787817
||w|| 0.16535633373526237
exp ma of ||w|| 0.19200017757879032
v before min max tensor([[  8.668,  -4.894,   9.060,  ...,  -8.811,  -3.432,  -1.948],
        [ 12.552,   8.320,  -3.244,  ...,  -7.333, -15.195,  -7.435],
        [ -9.931,   6.863,  -6.296,  ..., 138.659, -14.106, -10.852],
        ...,
        [ 18.759, -13.912, -12.750,  ..., -13.021,  -9.997, -13.229],
        [-13.804,  27.850, -13.251,  ...,  19.318, -14.640,  13.580],
        [  7.005,  11.610, -13.855,  ...,  -7.047,   9.726,  17.524]],
       device='cuda:0')
v tensor([[8.668e+00, 1.000e-12, 9.060e+00,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e+01, 8.320e+00, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 6.863e+00, 1.000e-12,  ..., 1.000e+01, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e+01, 1.000e-12,
         1.000e+01],
        [7.005e+00, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 9.726e+00,
         1.000e+01]], device='cuda:0')
v before min max tensor([ -0.258,   1.666, -15.634, -15.077,  -1.213,   0.280,   5.007, -11.775,
        -13.105,  17.866,  12.275,   6.875,  -4.637,  -6.397, -13.928,  25.912,
        -10.000,  -7.820,   6.433,  30.706,   3.535,  -9.317,  -1.193, -12.496,
         11.831,   4.862, -14.585,  -2.201,   5.436, -11.659,   9.148,  -3.945,
         -4.169, -10.236,  12.468,  -3.633,  -6.725,  -9.267,  -8.289,  14.206,
         -5.856,   4.308,  -7.045,  -6.429,  12.738,   8.304,  58.380,  -9.972,
         80.234,  -3.471,  -5.016,   8.835,  -9.911, -14.531,   6.646,  -8.729,
          6.065, -13.910, -14.138, -12.142,  -8.479, -13.102,  -6.143,  -1.846,
         -9.787, -11.304,   5.219,  -5.151,  17.408,  -6.563,  24.548, -13.066,
         -8.489, -10.018,  -8.410,  -6.089,  12.449, -11.233, -13.692, -10.937,
        -10.637, -12.042, -12.511,  14.274, -10.045, -10.655,  -5.232,   4.495,
        -10.590,  -3.791,  -3.751,   3.185,  -2.023,  -6.686,   1.084, -11.592,
         -8.917, -12.440,  -6.442,  -5.614,  -0.707,  45.393,  -6.900,   2.202,
         -7.036, -12.362, -15.795,  -5.516, -15.165,   3.947,  -9.671,  -5.099,
         -4.373,  11.397,  -4.486,  18.450,  13.869,   7.977, -11.225,  -9.602,
         -5.524,  14.746, -12.558, -13.218,  -9.625,  -2.370,  -7.136,  -8.530,
         35.462,  -7.101,   8.429,  17.203, -12.440,  -5.798,   5.408,  -8.988,
        -12.745,  -5.400,  -4.692, -10.870,  -8.838,  -5.274,  -8.364,   5.786,
         -5.185,  -8.829,  -7.269, -15.809,  -4.512, -12.826, -11.289,  -4.770,
         51.189, -11.697, -10.500,   0.949,  11.976, -15.826,   4.054, -11.005,
         -1.428,  -9.986,  -3.616,  -7.540,  -6.584,  -9.761,  -4.757, -12.188,
        -12.133,  -8.598,  67.062, -13.395,  18.021,  -8.873,  -6.607,  -8.010,
         -6.373,  -9.275,   1.758,  -9.662, -12.196,   1.755, -12.921, -10.654,
         -9.785,  -7.536,  -5.896,  -7.400,  -9.483, -12.154,  24.083,  -6.730,
         35.657, -12.979,   2.119,   1.028, -12.317,  16.210,  -3.478,  -9.379,
        -10.297,   0.156, -15.427,  -0.267,   2.980,  -6.781,  -7.687,  35.516,
         10.003, -10.758,  -9.565,  -7.991,  -8.272,   0.830,   1.747,  -6.116,
        -12.978,  -2.242,  -8.569,   8.204,  25.011,  -9.573, -12.860,  -3.677,
         38.475,  10.665,  -9.606,  -6.951, -11.588,  -8.637, -11.185, -11.618,
         -5.688,  19.164,   4.420,  -8.259,  23.397, -11.306, -13.647,  40.653,
         32.447,  18.921, -10.014, -14.191,  -3.145,  -0.629, -17.357,  -5.333,
        -13.111, -12.683,   6.007, -12.005,   0.172,  -9.799, -12.874, -12.881,
        -11.562,   9.957, -11.273,  -8.148,   0.998,  -4.849,  11.721,  -9.031,
         -8.170, -10.104,  -2.838,  -4.776,   6.621,  -7.978, -10.613,  -5.632,
         -6.008,  15.087,  -9.187,  14.240, -11.458,  -7.863,  -4.748, -12.719,
          2.293,  -8.137, -13.814, -11.549,   0.966,   3.500,   1.194,  -6.155,
         -9.647,  14.775, -12.617, -10.797,  -0.954,  28.040, -12.035,  -6.496,
         -7.941,  -0.656,   9.826,  -3.827], device='cuda:0')
v tensor([1.000e-12, 1.666e+00, 1.000e-12, 1.000e-12, 1.000e-12, 2.795e-01,
        5.007e+00, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 6.875e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        6.433e+00, 1.000e+01, 3.535e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 4.862e+00, 1.000e-12, 1.000e-12, 5.436e+00, 1.000e-12,
        9.148e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 4.308e+00,
        1.000e-12, 1.000e-12, 1.000e+01, 8.304e+00, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 8.835e+00, 1.000e-12, 1.000e-12,
        6.646e+00, 1.000e-12, 6.065e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        5.219e+00, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 4.495e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 3.185e+00, 1.000e-12, 1.000e-12, 1.084e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 2.202e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 3.947e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e+01, 7.977e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 8.429e+00, 1.000e+01,
        1.000e-12, 1.000e-12, 5.408e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.786e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 9.492e-01,
        1.000e+01, 1.000e-12, 4.054e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.758e+00, 1.000e-12,
        1.000e-12, 1.755e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 2.119e+00, 1.028e+00, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.564e-01, 1.000e-12, 1.000e-12,
        2.980e+00, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 8.303e-01, 1.747e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 8.204e+00, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        4.420e+00, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 6.007e+00, 1.000e-12,
        1.720e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 9.957e+00,
        1.000e-12, 1.000e-12, 9.984e-01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 6.621e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.293e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 9.660e-01, 3.500e+00, 1.194e+00, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 9.826e+00, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-1.018e+01],
         [-8.096e+00],
         [-9.602e+00],
         [-5.941e+00],
         [ 7.810e+00],
         [ 2.376e+01],
         [-1.062e+01],
         [-8.150e+00],
         [-1.169e+01],
         [ 1.294e+01]],

        [[-1.161e+01],
         [-6.355e+00],
         [ 1.456e+01],
         [-1.010e+01],
         [-3.908e+00],
         [ 1.211e+01],
         [ 4.732e+01],
         [-1.352e+01],
         [-1.605e+01],
         [-9.637e+00]],

        [[ 3.012e+00],
         [-6.221e+00],
         [-1.176e+01],
         [-1.107e+01],
         [-1.222e+01],
         [ 4.335e+01],
         [-8.454e+00],
         [ 9.484e-01],
         [-5.951e+00],
         [ 2.292e+01]],

        [[ 1.826e+00],
         [-9.347e+00],
         [-9.453e+00],
         [-8.715e+00],
         [ 6.163e+00],
         [-6.922e+00],
         [ 1.818e+01],
         [ 7.846e+00],
         [-1.063e+01],
         [-7.638e+00]],

        [[-9.062e+00],
         [-8.870e+00],
         [ 7.726e+00],
         [-1.203e+01],
         [-5.641e+00],
         [-9.024e+00],
         [-1.330e+01],
         [-9.606e-02],
         [-1.241e+01],
         [-4.437e+00]],

        [[ 1.335e+02],
         [-5.624e+00],
         [ 4.890e+01],
         [-1.007e+01],
         [-1.481e+01],
         [ 3.709e+01],
         [-1.239e+01],
         [-4.044e+00],
         [ 2.833e+01],
         [-7.100e+00]],

        [[ 1.073e+01],
         [-1.303e+01],
         [-4.941e+00],
         [ 1.054e+02],
         [ 2.722e+01],
         [-9.586e+00],
         [-8.150e+00],
         [-2.410e+00],
         [-3.735e-01],
         [-9.017e+00]],

        [[-5.658e+00],
         [-3.604e+00],
         [-8.958e+00],
         [-9.127e+00],
         [-8.329e+00],
         [ 7.719e-01],
         [-1.205e+01],
         [-7.756e-01],
         [-1.164e+01],
         [ 3.303e+00]],

        [[ 2.917e+01],
         [ 6.266e+00],
         [-1.015e+01],
         [-1.379e+01],
         [ 4.582e-01],
         [-1.688e+01],
         [-1.366e+01],
         [-9.051e+00],
         [-9.077e+00],
         [ 2.972e+01]],

        [[ 6.161e+00],
         [ 5.393e+00],
         [-1.239e+01],
         [-8.007e-01],
         [-1.008e+01],
         [-7.264e+00],
         [-1.115e+01],
         [-9.870e+00],
         [-8.447e+00],
         [ 1.139e+02]],

        [[-1.533e+01],
         [-9.562e+00],
         [-1.377e+01],
         [-3.760e+00],
         [-1.161e+01],
         [-1.306e+01],
         [-8.330e-01],
         [-1.011e+01],
         [ 4.839e+00],
         [ 1.912e+01]],

        [[ 3.652e+01],
         [-1.144e+01],
         [-9.208e+00],
         [-8.169e+00],
         [-7.798e+00],
         [-1.343e+01],
         [ 2.424e+01],
         [-1.197e+01],
         [ 3.469e+01],
         [ 4.502e+00]],

        [[-6.698e+00],
         [-6.160e+00],
         [ 4.957e-01],
         [-4.291e+00],
         [-4.227e+00],
         [-2.914e-01],
         [-5.466e+00],
         [ 2.289e+01],
         [-1.259e+01],
         [ 1.788e+01]],

        [[-7.902e+00],
         [-3.749e+00],
         [-9.564e+00],
         [-1.321e+01],
         [-9.827e+00],
         [ 4.958e+00],
         [ 2.069e+01],
         [-8.357e+00],
         [-2.287e+00],
         [-8.823e+00]],

        [[-2.234e+00],
         [-1.119e+01],
         [ 1.075e+01],
         [ 2.484e+00],
         [ 1.631e+00],
         [-1.612e+01],
         [-8.768e+00],
         [ 3.733e+00],
         [-1.352e+01],
         [ 3.515e+01]],

        [[-1.161e+01],
         [ 1.877e+01],
         [-6.091e+00],
         [-1.218e+01],
         [ 8.068e-01],
         [-1.038e+01],
         [-7.756e+00],
         [-7.449e+00],
         [ 4.128e+01],
         [-3.514e+00]],

        [[-9.031e+00],
         [-9.535e+00],
         [-8.106e+00],
         [-9.429e+00],
         [-1.488e+01],
         [-1.166e+01],
         [ 4.673e+00],
         [-1.393e+01],
         [ 1.852e+01],
         [ 5.786e+01]],

        [[-1.060e+01],
         [-3.743e+00],
         [ 9.584e+00],
         [-3.835e+00],
         [-7.647e+00],
         [-1.518e+01],
         [-1.508e+01],
         [-7.789e+00],
         [ 1.426e+01],
         [ 1.117e+01]],

        [[-7.855e+00],
         [-9.005e+00],
         [-1.194e+01],
         [ 7.229e+00],
         [ 6.908e-01],
         [ 4.703e+00],
         [-9.420e+00],
         [-6.520e-02],
         [-1.181e+01],
         [-1.196e+01]],

        [[-9.096e+00],
         [ 1.078e+01],
         [-1.054e+01],
         [-1.675e+01],
         [-6.110e+00],
         [-7.640e+00],
         [-6.118e+00],
         [-4.619e+00],
         [-8.234e+00],
         [-3.866e+00]],

        [[ 6.588e+00],
         [-7.035e+00],
         [ 9.635e+00],
         [ 4.039e+01],
         [ 5.694e+00],
         [-1.275e+01],
         [ 3.621e+01],
         [-9.160e+00],
         [-3.943e+00],
         [ 1.973e+01]],

        [[-8.415e+00],
         [ 2.428e+01],
         [-1.361e+01],
         [-1.178e+01],
         [-1.355e+01],
         [ 5.368e+00],
         [-5.142e-01],
         [-3.283e+00],
         [ 3.405e+01],
         [-1.192e+01]],

        [[ 5.917e+00],
         [-6.081e+00],
         [-1.081e+01],
         [-6.327e+00],
         [-9.562e+00],
         [-1.177e+01],
         [-1.336e+01],
         [-5.372e+00],
         [ 1.292e+01],
         [ 9.837e-01]],

        [[-1.077e+01],
         [-3.377e+00],
         [-9.456e+00],
         [ 2.517e+01],
         [ 2.084e+01],
         [-1.146e+01],
         [-6.465e+00],
         [-1.392e+01],
         [-5.788e+00],
         [ 9.159e+00]],

        [[-6.434e+00],
         [-1.504e+01],
         [-5.637e+00],
         [ 3.732e+01],
         [ 7.750e+00],
         [-5.422e+00],
         [-1.486e+01],
         [-1.006e+01],
         [ 1.461e+01],
         [-1.812e+00]],

        [[-1.171e+01],
         [-1.248e+01],
         [-1.580e+00],
         [-1.086e+00],
         [-1.018e+01],
         [-1.117e+01],
         [-8.016e+00],
         [ 9.465e+01],
         [-3.811e+00],
         [ 3.166e+01]],

        [[-1.309e+01],
         [-1.030e+01],
         [ 1.841e+01],
         [ 1.780e+00],
         [-1.366e+01],
         [-1.057e+01],
         [-1.025e+01],
         [-3.945e+00],
         [-1.700e+01],
         [ 1.539e+00]],

        [[ 2.899e+00],
         [-6.409e+00],
         [-6.150e+00],
         [-5.855e+00],
         [ 3.446e+01],
         [ 4.958e+01],
         [-3.665e+00],
         [-6.999e-01],
         [-2.678e+00],
         [-3.549e+00]],

        [[-1.394e+01],
         [-8.234e+00],
         [ 1.272e+01],
         [ 5.415e+00],
         [ 6.311e+01],
         [-1.554e+01],
         [ 2.095e+01],
         [ 1.015e+01],
         [-1.151e+01],
         [-4.687e+00]],

        [[ 4.308e+01],
         [ 2.908e+01],
         [-6.836e+00],
         [-1.087e+01],
         [-4.430e+00],
         [ 1.089e+00],
         [ 4.002e+01],
         [-9.411e+00],
         [-7.921e+00],
         [-6.083e+00]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.810e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[3.012e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [9.484e-01],
         [1.000e-12],
         [1.000e+01]],

        [[1.826e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.163e+00],
         [1.000e-12],
         [1.000e+01],
         [7.846e+00],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [7.726e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.719e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.303e+00]],

        [[1.000e+01],
         [6.266e+00],
         [1.000e-12],
         [1.000e-12],
         [4.582e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[6.161e+00],
         [5.393e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.839e+00],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [4.502e+00]],

        [[1.000e-12],
         [1.000e-12],
         [4.957e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.958e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [2.484e+00],
         [1.631e+00],
         [1.000e-12],
         [1.000e-12],
         [3.733e+00],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [8.068e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.673e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [9.584e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.229e+00],
         [6.908e-01],
         [4.703e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[6.588e+00],
         [1.000e-12],
         [9.635e+00],
         [1.000e+01],
         [5.694e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.368e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[5.917e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [9.837e-01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [9.159e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [7.750e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.780e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.539e+00]],

        [[2.899e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [5.415e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.089e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[  2.455],
        [  9.451],
        [ -6.910],
        [  6.205],
        [110.644],
        [-12.220],
        [-11.081],
        [-10.560],
        [-12.133],
        [  8.908],
        [ -3.758],
        [  6.539],
        [-12.873],
        [-10.172],
        [-12.494],
        [ -6.266],
        [-10.289],
        [ -5.648],
        [-12.372],
        [ -4.510],
        [ -8.556],
        [ -8.315],
        [-12.648],
        [-12.676],
        [ -2.864],
        [ -9.237],
        [-12.715],
        [ -3.248],
        [ -3.749],
        [ -8.875]], device='cuda:0')
v tensor([[2.455e+00],
        [9.451e+00],
        [1.000e-12],
        [6.205e+00],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [8.908e+00],
        [1.000e-12],
        [6.539e+00],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 0.009, -0.008, -0.011,  ..., -0.091,  0.007, -0.040],
        [-0.010,  0.037,  0.048,  ..., -0.027, -0.005,  0.052],
        [-0.012, -0.069,  0.033,  ..., -0.065, -0.027,  0.029],
        ...,
        [ 0.030, -0.021, -0.025,  ...,  0.124,  0.007, -0.012],
        [-0.001,  0.030,  0.017,  ...,  0.038,  0.027, -0.003],
        [-0.005,  0.008, -0.005,  ...,  0.094,  0.028, -0.010]],
       device='cuda:0')
s after update for 1 param tensor([[1.637, 0.665, 1.754,  ..., 1.794, 0.849, 1.431],
        [2.110, 1.493, 1.118,  ..., 1.522, 1.888, 0.910],
        [1.294, 1.262, 1.304,  ..., 2.234, 1.714, 1.415],
        ...,
        [1.611, 1.696, 1.594,  ..., 1.872, 1.333, 1.608],
        [1.714, 1.397, 1.617,  ..., 1.582, 1.780, 1.430],
        [1.791, 1.583, 1.779,  ..., 1.733, 1.663, 2.387]], device='cuda:0')
b after update for 1 param tensor([[156.219,  99.602, 161.714,  ..., 163.560, 112.500, 146.034],
        [177.355, 149.210, 129.093,  ..., 150.631, 167.757, 116.499],
        [138.914, 137.164, 139.441,  ..., 182.484, 159.850, 145.218],
        ...,
        [154.983, 159.003, 154.131,  ..., 167.042, 140.986, 154.804],
        [159.855, 144.291, 155.251,  ..., 153.558, 162.918, 146.026],
        [163.419, 153.604, 162.868,  ..., 160.717, 157.470, 188.637]],
       device='cuda:0')
clipping threshold 0.15825323586081833
a after update for 1 param tensor([-2.136e-02,  6.446e-02,  9.592e-03,  5.310e-02, -1.152e-02, -1.857e-02,
        -2.765e-02,  3.661e-02,  2.768e-02, -3.010e-02, -1.365e-03,  1.749e-02,
        -5.272e-02,  7.869e-02,  1.783e-02,  1.093e-02, -1.711e-02, -4.646e-02,
         8.005e-02, -2.760e-03,  2.659e-02,  2.449e-02,  1.472e-01,  7.249e-02,
         8.715e-02, -4.452e-02, -4.657e-02, -2.371e-02, -3.154e-02,  3.979e-02,
        -7.233e-02,  5.548e-02, -5.243e-02,  9.680e-03,  5.782e-02, -1.976e-02,
         5.912e-03, -5.173e-02, -4.897e-02,  9.962e-03, -2.626e-02, -1.108e-01,
        -6.132e-02, -9.103e-02, -3.082e-03,  4.824e-02,  4.849e-02, -4.488e-02,
        -3.032e-02,  3.602e-02,  2.258e-03,  1.339e-01, -3.054e-02, -2.849e-02,
        -6.651e-02,  4.464e-02, -9.340e-02,  5.207e-03, -3.589e-04, -2.468e-02,
        -2.693e-02,  3.234e-03,  5.686e-02, -7.161e-02, -1.369e-01,  1.052e-01,
         3.225e-02, -1.383e-02,  1.256e-01, -5.112e-03,  1.191e-02, -4.984e-02,
         2.858e-02, -2.752e-02, -2.456e-03, -3.232e-02,  2.385e-02,  3.804e-02,
        -9.304e-02, -2.722e-02, -2.489e-02,  9.795e-03, -1.702e-02,  4.440e-02,
        -3.876e-02, -5.912e-02,  3.118e-02,  1.784e-03, -7.868e-02, -9.696e-02,
         8.090e-03,  7.353e-02, -1.188e-02, -4.173e-02, -1.788e-02, -1.472e-02,
         2.062e-02, -3.702e-02, -5.778e-02,  5.567e-02, -6.687e-03,  1.623e-01,
        -9.739e-03, -5.898e-02,  6.749e-03,  5.124e-02, -4.564e-02,  1.185e-02,
         2.578e-03, -6.115e-02,  1.449e-02,  3.654e-02, -1.616e-01, -7.744e-02,
        -4.027e-02,  4.310e-02,  6.439e-02, -2.033e-02,  2.965e-02, -7.695e-02,
        -3.572e-02, -6.328e-02, -2.245e-02, -7.689e-02,  3.678e-02,  7.707e-02,
        -2.569e-02,  5.666e-02, -3.700e-02, -1.616e-02,  2.903e-02, -1.305e-02,
        -8.222e-02,  3.168e-02,  4.275e-02, -5.300e-02,  1.096e-02,  5.827e-02,
         2.066e-02, -3.008e-02,  6.990e-04, -1.708e-02, -3.398e-02,  6.705e-03,
        -1.076e-02, -3.868e-02,  1.344e-02, -4.830e-02, -6.205e-02,  4.140e-02,
         2.456e-02, -2.316e-02,  5.523e-02, -3.825e-06,  2.893e-02,  1.742e-02,
         2.429e-02, -1.986e-02, -6.623e-02, -9.193e-02,  1.546e-02, -1.419e-02,
         3.480e-02,  4.717e-02, -3.959e-03, -7.597e-03, -1.504e-02,  8.863e-03,
        -5.497e-02,  3.641e-02, -5.468e-03, -6.906e-04, -9.873e-03, -5.321e-02,
        -8.881e-03,  1.859e-02,  1.872e-02,  1.179e-02,  2.886e-02,  3.958e-02,
         5.629e-03, -9.900e-03,  1.720e-03, -1.424e-03, -1.231e-02, -2.873e-02,
        -9.026e-03,  1.042e-01, -3.934e-02,  5.784e-02,  2.938e-02,  4.236e-02,
         5.179e-02, -5.765e-02,  1.223e-02,  8.610e-02,  3.457e-02,  1.005e-02,
         7.470e-02,  1.734e-02,  3.042e-02, -3.555e-02,  7.868e-02, -1.631e-02,
         8.954e-02,  9.735e-02,  8.746e-02,  1.776e-02, -7.438e-02, -3.057e-03,
         2.403e-02, -2.070e-03,  4.829e-02, -4.040e-02,  8.623e-02, -1.989e-03,
        -8.267e-02, -4.816e-02,  4.879e-02, -9.354e-02, -5.760e-02, -3.359e-02,
         5.864e-03, -3.074e-02, -2.632e-02, -7.047e-03, -5.864e-03,  3.222e-03,
         4.671e-03,  5.026e-02,  1.276e-02, -7.725e-02, -1.176e-01,  3.876e-02,
        -2.579e-02, -6.068e-02,  1.359e-02, -1.678e-02,  2.873e-03,  3.207e-02,
         2.081e-02, -7.992e-03, -3.714e-02,  6.437e-02, -4.519e-02,  1.051e-02,
        -4.557e-02,  3.220e-02, -7.664e-02,  2.007e-02, -2.851e-02,  2.192e-02,
         1.359e-01, -2.391e-02, -2.907e-02,  1.572e-02, -4.832e-03,  2.929e-02,
         7.620e-02, -2.326e-02, -6.086e-03, -6.841e-02, -3.786e-03, -3.198e-02,
        -6.726e-02, -4.390e-02, -4.885e-02,  7.467e-02, -1.311e-02, -2.331e-02,
         2.970e-02, -2.536e-02, -1.218e-01, -2.356e-02,  1.961e-02,  2.846e-02,
        -1.985e-02,  7.110e-02, -1.025e-02, -9.038e-02, -5.025e-03,  1.112e-03,
        -3.552e-02, -3.746e-02,  6.649e-02,  1.013e-02,  4.560e-02,  8.346e-02,
        -4.594e-03, -5.026e-02,  4.216e-02, -6.559e-02, -1.082e-01,  1.510e-02,
         2.937e-02,  7.765e-02, -6.861e-02,  1.070e-02,  9.632e-02,  5.673e-02],
       device='cuda:0')
s after update for 1 param tensor([1.209, 1.416, 1.900, 1.832, 1.157, 1.441, 1.894, 1.441, 1.633, 2.109,
        2.197, 1.368, 1.212, 0.861, 1.833, 1.549, 1.228, 1.907, 1.693, 1.711,
        1.913, 1.199, 1.303, 1.558, 1.637, 1.654, 1.994, 1.521, 1.572, 1.651,
        1.453, 1.046, 0.623, 1.277, 1.841, 2.029, 0.907, 1.480, 1.045, 1.948,
        1.584, 1.223, 1.710, 0.895, 2.212, 1.443, 1.627, 2.011, 1.995, 1.376,
        1.895, 1.581, 1.677, 1.983, 1.751, 1.794, 1.760, 1.725, 1.830, 1.494,
        1.333, 1.723, 1.049, 1.612, 1.270, 1.516, 1.623, 0.635, 1.580, 1.568,
        1.617, 1.592, 1.184, 1.669, 1.393, 0.806, 1.842, 1.402, 1.664, 1.892,
        1.319, 1.637, 1.599, 1.921, 1.459, 1.510, 1.591, 1.589, 1.318, 1.337,
        1.573, 1.721, 1.008, 1.098, 1.158, 1.409, 1.206, 1.674, 1.548, 1.293,
        1.667, 1.894, 0.870, 1.206, 0.954, 1.798, 1.919, 1.739, 1.850, 2.145,
        1.706, 1.300, 1.002, 2.148, 1.171, 1.949, 2.134, 1.439, 1.582, 1.486,
        0.903, 1.782, 1.557, 1.619, 1.176, 0.985, 1.400, 1.519, 1.925, 1.236,
        1.685, 2.165, 1.512, 1.513, 1.407, 1.236, 1.628, 1.150, 0.571, 1.323,
        2.029, 1.286, 1.440, 1.516, 2.019, 2.016, 1.157, 1.951, 1.166, 1.585,
        1.816, 1.164, 1.919, 1.567, 1.298, 1.253, 1.978, 2.053, 1.377, 1.343,
        1.143, 1.350, 0.948, 1.178, 0.800, 1.660, 1.420, 1.559, 1.595, 1.256,
        1.857, 1.757, 1.597, 1.083, 0.936, 1.439, 1.217, 1.216, 0.996, 1.335,
        1.508, 1.374, 2.036, 1.296, 1.516, 0.950, 1.191, 1.103, 1.525, 1.625,
        1.620, 1.459, 2.274, 1.806, 1.264, 1.760, 1.505, 1.476, 1.421, 1.580,
        1.680, 1.534, 1.964, 1.347, 1.519, 1.487, 1.540, 1.490, 1.608, 1.308,
        1.312, 2.008, 1.683, 1.558, 0.702, 1.282, 1.599, 0.620, 1.167, 1.952,
        2.015, 2.000, 2.040, 1.038, 1.880, 1.816, 1.304, 1.552, 1.449, 1.348,
        1.564, 1.564, 1.113, 1.372, 1.803, 1.110, 1.804, 1.515, 1.919, 1.971,
        1.838, 1.974, 1.227, 1.737, 1.693, 1.229, 2.133, 1.251, 1.596, 1.579,
        1.470, 1.566, 1.399, 1.410, 1.596, 1.722, 1.559, 1.618, 1.370, 1.200,
        1.100, 0.596, 1.796, 1.661, 1.108, 1.305, 1.360, 0.884, 2.004, 1.084,
        1.417, 1.550, 1.120, 1.694, 1.227, 1.744, 1.548, 1.030, 1.246, 1.746,
        0.939, 1.052, 1.831, 1.417, 2.192, 0.860, 1.206, 1.235, 1.484, 1.744,
        1.543, 1.319, 1.380, 1.912, 1.462, 1.154, 1.616, 1.161, 1.441, 1.223],
       device='cuda:0')
b after update for 1 param tensor([134.233, 145.306, 168.306, 165.270, 131.329, 146.593, 168.041, 146.576,
        156.021, 177.298, 180.968, 142.797, 134.436, 113.306, 165.312, 151.947,
        135.296, 168.603, 158.857, 159.703, 168.853, 133.683, 139.392, 152.378,
        156.202, 157.029, 172.419, 150.579, 153.099, 156.881, 147.197, 124.862,
         96.347, 137.965, 165.680, 173.932, 116.286, 148.525, 124.809, 170.403,
        153.653, 135.015, 159.678, 115.535, 181.606, 146.662, 155.753, 173.147,
        172.464, 143.229, 168.096, 153.514, 158.102, 171.927, 161.588, 163.551,
        161.988, 160.348, 165.193, 149.261, 140.990, 160.281, 125.056, 155.020,
        137.613, 150.311, 155.547,  97.272, 153.486, 152.902, 155.254, 154.037,
        132.832, 157.746, 144.118, 109.649, 165.709, 144.563, 157.522, 167.961,
        140.252, 156.205, 154.383, 169.213, 147.457, 150.012, 154.022, 153.905,
        140.159, 141.156, 153.120, 160.192, 122.587, 127.966, 131.388, 144.941,
        134.105, 157.983, 151.937, 138.825, 157.630, 168.014, 113.873, 134.090,
        119.259, 163.715, 169.144, 161.005, 166.077, 178.824, 159.474, 139.228,
        122.229, 178.946, 132.122, 170.445, 178.351, 146.476, 153.596, 148.862,
        116.002, 162.988, 152.360, 155.365, 132.396, 121.181, 144.482, 150.489,
        169.422, 135.742, 158.479, 179.643, 150.114, 150.168, 144.835, 135.745,
        155.801, 130.930,  92.303, 140.435, 173.899, 138.467, 146.495, 150.315,
        173.474, 173.374, 131.338, 170.522, 131.861, 153.712, 164.525, 131.744,
        169.128, 152.818, 139.106, 136.695, 171.700, 174.944, 143.257, 141.504,
        130.548, 141.871, 118.910, 132.543, 109.226, 157.294, 145.488, 152.460,
        154.198, 136.828, 166.378, 161.864, 154.276, 127.063, 118.123, 146.470,
        134.695, 134.654, 121.843, 141.074, 149.934, 143.128, 174.211, 138.981,
        150.315, 118.990, 133.222, 128.237, 150.765, 155.633, 155.390, 147.473,
        184.136, 164.088, 137.289, 161.978, 149.778, 148.328, 145.572, 153.464,
        158.263, 151.223, 171.106, 141.707, 150.504, 148.897, 151.506, 149.033,
        154.808, 139.661, 139.831, 173.016, 158.382, 152.395, 102.270, 138.266,
        154.390,  96.120, 131.886, 170.603, 173.327, 172.688, 174.407, 124.392,
        167.410, 164.555, 139.447, 152.088, 146.951, 141.741, 152.688, 152.685,
        128.839, 143.025, 163.967, 128.614, 163.982, 150.262, 169.135, 171.433,
        165.516, 171.530, 135.222, 160.939, 158.889, 135.372, 178.301, 136.578,
        154.265, 153.416, 148.025, 152.797, 144.403, 144.985, 154.273, 160.205,
        152.472, 155.303, 142.920, 133.747, 128.085,  94.261, 163.625, 157.365,
        128.542, 139.463, 142.394, 114.777, 172.830, 127.120, 145.346, 152.007,
        129.229, 158.931, 135.227, 161.266, 151.935, 123.945, 136.296, 161.358,
        118.296, 125.216, 165.222, 145.330, 180.762, 113.198, 134.058, 135.664,
        148.722, 161.234, 151.675, 140.230, 143.409, 168.813, 147.651, 131.184,
        155.217, 131.538, 146.574, 135.009], device='cuda:0')
clipping threshold 0.15825323586081833
a after update for 1 param tensor([[[-1.317e-02],
         [ 3.363e-02],
         [ 2.345e-02],
         [-6.542e-02],
         [ 1.289e-02],
         [ 3.837e-02],
         [-1.058e-01],
         [ 8.923e-03],
         [ 2.454e-02],
         [ 5.559e-02]],

        [[-4.629e-02],
         [-7.689e-02],
         [ 1.134e-01],
         [-6.132e-02],
         [ 2.873e-02],
         [-3.262e-02],
         [ 4.053e-02],
         [-7.309e-02],
         [-5.176e-02],
         [ 9.237e-02]],

        [[-3.084e-02],
         [-8.734e-03],
         [ 8.790e-02],
         [ 5.118e-02],
         [ 2.891e-02],
         [ 4.132e-02],
         [ 9.301e-04],
         [-2.702e-02],
         [-3.678e-02],
         [ 4.456e-02]],

        [[-2.463e-02],
         [-4.578e-02],
         [-1.246e-01],
         [ 6.550e-02],
         [-9.703e-04],
         [ 8.691e-02],
         [-4.074e-02],
         [ 1.978e-02],
         [ 2.800e-02],
         [-2.929e-04]],

        [[-5.364e-02],
         [-9.387e-02],
         [ 1.893e-02],
         [ 9.032e-03],
         [ 3.829e-02],
         [ 9.286e-02],
         [-6.323e-02],
         [ 4.024e-02],
         [ 8.201e-02],
         [ 1.666e-02]],

        [[-5.384e-02],
         [-3.695e-02],
         [-1.481e-02],
         [-3.441e-02],
         [-1.729e-02],
         [-8.061e-02],
         [ 3.227e-02],
         [ 2.021e-02],
         [-8.626e-03],
         [ 2.757e-02]],

        [[-6.056e-03],
         [-5.846e-03],
         [-5.985e-02],
         [-5.505e-02],
         [ 7.350e-02],
         [ 1.762e-02],
         [ 2.788e-02],
         [-3.942e-02],
         [-9.313e-02],
         [ 7.867e-03]],

        [[-3.959e-02],
         [ 1.048e-02],
         [-1.193e-02],
         [-4.267e-02],
         [-5.014e-03],
         [-3.562e-02],
         [-7.799e-02],
         [ 4.267e-05],
         [-5.443e-02],
         [ 1.226e-02]],

        [[-5.920e-02],
         [ 1.272e-01],
         [-7.088e-02],
         [ 1.272e-02],
         [ 5.337e-02],
         [ 2.094e-01],
         [-2.757e-02],
         [ 1.546e-02],
         [-8.588e-02],
         [-8.343e-02]],

        [[ 1.838e-03],
         [-4.335e-02],
         [ 2.632e-03],
         [-3.268e-02],
         [-2.397e-02],
         [-5.631e-02],
         [-3.287e-02],
         [ 2.357e-02],
         [ 1.855e-02],
         [ 9.072e-02]],

        [[ 1.797e-02],
         [-1.010e-01],
         [ 1.227e-01],
         [-2.495e-02],
         [ 3.119e-03],
         [ 3.960e-02],
         [ 1.118e-01],
         [ 2.226e-02],
         [ 8.466e-03],
         [ 6.607e-02]],

        [[-5.094e-02],
         [-1.597e-02],
         [ 9.558e-03],
         [-2.025e-02],
         [-2.115e-02],
         [-7.340e-02],
         [ 6.709e-03],
         [ 4.505e-02],
         [ 1.073e-01],
         [-5.466e-02]],

        [[ 1.533e-03],
         [ 4.806e-02],
         [ 1.974e-02],
         [ 4.567e-02],
         [ 3.258e-02],
         [-3.318e-02],
         [-3.968e-02],
         [ 1.500e-02],
         [ 9.294e-02],
         [ 2.537e-02]],

        [[ 4.699e-02],
         [ 9.682e-02],
         [-3.677e-02],
         [ 9.793e-03],
         [ 4.754e-03],
         [ 1.531e-02],
         [ 2.179e-02],
         [ 6.424e-02],
         [-1.912e-03],
         [-7.045e-02]],

        [[-3.950e-03],
         [-8.380e-03],
         [-6.624e-02],
         [-2.233e-02],
         [-2.421e-02],
         [ 1.716e-02],
         [ 4.367e-02],
         [ 6.955e-02],
         [ 2.766e-02],
         [-4.198e-02]],

        [[ 6.147e-02],
         [-1.913e-02],
         [ 1.590e-02],
         [ 3.450e-02],
         [-7.853e-02],
         [ 7.792e-02],
         [-3.373e-02],
         [ 3.443e-02],
         [-2.204e-02],
         [ 1.272e-03]],

        [[ 1.451e-01],
         [-4.896e-02],
         [ 1.116e-02],
         [ 7.274e-03],
         [ 6.011e-02],
         [ 6.821e-02],
         [-1.993e-02],
         [-2.593e-02],
         [-4.021e-02],
         [-1.043e-02]],

        [[-2.012e-02],
         [-2.129e-02],
         [ 2.804e-03],
         [-9.061e-02],
         [-2.756e-02],
         [ 1.017e-01],
         [ 4.675e-02],
         [ 1.637e-04],
         [ 7.387e-02],
         [-4.571e-02]],

        [[ 1.444e-02],
         [-1.340e-02],
         [-5.347e-02],
         [-2.103e-02],
         [ 5.812e-03],
         [ 6.470e-02],
         [ 7.373e-02],
         [ 1.568e-02],
         [-9.240e-03],
         [ 5.343e-02]],

        [[ 2.893e-02],
         [ 4.187e-02],
         [-6.817e-04],
         [ 8.008e-02],
         [-2.024e-02],
         [ 2.115e-02],
         [-6.934e-03],
         [-3.406e-02],
         [-5.005e-02],
         [ 1.590e-02]],

        [[-5.513e-02],
         [ 6.371e-02],
         [ 4.199e-02],
         [-3.476e-02],
         [ 3.193e-02],
         [ 4.252e-02],
         [-5.469e-02],
         [-3.519e-02],
         [ 8.600e-03],
         [ 2.231e-02]],

        [[-9.281e-02],
         [-1.182e-02],
         [ 1.016e-01],
         [-6.064e-02],
         [ 2.960e-02],
         [-2.504e-02],
         [ 1.000e-02],
         [-2.488e-02],
         [ 1.200e-02],
         [-1.077e-01]],

        [[-3.548e-02],
         [ 1.404e-01],
         [ 1.059e-01],
         [ 1.928e-03],
         [ 1.344e-02],
         [-7.874e-02],
         [-1.587e-02],
         [-1.039e-01],
         [ 1.044e-01],
         [-1.768e-03]],

        [[ 3.314e-02],
         [ 9.245e-02],
         [ 1.785e-02],
         [ 8.523e-02],
         [-4.257e-02],
         [-1.050e-01],
         [-2.236e-02],
         [-9.775e-02],
         [-6.835e-02],
         [ 8.724e-02]],

        [[-5.358e-03],
         [-3.942e-02],
         [ 6.056e-02],
         [ 5.128e-02],
         [ 6.767e-02],
         [ 5.077e-03],
         [-7.332e-02],
         [-2.336e-02],
         [-2.856e-02],
         [ 3.154e-02]],

        [[-4.333e-02],
         [ 4.188e-02],
         [-8.936e-02],
         [-1.850e-02],
         [ 8.176e-02],
         [-1.710e-02],
         [ 3.301e-02],
         [-4.793e-02],
         [ 1.991e-03],
         [ 2.891e-02]],

        [[-7.925e-04],
         [ 1.669e-02],
         [-2.353e-02],
         [-1.803e-01],
         [-6.498e-02],
         [ 2.415e-02],
         [ 2.901e-02],
         [-7.190e-02],
         [-4.449e-02],
         [ 4.770e-02]],

        [[ 3.132e-02],
         [-2.629e-02],
         [-9.987e-02],
         [ 8.189e-02],
         [-2.067e-02],
         [-5.347e-02],
         [-5.836e-02],
         [ 1.617e-01],
         [-2.891e-02],
         [ 1.549e-01]],

        [[-5.913e-02],
         [ 3.039e-03],
         [-7.897e-02],
         [-5.025e-02],
         [-1.434e-02],
         [-2.569e-02],
         [-4.261e-03],
         [ 3.175e-02],
         [ 2.227e-02],
         [ 7.948e-03]],

        [[ 2.906e-02],
         [-6.380e-02],
         [ 3.377e-02],
         [ 6.831e-02],
         [ 5.100e-02],
         [-1.417e-01],
         [ 1.059e-01],
         [-1.993e-03],
         [ 4.232e-02],
         [ 7.132e-03]]], device='cuda:0')
s after update for 1 param tensor([[[1.451],
         [1.076],
         [1.206],
         [1.761],
         [1.314],
         [2.051],
         [1.371],
         [1.325],
         [1.593],
         [1.801]],

        [[1.438],
         [1.760],
         [1.872],
         [1.305],
         [1.209],
         [1.700],
         [1.929],
         [1.651],
         [1.962],
         [1.557]],

        [[1.413],
         [0.788],
         [1.856],
         [1.674],
         [1.626],
         [1.656],
         [1.169],
         [1.830],
         [0.900],
         [1.616]],

        [[1.866],
         [1.377],
         [1.201],
         [1.070],
         [1.842],
         [0.973],
         [1.401],
         [1.648],
         [1.439],
         [1.092]],

        [[1.513],
         [1.249],
         [1.529],
         [1.696],
         [1.171],
         [1.334],
         [1.622],
         [1.035],
         [1.599],
         [1.262]],

        [[1.957],
         [0.788],
         [1.919],
         [1.454],
         [1.813],
         [2.055],
         [1.853],
         [1.420],
         [1.844],
         [1.918]],

        [[1.817],
         [1.614],
         [1.594],
         [2.124],
         [1.787],
         [1.218],
         [1.835],
         [1.140],
         [1.221],
         [1.109]],

        [[0.879],
         [1.147],
         [1.402],
         [1.398],
         [1.336],
         [1.308],
         [1.465],
         [1.713],
         [1.445],
         [1.496]],

        [[1.870],
         [1.535],
         [1.379],
         [1.756],
         [1.709],
         [2.054],
         [1.707],
         [1.540],
         [1.343],
         [1.782]],

        [[1.302],
         [1.694],
         [1.599],
         [0.671],
         [1.605],
         [1.299],
         [1.470],
         [1.595],
         [1.797],
         [2.009]],

        [[2.119],
         [1.279],
         [1.774],
         [0.916],
         [1.465],
         [1.609],
         [1.568],
         [1.825],
         [2.160],
         [1.651]],

        [[1.856],
         [1.403],
         [1.487],
         [1.110],
         [1.407],
         [1.700],
         [1.281],
         [1.543],
         [1.832],
         [1.292]],

        [[0.819],
         [1.281],
         [1.725],
         [1.198],
         [1.544],
         [0.647],
         [1.033],
         [1.804],
         [2.008],
         [1.862]],

        [[0.961],
         [1.272],
         [1.220],
         [1.668],
         [1.584],
         [2.022],
         [1.824],
         [1.051],
         [1.956],
         [1.435]],

        [[1.589],
         [1.403],
         [2.190],
         [1.741],
         [0.855],
         [2.102],
         [1.204],
         [1.139],
         [1.927],
         [1.678]],

        [[1.671],
         [1.872],
         [1.264],
         [1.689],
         [1.117],
         [1.363],
         [1.272],
         [0.906],
         [1.710],
         [1.026]],

        [[1.100],
         [1.715],
         [1.504],
         [1.215],
         [1.973],
         [1.718],
         [1.239],
         [1.768],
         [2.362],
         [1.957]],

        [[1.524],
         [1.554],
         [1.246],
         [1.808],
         [1.334],
         [1.904],
         [1.844],
         [1.593],
         [1.464],
         [1.976]],

        [[1.096],
         [1.704],
         [1.566],
         [2.019],
         [1.594],
         [1.440],
         [1.149],
         [0.929],
         [1.438],
         [1.544]],

        [[1.291],
         [1.581],
         [1.496],
         [2.038],
         [1.724],
         [1.263],
         [1.867],
         [1.053],
         [1.056],
         [1.128]],

        [[1.640],
         [1.255],
         [1.790],
         [1.558],
         [1.983],
         [1.588],
         [1.606],
         [1.164],
         [1.390],
         [2.079]],

        [[1.327],
         [1.764],
         [1.916],
         [1.523],
         [1.653],
         [1.463],
         [1.313],
         [1.075],
         [1.350],
         [1.713]],

        [[1.274],
         [1.656],
         [1.391],
         [1.441],
         [1.208],
         [1.666],
         [1.651],
         [0.706],
         [1.815],
         [1.795]],

        [[1.370],
         [1.757],
         [1.169],
         [1.841],
         [2.014],
         [1.879],
         [0.830],
         [1.971],
         [1.041],
         [1.521]],

        [[1.803],
         [1.830],
         [0.886],
         [1.497],
         [1.998],
         [0.701],
         [1.954],
         [1.443],
         [1.393],
         [1.298]],

        [[1.424],
         [1.919],
         [1.019],
         [1.150],
         [1.370],
         [1.448],
         [1.017],
         [1.798],
         [1.094],
         [2.019]],

        [[1.861],
         [1.322],
         [1.525],
         [2.104],
         [1.754],
         [1.598],
         [1.381],
         [1.191],
         [2.127],
         [1.663]],

        [[1.210],
         [1.579],
         [1.773],
         [1.707],
         [1.622],
         [2.254],
         [1.652],
         [1.774],
         [1.209],
         [1.815]],

        [[1.750],
         [1.235],
         [1.833],
         [1.710],
         [2.213],
         [1.893],
         [1.640],
         [1.455],
         [1.734],
         [1.229]],

        [[1.859],
         [2.190],
         [1.733],
         [1.327],
         [1.410],
         [1.231],
         [1.331],
         [1.939],
         [1.564],
         [1.138]]], device='cuda:0')
b after update for 1 param tensor([[[147.070],
         [126.654],
         [134.095],
         [162.049],
         [139.949],
         [174.863],
         [142.981],
         [140.519],
         [154.110],
         [163.857]],

        [[146.427],
         [161.994],
         [167.035],
         [139.465],
         [134.261],
         [159.213],
         [169.589],
         [156.893],
         [171.017],
         [152.331]],

        [[145.147],
         [108.392],
         [166.323],
         [157.954],
         [155.675],
         [157.125],
         [132.041],
         [165.168],
         [115.820],
         [155.192]],

        [[166.800],
         [143.261],
         [133.822],
         [126.275],
         [165.722],
         [120.454],
         [144.544],
         [156.750],
         [146.446],
         [127.572]],

        [[150.194],
         [136.471],
         [151.001],
         [158.995],
         [132.101],
         [140.997],
         [155.505],
         [124.243],
         [154.406],
         [137.177]],

        [[170.784],
         [108.396],
         [169.156],
         [147.241],
         [164.384],
         [175.011],
         [166.224],
         [145.484],
         [165.795],
         [169.096]],

        [[164.582],
         [155.095],
         [154.131],
         [177.962],
         [163.232],
         [134.729],
         [165.384],
         [130.350],
         [134.896],
         [128.558]],

        [[114.489],
         [130.786],
         [144.548],
         [144.345],
         [141.123],
         [139.662],
         [147.781],
         [159.787],
         [146.788],
         [149.318]],

        [[166.978],
         [151.278],
         [143.388],
         [161.787],
         [159.609],
         [175.006],
         [159.515],
         [151.495],
         [141.521],
         [162.985]],

        [[139.319],
         [158.898],
         [154.382],
         [ 99.998],
         [154.686],
         [139.156],
         [148.044],
         [154.201],
         [163.693],
         [173.060]],

        [[177.715],
         [138.080],
         [162.623],
         [116.859],
         [147.774],
         [154.853],
         [152.894],
         [164.967],
         [179.454],
         [156.889]],

        [[166.326],
         [144.602],
         [148.892],
         [128.612],
         [144.842],
         [159.192],
         [138.190],
         [151.671],
         [165.254],
         [138.757]],

        [[110.526],
         [138.213],
         [160.368],
         [133.662],
         [151.715],
         [ 98.240],
         [124.109],
         [164.015],
         [173.016],
         [166.625]],

        [[119.690],
         [137.694],
         [134.863],
         [157.676],
         [153.663],
         [173.601],
         [164.920],
         [125.186],
         [170.752],
         [146.274]],

        [[153.906],
         [144.640],
         [180.683],
         [161.084],
         [112.916],
         [177.036],
         [133.985],
         [130.316],
         [169.492],
         [158.168]],

        [[157.821],
         [167.074],
         [137.262],
         [158.694],
         [129.035],
         [142.525],
         [137.713],
         [116.230],
         [159.661],
         [123.684]],

        [[128.055],
         [159.896],
         [149.747],
         [134.559],
         [171.486],
         [160.035],
         [135.881],
         [162.339],
         [187.649],
         [170.787]],

        [[150.722],
         [152.203],
         [136.267],
         [164.173],
         [141.018],
         [168.456],
         [165.791],
         [154.108],
         [147.745],
         [171.647]],

        [[127.806],
         [159.375],
         [152.805],
         [173.499],
         [154.158],
         [146.508],
         [130.895],
         [117.681],
         [146.408],
         [151.696]],

        [[138.743],
         [153.535],
         [149.341],
         [174.289],
         [160.337],
         [137.216],
         [166.815],
         [125.319],
         [125.461],
         [129.695]],

        [[156.343],
         [136.794],
         [163.345],
         [152.381],
         [171.930],
         [153.849],
         [154.724],
         [131.743],
         [143.927],
         [176.038]],

        [[140.637],
         [162.171],
         [169.009],
         [150.702],
         [156.988],
         [147.667],
         [139.899],
         [126.564],
         [141.888],
         [159.809]],

        [[137.823],
         [157.125],
         [143.980],
         [146.548],
         [134.210],
         [157.599],
         [156.877],
         [102.568],
         [164.506],
         [163.598]],

        [[142.925],
         [161.863],
         [131.990],
         [165.681],
         [173.279],
         [167.375],
         [111.212],
         [171.428],
         [124.594],
         [150.586]],

        [[163.955],
         [165.183],
         [114.933],
         [149.405],
         [172.568],
         [102.209],
         [170.672],
         [146.646],
         [144.123],
         [139.089]],

        [[145.693],
         [169.151],
         [123.228],
         [130.924],
         [142.921],
         [146.905],
         [123.155],
         [163.718],
         [127.701],
         [173.493]],

        [[166.555],
         [140.405],
         [150.773],
         [177.101],
         [161.691],
         [154.358],
         [143.494],
         [133.242],
         [178.057],
         [157.435]],

        [[134.284],
         [153.414],
         [162.597],
         [159.512],
         [155.503],
         [183.306],
         [156.953],
         [162.611],
         [134.264],
         [164.489]],

        [[161.541],
         [135.692],
         [165.322],
         [159.666],
         [181.631],
         [167.983],
         [156.343],
         [147.282],
         [160.785],
         [135.367]],

        [[166.489],
         [180.694],
         [160.732],
         [140.630],
         [144.968],
         [135.473],
         [140.889],
         [170.040],
         [152.704],
         [130.233]]], device='cuda:0')
clipping threshold 0.15825323586081833
a after update for 1 param tensor([[-0.052],
        [-0.035],
        [-0.043],
        [-0.028],
        [ 0.019],
        [ 0.010],
        [ 0.046],
        [-0.075],
        [-0.070],
        [-0.024],
        [-0.094],
        [ 0.001],
        [ 0.015],
        [-0.002],
        [-0.054],
        [-0.040],
        [-0.143],
        [-0.032],
        [ 0.029],
        [-0.003],
        [-0.001],
        [ 0.113],
        [ 0.003],
        [-0.027],
        [-0.028],
        [ 0.011],
        [-0.022],
        [-0.005],
        [ 0.052],
        [-0.051]], device='cuda:0')
s after update for 1 param tensor([[1.697],
        [1.933],
        [1.423],
        [1.931],
        [2.232],
        [1.824],
        [1.748],
        [1.527],
        [1.556],
        [1.549],
        [0.879],
        [1.632],
        [1.817],
        [1.570],
        [1.588],
        [1.634],
        [1.255],
        [1.637],
        [1.700],
        [1.635],
        [1.819],
        [1.082],
        [1.630],
        [1.546],
        [1.810],
        [1.125],
        [1.631],
        [1.292],
        [1.468],
        [1.847]], device='cuda:0')
b after update for 1 param tensor([[159.078],
        [169.750],
        [145.629],
        [169.665],
        [182.409],
        [164.879],
        [161.436],
        [150.871],
        [152.321],
        [151.978],
        [114.478],
        [155.991],
        [164.581],
        [153.010],
        [153.881],
        [156.069],
        [136.770],
        [156.235],
        [159.186],
        [156.109],
        [164.695],
        [127.000],
        [155.877],
        [151.819],
        [164.261],
        [129.526],
        [155.915],
        [138.775],
        [147.955],
        [165.936]], device='cuda:0')
clipping threshold 0.15825323586081833
cuda
Objective function 30.30 = squared loss an data 28.38 + 0.5*rho*h**2 1.030430 + alpha*h 0.243005 + L2reg 0.41 + L1reg 0.23 ; SHD = 64 ; DAG True
Proportion of microbatches that were clipped  0.7581532573160035
iteration 3 in inner loop, alpha 16.92743239628347 rho 10000.0 h 0.014355696379269034
iteration 3 in outer loop, alpha = 160.48439618897382, rho = 10000.0, h = 0.014355696379269034
cuda
9630
cuda
Objective function 32.36 = squared loss an data 28.38 + 0.5*rho*h**2 1.030430 + alpha*h 2.303865 + L2reg 0.41 + L1reg 0.23 ; SHD = 64 ; DAG True
||w||^2 11561997522.529053
exp ma of ||w||^2 2763721718.400266
||w|| 107526.72933986718
exp ma of ||w|| 25471.65363086741
||w||^2 0.19305787801182772
exp ma of ||w||^2 18.91587956330216
||w|| 0.4393835204144868
exp ma of ||w|| 0.5293241754993275
||w||^2 0.03849772243044869
exp ma of ||w||^2 0.04310078873522854
||w|| 0.1962083648330231
exp ma of ||w|| 0.20575729678049678
||w||^2 0.028003809048169487
exp ma of ||w||^2 0.04159212740420157
||w|| 0.1673433866281231
exp ma of ||w|| 0.20197346132223687
||w||^2 0.03457006925738699
exp ma of ||w||^2 0.0393483117355867
||w|| 0.1859302806360142
exp ma of ||w|| 0.19523205467555274
||w||^2 0.03845875564002572
exp ma of ||w||^2 0.039719781663576446
||w|| 0.19610904017924752
exp ma of ||w|| 0.19583400040576737
||w||^2 0.03367438571853372
exp ma of ||w||^2 0.03877923276802053
||w|| 0.18350581930427634
exp ma of ||w|| 0.19387633317620773
||w||^2 0.046959602731410366
exp ma of ||w||^2 0.04059656066422759
||w|| 0.21670164450555138
exp ma of ||w|| 0.1984418450156236
||w||^2 0.027481330027371013
exp ma of ||w||^2 0.04111700923016881
||w|| 0.16577493787473127
exp ma of ||w|| 0.1995741214140362
||w||^2 0.030218937525248193
exp ma of ||w||^2 0.03897280604401497
||w|| 0.17383595003694774
exp ma of ||w|| 0.1943094943610953
||w||^2 0.043802156398360846
exp ma of ||w||^2 0.04261896444916896
||w|| 0.20928964713611814
exp ma of ||w|| 0.20354200032458442
cuda
Objective function 30.97 = squared loss an data 28.42 + 0.5*rho*h**2 0.426657 + alpha*h 1.482475 + L2reg 0.43 + L1reg 0.22 ; SHD = 63 ; DAG True
Proportion of microbatches that were clipped  0.7603082545483435
iteration 1 in inner loop, alpha 160.48439618897382 rho 10000.0 h 0.009237503743054987
9630
cuda
Objective function 34.81 = squared loss an data 28.42 + 0.5*rho*h**2 4.266574 + alpha*h 1.482475 + L2reg 0.43 + L1reg 0.22 ; SHD = 63 ; DAG True
||w||^2 9.52082217564939
exp ma of ||w||^2 8556.577734440494
||w|| 3.085582955561135
exp ma of ||w|| 3.2456341969300517
||w||^2 2.166267570284614
exp ma of ||w||^2 10.513569031528869
||w|| 1.4718245718442855
exp ma of ||w|| 1.6234754923351178
||w||^2 0.17040773171847318
exp ma of ||w||^2 0.21883120729705224
||w|| 0.4128047137793768
exp ma of ||w|| 0.4639038007163606
||w||^2 0.16430009409360816
exp ma of ||w||^2 0.2101812553178892
||w|| 0.4053394800578993
exp ma of ||w|| 0.4548894156532675
||w||^2 0.18025445127526687
exp ma of ||w||^2 0.2080705835104929
||w|| 0.42456383651374136
exp ma of ||w|| 0.4526856649552808
v before min max tensor([[-54.614, 227.968, -71.361,  ..., -62.930,   7.244, -18.159],
        [ 54.761, -73.287, 184.048,  ..., -34.024, -35.141,  76.759],
        [ 36.854,   5.281, -37.247,  ...,  -4.901,  50.569, -26.116],
        ...,
        [-27.736, 198.165,  -3.583,  ..., -39.985, -50.658,  -2.610],
        [-57.441, -43.933, -61.876,  ...,  15.420, 122.968, 302.200],
        [130.946, -55.255, 236.586,  ...,  92.345, -55.388,  65.503]],
       device='cuda:0')
v tensor([[1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 7.244e+00,
         1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e+01],
        [1.000e+01, 5.281e+00, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         1.000e-12],
        ...,
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e+01, 1.000e+01,
         1.000e+01],
        [1.000e+01, 1.000e-12, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.000e+01]], device='cuda:0')
v before min max tensor([ 20.881, -40.205,  -5.978, -11.516,  52.166, -54.658, -50.543, -58.476,
        -50.631,  74.018, -42.461, -49.520, 126.532, -57.461,  87.632,  -5.593,
        -12.286, -40.022,  71.796, -15.798, -43.744, -19.858, -39.089, -42.447,
        -51.669, -46.851, -51.801,  73.489,  22.124, -31.724, 609.857, -10.482,
        -18.845,  44.489, -29.905,  14.517, 295.301, -75.740, -40.324, 488.961,
         -7.628, 230.808, -60.229, -33.129, -18.735, -62.563, 206.052, 108.387,
        -23.079, -19.799, -20.686, -58.645, -70.278, -75.592, -61.520, -36.863,
        -28.971, 160.954, 107.958, -73.095, -29.931, 257.525,  36.482, -33.302,
        -60.059, -57.460,  14.880, -56.261, -56.360, -59.215, -23.214, -14.463,
        -41.676, -54.584, 214.889, -48.651, 143.108, -34.922, -31.431, -36.084,
        -70.215, -65.424, -14.295, -39.790, 322.088, -19.933, 506.806, -13.622,
        -42.367, -49.820, -61.266, -52.560, -49.404, -54.403, -34.455, -32.354,
        119.307, -38.096, 626.474, -42.439, -57.330, -54.116, 212.185,  14.967,
        -50.725, -18.752,  23.503, -55.267,  42.001, -47.844, -22.107, 199.307,
        -46.849, -14.199,  14.579, -61.161,   2.312, -45.444, -46.000, -43.600,
        333.109,   7.723, 153.445, 174.386,  -6.449, -53.512, -46.315, -44.811,
        -31.829, -63.786, -68.343,  33.148, -67.304, -53.915, 339.343,  25.751,
        -59.427, -58.377, -42.924,  15.466,  77.103, -41.605, -47.048, -54.151,
         13.281, -63.040,   7.310, -48.509, -56.914, -29.074, -29.800, -44.546,
        -52.558,  52.919,  11.329, -24.300,  16.027, -56.005, -32.221, -65.079,
        -51.443, -37.224, 105.493, -13.003,  64.254, -45.662, -56.590,  -6.730,
         54.276, -18.592, -13.058, -53.263,  88.944, -55.076, -62.256,  35.367,
        -55.382, 104.955, -36.307, -34.845, -43.849,  83.227,  -3.412, -41.654,
        -64.827,  85.041, -39.069, -44.641, -13.659, 154.413, -20.625, -46.477,
        -52.755, -57.590, -51.690, 700.795, -64.864, -55.281, -41.095,  91.893,
         -5.595, -32.146,  64.979, -16.616, 250.368, -57.295,  56.770, -54.100,
         -0.838, 180.455,  15.838,  -3.901, 240.795, 125.130, -53.254, 236.948,
        -63.439, -54.543, -42.841,  81.705, 107.968,  -4.912, -59.779, -47.187,
        451.874, 315.379, -51.931, -58.480, 234.634, -44.135,  74.753, -29.575,
        -48.897, -41.206,  32.668,  15.877, -32.882, -51.109, 109.547,  18.609,
        -66.487, -56.624, -31.678, 479.141,  69.558,   5.535,  -5.591,  26.124,
        -44.535,  49.306, -34.257,  37.916, -30.323, -39.450, -56.832,  29.527,
        -41.552, -35.460, -17.918, -76.705,   9.214, -23.189,  26.501, -47.433,
        101.686, -38.668, 136.202, -70.199, -12.688, -21.891, -45.294, -48.653,
        191.061,   3.561,   9.970,  89.375, -47.317,  56.971, -31.995, -42.702,
        -34.582, 131.739, 286.316, 319.236,  -3.499, -69.487, 136.849, -60.074,
        -50.117, -60.219, -40.682, -60.127, -47.896, -63.836, -41.378, -14.205,
        -35.319, -48.520,  44.266, -59.216], device='cuda:0')
v tensor([1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 2.312e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 7.723e+00, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 7.310e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 5.535e+00,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 9.214e+00, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 3.561e+00, 9.970e+00, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-57.242],
         [ 25.884],
         [181.358],
         [ 14.342],
         [-72.454],
         [-34.376],
         [-35.659],
         [ 37.025],
         [-33.175],
         [ -5.533]],

        [[ -4.127],
         [ 31.487],
         [-31.393],
         [-31.101],
         [ 26.402],
         [-12.541],
         [ 87.652],
         [273.278],
         [243.156],
         [ -5.651]],

        [[  4.904],
         [-41.492],
         [ 10.976],
         [124.709],
         [ 54.361],
         [155.303],
         [-69.584],
         [-39.969],
         [-15.518],
         [ 51.126]],

        [[-33.819],
         [-61.077],
         [185.748],
         [217.487],
         [-41.328],
         [-49.204],
         [-45.310],
         [111.723],
         [-46.292],
         [-37.499]],

        [[154.851],
         [-53.017],
         [ 32.282],
         [-60.177],
         [-72.550],
         [-48.054],
         [-40.984],
         [-55.669],
         [-58.677],
         [ 33.135]],

        [[305.555],
         [-10.698],
         [-33.351],
         [ 53.217],
         [-27.665],
         [152.755],
         [-11.828],
         [-18.716],
         [ 16.642],
         [ 82.663]],

        [[-45.301],
         [-42.873],
         [-38.432],
         [-62.163],
         [ 63.629],
         [-30.090],
         [-48.120],
         [ 37.106],
         [167.792],
         [  1.510]],

        [[ 78.642],
         [162.833],
         [-26.205],
         [229.403],
         [ 10.592],
         [-20.153],
         [-49.740],
         [-54.298],
         [-51.329],
         [  7.095]],

        [[-52.354],
         [-53.836],
         [-49.735],
         [-17.402],
         [ 59.317],
         [-53.568],
         [-50.023],
         [-24.425],
         [-35.384],
         [-19.857]],

        [[-52.733],
         [-53.076],
         [313.825],
         [ 71.024],
         [ 46.066],
         [459.313],
         [-51.098],
         [324.989],
         [-23.777],
         [172.403]],

        [[ 70.916],
         [147.338],
         [-60.572],
         [135.562],
         [-55.500],
         [-60.051],
         [104.036],
         [-10.873],
         [ -1.265],
         [-54.068]],

        [[-62.081],
         [ -8.576],
         [-40.482],
         [ 56.502],
         [ 10.950],
         [-34.284],
         [-55.010],
         [-33.152],
         [ 89.815],
         [ -8.832]],

        [[131.198],
         [ -0.460],
         [ 17.811],
         [-52.249],
         [-14.487],
         [-28.848],
         [-50.965],
         [-22.065],
         [ 22.633],
         [ 20.483]],

        [[-54.174],
         [ 21.077],
         [ 13.979],
         [-11.185],
         [-42.314],
         [-29.101],
         [-33.559],
         [ 15.816],
         [ 28.703],
         [ 87.579]],

        [[-59.608],
         [-50.269],
         [-40.369],
         [-25.304],
         [236.752],
         [290.582],
         [-47.764],
         [-38.126],
         [148.740],
         [ 89.410]],

        [[-57.197],
         [ 92.483],
         [100.310],
         [-30.748],
         [ 82.719],
         [-49.542],
         [ 98.662],
         [-62.109],
         [-59.347],
         [197.078]],

        [[171.163],
         [ 22.545],
         [-33.844],
         [-49.498],
         [-65.259],
         [198.627],
         [-46.190],
         [-42.546],
         [-19.739],
         [-40.260]],

        [[ -7.523],
         [125.619],
         [ 54.134],
         [-27.746],
         [ -8.744],
         [-40.900],
         [ 13.301],
         [ -7.246],
         [ 18.407],
         [-70.068]],

        [[-26.985],
         [-39.018],
         [  7.318],
         [272.011],
         [-58.555],
         [101.074],
         [-43.293],
         [169.875],
         [-59.073],
         [-49.992]],

        [[-14.282],
         [-33.725],
         [-23.097],
         [-37.316],
         [-50.138],
         [  3.944],
         [-52.419],
         [-32.580],
         [ 40.893],
         [ 32.765]],

        [[-48.227],
         [-33.535],
         [-55.121],
         [-66.939],
         [-55.531],
         [-55.917],
         [-58.226],
         [-52.577],
         [-18.762],
         [126.527]],

        [[ 36.957],
         [-45.781],
         [ 82.920],
         [-58.044],
         [ -1.208],
         [ 14.542],
         [103.880],
         [-54.737],
         [-49.318],
         [ 63.123]],

        [[-48.708],
         [-25.354],
         [-47.122],
         [-41.923],
         [-30.799],
         [-31.183],
         [ 68.919],
         [ 31.160],
         [-76.307],
         [-15.530]],

        [[-46.800],
         [ 55.013],
         [-19.492],
         [-20.469],
         [-44.368],
         [ -2.722],
         [-61.783],
         [ 67.866],
         [  8.863],
         [ -6.836]],

        [[-55.509],
         [-30.933],
         [-20.585],
         [-27.739],
         [-42.839],
         [ 94.000],
         [-16.277],
         [-62.548],
         [-50.634],
         [  5.245]],

        [[-41.229],
         [-61.792],
         [-58.757],
         [ -3.328],
         [-60.264],
         [-53.847],
         [-26.469],
         [ 36.410],
         [ -7.020],
         [ 74.151]],

        [[-33.460],
         [-16.743],
         [  4.136],
         [126.292],
         [-29.453],
         [-23.234],
         [247.988],
         [-61.723],
         [224.202],
         [-25.901]],

        [[-60.449],
         [-62.309],
         [ 20.225],
         [-58.705],
         [-59.827],
         [309.070],
         [ 72.484],
         [-66.381],
         [-38.152],
         [ 59.749]],

        [[145.811],
         [-45.000],
         [-56.300],
         [-18.635],
         [-55.881],
         [-59.433],
         [ -6.031],
         [-74.167],
         [105.938],
         [ 38.267]],

        [[ 80.726],
         [-21.063],
         [ 25.454],
         [ 50.678],
         [ 75.830],
         [-24.167],
         [-46.792],
         [113.417],
         [-65.134],
         [-23.408]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[4.904e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.510e+00]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.095e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [7.318e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.944e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [8.863e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.245e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [4.136e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[-24.416],
        [-29.583],
        [-37.768],
        [ 26.190],
        [142.423],
        [-62.273],
        [-53.281],
        [ 70.133],
        [-60.039],
        [-35.012],
        [-11.266],
        [ 57.187],
        [-51.923],
        [-50.305],
        [-22.838],
        [112.606],
        [-37.320],
        [-38.194],
        [ 95.684],
        [-47.658],
        [228.110],
        [  7.830],
        [ 17.919],
        [ 50.503],
        [288.525],
        [-17.937],
        [-42.481],
        [-53.664],
        [  4.082],
        [-64.859]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [7.830e+00],
        [1.000e+01],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [4.082e+00],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 0.089,  0.566,  0.292,  ..., -0.107,  0.041, -0.186],
        [ 0.064, -0.103,  0.128,  ..., -0.172,  0.063, -0.145],
        [ 0.053, -0.075,  0.192,  ..., -0.062, -0.215,  0.327],
        ...,
        [-0.323,  0.134,  0.099,  ...,  0.544,  0.160,  0.006],
        [-0.371,  0.057,  0.140,  ..., -1.082,  0.001, -0.054],
        [-0.097, -0.136,  0.007,  ..., -0.471,  0.086, -0.108]],
       device='cuda:0')
s after update for 1 param tensor([[2.705, 2.335, 2.307,  ..., 2.020, 1.540, 0.953],
        [2.635, 2.241, 1.968,  ..., 1.608, 1.144, 1.948],
        [2.813, 1.699, 1.875,  ..., 1.264, 1.418, 1.511],
        ...,
        [1.833, 1.883, 1.586,  ..., 2.028, 1.767, 1.883],
        [1.776, 1.353, 1.903,  ..., 2.564, 2.223, 2.799],
        [2.096, 1.674, 1.711,  ..., 2.023, 1.855, 2.448]], device='cuda:0')
b after update for 1 param tensor([[221.352, 205.644, 204.434,  ..., 191.283, 167.015, 131.386],
        [218.466, 201.457, 188.824,  ..., 170.655, 143.939, 187.823],
        [225.733, 175.437, 184.311,  ..., 151.321, 160.281, 165.432],
        ...,
        [182.231, 184.670, 169.517,  ..., 191.678, 178.922, 184.695],
        [179.352, 156.562, 185.666,  ..., 215.512, 200.653, 225.184],
        [194.865, 174.121, 176.055,  ..., 191.433, 183.309, 210.564]],
       device='cuda:0')
clipping threshold 0.2879795919372675
a after update for 1 param tensor([-0.269,  0.283,  0.300, -0.552, -0.328,  0.119, -0.021, -0.320, -0.169,
         0.289, -1.218, -0.082,  0.372,  0.213, -0.076,  0.238, -1.061,  0.025,
         0.642,  0.190,  0.534,  0.077, -0.248, -0.050, -0.449, -0.378, -0.473,
         0.470, -0.432,  0.539,  0.030,  0.508, -0.044,  0.028, -0.232, -0.805,
        -0.182,  0.125,  0.052,  0.017, -0.032, -0.028,  0.331,  0.497,  0.149,
        -0.417,  0.759,  1.296, -0.259, -0.361, -0.004,  0.151, -0.034, -0.250,
         0.179,  0.268, -0.618, -0.111,  0.322,  0.072,  0.072, -0.607,  0.574,
         0.335,  0.201, -0.342,  0.046,  0.161,  0.316, -0.035, -0.079,  0.481,
         0.799,  0.313, -0.098,  0.162,  0.427,  0.396, -0.492,  0.438,  0.627,
        -0.587,  0.131, -0.807, -0.454,  0.583, -0.308, -0.392,  0.163,  0.646,
         0.158, -0.283,  0.109, -0.428,  0.512, -0.783, -0.056,  0.544, -0.483,
         0.505,  0.151, -0.217,  0.076,  0.066, -0.983,  0.138, -0.331, -0.340,
         0.133, -0.515, -0.003,  0.003,  0.312, -0.356,  0.554,  0.539, -0.454,
         0.364,  0.142,  0.261,  0.439, -0.539,  0.718,  0.063,  0.868,  0.116,
        -0.097,  0.504, -0.510, -0.422, -1.796,  0.103, -0.612,  0.132, -0.296,
        -0.298,  0.624, -0.446,  0.270,  0.649, -0.184, -0.098, -0.132, -0.314,
         0.464, -0.259,  0.548,  0.009,  0.514,  0.918, -0.265, -0.094, -0.271,
        -0.339, -0.406, -0.284, -0.256, -0.047, -0.194,  0.128, -0.196,  0.129,
         0.388,  0.476,  0.092, -0.163,  0.668,  0.135,  0.257, -0.236, -0.166,
         0.148,  0.174,  0.148, -0.103, -0.548, -0.048,  0.671, -0.473,  0.170,
         0.487,  0.609,  0.135, -0.227, -0.354, -0.384, -0.009,  0.056,  0.359,
        -0.134, -0.281,  0.319, -0.231, -0.786,  0.307,  0.414,  0.296,  0.368,
         0.457, -0.414, -0.233,  0.148, -0.379, -0.599,  0.275, -0.536,  0.498,
         0.245, -0.149,  0.316, -0.085, -0.215,  0.303, -0.211, -0.204,  0.195,
        -0.127,  0.305, -0.258, -0.365, -0.297,  0.073,  0.213, -0.316,  0.917,
         0.451,  0.062, -0.080,  0.669, -0.597, -0.612,  0.133, -0.533, -0.268,
        -0.587,  0.557, -0.339,  0.834,  0.592, -0.098, -0.053, -0.433,  0.131,
        -0.333, -0.072, -0.004,  0.307,  0.241, -0.294, -0.646, -0.004,  0.225,
         0.338, -0.189, -1.203,  0.380, -0.992, -0.490, -0.722,  0.513,  0.590,
        -0.250, -0.080,  0.035,  0.128, -0.004, -0.195,  0.154, -0.360, -0.794,
         0.812,  0.021,  0.389, -0.021, -0.190, -0.074,  0.416, -0.113, -0.128,
        -0.384,  0.031, -0.889, -0.907,  0.335,  0.313,  0.366,  0.383, -0.459,
         0.583,  0.312, -0.531, -0.390,  0.353,  0.057, -0.058,  0.325, -0.081,
         0.446,  0.268,  0.293], device='cuda:0')
s after update for 1 param tensor([1.904, 1.829, 1.700, 2.129, 1.927, 1.844, 1.676, 2.087, 2.366, 2.052,
        1.803, 1.533, 1.711, 1.795, 1.962, 1.735, 2.005, 1.620, 1.965, 1.444,
        1.582, 1.843, 2.163, 1.672, 1.744, 1.419, 1.665, 1.593, 2.054, 1.910,
        2.402, 1.563, 1.686, 1.661, 1.842, 2.174, 1.809, 2.294, 1.630, 2.181,
        1.555, 1.835, 2.074, 1.958, 1.581, 1.921, 1.835, 1.953, 1.642, 1.798,
        2.052, 2.013, 2.186, 2.336, 1.881, 1.748, 1.692, 2.297, 2.141, 2.214,
        1.483, 1.937, 1.672, 1.479, 1.834, 1.808, 1.992, 1.888, 1.720, 1.863,
        1.033, 2.068, 1.397, 1.662, 2.094, 1.502, 2.356, 1.691, 1.878, 1.298,
        2.149, 1.985, 1.552, 1.748, 2.402, 1.674, 2.463, 1.832, 1.611, 1.680,
        1.931, 1.898, 1.832, 1.705, 1.796, 1.722, 2.094, 1.499, 2.629, 1.773,
        1.763, 1.639, 2.237, 1.681, 2.052, 1.604, 1.999, 1.691, 2.622, 1.602,
        1.293, 1.766, 1.435, 1.602, 2.416, 1.916, 1.851, 1.769, 1.455, 1.562,
        2.325, 1.783, 2.010, 1.843, 1.884, 1.626, 1.625, 1.701, 2.023, 1.950,
        2.073, 1.924, 2.137, 1.685, 1.927, 2.058, 2.055, 1.771, 1.623, 1.848,
        1.765, 1.470, 1.565, 1.640, 2.257, 1.924, 2.291, 1.469, 2.104, 1.521,
        1.651, 1.855, 1.656, 2.123, 1.790, 2.010, 2.087, 1.870, 1.782, 1.973,
        1.709, 1.516, 1.923, 1.910, 1.632, 1.738, 1.727, 2.064, 1.277, 1.838,
        1.991, 1.705, 1.423, 1.902, 1.886, 1.319, 1.681, 2.217, 1.338, 1.788,
        1.527, 2.389, 1.695, 1.322, 1.978, 2.189, 1.813, 2.169, 1.498, 1.724,
        1.543, 1.897, 1.761, 1.779, 1.852, 2.037, 1.977, 1.819, 1.502, 2.195,
        1.830, 1.525, 1.855, 1.936, 1.920, 2.082, 1.728, 1.746, 1.757, 1.936,
        1.748, 2.022, 2.004, 2.044, 1.795, 1.934, 1.945, 1.652, 1.919, 1.699,
        2.205, 1.954, 1.837, 1.849, 2.015, 2.122, 1.578, 1.777, 1.994, 1.494,
        1.960, 1.267, 1.832, 1.857, 1.776, 2.314, 1.579, 2.275, 1.956, 2.090,
        2.042, 1.792, 1.291, 1.843, 2.079, 2.269, 2.150, 1.965, 1.610, 2.287,
        1.243, 2.190, 1.305, 1.268, 2.114, 2.201, 2.253, 1.863, 1.698, 2.456,
        1.899, 1.627, 2.499, 2.191, 1.876, 1.176, 2.169, 2.200, 1.614, 2.281,
        1.756, 1.614, 1.932, 1.606, 2.266, 2.134, 1.501, 2.051, 1.694, 1.305,
        2.073, 1.951, 2.093, 2.408, 1.363, 2.153, 2.433, 1.965, 1.591, 1.827,
        1.371, 2.026, 1.451, 2.110, 1.485, 1.214, 1.511, 2.105, 2.070, 1.982],
       device='cuda:0')
b after update for 1 param tensor([185.710, 182.041, 175.472, 196.373, 186.850, 182.778, 174.248, 194.428,
        207.004, 192.793, 180.727, 166.652, 176.042, 180.316, 188.528, 177.262,
        190.592, 171.294, 188.660, 161.710, 169.280, 182.713, 197.925, 174.024,
        177.740, 160.344, 173.671, 169.891, 192.908, 186.023, 208.588, 168.287,
        174.770, 173.453, 182.679, 198.459, 181.037, 203.862, 171.821, 198.784,
        167.822, 182.293, 193.840, 188.344, 169.241, 186.564, 182.314, 188.089,
        172.483, 180.448, 192.787, 190.949, 199.009, 205.686, 184.580, 177.962,
        175.088, 204.002, 196.948, 200.258, 163.881, 187.304, 174.020, 163.699,
        182.279, 180.957, 189.963, 184.917, 176.506, 183.687, 136.801, 193.546,
        159.069, 173.502, 194.739, 164.933, 206.578, 174.996, 184.458, 153.320,
        197.309, 189.599, 167.646, 177.928, 208.581, 174.155, 211.216, 182.150,
        170.833, 174.455, 187.019, 185.432, 182.182, 175.728, 180.373, 176.634,
        194.772, 164.796, 218.220, 179.202, 178.721, 172.324, 201.320, 174.488,
        192.799, 170.474, 190.311, 175.001, 217.947, 170.352, 153.031, 178.842,
        161.213, 170.324, 209.200, 186.280, 183.100, 179.027, 162.330, 168.185,
        205.218, 179.730, 190.810, 182.710, 184.735, 171.620, 171.590, 175.533,
        191.426, 187.944, 193.771, 186.668, 196.747, 174.729, 186.836, 193.088,
        192.960, 179.111, 171.478, 182.946, 178.826, 163.196, 168.367, 172.379,
        202.214, 186.680, 203.735, 163.137, 195.214, 165.961, 172.915, 183.330,
        173.171, 196.125, 180.092, 190.798, 194.439, 184.065, 179.659, 189.049,
        175.969, 165.723, 186.634, 185.984, 171.939, 177.428, 176.848, 193.349,
        152.089, 182.485, 189.932, 175.717, 160.539, 185.606, 184.812, 154.567,
        174.484, 200.414, 155.665, 179.978, 166.321, 208.020, 175.220, 154.721,
        189.275, 199.151, 181.226, 198.212, 164.752, 176.714, 167.193, 185.364,
        178.613, 179.527, 183.144, 192.098, 189.251, 181.526, 164.931, 199.391,
        182.062, 166.232, 183.288, 187.268, 186.503, 194.184, 176.924, 177.823,
        178.419, 187.258, 177.947, 191.389, 190.549, 192.427, 180.313, 187.153,
        187.698, 172.978, 186.435, 175.427, 199.837, 188.150, 182.431, 182.998,
        191.035, 196.068, 169.075, 179.425, 190.074, 164.502, 188.421, 151.480,
        182.158, 183.396, 179.344, 204.754, 169.136, 203.008, 188.231, 194.578,
        192.311, 180.157, 152.928, 182.725, 194.062, 202.723, 197.356, 188.662,
        170.754, 203.545, 150.083, 199.158, 153.776, 151.570, 195.676, 199.695,
        202.008, 183.707, 175.375, 210.934, 185.446, 171.690, 212.763, 199.208,
        184.352, 145.950, 198.213, 199.606, 170.988, 203.257, 178.365, 170.989,
        187.089, 170.553, 202.592, 196.621, 164.910, 192.738, 175.162, 153.728,
        193.802, 187.975, 194.704, 208.858, 157.143, 197.504, 209.917, 188.676,
        169.778, 181.942, 157.591, 191.594, 162.119, 195.492, 164.004, 148.292,
        165.455, 195.282, 193.662, 189.499], device='cuda:0')
clipping threshold 0.2879795919372675
a after update for 1 param tensor([[[ 0.058],
         [ 0.431],
         [-0.331],
         [ 0.109],
         [-0.106],
         [ 0.145],
         [-0.100],
         [ 0.263],
         [ 0.510],
         [ 0.167]],

        [[-0.070],
         [ 0.237],
         [ 0.490],
         [-0.279],
         [ 0.654],
         [ 0.117],
         [ 0.281],
         [ 0.095],
         [-0.789],
         [-0.209]],

        [[-0.022],
         [-0.218],
         [-1.093],
         [ 0.432],
         [-0.110],
         [ 0.574],
         [ 0.306],
         [ 0.506],
         [ 0.030],
         [ 0.053]],

        [[-0.427],
         [-0.210],
         [ 0.084],
         [ 0.620],
         [-0.573],
         [-0.322],
         [ 0.346],
         [-0.762],
         [ 0.051],
         [ 0.133]],

        [[-0.220],
         [-0.112],
         [ 0.423],
         [-0.118],
         [ 0.039],
         [-0.047],
         [-0.322],
         [ 0.663],
         [-0.151],
         [ 0.654]],

        [[-0.643],
         [-1.206],
         [-0.234],
         [ 0.409],
         [-0.040],
         [ 0.319],
         [-0.235],
         [ 0.087],
         [-0.196],
         [-0.176]],

        [[-0.044],
         [ 0.358],
         [-0.294],
         [ 0.179],
         [ 0.078],
         [ 0.153],
         [ 0.245],
         [-1.012],
         [ 0.302],
         [ 0.414]],

        [[ 0.199],
         [ 0.558],
         [ 0.525],
         [-0.632],
         [ 0.171],
         [-0.388],
         [-0.092],
         [ 0.555],
         [ 0.323],
         [ 0.078]],

        [[-0.516],
         [ 0.178],
         [ 0.111],
         [ 0.421],
         [-0.363],
         [ 0.295],
         [ 0.161],
         [ 0.182],
         [-0.781],
         [-0.095]],

        [[-0.325],
         [-0.063],
         [-0.049],
         [ 0.190],
         [ 0.266],
         [ 0.350],
         [ 0.398],
         [-0.525],
         [-0.052],
         [-0.039]],

        [[ 0.046],
         [ 0.814],
         [-0.488],
         [-0.416],
         [ 0.478],
         [ 0.125],
         [ 0.184],
         [-0.015],
         [-0.616],
         [-0.322]],

        [[-0.669],
         [-0.496],
         [ 0.686],
         [ 0.245],
         [ 0.018],
         [-0.156],
         [ 0.347],
         [ 0.486],
         [-0.529],
         [ 0.311]],

        [[ 0.388],
         [-0.178],
         [-0.419],
         [ 0.549],
         [-0.155],
         [-0.610],
         [-0.346],
         [ 0.869],
         [-0.127],
         [ 0.473]],

        [[-0.894],
         [ 0.715],
         [ 0.132],
         [-0.581],
         [ 0.271],
         [-0.127],
         [ 0.048],
         [-0.323],
         [-0.643],
         [-0.249]],

        [[-0.314],
         [ 0.393],
         [ 0.351],
         [ 0.112],
         [ 0.353],
         [ 0.460],
         [ 0.077],
         [ 0.150],
         [ 0.548],
         [-0.026]],

        [[ 0.423],
         [ 0.193],
         [-0.098],
         [-0.107],
         [ 0.208],
         [-0.486],
         [-0.571],
         [-0.375],
         [ 0.283],
         [-0.121]],

        [[ 0.770],
         [ 0.062],
         [ 0.014],
         [-0.631],
         [ 0.718],
         [ 0.161],
         [ 0.499],
         [ 0.435],
         [-0.054],
         [ 0.181]],

        [[ 0.401],
         [-0.138],
         [ 0.375],
         [-0.113],
         [-0.299],
         [-0.010],
         [-0.239],
         [ 0.336],
         [-0.193],
         [ 0.360]],

        [[-0.153],
         [-0.261],
         [ 0.565],
         [-0.181],
         [ 0.291],
         [ 0.275],
         [ 0.260],
         [ 0.201],
         [-0.466],
         [-0.706]],

        [[-0.374],
         [-0.016],
         [ 0.002],
         [-0.385],
         [-0.083],
         [ 0.149],
         [-0.226],
         [-0.541],
         [ 0.548],
         [-0.536]],

        [[ 0.891],
         [ 0.111],
         [ 0.473],
         [-0.687],
         [ 0.208],
         [-0.122],
         [-0.581],
         [-0.089],
         [ 0.198],
         [-0.038]],

        [[ 0.593],
         [ 0.431],
         [ 0.252],
         [ 0.532],
         [-0.344],
         [-0.140],
         [-0.292],
         [-0.480],
         [-0.169],
         [-0.522]],

        [[-0.380],
         [-0.620],
         [-0.830],
         [-0.757],
         [ 0.132],
         [ 0.136],
         [ 0.732],
         [ 0.447],
         [ 0.370],
         [ 0.250]],

        [[-0.314],
         [-0.358],
         [-0.053],
         [ 0.023],
         [ 0.226],
         [-0.688],
         [ 0.469],
         [ 0.122],
         [-0.138],
         [ 0.869]],

        [[ 0.246],
         [ 0.174],
         [ 0.040],
         [ 0.481],
         [ 0.249],
         [ 0.328],
         [-0.080],
         [ 0.293],
         [-0.036],
         [-0.010]],

        [[ 0.673],
         [-0.218],
         [-0.295],
         [ 0.516],
         [ 0.093],
         [-0.372],
         [ 0.261],
         [-0.159],
         [ 0.324],
         [ 0.200]],

        [[-0.043],
         [ 0.554],
         [-0.069],
         [-0.201],
         [-0.450],
         [ 0.159],
         [ 0.223],
         [ 0.228],
         [-0.642],
         [ 0.093]],

        [[-0.226],
         [ 0.108],
         [-1.863],
         [ 0.190],
         [-0.286],
         [ 0.657],
         [-0.148],
         [ 0.447],
         [-0.084],
         [ 0.134]],

        [[-0.531],
         [ 0.015],
         [-0.751],
         [ 0.175],
         [ 0.844],
         [-0.161],
         [ 0.423],
         [ 0.061],
         [-0.937],
         [-0.032]],

        [[ 0.148],
         [-0.394],
         [ 0.501],
         [ 0.407],
         [-0.409],
         [-0.265],
         [ 0.093],
         [-0.277],
         [-0.325],
         [ 0.571]]], device='cuda:0')
s after update for 1 param tensor([[[1.833],
         [1.842],
         [1.921],
         [1.654],
         [2.271],
         [1.789],
         [1.553],
         [2.033],
         [1.468],
         [1.473]],

        [[1.904],
         [2.082],
         [1.690],
         [1.843],
         [2.019],
         [1.514],
         [1.997],
         [1.942],
         [2.221],
         [2.065]],

        [[1.575],
         [2.095],
         [2.058],
         [2.348],
         [2.032],
         [2.011],
         [2.119],
         [1.211],
         [1.053],
         [2.278]],

        [[1.416],
         [1.853],
         [2.146],
         [2.122],
         [1.281],
         [1.586],
         [1.812],
         [2.146],
         [1.716],
         [1.543]],

        [[2.147],
         [1.613],
         [2.095],
         [1.829],
         [2.218],
         [1.561],
         [1.403],
         [1.787],
         [1.809],
         [2.282]],

        [[2.341],
         [1.723],
         [1.616],
         [1.473],
         [1.785],
         [1.694],
         [1.548],
         [2.011],
         [2.435],
         [2.046]],

        [[1.706],
         [1.774],
         [1.315],
         [1.884],
         [2.225],
         [2.008],
         [1.459],
         [1.608],
         [1.889],
         [2.021]],

        [[2.093],
         [2.208],
         [1.462],
         [2.116],
         [1.613],
         [1.807],
         [1.644],
         [1.708],
         [1.580],
         [2.011]],

        [[1.621],
         [1.721],
         [1.526],
         [2.365],
         [2.076],
         [1.676],
         [1.715],
         [1.679],
         [1.759],
         [1.865]],

        [[2.165],
         [1.610],
         [1.871],
         [1.985],
         [1.845],
         [1.784],
         [1.793],
         [1.907],
         [2.330],
         [1.593]],

        [[2.115],
         [2.361],
         [2.031],
         [2.370],
         [1.951],
         [2.090],
         [1.908],
         [1.221],
         [1.650],
         [1.661]],

        [[1.986],
         [1.334],
         [1.775],
         [2.174],
         [1.936],
         [1.540],
         [1.981],
         [1.972],
         [2.072],
         [1.733]],

        [[2.255],
         [0.844],
         [2.261],
         [1.767],
         [1.915],
         [1.969],
         [1.750],
         [1.830],
         [2.526],
         [2.191]],

        [[1.667],
         [1.947],
         [1.735],
         [1.959],
         [1.444],
         [1.511],
         [1.972],
         [2.084],
         [2.284],
         [2.211]],

        [[1.814],
         [1.627],
         [1.228],
         [1.644],
         [2.480],
         [2.097],
         [1.682],
         [1.485],
         [1.787],
         [2.221]],

        [[1.970],
         [2.580],
         [2.030],
         [1.711],
         [1.906],
         [1.511],
         [2.029],
         [1.881],
         [2.126],
         [1.907]],

        [[2.280],
         [2.124],
         [1.226],
         [2.242],
         [2.088],
         [2.341],
         [1.750],
         [2.196],
         [1.552],
         [1.867]],

        [[2.192],
         [2.102],
         [1.862],
         [1.695],
         [1.867],
         [1.369],
         [1.720],
         [1.280],
         [1.909],
         [2.122]],

        [[0.985],
         [1.402],
         [1.947],
         [2.020],
         [1.802],
         [2.465],
         [1.784],
         [2.022],
         [1.884],
         [1.950]],

        [[2.268],
         [1.694],
         [2.183],
         [1.705],
         [1.964],
         [1.984],
         [2.002],
         [1.469],
         [1.738],
         [2.013]],

        [[1.708],
         [1.812],
         [1.701],
         [2.260],
         [1.919],
         [1.848],
         [1.771],
         [1.736],
         [1.789],
         [1.943]],

        [[1.997],
         [1.671],
         [2.068],
         [1.962],
         [1.795],
         [2.012],
         [2.035],
         [1.682],
         [1.948],
         [1.773]],

        [[1.493],
         [1.620],
         [1.713],
         [1.988],
         [1.527],
         [1.512],
         [1.897],
         [1.755],
         [2.405],
         [1.953]],

        [[1.428],
         [2.014],
         [0.773],
         [1.885],
         [1.884],
         [1.356],
         [1.989],
         [2.212],
         [1.230],
         [1.690]],

        [[1.763],
         [1.681],
         [1.849],
         [1.488],
         [1.409],
         [2.186],
         [2.102],
         [1.965],
         [1.537],
         [1.542]],

        [[2.186],
         [1.906],
         [1.977],
         [1.704],
         [1.836],
         [1.632],
         [0.908],
         [2.049],
         [1.424],
         [1.793]],

        [[1.384],
         [1.688],
         [1.646],
         [2.240],
         [1.583],
         [1.412],
         [2.264],
         [2.009],
         [1.934],
         [1.605]],

        [[2.092],
         [2.149],
         [2.331],
         [1.822],
         [1.893],
         [2.123],
         [1.655],
         [2.217],
         [1.879],
         [1.397]],

        [[1.619],
         [1.785],
         [2.193],
         [1.483],
         [2.168],
         [1.808],
         [1.682],
         [2.253],
         [2.577],
         [1.606]],

        [[2.039],
         [1.988],
         [1.992],
         [2.195],
         [2.044],
         [1.610],
         [1.622],
         [2.355],
         [2.014],
         [1.086]]], device='cuda:0')
b after update for 1 param tensor([[[182.230],
         [182.667],
         [186.555],
         [173.098],
         [202.826],
         [180.038],
         [167.743],
         [191.902],
         [163.069],
         [163.369]],

        [[185.696],
         [194.217],
         [174.968],
         [182.690],
         [191.247],
         [165.588],
         [190.179],
         [187.573],
         [200.598],
         [193.390]],

        [[168.892],
         [194.828],
         [193.080],
         [206.224],
         [191.858],
         [190.876],
         [195.907],
         [148.092],
         [138.106],
         [203.140]],

        [[160.134],
         [183.224],
         [197.165],
         [196.068],
         [152.320],
         [169.509],
         [181.180],
         [197.184],
         [176.331],
         [167.190]],

        [[197.205],
         [170.918],
         [194.800],
         [182.033],
         [200.449],
         [168.149],
         [159.426],
         [179.928],
         [181.040],
         [203.308]],

        [[205.927],
         [176.665],
         [171.081],
         [163.359],
         [179.822],
         [175.152],
         [167.479],
         [190.872],
         [210.014],
         [192.512]],

        [[175.794],
         [179.274],
         [154.347],
         [184.726],
         [200.744],
         [190.720],
         [162.582],
         [170.668],
         [185.000],
         [191.326]],

        [[194.733],
         [199.971],
         [162.711],
         [195.785],
         [170.957],
         [180.927],
         [172.544],
         [175.890],
         [169.195],
         [190.879]],

        [[171.378],
         [176.577],
         [166.278],
         [206.984],
         [193.914],
         [174.217],
         [176.239],
         [174.402],
         [178.492],
         [183.807]],

        [[198.038],
         [170.768],
         [184.100],
         [189.641],
         [182.828],
         [179.780],
         [180.212],
         [185.864],
         [205.456],
         [169.877]],

        [[195.718],
         [206.823],
         [191.825],
         [207.209],
         [187.990],
         [194.565],
         [185.892],
         [148.703],
         [172.883],
         [173.447]],

        [[189.647],
         [155.460],
         [179.326],
         [198.433],
         [187.254],
         [167.017],
         [189.413],
         [189.021],
         [193.720],
         [177.152]],

        [[202.124],
         [123.664],
         [202.367],
         [178.887],
         [186.253],
         [188.839],
         [178.019],
         [182.077],
         [213.896],
         [199.203]],

        [[173.747],
         [187.809],
         [177.304],
         [188.365],
         [161.733],
         [165.460],
         [189.015],
         [194.278],
         [203.385],
         [200.123]],

        [[181.295],
         [171.676],
         [149.128],
         [172.543],
         [211.952],
         [194.912],
         [174.539],
         [163.985],
         [179.910],
         [200.581]],

        [[188.895],
         [216.186],
         [191.760],
         [176.033],
         [185.799],
         [165.438],
         [191.706],
         [184.592],
         [196.244],
         [185.871]],

        [[203.227],
         [196.152],
         [149.017],
         [201.503],
         [194.462],
         [205.905],
         [178.050],
         [199.465],
         [167.691],
         [183.901]],

        [[199.277],
         [195.128],
         [183.655],
         [175.219],
         [183.890],
         [157.458],
         [176.533],
         [152.257],
         [185.959],
         [196.057]],

        [[133.581],
         [159.378],
         [187.807],
         [191.289],
         [180.688],
         [211.318],
         [179.773],
         [191.398],
         [184.730],
         [187.965]],

        [[202.688],
         [175.147],
         [198.865],
         [175.722],
         [188.612],
         [189.590],
         [190.428],
         [163.132],
         [177.440],
         [190.932]],

        [[175.903],
         [181.156],
         [175.523],
         [202.337],
         [186.448],
         [182.952],
         [179.086],
         [177.354],
         [180.001],
         [187.598]],

        [[190.203],
         [173.966],
         [193.545],
         [188.521],
         [180.325],
         [190.890],
         [192.011],
         [174.532],
         [187.850],
         [179.220]],

        [[164.429],
         [171.313],
         [176.140],
         [189.785],
         [166.295],
         [165.493],
         [185.384],
         [178.313],
         [208.723],
         [188.110]],

        [[160.854],
         [190.990],
         [118.306],
         [184.767],
         [184.754],
         [156.752],
         [189.795],
         [200.190],
         [149.263],
         [174.974]],

        [[178.722],
         [174.511],
         [183.027],
         [164.162],
         [159.756],
         [198.997],
         [195.133],
         [188.659],
         [166.847],
         [167.142]],

        [[198.994],
         [185.794],
         [189.226],
         [175.695],
         [182.386],
         [171.950],
         [128.265],
         [192.639],
         [160.593],
         [180.212]],

        [[158.357],
         [174.881],
         [172.666],
         [201.433],
         [169.314],
         [159.943],
         [202.525],
         [190.772],
         [187.189],
         [170.491]],

        [[194.645],
         [197.277],
         [205.485],
         [181.659],
         [185.175],
         [196.092],
         [173.166],
         [200.400],
         [184.488],
         [159.050]],

        [[171.255],
         [179.816],
         [199.312],
         [163.925],
         [198.174],
         [180.954],
         [174.547],
         [202.027],
         [216.064],
         [170.572]],

        [[192.194],
         [189.756],
         [189.957],
         [199.417],
         [192.418],
         [170.771],
         [171.385],
         [206.521],
         [190.987],
         [140.267]]], device='cuda:0')
clipping threshold 0.2879795919372675
a after update for 1 param tensor([[-0.184],
        [-0.290],
        [-0.136],
        [-0.153],
        [ 0.037],
        [-0.939],
        [-0.140],
        [-0.555],
        [-0.519],
        [ 0.237],
        [ 0.186],
        [-0.160],
        [ 0.501],
        [ 0.132],
        [-0.585],
        [ 0.188],
        [-0.625],
        [-0.210],
        [-0.240],
        [-0.167],
        [-0.540],
        [-0.242],
        [ 0.252],
        [-0.026],
        [ 0.891],
        [-0.176],
        [ 0.575],
        [-0.580],
        [ 0.068],
        [-0.428]], device='cuda:0')
s after update for 1 param tensor([[1.989],
        [1.899],
        [1.380],
        [2.148],
        [1.960],
        [2.162],
        [1.745],
        [2.115],
        [2.082],
        [1.063],
        [1.891],
        [1.729],
        [1.644],
        [1.556],
        [1.822],
        [2.068],
        [2.108],
        [1.351],
        [1.826],
        [1.444],
        [1.975],
        [1.912],
        [1.506],
        [2.423],
        [2.154],
        [1.360],
        [1.952],
        [1.789],
        [1.435],
        [2.052]], device='cuda:0')
b after update for 1 param tensor([[189.835],
        [185.482],
        [158.132],
        [197.266],
        [188.412],
        [197.898],
        [177.783],
        [195.713],
        [194.218],
        [138.762],
        [185.084],
        [176.971],
        [172.586],
        [167.860],
        [181.677],
        [193.562],
        [195.426],
        [156.424],
        [181.864],
        [161.706],
        [189.139],
        [186.103],
        [165.184],
        [209.503],
        [197.541],
        [156.978],
        [188.026],
        [180.021],
        [161.248],
        [192.783]], device='cuda:0')
clipping threshold 0.2879795919372675
||w||^2 0.0665747270056284
exp ma of ||w||^2 0.057578441552653355
||w|| 0.2580207879331206
exp ma of ||w|| 0.2384092821248297
||w||^2 0.04430791258123676
exp ma of ||w||^2 0.04696436498181918
||w|| 0.21049444786320792
exp ma of ||w|| 0.2139614187971918
||w||^2 0.05607876568129572
exp ma of ||w||^2 0.04417124404410378
||w|| 0.23680955572209436
exp ma of ||w|| 0.20676966031767846
||w||^2 0.03428861489223857
exp ma of ||w||^2 0.04477495382965763
||w|| 0.18517185232167055
exp ma of ||w|| 0.20836093537351272
||w||^2 0.03357865860421597
exp ma of ||w||^2 0.041426365716062064
||w|| 0.18324480512204425
exp ma of ||w|| 0.19997333599935055
||w||^2 0.041074502596688475
exp ma of ||w||^2 0.04044158099121938
||w|| 0.20266845486332716
exp ma of ||w|| 0.1971987721243798
||w||^2 0.03107463604455164
exp ma of ||w||^2 0.04058834541130893
||w|| 0.17627999331901406
exp ma of ||w|| 0.19830225710792795
||w||^2 0.03751569883794257
exp ma of ||w||^2 0.042642716456465744
||w|| 0.1936896972942613
exp ma of ||w|| 0.20347473509307715
cuda
Objective function 30.31 = squared loss an data 29.02 + 0.5*rho*h**2 0.281336 + alpha*h 0.380680 + L2reg 0.43 + L1reg 0.20 ; SHD = 66 ; DAG True
Proportion of microbatches that were clipped  0.7549530761209593
iteration 2 in inner loop, alpha 160.48439618897382 rho 100000.0 h 0.0023720699140739043
iteration 4 in outer loop, alpha = 397.6913875963643, rho = 100000.0, h = 0.0023720699140739043
cuda
9630
cuda
Objective function 30.87 = squared loss an data 29.02 + 0.5*rho*h**2 0.281336 + alpha*h 0.943352 + L2reg 0.43 + L1reg 0.20 ; SHD = 66 ; DAG True
||w||^2 2021663125.2349708
exp ma of ||w||^2 743308806645.5574
||w|| 44962.90832714195
exp ma of ||w|| 417496.6459506414
||w||^2 12616559.843232682
exp ma of ||w||^2 189777200003.72446
||w|| 3551.9797076042933
exp ma of ||w|| 119232.06421120142
||w||^2 2202.8369305901574
exp ma of ||w||^2 9214218507.040289
||w|| 46.9343896369193
exp ma of ||w|| 6066.985539901182
||w||^2 0.1884336301718176
exp ma of ||w||^2 0.2288489524674687
||w|| 0.4340894264685764
exp ma of ||w|| 0.4744113306884953
||w||^2 0.0524641214822478
exp ma of ||w||^2 0.06594051741879162
||w|| 0.229050478022308
exp ma of ||w|| 0.25555195647986995
v before min max tensor([[-12.770, -20.963, -19.874,  ..., 207.807, -11.792,  -0.664],
        [ 21.134, 150.116, -22.681,  ...,  12.392, -26.409, -30.091],
        [-12.712, -23.520, -32.075,  ..., -24.997,  55.275,  11.034],
        ...,
        [ 36.164,   5.495, -22.243,  ..., -22.949,   1.485, -36.244],
        [-25.335, -13.409, -20.568,  ..., -13.491,  -3.101, -34.524],
        [ 26.402, -26.611, -24.046,  ..., -22.630, -23.545, 119.111]],
       device='cuda:0')
v tensor([[1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e+01, 1.000e-12,
         1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e-12,  ..., 1.000e+01, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         1.000e+01],
        ...,
        [1.000e+01, 5.495e+00, 1.000e-12,  ..., 1.000e-12, 1.485e+00,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e+01]], device='cuda:0')
v before min max tensor([-24.115,  34.383, -21.330,  -8.273, -21.427, -27.407, -29.136, -15.537,
          0.354,  -5.914,   1.821, 116.607,  -3.148,  -7.383, -22.629, -19.875,
        -20.221,  -0.410, -18.504, 120.708,  10.446, -16.370,  84.066,   9.851,
         18.251, -23.364, -20.609,  -8.213, -15.987, -24.139, -15.261,  15.726,
         15.972, -26.026, -25.289, -21.699, -12.158, -14.981, -10.880,  -3.894,
        -19.417,  31.929, -23.739, 168.108,   1.094,  -6.740, -23.617,  36.536,
        303.829,   1.643,  53.471,  18.455,  -3.946, 149.939, -25.997,  -3.747,
        -14.214, -22.983, -19.112,   5.317, -14.147, -14.917,  81.912, -19.342,
        -11.594,  83.459, -12.981, -10.308,  -0.718,  45.779,   7.943,   6.354,
          3.402, -23.468, -17.534, -19.345, -18.889, -22.117,  14.313,  86.798,
        -13.596,  45.487,   1.843,  -4.235, -20.321,  36.741, -19.246,  17.949,
         52.115, -28.105, -25.351,  60.838, -13.737, 144.420, -18.358, -16.649,
        -21.484,  -8.478,  53.705, -15.198, -26.246, -22.833, -22.294,  11.345,
        -31.419, -20.845, -27.864,  15.423, -17.394,  93.252,  22.756, -29.514,
        -16.955,   4.816,  -3.372, -25.576, -16.884,  99.070, -13.633, -29.037,
         70.249, -18.478,  -0.753,  96.894,  -7.294,   8.916,  50.483,  18.182,
        -14.053, -19.866,   4.654, -32.151, -15.083,  37.864,  50.784, -25.742,
         28.195, -17.306, -24.681, 139.306,   7.167,  13.668,  -6.161, -29.851,
        -34.490, 267.496, -13.365, -26.874,  31.320, -18.666,  -3.103, -27.949,
        -24.508, -18.640, -24.735,  69.304,  -4.348,  53.358, -17.065, -18.517,
        -27.588, -17.186, -23.701, -33.731, -12.092, -21.414,  30.338, -16.072,
        -25.139, -18.529, -34.867,  -3.919, -22.261, -20.535,  94.999, -26.584,
          8.867,  63.600, -18.345, -14.227, -16.570,  -2.047,   4.487,   1.307,
         55.969, -26.728,   3.180, -30.506,  64.764, -14.324, -22.385, -18.862,
         15.594,  25.976, -18.878,  -9.830, -18.348, -23.735, -32.971,  -9.264,
         69.333, -17.338, -18.807,  51.089,  28.667,  57.094,  -3.075, -22.234,
        -21.018, -15.993, -27.292,  19.615, -25.324, -12.065, -29.538,  19.288,
         70.788, -16.198, -24.337, -31.155, -27.601, -13.177,  10.445, -20.908,
          0.827,  10.339, -29.979, -14.635,  77.499,  -3.163,  56.351, -10.815,
        -22.913,   1.642,  -6.408, -32.562,  28.097, -23.615, -27.156, -21.867,
         -2.847, 160.774, -13.497, -34.179,  -6.619,  30.772,  30.855,   0.383,
        -28.778, -19.849, -26.780, -11.414,  85.971, -10.847,  16.735, -21.175,
         73.053, -25.849,   6.978,  -5.225,  16.202,  11.619, -26.239, -30.601,
        -25.844, -15.425,   3.188, -25.684,   5.802, -21.776, -21.436,  28.277,
         -8.898, 106.066, -33.339, -28.083, -11.162,  36.890, -17.523, -21.486,
          8.534,  58.794, 140.767,  73.992,  18.017,  57.886, -22.856, -13.376,
        -28.064,  17.993,  -4.892, -19.170,  25.120, -23.664, -27.917,   0.360,
        -34.572, -25.056, -33.381, -14.191], device='cuda:0')
v tensor([1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 3.542e-01, 1.000e-12, 1.821e+00, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 9.851e+00,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.094e+00, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.643e+00, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.317e+00,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 7.943e+00, 6.354e+00,
        3.402e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.843e+00, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 4.816e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 8.916e+00,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 4.654e+00, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 7.167e+00, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 8.867e+00, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 4.487e+00, 1.307e+00, 1.000e+01, 1.000e-12,
        3.180e+00, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 8.265e-01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.642e+00,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 3.831e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        6.978e+00, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 3.188e+00, 1.000e-12, 5.802e+00, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 8.534e+00, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 3.595e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-1.522e+01],
         [-1.227e+01],
         [-1.045e+01],
         [ 2.771e+01],
         [-2.416e+01],
         [-1.646e+01],
         [ 7.665e+01],
         [-1.022e+01],
         [ 3.331e+00],
         [-2.266e+01]],

        [[-1.677e+01],
         [ 1.970e+01],
         [-2.309e+01],
         [-1.465e+01],
         [-1.842e+01],
         [ 6.582e+01],
         [-2.727e+01],
         [-2.249e+01],
         [ 4.392e+00],
         [ 6.838e+01]],

        [[ 1.724e+01],
         [-2.286e+01],
         [-2.692e+01],
         [-2.827e+01],
         [-1.654e+01],
         [ 4.017e-01],
         [-2.249e+01],
         [-3.078e+01],
         [-2.119e+01],
         [-3.314e+01]],

        [[-2.210e+01],
         [ 6.168e+01],
         [-1.790e+01],
         [-1.189e+01],
         [-2.181e+01],
         [-3.127e+01],
         [-1.499e+01],
         [-1.976e+01],
         [-2.028e+01],
         [ 6.450e+01]],

        [[-1.003e+01],
         [ 2.601e+02],
         [-9.669e+00],
         [ 3.518e+01],
         [-2.510e+01],
         [ 5.081e+01],
         [-1.394e+01],
         [-2.602e+00],
         [ 7.995e+01],
         [-9.821e+00]],

        [[ 1.037e+02],
         [-2.227e+01],
         [-2.832e+01],
         [ 3.625e+01],
         [ 1.174e+02],
         [-2.837e+01],
         [ 3.453e+01],
         [-2.102e+01],
         [-2.515e+01],
         [-2.443e+01]],

        [[ 4.193e+01],
         [ 1.284e+00],
         [-5.698e+00],
         [ 2.302e+01],
         [ 7.828e+01],
         [-3.288e+00],
         [-4.438e+00],
         [ 1.248e+02],
         [-2.042e+01],
         [-2.432e+01]],

        [[-2.527e+01],
         [ 1.865e+02],
         [-2.704e+01],
         [-2.383e+01],
         [-2.013e+01],
         [ 2.336e+01],
         [ 1.710e+02],
         [ 4.030e+02],
         [-1.844e+01],
         [-6.868e+00]],

        [[-2.341e+01],
         [-1.421e+01],
         [-9.714e+00],
         [-1.899e+01],
         [ 1.343e+01],
         [-1.848e+01],
         [ 1.335e+01],
         [ 4.530e+01],
         [ 4.476e+01],
         [-1.958e+01]],

        [[ 2.511e+01],
         [ 3.171e+00],
         [-3.439e+01],
         [ 1.002e+01],
         [-1.985e+01],
         [-2.411e+01],
         [-2.646e+01],
         [-2.931e+01],
         [-7.884e+00],
         [-1.565e+01]],

        [[-1.290e+01],
         [-2.347e+01],
         [-2.283e+01],
         [-2.113e+01],
         [-5.963e+00],
         [ 1.211e+02],
         [-4.452e+00],
         [-1.701e+01],
         [-1.098e+01],
         [ 1.222e+01]],

        [[ 5.334e+01],
         [-8.040e+00],
         [ 3.387e+00],
         [-1.838e+01],
         [-2.723e+01],
         [-1.907e+01],
         [-2.048e+01],
         [-1.680e+01],
         [-2.664e+01],
         [ 4.600e+01]],

        [[-3.682e+01],
         [-2.499e+01],
         [-1.795e+01],
         [ 5.852e+01],
         [-2.354e+01],
         [-2.309e+01],
         [ 1.603e+02],
         [-6.520e-01],
         [-2.443e+01],
         [ 1.640e+02]],

        [[-2.420e+01],
         [ 1.275e+02],
         [ 8.484e+00],
         [-4.663e+00],
         [-2.154e+01],
         [-2.440e+01],
         [ 5.513e+01],
         [-3.413e+01],
         [ 3.092e+01],
         [-1.668e+01]],

        [[-3.302e+01],
         [ 6.081e+01],
         [ 2.684e+01],
         [-9.779e+00],
         [-3.455e+01],
         [ 3.921e+00],
         [-2.653e+01],
         [-3.099e+01],
         [-1.561e+01],
         [-2.466e+01]],

        [[-2.460e+01],
         [-1.217e+01],
         [-2.446e+01],
         [ 4.690e+01],
         [ 1.693e+01],
         [ 6.747e+00],
         [ 7.189e+01],
         [-2.223e+01],
         [-7.218e+00],
         [ 1.740e+01]],

        [[-2.203e+01],
         [ 1.742e+02],
         [-2.142e+01],
         [-2.034e+01],
         [-1.884e+01],
         [-3.018e+01],
         [ 2.008e+01],
         [-1.894e+01],
         [ 1.492e+02],
         [-2.131e+01]],

        [[-3.057e+01],
         [-2.436e+01],
         [-8.760e+00],
         [ 1.238e+01],
         [-2.989e+00],
         [-1.068e+01],
         [-2.148e+01],
         [ 1.358e+01],
         [-6.943e+00],
         [-1.388e+01]],

        [[ 2.019e+01],
         [-3.112e+01],
         [ 9.033e+00],
         [-1.586e+01],
         [-1.548e+01],
         [-2.617e+00],
         [ 6.899e+01],
         [-2.347e+01],
         [-2.325e+01],
         [-2.778e+01]],

        [[-2.387e+01],
         [ 1.045e+01],
         [-1.813e+01],
         [ 1.966e+01],
         [-2.453e+01],
         [ 3.356e+01],
         [ 1.331e+01],
         [-1.730e+01],
         [-3.513e+00],
         [ 1.911e+01]],

        [[-2.975e+01],
         [ 1.302e+01],
         [ 1.723e+01],
         [-2.276e+01],
         [ 9.350e+01],
         [-1.602e+01],
         [-2.565e+01],
         [ 3.769e+00],
         [-3.066e+01],
         [-2.678e+01]],

        [[-7.602e+00],
         [ 5.770e+01],
         [-1.960e+01],
         [ 5.523e+00],
         [ 1.780e+01],
         [-3.610e+00],
         [-2.176e+01],
         [-1.447e+01],
         [-2.205e+01],
         [-1.644e+01]],

        [[-2.574e+01],
         [-1.657e+01],
         [-9.337e+00],
         [ 5.955e+00],
         [-2.268e+01],
         [-2.572e+01],
         [-1.908e+01],
         [-2.736e+01],
         [ 2.590e+01],
         [-1.352e+01]],

        [[ 1.112e+02],
         [-2.486e+01],
         [-1.667e+01],
         [ 3.001e+00],
         [ 3.948e+01],
         [-2.668e+01],
         [-1.135e+01],
         [-3.202e+01],
         [ 1.228e+00],
         [ 1.850e+01]],

        [[-1.063e+01],
         [ 2.410e+01],
         [-2.201e+01],
         [-3.373e+01],
         [-2.378e+01],
         [ 1.425e+01],
         [ 6.536e+00],
         [-7.618e+00],
         [ 6.090e+01],
         [-1.916e+01]],

        [[ 1.715e+00],
         [-2.068e+01],
         [-1.480e+01],
         [ 2.785e+01],
         [-2.744e+01],
         [-3.038e+01],
         [ 3.366e+00],
         [-2.467e+01],
         [ 2.367e+01],
         [-2.783e+01]],

        [[ 2.139e+01],
         [-2.224e+01],
         [-6.302e+00],
         [-2.149e+01],
         [-2.193e+01],
         [ 7.887e+01],
         [-2.472e+01],
         [-1.371e+01],
         [-2.922e+01],
         [-1.498e+01]],

        [[-2.296e+01],
         [ 3.123e+00],
         [-1.024e+00],
         [-2.729e+01],
         [-1.812e+01],
         [-1.097e+01],
         [-1.696e+01],
         [-1.239e+01],
         [-2.629e+01],
         [-2.446e+01]],

        [[-1.395e+01],
         [-3.088e+01],
         [-1.591e+01],
         [-2.669e+01],
         [-2.090e+01],
         [ 2.294e+01],
         [-3.850e+01],
         [ 2.540e+01],
         [ 1.668e+02],
         [-2.873e+01]],

        [[ 4.255e+00],
         [-2.806e+01],
         [ 5.550e+01],
         [ 3.023e+01],
         [ 1.824e+01],
         [-2.815e+01],
         [-3.052e+01],
         [-1.458e+01],
         [-1.466e+01],
         [ 2.259e+02]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [3.331e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [4.392e+00],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.017e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.284e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [3.171e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [3.387e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [8.484e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [3.921e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [6.747e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [9.033e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [3.769e+00],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [5.523e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.955e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [3.001e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.228e+00],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [6.536e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.715e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [3.366e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [3.123e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[4.255e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]]], device='cuda:0')
v before min max tensor([[ 32.317],
        [  5.046],
        [138.147],
        [ 39.831],
        [  7.031],
        [ -2.375],
        [ -4.491],
        [  2.234],
        [-26.097],
        [ 51.041],
        [-29.558],
        [-23.226],
        [-23.766],
        [-10.910],
        [-18.020],
        [ 60.377],
        [  0.822],
        [-16.174],
        [ -8.394],
        [ 48.681],
        [ 10.214],
        [125.966],
        [  4.500],
        [127.725],
        [-18.717],
        [ 23.669],
        [ -0.446],
        [-26.051],
        [-23.319],
        [ -7.605]], device='cuda:0')
v tensor([[1.000e+01],
        [5.046e+00],
        [1.000e+01],
        [1.000e+01],
        [7.031e+00],
        [1.000e-12],
        [1.000e-12],
        [2.234e+00],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [8.217e-01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e+01],
        [4.500e+00],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-4.792e-02, -1.846e-01, -1.499e-01,  ..., -1.207e-01,  8.302e-02,
          8.868e-02],
        [ 3.793e-02,  1.830e-01, -2.293e-01,  ..., -3.536e-04,  9.642e-02,
         -1.932e-01],
        [-2.930e-02,  2.174e-01,  3.851e-02,  ...,  8.159e-02,  3.217e-03,
         -2.393e-01],
        ...,
        [ 1.422e-01, -4.396e-01,  1.341e-01,  ..., -2.746e-01,  2.014e-01,
         -3.461e-03],
        [ 4.067e-02, -2.025e-01,  1.283e-01,  ...,  1.731e-01,  2.294e-02,
         -9.611e-03],
        [ 9.202e-02,  2.203e-01, -7.225e-02,  ...,  9.906e-02,  1.396e-01,
          5.934e-03]], device='cuda:0')
s after update for 1 param tensor([[2.367, 1.316, 1.259,  ..., 2.376, 1.582, 2.006],
        [2.323, 2.200, 2.187,  ..., 1.661, 1.695, 1.957],
        [2.317, 1.905, 2.013,  ..., 1.547, 1.894, 2.012],
        ...,
        [1.953, 1.800, 1.442,  ..., 1.455, 1.398, 2.245],
        [1.755, 1.932, 1.641,  ..., 1.305, 1.798, 2.258],
        [2.290, 1.723, 1.488,  ..., 1.401, 1.538, 2.540]], device='cuda:0')
b after update for 1 param tensor([[199.185, 148.490, 145.234,  ..., 199.547, 162.859, 183.353],
        [197.304, 192.010, 191.475,  ..., 166.842, 168.528, 181.130],
        [197.071, 178.682, 183.704,  ..., 161.001, 178.185, 183.627],
        ...,
        [180.935, 173.706, 155.489,  ..., 156.183, 153.088, 193.975],
        [171.491, 179.959, 165.827,  ..., 147.867, 173.572, 194.535],
        [195.901, 169.937, 157.902,  ..., 153.221, 160.550, 206.329]],
       device='cuda:0')
clipping threshold 0.20924835860936417
a after update for 1 param tensor([ 0.553, -0.419, -0.241, -0.168,  0.209, -0.066, -0.002, -0.183,  0.161,
        -0.270, -0.415, -0.043, -0.346, -0.086, -0.484, -0.259, -0.255, -0.254,
        -0.155, -0.296, -0.523, -0.324, -0.063, -0.178,  0.027, -0.483,  0.142,
         0.364, -0.453,  0.054,  0.104,  0.275, -0.509, -0.066,  0.193,  0.236,
         0.467,  0.033,  0.456,  0.167, -0.019,  0.123, -0.099, -0.646, -0.325,
        -0.125, -0.035, -0.445,  0.217,  0.721, -0.548, -0.550,  0.060,  0.036,
         0.240, -0.141,  0.329,  0.188, -0.561,  0.255, -0.311, -0.276, -0.027,
        -0.276,  0.048,  0.695, -0.029, -0.567, -0.378,  0.350,  0.002,  0.286,
        -0.465,  0.238, -0.239,  0.187, -0.023, -0.530, -0.459,  0.160, -0.213,
        -0.537,  0.105,  0.752,  0.256,  0.309, -0.239, -0.112,  0.084, -0.033,
         0.095,  0.470,  0.124,  0.540, -0.142, -0.580,  0.072, -0.231,  0.126,
         0.095, -0.060,  0.155,  0.300, -0.559, -0.223,  0.321,  0.079,  0.166,
         0.274, -0.602,  0.604,  0.131, -0.652, -0.159,  0.152,  0.080,  0.257,
        -0.362,  0.036,  0.042, -0.418,  0.338,  0.107, -0.004, -0.090,  0.176,
         0.245, -0.038,  0.113, -0.308,  0.255, -0.923, -0.497,  0.103,  0.244,
         0.377, -0.316,  0.201,  0.175, -0.451, -0.332, -0.011, -0.549,  0.112,
        -0.461, -0.115,  0.012, -0.834, -0.253,  0.066,  0.308, -0.052,  0.346,
         0.042,  0.228, -0.042, -0.419,  0.178, -0.008,  0.162, -0.080, -0.093,
         0.037, -0.365,  0.342, -0.277,  0.516, -0.334,  0.140, -0.204,  0.742,
         0.159,  0.224, -0.398, -0.048, -0.292,  0.006,  0.118,  0.218, -0.305,
         0.182,  0.374, -0.353, -0.233,  0.035, -0.229, -0.313,  0.278, -0.166,
         0.057, -0.529,  0.237,  0.069,  0.213,  0.313, -0.108, -0.317,  0.135,
         0.603, -0.402,  0.396,  0.264, -0.125,  0.110,  0.076,  0.786, -0.071,
         0.679,  0.071, -0.492, -0.349,  0.147,  0.219,  0.254,  0.012,  0.210,
         0.620, -0.483,  0.232, -0.117,  0.468,  0.203, -0.920, -0.212,  0.217,
         0.169,  0.121,  0.018,  0.444,  0.150,  0.391,  0.246, -0.325, -0.033,
         0.336, -0.183, -0.097,  0.497,  0.065, -0.273, -0.280,  0.431,  0.210,
        -0.325, -0.242, -0.138,  0.101, -0.348,  0.459,  0.077,  0.135,  0.051,
        -0.310,  0.093,  0.515, -0.394, -0.049,  0.518, -0.033,  0.173,  0.719,
         0.479, -0.369,  0.171,  0.128, -0.247, -0.003,  0.213,  0.279, -0.358,
         0.024, -0.324, -0.250, -0.638, -0.294, -0.580,  0.666,  0.495,  0.148,
        -0.081, -0.221, -0.043, -0.162, -0.172,  0.238,  0.153, -0.396,  0.030,
        -0.341,  0.110, -0.093,  0.319,  0.628,  0.433,  0.169, -0.123,  0.430,
        -0.048, -0.460,  0.282], device='cuda:0')
s after update for 1 param tensor([1.499, 1.623, 2.175, 1.760, 1.483, 1.857, 1.804, 1.726, 1.653, 0.994,
        1.348, 1.558, 1.998, 1.370, 2.019, 1.397, 1.271, 1.616, 1.726, 2.246,
        2.107, 1.710, 1.534, 1.998, 1.970, 1.842, 1.761, 1.364, 1.845, 1.494,
        1.414, 1.638, 2.076, 1.707, 1.571, 1.772, 1.615, 0.967, 1.649, 1.714,
        1.612, 1.854, 1.490, 2.373, 1.648, 1.808, 1.534, 1.868, 2.206, 1.826,
        2.017, 2.283, 1.584, 1.792, 1.718, 1.667, 1.464, 1.782, 1.950, 1.650,
        2.050, 1.541, 1.625, 1.947, 1.276, 2.288, 2.231, 1.566, 1.197, 1.639,
        1.895, 1.801, 1.826, 2.271, 2.181, 1.197, 1.188, 1.801, 2.220, 2.210,
        1.393, 1.945, 1.620, 1.996, 1.273, 1.997, 1.874, 1.757, 1.992, 1.741,
        1.614, 2.142, 1.394, 2.150, 1.483, 1.362, 1.739, 1.583, 2.079, 1.084,
        1.678, 1.553, 1.516, 2.035, 2.315, 1.807, 1.759, 1.896, 1.166, 2.204,
        2.026, 1.841, 1.683, 1.751, 1.494, 1.838, 1.831, 2.034, 1.691, 1.917,
        2.015, 1.796, 1.760, 1.786, 1.819, 2.041, 2.336, 2.073, 1.414, 1.548,
        2.188, 2.248, 1.291, 1.688, 1.779, 1.611, 1.677, 1.282, 1.823, 1.912,
        1.816, 1.564, 2.344, 1.867, 2.340, 1.964, 0.978, 1.750, 1.533, 1.157,
        1.496, 1.779, 1.713, 1.734, 1.616, 1.873, 1.799, 2.143, 1.853, 1.174,
        1.825, 1.140, 2.086, 2.092, 1.724, 1.487, 1.544, 1.041, 1.612, 1.304,
        2.294, 0.996, 1.411, 1.441, 1.989, 1.688, 2.225, 1.865, 1.135, 1.060,
        1.233, 1.977, 1.619, 1.753, 1.852, 1.711, 1.673, 1.929, 2.416, 2.203,
        1.764, 1.230, 1.752, 1.728, 1.822, 1.338, 1.661, 1.856, 2.186, 1.832,
        1.624, 1.770, 1.181, 1.887, 1.795, 1.827, 1.394, 1.559, 1.939, 1.660,
        2.030, 1.940, 1.758, 1.176, 1.830, 1.906, 2.266, 1.573, 1.528, 1.929,
        1.910, 1.018, 2.478, 1.353, 2.028, 1.645, 1.912, 1.205, 2.125, 1.750,
        2.024, 1.825, 1.465, 1.778, 1.773, 2.015, 1.984, 1.573, 1.719, 1.366,
        1.763, 1.646, 1.017, 2.122, 1.190, 1.961, 2.174, 1.370, 1.782, 1.259,
        1.669, 1.713, 1.710, 1.062, 1.938, 1.505, 1.857, 1.864, 1.983, 1.864,
        2.211, 2.068, 1.995, 1.932, 1.610, 1.694, 1.097, 1.653, 1.584, 1.427,
        1.655, 2.102, 1.897, 1.871, 2.193, 1.779, 1.808, 1.855, 1.998, 1.423,
        1.686, 2.293, 2.041, 2.161, 1.822, 2.242, 1.619, 1.023, 1.786, 1.629,
        0.893, 1.818, 2.032, 1.532, 1.759, 1.372, 2.252, 1.863, 2.088, 1.402],
       device='cuda:0')
b after update for 1 param tensor([158.515, 164.952, 190.936, 171.748, 157.681, 176.424, 173.898, 170.082,
        166.456, 129.089, 150.310, 161.607, 183.014, 151.508, 183.953, 153.005,
        145.968, 164.596, 170.096, 194.042, 187.916, 169.315, 160.326, 182.996,
        181.697, 175.716, 171.787, 151.221, 175.860, 158.229, 153.972, 165.683,
        186.545, 169.132, 162.245, 172.323, 164.543, 127.322, 166.266, 169.490,
        164.389, 176.270, 158.040, 199.426, 166.213, 174.091, 160.355, 176.951,
        192.299, 174.920, 183.859, 195.600, 162.961, 173.296, 169.713, 167.152,
        156.632, 172.833, 180.786, 166.290, 185.367, 160.688, 165.026, 180.639,
        146.220, 195.846, 193.361, 162.033, 141.624, 165.740, 178.208, 173.748,
        174.919, 195.103, 191.207, 141.665, 141.124, 173.726, 192.876, 192.478,
        152.782, 180.554, 164.775, 182.895, 146.045, 182.937, 177.235, 171.625,
        182.740, 170.807, 164.469, 189.491, 152.856, 189.839, 157.647, 151.070,
        170.708, 162.903, 186.679, 134.798, 167.699, 161.326, 159.408, 184.685,
        196.961, 174.053, 171.716, 178.251, 139.769, 192.188, 184.288, 175.663,
        167.929, 171.334, 158.250, 175.538, 175.157, 184.653, 168.368, 179.234,
        183.770, 173.517, 171.760, 173.033, 174.621, 184.976, 197.858, 186.404,
        153.959, 161.063, 191.499, 194.127, 147.091, 168.179, 172.679, 164.296,
        167.661, 146.597, 174.817, 179.032, 174.470, 161.899, 198.210, 176.898,
        198.041, 181.441, 128.023, 171.273, 160.274, 139.230, 158.372, 172.656,
        169.423, 170.479, 164.578, 177.170, 173.656, 189.539, 176.207, 140.291,
        174.911, 138.205, 186.996, 187.243, 169.967, 157.844, 160.885, 132.120,
        164.363, 147.841, 196.097, 129.227, 153.762, 155.399, 182.574, 168.215,
        193.126, 176.803, 137.915, 133.266, 143.750, 182.042, 164.731, 171.423,
        176.199, 169.366, 167.440, 179.830, 201.240, 192.166, 171.951, 143.560,
        171.350, 170.196, 174.731, 149.771, 166.853, 176.388, 191.397, 175.220,
        164.971, 172.241, 140.667, 177.858, 173.440, 174.973, 152.838, 161.632,
        180.270, 166.819, 184.446, 180.315, 171.657, 140.411, 175.142, 178.721,
        194.872, 162.347, 160.033, 179.802, 178.910, 130.635, 203.793, 150.606,
        184.377, 166.031, 179.036, 142.089, 188.725, 171.240, 184.179, 174.885,
        156.683, 172.649, 172.367, 183.762, 182.340, 162.365, 169.755, 151.323,
        171.895, 166.103, 130.540, 188.570, 141.252, 181.302, 190.904, 151.518,
        172.820, 145.275, 167.251, 169.443, 169.310, 133.398, 180.248, 158.821,
        176.413, 176.740, 182.327, 176.752, 192.495, 186.170, 182.856, 179.958,
        164.265, 168.509, 135.606, 166.429, 162.934, 154.657, 166.541, 187.693,
        178.329, 177.067, 191.730, 172.652, 174.066, 176.329, 183.012, 154.429,
        168.086, 196.050, 184.958, 190.316, 174.758, 193.855, 164.715, 130.973,
        172.991, 165.259, 122.369, 174.556, 184.560, 160.262, 171.701, 151.668,
        194.297, 176.705, 187.072, 153.304], device='cuda:0')
clipping threshold 0.20924835860936417
a after update for 1 param tensor([[[-0.176],
         [ 0.528],
         [ 0.146],
         [ 0.341],
         [-0.185],
         [-0.010],
         [ 0.290],
         [-0.173],
         [ 0.275],
         [-0.190]],

        [[-0.318],
         [-0.069],
         [ 0.452],
         [ 0.053],
         [ 0.027],
         [-0.025],
         [ 0.204],
         [-0.109],
         [-0.208],
         [ 0.242]],

        [[ 0.398],
         [ 0.566],
         [-0.196],
         [-0.184],
         [-0.502],
         [ 0.089],
         [-0.389],
         [ 0.031],
         [ 0.287],
         [ 0.311]],

        [[-0.677],
         [ 0.841],
         [ 0.179],
         [ 0.304],
         [-0.437],
         [ 0.698],
         [-0.203],
         [-0.653],
         [ 0.418],
         [ 0.401]],

        [[ 0.247],
         [ 0.048],
         [-0.206],
         [ 0.046],
         [-0.183],
         [-0.233],
         [-0.174],
         [ 0.340],
         [ 0.108],
         [ 0.450]],

        [[-0.456],
         [ 0.072],
         [ 0.173],
         [-0.018],
         [-0.176],
         [-0.189],
         [-0.033],
         [ 0.280],
         [-0.415],
         [ 0.308]],

        [[-0.366],
         [-0.172],
         [ 0.211],
         [-0.088],
         [ 0.287],
         [ 0.273],
         [-0.443],
         [ 0.262],
         [ 0.433],
         [-0.267]],

        [[-0.070],
         [-0.201],
         [-0.140],
         [ 0.220],
         [ 0.321],
         [ 0.211],
         [-0.064],
         [-0.519],
         [-0.054],
         [ 0.290]],

        [[ 0.024],
         [ 0.059],
         [-0.073],
         [-0.348],
         [-0.013],
         [ 0.187],
         [-0.248],
         [-0.512],
         [ 0.201],
         [-0.258]],

        [[ 0.123],
         [ 0.096],
         [-0.080],
         [-0.269],
         [-0.086],
         [-0.004],
         [-0.199],
         [-0.069],
         [-0.238],
         [-0.170]],

        [[-0.324],
         [-0.276],
         [ 0.206],
         [-0.408],
         [-0.126],
         [ 0.375],
         [ 0.043],
         [-0.048],
         [ 0.090],
         [ 0.229]],

        [[-0.102],
         [ 0.141],
         [ 0.276],
         [ 0.340],
         [ 0.481],
         [-0.699],
         [-0.456],
         [-0.075],
         [ 0.417],
         [ 0.296]],

        [[-0.134],
         [ 0.208],
         [-0.278],
         [-0.619],
         [ 0.466],
         [ 0.301],
         [ 0.101],
         [-0.151],
         [ 0.139],
         [-0.603]],

        [[-0.473],
         [ 0.017],
         [-0.262],
         [ 0.312],
         [ 0.265],
         [ 0.014],
         [ 0.030],
         [ 0.312],
         [-0.566],
         [-0.239]],

        [[-0.407],
         [-0.053],
         [-0.310],
         [ 0.406],
         [ 0.276],
         [ 0.052],
         [ 0.463],
         [-0.140],
         [ 0.161],
         [-0.429]],

        [[ 0.429],
         [ 0.363],
         [ 0.074],
         [-0.054],
         [ 0.213],
         [-0.234],
         [-0.105],
         [ 0.251],
         [-0.475],
         [-0.080]],

        [[-0.390],
         [-0.739],
         [-0.192],
         [ 0.099],
         [-0.047],
         [-0.675],
         [ 0.287],
         [ 0.347],
         [ 0.173],
         [-0.200]],

        [[-0.106],
         [-0.493],
         [ 0.230],
         [ 0.267],
         [ 0.275],
         [ 0.276],
         [-0.479],
         [-0.094],
         [ 0.040],
         [ 0.297]],

        [[ 0.091],
         [-0.199],
         [ 0.357],
         [-0.276],
         [-0.371],
         [-0.364],
         [ 0.288],
         [ 0.395],
         [ 0.063],
         [ 0.263]],

        [[ 0.360],
         [-0.139],
         [-0.079],
         [-0.122],
         [-0.124],
         [-0.165],
         [-0.160],
         [-0.176],
         [ 0.083],
         [-0.396]],

        [[ 0.249],
         [ 0.462],
         [-0.387],
         [-0.150],
         [ 0.017],
         [ 0.021],
         [ 0.023],
         [ 0.609],
         [ 0.354],
         [-0.513]],

        [[-0.303],
         [ 0.064],
         [ 0.259],
         [ 0.051],
         [-0.342],
         [ 0.263],
         [ 0.185],
         [ 0.071],
         [-0.068],
         [ 0.197]],

        [[-0.320],
         [-0.154],
         [ 0.314],
         [-0.102],
         [ 0.444],
         [-0.174],
         [-0.030],
         [-0.238],
         [ 0.073],
         [-0.003]],

        [[ 0.011],
         [-0.175],
         [ 0.209],
         [-0.480],
         [ 0.172],
         [-0.613],
         [ 0.244],
         [ 0.074],
         [ 0.219],
         [ 0.517]],

        [[ 0.250],
         [-0.482],
         [ 0.086],
         [-0.543],
         [ 0.067],
         [-0.139],
         [-0.596],
         [-0.141],
         [-0.551],
         [-0.560]],

        [[-0.090],
         [-0.045],
         [-0.052],
         [-0.454],
         [-0.397],
         [ 0.291],
         [-0.210],
         [-0.043],
         [-0.468],
         [ 0.448]],

        [[-0.172],
         [-0.286],
         [-0.112],
         [ 0.015],
         [ 0.188],
         [ 0.011],
         [ 0.032],
         [-0.167],
         [-0.325],
         [-0.010]],

        [[ 0.184],
         [-0.046],
         [-0.046],
         [-0.237],
         [-0.089],
         [ 1.064],
         [ 0.217],
         [ 0.037],
         [-0.341],
         [-0.008]],

        [[ 0.025],
         [-0.680],
         [ 0.066],
         [-0.210],
         [ 0.030],
         [-0.219],
         [ 0.001],
         [ 0.421],
         [ 0.546],
         [ 0.587]],

        [[-0.319],
         [ 0.264],
         [ 0.375],
         [ 0.413],
         [-0.262],
         [ 0.342],
         [-0.143],
         [ 0.599],
         [ 0.526],
         [ 0.358]]], device='cuda:0')
s after update for 1 param tensor([[[1.234],
         [1.569],
         [1.618],
         [1.697],
         [1.545],
         [1.777],
         [2.182],
         [1.288],
         [1.930],
         [1.694]],

        [[1.169],
         [1.602],
         [1.519],
         [0.934],
         [1.902],
         [1.838],
         [1.703],
         [1.663],
         [1.619],
         [2.185]],

        [[1.743],
         [1.680],
         [1.766],
         [2.008],
         [1.406],
         [1.389],
         [2.081],
         [1.910],
         [1.337],
         [2.054]],

        [[1.424],
         [2.302],
         [1.531],
         [1.735],
         [1.766],
         [2.082],
         [1.557],
         [1.691],
         [1.816],
         [2.416]],

        [[1.616],
         [1.857],
         [1.464],
         [1.711],
         [1.609],
         [2.243],
         [1.337],
         [1.737],
         [2.014],
         [1.868]],

        [[1.983],
         [1.664],
         [2.014],
         [1.763],
         [1.966],
         [1.794],
         [1.813],
         [1.300],
         [1.683],
         [1.520]],

        [[1.987],
         [1.404],
         [0.844],
         [1.939],
         [1.735],
         [1.431],
         [1.590],
         [1.789],
         [1.780],
         [1.558]],

        [[1.593],
         [2.136],
         [1.762],
         [2.132],
         [1.335],
         [2.311],
         [1.972],
         [2.317],
         [1.394],
         [1.328]],

        [[1.654],
         [1.258],
         [1.525],
         [2.050],
         [1.483],
         [1.273],
         [1.867],
         [2.293],
         [1.985],
         [1.305]],

        [[2.019],
         [1.283],
         [2.194],
         [2.045],
         [1.265],
         [1.724],
         [1.679],
         [1.856],
         [1.724],
         [1.743]],

        [[1.646],
         [2.005],
         [1.611],
         [1.383],
         [1.491],
         [1.624],
         [1.571],
         [1.440],
         [1.501],
         [2.207]],

        [[2.330],
         [1.498],
         [1.404],
         [1.530],
         [1.716],
         [1.641],
         [2.034],
         [1.055],
         [1.760],
         [1.723]],

        [[2.311],
         [1.667],
         [1.763],
         [1.832],
         [1.660],
         [1.871],
         [2.029],
         [1.741],
         [1.837],
         [1.876]],

        [[1.552],
         [1.896],
         [1.610],
         [1.996],
         [1.381],
         [1.516],
         [1.888],
         [2.112],
         [2.196],
         [1.610]],

        [[2.107],
         [2.187],
         [2.145],
         [1.153],
         [2.146],
         [1.760],
         [1.662],
         [1.981],
         [1.440],
         [1.625]],

        [[1.630],
         [1.822],
         [1.536],
         [1.353],
         [1.979],
         [1.637],
         [1.491],
         [2.061],
         [1.521],
         [1.685]],

        [[1.430],
         [2.049],
         [1.350],
         [1.352],
         [1.209],
         [2.010],
         [1.662],
         [1.177],
         [2.479],
         [1.504]],

        [[1.950],
         [2.055],
         [1.915],
         [2.079],
         [0.834],
         [1.433],
         [1.566],
         [1.920],
         [1.684],
         [1.889]],

        [[1.860],
         [1.937],
         [2.074],
         [1.722],
         [1.673],
         [1.726],
         [2.197],
         [1.459],
         [1.729],
         [1.718]],

        [[1.596],
         [1.962],
         [1.216],
         [1.752],
         [1.552],
         [2.034],
         [1.793],
         [1.075],
         [1.805],
         [2.177]],

        [[1.945],
         [2.421],
         [1.730],
         [1.519],
         [2.197],
         [1.453],
         [1.610],
         [2.147],
         [1.977],
         [1.778]],

        [[2.062],
         [1.973],
         [1.352],
         [1.833],
         [1.893],
         [1.896],
         [1.355],
         [1.712],
         [1.534],
         [1.561]],

        [[1.660],
         [1.991],
         [1.576],
         [1.992],
         [2.008],
         [1.832],
         [1.745],
         [1.777],
         [2.400],
         [2.076]],

        [[2.043],
         [1.544],
         [1.534],
         [1.668],
         [1.965],
         [1.653],
         [1.662],
         [2.008],
         [1.687],
         [2.017]],

        [[1.843],
         [2.104],
         [1.608],
         [2.087],
         [1.727],
         [1.787],
         [1.915],
         [1.391],
         [1.970],
         [1.852]],

        [[1.806],
         [1.503],
         [2.105],
         [2.472],
         [1.924],
         [1.922],
         [1.989],
         [1.859],
         [2.080],
         [1.722]],

        [[2.131],
         [1.548],
         [1.031],
         [1.420],
         [1.532],
         [2.454],
         [2.033],
         [1.162],
         [1.810],
         [1.207]],

        [[1.440],
         [1.650],
         [0.955],
         [2.133],
         [1.125],
         [2.193],
         [1.139],
         [1.331],
         [1.635],
         [1.907]],

        [[1.039],
         [1.974],
         [1.177],
         [1.768],
         [1.652],
         [1.655],
         [2.382],
         [2.073],
         [2.236],
         [1.806]],

        [[1.635],
         [1.883],
         [1.619],
         [2.137],
         [2.038],
         [1.836],
         [1.902],
         [2.193],
         [1.816],
         [2.279]]], device='cuda:0')
b after update for 1 param tensor([[[143.797],
         [162.173],
         [164.686],
         [168.651],
         [160.900],
         [172.588],
         [191.255],
         [146.955],
         [179.857],
         [168.515]],

        [[139.995],
         [163.881],
         [159.558],
         [125.111],
         [178.536],
         [175.529],
         [168.937],
         [166.964],
         [164.721],
         [191.385]],

        [[170.934],
         [167.816],
         [172.032],
         [183.454],
         [153.492],
         [152.586],
         [186.769],
         [178.919],
         [149.698],
         [185.552]],

        [[154.504],
         [196.444],
         [160.203],
         [170.525],
         [172.047],
         [186.810],
         [161.549],
         [168.342],
         [174.439],
         [201.224]],

        [[164.554],
         [176.403],
         [156.664],
         [169.367],
         [164.213],
         [193.895],
         [149.668],
         [170.636],
         [183.707],
         [176.932]],

        [[182.293],
         [166.998],
         [183.735],
         [171.882],
         [181.521],
         [173.384],
         [174.329],
         [147.619],
         [167.957],
         [159.615]],

        [[182.495],
         [153.410],
         [118.926],
         [180.253],
         [170.505],
         [154.845],
         [163.264],
         [173.161],
         [172.743],
         [161.603]],

        [[163.394],
         [189.212],
         [171.865],
         [189.019],
         [149.609],
         [196.806],
         [181.812],
         [197.070],
         [152.847],
         [149.191]],

        [[166.499],
         [145.231],
         [159.889],
         [185.355],
         [157.659],
         [146.087],
         [176.918],
         [196.044],
         [182.397],
         [147.882]],

        [[183.944],
         [146.642],
         [191.759],
         [185.115],
         [145.613],
         [169.999],
         [167.728],
         [176.393],
         [170.005],
         [170.910]],

        [[166.111],
         [183.319],
         [164.309],
         [152.245],
         [158.089],
         [164.988],
         [162.291],
         [155.359],
         [158.618],
         [192.316]],

        [[197.606],
         [158.461],
         [153.409],
         [160.116],
         [169.566],
         [165.833],
         [184.634],
         [132.964],
         [171.737],
         [169.935]],

        [[196.825],
         [167.129],
         [171.921],
         [175.212],
         [166.819],
         [177.066],
         [184.397],
         [170.840],
         [175.469],
         [177.330]],

        [[161.277],
         [178.244],
         [164.292],
         [182.885],
         [152.115],
         [159.421],
         [177.871],
         [188.131],
         [191.833],
         [164.292]],

        [[187.918],
         [191.470],
         [189.613],
         [139.002],
         [189.641],
         [171.734],
         [166.880],
         [182.212],
         [155.359],
         [165.036]],

        [[165.284],
         [174.767],
         [160.435],
         [150.602],
         [182.125],
         [165.647],
         [158.097],
         [185.864],
         [159.660],
         [168.051]],

        [[154.817],
         [185.327],
         [150.403],
         [150.532],
         [142.343],
         [183.549],
         [166.896],
         [140.434],
         [203.835],
         [158.779]],

        [[180.806],
         [185.589],
         [179.141],
         [186.647],
         [118.232],
         [155.000],
         [162.025],
         [179.382],
         [168.002],
         [177.927]],

        [[176.565],
         [180.169],
         [186.429],
         [169.900],
         [167.437],
         [170.077],
         [191.897],
         [156.356],
         [170.249],
         [169.706]],

        [[163.551],
         [181.354],
         [142.790],
         [171.340],
         [161.271],
         [184.634],
         [173.345],
         [134.228],
         [173.911],
         [191.028]],

        [[180.535],
         [201.426],
         [170.288],
         [159.574],
         [191.890],
         [156.070],
         [164.256],
         [189.707],
         [182.036],
         [172.609]],

        [[185.906],
         [181.830],
         [150.545],
         [175.262],
         [178.114],
         [178.284],
         [150.713],
         [169.377],
         [160.325],
         [161.735]],

        [[166.816],
         [182.677],
         [162.509],
         [182.718],
         [183.446],
         [175.213],
         [171.027],
         [172.585],
         [200.571],
         [186.514]],

        [[185.050],
         [160.890],
         [160.320],
         [167.182],
         [181.495],
         [166.431],
         [166.894],
         [183.450],
         [168.152],
         [183.873]],

        [[175.768],
         [187.778],
         [164.166],
         [187.005],
         [170.156],
         [173.068],
         [179.135],
         [152.705],
         [181.707],
         [176.186]],

        [[173.978],
         [158.712],
         [187.813],
         [203.562],
         [179.581],
         [179.488],
         [182.599],
         [176.500],
         [186.701],
         [169.909]],

        [[188.995],
         [161.093],
         [131.447],
         [154.290],
         [160.228],
         [202.811],
         [184.597],
         [139.533],
         [174.153],
         [142.261]],

        [[155.331],
         [166.274],
         [126.510],
         [189.076],
         [137.291],
         [191.697],
         [138.174],
         [149.365],
         [165.539],
         [178.767]],

        [[131.952],
         [181.897],
         [140.468],
         [172.118],
         [166.374],
         [166.563],
         [199.826],
         [186.403],
         [193.589],
         [173.962]],

        [[165.540],
         [177.650],
         [164.729],
         [189.240],
         [184.828],
         [175.433],
         [178.566],
         [191.736],
         [174.463],
         [195.429]]], device='cuda:0')
clipping threshold 0.20924835860936417
a after update for 1 param tensor([[-0.367],
        [-0.169],
        [ 0.268],
        [ 0.610],
        [-0.221],
        [ 0.176],
        [ 0.217],
        [ 0.001],
        [ 0.076],
        [-0.421],
        [ 0.055],
        [-0.552],
        [-0.092],
        [-0.109],
        [-0.285],
        [ 0.144],
        [ 0.204],
        [-0.102],
        [ 0.095],
        [ 0.145],
        [-0.127],
        [ 0.099],
        [-0.225],
        [-0.295],
        [ 0.056],
        [-0.247],
        [ 0.090],
        [ 0.030],
        [ 0.210],
        [ 0.166]], device='cuda:0')
s after update for 1 param tensor([[1.796],
        [1.625],
        [1.967],
        [1.960],
        [1.849],
        [1.657],
        [1.493],
        [1.303],
        [1.723],
        [1.871],
        [1.871],
        [1.764],
        [1.479],
        [1.758],
        [1.644],
        [1.946],
        [1.188],
        [1.465],
        [1.385],
        [2.377],
        [1.858],
        [1.878],
        [1.920],
        [1.962],
        [1.917],
        [2.188],
        [1.937],
        [1.620],
        [1.863],
        [1.264]], device='cuda:0')
b after update for 1 param tensor([[173.499],
        [165.046],
        [181.561],
        [181.255],
        [176.033],
        [166.653],
        [158.168],
        [147.804],
        [169.936],
        [177.102],
        [177.070],
        [171.970],
        [157.462],
        [171.663],
        [165.970],
        [180.596],
        [141.114],
        [156.715],
        [152.354],
        [199.612],
        [176.474],
        [177.424],
        [179.391],
        [181.353],
        [179.240],
        [191.513],
        [180.163],
        [164.790],
        [176.709],
        [145.567]], device='cuda:0')
clipping threshold 0.20924835860936417
||w||^2 0.058451641074109
exp ma of ||w||^2 0.05462444589904701
||w|| 0.24176774200481957
exp ma of ||w|| 0.23190399748924848
||w||^2 0.0479902057349427
exp ma of ||w||^2 0.05194291793994124
||w|| 0.21906666961211305
exp ma of ||w|| 0.2260603897688752
||w||^2 0.047851119525800984
exp ma of ||w||^2 0.05297002834960031
||w|| 0.21874898748520183
exp ma of ||w|| 0.2280646356642098
||w||^2 0.045367036636126644
exp ma of ||w||^2 0.04704451401406173
||w|| 0.2129953911147531
exp ma of ||w|| 0.21464326628286026
||w||^2 0.05130134059088061
exp ma of ||w||^2 0.045504405772386444
||w|| 0.22649799246545346
exp ma of ||w|| 0.21108946440531742
||w||^2 0.027128299350832972
exp ma of ||w||^2 0.04595175618130388
||w|| 0.1647067070608631
exp ma of ||w|| 0.2115307008651655
||w||^2 0.042969009896173
exp ma of ||w||^2 0.04484901552565592
||w|| 0.20728967628942113
exp ma of ||w|| 0.2091792698317877
||w||^2 0.024714322685248088
exp ma of ||w||^2 0.04407662286314837
||w|| 0.15720789638325453
exp ma of ||w|| 0.20622725692523
||w||^2 0.026170718657572832
exp ma of ||w||^2 0.04501925411497873
||w|| 0.16177366490740336
exp ma of ||w|| 0.20881079994211893
cuda
Objective function 30.59 = squared loss an data 29.08 + 0.5*rho*h**2 0.164314 + alpha*h 0.720939 + L2reg 0.44 + L1reg 0.19 ; SHD = 60 ; DAG True
Proportion of microbatches that were clipped  0.7584296724470135
iteration 1 in inner loop, alpha 397.6913875963643 rho 100000.0 h 0.0018128103864150091
iteration 5 in outer loop, alpha = 2210.5017740113735, rho = 1000000.0, h = 0.0018128103864150091
Threshold 0.3
[[0.002 0.074 0.028 0.161 0.037 0.18  0.087 0.013 0.149 0.071 0.071 0.023
  0.194 0.011 0.035 0.081 0.137 0.227 0.078 0.047 0.014 0.016 0.1   0.015
  0.016 0.092 0.14  0.031 0.14  0.014]
 [0.022 0.001 0.071 0.191 0.041 0.066 0.229 0.03  0.044 0.011 0.079 0.01
  0.166 0.013 0.021 0.025 0.123 0.19  0.132 0.209 0.02  0.013 0.17  0.021
  0.02  0.035 0.177 0.016 0.189 0.12 ]
 [0.048 0.02  0.001 0.037 0.014 0.018 0.007 0.004 0.093 0.017 0.037 0.053
  0.11  0.02  0.005 0.022 0.067 0.135 0.035 0.022 0.008 0.013 0.166 0.006
  0.011 0.01  0.181 0.016 0.028 0.018]
 [0.012 0.008 0.071 0.002 0.028 0.021 0.016 0.003 0.032 0.01  0.02  0.017
  0.017 0.026 0.01  0.007 0.114 0.131 0.069 0.022 0.005 0.005 0.018 0.013
  0.008 0.013 0.132 0.004 0.054 0.007]
 [0.059 0.042 0.142 0.072 0.002 0.059 0.026 0.015 0.162 0.027 0.041 0.024
  0.146 0.045 0.065 0.055 0.101 0.47  0.269 0.15  0.073 0.016 0.187 0.011
  0.102 0.028 0.24  0.015 0.155 0.043]
 [0.006 0.035 0.089 0.115 0.04  0.002 0.028 0.007 0.179 0.011 0.042 0.006
  0.02  0.015 0.011 0.024 0.039 0.131 0.044 0.151 0.019 0.034 0.249 0.007
  0.025 0.012 0.148 0.005 0.25  0.023]
 [0.019 0.01  0.146 0.138 0.07  0.066 0.001 0.017 0.134 0.014 0.14  0.017
  0.151 0.02  0.012 0.009 0.146 0.128 0.024 0.037 0.008 0.05  0.15  0.009
  0.011 0.099 0.249 0.013 0.23  0.018]
 [0.143 0.055 0.458 0.601 0.164 0.257 0.15  0.002 0.146 0.153 0.15  0.063
  0.106 0.039 0.118 0.164 0.167 0.342 0.177 0.149 0.042 0.112 0.271 0.028
  0.076 0.428 0.206 0.081 0.142 0.129]
 [0.011 0.046 0.026 0.063 0.011 0.008 0.019 0.009 0.003 0.007 0.028 0.013
  0.037 0.012 0.011 0.006 0.105 0.072 0.15  0.018 0.002 0.006 0.087 0.008
  0.006 0.012 0.035 0.02  0.142 0.009]
 [0.027 0.152 0.087 0.191 0.049 0.185 0.138 0.012 0.261 0.001 0.092 0.08
  0.038 0.196 0.105 0.01  0.238 0.187 0.183 0.19  0.032 0.038 0.181 0.049
  0.035 0.088 0.307 0.022 0.191 0.017]
 [0.027 0.031 0.06  0.122 0.034 0.054 0.01  0.009 0.049 0.024 0.001 0.012
  0.058 0.008 0.013 0.026 0.289 0.096 0.147 0.131 0.006 0.009 0.113 0.01
  0.033 0.019 0.062 0.005 0.221 0.078]
 [0.093 0.229 0.064 0.113 0.068 0.201 0.106 0.03  0.127 0.012 0.135 0.001
  0.196 0.046 0.018 0.024 0.159 0.25  0.184 0.135 0.037 0.029 0.11  0.042
  0.016 0.031 0.38  0.029 0.199 0.178]
 [0.013 0.011 0.017 0.095 0.011 0.109 0.006 0.022 0.08  0.042 0.037 0.011
  0.002 0.016 0.014 0.009 0.106 0.179 0.035 0.035 0.011 0.015 0.031 0.006
  0.013 0.018 0.047 0.005 0.024 0.011]
 [0.177 0.173 0.114 0.069 0.04  0.113 0.059 0.038 0.207 0.007 0.203 0.042
  0.109 0.001 0.019 0.039 0.161 0.458 0.207 0.187 0.031 0.012 0.143 0.011
  0.098 0.04  0.14  0.029 0.068 0.086]
 [0.043 0.103 0.172 0.197 0.036 0.189 0.148 0.019 0.177 0.02  0.133 0.122
  0.151 0.14  0.002 0.128 0.209 0.36  0.198 0.141 0.021 0.158 0.257 0.035
  0.169 0.273 0.136 0.046 0.146 0.068]
 [0.031 0.079 0.113 0.206 0.045 0.123 0.21  0.013 0.281 0.115 0.081 0.084
  0.188 0.063 0.01  0.002 0.311 0.103 0.212 0.145 0.029 0.021 0.302 0.02
  0.037 0.147 0.408 0.033 0.293 0.097]
 [0.015 0.016 0.027 0.026 0.026 0.037 0.011 0.011 0.017 0.008 0.006 0.009
  0.021 0.01  0.009 0.006 0.001 0.088 0.116 0.024 0.01  0.013 0.085 0.004
  0.005 0.015 0.061 0.008 0.042 0.009]
 [0.006 0.012 0.012 0.008 0.004 0.012 0.013 0.005 0.034 0.007 0.021 0.007
  0.011 0.003 0.004 0.016 0.024 0.001 0.014 0.037 0.004 0.006 0.105 0.012
  0.013 0.004 0.087 0.004 0.112 0.008]
 [0.02  0.014 0.068 0.022 0.009 0.037 0.07  0.008 0.014 0.009 0.013 0.011
  0.041 0.006 0.007 0.004 0.021 0.123 0.002 0.037 0.005 0.008 0.065 0.005
  0.01  0.02  0.012 0.008 0.09  0.009]
 [0.037 0.012 0.087 0.078 0.013 0.02  0.064 0.009 0.13  0.01  0.014 0.015
  0.055 0.007 0.017 0.012 0.063 0.059 0.041 0.001 0.012 0.011 0.23  0.008
  0.038 0.014 0.036 0.01  0.198 0.014]
 [0.125 0.106 0.254 0.367 0.027 0.112 0.175 0.05  0.635 0.08  0.201 0.063
  0.169 0.063 0.083 0.059 0.213 0.298 0.395 0.143 0.001 0.063 0.125 0.098
  0.016 0.181 0.096 0.091 0.328 0.147]
 [0.11  0.18  0.178 0.21  0.116 0.053 0.039 0.013 0.199 0.04  0.169 0.063
  0.085 0.141 0.013 0.084 0.231 0.304 0.222 0.113 0.032 0.002 0.247 0.015
  0.048 0.131 0.123 0.009 0.11  0.045]
 [0.013 0.011 0.007 0.105 0.006 0.008 0.019 0.006 0.044 0.01  0.014 0.01
  0.062 0.011 0.004 0.006 0.023 0.015 0.044 0.011 0.011 0.006 0.001 0.002
  0.023 0.014 0.2   0.007 0.019 0.011]
 [0.1   0.078 0.287 0.187 0.168 0.244 0.179 0.078 0.223 0.052 0.153 0.061
  0.22  0.133 0.104 0.068 0.379 0.148 0.532 0.225 0.023 0.11  0.707 0.003
  0.06  0.29  0.259 0.103 0.216 0.111]
 [0.148 0.092 0.212 0.175 0.017 0.049 0.096 0.013 0.42  0.049 0.068 0.092
  0.185 0.021 0.02  0.052 0.226 0.127 0.179 0.04  0.1   0.045 0.078 0.031
  0.001 0.115 0.2   0.066 0.105 0.128]
 [0.014 0.039 0.139 0.16  0.069 0.155 0.025 0.005 0.152 0.017 0.102 0.043
  0.112 0.061 0.006 0.012 0.099 0.416 0.109 0.096 0.011 0.012 0.121 0.006
  0.016 0.002 0.158 0.009 0.156 0.037]
 [0.014 0.012 0.01  0.016 0.007 0.011 0.008 0.008 0.023 0.007 0.021 0.004
  0.036 0.014 0.009 0.004 0.029 0.043 0.078 0.038 0.009 0.02  0.014 0.007
  0.013 0.014 0.003 0.003 0.012 0.007]
 [0.058 0.201 0.126 0.301 0.141 0.202 0.137 0.025 0.099 0.103 0.377 0.063
  0.219 0.077 0.037 0.054 0.244 0.26  0.169 0.236 0.027 0.164 0.199 0.022
  0.032 0.267 0.459 0.001 0.133 0.14 ]
 [0.014 0.009 0.053 0.034 0.007 0.013 0.008 0.011 0.014 0.009 0.009 0.009
  0.048 0.02  0.009 0.005 0.043 0.01  0.022 0.009 0.006 0.017 0.117 0.008
  0.024 0.017 0.12  0.012 0.002 0.029]
 [0.175 0.019 0.107 0.205 0.063 0.106 0.099 0.017 0.177 0.119 0.02  0.01
  0.127 0.013 0.035 0.018 0.236 0.24  0.205 0.113 0.016 0.071 0.238 0.018
  0.01  0.053 0.318 0.008 0.061 0.002]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.47  0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.458 0.601 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.342 0.    0.    0.    0.    0.    0.
  0.    0.428 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.307 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.38  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.458 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.36  0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.311 0.    0.    0.    0.    0.    0.302 0.
  0.    0.    0.408 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.367 0.    0.    0.    0.    0.635 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.395 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.328 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.304 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.379 0.    0.532 0.    0.    0.    0.707 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.42  0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.416 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.301 0.    0.    0.    0.    0.    0.    0.377 0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.459 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.318 0.    0.    0.   ]]
{'fdr': 0.6153846153846154, 'tpr': 0.16666666666666666, 'fpr': 0.042666666666666665, 'f1': 0.23255813953488372, 'shd': 60, 'npred': 26, 'ntrue': 60}
[0.074 0.028 0.161 0.037 0.18  0.087 0.013 0.149 0.071 0.071 0.023 0.194
 0.011 0.035 0.081 0.137 0.227 0.078 0.047 0.014 0.016 0.1   0.015 0.016
 0.092 0.14  0.031 0.14  0.014 0.022 0.071 0.191 0.041 0.066 0.229 0.03
 0.044 0.011 0.079 0.01  0.166 0.013 0.021 0.025 0.123 0.19  0.132 0.209
 0.02  0.013 0.17  0.021 0.02  0.035 0.177 0.016 0.189 0.12  0.048 0.02
 0.037 0.014 0.018 0.007 0.004 0.093 0.017 0.037 0.053 0.11  0.02  0.005
 0.022 0.067 0.135 0.035 0.022 0.008 0.013 0.166 0.006 0.011 0.01  0.181
 0.016 0.028 0.018 0.012 0.008 0.071 0.028 0.021 0.016 0.003 0.032 0.01
 0.02  0.017 0.017 0.026 0.01  0.007 0.114 0.131 0.069 0.022 0.005 0.005
 0.018 0.013 0.008 0.013 0.132 0.004 0.054 0.007 0.059 0.042 0.142 0.072
 0.059 0.026 0.015 0.162 0.027 0.041 0.024 0.146 0.045 0.065 0.055 0.101
 0.47  0.269 0.15  0.073 0.016 0.187 0.011 0.102 0.028 0.24  0.015 0.155
 0.043 0.006 0.035 0.089 0.115 0.04  0.028 0.007 0.179 0.011 0.042 0.006
 0.02  0.015 0.011 0.024 0.039 0.131 0.044 0.151 0.019 0.034 0.249 0.007
 0.025 0.012 0.148 0.005 0.25  0.023 0.019 0.01  0.146 0.138 0.07  0.066
 0.017 0.134 0.014 0.14  0.017 0.151 0.02  0.012 0.009 0.146 0.128 0.024
 0.037 0.008 0.05  0.15  0.009 0.011 0.099 0.249 0.013 0.23  0.018 0.143
 0.055 0.458 0.601 0.164 0.257 0.15  0.146 0.153 0.15  0.063 0.106 0.039
 0.118 0.164 0.167 0.342 0.177 0.149 0.042 0.112 0.271 0.028 0.076 0.428
 0.206 0.081 0.142 0.129 0.011 0.046 0.026 0.063 0.011 0.008 0.019 0.009
 0.007 0.028 0.013 0.037 0.012 0.011 0.006 0.105 0.072 0.15  0.018 0.002
 0.006 0.087 0.008 0.006 0.012 0.035 0.02  0.142 0.009 0.027 0.152 0.087
 0.191 0.049 0.185 0.138 0.012 0.261 0.092 0.08  0.038 0.196 0.105 0.01
 0.238 0.187 0.183 0.19  0.032 0.038 0.181 0.049 0.035 0.088 0.307 0.022
 0.191 0.017 0.027 0.031 0.06  0.122 0.034 0.054 0.01  0.009 0.049 0.024
 0.012 0.058 0.008 0.013 0.026 0.289 0.096 0.147 0.131 0.006 0.009 0.113
 0.01  0.033 0.019 0.062 0.005 0.221 0.078 0.093 0.229 0.064 0.113 0.068
 0.201 0.106 0.03  0.127 0.012 0.135 0.196 0.046 0.018 0.024 0.159 0.25
 0.184 0.135 0.037 0.029 0.11  0.042 0.016 0.031 0.38  0.029 0.199 0.178
 0.013 0.011 0.017 0.095 0.011 0.109 0.006 0.022 0.08  0.042 0.037 0.011
 0.016 0.014 0.009 0.106 0.179 0.035 0.035 0.011 0.015 0.031 0.006 0.013
 0.018 0.047 0.005 0.024 0.011 0.177 0.173 0.114 0.069 0.04  0.113 0.059
 0.038 0.207 0.007 0.203 0.042 0.109 0.019 0.039 0.161 0.458 0.207 0.187
 0.031 0.012 0.143 0.011 0.098 0.04  0.14  0.029 0.068 0.086 0.043 0.103
 0.172 0.197 0.036 0.189 0.148 0.019 0.177 0.02  0.133 0.122 0.151 0.14
 0.128 0.209 0.36  0.198 0.141 0.021 0.158 0.257 0.035 0.169 0.273 0.136
 0.046 0.146 0.068 0.031 0.079 0.113 0.206 0.045 0.123 0.21  0.013 0.281
 0.115 0.081 0.084 0.188 0.063 0.01  0.311 0.103 0.212 0.145 0.029 0.021
 0.302 0.02  0.037 0.147 0.408 0.033 0.293 0.097 0.015 0.016 0.027 0.026
 0.026 0.037 0.011 0.011 0.017 0.008 0.006 0.009 0.021 0.01  0.009 0.006
 0.088 0.116 0.024 0.01  0.013 0.085 0.004 0.005 0.015 0.061 0.008 0.042
 0.009 0.006 0.012 0.012 0.008 0.004 0.012 0.013 0.005 0.034 0.007 0.021
 0.007 0.011 0.003 0.004 0.016 0.024 0.014 0.037 0.004 0.006 0.105 0.012
 0.013 0.004 0.087 0.004 0.112 0.008 0.02  0.014 0.068 0.022 0.009 0.037
 0.07  0.008 0.014 0.009 0.013 0.011 0.041 0.006 0.007 0.004 0.021 0.123
 0.037 0.005 0.008 0.065 0.005 0.01  0.02  0.012 0.008 0.09  0.009 0.037
 0.012 0.087 0.078 0.013 0.02  0.064 0.009 0.13  0.01  0.014 0.015 0.055
 0.007 0.017 0.012 0.063 0.059 0.041 0.012 0.011 0.23  0.008 0.038 0.014
 0.036 0.01  0.198 0.014 0.125 0.106 0.254 0.367 0.027 0.112 0.175 0.05
 0.635 0.08  0.201 0.063 0.169 0.063 0.083 0.059 0.213 0.298 0.395 0.143
 0.063 0.125 0.098 0.016 0.181 0.096 0.091 0.328 0.147 0.11  0.18  0.178
 0.21  0.116 0.053 0.039 0.013 0.199 0.04  0.169 0.063 0.085 0.141 0.013
 0.084 0.231 0.304 0.222 0.113 0.032 0.247 0.015 0.048 0.131 0.123 0.009
 0.11  0.045 0.013 0.011 0.007 0.105 0.006 0.008 0.019 0.006 0.044 0.01
 0.014 0.01  0.062 0.011 0.004 0.006 0.023 0.015 0.044 0.011 0.011 0.006
 0.002 0.023 0.014 0.2   0.007 0.019 0.011 0.1   0.078 0.287 0.187 0.168
 0.244 0.179 0.078 0.223 0.052 0.153 0.061 0.22  0.133 0.104 0.068 0.379
 0.148 0.532 0.225 0.023 0.11  0.707 0.06  0.29  0.259 0.103 0.216 0.111
 0.148 0.092 0.212 0.175 0.017 0.049 0.096 0.013 0.42  0.049 0.068 0.092
 0.185 0.021 0.02  0.052 0.226 0.127 0.179 0.04  0.1   0.045 0.078 0.031
 0.115 0.2   0.066 0.105 0.128 0.014 0.039 0.139 0.16  0.069 0.155 0.025
 0.005 0.152 0.017 0.102 0.043 0.112 0.061 0.006 0.012 0.099 0.416 0.109
 0.096 0.011 0.012 0.121 0.006 0.016 0.158 0.009 0.156 0.037 0.014 0.012
 0.01  0.016 0.007 0.011 0.008 0.008 0.023 0.007 0.021 0.004 0.036 0.014
 0.009 0.004 0.029 0.043 0.078 0.038 0.009 0.02  0.014 0.007 0.013 0.014
 0.003 0.012 0.007 0.058 0.201 0.126 0.301 0.141 0.202 0.137 0.025 0.099
 0.103 0.377 0.063 0.219 0.077 0.037 0.054 0.244 0.26  0.169 0.236 0.027
 0.164 0.199 0.022 0.032 0.267 0.459 0.133 0.14  0.014 0.009 0.053 0.034
 0.007 0.013 0.008 0.011 0.014 0.009 0.009 0.009 0.048 0.02  0.009 0.005
 0.043 0.01  0.022 0.009 0.006 0.017 0.117 0.008 0.024 0.017 0.12  0.012
 0.029 0.175 0.019 0.107 0.205 0.063 0.106 0.099 0.017 0.177 0.119 0.02
 0.01  0.127 0.013 0.035 0.018 0.236 0.24  0.205 0.113 0.016 0.071 0.238
 0.018 0.01  0.053 0.318 0.008 0.061]
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 1. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]]
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.6002674897119342, 0.20686934750804395)
Iterations 2500
Achieves (3.6993101023104464, 1e-05)-DP
