samples  5000  graph  30 60 ER mim  minibatch size  50  noise  0.8  minibatches per NN training  250 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 2.144444827137683
iteration 1 in outer loop, alpha = 2.144444827137683, rho = 1.0, h = 2.144444827137683
cuda
iteration 1 in inner loop,alpha 2.144444827137683 rho 1.0 h 1.3256466874605835
iteration 2 in inner loop,alpha 2.144444827137683 rho 10.0 h 0.5131010328032026
iteration 2 in outer loop, alpha = 7.275455155169709, rho = 10.0, h = 0.5131010328032026
cuda
iteration 1 in inner loop,alpha 7.275455155169709 rho 10.0 h 0.28442514981965417
iteration 2 in inner loop,alpha 7.275455155169709 rho 100.0 h 0.09687583592673477
iteration 3 in outer loop, alpha = 16.963038747843186, rho = 100.0, h = 0.09687583592673477
cuda
iteration 1 in inner loop,alpha 16.963038747843186 rho 100.0 h 0.05565872169768937
iteration 2 in inner loop,alpha 16.963038747843186 rho 1000.0 h 0.017246591836673986
iteration 4 in outer loop, alpha = 34.20963058451717, rho = 1000.0, h = 0.017246591836673986
cuda
iteration 1 in inner loop,alpha 34.20963058451717 rho 1000.0 h 0.007536379858688491
iteration 2 in inner loop,alpha 34.20963058451717 rho 10000.0 h 0.0024562545468960195
iteration 5 in outer loop, alpha = 58.77217605347737, rho = 10000.0, h = 0.0024562545468960195
cuda
iteration 1 in inner loop,alpha 58.77217605347737 rho 10000.0 h 0.0010792499674714406
iteration 2 in inner loop,alpha 58.77217605347737 rho 100000.0 h 0.0004212010900985774
iteration 6 in outer loop, alpha = 100.89228506333511, rho = 100000.0, h = 0.0004212010900985774
cuda
iteration 1 in inner loop,alpha 100.89228506333511 rho 100000.0 h 0.00023465825842805543
iteration 7 in outer loop, alpha = 335.55054349139056, rho = 1000000.0, h = 0.00023465825842805543
Threshold 0.3
[[0.    0.    0.101 0.046 0.058 0.001 0.114 0.022 0.057 0.348 0.    0.051
  0.    0.    0.    0.026 0.001 0.049 0.056 0.879 0.044 0.001 0.147 0.023
  0.    0.034 0.017 0.018 0.022 0.022]
 [0.    0.    0.017 0.003 0.011 0.681 1.88  0.085 0.112 0.002 0.    0.033
  0.    0.    0.001 0.057 0.    0.072 0.027 0.052 0.004 0.    0.102 0.055
  0.    0.013 0.    0.081 0.085 0.03 ]
 [0.    0.    0.004 0.009 0.107 0.    0.069 0.049 0.001 0.    0.    0.
  0.    0.    0.    0.005 0.    0.014 0.058 0.122 0.001 0.    0.01  0.02
  0.    0.    0.018 0.013 0.022 0.008]
 [0.    0.    0.006 0.002 0.02  0.003 0.019 0.    0.    0.    0.    0.001
  0.    0.    0.    0.002 0.    0.    0.001 0.053 0.    0.    0.001 0.001
  0.    0.    0.    0.    0.059 0.   ]
 [0.    0.    0.003 0.006 0.003 0.003 0.012 0.012 0.002 0.    0.    0.
  0.    0.    0.    0.001 0.    0.001 0.001 0.163 0.    0.    0.008 0.001
  0.    0.    0.001 0.009 0.012 0.001]
 [0.    0.    0.051 0.041 0.016 0.003 0.049 0.042 0.086 0.    0.    0.063
  0.    0.    0.    0.003 0.    0.006 0.003 0.831 0.001 0.    0.029 0.009
  0.    0.001 0.009 0.003 0.003 0.001]
 [0.    0.    0.011 0.028 0.025 0.    0.003 0.02  0.005 0.    0.    0.001
  0.    0.    0.    0.017 0.    0.01  0.008 0.091 0.    0.    0.093 0.046
  0.    0.    0.004 0.01  0.021 0.002]
 [0.    0.    0.009 1.484 0.008 0.014 0.027 0.003 0.001 0.    0.    0.001
  0.    0.    0.    0.003 0.    0.    0.001 0.009 0.001 0.    0.006 0.001
  0.    0.    0.001 0.    0.042 0.002]
 [0.    0.    0.051 0.001 0.042 0.005 0.041 0.057 0.003 0.001 0.    0.058
  0.    0.    0.    0.086 0.    0.047 0.754 1.09  0.    0.001 1.699 0.066
  0.    0.003 0.051 0.001 0.055 0.008]
 [0.    0.    0.126 0.141 0.029 1.134 0.056 0.637 0.091 0.    0.    2.435
  0.    0.    0.    0.246 0.    0.176 0.024 0.098 0.008 0.    0.06  0.005
  0.    0.013 0.569 0.021 0.01  0.024]
 [0.    0.    0.029 0.186 0.033 0.015 0.09  0.079 0.901 0.015 0.    0.036
  0.    0.001 0.023 0.027 0.    0.057 0.064 0.103 0.05  0.011 0.031 0.068
  0.    0.038 0.089 4.126 0.041 0.013]
 [0.    0.    4.284 0.009 0.03  0.011 0.019 0.056 0.013 0.    0.    0.002
  0.    0.    0.    0.121 0.    0.087 0.033 0.15  0.002 0.    0.004 0.062
  0.    0.    0.403 0.024 0.029 0.012]
 [0.    0.    0.    0.052 0.048 0.008 1.879 0.013 1.181 0.02  0.    0.052
  0.    0.    0.    0.117 0.    0.096 0.002 0.    0.022 0.021 0.08  0.313
  0.    0.037 0.441 0.038 0.02  3.056]
 [0.    0.    0.082 0.001 1.227 0.042 0.023 0.127 0.065 0.    0.    0.07
  0.    0.    0.    0.106 0.    0.913 0.032 1.339 0.019 0.    0.043 0.037
  0.    0.005 0.131 0.068 0.009 0.   ]
 [0.    0.    0.032 0.057 0.06  0.059 0.038 0.102 0.049 0.    0.    1.709
  0.    0.    0.    0.012 0.    0.181 0.021 0.002 0.013 0.01  0.11  0.746
  0.    3.166 0.    0.013 0.121 0.056]
 [0.    0.    0.047 0.004 0.071 0.031 0.019 0.055 0.015 0.001 0.    0.005
  0.    0.    0.    0.004 0.    0.084 0.01  0.026 0.004 0.002 0.451 0.013
  0.    0.007 0.736 0.005 0.009 0.074]
 [0.    0.    2.538 0.093 0.088 0.018 0.034 0.012 0.457 0.    0.    0.002
  0.    0.    0.    0.013 0.    0.118 0.001 0.034 2.838 0.399 0.122 0.017
  0.    0.001 0.046 0.05  0.074 0.041]
 [0.    0.    0.014 0.06  1.533 0.087 0.015 1.118 0.001 0.    0.    0.
  0.    0.    0.    0.004 0.    0.004 0.003 0.095 0.002 0.    0.017 0.001
  0.    0.001 0.004 0.011 0.207 0.001]
 [0.    0.    0.007 0.026 0.021 0.008 0.005 0.036 0.001 0.    0.    0.
  0.    0.    0.    0.001 0.    0.134 0.002 0.009 0.    0.    0.018 0.001
  0.    0.    0.01  0.006 0.035 0.001]
 [0.    0.    0.004 0.003 0.001 0.001 0.007 0.    0.001 0.    0.    0.001
  0.    0.    0.    0.022 0.    0.001 0.016 0.003 0.    0.    0.073 0.009
  0.    0.    0.006 0.003 0.009 0.001]
 [0.    0.    0.037 0.003 0.004 0.84  0.014 0.031 1.733 0.    0.    0.063
  0.    0.    0.    0.012 0.    0.075 0.023 0.081 0.002 0.001 0.002 0.031
  0.    0.018 0.008 0.012 2.129 0.037]
 [0.001 0.    0.045 1.339 1.122 0.025 0.052 0.121 0.239 0.    0.    0.042
  0.    0.    0.001 0.054 0.    0.695 0.069 0.067 0.331 0.001 0.1   0.198
  0.    0.027 0.23  0.049 1.58  2.033]
 [0.    0.    0.001 0.121 0.056 0.002 0.002 0.1   0.    0.    0.    0.002
  0.    0.    0.    0.005 0.    0.008 0.026 0.    0.    0.    0.004 0.
  0.    0.    0.155 0.    0.005 0.   ]
 [0.    0.    0.005 0.617 0.001 0.023 0.011 0.086 0.011 0.    0.    0.005
  0.    0.    0.    0.024 0.    0.127 1.183 0.024 0.005 0.    2.424 0.003
  0.    0.    0.362 0.004 0.177 0.   ]
 [0.    0.    0.058 0.077 0.016 0.099 1.495 0.026 0.004 0.034 0.    0.017
  0.001 0.    0.    0.081 0.    0.057 0.063 0.059 0.038 0.069 1.712 0.039
  0.    0.035 0.075 0.061 0.01  0.053]
 [0.    0.    0.047 0.062 0.179 0.042 0.007 2.524 0.041 0.001 0.    0.306
  0.    0.    0.    0.145 0.    1.16  0.071 0.036 0.003 0.    0.167 1.564
  0.    0.002 0.204 0.029 2.217 0.07 ]
 [0.    0.    0.041 0.01  0.178 0.023 0.033 0.066 0.002 0.    0.    0.002
  0.    0.    0.    0.003 0.    0.606 0.056 0.03  0.001 0.001 0.013 0.003
  0.    0.    0.004 0.01  0.044 0.002]
 [0.    0.    0.036 0.088 0.002 0.034 0.029 1.361 0.163 0.001 0.    0.007
  0.    0.    0.    0.02  0.    0.033 0.039 0.054 0.043 0.005 0.01  0.02
  0.    0.014 0.    0.003 0.024 0.013]
 [0.    0.    0.036 0.003 0.051 0.111 0.016 0.006 0.014 0.    0.    0.002
  0.    0.    0.    0.021 0.    0.002 0.009 0.059 0.    0.    0.047 0.001
  0.    0.    0.    0.    0.002 0.002]
 [0.    0.    0.029 0.081 0.062 0.619 0.202 0.047 0.036 0.001 0.    0.018
  0.    0.    0.    0.002 0.    0.192 1.025 0.036 0.007 0.    0.052 0.378
  0.    0.    0.04  0.015 0.069 0.002]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.348 0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.879 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.681 1.88  0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.831 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    1.484 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.754 1.09  0.    0.    1.699 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    1.134 0.    0.637 0.    0.    0.    2.435
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.569 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.901 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    4.126 0.    0.   ]
 [0.    0.    4.284 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.403 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    1.879 0.    1.181 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.313
  0.    0.    0.441 0.    0.    3.056]
 [0.    0.    0.    0.    1.227 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.913 0.    1.339 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.709
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.746
  0.    3.166 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.451 0.
  0.    0.    0.736 0.    0.    0.   ]
 [0.    0.    2.538 0.    0.    0.    0.    0.    0.457 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    2.838 0.399 0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    1.533 0.    0.    1.118 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.84  0.    0.    1.733 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    2.129 0.   ]
 [0.    0.    0.    1.339 1.122 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.695 0.    0.    0.331 0.    0.    0.
  0.    0.    0.    0.    1.58  2.033]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.617 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    1.183 0.    0.    0.    2.424 0.
  0.    0.    0.362 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    1.495 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.712 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    2.524 0.    0.    0.    0.306
  0.    0.    0.    0.    0.    1.16  0.    0.    0.    0.    0.    1.564
  0.    0.    0.    0.    2.217 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.606 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    1.361 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.619 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    1.025 0.    0.    0.    0.    0.378
  0.    0.    0.    0.    0.    0.   ]]
{'fdr': 0.11475409836065574, 'tpr': 0.9, 'fpr': 0.018666666666666668, 'f1': 0.8925619834710743, 'shd': 9, 'npred': 61, 'ntrue': 60}
[6.596e-05 1.009e-01 4.555e-02 5.751e-02 6.003e-04 1.138e-01 2.226e-02
 5.694e-02 3.480e-01 8.542e-05 5.050e-02 6.330e-05 2.237e-04 9.124e-05
 2.617e-02 6.502e-04 4.869e-02 5.559e-02 8.786e-01 4.388e-02 8.308e-04
 1.473e-01 2.266e-02 1.347e-04 3.425e-02 1.661e-02 1.754e-02 2.222e-02
 2.161e-02 5.216e-05 1.676e-02 3.461e-03 1.107e-02 6.808e-01 1.880e+00
 8.547e-02 1.123e-01 1.708e-03 3.772e-05 3.338e-02 5.108e-05 1.299e-05
 5.962e-04 5.736e-02 2.732e-04 7.191e-02 2.724e-02 5.177e-02 4.252e-03
 2.360e-04 1.021e-01 5.463e-02 1.170e-04 1.293e-02 2.770e-04 8.122e-02
 8.508e-02 2.992e-02 9.014e-06 2.531e-05 9.299e-03 1.065e-01 1.003e-04
 6.856e-02 4.916e-02 1.095e-03 5.202e-06 2.417e-05 5.941e-05 4.600e-05
 1.596e-05 1.278e-06 5.177e-03 3.860e-05 1.435e-02 5.817e-02 1.220e-01
 7.380e-04 1.706e-04 1.007e-02 1.992e-02 2.199e-05 3.642e-05 1.791e-02
 1.321e-02 2.239e-02 7.693e-03 2.552e-05 7.386e-06 6.006e-03 2.005e-02
 2.737e-03 1.945e-02 4.566e-04 3.445e-04 8.368e-05 1.104e-05 7.708e-04
 2.312e-05 2.181e-05 9.928e-07 1.868e-03 5.962e-05 7.332e-05 9.698e-04
 5.324e-02 2.797e-04 1.117e-04 1.219e-03 1.143e-03 3.967e-05 1.623e-05
 1.096e-04 5.791e-05 5.916e-02 4.514e-04 7.894e-06 2.293e-04 2.689e-03
 5.664e-03 2.837e-03 1.247e-02 1.210e-02 1.524e-03 2.351e-05 3.039e-05
 3.088e-04 2.430e-05 1.298e-05 2.204e-05 7.372e-04 2.525e-05 6.876e-04
 1.074e-03 1.633e-01 5.753e-05 9.030e-05 7.712e-03 1.302e-03 3.317e-05
 1.521e-04 1.219e-03 9.225e-03 1.250e-02 1.146e-03 7.325e-05 1.420e-05
 5.056e-02 4.109e-02 1.560e-02 4.874e-02 4.241e-02 8.622e-02 1.345e-04
 2.147e-04 6.292e-02 5.732e-06 1.075e-04 9.416e-05 2.928e-03 5.776e-06
 6.414e-03 3.169e-03 8.306e-01 6.213e-04 1.375e-04 2.930e-02 9.146e-03
 3.746e-04 5.661e-04 9.487e-03 3.335e-03 3.243e-03 1.158e-03 2.377e-05
 1.008e-05 1.053e-02 2.836e-02 2.538e-02 3.718e-04 2.004e-02 5.418e-03
 1.213e-04 2.677e-05 5.393e-04 1.805e-05 1.369e-04 3.989e-05 1.708e-02
 2.086e-05 9.535e-03 7.745e-03 9.120e-02 4.104e-04 1.157e-04 9.298e-02
 4.554e-02 1.014e-05 5.225e-05 3.738e-03 9.667e-03 2.098e-02 2.072e-03
 7.047e-06 1.443e-05 9.321e-03 1.484e+00 8.358e-03 1.425e-02 2.694e-02
 6.341e-04 1.068e-04 7.263e-07 1.346e-03 9.244e-05 2.128e-05 2.741e-06
 3.257e-03 6.737e-05 3.635e-04 8.886e-04 8.551e-03 7.596e-04 2.108e-04
 5.803e-03 5.468e-04 6.809e-06 1.152e-04 9.456e-04 3.308e-04 4.231e-02
 1.861e-03 1.047e-04 2.088e-05 5.142e-02 7.383e-04 4.156e-02 5.178e-03
 4.109e-02 5.726e-02 8.560e-04 8.119e-06 5.808e-02 1.567e-05 5.444e-05
 2.167e-04 8.619e-02 2.742e-06 4.690e-02 7.543e-01 1.090e+00 2.323e-04
 5.749e-04 1.699e+00 6.637e-02 7.375e-06 2.597e-03 5.123e-02 1.460e-03
 5.455e-02 8.453e-03 1.491e-04 4.139e-06 1.259e-01 1.413e-01 2.934e-02
 1.134e+00 5.553e-02 6.371e-01 9.059e-02 1.107e-04 2.435e+00 3.794e-05
 1.006e-04 7.283e-05 2.465e-01 1.724e-05 1.763e-01 2.396e-02 9.842e-02
 8.362e-03 2.561e-04 5.997e-02 4.629e-03 2.612e-05 1.299e-02 5.691e-01
 2.098e-02 1.046e-02 2.447e-02 9.893e-05 5.128e-05 2.903e-02 1.858e-01
 3.291e-02 1.530e-02 9.004e-02 7.926e-02 9.007e-01 1.501e-02 3.614e-02
 2.055e-04 5.409e-04 2.305e-02 2.720e-02 4.939e-05 5.718e-02 6.368e-02
 1.034e-01 4.953e-02 1.133e-02 3.059e-02 6.782e-02 5.590e-05 3.799e-02
 8.912e-02 4.126e+00 4.133e-02 1.326e-02 1.406e-05 6.139e-05 4.284e+00
 8.713e-03 2.968e-02 1.065e-02 1.920e-02 5.606e-02 1.293e-02 3.411e-05
 1.675e-04 3.277e-04 1.113e-05 7.627e-06 1.208e-01 3.056e-05 8.717e-02
 3.298e-02 1.503e-01 1.832e-03 3.981e-04 3.754e-03 6.196e-02 7.784e-06
 2.264e-04 4.026e-01 2.359e-02 2.913e-02 1.211e-02 9.564e-05 1.633e-04
 4.809e-04 5.233e-02 4.784e-02 7.560e-03 1.879e+00 1.306e-02 1.181e+00
 2.046e-02 7.321e-05 5.161e-02 8.608e-05 7.329e-05 1.173e-01 2.655e-05
 9.568e-02 2.216e-03 2.223e-04 2.184e-02 2.126e-02 7.980e-02 3.126e-01
 2.507e-04 3.737e-02 4.411e-01 3.844e-02 2.018e-02 3.056e+00 5.579e-05
 3.578e-04 8.225e-02 7.416e-04 1.227e+00 4.237e-02 2.308e-02 1.267e-01
 6.456e-02 2.653e-04 2.670e-05 7.004e-02 1.523e-04 1.172e-04 1.065e-01
 1.314e-04 9.128e-01 3.182e-02 1.339e+00 1.892e-02 4.522e-05 4.316e-02
 3.744e-02 4.727e-04 4.998e-03 1.310e-01 6.773e-02 8.946e-03 4.133e-04
 6.995e-05 4.983e-05 3.224e-02 5.724e-02 6.022e-02 5.903e-02 3.811e-02
 1.018e-01 4.857e-02 2.496e-04 1.145e-04 1.709e+00 1.406e-04 4.672e-04
 1.191e-02 3.486e-04 1.811e-01 2.067e-02 2.021e-03 1.346e-02 9.822e-03
 1.099e-01 7.464e-01 4.062e-05 3.166e+00 3.485e-05 1.325e-02 1.215e-01
 5.640e-02 7.868e-05 8.561e-05 4.701e-02 3.541e-03 7.072e-02 3.054e-02
 1.898e-02 5.547e-02 1.482e-02 5.767e-04 2.055e-04 5.154e-03 5.241e-05
 1.073e-04 1.197e-04 4.761e-05 8.448e-02 9.558e-03 2.636e-02 3.589e-03
 1.640e-03 4.509e-01 1.300e-02 1.338e-04 6.536e-03 7.361e-01 4.840e-03
 8.525e-03 7.411e-02 2.273e-05 5.905e-05 2.538e+00 9.300e-02 8.825e-02
 1.802e-02 3.355e-02 1.243e-02 4.566e-01 2.235e-04 4.641e-06 1.737e-03
 5.328e-06 7.769e-05 1.143e-04 1.303e-02 1.185e-01 1.478e-03 3.372e-02
 2.838e+00 3.991e-01 1.221e-01 1.665e-02 6.180e-05 6.689e-04 4.598e-02
 5.040e-02 7.406e-02 4.140e-02 1.542e-04 1.189e-04 1.384e-02 5.991e-02
 1.533e+00 8.694e-02 1.485e-02 1.118e+00 1.492e-03 6.476e-05 2.110e-05
 3.480e-04 2.483e-05 4.725e-06 9.305e-06 4.130e-03 7.643e-06 2.929e-03
 9.538e-02 2.330e-03 3.804e-04 1.748e-02 8.043e-04 1.615e-05 5.674e-04
 3.552e-03 1.096e-02 2.072e-01 1.348e-03 1.619e-04 1.522e-04 6.791e-03
 2.559e-02 2.068e-02 7.545e-03 4.726e-03 3.582e-02 1.001e-03 1.133e-04
 1.556e-05 1.297e-04 1.263e-05 5.611e-06 1.212e-05 6.452e-04 1.046e-05
 1.337e-01 9.183e-03 1.870e-04 6.182e-05 1.820e-02 6.789e-04 4.751e-06
 1.742e-04 1.037e-02 6.223e-03 3.451e-02 5.541e-04 4.853e-06 7.600e-06
 4.369e-03 3.216e-03 6.861e-04 9.385e-04 7.013e-03 9.815e-05 6.984e-04
 4.476e-05 3.976e-06 5.088e-04 8.284e-06 8.935e-06 1.411e-05 2.222e-02
 8.614e-06 9.046e-04 1.636e-02 1.455e-04 1.359e-04 7.302e-02 9.245e-03
 3.085e-05 4.176e-04 5.924e-03 2.816e-03 8.701e-03 9.514e-04 4.356e-05
 4.760e-05 3.706e-02 2.690e-03 4.121e-03 8.400e-01 1.395e-02 3.057e-02
 1.733e+00 2.964e-04 2.254e-05 6.251e-02 5.513e-05 1.193e-04 5.700e-05
 1.238e-02 3.779e-06 7.509e-02 2.310e-02 8.127e-02 1.485e-03 2.305e-03
 3.139e-02 1.173e-04 1.781e-02 8.480e-03 1.203e-02 2.129e+00 3.681e-02
 6.527e-04 1.896e-05 4.500e-02 1.339e+00 1.122e+00 2.455e-02 5.176e-02
 1.207e-01 2.389e-01 6.548e-05 2.662e-04 4.194e-02 1.246e-04 7.036e-06
 5.438e-04 5.351e-02 1.470e-04 6.953e-01 6.897e-02 6.711e-02 3.314e-01
 1.003e-01 1.976e-01 1.104e-04 2.750e-02 2.303e-01 4.915e-02 1.580e+00
 2.033e+00 7.914e-06 3.578e-05 1.231e-03 1.214e-01 5.590e-02 1.971e-03
 1.707e-03 1.003e-01 2.261e-04 2.719e-04 1.613e-05 2.276e-03 8.057e-06
 2.378e-05 1.616e-06 5.027e-03 1.130e-05 8.045e-03 2.635e-02 4.195e-04
 4.553e-05 4.305e-05 2.062e-04 6.215e-06 5.216e-05 1.554e-01 4.489e-04
 5.384e-03 6.428e-05 6.563e-05 1.864e-04 5.067e-03 6.173e-01 8.183e-04
 2.263e-02 1.094e-02 8.642e-02 1.121e-02 2.746e-04 2.312e-05 4.612e-03
 2.709e-06 2.279e-05 6.918e-06 2.359e-02 4.522e-05 1.266e-01 1.183e+00
 2.438e-02 5.063e-03 3.558e-05 2.424e+00 1.166e-04 3.217e-04 3.619e-01
 3.887e-03 1.771e-01 4.447e-04 4.716e-04 1.091e-04 5.792e-02 7.651e-02
 1.649e-02 9.869e-02 1.495e+00 2.580e-02 3.673e-03 3.391e-02 3.541e-05
 1.661e-02 6.525e-04 4.969e-05 2.360e-05 8.084e-02 2.727e-04 5.686e-02
 6.305e-02 5.914e-02 3.831e-02 6.917e-02 1.712e+00 3.906e-02 3.535e-02
 7.512e-02 6.087e-02 9.574e-03 5.293e-02 6.042e-05 1.833e-05 4.664e-02
 6.238e-02 1.787e-01 4.182e-02 6.920e-03 2.524e+00 4.064e-02 6.111e-04
 8.747e-05 3.063e-01 5.492e-05 4.937e-05 1.141e-05 1.447e-01 1.329e-04
 1.160e+00 7.131e-02 3.584e-02 3.195e-03 4.797e-04 1.671e-01 1.564e+00
 3.557e-05 2.044e-01 2.906e-02 2.217e+00 6.951e-02 2.454e-05 1.182e-04
 4.063e-02 9.907e-03 1.784e-01 2.269e-02 3.251e-02 6.568e-02 2.393e-03
 2.242e-04 3.314e-05 2.171e-03 1.647e-05 2.474e-05 5.538e-06 2.717e-03
 3.553e-05 6.056e-01 5.590e-02 2.955e-02 7.564e-04 9.909e-04 1.330e-02
 3.208e-03 3.329e-05 3.792e-04 9.618e-03 4.354e-02 2.256e-03 4.620e-05
 1.445e-04 3.643e-02 8.788e-02 1.893e-03 3.435e-02 2.915e-02 1.361e+00
 1.631e-01 6.436e-04 7.010e-07 6.535e-03 8.585e-05 6.057e-05 1.290e-04
 1.975e-02 9.146e-05 3.286e-02 3.937e-02 5.428e-02 4.284e-02 4.911e-03
 1.031e-02 1.953e-02 7.954e-05 1.402e-02 1.410e-04 2.392e-02 1.348e-02
 1.645e-04 9.114e-06 3.599e-02 2.743e-03 5.122e-02 1.112e-01 1.593e-02
 5.743e-03 1.386e-02 8.946e-05 5.170e-05 1.705e-03 1.382e-05 1.613e-05
 1.459e-06 2.099e-02 1.788e-06 2.026e-03 9.045e-03 5.866e-02 1.116e-04
 9.426e-05 4.744e-02 1.365e-03 2.909e-04 1.346e-04 4.553e-04 1.037e-04
 1.772e-03 5.408e-05 1.322e-05 2.946e-02 8.071e-02 6.175e-02 6.189e-01
 2.016e-01 4.681e-02 3.617e-02 1.368e-03 1.076e-05 1.813e-02 1.865e-06
 2.859e-05 2.696e-05 1.527e-03 1.584e-05 1.920e-01 1.025e+00 3.646e-02
 6.581e-03 8.649e-05 5.170e-02 3.782e-01 6.487e-05 3.649e-04 3.950e-02
 1.536e-02 6.857e-02]
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 1. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]]
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.9624691358024692, 0.9247510801272201)
cuda
9630
cuda
Objective function 291.21 = squared loss an data 35.20 + 0.5*rho*h**2 254.631624 + alpha*h 0.000000 + L2reg 0.55 + L1reg 0.82 ; SHD = 416 ; DAG False
||w||^2 6597445.253940232
exp ma of ||w||^2 33395613658.06204
||w|| 2568.549250830171
exp ma of ||w|| 54035.26102150596
||w||^2 0.019314602801329656
exp ma of ||w||^2 0.02559216138283159
||w|| 0.13897698658889412
exp ma of ||w|| 0.15632789960460458
||w||^2 0.017855017018120853
exp ma of ||w||^2 0.029968688374999632
||w|| 0.1336226665581886
exp ma of ||w|| 0.17092689184931156
||w||^2 0.030224959730961426
exp ma of ||w||^2 0.029567913468141464
||w|| 0.1738532706938855
exp ma of ||w|| 0.16902350973844416
||w||^2 0.02840371297588922
exp ma of ||w||^2 0.02996076941381187
||w|| 0.16853401133269574
exp ma of ||w|| 0.17084766877584512
||w||^2 0.019018479197866322
exp ma of ||w||^2 0.029288252099061912
||w|| 0.13790750232625607
exp ma of ||w|| 0.16826678717217985
||w||^2 0.04447807681440155
exp ma of ||w||^2 0.029539895990518913
||w|| 0.21089826176239942
exp ma of ||w|| 0.16934350471912393
||w||^2 0.02384378852543415
exp ma of ||w||^2 0.030938908253988897
||w|| 0.15441434041381696
exp ma of ||w|| 0.17364370831916043
||w||^2 0.026891954765198286
exp ma of ||w||^2 0.031182917551225067
||w|| 0.16398766650330227
exp ma of ||w|| 0.17385516185979277
||w||^2 0.014446374081774656
exp ma of ||w||^2 0.03179469113589855
||w|| 0.12019307002391884
exp ma of ||w|| 0.1753935194696182
||w||^2 0.031273114510048175
exp ma of ||w||^2 0.031188451906064257
||w|| 0.17684206091891197
exp ma of ||w|| 0.17369720518678924
||w||^2 0.05064837853125687
exp ma of ||w||^2 0.029740519855256536
||w|| 0.22505194629519842
exp ma of ||w|| 0.17021215408557602
cuda
Objective function 28.97 = squared loss an data 26.92 + 0.5*rho*h**2 1.283100 + alpha*h 0.000000 + L2reg 0.31 + L1reg 0.45 ; SHD = 76 ; DAG False
Proportion of microbatches that were clipped  0.7539964476021315
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 1.6019361720698768
iteration 1 in outer loop, alpha = 1.6019361720698768, rho = 1.0, h = 1.6019361720698768
cuda
9630
cuda
Objective function 31.54 = squared loss an data 26.92 + 0.5*rho*h**2 1.283100 + alpha*h 2.566199 + L2reg 0.31 + L1reg 0.45 ; SHD = 76 ; DAG False
||w||^2 41988.34260862582
exp ma of ||w||^2 20407367.423109416
||w|| 204.91057222267918
exp ma of ||w|| 1426.9720555377623
||w||^2 0.035516439957469045
exp ma of ||w||^2 37823.14708184475
||w|| 0.1884580588817285
exp ma of ||w|| 3.718520425791897
||w||^2 0.03644243097431985
exp ma of ||w||^2 12774.956335993376
||w|| 0.19089900726384057
exp ma of ||w|| 1.375491359963569
||w||^2 0.031876323436070816
exp ma of ||w||^2 0.031099194770946668
||w|| 0.1785394170374453
exp ma of ||w|| 0.17443450567312996
||w||^2 0.024895927497397125
exp ma of ||w||^2 0.02935940099240234
||w|| 0.15778443363461786
exp ma of ||w|| 0.16908108874501712
||w||^2 0.036518467527314066
exp ma of ||w||^2 0.03071931499092233
||w|| 0.1910980573614344
exp ma of ||w|| 0.1727983171396057
||w||^2 0.01761634138131413
exp ma of ||w||^2 0.02811956707105369
||w|| 0.13272656622287088
exp ma of ||w|| 0.16487183780181516
||w||^2 0.027577188596499054
exp ma of ||w||^2 0.03522337525836023
||w|| 0.16606380881004462
exp ma of ||w|| 0.18479506642480842
cuda
Objective function 29.07 = squared loss an data 26.00 + 0.5*rho*h**2 0.566609 + alpha*h 1.705304 + L2reg 0.37 + L1reg 0.42 ; SHD = 67 ; DAG False
Proportion of microbatches that were clipped  0.7520560214966208
iteration 1 in inner loop, alpha 1.6019361720698768 rho 1.0 h 1.0645269375345379
9630
cuda
Objective function 34.17 = squared loss an data 26.00 + 0.5*rho*h**2 5.666088 + alpha*h 1.705304 + L2reg 0.37 + L1reg 0.42 ; SHD = 67 ; DAG False
||w||^2 3519.1363075088616
exp ma of ||w||^2 17331605.22888872
||w|| 59.32230868323368
exp ma of ||w|| 972.5678371268841
||w||^2 0.022427244418188427
exp ma of ||w||^2 0.031238247958077107
||w|| 0.1497572850254318
exp ma of ||w|| 0.17289458733506072
||w||^2 0.035360028097094987
exp ma of ||w||^2 0.03776874894813829
||w|| 0.18804262308608383
exp ma of ||w|| 0.19099310626106275
||w||^2 0.039425785050915235
exp ma of ||w||^2 0.03715075399284473
||w|| 0.19855927339440793
exp ma of ||w|| 0.18916100697646215
||w||^2 0.025795263921449728
exp ma of ||w||^2 0.03754332027325177
||w|| 0.1606090405968784
exp ma of ||w|| 0.19055464145491818
||w||^2 0.06977810107706484
exp ma of ||w||^2 0.034413278331449686
||w|| 0.26415544869842233
exp ma of ||w|| 0.18213667644844975
||w||^2 0.02837475147734711
exp ma of ||w||^2 0.03483746865630415
||w|| 0.16844806759754505
exp ma of ||w|| 0.18333117152363376
||w||^2 0.03106775115002884
exp ma of ||w||^2 0.03725370837645201
||w|| 0.1762604639447793
exp ma of ||w|| 0.18955076570192303
||w||^2 0.03356531359863271
exp ma of ||w||^2 0.036187539825473694
||w|| 0.1832083884505093
exp ma of ||w|| 0.1863721496047256
||w||^2 0.017895643614173888
exp ma of ||w||^2 0.036961343688081086
||w|| 0.13377460003369057
exp ma of ||w|| 0.1884162929817165
||w||^2 0.04139133062131228
exp ma of ||w||^2 0.04048670262627127
||w|| 0.20344859454248457
exp ma of ||w|| 0.19760944946355455
||w||^2 0.026231147572470866
exp ma of ||w||^2 0.04102443527637287
||w|| 0.16196032715597627
exp ma of ||w|| 0.19797814978030925
||w||^2 0.04658332215834688
exp ma of ||w||^2 0.0395999766485453
||w|| 0.21583169868753496
exp ma of ||w|| 0.19481785274434038
cuda
Objective function 29.15 = squared loss an data 26.63 + 0.5*rho*h**2 1.025569 + alpha*h 0.725509 + L2reg 0.41 + L1reg 0.37 ; SHD = 59 ; DAG True
Proportion of microbatches that were clipped  0.7563113040681781
iteration 2 in inner loop, alpha 1.6019361720698768 rho 10.0 h 0.45289494506335615
9630
cuda
Objective function 38.38 = squared loss an data 26.63 + 0.5*rho*h**2 10.255692 + alpha*h 0.725509 + L2reg 0.41 + L1reg 0.37 ; SHD = 59 ; DAG True
||w||^2 16329068295.230469
exp ma of ||w||^2 4701044552.206677
||w|| 127785.24286955231
exp ma of ||w|| 36353.16124553418
||w||^2 0.7089904625953349
exp ma of ||w||^2 491258.43729611527
||w|| 0.8420157139836139
exp ma of ||w|| 20.681668269315132
||w||^2 0.6363038874698698
exp ma of ||w||^2 481482.40504788567
||w|| 0.7976865847373076
exp ma of ||w|| 20.284597616386822
||w||^2 0.12145821815075919
exp ma of ||w||^2 1876.0312537223463
||w|| 0.3485085625214382
exp ma of ||w|| 0.4496666054135907
||w||^2 0.07196972903306152
exp ma of ||w||^2 93.93781231962804
||w|| 0.2682717447534524
exp ma of ||w|| 0.2741887067296937
||w||^2 0.023912380523086366
exp ma of ||w||^2 0.07885748539013929
||w|| 0.15463628462649498
exp ma of ||w|| 0.1852060059689949
||w||^2 0.05345545774574298
exp ma of ||w||^2 0.03926973306166305
||w|| 0.23120436359580884
exp ma of ||w|| 0.1934078063637703
||w||^2 0.09322969327337507
exp ma of ||w||^2 0.04269925887006067
||w|| 0.30533537835202634
exp ma of ||w|| 0.20258250069753114
||w||^2 0.05411753819094798
exp ma of ||w||^2 0.04325827339748503
||w|| 0.2326317652233847
exp ma of ||w|| 0.20399434802616337
||w||^2 0.032953378204430075
exp ma of ||w||^2 0.042053968636596946
||w|| 0.18153065362199872
exp ma of ||w|| 0.2008879764208247
||w||^2 0.029153684866569777
exp ma of ||w||^2 0.04416957823031132
||w|| 0.1707445017169507
exp ma of ||w|| 0.20520372244563356
||w||^2 0.021994482370417033
exp ma of ||w||^2 0.040810175908289295
||w|| 0.14830536865001562
exp ma of ||w|| 0.19781965504210647
||w||^2 0.02572753890746436
exp ma of ||w||^2 0.041468698038884776
||w|| 0.16039806391432646
exp ma of ||w|| 0.19965897873550345
||w||^2 0.03672496869768928
exp ma of ||w||^2 0.04071024750491311
||w|| 0.19163759729679686
exp ma of ||w|| 0.19755999782160208
||w||^2 0.06070696169201669
exp ma of ||w||^2 0.041937097544876775
||w|| 0.24638782780814616
exp ma of ||w|| 0.20027307417187085
||w||^2 0.022121053110211585
exp ma of ||w||^2 0.042312774776160716
||w|| 0.1487314798898054
exp ma of ||w|| 0.20120717659508824
||w||^2 0.03796023111453584
exp ma of ||w||^2 0.044177211082159266
||w|| 0.19483385515493923
exp ma of ||w|| 0.20519072133766722
cuda
Objective function 29.39 = squared loss an data 27.26 + 0.5*rho*h**2 1.142407 + alpha*h 0.242142 + L2reg 0.44 + L1reg 0.31 ; SHD = 62 ; DAG True
Proportion of microbatches that were clipped  0.7547323096920953
iteration 3 in inner loop, alpha 1.6019361720698768 rho 100.0 h 0.1511560105184344
iteration 2 in outer loop, alpha = 16.717537223913318, rho = 100.0, h = 0.1511560105184344
cuda
9630
cuda
Objective function 31.68 = squared loss an data 27.26 + 0.5*rho*h**2 1.142407 + alpha*h 2.526956 + L2reg 0.44 + L1reg 0.31 ; SHD = 62 ; DAG True
||w||^2 759875039.9709746
exp ma of ||w||^2 2245169648.7141037
||w|| 27565.831022680497
exp ma of ||w|| 39549.12063453054
||w||^2 1711745.370452128
exp ma of ||w||^2 133510468.27098435
||w|| 1308.3368719302105
exp ma of ||w|| 5245.058455434673
||w||^2 8190.420656818077
exp ma of ||w||^2 26564936.9401337
||w|| 90.50094285043707
exp ma of ||w|| 1250.9188251719797
||w||^2 0.18385136202901198
exp ma of ||w||^2 48226.93590260015
||w|| 0.4287789197582036
exp ma of ||w|| 3.1642170649029184
||w||^2 0.025519974788178447
exp ma of ||w||^2 5.246396625659101
||w|| 0.15974972547137115
exp ma of ||w|| 0.22173912066307822
v before min max tensor([[ 11.596,  12.248,  15.979,  ...,  -0.530,  -6.046,  -7.810],
        [-11.170,  -5.971,   2.815,  ...,   2.598, -10.694,  -9.736],
        [  6.861,  -8.529,  -9.368,  ...,  -8.390,  -7.765,   4.990],
        ...,
        [ -6.937,  -1.363, -10.711,  ...,  -4.392,  -7.931, -13.604],
        [ -4.825,  -8.482,  -6.746,  ...,  -6.037,  -7.236,  -3.096],
        [  1.142, -10.339,  -8.643,  ...,   4.346,  24.686,  -2.379]],
       device='cuda:0')
v tensor([[1.000e+01, 1.000e+01, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 2.815e+00,  ..., 2.598e+00, 1.000e-12,
         1.000e-12],
        [6.861e+00, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         4.990e+00],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.142e+00, 1.000e-12, 1.000e-12,  ..., 4.346e+00, 1.000e+01,
         1.000e-12]], device='cuda:0')
v before min max tensor([ 5.699e+00, -1.077e+01, -3.205e+00, -6.774e+00, -1.051e+00,  3.774e+00,
        -1.048e+01, -6.752e+00,  7.996e+00, -1.239e+01, -9.177e+00, -9.800e+00,
        -8.156e+00,  1.028e+01,  1.243e+01, -9.806e+00,  4.005e+00, -6.415e+00,
        -8.732e+00, -1.024e+01,  2.786e+00, -6.477e+00,  1.288e+01,  6.896e+00,
        -8.552e+00, -2.862e+00,  2.031e+01, -5.292e+00,  1.870e+01,  6.768e+00,
        -4.103e+00,  4.386e+01,  1.378e+01, -5.283e+00, -1.020e+01, -8.500e+00,
         1.462e+01, -7.541e+00,  6.393e+00, -9.532e+00, -3.935e+00,  3.877e+00,
        -3.945e+00, -4.338e+00, -1.193e+00, -9.232e+00, -6.864e+00, -4.020e+00,
        -6.542e+00, -6.350e+00,  1.128e+01,  3.810e+01, -7.178e+00, -8.024e+00,
        -6.116e+00, -6.726e+00, -8.441e+00,  4.152e+00,  3.193e+01, -3.548e+00,
        -6.531e+00,  5.339e+00, -8.483e+00, -1.099e+01, -2.811e+00, -2.871e+00,
        -2.811e+00,  2.796e+01, -2.350e+00, -5.989e+00, -7.427e+00, -1.482e+00,
        -4.564e+00, -6.083e+00,  1.265e+00, -3.130e+00,  2.668e+00, -1.033e+01,
        -4.778e+00,  1.873e+01, -3.040e+00, -5.794e+00, -9.396e+00, -5.092e+00,
        -7.168e+00, -9.210e+00,  1.288e+01,  1.502e+01,  9.975e+00, -6.432e+00,
        -6.537e+00, -9.852e+00, -9.931e+00, -6.004e+00,  7.760e+00, -9.165e+00,
        -5.305e+00, -5.122e+00,  5.981e-01, -9.495e+00, -3.262e+00, -9.532e+00,
         3.205e+01, -1.105e+01, -9.173e+00, -3.744e+00, -7.695e+00,  2.699e-02,
        -8.371e+00, -5.261e+00, -8.771e+00, -7.844e-01, -2.800e-01, -8.826e+00,
        -8.245e+00,  4.048e+00, -8.557e+00,  4.324e+01, -6.159e+00, -1.056e+01,
        -7.295e+00, -5.120e+00, -3.750e-01,  4.915e+00, -8.555e+00, -7.782e+00,
        -5.564e+00, -2.299e+00, -5.085e+00, -8.537e-01,  2.155e+01, -3.831e+00,
        -4.477e+00,  2.837e-01,  6.911e+00, -7.414e+00, -1.029e+01,  7.119e-01,
         6.312e+00,  1.353e+01, -8.695e+00, -6.202e+00,  4.300e+01,  3.208e+01,
        -4.476e+00, -6.861e-01, -1.058e+01,  4.462e+00, -5.985e+00, -8.030e+00,
        -1.915e+00, -3.022e+00, -9.141e+00, -8.065e+00,  7.301e+00, -2.898e+00,
         5.022e-01, -6.283e+00,  2.319e+01,  1.393e+01, -3.984e+00, -8.052e+00,
         2.727e+01, -5.945e+00, -8.413e+00, -9.570e+00, -8.503e+00, -1.316e+01,
        -1.900e+00,  2.398e+01, -7.939e+00,  1.249e+00,  2.624e+01, -1.118e+01,
        -6.093e+00, -1.021e+01, -1.576e+00,  3.655e+00, -8.062e+00, -7.001e+00,
        -1.010e+01,  9.887e+00, -5.270e+00,  1.372e-01, -6.257e+00,  1.520e+01,
        -7.249e+00,  1.302e+01, -1.085e+01, -4.224e+00, -2.530e+00,  5.035e+00,
         4.082e+01, -7.459e+00, -6.929e+00, -4.601e+00, -1.205e+01,  5.299e-01,
        -1.167e+01, -7.958e+00, -4.666e+00,  9.594e+00, -1.129e+01, -8.619e+00,
         2.741e+00, -9.186e+00, -1.407e+00,  3.830e+00, -9.733e+00, -6.792e+00,
         2.686e+00,  7.216e-01, -9.117e+00, -7.191e+00, -6.978e+00, -1.004e+01,
        -9.350e+00, -1.054e+00, -8.916e+00,  1.222e+00, -3.317e+00, -7.966e+00,
        -9.046e+00,  2.247e+00, -8.922e+00, -4.880e+00,  3.646e+00, -6.317e+00,
         2.361e-01, -5.993e+00,  1.734e+01, -7.467e+00, -9.493e-01,  1.905e+00,
        -1.523e+00,  1.046e+01, -6.692e+00, -9.829e+00,  2.690e+01,  2.069e+00,
        -1.070e+01,  1.458e+01, -9.343e+00, -3.224e+00, -4.908e+00, -4.777e+00,
        -8.822e+00,  1.288e+00, -5.430e+00, -2.434e+00, -4.771e+00, -7.500e+00,
        -5.468e-01,  6.108e+01, -8.607e-01,  1.992e+00, -6.567e+00, -6.524e+00,
        -8.144e-01, -9.379e+00, -8.448e+00, -7.300e+00, -1.250e+01, -1.081e+01,
        -1.035e+01, -8.288e+00,  7.270e+00,  3.607e+00, -9.132e+00, -9.035e+00,
        -5.050e+00, -8.506e+00,  5.792e+01, -7.534e+00, -7.352e+00, -5.304e+00,
        -1.025e+01, -7.821e+00,  1.071e+01,  6.335e+00,  7.520e+00, -9.400e+00,
        -8.493e+00, -5.025e-01, -5.550e+00, -1.030e+01, -6.075e+00,  5.589e+01,
        -2.202e+00, -1.474e+00,  1.085e+01, -6.194e+00, -1.271e+00, -7.698e+00,
        -9.333e+00, -1.578e+00, -1.267e+00, -1.061e+01, -4.453e+00, -6.755e+00],
       device='cuda:0')
v tensor([5.699e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.774e+00,
        1.000e-12, 1.000e-12, 7.996e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 4.005e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 2.786e+00, 1.000e-12, 1.000e+01, 6.896e+00,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 6.768e+00,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 6.393e+00, 1.000e-12, 1.000e-12, 3.877e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 4.152e+00, 1.000e+01, 1.000e-12,
        1.000e-12, 5.339e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.265e+00, 1.000e-12, 2.668e+00, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 9.975e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 7.760e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 5.981e-01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.699e-02,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 4.048e+00, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 4.915e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 2.837e-01, 6.911e+00, 1.000e-12, 1.000e-12, 7.119e-01,
        6.312e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 4.462e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 7.301e+00, 1.000e-12,
        5.022e-01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.249e+00, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 3.655e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 9.887e+00, 1.000e-12, 1.372e-01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 5.035e+00,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.299e-01,
        1.000e-12, 1.000e-12, 1.000e-12, 9.594e+00, 1.000e-12, 1.000e-12,
        2.741e+00, 1.000e-12, 1.000e-12, 3.830e+00, 1.000e-12, 1.000e-12,
        2.686e+00, 7.216e-01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.222e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 2.247e+00, 1.000e-12, 1.000e-12, 3.646e+00, 1.000e-12,
        2.361e-01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.905e+00,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 2.069e+00,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.288e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.992e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 7.270e+00, 3.607e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 6.335e+00, 7.520e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-3.751e+00],
         [-8.941e+00],
         [ 1.884e+01],
         [-9.257e+00],
         [-6.379e+00],
         [-5.163e+00],
         [ 8.885e+00],
         [ 9.171e+00],
         [-6.287e+00],
         [-7.689e-01]],

        [[ 1.057e+01],
         [-5.890e+00],
         [-5.301e+00],
         [-9.851e+00],
         [-2.697e+00],
         [-7.240e+00],
         [ 1.569e+01],
         [-9.899e+00],
         [ 5.630e+00],
         [ 1.489e+01]],

        [[-4.466e-01],
         [-4.753e+00],
         [-1.092e+01],
         [-4.723e+00],
         [ 2.004e+01],
         [ 1.323e+01],
         [-6.808e+00],
         [-9.909e+00],
         [-2.610e+00],
         [ 9.856e+00]],

        [[-7.340e+00],
         [-2.013e-01],
         [ 9.420e+00],
         [-8.586e+00],
         [-2.352e-01],
         [-6.700e+00],
         [-3.939e+00],
         [ 1.782e+01],
         [-8.653e+00],
         [-5.289e+00]],

        [[ 4.813e+00],
         [-4.403e+00],
         [ 3.209e+01],
         [-7.008e+00],
         [ 4.173e+01],
         [-6.874e+00],
         [-9.259e+00],
         [ 2.404e+01],
         [ 8.307e+00],
         [ 2.439e+01]],

        [[-1.219e+00],
         [ 2.796e+01],
         [-8.151e+00],
         [ 3.130e+00],
         [-6.682e+00],
         [ 1.238e+01],
         [-4.711e+00],
         [-1.098e+01],
         [ 6.057e+00],
         [-5.765e+00]],

        [[-1.064e+01],
         [-6.854e+00],
         [-5.320e+00],
         [-8.166e+00],
         [-8.266e+00],
         [ 7.357e+00],
         [-8.202e+00],
         [-7.809e+00],
         [-6.385e+00],
         [-9.700e-01]],

        [[-9.607e+00],
         [-9.664e+00],
         [-1.067e+01],
         [-1.007e+01],
         [ 6.803e+00],
         [-8.477e+00],
         [-1.192e+01],
         [ 8.680e+00],
         [-1.084e+01],
         [-1.164e+01]],

        [[-9.314e+00],
         [ 9.258e+00],
         [ 5.194e+00],
         [-1.084e+01],
         [ 1.694e+01],
         [ 6.484e+00],
         [-6.388e+00],
         [-8.087e+00],
         [-7.934e+00],
         [-7.002e+00]],

        [[-4.975e+00],
         [-1.179e+00],
         [-8.906e+00],
         [-3.260e+00],
         [-7.854e+00],
         [ 9.509e+00],
         [-1.166e+01],
         [-1.593e+00],
         [-7.172e+00],
         [-1.103e+01]],

        [[-8.407e+00],
         [-9.162e-01],
         [-4.855e+00],
         [-9.113e+00],
         [-8.011e+00],
         [ 1.092e+01],
         [-8.845e+00],
         [-7.060e+00],
         [-1.017e+01],
         [ 1.353e+01]],

        [[ 1.125e+01],
         [-7.658e+00],
         [-1.228e+01],
         [ 1.424e+01],
         [ 1.030e+02],
         [ 2.299e+01],
         [ 1.718e+00],
         [ 4.988e+00],
         [-9.430e+00],
         [ 1.075e+02]],

        [[-6.855e+00],
         [-1.977e+00],
         [-8.625e+00],
         [ 5.733e+00],
         [-8.237e+00],
         [ 1.709e+01],
         [-1.111e+01],
         [ 4.771e+00],
         [ 2.768e+00],
         [-6.807e+00]],

        [[-2.042e+00],
         [ 4.920e+01],
         [ 1.218e+00],
         [-9.332e+00],
         [-6.928e+00],
         [ 4.766e+00],
         [-1.132e+01],
         [-3.727e+00],
         [-9.154e+00],
         [ 2.802e+00]],

        [[-3.052e+00],
         [-9.378e+00],
         [-1.052e+01],
         [-5.019e+00],
         [-1.215e+00],
         [ 5.178e+01],
         [-4.657e+00],
         [-8.318e+00],
         [-7.368e+00],
         [ 1.206e+01]],

        [[-8.219e+00],
         [-4.984e+00],
         [ 6.988e+00],
         [ 4.405e+01],
         [-9.128e+00],
         [-6.165e+00],
         [-1.051e+01],
         [-1.400e+00],
         [-1.116e+01],
         [-2.895e-01]],

        [[-6.558e+00],
         [-8.238e+00],
         [-6.360e+00],
         [-4.250e+00],
         [-8.088e-01],
         [ 7.201e+00],
         [-1.147e+01],
         [-4.809e+00],
         [-5.709e+00],
         [ 1.510e+01]],

        [[-5.354e+00],
         [ 2.389e+01],
         [ 1.294e+01],
         [-1.046e+01],
         [-9.239e+00],
         [-9.108e+00],
         [ 3.639e+00],
         [-7.081e+00],
         [ 1.767e+01],
         [-1.089e+01]],

        [[-4.396e+00],
         [ 1.561e+00],
         [-2.871e+00],
         [ 1.440e+01],
         [-8.754e+00],
         [-9.654e+00],
         [-3.882e+00],
         [-6.602e+00],
         [-1.994e+00],
         [-8.092e-01]],

        [[-9.621e+00],
         [ 4.568e+00],
         [-7.781e+00],
         [-1.076e+01],
         [-3.991e+00],
         [ 2.129e-02],
         [-1.114e+01],
         [ 2.726e+01],
         [ 1.275e+01],
         [-9.873e+00]],

        [[ 1.204e+01],
         [ 4.530e+00],
         [-9.089e+00],
         [-2.784e+00],
         [-8.693e+00],
         [-1.002e+01],
         [ 2.019e+00],
         [-1.032e+01],
         [ 3.225e+00],
         [-1.654e+00]],

        [[ 7.451e+00],
         [-1.073e+01],
         [-1.012e+01],
         [-9.887e+00],
         [ 1.144e+01],
         [-3.643e+00],
         [ 1.039e+01],
         [-2.255e+00],
         [-4.078e+00],
         [-5.962e+00]],

        [[-1.060e+01],
         [ 1.460e+01],
         [-9.333e+00],
         [ 3.115e+01],
         [-7.043e+00],
         [ 1.478e+01],
         [ 2.588e+01],
         [-7.850e+00],
         [ 3.709e+00],
         [-1.144e+01]],

        [[-9.777e+00],
         [-7.007e+00],
         [-6.132e+00],
         [-8.553e+00],
         [ 3.971e+01],
         [-9.484e+00],
         [ 2.617e+01],
         [-8.322e+00],
         [ 3.350e+00],
         [-7.854e+00]],

        [[-5.745e+00],
         [-6.084e+00],
         [ 6.735e+01],
         [-8.563e+00],
         [ 6.970e+00],
         [-2.767e+00],
         [-7.225e+00],
         [ 3.406e+01],
         [-8.261e+00],
         [ 2.122e+01]],

        [[-1.244e+01],
         [-7.044e+00],
         [-3.097e+00],
         [-7.795e+00],
         [-4.858e+00],
         [-6.344e+00],
         [-4.287e+00],
         [-1.132e+01],
         [ 5.088e+00],
         [-1.969e+00]],

        [[-8.591e+00],
         [-2.789e+00],
         [-6.067e+00],
         [-9.120e+00],
         [ 7.289e+01],
         [-5.412e+00],
         [ 8.345e+01],
         [-4.457e+00],
         [ 1.216e+00],
         [-4.404e+00]],

        [[-5.722e-01],
         [-4.612e+00],
         [-4.039e+00],
         [-8.771e+00],
         [ 6.022e+01],
         [-1.173e+01],
         [-2.587e+00],
         [-1.057e+01],
         [-4.817e+00],
         [ 7.829e+00]],

        [[ 5.543e-01],
         [-2.563e+00],
         [ 1.261e+01],
         [ 1.600e+01],
         [ 7.078e+00],
         [-5.406e+00],
         [ 2.366e+01],
         [ 2.166e+01],
         [ 1.461e+01],
         [-6.868e+00]],

        [[-8.250e+00],
         [-4.709e-01],
         [ 4.646e+01],
         [-7.874e+00],
         [-8.565e+00],
         [-7.115e+00],
         [-5.920e+00],
         [ 8.480e+00],
         [ 1.633e+00],
         [-4.833e+00]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [8.885e+00],
         [9.171e+00],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [5.630e+00],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [9.856e+00]],

        [[1.000e-12],
         [1.000e-12],
         [9.420e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[4.813e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [8.307e+00],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [3.130e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [6.057e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.357e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.803e+00],
         [1.000e-12],
         [1.000e-12],
         [8.680e+00],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [9.258e+00],
         [5.194e+00],
         [1.000e-12],
         [1.000e+01],
         [6.484e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [9.509e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.718e+00],
         [4.988e+00],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.733e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [4.771e+00],
         [2.768e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.218e+00],
         [1.000e-12],
         [1.000e-12],
         [4.766e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.802e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [6.988e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.201e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.639e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.561e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [4.568e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.129e-02],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [4.530e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.019e+00],
         [1.000e-12],
         [3.225e+00],
         [1.000e-12]],

        [[7.451e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [3.709e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [3.350e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [6.970e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.088e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.216e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.829e+00]],

        [[5.543e-01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [7.078e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [8.480e+00],
         [1.633e+00],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[-11.530],
        [ 53.082],
        [ -9.609],
        [ -8.130],
        [ 23.270],
        [ -1.195],
        [  9.274],
        [ -8.403],
        [ 19.753],
        [-10.103],
        [ -9.977],
        [ -8.200],
        [-10.820],
        [-10.580],
        [-10.287],
        [ -6.283],
        [ -8.928],
        [ -9.695],
        [ 21.652],
        [ -1.568],
        [ -4.689],
        [ -2.659],
        [  1.656],
        [ -5.507],
        [ -5.713],
        [ -6.502],
        [  5.722],
        [ 14.100],
        [ -8.012],
        [ -2.588]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [9.274e+00],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.656e+00],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [5.722e+00],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 0.003,  0.025,  0.028,  ..., -0.016, -0.007,  0.095],
        [ 0.006,  0.061,  0.053,  ..., -0.115,  0.021, -0.056],
        [-0.021, -0.065, -0.047,  ..., -0.062, -0.014,  0.005],
        ...,
        [-0.023, -0.073,  0.069,  ...,  0.011, -0.025, -0.007],
        [-0.021,  0.074, -0.047,  ...,  0.017,  0.260, -0.044],
        [ 0.119,  0.086, -0.130,  ...,  0.159, -0.167,  0.051]],
       device='cuda:0')
s after update for 1 param tensor([[2.356, 1.934, 1.913,  ..., 1.859, 1.313, 1.293],
        [2.137, 1.407, 1.454,  ..., 2.145, 1.762, 1.614],
        [2.106, 1.523, 1.609,  ..., 1.696, 1.273, 1.828],
        ...,
        [1.321, 2.060, 1.992,  ..., 1.371, 1.311, 2.275],
        [1.160, 1.402, 1.133,  ..., 0.998, 1.214, 1.722],
        [1.668, 1.706, 1.802,  ..., 1.896, 1.616, 2.017]], device='cuda:0')
b after update for 1 param tensor([[194.645, 176.387, 175.414,  ..., 172.926, 145.295, 144.222],
        [185.404, 150.412, 152.903,  ..., 185.730, 168.349, 161.097],
        [184.038, 156.500, 160.848,  ..., 165.178, 143.081, 171.485],
        ...,
        [145.776, 182.033, 179.001,  ..., 148.468, 145.208, 191.305],
        [136.601, 150.158, 134.980,  ..., 126.685, 139.727, 166.436],
        [163.808, 165.661, 170.237,  ..., 174.632, 161.212, 180.098]],
       device='cuda:0')
clipping threshold 0.16502717176964302
a after update for 1 param tensor([ 5.924e-02, -1.450e-02,  3.205e-02,  1.565e-02,  1.360e-01,  7.258e-02,
         1.731e-02, -2.931e-01,  1.763e-02,  4.218e-02, -2.370e-01,  7.183e-02,
        -8.426e-02, -7.287e-02,  5.410e-02,  2.081e-01,  8.744e-02,  4.330e-02,
        -1.022e-01,  1.726e-01,  1.368e-02,  5.709e-02, -7.225e-02, -6.282e-03,
        -1.063e-01, -3.513e-02,  1.265e-01, -1.650e-02, -7.058e-02,  1.472e-01,
        -4.008e-02,  1.075e-01,  7.128e-02,  5.817e-02, -2.966e-01, -1.692e-01,
         4.822e-02, -8.327e-02, -2.005e-01,  2.703e-02,  5.296e-03, -2.250e-02,
         9.792e-02, -4.598e-02, -1.027e-03,  9.074e-02, -4.036e-02, -8.852e-02,
         1.110e-01,  3.076e-02, -8.125e-02,  7.503e-02,  1.083e-01, -6.710e-02,
         3.488e-02,  4.029e-02, -5.566e-02,  3.421e-02,  3.504e-02, -1.079e-01,
        -2.247e-02, -1.344e-01,  5.621e-02, -1.048e-03, -6.415e-02,  3.074e-02,
         1.731e-01,  5.139e-02, -1.111e-01,  4.651e-03, -2.595e-02,  6.375e-02,
        -1.022e-01,  1.320e-03, -1.124e-01,  1.570e-01,  5.441e-02,  4.223e-02,
        -1.824e-01, -2.130e-02, -4.570e-02, -2.417e-01,  1.283e-01, -1.305e-01,
        -8.056e-02, -5.115e-02, -1.532e-01,  4.568e-02,  9.457e-02, -1.867e-01,
         1.174e-01,  8.553e-02, -1.340e-02,  3.532e-02, -4.617e-02, -8.849e-02,
         3.106e-02, -1.063e-01,  1.443e-02, -2.349e-02,  3.263e-02,  2.568e-02,
        -1.625e-01,  5.253e-02,  1.491e-01, -2.418e-01, -7.960e-02, -5.831e-02,
         7.024e-02,  7.315e-02,  2.580e-02,  1.211e-02,  8.110e-02, -2.674e-02,
         1.662e-02,  6.628e-02, -1.959e-01, -1.111e-02, -1.258e-01, -2.164e-02,
         6.561e-02, -3.106e-02,  5.199e-02, -1.392e-01,  9.013e-03,  7.129e-02,
        -2.422e-04, -6.925e-02, -1.810e-01,  7.541e-03,  1.723e-02,  7.691e-02,
        -2.491e-01, -3.200e-03, -5.695e-02, -1.743e-03,  1.607e-02,  7.228e-03,
         4.653e-02, -8.294e-03,  9.084e-02,  2.731e-02,  1.358e-01,  8.253e-02,
        -2.044e-01, -1.830e-02, -1.303e-01,  1.331e-01,  1.645e-01,  2.042e-02,
        -7.790e-03, -8.710e-02,  9.188e-02, -1.390e-01,  2.062e-01,  1.630e-01,
         2.627e-01, -4.313e-02,  8.601e-02, -1.366e-01, -4.616e-02, -5.242e-02,
         4.853e-01,  1.079e-01,  8.231e-02, -3.349e-02,  4.151e-02,  1.576e-02,
         1.438e-01,  5.258e-02, -8.634e-02,  8.242e-02,  1.192e-01,  1.382e-01,
         2.777e-02, -6.679e-03,  1.103e-01, -1.969e-01, -4.006e-02, -5.152e-02,
        -2.193e-01, -1.186e-02, -1.905e-02,  6.945e-02,  8.327e-02,  1.058e-01,
        -3.596e-02,  1.055e-01, -5.948e-02, -1.816e-01, -2.362e-01,  2.123e-02,
         1.317e-01,  1.837e-01, -6.120e-02,  8.889e-03, -5.157e-02, -1.014e-01,
         3.775e-02, -1.392e-01,  3.889e-02,  4.426e-02, -1.294e-01, -1.411e-01,
         2.562e-01, -1.232e-02, -3.214e-03, -3.540e-02,  6.234e-02,  2.013e-02,
         2.115e-02, -1.086e-01,  4.868e-02,  1.114e-02,  2.230e-02,  1.217e-01,
         1.396e-01, -7.427e-02, -1.505e-01, -5.222e-02, -8.350e-02,  7.034e-02,
         4.115e-01, -1.136e-01,  1.642e-01, -6.317e-02, -2.129e-02,  9.201e-02,
        -3.424e-04, -1.019e-01,  8.389e-03,  3.686e-02, -1.196e-01, -1.461e-02,
        -1.167e-02, -1.360e-01,  4.428e-02,  5.992e-02, -3.665e-02, -4.442e-02,
         1.332e-01,  3.992e-02,  4.940e-02, -9.688e-02, -1.296e-01, -2.221e-02,
        -3.846e-02,  5.017e-02, -7.171e-02, -1.220e-01, -1.324e-02, -8.204e-03,
         1.466e-01,  2.676e-01,  6.529e-02, -3.565e-02, -1.664e-01, -3.581e-02,
        -9.185e-02, -2.101e-01,  1.006e-01, -1.257e-02,  4.691e-02,  4.156e-02,
         6.938e-02,  2.267e-02, -2.106e-02, -2.351e-01,  8.602e-02, -2.870e-02,
        -1.884e-02, -1.148e-01,  2.699e-01, -5.635e-02, -6.706e-02,  1.540e-01,
        -2.366e-03, -4.250e-02, -1.541e-01,  1.749e-02, -7.677e-02, -2.014e-01,
        -5.683e-02,  1.908e-01, -5.273e-02, -7.038e-02, -8.287e-02,  2.505e-01,
        -2.169e-01,  2.720e-01,  5.530e-02, -1.464e-02,  2.414e-02,  2.230e-02,
        -5.596e-02, -2.256e-01,  2.325e-01,  3.476e-02, -1.058e-01, -2.945e-04],
       device='cuda:0')
s after update for 1 param tensor([1.421, 1.828, 1.549, 1.139, 0.669, 1.733, 1.794, 1.428, 1.715, 2.016,
        1.602, 1.625, 1.393, 1.922, 2.116, 1.675, 1.249, 1.618, 1.603, 1.738,
        1.929, 1.353, 1.576, 1.802, 1.591, 1.998, 1.972, 1.463, 1.745, 1.911,
        1.402, 1.910, 1.308, 0.884, 1.668, 2.081, 1.872, 1.475, 2.028, 1.902,
        0.885, 1.471, 1.596, 1.617, 0.882, 1.843, 1.117, 1.323, 1.151, 1.591,
        1.784, 1.736, 1.579, 1.802, 1.929, 1.362, 1.394, 1.681, 1.834, 1.240,
        1.765, 1.377, 1.622, 1.836, 1.237, 1.549, 1.696, 2.049, 1.739, 1.459,
        1.867, 1.513, 1.428, 1.754, 1.758, 1.500, 1.407, 1.680, 1.370, 1.299,
        1.792, 1.194, 2.015, 1.010, 1.343, 1.520, 1.560, 1.770, 1.629, 1.669,
        1.130, 1.775, 1.626, 1.010, 1.780, 1.492, 1.563, 1.306, 1.752, 1.590,
        0.838, 1.826, 1.919, 1.802, 1.544, 1.546, 1.257, 0.926, 1.436, 1.212,
        2.180, 1.727, 1.663, 1.516, 1.508, 1.128, 1.441, 1.617, 1.260, 1.900,
        1.740, 1.691, 1.644, 1.154, 1.423, 1.705, 1.192, 1.530, 1.716, 1.442,
        2.429, 1.724, 1.707, 1.269, 1.637, 1.385, 1.891, 1.512, 1.866, 1.339,
        1.418, 1.474, 1.915, 1.529, 1.979, 1.409, 1.831, 1.694, 1.387, 1.309,
        1.497, 1.422, 2.078, 1.362, 1.330, 1.559, 1.338, 1.383, 1.759, 2.066,
        1.002, 1.349, 2.163, 2.054, 1.426, 1.826, 1.387, 2.163, 1.434, 1.648,
        1.372, 0.996, 1.719, 2.087, 1.534, 1.676, 1.947, 1.753, 1.508, 1.139,
        1.750, 1.487, 1.071, 1.235, 1.773, 2.046, 2.092, 1.856, 1.809, 1.857,
        1.244, 1.422, 2.159, 1.224, 1.187, 1.464, 2.207, 1.279, 1.902, 1.783,
        1.453, 1.930, 1.912, 1.595, 1.252, 1.612, 0.754, 1.627, 1.602, 1.111,
        1.400, 1.356, 1.503, 1.183, 1.506, 1.634, 1.940, 1.644, 1.450, 1.290,
        2.082, 1.523, 1.743, 1.506, 1.491, 1.096, 1.591, 1.218, 1.316, 1.317,
        1.978, 1.378, 1.643, 1.594, 1.179, 1.993, 1.632, 1.865, 1.765, 1.711,
        1.891, 1.993, 1.570, 1.009, 1.593, 1.217, 1.753, 1.174, 1.011, 1.554,
        1.271, 1.234, 1.491, 2.048, 1.233, 1.581, 1.651, 2.017, 1.426, 1.526,
        1.507, 1.250, 2.133, 1.766, 1.685, 1.379, 1.690, 2.021, 1.753, 1.557,
        1.315, 1.417, 1.699, 1.283, 1.515, 1.319, 1.847, 1.287, 1.867, 1.309,
        1.608, 1.562, 1.863, 1.020, 1.420, 1.679, 1.231, 2.002, 1.368, 1.511,
        1.709, 1.452, 1.285, 1.723, 1.780, 1.537, 1.435, 1.794, 1.048, 1.975],
       device='cuda:0')
b after update for 1 param tensor([151.181, 171.486, 157.821, 135.349, 103.705, 166.928, 169.877, 151.557,
        166.076, 180.056, 160.527, 161.651, 149.700, 175.837, 184.471, 164.116,
        141.733, 161.327, 160.567, 167.207, 176.148, 147.493, 159.187, 170.263,
        159.964, 179.248, 178.090, 153.372, 167.548, 175.313, 150.165, 175.261,
        145.051, 119.272, 163.771, 182.950, 173.501, 154.005, 180.621, 174.888,
        119.282, 153.788, 160.220, 161.281, 119.136, 172.176, 134.006, 145.897,
        136.075, 159.980, 169.370, 167.119, 159.386, 170.255, 176.144, 148.000,
        149.757, 164.443, 171.761, 141.196, 168.475, 148.840, 161.527, 171.846,
        141.039, 157.847, 165.165, 181.525, 167.261, 153.199, 173.297, 156.007,
        151.536, 167.947, 168.146, 155.343, 150.454, 164.380, 148.433, 144.523,
        169.791, 138.553, 180.044, 127.452, 146.959, 156.363, 158.406, 168.706,
        161.879, 163.853, 134.831, 168.981, 161.709, 127.468, 169.182, 154.895,
        158.536, 144.940, 167.878, 159.895, 116.089, 171.394, 175.672, 170.240,
        157.587, 157.676, 142.161, 122.039, 151.997, 139.634, 187.257, 166.644,
        163.531, 156.148, 155.733, 134.700, 152.249, 161.275, 142.331, 174.809,
        167.271, 164.914, 162.608, 136.258, 151.309, 165.617, 138.459, 156.848,
        166.152, 152.285, 197.643, 166.517, 165.703, 142.848, 162.269, 149.228,
        174.404, 155.947, 173.221, 146.753, 151.005, 153.968, 175.477, 156.841,
        178.398, 150.557, 171.590, 165.064, 149.337, 145.084, 155.175, 151.205,
        182.833, 147.993, 146.280, 158.329, 146.676, 149.125, 168.181, 182.291,
        126.926, 147.276, 186.530, 181.748, 151.428, 171.381, 149.334, 186.528,
        151.842, 162.822, 148.566, 126.578, 166.283, 183.207, 157.071, 164.184,
        176.980, 167.914, 155.752, 135.336, 167.768, 154.673, 131.248, 140.949,
        168.867, 181.389, 183.418, 172.751, 170.560, 172.801, 141.461, 151.224,
        186.344, 140.328, 138.161, 153.422, 188.415, 143.437, 174.913, 169.328,
        152.867, 176.164, 175.367, 160.175, 141.902, 161.034, 110.139, 161.746,
        160.528, 133.675, 150.076, 147.655, 155.454, 137.950, 155.608, 162.112,
        176.640, 162.602, 152.725, 144.042, 182.990, 156.487, 167.447, 155.638,
        154.843, 132.748, 159.946, 139.965, 145.485, 145.519, 178.363, 148.875,
        162.561, 160.119, 137.725, 179.018, 161.999, 173.211, 168.483, 165.887,
        174.381, 179.031, 158.908, 127.361, 160.045, 139.884, 167.900, 137.426,
        127.519, 158.086, 142.956, 140.906, 154.858, 181.470, 140.829, 159.458,
        162.977, 180.112, 151.424, 156.639, 155.687, 141.780, 185.221, 168.513,
        164.629, 148.944, 164.872, 180.271, 167.903, 158.265, 145.417, 150.988,
        165.300, 143.642, 156.084, 145.625, 172.362, 143.871, 173.280, 145.110,
        160.815, 158.522, 173.080, 128.096, 151.150, 164.330, 140.683, 179.452,
        148.341, 155.898, 165.800, 152.828, 143.785, 166.479, 169.217, 157.203,
        151.894, 169.849, 129.824, 178.247], device='cuda:0')
clipping threshold 0.16502717176964302
a after update for 1 param tensor([[[ 7.787e-02],
         [-9.187e-02],
         [-1.273e-01],
         [-2.577e-02],
         [-1.139e-01],
         [ 1.266e-01],
         [-7.519e-02],
         [-8.258e-02],
         [-4.556e-02],
         [ 6.358e-02]],

        [[-4.853e-02],
         [ 1.567e-01],
         [-7.865e-02],
         [-8.513e-03],
         [ 3.349e-02],
         [ 2.043e-01],
         [ 9.291e-02],
         [ 1.861e-03],
         [-3.590e-02],
         [-9.491e-02]],

        [[-6.234e-02],
         [-1.148e-01],
         [ 7.937e-02],
         [-1.091e-01],
         [ 9.121e-02],
         [ 2.441e-02],
         [-8.117e-02],
         [-9.078e-03],
         [ 1.524e-01],
         [-5.585e-02]],

        [[ 8.372e-02],
         [ 1.364e-02],
         [ 5.660e-02],
         [ 4.935e-02],
         [ 9.116e-02],
         [ 7.470e-02],
         [ 5.851e-02],
         [ 2.489e-02],
         [ 3.272e-02],
         [-7.814e-02]],

        [[ 1.368e-02],
         [ 8.497e-03],
         [-1.009e-01],
         [ 1.189e-02],
         [-2.122e-03],
         [-7.743e-02],
         [-3.031e-02],
         [ 5.950e-03],
         [ 1.097e-02],
         [ 1.555e-01]],

        [[ 3.660e-02],
         [-8.782e-02],
         [ 2.534e-02],
         [-1.150e-01],
         [-1.791e-02],
         [-1.190e-01],
         [-1.179e-01],
         [ 9.876e-02],
         [-3.151e-02],
         [ 8.773e-02]],

        [[-3.704e-02],
         [ 3.108e-02],
         [-1.050e-01],
         [-3.720e-02],
         [-4.575e-02],
         [ 1.047e-01],
         [ 4.975e-02],
         [ 1.463e-02],
         [-1.943e-01],
         [-2.815e-02]],

        [[ 1.711e-01],
         [-7.158e-02],
         [ 8.710e-02],
         [ 1.234e-02],
         [-1.769e-01],
         [ 1.358e-01],
         [-2.179e-01],
         [ 1.503e-02],
         [-1.983e-03],
         [ 1.320e-02]],

        [[-4.405e-02],
         [-5.952e-02],
         [ 3.196e-02],
         [-8.536e-03],
         [ 7.846e-02],
         [ 7.061e-02],
         [-5.312e-02],
         [ 2.222e-01],
         [ 2.505e-02],
         [-4.707e-02]],

        [[-8.168e-02],
         [-1.285e-01],
         [ 2.029e-01],
         [ 9.790e-03],
         [ 2.561e-02],
         [ 1.025e-01],
         [-1.467e-03],
         [ 4.346e-02],
         [-3.440e-02],
         [-8.188e-02]],

        [[ 1.291e-01],
         [ 2.764e-03],
         [ 7.217e-02],
         [ 1.274e-01],
         [-1.426e-01],
         [-7.929e-02],
         [ 7.775e-02],
         [-6.374e-02],
         [-9.642e-02],
         [-3.367e-02]],

        [[ 1.125e-01],
         [ 1.704e-01],
         [ 8.245e-03],
         [ 1.324e-01],
         [ 2.824e-02],
         [ 6.419e-02],
         [ 6.291e-02],
         [-8.304e-02],
         [ 9.658e-04],
         [-2.102e-02]],

        [[ 5.680e-02],
         [ 7.544e-02],
         [ 4.636e-02],
         [ 7.551e-02],
         [ 2.231e-02],
         [-4.792e-02],
         [-3.584e-02],
         [ 1.901e-01],
         [-7.867e-02],
         [ 8.696e-02]],

        [[-4.576e-02],
         [ 5.147e-02],
         [ 2.043e-01],
         [ 1.797e-01],
         [-1.715e-01],
         [-1.100e-01],
         [ 1.183e-01],
         [-2.029e-02],
         [-4.603e-02],
         [-1.244e-01]],

        [[ 1.233e-01],
         [-1.463e-03],
         [-1.190e-03],
         [-1.903e-02],
         [ 3.538e-02],
         [ 1.883e-01],
         [-8.691e-02],
         [-3.732e-02],
         [ 2.047e-01],
         [ 9.274e-02]],

        [[-1.399e-02],
         [-2.605e-01],
         [ 4.597e-02],
         [ 2.197e-01],
         [ 4.961e-02],
         [-2.920e-02],
         [-2.080e-01],
         [ 1.959e-01],
         [ 7.539e-02],
         [ 5.050e-02]],

        [[-2.713e-01],
         [ 1.778e-01],
         [-2.471e-02],
         [ 8.063e-02],
         [ 3.960e-03],
         [ 3.696e-02],
         [ 1.470e-01],
         [-7.343e-02],
         [ 2.476e-02],
         [ 1.375e-01]],

        [[-4.061e-02],
         [-5.560e-02],
         [-8.990e-03],
         [-1.106e-01],
         [ 1.338e-01],
         [ 6.623e-02],
         [-1.041e-02],
         [-4.365e-02],
         [ 2.208e-02],
         [-7.946e-03]],

        [[-6.719e-02],
         [-1.087e-02],
         [ 2.056e-02],
         [ 6.845e-03],
         [ 1.465e-02],
         [-1.385e-01],
         [ 1.337e-01],
         [-6.414e-02],
         [ 4.821e-02],
         [ 9.518e-02]],

        [[ 1.960e-01],
         [-1.105e-01],
         [-7.545e-02],
         [-1.736e-01],
         [-2.825e-02],
         [-1.629e-02],
         [ 4.804e-02],
         [-8.442e-03],
         [-2.627e-02],
         [-4.586e-02]],

        [[-1.570e-01],
         [-2.566e-01],
         [-6.773e-02],
         [ 7.379e-02],
         [ 1.991e-01],
         [-1.047e-02],
         [-1.368e-01],
         [ 4.563e-02],
         [-1.083e-01],
         [-4.110e-02]],

        [[ 6.192e-02],
         [ 1.124e-01],
         [ 2.054e-01],
         [-5.895e-02],
         [-1.620e-01],
         [-3.348e-01],
         [ 5.101e-02],
         [ 8.251e-02],
         [ 1.450e-02],
         [-3.317e-02]],

        [[ 6.305e-02],
         [ 1.386e-01],
         [ 1.119e-01],
         [ 4.643e-02],
         [ 4.964e-02],
         [ 8.694e-03],
         [ 1.009e-01],
         [ 3.419e-02],
         [-1.622e-01],
         [ 6.612e-02]],

        [[ 7.751e-02],
         [ 1.059e-02],
         [ 1.709e-02],
         [ 2.885e-02],
         [ 4.880e-03],
         [-4.557e-02],
         [ 6.197e-02],
         [-1.269e-01],
         [-2.718e-04],
         [ 1.131e-01]],

        [[-5.741e-02],
         [ 6.830e-03],
         [ 1.342e-01],
         [-3.067e-02],
         [-3.598e-02],
         [-9.293e-02],
         [ 9.017e-02],
         [-6.080e-02],
         [ 9.656e-02],
         [ 3.564e-02]],

        [[ 5.693e-02],
         [-1.291e-01],
         [-1.264e-02],
         [ 9.895e-02],
         [ 3.527e-02],
         [ 1.155e-01],
         [ 6.143e-02],
         [-2.881e-02],
         [ 2.481e-01],
         [ 2.016e-02]],

        [[ 2.915e-02],
         [ 1.616e-01],
         [-6.075e-02],
         [ 1.072e-02],
         [-2.644e-02],
         [-1.524e-01],
         [ 1.240e-01],
         [ 2.115e-01],
         [-2.139e-01],
         [-9.982e-03]],

        [[ 1.015e-01],
         [ 1.520e-01],
         [ 4.050e-02],
         [ 1.678e-01],
         [-7.403e-02],
         [-3.715e-02],
         [ 2.818e-02],
         [ 1.172e-01],
         [ 2.579e-02],
         [ 1.412e-03]],

        [[-3.083e-03],
         [ 1.342e-01],
         [ 2.165e-02],
         [-1.389e-01],
         [-2.746e-02],
         [ 2.806e-02],
         [-2.522e-02],
         [ 4.207e-02],
         [-5.353e-02],
         [ 9.915e-02]],

        [[ 1.183e-01],
         [-1.041e-01],
         [-6.134e-02],
         [-4.947e-02],
         [-8.905e-02],
         [ 2.470e-02],
         [-4.119e-02],
         [ 2.545e-01],
         [ 1.204e-01],
         [-1.162e-01]]], device='cuda:0')
s after update for 1 param tensor([[[1.182],
         [1.455],
         [1.947],
         [1.517],
         [1.177],
         [1.339],
         [2.155],
         [1.328],
         [1.348],
         [1.010]],

        [[2.373],
         [1.344],
         [1.484],
         [1.704],
         [1.185],
         [1.593],
         [2.129],
         [1.619],
         [1.322],
         [2.029]],

        [[1.019],
         [1.325],
         [1.776],
         [0.828],
         [1.491],
         [1.719],
         [1.291],
         [1.612],
         [1.204],
         [2.047]],

        [[1.513],
         [1.677],
         [2.244],
         [1.445],
         [1.770],
         [1.385],
         [1.019],
         [2.400],
         [1.861],
         [1.195]],

        [[1.773],
         [1.546],
         [1.710],
         [1.657],
         [1.692],
         [1.277],
         [1.691],
         [1.652],
         [1.887],
         [1.452]],

        [[1.748],
         [1.852],
         [1.326],
         [1.519],
         [1.617],
         [1.364],
         [1.533],
         [1.943],
         [1.760],
         [1.746]],

        [[1.739],
         [1.307],
         [1.215],
         [1.555],
         [1.440],
         [1.492],
         [1.681],
         [1.461],
         [1.133],
         [1.810]],

        [[1.577],
         [1.653],
         [1.763],
         [1.954],
         [2.179],
         [1.396],
         [2.152],
         [2.058],
         [1.851],
         [1.905]],

        [[1.565],
         [1.378],
         [1.899],
         [1.822],
         [1.810],
         [1.185],
         [1.514],
         [1.597],
         [1.432],
         [1.672]],

        [[0.914],
         [2.251],
         [1.478],
         [1.329],
         [1.500],
         [2.138],
         [2.199],
         [1.893],
         [1.732],
         [1.854]],

        [[1.498],
         [1.222],
         [1.427],
         [1.576],
         [1.330],
         [2.285],
         [1.759],
         [1.635],
         [1.666],
         [2.013]],

        [[1.939],
         [1.254],
         [2.065],
         [1.811],
         [2.322],
         [1.643],
         [1.432],
         [2.053],
         [1.629],
         [1.712]],

        [[1.177],
         [1.357],
         [1.984],
         [2.071],
         [1.378],
         [1.551],
         [1.809],
         [1.649],
         [1.725],
         [1.459]],

        [[1.079],
         [1.835],
         [1.633],
         [1.875],
         [1.678],
         [1.261],
         [1.890],
         [1.235],
         [1.570],
         [1.526]],

        [[1.579],
         [1.757],
         [1.776],
         [1.374],
         [1.097],
         [1.710],
         [1.414],
         [1.515],
         [1.650],
         [2.138]],

        [[1.863],
         [1.496],
         [1.419],
         [1.910],
         [1.695],
         [1.570],
         [1.712],
         [1.444],
         [1.817],
         [1.289]],

        [[1.103],
         [1.434],
         [1.800],
         [1.476],
         [1.469],
         [1.724],
         [1.906],
         [1.355],
         [1.713],
         [1.789]],

        [[1.430],
         [2.091],
         [1.875],
         [1.704],
         [1.506],
         [1.523],
         [1.307],
         [1.167],
         [2.011],
         [1.975]],

        [[0.808],
         [1.966],
         [1.290],
         [1.399],
         [1.640],
         [2.171],
         [0.996],
         [1.099],
         [1.897],
         [1.689]],

        [[1.820],
         [1.182],
         [1.272],
         [1.855],
         [1.539],
         [1.389],
         [1.898],
         [1.544],
         [1.849],
         [1.788]],

        [[1.872],
         [1.707],
         [1.620],
         [1.686],
         [2.117],
         [1.636],
         [1.932],
         [1.843],
         [1.031],
         [1.880]],

        [[1.819],
         [1.881],
         [1.966],
         [1.619],
         [2.118],
         [1.898],
         [2.530],
         [1.792],
         [0.782],
         [1.873]],

        [[1.905],
         [1.820],
         [1.750],
         [2.086],
         [1.345],
         [1.964],
         [1.925],
         [1.336],
         [1.417],
         [1.948]],

        [[1.674],
         [1.318],
         [1.898],
         [1.932],
         [1.655],
         [1.547],
         [1.790],
         [1.416],
         [1.716],
         [1.281]],

        [[1.381],
         [0.999],
         [1.921],
         [1.562],
         [1.331],
         [1.368],
         [1.212],
         [2.201],
         [1.555],
         [1.895]],

        [[2.040],
         [1.493],
         [0.974],
         [1.638],
         [1.122],
         [1.538],
         [0.704],
         [2.127],
         [1.675],
         [1.578]],

        [[1.620],
         [1.238],
         [1.758],
         [1.570],
         [1.960],
         [1.348],
         [2.350],
         [1.823],
         [1.645],
         [1.302]],

        [[1.426],
         [1.675],
         [1.234],
         [1.565],
         [2.066],
         [2.006],
         [1.549],
         [1.829],
         [1.387],
         [1.349]],

        [[0.936],
         [1.298],
         [1.514],
         [1.808],
         [1.805],
         [1.725],
         [1.324],
         [1.731],
         [2.081],
         [1.330]],

        [[1.686],
         [1.469],
         [2.143],
         [1.317],
         [1.624],
         [1.361],
         [1.854],
         [1.761],
         [1.376],
         [1.817]]], device='cuda:0')
b after update for 1 param tensor([[[137.892],
         [152.975],
         [176.981],
         [156.223],
         [137.577],
         [146.768],
         [186.153],
         [146.144],
         [147.250],
         [127.448]],

        [[195.346],
         [147.051],
         [154.509],
         [165.536],
         [138.030],
         [160.078],
         [185.055],
         [161.375],
         [145.812],
         [180.656]],

        [[128.018],
         [145.961],
         [169.005],
         [115.422],
         [154.859],
         [166.273],
         [144.076],
         [161.008],
         [139.179],
         [181.466]],

        [[156.007],
         [164.256],
         [189.956],
         [152.443],
         [168.711],
         [149.238],
         [127.993],
         [196.471],
         [173.021],
         [138.621]],

        [[168.870],
         [157.698],
         [165.830],
         [163.272],
         [164.966],
         [143.333],
         [164.907],
         [163.017],
         [174.228],
         [152.828]],

        [[167.650],
         [172.571],
         [146.028],
         [156.279],
         [161.258],
         [148.102],
         [156.997],
         [176.774],
         [168.243],
         [167.582]],

        [[167.261],
         [144.992],
         [139.819],
         [158.161],
         [152.162],
         [154.895],
         [164.415],
         [153.272],
         [134.997],
         [170.632]],

        [[159.275],
         [163.075],
         [168.397],
         [177.280],
         [187.209],
         [149.865],
         [186.063],
         [181.913],
         [172.539],
         [175.023]],

        [[158.664],
         [148.878],
         [174.759],
         [171.192],
         [170.629],
         [138.075],
         [156.026],
         [160.262],
         [151.751],
         [163.968]],

        [[121.267],
         [190.277],
         [154.175],
         [146.180],
         [155.302],
         [185.440],
         [188.063],
         [174.477],
         [166.897],
         [172.679]],

        [[155.228],
         [140.215],
         [151.477],
         [159.212],
         [146.276],
         [191.712],
         [168.216],
         [162.167],
         [163.693],
         [179.915]],

        [[176.607],
         [142.041],
         [182.247],
         [170.665],
         [193.230],
         [162.577],
         [151.779],
         [181.730],
         [161.878],
         [165.919]],

        [[137.587],
         [147.723],
         [178.648],
         [182.501],
         [148.850],
         [157.960],
         [170.560],
         [162.839],
         [166.553],
         [153.195]],

        [[131.709],
         [171.796],
         [162.047],
         [173.677],
         [164.295],
         [142.393],
         [174.369],
         [140.939],
         [158.901],
         [156.641]],

        [[159.349],
         [168.081],
         [169.019],
         [148.673],
         [132.801],
         [165.820],
         [150.822],
         [156.093],
         [162.902],
         [185.415]],

        [[173.114],
         [155.130],
         [151.075],
         [175.261],
         [165.107],
         [158.911],
         [165.940],
         [152.385],
         [170.951],
         [143.977]],

        [[133.195],
         [151.891],
         [170.125],
         [154.055],
         [153.715],
         [166.523],
         [175.089],
         [147.610],
         [165.985],
         [169.607]],

        [[151.674],
         [183.370],
         [173.643],
         [165.552],
         [155.647],
         [156.502],
         [145.007],
         [136.983],
         [179.851],
         [178.224]],

        [[114.022],
         [177.804],
         [144.039],
         [149.984],
         [162.416],
         [186.866],
         [126.572],
         [132.943],
         [174.675],
         [164.803]],

        [[171.103],
         [137.897],
         [143.043],
         [172.705],
         [157.313],
         [149.447],
         [174.731],
         [157.594],
         [172.460],
         [169.562]],

        [[173.511],
         [165.687],
         [161.438],
         [164.689],
         [184.508],
         [162.233],
         [176.263],
         [172.163],
         [128.741],
         [173.900]],

        [[171.030],
         [173.928],
         [177.815],
         [161.354],
         [184.574],
         [174.717],
         [201.709],
         [169.764],
         [112.162],
         [173.541]],

        [[175.043],
         [171.104],
         [167.768],
         [183.184],
         [147.088],
         [177.726],
         [175.941],
         [146.597],
         [150.988],
         [177.023]],

        [[164.069],
         [145.568],
         [174.733],
         [176.260],
         [163.162],
         [157.723],
         [169.652],
         [150.889],
         [166.141],
         [143.549]],

        [[149.050],
         [126.736],
         [175.770],
         [158.478],
         [146.322],
         [148.339],
         [139.591],
         [188.147],
         [158.129],
         [174.601]],

        [[181.131],
         [154.963],
         [125.151],
         [162.293],
         [134.348],
         [157.278],
         [106.438],
         [184.942],
         [164.119],
         [159.287]],

        [[161.395],
         [141.107],
         [168.149],
         [158.891],
         [177.551],
         [147.261],
         [194.416],
         [171.234],
         [162.674],
         [144.695]],

        [[151.461],
         [164.150],
         [140.888],
         [158.637],
         [182.281],
         [179.619],
         [157.824],
         [171.516],
         [149.384],
         [147.307]],

        [[122.670],
         [144.485],
         [156.032],
         [170.546],
         [170.372],
         [166.584],
         [145.914],
         [166.832],
         [182.966],
         [146.234]],

        [[164.678],
         [153.714],
         [185.635],
         [145.517],
         [161.605],
         [147.937],
         [172.688],
         [168.301],
         [148.790],
         [170.932]]], device='cuda:0')
clipping threshold 0.16502717176964302
a after update for 1 param tensor([[ 0.117],
        [-0.244],
        [ 0.078],
        [ 0.024],
        [-0.007],
        [-0.024],
        [ 0.023],
        [ 0.039],
        [ 0.141],
        [-0.120],
        [ 0.013],
        [ 0.188],
        [ 0.083],
        [ 0.044],
        [-0.031],
        [ 0.004],
        [-0.012],
        [ 0.092],
        [ 0.059],
        [-0.049],
        [ 0.242],
        [ 0.137],
        [-0.057],
        [-0.119],
        [ 0.037],
        [ 0.079],
        [ 0.010],
        [-0.017],
        [ 0.068],
        [ 0.044]], device='cuda:0')
s after update for 1 param tensor([[1.886],
        [2.152],
        [1.608],
        [1.418],
        [1.581],
        [1.771],
        [1.836],
        [1.476],
        [1.904],
        [1.805],
        [2.025],
        [1.973],
        [2.062],
        [1.932],
        [1.673],
        [1.472],
        [1.772],
        [1.819],
        [1.911],
        [2.019],
        [1.502],
        [1.431],
        [1.518],
        [1.312],
        [1.335],
        [1.756],
        [1.734],
        [1.823],
        [1.416],
        [1.058]], device='cuda:0')
b after update for 1 param tensor([[174.170],
        [186.061],
        [160.803],
        [151.026],
        [159.441],
        [168.792],
        [171.862],
        [154.060],
        [174.996],
        [170.375],
        [180.469],
        [178.123],
        [182.093],
        [176.257],
        [164.050],
        [153.842],
        [168.803],
        [171.041],
        [175.321],
        [180.222],
        [155.428],
        [151.695],
        [156.234],
        [145.275],
        [146.537],
        [168.056],
        [167.016],
        [171.244],
        [150.898],
        [130.477]], device='cuda:0')
clipping threshold 0.16502717176964302
||w||^2 0.030606265037577327
exp ma of ||w||^2 0.0407103211234061
||w|| 0.17494646334686886
exp ma of ||w|| 0.19813947565978177
||w||^2 0.05366144302340793
exp ma of ||w||^2 0.04558754178000772
||w|| 0.23164939676892735
exp ma of ||w|| 0.20923059976418354
||w||^2 0.06591894195777374
exp ma of ||w||^2 0.046581325672148184
||w|| 0.2567468441047986
exp ma of ||w|| 0.21192392565324236
||w||^2 0.03844850662314525
exp ma of ||w||^2 0.0445947691734855
||w|| 0.19608290752420326
exp ma of ||w|| 0.207293375398058
||w||^2 0.027268757339768874
exp ma of ||w||^2 0.040619609332543084
||w|| 0.16513254476259026
exp ma of ||w|| 0.1975808813061445
||w||^2 0.05420826719913369
exp ma of ||w||^2 0.047196519914544745
||w|| 0.2328266891899073
exp ma of ||w|| 0.21258872369051846
||w||^2 0.021311280928097483
exp ma of ||w||^2 0.0494672820883665
||w|| 0.14598383790028774
exp ma of ||w|| 0.21803239435228153
||w||^2 0.062271854435371705
exp ma of ||w||^2 0.04988623571066502
||w|| 0.24954329170581144
exp ma of ||w|| 0.2186353144567426
||w||^2 0.04619347692434378
exp ma of ||w||^2 0.045299732915447075
||w|| 0.21492667801914164
exp ma of ||w|| 0.20785209609981384
||w||^2 0.05250694726480229
exp ma of ||w||^2 0.04476833326884442
||w|| 0.22914394442097372
exp ma of ||w|| 0.20748321609047632
cuda
Objective function 30.33 = squared loss an data 27.35 + 0.5*rho*h**2 0.513662 + alpha*h 1.694439 + L2reg 0.47 + L1reg 0.30 ; SHD = 66 ; DAG True
Proportion of microbatches that were clipped  0.7548115801390911
iteration 1 in inner loop, alpha 16.717537223913318 rho 100.0 h 0.10135700109203327
9630
cuda
Objective function 34.95 = squared loss an data 27.35 + 0.5*rho*h**2 5.136621 + alpha*h 1.694439 + L2reg 0.47 + L1reg 0.30 ; SHD = 66 ; DAG True
||w||^2 11807029.29726285
exp ma of ||w||^2 1164088338.2022285
||w|| 3436.1358089084383
exp ma of ||w|| 21290.397383001702
||w||^2 250.31414913578053
exp ma of ||w||^2 9559378.69964729
||w|| 15.821319449899889
exp ma of ||w|| 300.58252893992125
||w||^2 0.06186066346119262
exp ma of ||w||^2 0.04154926036994539
||w|| 0.24871804007991183
exp ma of ||w|| 0.20066490649802698
||w||^2 0.0472483140188468
exp ma of ||w||^2 0.04143334625287076
||w|| 0.21736677303315427
exp ma of ||w|| 0.20054249680102723
||w||^2 0.039400963868944844
exp ma of ||w||^2 0.04293962427974102
||w|| 0.1984967603487393
exp ma of ||w|| 0.20379805351668817
||w||^2 0.040492551883737384
exp ma of ||w||^2 0.046137926864509946
||w|| 0.20122761213048618
exp ma of ||w|| 0.21090395281858795
||w||^2 0.049720689801800326
exp ma of ||w||^2 0.04569438165539785
||w|| 0.22298136649011802
exp ma of ||w|| 0.21037428895140778
||w||^2 0.029329842093030835
exp ma of ||w||^2 0.045928236216174485
||w|| 0.17125957518641355
exp ma of ||w|| 0.20979105666363146
||w||^2 0.031864761686436975
exp ma of ||w||^2 0.0423181817053356
||w|| 0.17850703539759147
exp ma of ||w|| 0.2016594800390755
||w||^2 0.041754316543814306
exp ma of ||w||^2 0.042805218312311905
||w|| 0.20433872991631885
exp ma of ||w|| 0.20314635054089056
||w||^2 0.025087470047765074
exp ma of ||w||^2 0.043047411999351706
||w|| 0.15839024606258137
exp ma of ||w|| 0.20265721411966542
||w||^2 0.025473058072962886
exp ma of ||w||^2 0.043902938799392666
||w|| 0.1596028134869899
exp ma of ||w|| 0.20495027543456917
||w||^2 0.037545100275071096
exp ma of ||w||^2 0.043534315981479284
||w|| 0.19376558072854708
exp ma of ||w|| 0.20476874738919357
||w||^2 0.037910445675582785
exp ma of ||w||^2 0.04411229698349627
||w|| 0.19470604940674746
exp ma of ||w|| 0.20589117547001431
cuda
Objective function 30.07 = squared loss an data 27.54 + 0.5*rho*h**2 0.993813 + alpha*h 0.745314 + L2reg 0.51 + L1reg 0.28 ; SHD = 65 ; DAG True
Proportion of microbatches that were clipped  0.7590601354042215
iteration 2 in inner loop, alpha 16.717537223913318 rho 1000.0 h 0.04458279129095999
9630
cuda
Objective function 39.01 = squared loss an data 27.54 + 0.5*rho*h**2 9.938126 + alpha*h 0.745314 + L2reg 0.51 + L1reg 0.28 ; SHD = 65 ; DAG True
||w||^2 2797245697.113776
exp ma of ||w||^2 32746008482.83663
||w|| 52888.994101928016
exp ma of ||w|| 136334.80367671864
||w||^2 387173.8679667699
exp ma of ||w||^2 1066639320.4718106
||w|| 622.2329692058835
exp ma of ||w|| 7381.955731264808
||w||^2 0.05306805947915585
exp ma of ||w||^2 3.895806177060249
||w|| 0.23036505698381396
exp ma of ||w|| 0.27062988962434675
||w||^2 0.07471056585848383
exp ma of ||w||^2 1.3052529698986206
||w|| 0.2733323359181709
exp ma of ||w|| 0.25393942822632287
||w||^2 0.03672345348251214
exp ma of ||w||^2 0.6686141054061167
||w|| 0.1916336439211866
exp ma of ||w|| 0.24573945907316175
||w||^2 0.026217708875126613
exp ma of ||w||^2 0.047528691228279386
||w|| 0.16191883421988504
exp ma of ||w|| 0.21328305392057195
||w||^2 0.030663498763334605
exp ma of ||w||^2 0.046163978377764654
||w|| 0.1751099619191741
exp ma of ||w|| 0.21056498979043695
||w||^2 0.07552111894768097
exp ma of ||w||^2 0.050140846312090946
||w|| 0.27481106045368875
exp ma of ||w|| 0.21984749125671066
||w||^2 0.03220444729441544
exp ma of ||w||^2 0.04728712703714421
||w|| 0.17945597592283027
exp ma of ||w|| 0.21329055296017968
||w||^2 0.04750069745685473
exp ma of ||w||^2 0.05051627894306866
||w|| 0.21794654724692183
exp ma of ||w|| 0.22061244973608213
||w||^2 0.09390882987117116
exp ma of ||w||^2 0.050474711858642815
||w|| 0.30644547617997425
exp ma of ||w|| 0.2208308567385004
||w||^2 0.03439863782874673
exp ma of ||w||^2 0.049900427567212885
||w|| 0.18546869770596527
exp ma of ||w|| 0.21955629487749384
v before min max tensor([[ 23.444,  -3.909,   4.967,  ...,  -6.751,  -3.193,  -0.824],
        [ -8.381,   5.520,  -3.040,  ...,  -6.131, -11.278,  -5.154],
        [ -8.403,   5.668,  -5.133,  ..., 113.243, -10.746,  -8.532],
        ...,
        [ 14.623, -10.801, -10.344,  ..., -10.481,  -7.666,  -9.790],
        [-10.575,  23.344, -10.565,  ...,  15.036,  -9.001,   7.793],
        [  4.900,  10.197, -10.987,  ...,  -5.417,   2.308,   7.116]],
       device='cuda:0')
v tensor([[1.000e+01, 1.000e-12, 4.967e+00,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 5.520e+00, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 5.668e+00, 1.000e-12,  ..., 1.000e+01, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e+01, 1.000e-12,
         7.793e+00],
        [4.900e+00, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 2.308e+00,
         7.116e+00]], device='cuda:0')
v before min max tensor([-1.772e-01,  1.575e+00, -1.217e+01, -1.191e+01, -1.301e+00, -2.189e-02,
         4.064e+00, -9.190e+00, -1.034e+01,  1.404e+01,  9.456e+00,  5.530e+00,
        -3.759e+00, -4.827e+00, -1.054e+01,  2.109e+01, -7.711e+00, -6.717e+00,
         5.074e+00,  2.385e+01,  3.302e+00, -7.479e+00, -1.278e+00, -9.302e+00,
         8.570e+00,  4.045e+00, -1.169e+01, -2.276e+00,  3.671e+00, -8.942e+00,
         6.854e+00, -2.895e+00, -3.101e+00, -7.878e+00,  9.383e+00, -2.446e+00,
        -5.019e+00, -7.026e+00, -6.343e+00,  1.132e+01, -4.720e+00,  2.203e+00,
        -5.767e+00, -4.893e+00,  1.080e+01,  7.554e+00,  4.674e+01, -7.560e+00,
         6.107e+01, -2.971e+00, -4.096e+00,  5.578e+00, -7.287e+00, -1.119e+01,
         5.180e+00, -6.623e+00,  5.515e+00, -1.074e+01, -1.082e+01, -8.983e+00,
        -6.712e+00, -1.010e+01, -4.238e+00, -1.658e+00, -7.838e+00, -8.674e+00,
         3.681e+00, -4.045e+00,  1.550e+01, -4.700e+00,  1.899e+01, -1.021e+01,
        -6.846e+00, -7.015e+00, -6.619e+00, -4.682e+00,  9.817e+00, -8.775e+00,
        -1.044e+01, -8.191e+00, -8.214e+00, -9.134e+00, -9.932e+00,  1.095e+01,
        -7.667e+00, -8.434e+00, -3.476e+00,  3.856e+00, -8.337e+00, -2.327e+00,
        -2.948e+00,  3.704e+00, -1.451e+00, -4.745e+00,  1.116e+00, -9.157e+00,
        -6.926e+00, -9.499e+00, -5.447e+00, -4.605e+00, -8.154e-01,  3.807e+01,
        -5.019e+00,  1.842e+00, -5.392e+00, -9.570e+00, -1.220e+01, -3.893e+00,
        -1.169e+01,  3.382e+00, -7.697e+00, -4.136e+00, -3.016e+00,  9.338e+00,
        -3.586e+00,  1.509e+01,  1.072e+01,  5.624e+00, -8.772e+00, -7.683e+00,
        -3.694e+00,  1.138e+01, -9.604e+00, -1.044e+01, -7.396e+00, -1.710e+00,
        -5.949e+00, -6.339e+00,  2.791e+01, -5.272e+00,  6.285e+00,  1.437e+01,
        -9.546e+00, -4.140e+00,  4.905e+00, -6.696e+00, -9.749e+00, -3.620e+00,
        -3.717e+00, -8.382e+00, -7.049e+00, -3.851e+00, -6.457e+00,  5.173e+00,
        -3.984e+00, -6.705e+00, -5.516e+00, -1.236e+01, -2.876e+00, -9.701e+00,
        -9.139e+00, -2.951e+00,  4.071e+01, -8.969e+00, -8.302e+00,  1.088e+00,
         8.935e+00, -1.185e+01,  3.170e+00, -8.329e+00, -1.698e+00, -7.833e+00,
        -2.676e+00, -5.731e+00, -4.739e+00, -7.685e+00, -3.822e+00, -9.081e+00,
        -9.136e+00, -6.084e+00,  5.295e+01, -1.035e+01,  1.256e+01, -6.430e+00,
        -4.774e+00, -5.810e+00, -4.553e+00, -6.715e+00,  1.287e+00, -7.661e+00,
        -8.569e+00,  2.217e+00, -9.604e+00, -8.066e+00, -7.637e+00, -5.574e+00,
        -4.216e+00, -5.809e+00, -7.369e+00, -9.499e+00,  1.815e+01, -5.015e+00,
         2.691e+01, -9.944e+00,  1.301e+00,  3.453e-01, -9.303e+00,  1.248e+01,
        -3.200e+00, -7.172e+00, -7.994e+00,  2.414e-01, -1.189e+01,  1.383e-01,
         2.930e+00, -4.858e+00, -6.656e+00,  2.758e+01,  6.960e+00, -8.561e+00,
        -7.442e+00, -6.621e+00, -6.441e+00,  9.568e-01,  1.319e+00, -4.488e+00,
        -1.027e+01, -1.731e+00, -6.549e+00,  5.599e+00,  2.012e+01, -7.506e+00,
        -9.536e+00, -2.404e+00,  3.013e+01,  7.238e+00, -7.538e+00, -4.745e+00,
        -9.052e+00, -6.530e+00, -8.759e+00, -9.009e+00, -4.081e+00,  1.451e+01,
         3.331e+00, -6.393e+00,  1.808e+01, -8.914e+00, -1.047e+01,  3.163e+01,
         2.563e+01,  1.471e+01, -7.096e+00, -1.035e+01, -2.453e+00, -1.911e-01,
        -1.293e+01, -3.732e+00, -1.018e+01, -1.015e+01,  4.825e+00, -9.143e+00,
        -6.534e-01, -7.783e+00, -1.010e+01, -9.574e+00, -8.823e+00,  9.670e+00,
        -8.797e+00, -6.139e+00,  1.027e+00, -3.831e+00,  8.359e+00, -6.693e+00,
        -6.273e+00, -7.956e+00, -3.428e+00, -4.486e+00,  7.328e+00, -5.849e+00,
        -6.995e+00, -4.201e+00, -4.986e+00,  1.075e+01, -6.885e+00,  9.827e+00,
        -8.958e+00, -5.995e+00, -3.895e+00, -9.728e+00,  1.524e+00, -5.920e+00,
        -1.090e+01, -8.706e+00, -2.434e-01,  2.843e+00,  8.093e-01, -4.311e+00,
        -7.429e+00,  1.142e+01, -9.749e+00, -7.991e+00, -8.603e-01,  2.306e+01,
        -9.394e+00, -5.569e+00, -6.258e+00, -5.567e-02,  8.011e+00, -3.418e+00],
       device='cuda:0')
v tensor([1.000e-12, 1.575e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        4.064e+00, 1.000e-12, 1.000e-12, 1.000e+01, 9.456e+00, 5.530e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        5.074e+00, 1.000e+01, 3.302e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        8.570e+00, 4.045e+00, 1.000e-12, 1.000e-12, 3.671e+00, 1.000e-12,
        6.854e+00, 1.000e-12, 1.000e-12, 1.000e-12, 9.383e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 2.203e+00,
        1.000e-12, 1.000e-12, 1.000e+01, 7.554e+00, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 5.578e+00, 1.000e-12, 1.000e-12,
        5.180e+00, 1.000e-12, 5.515e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        3.681e+00, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 9.817e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 3.856e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 3.704e+00, 1.000e-12, 1.000e-12, 1.116e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.842e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 3.382e+00, 1.000e-12, 1.000e-12, 1.000e-12, 9.338e+00,
        1.000e-12, 1.000e+01, 1.000e+01, 5.624e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 6.285e+00, 1.000e+01,
        1.000e-12, 1.000e-12, 4.905e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.173e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.088e+00,
        8.935e+00, 1.000e-12, 3.170e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.287e+00, 1.000e-12,
        1.000e-12, 2.217e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.301e+00, 3.453e-01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 2.414e-01, 1.000e-12, 1.383e-01,
        2.930e+00, 1.000e-12, 1.000e-12, 1.000e+01, 6.960e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 9.568e-01, 1.319e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 5.599e+00, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 7.238e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        3.331e+00, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 4.825e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 9.670e+00,
        1.000e-12, 1.000e-12, 1.027e+00, 1.000e-12, 8.359e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 7.328e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 9.827e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.524e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 2.843e+00, 8.093e-01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 8.011e+00, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-7.961e+00],
         [-5.362e+00],
         [-7.534e+00],
         [-3.446e+00],
         [ 6.307e+00],
         [ 1.809e+01],
         [-8.786e+00],
         [-6.391e+00],
         [-9.078e+00],
         [ 1.051e+01]],

        [[-9.078e+00],
         [-4.875e+00],
         [ 1.114e+01],
         [-7.570e+00],
         [-2.886e+00],
         [ 8.469e+00],
         [ 3.869e+01],
         [-1.055e+01],
         [-1.270e+01],
         [-7.739e+00]],

        [[ 2.667e+00],
         [-4.417e+00],
         [-9.714e+00],
         [-8.691e+00],
         [-9.442e+00],
         [ 3.213e+01],
         [-6.816e+00],
         [ 2.988e-01],
         [-4.984e+00],
         [ 1.771e+01]],

        [[ 7.345e-01],
         [-7.649e+00],
         [-7.282e+00],
         [-6.862e+00],
         [ 4.872e+00],
         [-5.631e+00],
         [ 1.322e+01],
         [ 6.398e+00],
         [-8.364e+00],
         [-6.178e+00]],

        [[-6.044e+00],
         [-6.433e+00],
         [ 7.307e+00],
         [-7.714e+00],
         [-3.934e+00],
         [-7.120e+00],
         [-1.077e+01],
         [ 5.501e-01],
         [-9.972e+00],
         [-3.778e+00]],

        [[ 1.023e+02],
         [-4.304e+00],
         [ 3.730e+01],
         [-7.873e+00],
         [-1.175e+01],
         [ 3.103e+01],
         [-9.750e+00],
         [-3.191e+00],
         [ 2.206e+01],
         [-5.479e+00]],

        [[ 1.052e+01],
         [-1.011e+01],
         [-4.221e+00],
         [ 8.724e+01],
         [ 2.434e+01],
         [-7.397e+00],
         [-5.377e+00],
         [-1.693e+00],
         [ 5.311e-01],
         [-6.880e+00]],

        [[-3.949e+00],
         [-2.729e+00],
         [-6.850e+00],
         [-7.769e+00],
         [-6.172e+00],
         [ 8.572e-01],
         [-8.916e+00],
         [-1.961e-01],
         [-9.176e+00],
         [ 3.590e+00]],

        [[ 2.370e+01],
         [ 3.973e+00],
         [-8.376e+00],
         [-1.091e+01],
         [ 1.045e+00],
         [-1.186e+01],
         [-1.102e+01],
         [-7.271e+00],
         [-6.529e+00],
         [ 2.396e+01]],

        [[ 5.754e+00],
         [ 4.189e+00],
         [-9.979e+00],
         [-6.648e-01],
         [-8.142e+00],
         [-5.629e+00],
         [-8.960e+00],
         [-7.589e+00],
         [-5.953e+00],
         [ 9.121e+01]],

        [[-1.199e+01],
         [-8.034e+00],
         [-1.093e+01],
         [-2.785e+00],
         [-9.111e+00],
         [-1.013e+01],
         [-1.030e-01],
         [-7.744e+00],
         [ 3.809e+00],
         [ 1.526e+01]],

        [[ 2.926e+01],
         [-8.735e+00],
         [-6.957e+00],
         [-6.212e+00],
         [-5.593e+00],
         [-1.004e+01],
         [ 2.050e+01],
         [-9.526e+00],
         [ 2.512e+01],
         [ 2.988e+00]],

        [[-5.183e+00],
         [-5.268e+00],
         [ 4.437e-01],
         [-2.367e+00],
         [-2.835e+00],
         [-7.354e-02],
         [-3.725e+00],
         [ 1.635e+01],
         [-9.992e+00],
         [ 1.431e+01]],

        [[-5.553e+00],
         [-2.642e+00],
         [-7.138e+00],
         [-1.017e+01],
         [-6.938e+00],
         [ 3.993e+00],
         [ 1.511e+01],
         [-5.777e+00],
         [-1.489e+00],
         [-6.560e+00]],

        [[-2.042e+00],
         [-8.684e+00],
         [ 7.545e+00],
         [ 2.157e+00],
         [ 1.351e+00],
         [-1.242e+01],
         [-6.669e+00],
         [ 2.856e+00],
         [-1.068e+01],
         [ 2.449e+01]],

        [[-8.921e+00],
         [ 1.506e+01],
         [-5.293e+00],
         [-9.514e+00],
         [ 4.449e-01],
         [-8.735e+00],
         [-5.594e+00],
         [-5.436e+00],
         [ 3.214e+01],
         [-3.185e+00]],

        [[-6.988e+00],
         [-7.092e+00],
         [-6.047e+00],
         [-7.097e+00],
         [-1.170e+01],
         [-8.918e+00],
         [ 4.609e+00],
         [-1.105e+01],
         [ 1.591e+01],
         [ 4.352e+01]],

        [[-8.030e+00],
         [-2.749e+00],
         [ 7.456e+00],
         [-2.420e+00],
         [-6.157e+00],
         [-1.213e+01],
         [-1.180e+01],
         [-6.740e+00],
         [ 1.095e+01],
         [ 9.292e+00]],

        [[-5.829e+00],
         [-6.297e+00],
         [-8.961e+00],
         [ 4.951e+00],
         [ 1.545e-01],
         [ 4.427e+00],
         [-6.591e+00],
         [ 3.330e-01],
         [-9.464e+00],
         [-9.058e+00]],

        [[-7.090e+00],
         [ 8.768e+00],
         [-8.000e+00],
         [-1.325e+01],
         [-4.263e+00],
         [-5.572e+00],
         [-5.251e+00],
         [-3.816e+00],
         [-6.420e+00],
         [-3.346e+00]],

        [[ 4.662e+00],
         [-6.068e+00],
         [ 8.019e+00],
         [ 2.881e+01],
         [ 3.365e+00],
         [-1.031e+01],
         [ 2.926e+01],
         [-7.167e+00],
         [-2.978e+00],
         [ 1.563e+01]],

        [[-6.574e+00],
         [ 1.979e+01],
         [-1.121e+01],
         [-9.333e+00],
         [-1.023e+01],
         [ 4.277e+00],
         [-7.254e-01],
         [-2.354e+00],
         [ 2.529e+01],
         [-9.266e+00]],

        [[ 3.740e+00],
         [-3.457e+00],
         [-8.303e+00],
         [-4.407e+00],
         [-7.258e+00],
         [-9.270e+00],
         [-1.010e+01],
         [-4.360e+00],
         [ 8.449e+00],
         [ 1.111e+00]],

        [[-7.509e+00],
         [-2.168e+00],
         [-6.660e+00],
         [ 1.970e+01],
         [ 1.878e+01],
         [-8.666e+00],
         [-5.298e+00],
         [-9.980e+00],
         [-4.716e+00],
         [ 7.102e+00]],

        [[-5.291e+00],
         [-1.183e+01],
         [-3.928e+00],
         [ 2.819e+01],
         [ 7.730e+00],
         [-4.407e+00],
         [-1.154e+01],
         [-8.039e+00],
         [ 9.170e+00],
         [-2.160e+00]],

        [[-9.233e+00],
         [-9.178e+00],
         [ 3.257e-02],
         [-6.035e-02],
         [-6.375e+00],
         [-8.943e+00],
         [-5.535e+00],
         [ 7.750e+01],
         [-3.679e+00],
         [ 1.971e+01]],

        [[-9.147e+00],
         [-7.666e+00],
         [ 1.098e+01],
         [-6.582e-01],
         [-1.019e+01],
         [-6.005e+00],
         [-8.497e+00],
         [-1.713e+00],
         [-1.355e+01],
         [ 2.834e-01]],

        [[ 2.582e+00],
         [-4.475e+00],
         [-5.339e+00],
         [-4.725e+00],
         [ 2.952e+01],
         [ 3.808e+01],
         [-2.720e+00],
         [ 4.132e-01],
         [-1.581e+00],
         [-2.970e+00]],

        [[-1.097e+01],
         [-5.972e+00],
         [ 1.013e+01],
         [ 4.142e+00],
         [ 5.041e+01],
         [-1.239e+01],
         [ 1.600e+01],
         [ 8.967e+00],
         [-8.498e+00],
         [-2.726e+00]],

        [[ 3.877e+01],
         [ 2.224e+01],
         [-5.836e+00],
         [-8.214e+00],
         [-2.388e+00],
         [ 1.297e+00],
         [ 3.303e+01],
         [-6.486e+00],
         [-7.355e+00],
         [-5.293e+00]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.307e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [8.469e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[2.667e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [2.988e-01],
         [1.000e-12],
         [1.000e+01]],

        [[7.345e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.872e+00],
         [1.000e-12],
         [1.000e+01],
         [6.398e+00],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [7.307e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.501e-01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.311e-01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [8.572e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.590e+00]],

        [[1.000e+01],
         [3.973e+00],
         [1.000e-12],
         [1.000e-12],
         [1.045e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[5.754e+00],
         [4.189e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.809e+00],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [2.988e+00]],

        [[1.000e-12],
         [1.000e-12],
         [4.437e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.993e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [7.545e+00],
         [2.157e+00],
         [1.351e+00],
         [1.000e-12],
         [1.000e-12],
         [2.856e+00],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [4.449e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.609e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [7.456e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [9.292e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.951e+00],
         [1.545e-01],
         [4.427e+00],
         [1.000e-12],
         [3.330e-01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [8.768e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[4.662e+00],
         [1.000e-12],
         [8.019e+00],
         [1.000e+01],
         [3.365e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.277e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[3.740e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [8.449e+00],
         [1.111e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.102e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [7.730e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [9.170e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [3.257e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.834e-01]],

        [[2.582e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [4.132e-01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [4.142e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [8.967e+00],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.297e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[  0.912],
        [  7.925],
        [ -5.781],
        [  5.421],
        [ 93.403],
        [ -8.941],
        [ -8.047],
        [ -8.697],
        [ -9.707],
        [  7.810],
        [ -2.246],
        [  4.435],
        [-10.146],
        [ -7.911],
        [ -9.675],
        [ -5.397],
        [ -8.136],
        [ -3.999],
        [ -8.750],
        [ -2.467],
        [ -7.077],
        [ -6.686],
        [ -9.677],
        [ -9.811],
        [ -3.176],
        [ -6.503],
        [ -8.899],
        [ -2.022],
        [ -3.818],
        [ -8.064]], device='cuda:0')
v tensor([[9.122e-01],
        [7.925e+00],
        [1.000e-12],
        [5.421e+00],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [7.810e+00],
        [1.000e-12],
        [4.435e+00],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-0.003, -0.013,  0.000,  ..., -0.046,  0.015, -0.022],
        [ 0.000,  0.039,  0.030,  ..., -0.034,  0.001,  0.018],
        [-0.007, -0.043,  0.024,  ..., -0.046, -0.003,  0.019],
        ...,
        [ 0.018,  0.004, -0.015,  ...,  0.084, -0.001, -0.000],
        [-0.006,  0.008,  0.010,  ...,  0.024, -0.006, -0.003],
        [-0.003,  0.015,  0.003,  ...,  0.072,  0.020, -0.013]],
       device='cuda:0')
s after update for 1 param tensor([[1.571, 0.642, 1.534,  ..., 1.782, 1.039, 1.334],
        [2.333, 1.305, 1.085,  ..., 1.476, 1.893, 0.787],
        [1.288, 1.167, 1.188,  ..., 2.224, 1.629, 1.377],
        ...,
        [1.478, 1.699, 1.590,  ..., 1.841, 1.306, 1.515],
        [1.616, 1.413, 1.611,  ..., 1.533, 1.386, 1.352],
        [1.663, 1.618, 1.747,  ..., 1.710, 1.361, 2.353]], device='cuda:0')
b after update for 1 param tensor([[150.801,  96.356, 149.002,  ..., 160.607, 122.629, 138.917],
        [183.728, 137.436, 125.286,  ..., 146.135, 165.494, 106.732],
        [136.552, 129.980, 131.137,  ..., 179.385, 153.526, 141.173],
        ...,
        [146.265, 156.808, 151.689,  ..., 163.234, 137.476, 148.062],
        [152.914, 143.017, 152.706,  ..., 148.924, 141.627, 139.891],
        [155.112, 153.027, 159.020,  ..., 157.310, 140.365, 184.528]],
       device='cuda:0')
clipping threshold 0.18130786692853607
a after update for 1 param tensor([-0.019,  0.050,  0.007,  0.036, -0.027, -0.004, -0.022,  0.037,  0.017,
        -0.020,  0.009,  0.017, -0.051,  0.065,  0.026,  0.014, -0.008, -0.019,
         0.064, -0.000,  0.017,  0.013,  0.118,  0.064,  0.062, -0.035, -0.047,
        -0.011, -0.017,  0.036, -0.056,  0.047, -0.040,  0.002,  0.044, -0.017,
         0.003, -0.048, -0.037,  0.005, -0.023, -0.062, -0.042, -0.069,  0.003,
         0.030,  0.043, -0.023, -0.038,  0.021, -0.011,  0.093, -0.013, -0.010,
        -0.051,  0.043, -0.071,  0.011,  0.010, -0.012, -0.027,  0.003,  0.037,
        -0.051, -0.105,  0.086,  0.015, -0.010,  0.089, -0.006,  0.007, -0.048,
         0.025,  0.006, -0.005, -0.012,  0.011,  0.018, -0.076, -0.017, -0.016,
         0.015, -0.016,  0.048, -0.041, -0.040,  0.039, -0.004, -0.057, -0.077,
         0.010,  0.041, -0.010, -0.021, -0.012, -0.020,  0.006, -0.024, -0.030,
         0.039,  0.002,  0.126, -0.010, -0.056, -0.001,  0.031, -0.025,  0.022,
         0.005, -0.053,  0.015,  0.026, -0.119, -0.063, -0.036,  0.040,  0.051,
        -0.024,  0.018, -0.056, -0.037, -0.043, -0.019, -0.047,  0.018,  0.069,
        -0.007,  0.039, -0.021, -0.016,  0.016, -0.003, -0.054,  0.039,  0.021,
        -0.034,  0.012,  0.046,  0.009, -0.025, -0.008, -0.007, -0.031,  0.017,
        -0.011, -0.035,  0.007, -0.038, -0.041,  0.023,  0.025, -0.013,  0.043,
        -0.003,  0.014,  0.016,  0.021, -0.015, -0.053, -0.070, -0.001, -0.004,
         0.024,  0.032,  0.007, -0.010, -0.020, -0.009, -0.023,  0.027, -0.004,
        -0.006, -0.002, -0.043, -0.011,  0.032,  0.014,  0.004,  0.021,  0.032,
         0.011, -0.004,  0.011,  0.000, -0.012, -0.018, -0.009,  0.079, -0.035,
         0.036,  0.015,  0.034,  0.030, -0.034, -0.001,  0.061,  0.030,  0.024,
         0.042,  0.014,  0.024, -0.031,  0.049, -0.018,  0.072,  0.073,  0.060,
         0.002, -0.043, -0.007,  0.014,  0.009,  0.045, -0.038,  0.070,  0.004,
        -0.056, -0.027,  0.040, -0.069, -0.046, -0.027,  0.023, -0.014, -0.011,
         0.012,  0.001,  0.014,  0.006,  0.046,  0.003, -0.058, -0.071,  0.022,
        -0.018, -0.058,  0.011, -0.012, -0.002,  0.025,  0.029,  0.006, -0.024,
         0.049, -0.051,  0.016, -0.004,  0.024, -0.075,  0.014, -0.030,  0.010,
         0.092, -0.009, -0.020,  0.015,  0.008,  0.028,  0.055, -0.016,  0.004,
        -0.041,  0.000, -0.015, -0.051, -0.046, -0.039,  0.040, -0.009, -0.028,
         0.019, -0.022, -0.089, -0.012,  0.013, -0.001, -0.002,  0.038, -0.000,
        -0.070,  0.011, -0.014, -0.027, -0.027,  0.032, -0.002,  0.033,  0.063,
         0.005, -0.045,  0.026, -0.060, -0.100,  0.014,  0.018,  0.052, -0.062,
         0.004,  0.077,  0.031], device='cuda:0')
s after update for 1 param tensor([1.171, 1.359, 1.842, 1.802, 1.133, 1.399, 1.825, 1.399, 1.612, 2.044,
        2.157, 1.282, 1.193, 0.811, 1.748, 1.529, 1.177, 1.858, 1.633, 1.645,
        1.828, 1.193, 1.286, 1.453, 1.505, 1.604, 1.969, 1.349, 1.398, 1.592,
        1.306, 0.970, 0.567, 1.222, 1.742, 1.899, 0.847, 1.400, 1.001, 1.917,
        1.581, 1.062, 1.663, 0.870, 2.124, 1.399, 1.609, 1.987, 1.912, 1.364,
        1.801, 1.350, 1.599, 1.958, 1.615, 1.723, 1.658, 1.657, 1.768, 1.368,
        1.326, 1.657, 0.961, 1.484, 1.269, 1.435, 1.472, 0.622, 1.548, 1.508,
        1.530, 1.551, 1.179, 1.669, 1.354, 0.799, 1.821, 1.349, 1.581, 1.840,
        1.272, 1.546, 1.579, 1.916, 1.362, 1.496, 1.517, 1.486, 1.310, 1.215,
        1.554, 1.667, 0.963, 1.032, 1.152, 1.388, 1.192, 1.617, 1.485, 1.267,
        1.517, 1.877, 0.784, 1.152, 0.902, 1.716, 1.848, 1.616, 1.778, 2.074,
        1.660, 1.270, 1.020, 2.132, 1.164, 1.908, 2.052, 1.285, 1.533, 1.466,
        0.772, 1.748, 1.487, 1.586, 1.121, 0.818, 1.371, 1.447, 1.899, 1.144,
        1.555, 2.110, 1.445, 1.469, 1.316, 1.125, 1.551, 0.957, 0.563, 1.270,
        1.976, 1.139, 1.400, 1.448, 1.976, 1.932, 1.087, 1.893, 0.949, 1.505,
        1.801, 0.995, 1.875, 1.491, 1.272, 1.155, 1.789, 1.946, 1.298, 1.267,
        1.152, 1.312, 0.937, 1.080, 0.717, 1.645, 1.350, 1.435, 1.464, 1.122,
        1.815, 1.695, 1.483, 0.977, 0.885, 1.375, 1.112, 1.109, 0.843, 1.320,
        1.319, 1.304, 1.924, 1.222, 1.464, 0.903, 1.170, 1.048, 1.451, 1.565,
        1.570, 1.400, 2.194, 1.769, 1.144, 1.726, 1.416, 1.466, 1.308, 1.511,
        1.644, 1.439, 1.917, 1.235, 1.490, 1.426, 1.550, 1.481, 1.473, 1.297,
        1.288, 1.981, 1.679, 1.556, 0.647, 1.211, 1.587, 0.542, 1.089, 1.776,
        1.993, 1.952, 2.011, 0.944, 1.864, 1.642, 1.273, 1.421, 1.412, 1.285,
        1.511, 1.525, 0.908, 1.343, 1.766, 1.081, 1.727, 1.497, 1.852, 1.901,
        1.813, 1.960, 1.081, 1.576, 1.599, 1.166, 1.962, 1.103, 1.547, 1.576,
        1.345, 1.512, 1.355, 1.342, 1.574, 1.575, 1.456, 1.598, 1.336, 1.110,
        1.056, 0.580, 1.705, 1.524, 1.050, 1.274, 1.304, 0.847, 1.987, 0.983,
        1.178, 1.477, 1.096, 1.580, 1.156, 1.666, 1.477, 1.025, 1.235, 1.696,
        0.863, 0.975, 1.792, 1.325, 2.065, 0.773, 1.161, 1.139, 1.482, 1.712,
        1.486, 1.215, 1.312, 1.878, 1.422, 1.131, 1.599, 1.009, 1.332, 1.197],
       device='cuda:0')
b after update for 1 param tensor([130.190, 140.245, 163.265, 161.501, 128.042, 142.283, 162.508, 142.289,
        152.742, 172.006, 176.680, 136.234, 131.416, 108.335, 159.071, 148.745,
        130.492, 163.989, 153.741, 154.306, 162.632, 131.382, 136.441, 145.025,
        147.586, 152.363, 168.807, 139.732, 142.221, 151.800, 137.464, 118.484,
         90.610, 132.960, 158.767, 165.795, 110.731, 142.325, 120.342, 166.554,
        151.253, 123.979, 155.121, 112.177, 175.304, 142.268, 152.590, 169.584,
        166.350, 140.471, 161.443, 139.762, 152.112, 168.325, 152.858, 157.908,
        154.882, 154.849, 159.971, 140.726, 138.530, 154.843, 117.911, 146.556,
        135.491, 144.091, 145.973,  94.902, 149.663, 147.734, 148.785, 149.806,
        130.618, 155.408, 139.988, 107.538, 162.352, 139.718, 151.266, 163.172,
        135.701, 149.557, 151.168, 166.533, 140.401, 147.147, 148.187, 146.653,
        137.664, 132.624, 149.965, 155.342, 118.060, 122.199, 129.124, 141.738,
        131.315, 152.959, 146.610, 135.425, 148.156, 164.806, 106.510, 129.124,
        114.242, 157.604, 163.538, 152.946, 160.419, 173.252, 155.014, 135.551,
        121.495, 175.659, 129.766, 166.188, 172.310, 136.346, 148.969, 145.667,
        105.699, 159.055, 146.690, 151.496, 127.362, 108.795, 140.842, 144.732,
        165.765, 128.689, 150.011, 174.743, 144.605, 145.812, 137.986, 127.621,
        149.811, 117.666,  90.244, 135.590, 169.113, 128.389, 142.316, 144.758,
        169.084, 167.217, 125.411, 165.516, 117.179, 147.586, 161.440, 120.005,
        164.731, 146.869, 135.653, 129.289, 160.895, 167.802, 137.051, 135.383,
        129.097, 137.790, 116.466, 125.029, 101.879, 154.302, 139.795, 144.108,
        145.566, 127.423, 162.084, 156.596, 146.474, 118.907, 113.196, 141.077,
        126.830, 126.712, 110.443, 138.190, 138.185, 137.396, 166.860, 132.992,
        145.564, 114.326, 130.097, 123.150, 144.897, 150.502, 150.741, 142.340,
        178.171, 160.003, 128.645, 158.040, 143.151, 145.675, 137.606, 147.881,
        154.244, 144.287, 166.556, 133.668, 146.867, 143.650, 149.784, 146.408,
        145.982, 136.979, 136.521, 169.328, 155.871, 150.053,  96.748, 132.368,
        151.527,  88.527, 125.519, 160.306, 169.830, 168.079, 170.593, 116.898,
        164.235, 154.170, 135.727, 143.395, 142.953, 136.378, 147.892, 148.548,
        114.623, 139.387, 159.880, 125.063, 158.109, 147.185, 163.731, 165.866,
        161.978, 168.422, 125.084, 151.003, 152.104, 129.924, 168.500, 126.363,
        149.615, 151.019, 139.512, 147.914, 140.056, 139.363, 150.943, 150.959,
        145.181, 152.091, 139.033, 126.765, 123.625,  91.614, 157.068, 148.504,
        123.260, 135.761, 137.363, 110.688, 169.565, 119.243, 130.564, 146.200,
        125.963, 151.221, 129.356, 155.281, 146.194, 121.800, 133.692, 156.643,
        111.727, 118.785, 161.024, 138.499, 172.849, 105.735, 129.647, 128.372,
        146.464, 157.414, 146.633, 132.615, 137.779, 164.856, 143.439, 127.944,
        152.099, 120.819, 138.827, 131.592], device='cuda:0')
clipping threshold 0.18130786692853607
a after update for 1 param tensor([[[-9.968e-03],
         [ 4.542e-02],
         [ 1.350e-02],
         [-4.286e-02],
         [ 7.455e-03],
         [ 5.933e-03],
         [-6.470e-02],
         [ 4.746e-03],
         [ 9.798e-03],
         [ 4.170e-02]],

        [[-4.100e-02],
         [-6.472e-02],
         [ 8.776e-02],
         [-4.773e-02],
         [ 2.377e-02],
         [-1.715e-02],
         [ 2.057e-02],
         [-5.285e-02],
         [-4.485e-02],
         [ 5.626e-02]],

        [[-2.762e-02],
         [ 2.753e-03],
         [ 5.217e-02],
         [ 4.039e-02],
         [ 1.738e-02],
         [ 2.354e-02],
         [-3.504e-03],
         [-2.306e-03],
         [-1.815e-02],
         [ 1.793e-02]],

        [[-1.063e-02],
         [-3.271e-02],
         [-8.551e-02],
         [ 5.212e-02],
         [-3.707e-03],
         [ 7.177e-02],
         [-2.141e-02],
         [ 1.959e-02],
         [ 2.402e-02],
         [-3.116e-04]],

        [[-2.679e-02],
         [-7.644e-02],
         [ 1.039e-02],
         [ 1.425e-02],
         [ 2.324e-02],
         [ 5.952e-02],
         [-4.163e-02],
         [ 1.419e-02],
         [ 5.803e-02],
         [ 1.481e-02]],

        [[-2.013e-02],
         [-2.515e-02],
         [-5.088e-03],
         [-1.878e-02],
         [-1.556e-02],
         [-5.675e-02],
         [ 1.798e-02],
         [ 3.923e-03],
         [ 1.026e-03],
         [ 2.267e-02]],

        [[-1.238e-02],
         [-8.322e-04],
         [-5.212e-02],
         [-4.039e-02],
         [ 4.835e-02],
         [ 1.909e-02],
         [ 2.558e-02],
         [-2.375e-02],
         [-5.265e-02],
         [ 1.107e-02]],

        [[-1.929e-02],
         [ 1.992e-02],
         [-8.636e-03],
         [-1.044e-02],
         [ 1.238e-02],
         [-3.154e-02],
         [-4.344e-02],
         [ 2.985e-03],
         [-3.942e-02],
         [ 2.413e-02]],

        [[-4.349e-02],
         [ 7.232e-02],
         [-5.776e-02],
         [ 1.340e-03],
         [ 2.592e-02],
         [ 1.357e-01],
         [-7.367e-03],
         [ 1.211e-02],
         [-4.968e-02],
         [-7.054e-02]],

        [[-5.506e-03],
         [-1.156e-02],
         [-5.727e-03],
         [-9.914e-03],
         [-6.653e-03],
         [-3.909e-02],
         [-3.418e-02],
         [ 1.372e-02],
         [ 1.378e-02],
         [ 7.559e-02]],

        [[ 1.232e-02],
         [-6.545e-02],
         [ 8.073e-02],
         [-3.227e-02],
         [-5.115e-03],
         [ 1.948e-02],
         [ 7.241e-02],
         [ 1.378e-02],
         [ 3.922e-03],
         [ 4.670e-02]],

        [[-3.262e-02],
         [-1.500e-02],
         [ 1.043e-02],
         [-3.231e-03],
         [-1.914e-02],
         [-4.586e-02],
         [-1.403e-03],
         [ 5.041e-02],
         [ 8.249e-02],
         [-4.983e-02]],

        [[-8.889e-03],
         [ 3.584e-02],
         [ 1.039e-03],
         [ 4.784e-02],
         [ 3.340e-02],
         [-3.669e-02],
         [-3.395e-02],
         [ 2.319e-02],
         [ 6.349e-02],
         [ 9.242e-03]],

        [[ 4.041e-02],
         [ 6.506e-02],
         [-2.994e-02],
         [ 4.505e-03],
         [ 1.966e-02],
         [ 1.256e-02],
         [ 2.730e-02],
         [ 3.589e-02],
         [-5.029e-03],
         [-5.182e-02]],

        [[-1.145e-02],
         [ 7.937e-03],
         [-5.325e-02],
         [-2.338e-02],
         [-1.920e-02],
         [ 1.686e-02],
         [ 3.189e-02],
         [ 8.055e-02],
         [-7.644e-03],
         [-4.038e-02]],

        [[ 4.901e-02],
         [-1.393e-02],
         [ 2.960e-03],
         [ 3.682e-02],
         [-5.323e-02],
         [ 5.432e-02],
         [-3.490e-02],
         [ 4.052e-02],
         [ 3.179e-03],
         [ 8.824e-03]],

        [[ 1.180e-01],
         [-3.268e-02],
         [-1.564e-03],
         [-3.954e-03],
         [ 4.866e-02],
         [ 4.970e-02],
         [-1.342e-02],
         [-2.190e-02],
         [-3.734e-02],
         [-1.132e-02]],

        [[-1.535e-02],
         [-1.114e-02],
         [-2.256e-02],
         [-6.806e-02],
         [-1.569e-02],
         [ 6.651e-02],
         [ 4.956e-02],
         [-1.684e-02],
         [ 5.092e-02],
         [-4.825e-02]],

        [[-2.671e-03],
         [-9.942e-03],
         [-3.252e-02],
         [-1.450e-02],
         [-9.516e-03],
         [ 3.463e-02],
         [ 6.947e-02],
         [ 2.954e-04],
         [-3.542e-03],
         [ 5.118e-02]],

        [[ 2.565e-02],
         [ 3.559e-02],
         [-5.897e-03],
         [ 5.294e-02],
         [-1.200e-02],
         [ 2.317e-02],
         [-1.584e-03],
         [-1.378e-02],
         [-5.393e-02],
         [ 2.783e-02]],

        [[-2.739e-02],
         [ 3.139e-02],
         [ 3.885e-02],
         [-2.270e-02],
         [ 9.085e-03],
         [ 1.910e-02],
         [-3.644e-02],
         [-2.633e-02],
         [ 1.524e-02],
         [ 2.360e-02]],

        [[-7.437e-02],
         [ 2.413e-03],
         [ 6.530e-02],
         [-5.471e-02],
         [ 2.020e-02],
         [-1.721e-02],
         [ 8.986e-05],
         [-1.506e-02],
         [ 6.374e-03],
         [-8.142e-02]],

        [[-3.112e-02],
         [ 1.001e-01],
         [ 4.059e-02],
         [-7.695e-04],
         [ 6.385e-04],
         [-5.085e-02],
         [-1.635e-02],
         [-7.443e-02],
         [ 6.736e-02],
         [-6.505e-04]],

        [[ 4.543e-02],
         [ 6.000e-02],
         [ 9.283e-03],
         [ 6.885e-02],
         [-3.450e-02],
         [-6.443e-02],
         [-2.346e-02],
         [-6.314e-02],
         [-6.514e-02],
         [ 7.088e-02]],

        [[-9.875e-03],
         [-1.468e-02],
         [ 3.566e-02],
         [ 3.455e-02],
         [ 4.375e-02],
         [-4.187e-04],
         [-5.048e-02],
         [-3.617e-02],
         [-1.279e-02],
         [ 1.320e-02]],

        [[-1.131e-02],
         [ 2.717e-02],
         [-7.549e-02],
         [ 1.494e-02],
         [ 3.960e-02],
         [-4.421e-02],
         [ 2.386e-02],
         [-1.846e-02],
         [ 1.665e-02],
         [ 2.265e-02]],

        [[ 1.172e-03],
         [ 1.854e-02],
         [-2.627e-02],
         [-1.309e-01],
         [-4.350e-02],
         [ 4.815e-03],
         [ 9.548e-03],
         [-5.735e-02],
         [-4.622e-02],
         [ 4.654e-02]],

        [[ 1.675e-02],
         [-3.880e-03],
         [-7.517e-02],
         [ 6.870e-02],
         [-7.428e-03],
         [-3.377e-02],
         [-4.525e-02],
         [ 1.177e-01],
         [-1.995e-02],
         [ 1.250e-01]],

        [[-4.727e-02],
         [-4.881e-04],
         [-5.259e-02],
         [-2.984e-02],
         [-9.345e-03],
         [-2.165e-02],
         [-2.098e-02],
         [ 2.768e-02],
         [ 2.636e-02],
         [ 5.071e-03]],

        [[ 6.474e-03],
         [-5.482e-02],
         [ 2.307e-02],
         [ 4.941e-02],
         [ 3.578e-02],
         [-9.966e-02],
         [ 8.363e-02],
         [-4.645e-03],
         [ 1.624e-02],
         [ 3.516e-03]]], device='cuda:0')
s after update for 1 param tensor([[[1.394],
         [0.946],
         [1.180],
         [1.698],
         [1.182],
         [2.015],
         [1.369],
         [1.325],
         [1.519],
         [1.791]],

        [[1.417],
         [1.756],
         [1.781],
         [1.235],
         [1.164],
         [1.610],
         [1.883],
         [1.598],
         [1.931],
         [1.510]],

        [[1.355],
         [0.694],
         [1.794],
         [1.670],
         [1.541],
         [1.617],
         [1.153],
         [1.762],
         [0.904],
         [1.607]],

        [[1.705],
         [1.399],
         [1.188],
         [1.053],
         [1.781],
         [0.966],
         [1.326],
         [1.598],
         [1.414],
         [1.088]],

        [[1.422],
         [1.088],
         [1.474],
         [1.451],
         [1.133],
         [1.326],
         [1.631],
         [0.990],
         [1.599],
         [1.220]],

        [[1.916],
         [0.737],
         [1.877],
         [1.399],
         [1.788],
         [2.032],
         [1.808],
         [1.381],
         [1.819],
         [1.892]],

        [[1.770],
         [1.555],
         [1.569],
         [2.125],
         [1.771],
         [1.155],
         [1.750],
         [1.096],
         [1.176],
         [1.046]],

        [[0.771],
         [1.096],
         [1.354],
         [1.366],
         [1.336],
         [1.296],
         [1.350],
         [1.538],
         [1.411],
         [1.437]],

        [[1.891],
         [1.431],
         [1.379],
         [1.755],
         [1.679],
         [1.795],
         [1.697],
         [1.545],
         [1.270],
         [1.745]],

        [[1.271],
         [1.653],
         [1.574],
         [0.651],
         [1.595],
         [1.236],
         [1.444],
         [1.467],
         [1.686],
         [2.000]],

        [[2.068],
         [1.294],
         [1.769],
         [0.837],
         [1.439],
         [1.554],
         [1.517],
         [1.761],
         [2.096],
         [1.616]],

        [[1.828],
         [1.329],
         [1.476],
         [1.040],
         [1.336],
         [1.596],
         [1.258],
         [1.512],
         [1.763],
         [1.249]],

        [[0.786],
         [1.234],
         [1.651],
         [1.190],
         [1.528],
         [0.621],
         [0.992],
         [1.774],
         [1.956],
         [1.771]],

        [[0.840],
         [1.150],
         [1.130],
         [1.612],
         [1.517],
         [1.949],
         [1.765],
         [0.916],
         [1.884],
         [1.410]],

        [[1.527],
         [1.387],
         [2.126],
         [1.574],
         [0.815],
         [2.005],
         [1.160],
         [1.013],
         [1.910],
         [1.546]],

        [[1.656],
         [1.843],
         [1.152],
         [1.621],
         [1.022],
         [1.403],
         [1.241],
         [0.823],
         [1.680],
         [1.002]],

        [[1.063],
         [1.707],
         [1.383],
         [1.143],
         [1.934],
         [1.652],
         [1.230],
         [1.760],
         [2.324],
         [1.878]],

        [[1.475],
         [1.538],
         [1.176],
         [1.732],
         [1.288],
         [1.861],
         [1.799],
         [1.511],
         [1.432],
         [1.940]],

        [[1.040],
         [1.630],
         [1.584],
         [1.956],
         [1.469],
         [1.435],
         [1.028],
         [0.939],
         [1.445],
         [1.421]],

        [[1.278],
         [1.478],
         [1.456],
         [2.010],
         [1.690],
         [1.202],
         [1.837],
         [0.951],
         [1.022],
         [1.061]],

        [[1.532],
         [1.229],
         [1.706],
         [1.458],
         [1.920],
         [1.578],
         [1.590],
         [1.127],
         [1.293],
         [2.025]],

        [[1.295],
         [1.739],
         [1.895],
         [1.496],
         [1.563],
         [1.408],
         [1.274],
         [1.022],
         [1.318],
         [1.691]],

        [[1.164],
         [1.612],
         [1.278],
         [1.342],
         [1.162],
         [1.637],
         [1.550],
         [0.717],
         [1.652],
         [1.801]],

        [[1.209],
         [1.562],
         [1.012],
         [1.775],
         [2.015],
         [1.864],
         [0.843],
         [1.871],
         [1.014],
         [1.353]],

        [[1.731],
         [1.791],
         [0.854],
         [1.481],
         [1.954],
         [0.736],
         [1.916],
         [1.372],
         [1.281],
         [1.191]],

        [[1.402],
         [1.849],
         [0.887],
         [1.057],
         [1.142],
         [1.435],
         [0.901],
         [1.737],
         [1.082],
         [1.972]],

        [[1.775],
         [1.318],
         [1.470],
         [2.059],
         [1.679],
         [1.323],
         [1.369],
         [1.160],
         [2.080],
         [1.505]],

        [[1.156],
         [1.564],
         [1.771],
         [1.692],
         [1.622],
         [2.212],
         [1.454],
         [1.736],
         [1.175],
         [1.793]],

        [[1.708],
         [1.220],
         [1.817],
         [1.561],
         [2.180],
         [1.886],
         [1.622],
         [1.311],
         [1.637],
         [1.157]],

        [[1.855],
         [2.145],
         [1.640],
         [1.257],
         [1.359],
         [1.223],
         [1.296],
         [1.891],
         [1.535],
         [1.136]]], device='cuda:0')
b after update for 1 param tensor([[[142.028],
         [116.982],
         [130.673],
         [156.758],
         [130.798],
         [170.766],
         [140.741],
         [138.492],
         [148.287],
         [160.993]],

        [[143.221],
         [159.433],
         [160.538],
         [133.708],
         [129.816],
         [152.630],
         [165.062],
         [152.077],
         [167.160],
         [147.846]],

        [[140.011],
         [100.204],
         [161.123],
         [155.466],
         [149.336],
         [152.955],
         [129.164],
         [159.699],
         [114.404],
         [152.478]],

        [[157.096],
         [142.296],
         [131.107],
         [123.441],
         [160.543],
         [118.261],
         [138.535],
         [152.050],
         [143.040],
         [125.465]],

        [[143.467],
         [125.471],
         [146.048],
         [144.918],
         [128.036],
         [138.516],
         [153.614],
         [119.694],
         [152.120],
         [132.895]],

        [[166.520],
         [103.302],
         [164.824],
         [142.286],
         [160.874],
         [171.482],
         [161.774],
         [141.387],
         [162.226],
         [165.451]],

        [[160.060],
         [150.008],
         [150.686],
         [175.373],
         [160.093],
         [129.297],
         [159.117],
         [125.925],
         [130.451],
         [123.017]],

        [[105.641],
         [125.927],
         [139.994],
         [140.590],
         [139.023],
         [136.955],
         [139.770],
         [149.201],
         [142.896],
         [144.205]],

        [[165.441],
         [143.920],
         [141.263],
         [159.351],
         [155.892],
         [161.195],
         [156.721],
         [149.544],
         [135.545],
         [158.891]],

        [[135.597],
         [154.646],
         [150.917],
         [ 97.090],
         [151.943],
         [133.761],
         [144.576],
         [145.698],
         [156.216],
         [170.119]],

        [[172.983],
         [136.828],
         [159.992],
         [110.044],
         [144.298],
         [149.971],
         [148.172],
         [159.653],
         [174.166],
         [152.925]],

        [[162.637],
         [138.660],
         [146.145],
         [122.704],
         [139.066],
         [151.996],
         [134.919],
         [147.929],
         [159.708],
         [134.448]],

        [[106.628],
         [133.622],
         [154.578],
         [131.231],
         [148.694],
         [ 94.825],
         [119.821],
         [160.226],
         [168.247],
         [160.073]],

        [[110.278],
         [129.001],
         [127.875],
         [152.714],
         [148.162],
         [167.944],
         [159.821],
         [115.158],
         [165.105],
         [142.870]],

        [[148.657],
         [141.685],
         [175.398],
         [150.944],
         [108.599],
         [170.351],
         [129.557],
         [121.053],
         [166.274],
         [149.559]],

        [[154.814],
         [163.293],
         [129.130],
         [153.165],
         [121.593],
         [142.492],
         [134.009],
         [109.131],
         [155.909],
         [120.438]],

        [[124.030],
         [157.166],
         [141.496],
         [128.638],
         [167.280],
         [154.627],
         [133.439],
         [159.599],
         [183.401],
         [164.840]],

        [[146.115],
         [149.183],
         [130.446],
         [158.326],
         [136.511],
         [164.126],
         [161.359],
         [147.884],
         [143.943],
         [167.563]],

        [[122.694],
         [153.596],
         [151.407],
         [168.240],
         [145.814],
         [144.129],
         [121.942],
         [116.554],
         [144.585],
         [143.384]],

        [[135.993],
         [146.232],
         [145.172],
         [170.555],
         [156.394],
         [131.910],
         [163.037],
         [117.296],
         [121.630],
         [123.920]],

        [[148.877],
         [133.354],
         [157.130],
         [145.245],
         [166.701],
         [151.111],
         [151.704],
         [127.717],
         [136.774],
         [171.184]],

        [[136.919],
         [158.660],
         [165.600],
         [147.123],
         [150.408],
         [142.732],
         [135.781],
         [121.614],
         [138.108],
         [156.438]],

        [[129.799],
         [152.735],
         [135.996],
         [139.347],
         [129.663],
         [153.928],
         [149.791],
         [101.849],
         [154.632],
         [161.445]],

        [[132.294],
         [150.343],
         [121.007],
         [160.287],
         [170.748],
         [164.257],
         [110.453],
         [164.564],
         [121.132],
         [139.925]],

        [[158.280],
         [161.014],
         [111.164],
         [146.393],
         [168.169],
         [103.212],
         [166.495],
         [140.905],
         [136.135],
         [131.276]],

        [[142.445],
         [163.580],
         [113.307],
         [123.692],
         [128.533],
         [144.095],
         [114.211],
         [158.527],
         [125.128],
         [168.920]],

        [[160.257],
         [138.110],
         [145.851],
         [172.621],
         [155.859],
         [138.356],
         [140.761],
         [129.548],
         [173.486],
         [147.557]],

        [[129.362],
         [150.454],
         [160.071],
         [156.484],
         [153.216],
         [178.915],
         [145.070],
         [158.504],
         [130.379],
         [161.071]],

        [[157.220],
         [132.859],
         [162.158],
         [150.298],
         [177.621],
         [165.213],
         [153.227],
         [137.761],
         [153.895],
         [129.416]],

        [[163.857],
         [176.166],
         [154.044],
         [134.884],
         [140.223],
         [133.057],
         [136.942],
         [165.444],
         [149.052],
         [128.239]]], device='cuda:0')
clipping threshold 0.18130786692853607
a after update for 1 param tensor([[-0.040],
        [-0.033],
        [-0.036],
        [-0.021],
        [ 0.010],
        [ 0.029],
        [ 0.028],
        [-0.039],
        [-0.051],
        [-0.008],
        [-0.071],
        [ 0.012],
        [-0.008],
        [-0.007],
        [-0.035],
        [-0.028],
        [-0.112],
        [-0.021],
        [ 0.007],
        [ 0.010],
        [ 0.006],
        [ 0.083],
        [ 0.006],
        [-0.021],
        [-0.021],
        [ 0.027],
        [-0.018],
        [-0.002],
        [ 0.048],
        [-0.042]], device='cuda:0')
s after update for 1 param tensor([[1.628],
        [1.772],
        [1.454],
        [1.855],
        [2.227],
        [1.760],
        [1.784],
        [1.499],
        [1.582],
        [1.503],
        [0.875],
        [1.478],
        [1.731],
        [1.489],
        [1.502],
        [1.593],
        [1.232],
        [1.517],
        [1.594],
        [1.515],
        [1.818],
        [1.047],
        [1.575],
        [1.497],
        [1.787],
        [1.014],
        [1.589],
        [1.328],
        [1.456],
        [1.819]], device='cuda:0')
b after update for 1 param tensor([[153.513],
        [160.128],
        [145.046],
        [163.845],
        [179.524],
        [159.580],
        [160.675],
        [147.275],
        [151.319],
        [147.475],
        [112.556],
        [146.259],
        [158.252],
        [146.811],
        [147.412],
        [151.854],
        [133.528],
        [148.173],
        [151.858],
        [148.080],
        [162.217],
        [123.108],
        [150.990],
        [147.211],
        [160.826],
        [121.113],
        [151.626],
        [138.608],
        [145.143],
        [162.242]], device='cuda:0')
clipping threshold 0.18130786692853607
cuda
Objective function 29.79 = squared loss an data 27.58 + 0.5*rho*h**2 1.149713 + alpha*h 0.253502 + L2reg 0.55 + L1reg 0.26 ; SHD = 63 ; DAG True
Proportion of microbatches that were clipped  0.7594290726417351
iteration 3 in inner loop, alpha 16.717537223913318 rho 10000.0 h 0.015163860982404742
iteration 3 in outer loop, alpha = 168.35614704796075, rho = 10000.0, h = 0.015163860982404742
cuda
9630
cuda
Objective function 32.09 = squared loss an data 27.58 + 0.5*rho*h**2 1.149713 + alpha*h 2.552929 + L2reg 0.55 + L1reg 0.26 ; SHD = 63 ; DAG True
||w||^2 14093487904.161282
exp ma of ||w||^2 3499625036.071924
||w|| 118715.99683345662
exp ma of ||w|| 28669.753934650354
||w||^2 0.10252048899763751
exp ma of ||w||^2 25.752884907462967
||w|| 0.32018820871112275
exp ma of ||w|| 0.3872207546421758
||w||^2 0.043354788383810544
exp ma of ||w||^2 0.04562423701755144
||w|| 0.20821812693377717
exp ma of ||w|| 0.21035785423292674
||w||^2 0.029705945029814808
exp ma of ||w||^2 0.04726643964987984
||w|| 0.1723541268139954
exp ma of ||w|| 0.2142523280654089
||w||^2 0.03946983924460524
exp ma of ||w||^2 0.04932428190331016
||w|| 0.19867017703874237
exp ma of ||w|| 0.21809247471841708
||w||^2 0.04568476776749915
exp ma of ||w||^2 0.04998245149192219
||w|| 0.21373995360600964
exp ma of ||w|| 0.21911770764597024
||w||^2 0.040975837757845815
exp ma of ||w||^2 0.04902708695932164
||w|| 0.20242489411593084
exp ma of ||w|| 0.2176847984117392
||w||^2 0.06305743297469167
exp ma of ||w||^2 0.05166591634472816
||w|| 0.2511123911213695
exp ma of ||w|| 0.2234887409185356
||w||^2 0.034344107608001065
exp ma of ||w||^2 0.052488536313468385
||w|| 0.1853216328656778
exp ma of ||w|| 0.22514437303893634
||w||^2 0.03814916728552449
exp ma of ||w||^2 0.04954844001128242
||w|| 0.19531811817013928
exp ma of ||w|| 0.21870280157467747
||w||^2 0.055694284398665576
exp ma of ||w||^2 0.054523953197966296
||w|| 0.23599636522341944
exp ma of ||w|| 0.22995991776507982
cuda
Objective function 30.38 = squared loss an data 27.52 + 0.5*rho*h**2 0.446219 + alpha*h 1.590443 + L2reg 0.58 + L1reg 0.25 ; SHD = 64 ; DAG True
Proportion of microbatches that were clipped  0.7614205132279336
iteration 1 in inner loop, alpha 168.35614704796075 rho 10000.0 h 0.009446895308155234
9630
cuda
Objective function 34.39 = squared loss an data 27.52 + 0.5*rho*h**2 4.462192 + alpha*h 1.590443 + L2reg 0.58 + L1reg 0.25 ; SHD = 64 ; DAG True
||w||^2 2.445422633017196
exp ma of ||w||^2 11515.087861209417
||w|| 1.5637847144083472
exp ma of ||w|| 1.7173622356116254
||w||^2 0.4147992516883087
exp ma of ||w||^2 11.100387373062304
||w|| 0.6440491065814071
exp ma of ||w|| 0.7343144067380614
||w||^2 0.0524750588228175
exp ma of ||w||^2 0.07028336868336739
||w|| 0.22907435217155478
exp ma of ||w|| 0.2631401987830669
||w||^2 0.0442138457978911
exp ma of ||w||^2 0.06809427088833517
||w|| 0.21027088671019367
exp ma of ||w|| 0.25900278894301487
||w||^2 0.0661743097075218
exp ma of ||w||^2 0.06751886488191637
||w|| 0.25724367768231315
exp ma of ||w|| 0.2579426796508266
v before min max tensor([[ 20.303, 102.286, -16.474,  ..., -13.195,   4.551,  -6.261],
        [ -1.853, -14.354,  76.431,  ...,  -6.719,  -7.051,  15.747],
        [  6.930,   2.408,  -8.431,  ...,  -2.556,  16.030,   2.866],
        ...,
        [ -2.723,  72.867,   1.809,  ...,  -7.691,  -6.371, -13.028],
        [-12.024,  -9.726, -11.435,  ...,   3.017,  64.965, 119.391],
        [ 47.452, -14.211,  67.732,  ...,  43.445, -10.622,  97.025]],
       device='cuda:0')
v tensor([[1.000e+01, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 4.551e+00,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e+01],
        [6.930e+00, 2.408e+00, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         2.866e+00],
        ...,
        [1.000e-12, 1.000e+01, 1.809e+00,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 3.017e+00, 1.000e+01,
         1.000e+01],
        [1.000e+01, 1.000e-12, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.000e+01]], device='cuda:0')
v before min max tensor([ 5.978e+00, -6.052e+00,  6.085e+00, -5.008e-01,  2.194e+01, -1.237e+01,
        -1.002e+01, -1.503e+01, -9.693e+00,  3.202e+01, -3.640e+00, -9.666e+00,
         3.807e+01, -1.312e+01,  3.031e+01,  8.878e+00, -1.363e-01, -7.043e+00,
         2.637e+01, -1.851e+00, -5.612e+00, -2.053e+00, -6.183e+00, -6.749e+00,
        -9.512e+00, -1.179e+01, -1.111e+01,  2.777e+01,  1.008e+01, -1.737e+00,
         2.093e+02, -9.258e-01, -2.924e+00,  1.945e+01, -4.879e+00,  1.128e+01,
         9.870e+01, -1.750e+01, -5.961e+00,  1.584e+02, -2.274e+00,  7.905e+01,
        -1.661e+01, -5.883e+00, -2.757e+00, -1.330e+01,  6.098e+01,  2.562e+01,
         2.751e+00, -5.258e+00, -8.063e-01, -1.302e+01, -1.607e+01, -1.671e+01,
        -1.484e+01, -8.916e+00, -1.938e-01,  4.816e+01,  4.815e+01, -1.533e+01,
        -3.532e+00,  8.279e+01,  2.046e+01, -5.687e+00, -1.320e+01, -1.421e+01,
         1.068e+01, -1.362e+01, -1.054e+01, -1.383e+01, -4.697e+00, -1.203e+00,
        -8.520e+00, -1.187e+01,  7.553e+01, -1.174e+01,  4.685e+01, -6.985e+00,
        -8.027e+00, -7.738e+00, -1.274e+01, -1.421e+01, -3.629e-01, -8.558e-01,
         9.645e+01,  9.366e+00,  1.574e+02,  2.348e+00, -8.409e+00, -9.769e+00,
        -1.138e+01, -1.245e+01, -8.926e+00, -1.287e+01, -7.091e+00, -8.003e+00,
         4.701e+01, -1.142e+01,  2.222e+02, -9.854e+00, -1.246e+01, -1.306e+01,
         6.464e+01,  6.140e+00, -1.038e+01,  3.268e-01,  1.170e+01, -1.307e+01,
         1.991e+01, -9.444e+00, -1.868e+00,  6.314e+01, -1.024e+01, -4.512e-02,
         7.416e+00, -1.339e+01,  6.109e+00, -8.110e+00, -1.039e+01, -9.443e+00,
         1.172e+02,  6.559e+00,  4.684e+01,  5.487e+01, -2.687e-01, -1.003e+01,
        -1.054e+01, -7.365e+00, -3.189e+00, -1.401e+01, -1.569e+01,  1.640e+01,
        -1.618e+01, -1.098e+01,  1.183e+02,  1.424e+01, -1.169e+01, -1.300e+01,
        -9.016e+00,  6.746e+00,  2.426e+01, -8.297e+00, -1.072e+01, -1.215e+01,
         1.309e+01, -1.345e+01,  1.119e+01, -1.142e+01, -1.056e+01, -6.718e+00,
        -2.322e+00, -9.200e+00, -1.200e+01,  2.144e+01,  6.066e+00, -1.399e+00,
         1.122e+01, -1.102e+01, -7.146e+00, -1.386e+01, -9.602e+00, -1.030e+01,
         3.112e+01, -1.153e+00,  1.888e+01, -9.259e+00, -1.233e+01,  5.640e+00,
         2.089e+01, -1.396e+00,  4.270e+00, -1.191e+01,  2.575e+01, -1.128e+01,
        -1.411e+01,  1.307e+01, -1.183e+01,  3.465e+01, -9.339e+00, -7.166e+00,
        -8.545e+00,  3.167e+01,  3.460e+00, -9.333e+00, -1.474e+01,  3.765e+01,
        -8.821e+00, -7.204e+00,  3.071e+00,  4.766e+01, -1.731e+00, -1.174e+01,
        -1.171e+01, -1.404e+01, -1.066e+01,  2.130e+02, -1.498e+01, -1.104e+01,
        -9.680e+00,  2.877e+01,  5.448e+00, -5.340e+00,  2.381e+01,  6.127e+00,
         8.350e+01, -1.363e+01,  2.272e+01, -1.035e+01, -2.490e-01,  7.417e+01,
         1.023e+01,  5.406e+00,  7.237e+01,  3.246e+01, -9.460e+00,  8.487e+01,
        -1.540e+01, -1.145e+01, -6.838e+00,  4.211e+01,  2.902e+01,  4.912e+00,
        -1.394e+01, -8.508e+00,  1.579e+02,  1.080e+02, -1.194e+01, -1.381e+01,
         6.639e+01, -9.764e+00,  3.491e+01, -3.607e+00, -6.478e+00, -6.056e+00,
         1.441e+01,  1.401e+01, -5.638e+00, -8.991e+00,  3.186e+01,  1.526e+01,
        -1.579e+01, -1.354e+01, -7.731e+00,  1.487e+02,  2.637e+01,  3.228e+00,
        -1.129e+00,  6.238e+00, -8.037e+00,  1.423e+01, -8.149e+00,  1.536e+01,
        -6.091e+00, -8.348e+00, -8.861e+00,  1.681e+01, -1.106e+01, -5.427e+00,
        -2.511e+00, -1.615e+01,  1.700e+01, -1.801e+00,  1.451e+01, -1.126e+01,
         3.810e+01, -8.989e+00,  4.610e+01, -1.612e+01,  2.389e+00,  1.772e-01,
        -9.777e+00, -1.192e+01,  4.718e+01,  5.791e+00,  1.020e+01,  4.359e+01,
        -1.168e+01,  2.877e+01, -4.954e+00, -1.047e+01, -6.686e+00,  4.192e+01,
         7.994e+01,  1.198e+02, -1.474e+00, -1.656e+01,  4.494e+01, -1.242e+01,
        -9.877e+00, -1.253e+01, -9.509e+00, -1.365e+01, -8.742e+00, -1.334e+01,
        -8.523e+00,  4.825e-01, -7.383e+00, -1.125e+01,  1.644e+01, -1.068e+01],
       device='cuda:0')
v tensor([5.978e+00, 1.000e-12, 6.085e+00, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 8.878e+00, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        2.751e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 9.366e+00, 1.000e+01, 2.348e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 6.140e+00, 1.000e-12, 3.268e-01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        7.416e+00, 1.000e-12, 6.109e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 6.559e+00, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 6.746e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 6.066e+00, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 5.640e+00,
        1.000e+01, 1.000e-12, 4.270e+00, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 3.460e+00, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 3.071e+00, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 5.448e+00, 1.000e-12, 1.000e+01, 6.127e+00,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 5.406e+00, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 4.912e+00,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 3.228e+00,
        1.000e-12, 6.238e+00, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 2.389e+00, 1.772e-01,
        1.000e-12, 1.000e-12, 1.000e+01, 5.791e+00, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 4.825e-01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-1.075e+01],
         [ 1.452e+01],
         [ 5.708e+01],
         [ 9.824e+00],
         [-1.538e+01],
         [-6.556e+00],
         [-5.786e+00],
         [ 1.383e+01],
         [-4.606e+00],
         [ 2.980e+00]],

        [[ 5.118e+00],
         [ 1.480e+01],
         [-5.794e+00],
         [-2.307e+00],
         [ 8.227e+00],
         [-6.185e-02],
         [ 3.156e+01],
         [ 9.842e+01],
         [ 6.829e+01],
         [-3.442e-01]],

        [[ 3.201e+00],
         [-6.793e+00],
         [ 7.150e+00],
         [ 4.141e+01],
         [ 2.379e+01],
         [ 3.477e+01],
         [-1.648e+01],
         [-9.112e+00],
         [ 2.111e+00],
         [ 1.773e+01]],

        [[-8.087e+00],
         [-1.484e+01],
         [ 6.047e+01],
         [ 6.066e+01],
         [-9.856e+00],
         [-1.212e+01],
         [-9.270e+00],
         [ 3.522e+01],
         [-9.316e+00],
         [-6.674e+00]],

        [[ 6.699e+01],
         [-8.765e+00],
         [ 2.111e+01],
         [-1.500e+01],
         [-1.318e+01],
         [-1.176e+01],
         [-5.526e+00],
         [-1.281e+01],
         [-1.232e+01],
         [ 2.136e+01]],

        [[ 1.139e+02],
         [ 8.456e+00],
         [-7.149e+00],
         [ 2.447e+01],
         [-2.805e+00],
         [ 4.831e+01],
         [ 4.552e+00],
         [-2.004e+00],
         [ 8.481e+00],
         [ 3.326e+01]],

        [[-1.023e+01],
         [-1.285e+00],
         [-8.986e+00],
         [-1.456e+01],
         [ 1.432e+01],
         [-6.079e+00],
         [-1.112e+01],
         [ 1.426e+01],
         [ 6.979e+01],
         [ 6.713e+00]],

        [[ 2.790e+01],
         [ 4.672e+01],
         [-4.893e+00],
         [ 8.013e+01],
         [ 4.585e+00],
         [-1.540e+00],
         [-1.220e+01],
         [-9.614e+00],
         [-1.304e+01],
         [ 6.613e+00]],

        [[-1.078e+01],
         [-8.323e+00],
         [-1.171e+01],
         [-6.084e+00],
         [ 1.545e+01],
         [-1.345e+01],
         [-9.579e+00],
         [-5.346e+00],
         [-9.380e+00],
         [-3.126e+00]],

        [[-5.756e+00],
         [-1.338e+01],
         [ 9.963e+01],
         [ 1.420e+01],
         [ 2.342e+01],
         [ 1.783e+02],
         [-1.185e+01],
         [ 1.205e+02],
         [ 3.499e+00],
         [ 6.111e+01]],

        [[ 2.748e+01],
         [ 4.443e+01],
         [-1.269e+01],
         [ 4.501e+01],
         [-1.152e+01],
         [-1.301e+01],
         [ 3.184e+01],
         [ 3.378e-01],
         [ 3.441e+00],
         [-1.140e+01]],

        [[-1.157e+01],
         [-2.527e+00],
         [-8.848e+00],
         [ 1.585e+01],
         [ 1.329e+01],
         [-5.797e+00],
         [-1.326e+01],
         [-5.893e+00],
         [ 2.750e+01],
         [ 5.999e+00]],

        [[ 4.567e+01],
         [ 3.903e+00],
         [ 2.291e+01],
         [-9.885e+00],
         [ 2.096e+00],
         [ 4.880e+00],
         [-1.167e+01],
         [ 3.282e-01],
         [ 2.122e+01],
         [ 1.128e+01]],

        [[-1.201e+01],
         [ 1.363e+01],
         [ 8.981e+00],
         [-3.947e+00],
         [-1.134e+01],
         [-4.005e+00],
         [-7.312e+00],
         [ 1.118e+01],
         [ 1.486e+01],
         [ 3.601e+01]],

        [[-1.267e+01],
         [-1.400e+01],
         [-1.005e+01],
         [-2.066e+00],
         [ 8.611e+01],
         [ 8.731e+01],
         [-9.950e+00],
         [-6.820e+00],
         [ 4.224e+01],
         [ 3.269e+01]],

        [[-1.070e+01],
         [ 4.039e+01],
         [ 5.773e+01],
         [-9.877e+00],
         [ 3.204e+01],
         [-1.192e+01],
         [ 5.364e+01],
         [-1.314e+01],
         [-1.493e+01],
         [ 8.961e+01]],

        [[ 5.659e+01],
         [ 1.294e+01],
         [-6.969e+00],
         [-1.397e+01],
         [-1.630e+01],
         [ 7.002e+01],
         [-9.213e+00],
         [-2.594e+00],
         [-1.383e+00],
         [-6.873e+00]],

        [[ 4.572e+00],
         [ 5.143e+01],
         [ 1.504e+01],
         [-3.227e+00],
         [ 2.763e+00],
         [-9.614e+00],
         [ 6.777e+00],
         [ 3.835e+00],
         [ 8.998e+00],
         [-1.728e+01]],

        [[-6.123e+00],
         [-9.363e+00],
         [ 7.312e+00],
         [ 7.842e+01],
         [-1.356e+01],
         [ 3.523e+01],
         [-5.723e+00],
         [ 6.158e+01],
         [-1.035e+01],
         [-1.244e+01]],

        [[ 5.481e+00],
         [-6.431e+00],
         [-2.746e+00],
         [-8.302e+00],
         [-7.875e+00],
         [ 1.125e+00],
         [-1.060e+01],
         [-9.660e+00],
         [ 1.780e+01],
         [ 3.289e+01]],

        [[-1.427e+01],
         [-5.975e+00],
         [-1.187e+01],
         [-1.537e+01],
         [-1.266e+01],
         [-1.280e+01],
         [-1.308e+01],
         [-1.239e+01],
         [-3.564e+00],
         [ 3.942e+01]],

        [[ 1.955e+01],
         [-1.231e+01],
         [ 2.676e+01],
         [-1.261e+01],
         [ 1.829e+00],
         [ 1.083e+01],
         [ 3.240e+01],
         [-1.198e+01],
         [-1.037e+01],
         [ 3.833e+01]],

        [[-8.364e+00],
         [-2.609e+00],
         [-1.148e+01],
         [-1.045e+01],
         [-4.932e+00],
         [-4.358e+00],
         [ 2.375e+01],
         [ 1.431e+01],
         [-1.747e+01],
         [ 1.007e+00]],

        [[-1.050e+01],
         [ 1.361e+01],
         [-4.613e+00],
         [ 3.584e+00],
         [-7.761e+00],
         [ 1.464e+00],
         [-1.526e+01],
         [ 3.444e+01],
         [ 9.526e+00],
         [ 2.134e+00]],

        [[-1.176e+01],
         [-5.652e+00],
         [ 3.446e-01],
         [-5.799e+00],
         [-1.058e+01],
         [ 3.869e+01],
         [-1.791e+00],
         [-1.385e+01],
         [-1.167e+01],
         [ 4.631e+00]],

        [[-8.689e+00],
         [-1.577e+01],
         [-1.319e+01],
         [ 3.723e+00],
         [-1.509e+01],
         [-1.363e+01],
         [-5.476e+00],
         [ 9.708e+00],
         [-2.392e+00],
         [ 2.961e+01]],

        [[-9.644e+00],
         [-4.410e-02],
         [ 5.495e+00],
         [ 4.466e+01],
         [-1.617e+00],
         [-2.870e+00],
         [ 8.172e+01],
         [-1.509e+01],
         [ 7.853e+01],
         [-4.625e+00]],

        [[-1.070e+01],
         [-1.440e+01],
         [ 7.380e+00],
         [-1.167e+01],
         [-1.278e+01],
         [ 7.703e+01],
         [ 4.047e+01],
         [-9.062e+00],
         [-1.110e+01],
         [ 2.280e+01]],

        [[ 3.606e+01],
         [-8.481e+00],
         [-1.356e+01],
         [ 1.082e+00],
         [-1.126e+01],
         [-1.426e+01],
         [ 3.641e+00],
         [-1.506e+01],
         [ 3.897e+01],
         [ 1.292e+01]],

        [[ 3.444e+01],
         [ 7.246e+00],
         [ 1.825e+01],
         [ 2.626e+01],
         [ 1.467e+01],
         [ 1.573e+00],
         [-7.044e+00],
         [ 3.921e+01],
         [-1.240e+01],
         [ 3.513e-01]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [9.824e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [2.980e+00]],

        [[5.118e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [8.227e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[3.201e+00],
         [1.000e-12],
         [7.150e+00],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [2.111e+00],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [8.456e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [4.552e+00],
         [1.000e-12],
         [8.481e+00],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [6.713e+00]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [4.585e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.613e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [3.499e+00],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [3.378e-01],
         [3.441e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [5.999e+00]],

        [[1.000e+01],
         [3.903e+00],
         [1.000e+01],
         [1.000e-12],
         [2.096e+00],
         [4.880e+00],
         [1.000e-12],
         [3.282e-01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [8.981e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[4.572e+00],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [2.763e+00],
         [1.000e-12],
         [6.777e+00],
         [3.835e+00],
         [8.998e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [7.312e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[5.481e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.125e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.829e+00],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.007e+00]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [3.584e+00],
         [1.000e-12],
         [1.464e+00],
         [1.000e-12],
         [1.000e+01],
         [9.526e+00],
         [2.134e+00]],

        [[1.000e-12],
         [1.000e-12],
         [3.446e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.631e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.723e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [9.708e+00],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [5.495e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [7.380e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.082e+00],
         [1.000e-12],
         [1.000e-12],
         [3.641e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [7.246e+00],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.573e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [3.513e-01]]], device='cuda:0')
v before min max tensor([[ -0.610],
        [ -4.512],
        [ -8.048],
        [ 12.927],
        [ 71.236],
        [-14.467],
        [-12.717],
        [ 26.240],
        [ -9.727],
        [ -9.949],
        [  0.702],
        [ 33.165],
        [ -8.934],
        [-12.019],
        [ -2.291],
        [ 51.224],
        [-11.333],
        [ -7.252],
        [ 34.152],
        [-11.524],
        [ 75.584],
        [ 14.597],
        [  6.301],
        [ 12.535],
        [ 90.173],
        [ -1.439],
        [ -7.165],
        [ -6.318],
        [  5.810],
        [-15.520]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [7.023e-01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [6.301e+00],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [5.810e+00],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 2.461e-02,  4.551e-01,  1.766e-01,  ..., -7.034e-02,  4.751e-03,
         -7.014e-02],
        [ 1.693e-02, -3.008e-02,  7.214e-02,  ..., -1.042e-01,  3.149e-02,
         -6.993e-02],
        [-2.482e-04,  3.117e-03,  7.083e-02,  ..., -5.786e-03, -7.940e-02,
          1.222e-01],
        ...,
        [-1.833e-01,  5.448e-02,  3.865e-02,  ...,  2.862e-01,  7.689e-02,
          5.705e-03],
        [-1.411e-01,  6.410e-02,  7.836e-02,  ..., -4.613e-01, -2.304e-02,
         -1.882e-02],
        [-4.032e-02,  7.768e-03,  4.432e-03,  ..., -1.080e-01,  2.184e-02,
         -2.208e-02]], device='cuda:0')
s after update for 1 param tensor([[2.986, 2.410, 2.287,  ..., 1.803, 1.441, 1.075],
        [2.081, 1.860, 2.100,  ..., 1.487, 0.915, 1.569],
        [2.473, 1.416, 1.679,  ..., 0.962, 1.401, 1.623],
        ...,
        [1.863, 1.793, 1.606,  ..., 1.953, 1.656, 2.067],
        [1.498, 1.390, 1.605,  ..., 2.200, 2.228, 2.825],
        [1.972, 1.814, 1.567,  ..., 1.776, 1.451, 2.495]], device='cuda:0')
b after update for 1 param tensor([[225.417, 202.520, 197.263,  ..., 175.161, 156.596, 135.237],
        [188.181, 177.902, 189.022,  ..., 159.098, 124.778, 163.418],
        [205.134, 155.221, 169.033,  ..., 127.977, 154.408, 166.195],
        ...,
        [178.041, 174.688, 165.313,  ..., 182.313, 167.885, 187.543],
        [159.682, 153.784, 165.261,  ..., 193.489, 194.732, 219.244],
        [183.195, 175.694, 163.301,  ..., 173.838, 157.156, 206.039]],
       device='cuda:0')
clipping threshold 0.18546934573626117
a after update for 1 param tensor([-0.237,  0.182,  0.115, -0.252, -0.199,  0.043,  0.014, -0.252, -0.085,
         0.144, -0.493,  0.108,  0.122,  0.060, -0.013,  0.040, -0.563, -0.013,
         0.414,  0.052,  0.164,  0.073, -0.139, -0.067, -0.198, -0.170, -0.219,
         0.240, -0.209,  0.208,  0.006,  0.218, -0.070,  0.001, -0.068, -0.464,
        -0.065,  0.031, -0.042,  0.008,  0.062,  0.092,  0.030,  0.245,  0.091,
        -0.164,  0.299,  0.590, -0.047, -0.077,  0.004,  0.115, -0.049, -0.108,
         0.111,  0.088, -0.264, -0.085,  0.115,  0.038,  0.029, -0.244,  0.215,
         0.176,  0.086, -0.110,  0.009,  0.124,  0.174,  0.017, -0.070,  0.223,
         0.396,  0.161, -0.064,  0.057,  0.175,  0.156, -0.169,  0.184,  0.247,
        -0.267,  0.059, -0.283, -0.203,  0.146, -0.192, -0.206,  0.060,  0.308,
         0.161, -0.092, -0.001, -0.215,  0.215, -0.366, -0.059,  0.193, -0.173,
         0.226,  0.078, -0.061,  0.005,  0.098, -0.559,  0.039, -0.177, -0.121,
         0.097, -0.230, -0.007,  0.017,  0.161, -0.231,  0.249,  0.231, -0.251,
         0.248,  0.067,  0.101,  0.236, -0.285,  0.294, -0.031,  0.418,  0.090,
        -0.060,  0.207, -0.311, -0.178, -0.830,  0.096, -0.256,  0.067, -0.160,
        -0.173,  0.356, -0.161,  0.167,  0.311, -0.035, -0.002, -0.052, -0.168,
         0.210, -0.047,  0.239, -0.011,  0.244,  0.471, -0.164, -0.029, -0.169,
        -0.238, -0.184, -0.141, -0.175,  0.003, -0.076,  0.086, -0.089,  0.141,
         0.157,  0.216,  0.020, -0.104,  0.347,  0.039,  0.166, -0.098, -0.048,
         0.098,  0.045,  0.128, -0.045, -0.258, -0.011,  0.308, -0.161,  0.052,
         0.239,  0.301,  0.065, -0.041, -0.187, -0.151, -0.036,  0.030,  0.131,
        -0.022, -0.163,  0.082, -0.115, -0.404,  0.090,  0.279,  0.139,  0.195,
         0.234, -0.287, -0.110,  0.077, -0.183, -0.217,  0.155, -0.264,  0.232,
         0.076,  0.043,  0.220, -0.005, -0.129,  0.103, -0.070, -0.022,  0.099,
        -0.074,  0.104, -0.123, -0.141, -0.059,  0.046,  0.082, -0.137,  0.513,
         0.225,  0.015, -0.054,  0.293, -0.260, -0.303,  0.076, -0.213, -0.127,
        -0.249,  0.232, -0.142,  0.341,  0.253, -0.095, -0.011, -0.228,  0.147,
        -0.135, -0.036,  0.078,  0.053,  0.027, -0.148, -0.252,  0.008,  0.147,
         0.174, -0.090, -0.574,  0.191, -0.402, -0.254, -0.333,  0.253,  0.167,
        -0.110, -0.036, -0.067,  0.046,  0.001, -0.031,  0.040, -0.138, -0.453,
         0.380, -0.038,  0.164, -0.011, -0.123, -0.107,  0.165, -0.037, -0.107,
        -0.179,  0.045, -0.427, -0.429,  0.241,  0.061,  0.076,  0.152, -0.167,
         0.244,  0.158, -0.226, -0.168,  0.251,  0.010, -0.074,  0.091, -0.052,
         0.157,  0.083,  0.085], device='cuda:0')
s after update for 1 param tensor([1.591, 1.640, 1.858, 2.097, 1.793, 1.732, 1.471, 2.171, 2.282, 1.999,
        1.220, 1.216, 1.676, 1.790, 1.850, 1.968, 2.031, 1.458, 1.965, 1.058,
        1.405, 1.688, 2.072, 1.519, 1.527, 1.482, 1.576, 1.556, 1.799, 1.631,
        2.321, 1.412, 1.590, 1.628, 1.449, 1.991, 1.796, 2.184, 1.479, 2.037,
        1.517, 1.616, 2.153, 1.786, 1.403, 1.681, 1.847, 1.842, 1.761, 1.676,
        1.587, 2.008, 2.130, 2.107, 1.876, 1.700, 1.692, 1.983, 2.103, 1.914,
        1.128, 1.988, 1.575, 1.263, 1.658, 1.802, 1.710, 1.866, 1.350, 1.820,
        0.983, 2.172, 1.315, 1.481, 2.034, 1.477, 2.307, 1.474, 1.762, 1.104,
        1.668, 1.778, 1.503, 1.451, 2.115, 1.609, 2.190, 1.859, 1.513, 1.339,
        1.643, 1.788, 1.762, 1.705, 1.602, 1.680, 1.996, 1.604, 2.487, 1.713,
        1.585, 1.653, 2.017, 1.517, 1.985, 1.534, 1.787, 1.629, 2.584, 1.500,
        1.170, 1.652, 1.296, 1.550, 2.105, 1.683, 1.880, 1.803, 1.338, 1.453,
        2.258, 1.714, 2.059, 1.785, 1.878, 1.250, 1.627, 1.575, 1.951, 1.747,
        2.093, 1.710, 2.045, 1.433, 1.916, 1.983, 1.818, 1.684, 1.623, 1.841,
        1.707, 1.184, 1.487, 1.514, 2.154, 1.677, 2.099, 1.423, 2.084, 1.495,
        1.503, 1.889, 1.648, 2.027, 1.654, 1.768, 1.984, 1.869, 1.801, 1.727,
        1.357, 1.736, 1.715, 1.787, 1.445, 1.657, 1.542, 2.163, 1.248, 1.600,
        2.059, 1.557, 1.222, 1.841, 1.758, 1.457, 1.475, 2.175, 1.288, 1.616,
        1.261, 2.187, 1.763, 1.176, 1.851, 1.996, 1.775, 1.959, 1.615, 1.650,
        1.497, 1.802, 1.722, 1.768, 1.496, 1.779, 1.870, 1.574, 1.548, 1.972,
        1.987, 1.319, 1.823, 2.008, 1.825, 2.029, 1.531, 1.578, 1.743, 1.924,
        1.522, 2.106, 1.884, 1.640, 1.625, 1.921, 1.960, 1.442, 1.837, 1.820,
        1.947, 2.117, 1.751, 1.744, 2.030, 2.104, 1.489, 1.733, 1.786, 1.311,
        2.030, 1.062, 1.765, 1.521, 1.629, 2.117, 1.579, 2.125, 1.658, 2.078,
        1.984, 1.838, 1.196, 1.758, 1.966, 1.945, 2.129, 1.512, 1.307, 1.974,
        1.296, 2.000, 1.211, 1.123, 2.077, 2.110, 2.053, 1.874, 1.445, 2.146,
        1.809, 1.522, 2.503, 2.142, 1.771, 1.127, 2.084, 2.168, 1.495, 2.386,
        1.519, 1.563, 1.631, 1.543, 1.893, 2.217, 1.508, 2.063, 1.050, 1.305,
        1.916, 1.920, 1.822, 2.367, 1.184, 2.064, 2.307, 1.978, 1.506, 1.565,
        1.322, 1.868, 1.119, 1.820, 1.499, 1.294, 1.441, 1.984, 2.032, 1.777],
       device='cuda:0')
b after update for 1 param tensor([164.531, 167.047, 177.836, 188.886, 174.678, 171.664, 158.224, 192.230,
        197.054, 184.435, 144.090, 143.862, 168.886, 174.554, 177.414, 182.983,
        185.912, 157.507, 182.867, 134.181, 154.642, 169.495, 187.787, 160.770,
        161.205, 158.816, 163.766, 162.719, 174.959, 166.604, 198.736, 154.984,
        164.493, 166.455, 157.054, 184.083, 174.823, 192.773, 158.651, 186.160,
        160.677, 165.824, 191.428, 174.334, 154.520, 169.156, 177.307, 177.033,
        173.097, 168.876, 164.332, 184.851, 190.364, 189.333, 178.693, 170.086,
        169.703, 183.708, 189.160, 180.473, 138.518, 183.912, 163.700, 146.582,
        167.964, 175.119, 170.584, 178.215, 151.557, 176.006, 129.310, 192.236,
        149.596, 158.742, 186.030, 158.558, 198.135, 158.383, 173.148, 137.043,
        168.485, 173.952, 159.949, 157.136, 189.722, 165.495, 193.041, 177.870,
        160.478, 150.943, 167.231, 174.446, 173.139, 170.323, 165.095, 169.105,
        184.313, 165.201, 205.711, 170.736, 164.257, 167.721, 185.278, 160.662,
        183.796, 161.576, 174.386, 166.497, 209.713, 159.752, 141.132, 167.683,
        148.521, 162.420, 189.263, 169.248, 178.867, 175.152, 150.871, 157.257,
        196.022, 170.779, 187.197, 174.305, 178.751, 145.850, 166.417, 163.719,
        182.191, 172.406, 188.746, 170.574, 186.544, 156.171, 180.549, 183.690,
        175.906, 169.302, 166.202, 177.017, 170.426, 141.933, 159.059, 160.500,
        191.438, 168.955, 188.979, 155.610, 188.305, 159.510, 159.910, 179.286,
        167.442, 185.738, 167.793, 173.474, 183.753, 178.362, 175.060, 171.419,
        151.970, 171.871, 170.818, 174.366, 156.810, 167.897, 161.978, 191.875,
        145.714, 164.986, 187.177, 162.767, 144.220, 177.018, 172.986, 157.459,
        158.409, 192.369, 148.024, 165.806, 146.487, 192.934, 173.222, 141.440,
        177.492, 184.300, 173.789, 182.563, 165.779, 167.577, 159.586, 175.118,
        171.206, 173.457, 159.532, 174.005, 178.379, 163.645, 162.297, 183.183,
        183.887, 149.807, 176.116, 184.846, 176.210, 185.828, 161.404, 163.863,
        172.225, 180.940, 160.915, 189.294, 179.047, 167.038, 166.299, 180.814,
        182.630, 156.662, 176.788, 175.973, 182.040, 189.809, 172.618, 172.257,
        185.876, 189.237, 159.180, 171.745, 174.333, 149.379, 185.860, 134.414,
        173.297, 160.900, 166.501, 189.786, 163.907, 190.178, 167.976, 188.067,
        183.756, 176.848, 142.659, 172.942, 182.895, 181.921, 190.341, 160.410,
        149.141, 183.279, 148.529, 184.471, 143.576, 138.222, 187.992, 189.507,
        186.897, 178.595, 156.805, 191.089, 175.463, 160.944, 206.399, 190.923,
        173.590, 138.492, 188.303, 192.091, 159.519, 201.496, 160.775, 163.103,
        166.615, 162.047, 179.465, 194.252, 160.216, 187.385, 133.676, 149.000,
        180.579, 180.778, 176.083, 200.702, 141.959, 187.420, 198.143, 183.449,
        160.075, 163.211, 150.016, 178.302, 138.018, 175.978, 159.719, 148.417,
        156.568, 183.742, 185.950, 173.887], device='cuda:0')
clipping threshold 0.18546934573626117
a after update for 1 param tensor([[[ 2.635e-02],
         [ 2.209e-01],
         [-7.993e-02],
         [ 6.336e-02],
         [-1.217e-01],
         [ 4.047e-02],
         [-1.119e-01],
         [ 7.749e-02],
         [ 2.233e-01],
         [ 7.769e-02]],

        [[-2.901e-02],
         [ 9.648e-02],
         [ 1.970e-01],
         [-1.275e-01],
         [ 2.513e-01],
         [ 5.646e-02],
         [ 9.333e-02],
         [ 2.340e-02],
         [-3.588e-01],
         [-3.909e-02]],

        [[-2.393e-02],
         [-9.166e-02],
         [-5.213e-01],
         [ 1.595e-01],
         [-3.757e-02],
         [ 1.850e-01],
         [ 1.370e-01],
         [ 2.659e-01],
         [-3.273e-02],
         [ 2.271e-02]],

        [[-1.567e-01],
         [-8.975e-02],
         [-2.659e-02],
         [ 2.598e-01],
         [-2.374e-01],
         [-1.840e-01],
         [ 1.734e-01],
         [-3.221e-01],
         [ 6.363e-02],
         [ 1.132e-01]],

        [[-1.426e-01],
         [ 1.741e-02],
         [ 1.787e-01],
         [-6.602e-02],
         [ 6.243e-02],
         [-1.021e-01],
         [-1.512e-01],
         [ 3.105e-01],
         [-1.387e-01],
         [ 3.020e-01]],

        [[-3.229e-01],
         [-5.559e-01],
         [-1.601e-01],
         [ 2.163e-01],
         [-3.010e-02],
         [ 1.616e-01],
         [-3.893e-02],
         [ 8.811e-03],
         [-1.152e-01],
         [-8.691e-02]],

        [[-6.537e-02],
         [ 1.254e-01],
         [-1.676e-01],
         [ 5.247e-02],
         [ 7.011e-02],
         [ 6.450e-02],
         [ 1.056e-01],
         [-5.016e-01],
         [ 1.598e-01],
         [ 1.807e-01]],

        [[ 3.762e-02],
         [ 2.360e-01],
         [ 2.232e-01],
         [-3.299e-01],
         [ 4.798e-02],
         [-2.053e-01],
         [-3.969e-03],
         [ 1.923e-01],
         [ 1.492e-01],
         [ 7.580e-02]],

        [[-2.632e-01],
         [ 2.035e-01],
         [ 6.346e-02],
         [ 3.074e-01],
         [-1.789e-01],
         [ 1.875e-01],
         [ 5.174e-02],
         [ 7.752e-02],
         [-3.474e-01],
         [-9.025e-02]],

        [[-1.392e-01],
         [-5.034e-02],
         [-6.609e-02],
         [ 1.419e-01],
         [ 1.052e-01],
         [ 1.872e-01],
         [ 1.284e-01],
         [-2.690e-01],
         [-5.746e-02],
         [-1.102e-01]],

        [[ 2.322e-02],
         [ 3.671e-01],
         [-3.024e-01],
         [-1.951e-01],
         [ 2.645e-01],
         [ 9.305e-02],
         [ 6.461e-02],
         [ 2.671e-04],
         [-3.141e-01],
         [-1.740e-01]],

        [[-2.975e-01],
         [-2.330e-01],
         [ 3.016e-01],
         [ 1.566e-01],
         [ 3.031e-02],
         [-1.149e-01],
         [ 1.827e-01],
         [ 2.097e-01],
         [-2.653e-01],
         [ 1.712e-01]],

        [[ 1.467e-01],
         [-1.251e-01],
         [-1.266e-01],
         [ 2.766e-01],
         [-8.672e-02],
         [-1.937e-01],
         [-1.665e-01],
         [ 4.388e-01],
         [-1.175e-03],
         [ 2.108e-01]],

        [[-4.303e-01],
         [ 3.660e-01],
         [ 1.175e-01],
         [-1.668e-01],
         [ 2.923e-02],
         [-3.853e-02],
         [-2.612e-02],
         [-1.529e-01],
         [-3.355e-01],
         [-1.594e-01]],

        [[-1.854e-01],
         [ 2.526e-01],
         [ 1.430e-01],
         [ 1.108e-01],
         [ 1.101e-01],
         [ 1.729e-01],
         [ 3.334e-02],
         [ 6.538e-02],
         [ 2.402e-01],
         [-2.702e-02]],

        [[ 2.246e-01],
         [ 6.126e-02],
         [-7.126e-03],
         [-9.898e-04],
         [ 4.097e-02],
         [-2.352e-01],
         [-3.212e-01],
         [-1.905e-01],
         [ 1.768e-01],
         [-5.217e-02]],

        [[ 3.303e-01],
         [ 1.380e-02],
         [ 9.805e-04],
         [-2.320e-01],
         [ 2.771e-01],
         [ 3.411e-02],
         [ 2.762e-01],
         [ 1.201e-01],
         [-6.021e-02],
         [ 8.304e-02]],

        [[ 1.844e-01],
         [-5.513e-02],
         [ 1.422e-01],
         [-7.833e-02],
         [-1.212e-01],
         [ 2.340e-02],
         [-1.508e-01],
         [ 1.049e-01],
         [-1.320e-01],
         [ 2.224e-01]],

        [[-6.208e-02],
         [-2.522e-01],
         [ 2.625e-01],
         [-1.319e-01],
         [ 9.137e-02],
         [ 1.038e-01],
         [ 3.137e-02],
         [ 8.385e-02],
         [-1.924e-01],
         [-3.567e-01]],

        [[-2.216e-01],
         [-1.856e-02],
         [ 3.786e-02],
         [-1.743e-01],
         [-1.331e-02],
         [ 1.732e-01],
         [-1.486e-01],
         [-2.368e-01],
         [ 2.163e-01],
         [-1.789e-01]],

        [[ 3.667e-01],
         [ 1.010e-01],
         [ 2.546e-01],
         [-2.932e-01],
         [ 6.549e-02],
         [-5.542e-02],
         [-2.148e-01],
         [ 9.939e-03],
         [ 1.117e-01],
         [-4.118e-02]],

        [[ 3.281e-01],
         [ 8.158e-02],
         [ 4.457e-02],
         [ 1.905e-01],
         [-1.489e-01],
         [-1.023e-01],
         [-1.218e-01],
         [-1.786e-01],
         [-8.863e-02],
         [-2.080e-01]],

        [[-1.662e-01],
         [-3.780e-01],
         [-3.719e-01],
         [-2.740e-01],
         [ 3.715e-02],
         [ 1.351e-01],
         [ 3.576e-01],
         [ 2.353e-01],
         [ 1.041e-01],
         [ 1.593e-01]],

        [[-2.367e-01],
         [-1.399e-01],
         [-7.495e-02],
         [ 2.632e-02],
         [ 8.894e-02],
         [-4.165e-01],
         [ 2.775e-01],
         [ 3.811e-02],
         [-1.526e-01],
         [ 4.586e-01]],

        [[ 8.983e-02],
         [ 4.714e-02],
         [ 2.621e-03],
         [ 2.352e-01],
         [ 1.394e-01],
         [ 1.973e-01],
         [-3.981e-02],
         [ 1.573e-01],
         [-1.396e-01],
         [-3.816e-02]],

        [[ 3.490e-01],
         [-1.130e-01],
         [-1.066e-01],
         [ 3.352e-01],
         [ 1.054e-01],
         [-1.900e-01],
         [ 1.117e-01],
         [-1.224e-01],
         [ 4.354e-02],
         [ 1.131e-01]],

        [[ 3.533e-02],
         [ 3.208e-01],
         [-8.990e-02],
         [-1.125e-01],
         [-1.913e-01],
         [ 4.989e-02],
         [ 3.482e-02],
         [ 5.122e-02],
         [-3.428e-01],
         [ 5.215e-02]],

        [[-3.639e-02],
         [ 1.876e-02],
         [-7.907e-01],
         [ 1.030e-01],
         [-1.159e-01],
         [ 3.121e-01],
         [-1.001e-01],
         [ 1.746e-01],
         [-4.685e-02],
         [ 1.414e-01]],

        [[-1.784e-01],
         [-1.391e-02],
         [-3.252e-01],
         [ 4.727e-02],
         [ 3.756e-01],
         [-9.724e-02],
         [ 2.287e-01],
         [ 2.337e-02],
         [-4.448e-01],
         [ 1.486e-02]],

        [[ 1.088e-03],
         [-1.693e-01],
         [ 2.457e-01],
         [ 1.989e-01],
         [-1.687e-01],
         [-1.577e-01],
         [ 5.989e-02],
         [-2.436e-01],
         [-1.313e-01],
         [ 2.526e-01]]], device='cuda:0')
s after update for 1 param tensor([[[1.473],
         [1.895],
         [2.009],
         [1.496],
         [1.973],
         [1.773],
         [1.434],
         [1.735],
         [1.262],
         [1.578]],

        [[1.613],
         [2.097],
         [1.492],
         [1.539],
         [1.902],
         [1.428],
         [1.997],
         [1.910],
         [2.006],
         [1.959]],

        [[1.299],
         [1.861],
         [1.973],
         [2.313],
         [2.012],
         [1.711],
         [2.054],
         [1.201],
         [1.178],
         [2.215]],

        [[1.307],
         [1.849],
         [2.136],
         [1.847],
         [1.401],
         [1.599],
         [1.570],
         [2.141],
         [1.480],
         [1.346]],

        [[2.126],
         [1.381],
         [2.037],
         [1.903],
         [1.837],
         [1.549],
         [1.244],
         [1.807],
         [1.619],
         [2.254]],

        [[2.306],
         [1.975],
         [1.592],
         [1.498],
         [1.717],
         [1.578],
         [1.608],
         [1.711],
         [2.119],
         [2.012]],

        [[1.602],
         [1.054],
         [1.167],
         [1.824],
         [1.899],
         [1.943],
         [1.413],
         [1.365],
         [1.915],
         [2.082]],

        [[2.171],
         [1.965],
         [1.249],
         [2.095],
         [1.352],
         [1.737],
         [1.629],
         [1.412],
         [1.634],
         [1.932]],

        [[1.633],
         [1.761],
         [1.458],
         [2.001],
         [2.025],
         [1.676],
         [1.591],
         [1.510],
         [1.603],
         [1.701]],

        [[1.880],
         [1.670],
         [1.583],
         [1.806],
         [1.865],
         [1.803],
         [1.741],
         [1.762],
         [2.058],
         [1.555]],

        [[2.012],
         [2.205],
         [1.915],
         [2.297],
         [1.795],
         [1.872],
         [1.712],
         [1.239],
         [1.423],
         [1.469]],

        [[2.064],
         [1.360],
         [1.783],
         [1.942],
         [1.702],
         [1.474],
         [1.939],
         [1.992],
         [2.104],
         [1.846]],

        [[2.037],
         [1.107],
         [2.247],
         [1.500],
         [1.698],
         [1.860],
         [1.619],
         [1.398],
         [2.382],
         [1.872]],

        [[1.598],
         [1.833],
         [1.531],
         [1.845],
         [1.451],
         [1.438],
         [2.020],
         [1.946],
         [2.066],
         [2.145]],

        [[1.628],
         [1.922],
         [1.303],
         [1.489],
         [2.105],
         [2.052],
         [1.563],
         [1.575],
         [1.505],
         [2.105]],

        [[1.965],
         [2.489],
         [2.054],
         [1.624],
         [1.782],
         [1.508],
         [2.070],
         [1.717],
         [2.045],
         [1.948]],

        [[2.235],
         [2.014],
         [1.150],
         [2.196],
         [2.054],
         [2.330],
         [1.682],
         [1.847],
         [1.520],
         [1.576]],

        [[2.169],
         [1.972],
         [1.618],
         [1.108],
         [1.783],
         [1.335],
         [1.431],
         [1.353],
         [1.737],
         [2.154]],

        [[1.100],
         [1.292],
         [1.842],
         [1.742],
         [1.750],
         [2.176],
         [1.439],
         [1.980],
         [1.472],
         [1.878]],

        [[2.407],
         [1.785],
         [2.060],
         [1.625],
         [1.939],
         [2.012],
         [1.986],
         [1.470],
         [1.802],
         [2.088]],

        [[1.794],
         [1.468],
         [1.483],
         [2.207],
         [1.682],
         [1.730],
         [1.659],
         [1.802],
         [1.767],
         [1.512]],

        [[2.029],
         [1.674],
         [1.979],
         [1.711],
         [1.677],
         [2.012],
         [1.931],
         [1.499],
         [1.789],
         [1.867]],

        [[1.082],
         [1.528],
         [1.697],
         [1.699],
         [1.306],
         [1.511],
         [1.677],
         [1.599],
         [2.190],
         [1.737]],

        [[1.315],
         [1.816],
         [1.044],
         [1.983],
         [1.658],
         [1.256],
         [1.956],
         [2.006],
         [1.294],
         [1.591]],

        [[1.580],
         [1.675],
         [1.684],
         [1.563],
         [1.412],
         [1.883],
         [2.084],
         [1.860],
         [1.458],
         [1.411]],

        [[2.092],
         [2.030],
         [1.901],
         [1.837],
         [1.881],
         [1.700],
         [0.763],
         [1.703],
         [1.093],
         [1.793]],

        [[1.605],
         [1.833],
         [1.725],
         [2.237],
         [1.593],
         [1.420],
         [1.953],
         [1.989],
         [1.951],
         [1.605]],

        [[1.540],
         [1.877],
         [1.922],
         [1.691],
         [1.781],
         [1.927],
         [1.746],
         [1.838],
         [1.952],
         [1.307]],

        [[1.620],
         [1.534],
         [1.983],
         [1.353],
         [1.813],
         [1.800],
         [1.818],
         [1.894],
         [2.581],
         [1.610]],

        [[1.909],
         [2.053],
         [1.680],
         [2.104],
         [1.865],
         [1.541],
         [1.455],
         [2.290],
         [1.986],
         [0.731]]], device='cuda:0')
b after update for 1 param tensor([[[158.303],
         [179.563],
         [184.890],
         [159.558],
         [183.219],
         [173.678],
         [156.196],
         [171.829],
         [146.534],
         [163.847]],

        [[165.666],
         [188.920],
         [159.359],
         [161.844],
         [179.914],
         [155.891],
         [184.328],
         [180.284],
         [184.750],
         [182.594]],

        [[148.659],
         [177.944],
         [183.229],
         [198.396],
         [185.047],
         [170.641],
         [186.960],
         [142.932],
         [141.594],
         [194.135]],

        [[149.133],
         [177.360],
         [190.648],
         [177.279],
         [154.422],
         [164.949],
         [163.458],
         [190.858],
         [158.682],
         [151.325]],

        [[190.223],
         [153.324],
         [186.179],
         [179.939],
         [176.792],
         [162.355],
         [145.514],
         [175.357],
         [165.966],
         [195.862]],

        [[198.088],
         [183.339],
         [164.618],
         [159.649],
         [170.916],
         [163.878],
         [165.430],
         [170.615],
         [189.877],
         [185.023]],

        [[165.101],
         [133.927],
         [140.910],
         [176.194],
         [179.756],
         [181.833],
         [155.043],
         [152.407],
         [180.501],
         [188.232]],

        [[192.229],
         [182.842],
         [145.791],
         [188.798],
         [151.670],
         [171.929],
         [166.517],
         [154.987],
         [166.754],
         [181.342]],

        [[166.726],
         [173.132],
         [157.540],
         [184.524],
         [185.644],
         [168.905],
         [164.528],
         [160.306],
         [165.185],
         [170.118]],

        [[178.853],
         [168.585],
         [164.134],
         [175.293],
         [178.154],
         [175.150],
         [172.148],
         [173.160],
         [187.142],
         [162.661]],

        [[185.059],
         [193.689],
         [180.515],
         [197.713],
         [174.773],
         [178.506],
         [170.692],
         [145.218],
         [155.624],
         [158.115]],

        [[187.395],
         [152.136],
         [174.193],
         [181.808],
         [170.169],
         [158.366],
         [181.663],
         [184.129],
         [189.217],
         [177.253]],

        [[186.177],
         [137.231],
         [195.564],
         [159.784],
         [170.000],
         [177.914],
         [165.965],
         [154.246],
         [201.314],
         [178.470]],

        [[164.929],
         [176.610],
         [161.414],
         [177.208],
         [157.153],
         [156.410],
         [185.422],
         [181.957],
         [187.524],
         [191.064]],

        [[166.447],
         [180.848],
         [148.903],
         [159.170],
         [189.270],
         [186.876],
         [163.064],
         [163.692],
         [160.010],
         [189.264]],

        [[182.884],
         [205.797],
         [186.955],
         [166.260],
         [174.124],
         [160.179],
         [187.689],
         [170.941],
         [186.562],
         [182.065]],

        [[195.025],
         [185.111],
         [139.883],
         [193.291],
         [186.937],
         [199.144],
         [169.177],
         [177.267],
         [160.816],
         [163.791]],

        [[192.115],
         [183.205],
         [165.957],
         [137.307],
         [174.175],
         [150.717],
         [156.026],
         [151.723],
         [171.916],
         [191.434]],

        [[136.823],
         [148.297],
         [177.061],
         [172.189],
         [172.575],
         [192.437],
         [156.493],
         [183.541],
         [158.296],
         [178.747]],

        [[202.387],
         [174.308],
         [187.235],
         [166.286],
         [181.662],
         [185.036],
         [183.847],
         [158.156],
         [175.104],
         [188.521]],

        [[174.742],
         [158.040],
         [158.837],
         [193.783],
         [169.176],
         [171.593],
         [168.046],
         [175.093],
         [173.424],
         [160.405]],

        [[185.839],
         [168.758],
         [183.491],
         [170.625],
         [168.938],
         [185.017],
         [181.271],
         [159.697],
         [174.501],
         [178.233]],

        [[135.696],
         [161.249],
         [169.933],
         [170.030],
         [149.067],
         [160.354],
         [168.956],
         [164.963],
         [193.051],
         [171.904]],

        [[149.616],
         [175.807],
         [133.268],
         [183.678],
         [167.993],
         [146.183],
         [182.458],
         [184.753],
         [148.367],
         [164.541]],

        [[163.973],
         [168.835],
         [169.270],
         [163.099],
         [155.034],
         [179.001],
         [188.314],
         [177.921],
         [157.509],
         [154.956]],

        [[188.661],
         [185.857],
         [179.841],
         [176.805],
         [178.905],
         [170.098],
         [113.950],
         [170.222],
         [136.358],
         [174.670]],

        [[165.264],
         [176.623],
         [171.314],
         [195.118],
         [164.650],
         [155.458],
         [182.309],
         [183.994],
         [182.189],
         [165.244]],

        [[161.894],
         [178.711],
         [180.872],
         [169.611],
         [174.114],
         [181.106],
         [172.351],
         [176.876],
         [182.275],
         [149.137]],

        [[166.038],
         [161.554],
         [183.691],
         [151.762],
         [175.653],
         [175.035],
         [175.882],
         [179.514],
         [209.556],
         [165.503]],

        [[180.257],
         [186.931],
         [169.077],
         [189.214],
         [178.132],
         [161.943],
         [157.338],
         [197.407],
         [183.836],
         [111.564]]], device='cuda:0')
clipping threshold 0.18546934573626117
a after update for 1 param tensor([[-0.129],
        [-0.222],
        [-0.012],
        [-0.014],
        [-0.006],
        [-0.364],
        [-0.020],
        [-0.259],
        [-0.336],
        [ 0.138],
        [ 0.067],
        [-0.060],
        [ 0.219],
        [ 0.105],
        [-0.242],
        [-0.009],
        [-0.252],
        [-0.084],
        [-0.147],
        [-0.038],
        [-0.214],
        [-0.044],
        [ 0.072],
        [-0.054],
        [ 0.317],
        [-0.078],
        [ 0.239],
        [-0.247],
        [ 0.011],
        [-0.224]], device='cuda:0')
s after update for 1 param tensor([[1.805],
        [1.852],
        [1.266],
        [2.219],
        [1.936],
        [1.916],
        [1.594],
        [2.152],
        [2.132],
        [1.290],
        [1.948],
        [1.597],
        [1.246],
        [1.558],
        [1.514],
        [1.942],
        [2.111],
        [1.294],
        [1.867],
        [1.569],
        [1.688],
        [1.667],
        [1.258],
        [2.355],
        [2.133],
        [1.378],
        [1.935],
        [1.431],
        [1.449],
        [1.977]], device='cuda:0')
b after update for 1 param tensor([[175.242],
        [177.547],
        [146.758],
        [194.336],
        [181.516],
        [180.569],
        [164.698],
        [191.348],
        [190.482],
        [148.146],
        [182.064],
        [164.829],
        [145.619],
        [162.810],
        [160.508],
        [181.811],
        [189.543],
        [148.389],
        [178.244],
        [163.400],
        [169.482],
        [168.446],
        [146.327],
        [200.185],
        [190.520],
        [153.138],
        [181.481],
        [156.038],
        [157.002],
        [183.430]], device='cuda:0')
clipping threshold 0.18546934573626117
||w||^2 0.07717933556531399
exp ma of ||w||^2 0.058024006338124476
||w|| 0.2778116908362821
exp ma of ||w|| 0.23749627647774998
||w||^2 0.053753446542587076
exp ma of ||w||^2 0.052801433776374536
||w|| 0.2318478952731447
exp ma of ||w|| 0.22490135144859638
||w||^2 0.08031869477633045
exp ma of ||w||^2 0.05498607372053893
||w|| 0.28340553060293383
exp ma of ||w|| 0.22943630548469754
||w||^2 0.04254892127728431
exp ma of ||w||^2 0.05628988526213226
||w|| 0.20627389868154505
exp ma of ||w|| 0.23279951738002597
||w||^2 0.042828845436397776
exp ma of ||w||^2 0.05197963171569043
||w|| 0.20695131175326667
exp ma of ||w|| 0.22342183255588804
||w||^2 0.058832472024934024
exp ma of ||w||^2 0.05163830980974013
||w|| 0.24255406000505128
exp ma of ||w|| 0.2225046376342833
||w||^2 0.04120407621352197
exp ma of ||w||^2 0.05141508061071503
||w|| 0.20298787208481686
exp ma of ||w|| 0.22299260275864707
||w||^2 0.05109967007902219
exp ma of ||w||^2 0.05432855479085305
||w|| 0.22605236136572915
exp ma of ||w|| 0.22952611299141815
cuda
Objective function 29.50 = squared loss an data 27.84 + 0.5*rho*h**2 0.389764 + alpha*h 0.470051 + L2reg 0.58 + L1reg 0.22 ; SHD = 67 ; DAG True
Proportion of microbatches that were clipped  0.7560760407475736
iteration 2 in inner loop, alpha 168.35614704796075 rho 100000.0 h 0.0027920033987172133
iteration 4 in outer loop, alpha = 447.5564869196821, rho = 100000.0, h = 0.0027920033987172133
cuda
9630
cuda
Objective function 30.28 = squared loss an data 27.84 + 0.5*rho*h**2 0.389764 + alpha*h 1.249579 + L2reg 0.58 + L1reg 0.22 ; SHD = 67 ; DAG True
||w||^2 1878480648.334186
exp ma of ||w||^2 1066527828798.3474
||w|| 43341.442619439724
exp ma of ||w|| 486509.51737519563
||w||^2 8846864.466385093
exp ma of ||w||^2 272122063623.19803
||w|| 2974.367910394592
exp ma of ||w|| 135438.13157345293
||w||^2 2048.421655009244
exp ma of ||w||^2 13212005196.360737
||w|| 45.25949242986762
exp ma of ||w|| 6840.311017154117
||w||^2 0.08558306086707904
exp ma of ||w||^2 0.07719898611291803
||w|| 0.2925458269520846
exp ma of ||w|| 0.27557361219429827
||w||^2 0.034912896864063694
exp ma of ||w||^2 0.053431613920851204
||w|| 0.18684993139967618
exp ma of ||w|| 0.22834316590086307
v before min max tensor([[ -4.500,  -8.131,  -8.915,  ...,  91.773,  -8.713,  -1.602],
        [ 12.765,  63.487, -10.207,  ...,   5.424, -11.389, -13.014],
        [-12.845,  -7.195, -14.288,  ..., -11.894,  21.555,   6.250],
        ...,
        [  9.224,  11.315, -10.838,  ...,  -8.362,   3.334, -13.192],
        [-11.332,  -9.286,  -9.832,  ...,  -7.417,   1.082,   9.734],
        [ 13.289,  -9.156, -11.401,  ..., -10.468, -11.256,  53.581]],
       device='cuda:0')
v tensor([[1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e+01, 1.000e-12,
         1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e-12,  ..., 5.424e+00, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         6.250e+00],
        ...,
        [9.224e+00, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 3.334e+00,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.082e+00,
         9.734e+00],
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e+01]], device='cuda:0')
v before min max tensor([-9.378e+00,  1.248e+01, -1.148e+01, -3.724e+00, -8.673e+00, -1.265e+01,
        -1.399e+01, -6.772e+00, -8.779e-01, -2.018e+00, -3.684e+00,  5.755e+01,
        -5.286e-01, -4.959e+00, -8.962e+00, -9.242e+00, -1.019e+01, -3.138e+00,
        -8.142e+00,  4.475e+01, -1.564e+00, -6.380e+00,  3.306e+01,  5.443e+00,
         9.345e+00, -1.144e+01, -7.669e+00, -7.624e-02, -7.650e+00, -8.895e+00,
        -6.064e+00,  2.792e+00,  2.840e+00, -1.161e+01, -1.012e+01, -7.089e+00,
        -2.259e+00, -5.145e+00, -8.028e+00, -2.138e+00, -8.530e+00,  1.360e+01,
        -1.053e+01,  5.895e+01, -4.109e+00, -1.674e+00, -1.028e+01,  1.210e+01,
         1.371e+02, -4.914e+00,  1.756e+01, -3.489e+00,  9.751e-01,  7.065e+01,
        -1.124e+01, -2.166e+00, -7.663e+00, -1.061e+01, -4.490e+00,  6.300e+00,
        -6.192e+00, -4.528e+00,  3.983e+01, -6.484e+00, -4.811e+00,  3.621e+01,
        -6.625e+00, -6.902e+00, -2.696e+00,  9.099e+00,  7.410e-01,  4.821e+00,
        -2.958e+00, -8.698e+00, -1.061e+01, -9.042e+00, -7.607e+00, -1.229e+01,
         1.203e+01,  4.236e+01, -7.822e+00,  2.283e+01,  1.204e+00, -5.431e+00,
        -8.054e+00,  9.181e+00, -7.266e+00,  1.268e+01,  2.631e+01, -1.301e+01,
        -1.131e+01,  3.218e+01, -6.919e+00,  4.839e+01, -7.006e+00, -7.633e+00,
        -1.125e+01, -3.439e+00,  2.435e+01, -5.349e+00, -1.244e+01, -1.026e+01,
        -1.052e+01,  2.313e+00, -1.604e+01, -7.925e+00, -1.237e+01,  7.714e+00,
        -6.387e+00,  3.399e+01,  4.009e-01, -1.328e+01, -7.749e+00,  9.460e-01,
        -2.704e+00, -1.249e+01, -7.785e+00,  3.485e+01, -6.215e+00, -1.269e+01,
         2.935e+01, -5.101e+00,  5.221e-01,  4.934e+01, -1.614e+00,  2.908e+00,
         1.710e+01,  8.125e+00, -6.513e+00, -8.874e+00, -4.805e-01, -1.073e+01,
        -5.224e+00,  1.084e+01,  2.015e+01, -1.060e+01,  1.281e+01, -7.883e+00,
        -1.274e+01,  5.759e+01,  2.311e-01,  4.298e+00, -7.077e+00, -1.165e+01,
        -1.608e+01,  1.092e+02, -5.143e+00, -7.902e+00,  1.434e+01, -7.815e+00,
        -7.054e-01, -1.221e+01, -1.160e+01, -8.328e+00, -1.096e+01,  2.958e+01,
        -2.220e+00,  2.638e+01, -7.337e+00, -8.874e+00, -1.325e+01, -7.984e+00,
        -1.238e+01, -1.638e+01, -5.837e+00, -9.737e+00,  7.329e+00, -5.881e+00,
        -1.078e+01, -7.053e+00, -1.662e+01, -1.241e+00, -9.437e+00, -7.207e+00,
         5.406e+01, -1.112e+01,  6.568e+00,  2.847e+01, -6.363e+00, -7.224e+00,
        -6.671e+00, -4.239e+00, -1.479e-01, -2.673e+00,  1.893e+01, -9.791e+00,
         4.072e+00, -1.270e+01,  3.056e+01, -6.176e+00, -6.892e+00, -6.666e+00,
         7.243e+00,  8.478e+00, -5.631e+00, -2.861e+00, -7.466e+00, -1.009e+01,
        -1.451e+01, -4.484e+00,  2.126e+01, -9.436e+00, -7.436e+00,  2.138e+01,
         8.924e+00,  1.328e+01, -1.470e+00, -1.174e+01, -1.014e+01, -9.455e+00,
        -1.196e+01,  8.062e+00, -1.055e+01, -6.100e+00, -1.360e+01,  5.703e+00,
         2.135e+01, -7.093e+00, -1.054e+01, -1.431e+01, -1.125e+01, -6.025e+00,
        -4.039e+00, -7.390e+00,  1.281e+00,  3.656e+00, -1.453e+01, -6.248e+00,
         2.888e+01, -2.863e+00,  1.901e+01, -5.560e+00, -1.099e+01,  2.465e+00,
        -5.046e+00, -1.585e+01,  1.841e+01, -9.879e+00, -1.149e+01, -9.374e+00,
        -3.016e+00,  5.584e+01, -5.133e+00, -1.500e+01, -4.505e+00,  1.519e+01,
         1.227e+01, -8.865e-01, -1.289e+01, -7.856e+00, -1.138e+01, -3.779e+00,
         3.627e+01, -4.296e+00,  7.217e-01, -9.150e+00,  3.645e+01, -1.003e+01,
         5.651e+00, -4.627e+00,  5.172e-01,  1.045e+01, -9.912e+00, -1.420e+01,
        -1.185e+01, -9.029e+00,  9.458e-02, -1.200e+01,  3.481e+00, -6.089e+00,
        -1.051e+01,  1.209e+01, -6.567e+00,  3.695e+01, -1.438e+01, -1.347e+01,
        -6.539e+00,  1.275e+01, -6.707e+00, -9.896e+00,  1.321e+00,  2.483e+01,
         6.859e+01,  3.114e+01,  9.214e+00,  3.075e+01, -9.405e+00, -6.011e+00,
        -1.223e+01,  6.774e+00, -3.627e+00, -9.530e+00,  3.613e+00, -1.167e+01,
        -1.346e+01,  1.797e+00, -1.574e+01, -1.214e+01, -1.355e+01, -6.022e+00],
       device='cuda:0')
v tensor([1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 5.443e+00,
        9.345e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 2.792e+00, 2.840e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 9.751e-01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 6.300e+00,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 9.099e+00, 7.410e-01, 4.821e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.204e+00, 1.000e-12,
        1.000e-12, 9.181e+00, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 2.313e+00, 1.000e-12, 1.000e-12, 1.000e-12, 7.714e+00,
        1.000e-12, 1.000e+01, 4.009e-01, 1.000e-12, 1.000e-12, 9.460e-01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 5.221e-01, 1.000e+01, 1.000e-12, 2.908e+00,
        1.000e+01, 8.125e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 2.311e-01, 4.298e+00, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 7.329e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 6.568e+00, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        4.072e+00, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        7.243e+00, 8.478e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        8.924e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 8.062e+00, 1.000e-12, 1.000e-12, 1.000e-12, 5.703e+00,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.281e+00, 3.656e+00, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 2.465e+00,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 7.217e-01, 1.000e-12, 1.000e+01, 1.000e-12,
        5.651e+00, 1.000e-12, 5.172e-01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 9.458e-02, 1.000e-12, 3.481e+00, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.321e+00, 1.000e+01,
        1.000e+01, 1.000e+01, 9.214e+00, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 6.774e+00, 1.000e-12, 1.000e-12, 3.613e+00, 1.000e-12,
        1.000e-12, 1.797e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-5.268e+00],
         [-3.911e+00],
         [-5.254e+00],
         [ 1.254e+01],
         [-1.236e+01],
         [-6.001e+00],
         [ 3.506e+01],
         [-5.563e+00],
         [-6.646e-01],
         [-6.639e+00]],

        [[-5.358e+00],
         [ 6.796e+00],
         [-9.275e+00],
         [-6.137e+00],
         [-9.867e+00],
         [ 1.835e+01],
         [-1.218e+01],
         [-8.720e+00],
         [-1.952e+00],
         [ 2.778e+01]],

        [[ 1.166e+01],
         [-8.783e+00],
         [-1.326e+01],
         [-1.144e+01],
         [-9.240e+00],
         [ 3.132e+00],
         [-1.193e+01],
         [-1.483e+01],
         [-9.070e+00],
         [-1.380e+01]],

        [[-6.550e+00],
         [ 1.623e+01],
         [-6.378e+00],
         [-2.380e+00],
         [-6.397e+00],
         [-1.558e+01],
         [-6.444e+00],
         [-5.756e+00],
         [-9.392e+00],
         [ 3.048e+01]],

        [[-4.375e+00],
         [ 1.148e+02],
         [-8.053e+00],
         [ 2.566e+01],
         [-9.545e+00],
         [ 1.525e+01],
         [-8.317e+00],
         [-1.259e+00],
         [ 3.789e+01],
         [-3.739e+00]],

        [[ 3.398e+01],
         [-9.578e+00],
         [-1.339e+01],
         [ 2.111e+01],
         [ 5.513e+01],
         [-1.336e+01],
         [ 1.671e+01],
         [-8.404e+00],
         [-8.918e+00],
         [-1.131e+01]],

        [[ 2.335e+01],
         [ 2.746e+00],
         [-3.200e+00],
         [ 5.689e+00],
         [ 4.360e+01],
         [ 7.017e-01],
         [-3.923e+00],
         [ 5.096e+01],
         [-1.047e+01],
         [-1.088e+01]],

        [[-1.176e+01],
         [ 8.119e+01],
         [-1.173e+01],
         [-9.901e+00],
         [-8.320e+00],
         [ 1.546e+01],
         [ 8.187e+01],
         [ 1.777e+02],
         [-1.022e+01],
         [ 7.215e-01]],

        [[-1.058e+01],
         [-1.935e+00],
         [-7.612e+00],
         [-1.099e+01],
         [ 3.932e+00],
         [-8.940e+00],
         [ 1.134e+01],
         [ 8.953e+00],
         [ 1.737e+01],
         [-9.918e+00]],

        [[ 7.495e+00],
         [-4.332e-01],
         [-1.580e+01],
         [ 2.429e+00],
         [-7.660e+00],
         [-1.102e+01],
         [-1.326e+01],
         [-1.222e+01],
         [-6.131e+00],
         [-6.927e+00]],

        [[-8.186e+00],
         [-1.059e+01],
         [-9.559e+00],
         [-6.885e+00],
         [-4.641e+00],
         [ 4.183e+01],
         [-1.615e+00],
         [-9.065e+00],
         [-3.569e+00],
         [ 4.233e+00]],

        [[ 3.480e+01],
         [-3.676e+00],
         [ 1.317e+00],
         [-7.121e+00],
         [-1.027e+01],
         [-6.927e+00],
         [-1.212e+01],
         [-8.086e+00],
         [-1.042e+01],
         [ 1.507e+01]],

        [[-1.612e+01],
         [-1.211e+01],
         [-7.354e+00],
         [ 1.986e+01],
         [-6.136e+00],
         [-1.251e+01],
         [ 8.781e+01],
         [ 6.245e-01],
         [-8.432e+00],
         [ 6.240e+01]],

        [[-1.156e+01],
         [ 5.502e+01],
         [ 8.142e+00],
         [-5.365e+00],
         [-9.488e+00],
         [-1.141e+01],
         [ 2.510e+01],
         [-1.583e+01],
         [ 2.047e+01],
         [-7.589e+00]],

        [[-1.353e+01],
         [ 2.885e+01],
         [ 1.009e+01],
         [-5.813e+00],
         [-1.636e+01],
         [ 3.196e+00],
         [-1.208e+01],
         [-1.422e+01],
         [-7.101e+00],
         [-1.018e+01]],

        [[-1.045e+01],
         [-2.395e+00],
         [-1.054e+01],
         [ 2.008e+01],
         [ 3.736e+00],
         [ 1.863e+00],
         [ 3.474e+01],
         [-8.561e+00],
         [-1.722e+00],
         [ 5.656e+00]],

        [[-1.118e+01],
         [ 6.669e+01],
         [-9.731e+00],
         [-9.326e+00],
         [-7.712e+00],
         [-1.210e+01],
         [ 4.044e+00],
         [-5.717e+00],
         [ 8.135e+01],
         [-8.859e+00]],

        [[-1.313e+01],
         [-7.871e+00],
         [-5.435e+00],
         [ 4.586e+00],
         [ 8.623e-01],
         [-2.557e+00],
         [-1.099e+01],
         [ 1.354e-01],
         [ 4.599e-01],
         [-7.943e+00]],

        [[ 7.710e+00],
         [-1.362e+01],
         [-3.434e-01],
         [-9.173e+00],
         [-7.368e+00],
         [ 6.549e-01],
         [ 2.145e+01],
         [-8.010e+00],
         [-1.336e+01],
         [-1.007e+01]],

        [[-1.017e+01],
         [ 4.214e+00],
         [-7.861e+00],
         [ 1.199e+01],
         [-1.087e+01],
         [ 2.073e+01],
         [ 7.196e+00],
         [-7.950e+00],
         [-2.172e+00],
         [ 1.521e+01]],

        [[-1.114e+01],
         [ 1.224e+01],
         [ 8.294e+00],
         [-1.008e+01],
         [ 5.076e+01],
         [-8.456e+00],
         [-1.154e+01],
         [-5.279e+00],
         [-1.446e+01],
         [-1.026e+01]],

        [[-3.979e+00],
         [ 2.420e+01],
         [-9.678e+00],
         [ 1.475e+00],
         [ 3.315e+00],
         [-6.003e+00],
         [-1.002e+01],
         [-5.697e+00],
         [-9.114e+00],
         [-8.802e+00]],

        [[-1.275e+01],
         [-9.366e+00],
         [ 1.816e-01],
         [ 3.324e+00],
         [-1.054e+01],
         [-1.096e+01],
         [-8.390e+00],
         [-1.095e+01],
         [ 1.512e+01],
         [-4.524e+00]],

        [[ 5.111e+01],
         [-1.055e+01],
         [-6.101e+00],
         [-4.161e+00],
         [ 1.971e+01],
         [-1.063e+01],
         [-4.522e+00],
         [-1.372e+01],
         [-8.675e-01],
         [ 2.150e+00]],

        [[-4.822e+00],
         [ 6.749e+00],
         [-1.019e+01],
         [-1.384e+01],
         [-1.132e+01],
         [ 1.887e+00],
         [-7.731e-01],
         [-4.086e+00],
         [ 3.666e+01],
         [-5.769e+00]],

        [[ 2.190e+00],
         [-7.480e+00],
         [-6.102e+00],
         [ 7.057e+00],
         [-1.073e+01],
         [-1.314e+01],
         [ 5.059e+00],
         [-1.162e+01],
         [ 6.756e+00],
         [-1.090e+01]],

        [[ 9.107e+00],
         [-9.617e+00],
         [-1.831e+00],
         [-8.348e+00],
         [-9.706e+00],
         [ 4.063e+01],
         [-1.170e+01],
         [-5.452e+00],
         [-1.293e+01],
         [-4.476e+00]],

        [[-1.078e+01],
         [ 1.714e+00],
         [ 8.134e-01],
         [-1.006e+01],
         [-8.946e+00],
         [-1.285e+01],
         [-8.575e+00],
         [-7.380e+00],
         [-1.147e+01],
         [-1.267e+01]],

        [[-4.511e+00],
         [-1.420e+01],
         [-7.051e+00],
         [-1.265e+01],
         [-8.847e+00],
         [ 7.636e+00],
         [-1.682e+01],
         [ 1.507e+01],
         [ 5.955e+01],
         [-1.226e+01]],

        [[ 3.147e+00],
         [-1.292e+01],
         [ 1.838e+01],
         [ 9.839e+00],
         [ 3.745e+00],
         [-1.470e+01],
         [-1.322e+01],
         [-2.636e+00],
         [-1.054e+01],
         [ 8.174e+01]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [6.796e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.132e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [2.746e+00],
         [1.000e-12],
         [5.689e+00],
         [1.000e+01],
         [7.017e-01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [7.215e-01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.932e+00],
         [1.000e-12],
         [1.000e+01],
         [8.953e+00],
         [1.000e+01],
         [1.000e-12]],

        [[7.495e+00],
         [1.000e-12],
         [1.000e-12],
         [2.429e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.233e+00]],

        [[1.000e+01],
         [1.000e-12],
         [1.317e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [6.245e-01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [8.142e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [3.196e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [3.736e+00],
         [1.863e+00],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [5.656e+00]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.044e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.586e+00],
         [8.623e-01],
         [1.000e-12],
         [1.000e-12],
         [1.354e-01],
         [4.599e-01],
         [1.000e-12]],

        [[7.710e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.549e-01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [4.214e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [7.196e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [8.294e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.475e+00],
         [3.315e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.816e-01],
         [3.324e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.150e+00]],

        [[1.000e-12],
         [6.749e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.887e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[2.190e+00],
         [1.000e-12],
         [1.000e-12],
         [7.057e+00],
         [1.000e-12],
         [1.000e-12],
         [5.059e+00],
         [1.000e-12],
         [6.756e+00],
         [1.000e-12]],

        [[9.107e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.714e+00],
         [8.134e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.636e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[3.147e+00],
         [1.000e-12],
         [1.000e+01],
         [9.839e+00],
         [3.745e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]]], device='cuda:0')
v before min max tensor([[  9.181],
        [ -1.421],
        [ 55.002],
        [ 15.794],
        [ -4.829],
        [ -2.646],
        [ -4.829],
        [  2.014],
        [-11.498],
        [ 21.988],
        [-13.496],
        [-11.960],
        [-11.192],
        [ -4.828],
        [ -6.960],
        [ 22.368],
        [  5.263],
        [ -9.231],
        [ -8.707],
        [ 32.400],
        [  4.422],
        [ 48.231],
        [ -3.007],
        [ 53.382],
        [ -9.687],
        [  8.957],
        [ -0.757],
        [-11.203],
        [-11.928],
        [ -5.550]], device='cuda:0')
v tensor([[9.181e+00],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [2.014e+00],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [5.263e+00],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [4.422e+00],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [8.957e+00],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-0.005, -0.070, -0.101,  ..., -0.069,  0.068,  0.017],
        [-0.011,  0.092, -0.119,  ...,  0.009,  0.048, -0.119],
        [-0.016,  0.063, -0.003,  ...,  0.069, -0.012, -0.155],
        ...,
        [ 0.023, -0.174,  0.070,  ..., -0.185,  0.099, -0.005],
        [-0.002, -0.063,  0.077,  ...,  0.033,  0.044, -0.002],
        [ 0.027,  0.088, -0.033,  ..., -0.002,  0.070, -0.002]],
       device='cuda:0')
s after update for 1 param tensor([[2.342, 1.097, 1.172,  ..., 2.237, 1.484, 1.811],
        [2.287, 2.017, 1.942,  ..., 1.406, 1.549, 1.731],
        [2.083, 1.559, 1.826,  ..., 1.520, 1.738, 1.800],
        ...,
        [1.805, 1.832, 1.415,  ..., 1.079, 1.458, 1.960],
        [1.602, 1.845, 1.647,  ..., 1.119, 1.607, 2.446],
        [2.159, 1.299, 1.458,  ..., 1.357, 1.498, 2.485]], device='cuda:0')
b after update for 1 param tensor([[189.770, 129.881, 134.213,  ..., 185.434, 151.066, 166.866],
        [187.533, 176.104, 172.811,  ..., 147.009, 154.337, 163.129],
        [178.954, 154.828, 167.561,  ..., 152.871, 163.470, 166.334],
        ...,
        [166.577, 167.810, 147.482,  ..., 128.776, 149.708, 173.572],
        [156.961, 168.432, 159.123,  ..., 131.139, 157.182, 193.936],
        [182.189, 141.326, 149.700,  ..., 144.424, 151.756, 195.455]],
       device='cuda:0')
clipping threshold 0.19162146033302807
a after update for 1 param tensor([ 0.294, -0.253, -0.127, -0.110,  0.139, -0.010, -0.072, -0.033,  0.069,
        -0.160, -0.176,  0.004, -0.216, -0.016, -0.284, -0.158, -0.116, -0.118,
        -0.149, -0.129, -0.233, -0.202,  0.009, -0.158,  0.050, -0.313,  0.065,
         0.163, -0.312,  0.088,  0.019,  0.108, -0.267, -0.053,  0.089,  0.093,
         0.250,  0.041,  0.212,  0.100, -0.014,  0.077, -0.010, -0.286, -0.145,
        -0.098, -0.038, -0.212,  0.102,  0.350, -0.303, -0.152, -0.014,  0.002,
         0.030, -0.100,  0.180,  0.136, -0.273,  0.103, -0.221, -0.119, -0.022,
        -0.122,  0.053,  0.462, -0.007, -0.331, -0.199,  0.100,  0.047,  0.238,
        -0.221,  0.135, -0.070,  0.170, -0.015, -0.239, -0.187,  0.085, -0.039,
        -0.363,  0.073,  0.390,  0.108,  0.143, -0.134, -0.021,  0.054, -0.031,
         0.027,  0.217,  0.015,  0.239, -0.038, -0.365, -0.002, -0.148,  0.082,
         0.033, -0.043,  0.064,  0.111, -0.313, -0.039,  0.180, -0.014,  0.118,
         0.131, -0.348,  0.249,  0.126, -0.352, -0.089,  0.072,  0.035,  0.179,
        -0.179,  0.032,  0.050, -0.243,  0.129,  0.082,  0.022, -0.033,  0.100,
         0.086, -0.014,  0.074, -0.121,  0.128, -0.417, -0.296,  0.031,  0.131,
         0.138, -0.211,  0.049,  0.038, -0.236, -0.155,  0.022, -0.272,  0.097,
        -0.245, -0.011, -0.013, -0.402, -0.146, -0.006,  0.197, -0.013,  0.206,
         0.026,  0.149, -0.051, -0.267,  0.144,  0.020,  0.132, -0.056, -0.016,
        -0.033, -0.209,  0.196, -0.143,  0.236, -0.166,  0.082, -0.138,  0.391,
         0.057,  0.130, -0.194, -0.076, -0.129,  0.023,  0.082,  0.154, -0.162,
         0.058,  0.202, -0.195, -0.085, -0.046, -0.118, -0.187,  0.214, -0.083,
         0.053, -0.258,  0.107,  0.050,  0.097,  0.136, -0.040, -0.236,  0.071,
         0.241, -0.253,  0.174,  0.101, -0.066,  0.053,  0.009,  0.366, -0.048,
         0.312,  0.002, -0.191, -0.206,  0.100,  0.134,  0.153, -0.009,  0.082,
         0.297, -0.217,  0.143, -0.123,  0.258,  0.105, -0.458, -0.096,  0.145,
         0.079,  0.055,  0.051,  0.264,  0.065,  0.175,  0.159, -0.148, -0.056,
         0.171, -0.100, -0.142,  0.306,  0.029, -0.134, -0.153,  0.222,  0.086,
        -0.221, -0.117, -0.071,  0.065, -0.198,  0.247,  0.028,  0.097,  0.002,
        -0.181,  0.037,  0.209, -0.267, -0.098,  0.336, -0.074,  0.069,  0.371,
         0.244, -0.197,  0.137,  0.018, -0.075, -0.055,  0.104,  0.155, -0.121,
         0.004, -0.217, -0.104, -0.320, -0.141, -0.321,  0.389,  0.281,  0.089,
        -0.013, -0.104, -0.059, -0.089, -0.076,  0.142,  0.070, -0.192, -0.019,
        -0.169,  0.042, -0.113,  0.105,  0.288,  0.176,  0.109, -0.132,  0.176,
        -0.049, -0.252,  0.175], device='cuda:0')
s after update for 1 param tensor([1.200, 1.448, 2.121, 1.599, 1.246, 1.715, 1.800, 1.159, 1.128, 0.891,
        1.282, 1.516, 1.806, 1.289, 2.069, 1.303, 1.301, 1.625, 1.753, 2.024,
        1.673, 1.505, 1.294, 1.538, 1.725, 1.752, 1.298, 1.191, 1.765, 1.141,
        1.392, 1.344, 1.674, 1.542, 1.317, 1.438, 1.494, 0.707, 1.543, 1.582,
        1.415, 1.755, 1.345, 2.266, 1.625, 1.736, 1.398, 1.736, 2.134, 1.585,
        1.784, 1.895, 1.452, 1.705, 1.435, 1.579, 1.423, 1.713, 1.757, 1.681,
        1.855, 1.466, 1.597, 1.874, 1.205, 2.183, 2.138, 1.513, 1.171, 1.265,
        1.461, 1.725, 1.537, 2.155, 1.947, 1.158, 0.983, 1.664, 1.825, 2.053,
        1.200, 1.848, 1.278, 1.702, 1.156, 1.869, 1.737, 1.753, 1.907, 1.661,
        1.541, 1.835, 1.160, 1.888, 1.424, 1.207, 1.701, 1.283, 1.951, 0.864,
        1.641, 1.374, 1.361, 1.507, 2.151, 1.333, 1.697, 1.788, 0.972, 1.926,
        1.616, 1.696, 1.290, 1.606, 1.408, 1.791, 1.757, 1.806, 1.654, 1.792,
        1.976, 1.773, 1.659, 1.760, 1.640, 1.673, 2.302, 1.860, 1.379, 1.253,
        2.083, 1.393, 1.032, 1.346, 1.673, 1.373, 1.666, 1.060, 1.747, 1.884,
        1.346, 1.182, 2.111, 1.522, 2.121, 1.820, 0.819, 1.308, 1.411, 1.023,
        1.479, 1.639, 1.614, 1.657, 1.492, 1.755, 1.576, 2.139, 1.525, 1.170,
        1.796, 1.185, 1.980, 2.097, 1.474, 1.322, 1.236, 0.831, 1.419, 1.028,
        2.137, 0.766, 1.224, 1.332, 1.939, 1.518, 2.088, 1.734, 0.812, 1.047,
        0.923, 1.851, 1.432, 1.560, 1.666, 1.327, 1.601, 1.683, 2.208, 1.901,
        1.591, 0.953, 1.594, 1.502, 1.575, 1.103, 1.493, 1.586, 1.855, 1.599,
        1.425, 1.592, 0.956, 1.781, 1.526, 1.623, 1.358, 1.499, 1.709, 1.378,
        2.000, 1.597, 1.559, 1.131, 1.736, 1.751, 2.054, 1.117, 1.366, 1.830,
        1.764, 0.893, 2.058, 0.960, 2.009, 0.975, 1.884, 1.199, 1.811, 1.587,
        1.933, 1.848, 1.403, 1.715, 1.555, 2.035, 1.917, 1.329, 1.521, 1.197,
        1.698, 1.431, 0.979, 1.920, 1.091, 1.807, 1.872, 1.129, 1.663, 1.016,
        1.462, 1.574, 1.652, 1.024, 1.547, 1.375, 1.648, 1.614, 1.754, 1.789,
        1.819, 1.937, 1.731, 1.840, 1.517, 1.509, 1.154, 1.673, 1.327, 0.986,
        1.615, 1.703, 1.935, 1.824, 1.891, 1.720, 1.672, 1.795, 1.784, 1.468,
        1.291, 2.181, 1.954, 2.123, 1.642, 2.177, 1.264, 0.870, 1.569, 1.450,
        0.861, 1.443, 1.566, 1.490, 1.740, 1.373, 2.014, 1.837, 1.824, 1.346],
       device='cuda:0')
b after update for 1 param tensor([135.828, 149.186, 180.599, 156.813, 138.402, 162.401, 166.340, 133.506,
        131.695, 117.064, 140.392, 152.657, 166.648, 140.783, 178.335, 141.525,
        141.438, 158.060, 164.154, 176.423, 160.384, 152.096, 141.027, 153.787,
        162.868, 164.126, 141.247, 135.306, 164.741, 132.441, 146.318, 143.738,
        160.423, 153.973, 142.291, 148.712, 151.573, 104.278, 154.015, 155.969,
        147.475, 164.284, 143.792, 186.642, 158.054, 163.384, 146.630, 163.360,
        181.146, 156.120, 165.612, 170.683, 149.388, 161.917, 148.556, 155.798,
        147.926, 162.293, 164.365, 160.767, 168.870, 150.151, 156.711, 169.753,
        136.094, 183.210, 181.307, 152.498, 134.154, 139.458, 149.849, 162.855,
        153.733, 182.006, 173.014, 133.410, 122.933, 159.932, 167.508, 177.674,
        135.822, 168.549, 140.183, 161.785, 133.309, 169.514, 163.413, 164.164,
        171.247, 159.827, 153.916, 167.970, 133.565, 170.367, 147.981, 136.248,
        161.719, 140.439, 173.203, 115.230, 158.853, 145.330, 144.641, 152.239,
        181.870, 143.147, 161.517, 165.792, 122.231, 172.093, 157.601, 161.497,
        140.825, 157.143, 147.143, 165.951, 164.361, 166.629, 159.461, 165.984,
        174.320, 165.127, 159.731, 164.479, 158.793, 160.382, 188.125, 169.103,
        145.611, 138.787, 178.948, 146.345, 125.968, 143.861, 160.399, 145.294,
        160.052, 127.635, 163.866, 170.199, 143.858, 134.788, 180.136, 152.972,
        180.603, 167.283, 112.234, 141.809, 147.311, 125.440, 150.786, 158.759,
        157.541, 159.604, 151.462, 164.250, 155.645, 181.333, 153.133, 134.132,
        166.149, 134.982, 174.494, 179.574, 150.548, 142.585, 137.841, 113.007,
        147.705, 125.729, 181.258, 108.500, 137.208, 143.108, 172.645, 152.766,
        179.174, 163.274, 111.756, 126.893, 119.146, 168.679, 148.402, 154.859,
        160.032, 142.844, 156.912, 160.882, 184.240, 170.971, 156.407, 121.025,
        156.556, 151.970, 155.606, 130.208, 151.514, 156.132, 168.881, 156.789,
        147.995, 156.430, 121.238, 165.486, 153.163, 157.959, 144.491, 151.789,
        162.088, 145.541, 175.358, 156.690, 154.842, 131.841, 163.393, 164.054,
        177.693, 131.048, 144.907, 167.753, 164.692, 117.168, 177.887, 121.488,
        175.745, 122.404, 170.203, 135.794, 166.845, 156.191, 172.409, 168.541,
        146.890, 162.359, 154.643, 176.894, 171.690, 142.958, 152.941, 135.651,
        161.583, 148.346, 122.675, 171.829, 129.520, 166.696, 169.669, 131.752,
        159.910, 124.972, 149.926, 155.552, 159.382, 125.486, 154.218, 145.381,
        159.180, 157.505, 164.227, 165.868, 167.229, 172.557, 163.124, 168.188,
        152.728, 152.329, 133.182, 160.369, 142.847, 123.131, 157.600, 161.834,
        172.472, 167.476, 170.489, 162.627, 160.313, 166.115, 165.606, 150.235,
        140.872, 183.133, 173.317, 180.682, 158.880, 182.945, 139.411, 115.684,
        155.334, 149.312, 115.026, 148.932, 155.178, 151.347, 163.572, 145.290,
        175.959, 168.065, 167.441, 143.831], device='cuda:0')
clipping threshold 0.19162146033302807
a after update for 1 param tensor([[[-0.106],
         [ 0.262],
         [ 0.086],
         [ 0.207],
         [-0.064],
         [ 0.006],
         [ 0.160],
         [-0.116],
         [ 0.131],
         [-0.097]],

        [[-0.162],
         [-0.050],
         [ 0.203],
         [ 0.017],
         [ 0.047],
         [ 0.015],
         [ 0.085],
         [-0.048],
         [-0.096],
         [ 0.087]],

        [[ 0.128],
         [ 0.301],
         [-0.089],
         [-0.081],
         [-0.218],
         [-0.031],
         [-0.186],
         [ 0.069],
         [ 0.150],
         [ 0.150]],

        [[-0.339],
         [ 0.418],
         [ 0.120],
         [ 0.139],
         [-0.206],
         [ 0.371],
         [-0.151],
         [-0.372],
         [ 0.192],
         [ 0.259]],

        [[ 0.098],
         [-0.038],
         [-0.078],
         [ 0.077],
         [-0.174],
         [-0.110],
         [-0.075],
         [ 0.178],
         [ 0.028],
         [ 0.213]],

        [[-0.181],
         [ 0.035],
         [ 0.103],
         [-0.042],
         [-0.112],
         [-0.152],
         [ 0.018],
         [ 0.128],
         [-0.171],
         [ 0.112]],

        [[-0.153],
         [-0.133],
         [ 0.141],
         [-0.102],
         [ 0.181],
         [ 0.143],
         [-0.222],
         [ 0.155],
         [ 0.214],
         [-0.166]],

        [[-0.020],
         [-0.100],
         [-0.056],
         [ 0.122],
         [ 0.177],
         [ 0.108],
         [-0.040],
         [-0.254],
         [-0.026],
         [ 0.096]],

        [[-0.046],
         [ 0.077],
         [ 0.025],
         [-0.185],
         [-0.018],
         [ 0.057],
         [-0.166],
         [-0.266],
         [ 0.116],
         [-0.163]],

        [[ 0.057],
         [ 0.055],
         [ 0.019],
         [-0.098],
         [-0.002],
         [ 0.062],
         [-0.131],
         [-0.049],
         [-0.042],
         [-0.083]],

        [[-0.115],
         [-0.172],
         [ 0.039],
         [-0.123],
         [-0.022],
         [ 0.148],
         [ 0.027],
         [ 0.001],
         [ 0.016],
         [ 0.119]],

        [[-0.011],
         [ 0.099],
         [ 0.149],
         [ 0.181],
         [ 0.188],
         [-0.442],
         [-0.259],
         [-0.012],
         [ 0.209],
         [ 0.088]],

        [[-0.103],
         [ 0.140],
         [-0.124],
         [-0.269],
         [ 0.147],
         [ 0.076],
         [-0.022],
         [-0.072],
         [ 0.075],
         [-0.297]],

        [[-0.308],
         [-0.020],
         [-0.102],
         [ 0.137],
         [ 0.141],
         [-0.049],
         [ 0.013],
         [ 0.202],
         [-0.277],
         [-0.158]],

        [[-0.204],
         [-0.011],
         [-0.163],
         [ 0.247],
         [ 0.158],
         [ 0.024],
         [ 0.245],
         [-0.086],
         [ 0.051],
         [-0.173]],

        [[ 0.219],
         [ 0.191],
         [ 0.055],
         [-0.034],
         [ 0.085],
         [-0.117],
         [-0.064],
         [ 0.154],
         [-0.215],
         [-0.072]],

        [[-0.173],
         [-0.406],
         [-0.041],
         [ 0.059],
         [-0.067],
         [-0.333],
         [ 0.135],
         [ 0.164],
         [ 0.074],
         [-0.088]],

        [[-0.056],
         [-0.265],
         [ 0.086],
         [ 0.112],
         [ 0.180],
         [ 0.162],
         [-0.285],
         [ 0.030],
         [ 0.039],
         [ 0.205]],

        [[ 0.053],
         [-0.075],
         [ 0.194],
         [-0.096],
         [-0.195],
         [-0.177],
         [ 0.136],
         [ 0.122],
         [-0.023],
         [ 0.093]],

        [[ 0.204],
         [-0.094],
         [-0.064],
         [-0.111],
         [-0.082],
         [-0.208],
         [-0.121],
         [-0.143],
         [ 0.033],
         [-0.191]],

        [[ 0.070],
         [ 0.231],
         [-0.245],
         [-0.089],
         [-0.016],
         [-0.033],
         [-0.044],
         [ 0.288],
         [ 0.228],
         [-0.288]],

        [[-0.207],
         [ 0.020],
         [ 0.108],
         [-0.001],
         [-0.155],
         [ 0.079],
         [ 0.092],
         [ 0.045],
         [-0.066],
         [ 0.059]],

        [[-0.207],
         [-0.052],
         [ 0.098],
         [-0.082],
         [ 0.231],
         [-0.104],
         [-0.010],
         [-0.072],
         [ 0.016],
         [ 0.034]],

        [[ 0.026],
         [-0.090],
         [ 0.094],
         [-0.202],
         [ 0.146],
         [-0.315],
         [ 0.146],
         [ 0.088],
         [ 0.084],
         [ 0.245]],

        [[ 0.197],
         [-0.235],
         [ 0.101],
         [-0.269],
         [ 0.076],
         [-0.145],
         [-0.291],
         [-0.042],
         [-0.225],
         [-0.272]],

        [[ 0.001],
         [ 0.027],
         [ 0.004],
         [-0.202],
         [-0.171],
         [ 0.169],
         [-0.074],
         [ 0.040],
         [-0.230],
         [ 0.196]],

        [[-0.102],
         [-0.148],
         [-0.060],
         [ 0.045],
         [ 0.122],
         [ 0.053],
         [ 0.029],
         [-0.081],
         [-0.165],
         [-0.111]],

        [[ 0.092],
         [ 0.003],
         [ 0.034],
         [-0.050],
         [-0.048],
         [ 0.502],
         [ 0.137],
         [-0.005],
         [-0.186],
         [-0.040]],

        [[ 0.018],
         [-0.385],
         [ 0.021],
         [-0.111],
         [-0.018],
         [-0.079],
         [ 0.031],
         [ 0.287],
         [ 0.284],
         [ 0.292]],

        [[-0.233],
         [ 0.100],
         [ 0.166],
         [ 0.219],
         [-0.103],
         [ 0.151],
         [-0.102],
         [ 0.248],
         [ 0.201],
         [ 0.047]]], device='cuda:0')
s after update for 1 param tensor([[[0.983],
         [1.068],
         [1.444],
         [1.575],
         [1.578],
         [1.680],
         [2.115],
         [1.208],
         [1.749],
         [1.217]],

        [[1.004],
         [1.328],
         [1.334],
         [0.788],
         [1.736],
         [1.516],
         [1.566],
         [1.538],
         [1.326],
         [2.037]],

        [[1.459],
         [1.540],
         [1.724],
         [1.923],
         [1.284],
         [1.322],
         [1.825],
         [1.897],
         [1.206],
         [1.767]],

        [[1.031],
         [2.030],
         [1.204],
         [1.630],
         [1.464],
         [2.001],
         [1.512],
         [1.481],
         [1.564],
         [2.320]],

        [[1.408],
         [1.718],
         [1.455],
         [1.725],
         [1.254],
         [2.117],
         [1.232],
         [1.631],
         [1.934],
         [1.521]],

        [[1.864],
         [1.460],
         [1.919],
         [1.750],
         [1.892],
         [1.768],
         [1.692],
         [1.089],
         [1.438],
         [1.476]],

        [[1.838],
         [1.287],
         [0.767],
         [1.652],
         [1.708],
         [1.264],
         [1.476],
         [1.686],
         [1.578],
         [1.426]],

        [[1.549],
         [2.043],
         [1.615],
         [2.053],
         [1.098],
         [2.226],
         [1.912],
         [2.298],
         [1.558],
         [1.103]],

        [[1.541],
         [0.902],
         [1.380],
         [1.798],
         [1.160],
         [1.241],
         [1.861],
         [1.940],
         [1.816],
         [1.281]],

        [[1.864],
         [0.914],
         [2.057],
         [1.843],
         [1.024],
         [1.604],
         [1.712],
         [1.562],
         [1.563],
         [1.638]],

        [[1.388],
         [1.858],
         [1.244],
         [1.340],
         [1.352],
         [1.471],
         [1.358],
         [1.472],
         [1.424],
         [1.928]],

        [[2.305],
         [1.504],
         [1.035],
         [1.205],
         [1.475],
         [1.505],
         [1.993],
         [1.033],
         [1.387],
         [1.714]],

        [[2.058],
         [1.569],
         [1.662],
         [1.705],
         [1.801],
         [1.647],
         [1.848],
         [1.649],
         [1.553],
         [1.621]],

        [[1.506],
         [1.806],
         [1.519],
         [1.860],
         [1.224],
         [1.461],
         [1.742],
         [2.025],
         [1.963],
         [1.606]],

        [[1.856],
         [2.162],
         [2.065],
         [1.112],
         [2.145],
         [1.673],
         [1.543],
         [1.872],
         [1.199],
         [1.690]],

        [[1.346],
         [1.532],
         [1.383],
         [1.316],
         [1.757],
         [1.449],
         [1.430],
         [1.933],
         [0.791],
         [1.441]],

        [[1.430],
         [1.910],
         [1.244],
         [1.235],
         [1.083],
         [2.183],
         [1.373],
         [0.797],
         [2.477],
         [1.220]],

        [[1.860],
         [1.897],
         [1.806],
         [1.762],
         [0.827],
         [1.233],
         [1.459],
         [1.564],
         [1.671],
         [1.583]],

        [[1.626],
         [1.739],
         [1.723],
         [1.562],
         [1.506],
         [1.582],
         [2.058],
         [1.093],
         [1.829],
         [1.389]],

        [[1.332],
         [1.557],
         [1.093],
         [1.660],
         [1.414],
         [2.001],
         [1.700],
         [1.016],
         [1.634],
         [2.074]],

        [[1.810],
         [2.098],
         [1.588],
         [1.363],
         [2.188],
         [1.339],
         [1.475],
         [1.814],
         [1.878],
         [1.469]],

        [[1.934],
         [1.737],
         [1.280],
         [1.551],
         [1.562],
         [1.882],
         [1.312],
         [1.508],
         [1.297],
         [1.440]],

        [[1.643],
         [1.751],
         [1.471],
         [1.864],
         [1.800],
         [1.566],
         [1.640],
         [1.399],
         [2.325],
         [1.950]],

        [[1.903],
         [1.354],
         [1.384],
         [1.589],
         [1.967],
         [1.395],
         [1.492],
         [1.752],
         [1.633],
         [1.340]],

        [[1.815],
         [1.927],
         [1.494],
         [1.795],
         [1.710],
         [1.291],
         [1.541],
         [1.215],
         [1.816],
         [1.804]],

        [[1.620],
         [1.054],
         [1.989],
         [2.177],
         [1.874],
         [1.688],
         [1.913],
         [1.740],
         [1.795],
         [1.471]],

        [[2.017],
         [1.529],
         [1.050],
         [1.193],
         [1.453],
         [2.341],
         [1.972],
         [1.166],
         [1.658],
         [1.144]],

        [[1.376],
         [1.466],
         [1.032],
         [1.865],
         [1.148],
         [1.933],
         [1.123],
         [1.262],
         [1.479],
         [1.836]],

        [[0.720],
         [1.820],
         [1.027],
         [1.743],
         [1.610],
         [1.458],
         [2.149],
         [2.028],
         [2.103],
         [1.574]],

        [[1.558],
         [1.691],
         [1.446],
         [1.765],
         [1.828],
         [1.891],
         [1.695],
         [1.389],
         [1.686],
         [2.213]]], device='cuda:0')
b after update for 1 param tensor([[[122.942],
         [128.137],
         [149.019],
         [155.628],
         [155.755],
         [160.726],
         [180.334],
         [136.286],
         [163.974],
         [136.788]],

        [[124.263],
         [142.872],
         [143.189],
         [110.077],
         [163.382],
         [152.682],
         [155.172],
         [153.762],
         [142.778],
         [176.974]],

        [[149.756],
         [153.891],
         [162.815],
         [171.960],
         [140.512],
         [142.556],
         [167.494],
         [170.786],
         [136.173],
         [164.807]],

        [[125.884],
         [176.659],
         [136.068],
         [158.286],
         [150.008],
         [175.395],
         [152.462],
         [150.902],
         [155.090],
         [188.856]],

        [[147.122],
         [162.516],
         [149.566],
         [162.845],
         [138.869],
         [180.395],
         [137.640],
         [158.369],
         [172.416],
         [152.939]],

        [[169.285],
         [149.825],
         [171.779],
         [164.014],
         [170.545],
         [164.894],
         [161.294],
         [129.393],
         [148.700],
         [150.665]],

        [[168.082],
         [140.653],
         [108.577],
         [159.360],
         [162.048],
         [139.410],
         [150.628],
         [161.020],
         [155.759],
         [148.058]],

        [[154.332],
         [177.227],
         [157.583],
         [177.649],
         [129.943],
         [184.979],
         [171.465],
         [187.983],
         [154.779],
         [130.233]],

        [[153.933],
         [117.779],
         [145.680],
         [166.247],
         [133.532],
         [138.147],
         [169.146],
         [172.685],
         [167.096],
         [140.347]],

        [[169.285],
         [118.562],
         [177.844],
         [168.349],
         [125.469],
         [157.027],
         [162.244],
         [154.965],
         [155.015],
         [158.697]],

        [[146.076],
         [169.030],
         [138.324],
         [143.551],
         [144.200],
         [150.409],
         [144.513],
         [150.416],
         [147.977],
         [172.174]],

        [[188.271],
         [152.088],
         [126.174],
         [136.118],
         [150.612],
         [152.120],
         [175.037],
         [126.015],
         [146.034],
         [162.344]],

        [[177.899],
         [155.297],
         [159.871],
         [161.904],
         [166.391],
         [159.121],
         [168.571],
         [159.249],
         [154.499],
         [157.853]],

        [[152.165],
         [166.629],
         [152.828],
         [169.087],
         [137.184],
         [149.887],
         [163.636],
         [176.447],
         [173.735],
         [157.125]],

        [[168.918],
         [182.336],
         [178.168],
         [130.744],
         [181.593],
         [160.359],
         [154.048],
         [169.633],
         [135.760],
         [161.183]],

        [[143.841],
         [153.467],
         [145.794],
         [142.266],
         [164.348],
         [149.280],
         [148.276],
         [172.401],
         [110.255],
         [148.833]],

        [[148.275],
         [171.375],
         [138.276],
         [137.794],
         [129.008],
         [183.190],
         [145.293],
         [110.702],
         [195.155],
         [136.970]],

        [[169.125],
         [170.768],
         [166.642],
         [164.574],
         [112.762],
         [137.706],
         [149.769],
         [155.093],
         [160.291],
         [156.000]],

        [[158.091],
         [163.498],
         [162.754],
         [154.981],
         [152.156],
         [155.937],
         [177.896],
         [129.626],
         [167.672],
         [146.121]],

        [[143.123],
         [154.704],
         [129.648],
         [159.742],
         [147.430],
         [175.399],
         [161.684],
         [124.980],
         [158.477],
         [178.565]],

        [[166.809],
         [179.602],
         [156.273],
         [144.772],
         [183.397],
         [143.489],
         [150.607],
         [167.024],
         [169.907],
         [150.307]],

        [[172.446],
         [163.410],
         [140.278],
         [154.414],
         [154.974],
         [170.114],
         [142.007],
         [152.281],
         [141.235],
         [148.817]],

        [[158.918],
         [164.081],
         [150.373],
         [169.286],
         [166.372],
         [155.190],
         [158.768],
         [146.636],
         [189.068],
         [173.153]],

        [[171.060],
         [144.280],
         [145.882],
         [156.327],
         [173.917],
         [146.459],
         [151.471],
         [164.136],
         [158.459],
         [143.515]],

        [[167.069],
         [172.141],
         [151.543],
         [166.130],
         [162.126],
         [140.898],
         [153.901],
         [136.689],
         [167.078],
         [166.521]],

        [[157.840],
         [127.294],
         [174.871],
         [182.931],
         [169.736],
         [161.103],
         [171.479],
         [163.549],
         [166.122],
         [150.389]],

        [[176.089],
         [153.327],
         [127.030],
         [135.410],
         [149.477],
         [189.736],
         [174.130],
         [133.866],
         [159.652],
         [132.595]],

        [[145.455],
         [150.116],
         [125.982],
         [169.336],
         [132.855],
         [172.412],
         [131.410],
         [139.301],
         [150.802],
         [168.029]],

        [[105.213],
         [167.281],
         [125.653],
         [163.692],
         [157.333],
         [149.726],
         [181.790],
         [176.569],
         [179.831],
         [155.574]],

        [[154.780],
         [161.228],
         [149.088],
         [164.751],
         [167.658],
         [170.526],
         [161.435],
         [146.158],
         [160.987],
         [184.444]]], device='cuda:0')
clipping threshold 0.19162146033302807
a after update for 1 param tensor([[-0.215],
        [-0.110],
        [ 0.114],
        [ 0.355],
        [-0.058],
        [ 0.092],
        [ 0.121],
        [ 0.014],
        [ 0.025],
        [-0.195],
        [ 0.015],
        [-0.288],
        [-0.042],
        [-0.075],
        [-0.205],
        [ 0.059],
        [ 0.071],
        [-0.121],
        [-0.009],
        [ 0.008],
        [-0.035],
        [ 0.002],
        [-0.072],
        [-0.147],
        [ 0.056],
        [-0.099],
        [ 0.086],
        [-0.014],
        [ 0.074],
        [ 0.060]], device='cuda:0')
s after update for 1 param tensor([[1.719],
        [1.286],
        [1.748],
        [1.747],
        [1.526],
        [1.621],
        [1.359],
        [1.306],
        [1.722],
        [1.854],
        [1.742],
        [1.576],
        [1.501],
        [1.604],
        [1.486],
        [1.913],
        [1.309],
        [1.530],
        [1.468],
        [2.405],
        [1.530],
        [1.624],
        [1.682],
        [1.938],
        [1.806],
        [2.008],
        [1.940],
        [1.544],
        [1.702],
        [1.318]], device='cuda:0')
b after update for 1 param tensor([[162.591],
        [140.627],
        [163.948],
        [163.883],
        [153.171],
        [157.879],
        [144.540],
        [141.720],
        [162.710],
        [168.825],
        [163.667],
        [155.656],
        [151.906],
        [157.019],
        [151.171],
        [171.511],
        [141.869],
        [153.352],
        [150.213],
        [192.286],
        [153.391],
        [158.027],
        [160.816],
        [172.597],
        [166.636],
        [175.695],
        [172.723],
        [154.078],
        [161.771],
        [142.333]], device='cuda:0')
clipping threshold 0.19162146033302807
||w||^2 0.06343789978973306
exp ma of ||w||^2 0.053263329312130625
||w|| 0.2518688146431254
exp ma of ||w|| 0.22704838421508386
||w||^2 0.047353292476238235
exp ma of ||w||^2 0.05319294693167361
||w|| 0.21760811675173847
exp ma of ||w|| 0.226905540648467
||w||^2 0.04850256739518451
exp ma of ||w||^2 0.0561038206814279
||w|| 0.220232984348813
exp ma of ||w|| 0.23277569810715837
||w||^2 0.054730346313604926
exp ma of ||w||^2 0.051192624460766514
||w|| 0.23394517800887651
exp ma of ||w|| 0.2223684661026949
||w||^2 0.060944606206730645
exp ma of ||w||^2 0.05170719914258951
||w|| 0.24686961377765926
exp ma of ||w|| 0.22376866110482393
||w||^2 0.028215204235264156
exp ma of ||w||^2 0.05250720006164079
||w|| 0.1679738200889179
exp ma of ||w|| 0.2247331967367454
||w||^2 0.05056358129197449
exp ma of ||w||^2 0.05378933917358485
||w|| 0.22486347256051725
exp ma of ||w|| 0.22842154897081293
||w||^2 0.02879696051304126
exp ma of ||w||^2 0.05446797078562101
||w|| 0.16969667207414899
exp ma of ||w|| 0.2289605733899722
||w||^2 0.030511480562893736
exp ma of ||w||^2 0.05714963577707466
||w|| 0.1746753576292138
exp ma of ||w|| 0.23491824409001463
cuda
Objective function 29.86 = squared loss an data 27.90 + 0.5*rho*h**2 0.220736 + alpha*h 0.940371 + L2reg 0.59 + L1reg 0.21 ; SHD = 63 ; DAG True
Proportion of microbatches that were clipped  0.7597944765574823
iteration 1 in inner loop, alpha 447.5564869196821 rho 100000.0 h 0.002101121545834417
iteration 5 in outer loop, alpha = 2548.6780327540987, rho = 1000000.0, h = 0.002101121545834417
Threshold 0.3
[[0.002 0.09  0.042 0.131 0.037 0.187 0.103 0.03  0.122 0.034 0.106 0.039
  0.163 0.015 0.075 0.057 0.095 0.183 0.159 0.072 0.013 0.01  0.123 0.019
  0.016 0.012 0.192 0.026 0.127 0.01 ]
 [0.023 0.001 0.088 0.165 0.048 0.109 0.271 0.066 0.059 0.013 0.079 0.007
  0.111 0.012 0.1   0.03  0.166 0.111 0.158 0.206 0.016 0.009 0.167 0.057
  0.017 0.01  0.188 0.014 0.257 0.113]
 [0.047 0.017 0.001 0.049 0.012 0.024 0.022 0.004 0.065 0.014 0.039 0.003
  0.048 0.018 0.011 0.019 0.055 0.085 0.051 0.036 0.007 0.007 0.147 0.011
  0.013 0.008 0.204 0.013 0.06  0.017]
 [0.016 0.009 0.061 0.002 0.034 0.027 0.023 0.003 0.016 0.007 0.015 0.022
  0.015 0.025 0.018 0.01  0.104 0.152 0.111 0.034 0.007 0.003 0.021 0.016
  0.01  0.003 0.167 0.007 0.075 0.008]
 [0.069 0.03  0.182 0.06  0.001 0.048 0.032 0.017 0.136 0.032 0.043 0.023
  0.058 0.039 0.17  0.039 0.11  0.542 0.271 0.163 0.061 0.01  0.204 0.036
  0.032 0.019 0.25  0.015 0.131 0.081]
 [0.01  0.027 0.063 0.102 0.052 0.001 0.148 0.009 0.156 0.003 0.044 0.006
  0.013 0.014 0.029 0.021 0.034 0.13  0.137 0.264 0.01  0.016 0.264 0.011
  0.024 0.01  0.2   0.007 0.212 0.033]
 [0.015 0.009 0.073 0.103 0.056 0.014 0.001 0.019 0.083 0.007 0.12  0.022
  0.107 0.02  0.052 0.012 0.09  0.07  0.03  0.061 0.008 0.012 0.155 0.011
  0.009 0.008 0.212 0.018 0.2   0.008]
 [0.078 0.018 0.405 0.596 0.146 0.213 0.147 0.002 0.103 0.089 0.072 0.038
  0.043 0.035 0.141 0.082 0.112 0.321 0.14  0.134 0.021 0.057 0.23  0.019
  0.052 0.004 0.206 0.019 0.078 0.101]
 [0.014 0.039 0.037 0.099 0.016 0.012 0.033 0.016 0.003 0.007 0.034 0.013
  0.007 0.016 0.03  0.007 0.101 0.076 0.14  0.064 0.003 0.011 0.157 0.019
  0.006 0.004 0.043 0.02  0.159 0.014]
 [0.054 0.184 0.106 0.255 0.062 0.53  0.241 0.024 0.328 0.002 0.116 0.127
  0.063 0.223 0.209 0.022 0.285 0.248 0.268 0.242 0.055 0.032 0.262 0.183
  0.062 0.019 0.455 0.022 0.217 0.037]
 [0.016 0.031 0.059 0.149 0.032 0.051 0.012 0.029 0.063 0.009 0.002 0.014
  0.031 0.008 0.083 0.015 0.152 0.069 0.129 0.156 0.006 0.008 0.129 0.012
  0.022 0.004 0.065 0.004 0.228 0.046]
 [0.065 0.225 0.433 0.098 0.069 0.227 0.112 0.044 0.136 0.012 0.138 0.001
  0.199 0.025 0.074 0.024 0.159 0.194 0.191 0.114 0.041 0.02  0.101 0.062
  0.02  0.008 0.384 0.03  0.178 0.126]
 [0.022 0.019 0.038 0.113 0.047 0.172 0.009 0.065 0.203 0.023 0.069 0.011
  0.002 0.015 0.062 0.011 0.107 0.18  0.081 0.104 0.013 0.012 0.058 0.023
  0.019 0.013 0.163 0.008 0.063 0.018]
 [0.162 0.209 0.125 0.074 0.053 0.121 0.07  0.045 0.172 0.011 0.261 0.063
  0.111 0.002 0.128 0.052 0.146 0.564 0.237 0.38  0.037 0.011 0.185 0.09
  0.106 0.008 0.207 0.031 0.079 0.1  ]
 [0.025 0.022 0.145 0.126 0.013 0.083 0.052 0.017 0.077 0.009 0.023 0.018
  0.04  0.015 0.002 0.034 0.032 0.149 0.085 0.043 0.015 0.011 0.16  0.013
  0.023 0.001 0.103 0.013 0.079 0.021]
 [0.046 0.076 0.138 0.195 0.062 0.166 0.216 0.025 0.26  0.047 0.137 0.077
  0.2   0.05  0.06  0.002 0.31  0.089 0.169 0.163 0.014 0.019 0.427 0.031
  0.027 0.024 0.519 0.04  0.302 0.094]
 [0.027 0.01  0.037 0.03  0.024 0.051 0.022 0.018 0.018 0.006 0.009 0.011
  0.017 0.015 0.058 0.008 0.001 0.098 0.147 0.058 0.006 0.007 0.129 0.01
  0.007 0.01  0.061 0.008 0.073 0.014]
 [0.011 0.023 0.02  0.009 0.004 0.011 0.023 0.006 0.037 0.012 0.032 0.011
  0.011 0.003 0.012 0.021 0.027 0.002 0.069 0.053 0.006 0.005 0.098 0.022
  0.014 0.001 0.177 0.004 0.106 0.011]
 [0.012 0.009 0.049 0.024 0.01  0.012 0.064 0.011 0.017 0.005 0.016 0.011
  0.022 0.007 0.017 0.006 0.016 0.031 0.002 0.044 0.004 0.007 0.096 0.004
  0.01  0.004 0.019 0.007 0.068 0.004]
 [0.029 0.014 0.065 0.048 0.014 0.006 0.032 0.008 0.064 0.004 0.011 0.015
  0.02  0.005 0.046 0.013 0.031 0.044 0.048 0.001 0.009 0.004 0.195 0.008
  0.015 0.009 0.029 0.006 0.145 0.016]
 [0.142 0.154 0.312 0.354 0.037 0.213 0.184 0.11  0.643 0.054 0.257 0.065
  0.134 0.059 0.214 0.125 0.307 0.322 0.47  0.192 0.001 0.045 0.18  0.159
  0.028 0.017 0.132 0.077 0.584 0.125]
 [0.193 0.245 0.254 0.534 0.192 0.106 0.117 0.033 0.195 0.055 0.237 0.122
  0.151 0.137 0.178 0.118 0.293 0.408 0.266 0.35  0.035 0.002 0.237 0.064
  0.073 0.02  0.278 0.014 0.18  0.083]
 [0.014 0.011 0.009 0.099 0.006 0.008 0.021 0.006 0.016 0.006 0.017 0.011
  0.027 0.006 0.007 0.005 0.019 0.02  0.026 0.012 0.007 0.005 0.002 0.001
  0.012 0.003 0.193 0.006 0.026 0.012]
 [0.086 0.033 0.193 0.176 0.076 0.192 0.141 0.086 0.124 0.01  0.13  0.042
  0.096 0.017 0.188 0.052 0.199 0.107 0.569 0.216 0.016 0.037 0.722 0.002
  0.025 0.002 0.3   0.021 0.212 0.073]
 [0.142 0.104 0.249 0.203 0.088 0.06  0.287 0.035 0.371 0.022 0.114 0.096
  0.167 0.024 0.083 0.065 0.183 0.155 0.194 0.104 0.064 0.03  0.225 0.081
  0.001 0.044 0.198 0.075 0.137 0.151]
 [0.141 0.227 0.32  0.405 0.107 0.218 0.187 0.497 0.202 0.065 0.442 0.22
  0.161 0.172 0.836 0.085 0.308 0.789 0.365 0.261 0.123 0.077 0.498 0.639
  0.048 0.002 0.334 0.028 0.488 0.237]
 [0.015 0.013 0.009 0.019 0.008 0.015 0.012 0.011 0.026 0.005 0.035 0.002
  0.013 0.013 0.016 0.003 0.037 0.019 0.064 0.045 0.01  0.007 0.018 0.006
  0.011 0.006 0.003 0.003 0.013 0.007]
 [0.098 0.205 0.169 0.269 0.154 0.203 0.119 0.17  0.112 0.103 0.648 0.094
  0.156 0.079 0.168 0.062 0.283 0.252 0.193 0.334 0.033 0.148 0.365 0.086
  0.028 0.103 0.486 0.001 0.121 0.147]
 [0.016 0.008 0.026 0.021 0.011 0.017 0.01  0.018 0.013 0.012 0.01  0.013
  0.027 0.019 0.017 0.005 0.029 0.016 0.027 0.013 0.003 0.013 0.098 0.01
  0.023 0.004 0.11  0.014 0.002 0.029]
 [0.185 0.026 0.114 0.171 0.033 0.083 0.199 0.023 0.134 0.035 0.034 0.016
  0.112 0.014 0.102 0.017 0.168 0.204 0.318 0.11  0.023 0.038 0.195 0.035
  0.009 0.007 0.373 0.015 0.055 0.002]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.542 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.405 0.596 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.321 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.53  0.    0.    0.328 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.455 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.433 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.384 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.564 0.    0.38  0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.31  0.    0.    0.    0.    0.    0.427 0.
  0.    0.    0.519 0.    0.302 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.312 0.354 0.    0.    0.    0.    0.643 0.    0.    0.
  0.    0.    0.    0.    0.307 0.322 0.47  0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.584 0.   ]
 [0.    0.    0.    0.534 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.408 0.    0.35  0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.569 0.    0.    0.    0.722 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.371 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.32  0.405 0.    0.    0.    0.497 0.    0.    0.442 0.
  0.    0.    0.836 0.    0.308 0.789 0.365 0.    0.    0.    0.498 0.639
  0.    0.    0.334 0.    0.488 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.648 0.
  0.    0.    0.    0.    0.    0.    0.    0.334 0.    0.    0.365 0.
  0.    0.    0.486 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.318 0.    0.    0.    0.    0.
  0.    0.    0.373 0.    0.    0.   ]]
{'fdr': 0.6086956521739131, 'tpr': 0.3, 'fpr': 0.07466666666666667, 'f1': 0.33962264150943394, 'shd': 63, 'npred': 46, 'ntrue': 60}
[9.005e-02 4.232e-02 1.311e-01 3.700e-02 1.866e-01 1.028e-01 3.017e-02
 1.225e-01 3.357e-02 1.060e-01 3.945e-02 1.634e-01 1.451e-02 7.495e-02
 5.696e-02 9.505e-02 1.833e-01 1.590e-01 7.163e-02 1.303e-02 1.017e-02
 1.232e-01 1.919e-02 1.604e-02 1.242e-02 1.922e-01 2.589e-02 1.267e-01
 1.036e-02 2.297e-02 8.844e-02 1.653e-01 4.827e-02 1.090e-01 2.706e-01
 6.599e-02 5.921e-02 1.327e-02 7.878e-02 7.128e-03 1.105e-01 1.202e-02
 1.000e-01 3.048e-02 1.664e-01 1.108e-01 1.584e-01 2.062e-01 1.566e-02
 8.646e-03 1.671e-01 5.683e-02 1.663e-02 9.556e-03 1.883e-01 1.447e-02
 2.565e-01 1.133e-01 4.676e-02 1.716e-02 4.918e-02 1.238e-02 2.390e-02
 2.176e-02 4.396e-03 6.524e-02 1.391e-02 3.933e-02 3.052e-03 4.785e-02
 1.779e-02 1.070e-02 1.868e-02 5.536e-02 8.520e-02 5.080e-02 3.609e-02
 6.599e-03 7.229e-03 1.470e-01 1.063e-02 1.266e-02 7.748e-03 2.039e-01
 1.265e-02 6.048e-02 1.654e-02 1.628e-02 8.908e-03 6.072e-02 3.374e-02
 2.663e-02 2.332e-02 2.669e-03 1.625e-02 7.252e-03 1.525e-02 2.210e-02
 1.481e-02 2.541e-02 1.802e-02 1.012e-02 1.039e-01 1.524e-01 1.110e-01
 3.434e-02 7.058e-03 3.482e-03 2.106e-02 1.581e-02 1.040e-02 3.149e-03
 1.673e-01 6.941e-03 7.462e-02 8.332e-03 6.878e-02 3.027e-02 1.820e-01
 6.000e-02 4.831e-02 3.152e-02 1.679e-02 1.358e-01 3.189e-02 4.263e-02
 2.304e-02 5.846e-02 3.894e-02 1.705e-01 3.910e-02 1.099e-01 5.420e-01
 2.708e-01 1.630e-01 6.069e-02 9.595e-03 2.044e-01 3.588e-02 3.231e-02
 1.925e-02 2.502e-01 1.457e-02 1.306e-01 8.075e-02 1.000e-02 2.744e-02
 6.258e-02 1.017e-01 5.221e-02 1.478e-01 8.920e-03 1.563e-01 3.066e-03
 4.374e-02 6.298e-03 1.284e-02 1.388e-02 2.929e-02 2.079e-02 3.381e-02
 1.299e-01 1.372e-01 2.639e-01 1.043e-02 1.562e-02 2.640e-01 1.131e-02
 2.422e-02 9.784e-03 1.998e-01 7.180e-03 2.124e-01 3.271e-02 1.474e-02
 8.575e-03 7.277e-02 1.026e-01 5.645e-02 1.447e-02 1.950e-02 8.306e-02
 6.503e-03 1.202e-01 2.212e-02 1.069e-01 2.003e-02 5.205e-02 1.243e-02
 8.969e-02 7.047e-02 2.995e-02 6.148e-02 7.524e-03 1.210e-02 1.547e-01
 1.150e-02 9.012e-03 7.894e-03 2.124e-01 1.835e-02 1.996e-01 8.435e-03
 7.762e-02 1.758e-02 4.050e-01 5.958e-01 1.464e-01 2.128e-01 1.466e-01
 1.034e-01 8.886e-02 7.151e-02 3.820e-02 4.262e-02 3.546e-02 1.410e-01
 8.175e-02 1.117e-01 3.213e-01 1.397e-01 1.337e-01 2.117e-02 5.692e-02
 2.304e-01 1.924e-02 5.234e-02 4.200e-03 2.055e-01 1.853e-02 7.793e-02
 1.012e-01 1.361e-02 3.928e-02 3.739e-02 9.917e-02 1.562e-02 1.171e-02
 3.301e-02 1.586e-02 7.338e-03 3.377e-02 1.315e-02 7.487e-03 1.603e-02
 3.017e-02 6.593e-03 1.009e-01 7.576e-02 1.396e-01 6.358e-02 2.710e-03
 1.117e-02 1.574e-01 1.865e-02 5.841e-03 4.210e-03 4.337e-02 2.004e-02
 1.589e-01 1.399e-02 5.410e-02 1.839e-01 1.060e-01 2.546e-01 6.173e-02
 5.297e-01 2.414e-01 2.445e-02 3.284e-01 1.158e-01 1.270e-01 6.284e-02
 2.231e-01 2.090e-01 2.216e-02 2.855e-01 2.484e-01 2.676e-01 2.415e-01
 5.455e-02 3.247e-02 2.619e-01 1.834e-01 6.236e-02 1.904e-02 4.548e-01
 2.234e-02 2.165e-01 3.675e-02 1.608e-02 3.126e-02 5.915e-02 1.488e-01
 3.224e-02 5.099e-02 1.248e-02 2.901e-02 6.271e-02 8.880e-03 1.420e-02
 3.052e-02 7.949e-03 8.286e-02 1.450e-02 1.525e-01 6.921e-02 1.292e-01
 1.562e-01 5.866e-03 8.255e-03 1.289e-01 1.217e-02 2.187e-02 3.904e-03
 6.532e-02 3.632e-03 2.283e-01 4.611e-02 6.496e-02 2.246e-01 4.332e-01
 9.795e-02 6.907e-02 2.267e-01 1.124e-01 4.429e-02 1.357e-01 1.230e-02
 1.377e-01 1.986e-01 2.523e-02 7.421e-02 2.351e-02 1.590e-01 1.945e-01
 1.909e-01 1.136e-01 4.096e-02 1.981e-02 1.008e-01 6.206e-02 2.031e-02
 8.101e-03 3.835e-01 2.988e-02 1.782e-01 1.262e-01 2.154e-02 1.933e-02
 3.844e-02 1.127e-01 4.659e-02 1.721e-01 9.036e-03 6.470e-02 2.034e-01
 2.301e-02 6.880e-02 1.136e-02 1.453e-02 6.171e-02 1.122e-02 1.073e-01
 1.801e-01 8.094e-02 1.036e-01 1.285e-02 1.158e-02 5.760e-02 2.326e-02
 1.869e-02 1.266e-02 1.631e-01 8.487e-03 6.280e-02 1.796e-02 1.621e-01
 2.092e-01 1.250e-01 7.441e-02 5.309e-02 1.209e-01 6.975e-02 4.507e-02
 1.718e-01 1.130e-02 2.610e-01 6.253e-02 1.113e-01 1.282e-01 5.166e-02
 1.457e-01 5.641e-01 2.373e-01 3.798e-01 3.703e-02 1.130e-02 1.849e-01
 8.970e-02 1.055e-01 7.509e-03 2.075e-01 3.119e-02 7.905e-02 9.997e-02
 2.457e-02 2.173e-02 1.446e-01 1.262e-01 1.339e-02 8.264e-02 5.185e-02
 1.718e-02 7.703e-02 8.679e-03 2.302e-02 1.809e-02 4.010e-02 1.514e-02
 3.356e-02 3.171e-02 1.492e-01 8.471e-02 4.302e-02 1.500e-02 1.106e-02
 1.597e-01 1.259e-02 2.257e-02 7.852e-04 1.027e-01 1.295e-02 7.873e-02
 2.084e-02 4.604e-02 7.608e-02 1.378e-01 1.954e-01 6.232e-02 1.656e-01
 2.165e-01 2.497e-02 2.597e-01 4.695e-02 1.366e-01 7.709e-02 1.998e-01
 4.955e-02 5.995e-02 3.105e-01 8.894e-02 1.693e-01 1.627e-01 1.408e-02
 1.936e-02 4.271e-01 3.062e-02 2.739e-02 2.433e-02 5.193e-01 3.982e-02
 3.022e-01 9.436e-02 2.719e-02 1.030e-02 3.661e-02 3.015e-02 2.366e-02
 5.119e-02 2.155e-02 1.780e-02 1.840e-02 6.383e-03 9.377e-03 1.057e-02
 1.673e-02 1.505e-02 5.808e-02 7.565e-03 9.765e-02 1.474e-01 5.753e-02
 5.970e-03 7.174e-03 1.285e-01 9.582e-03 6.886e-03 9.764e-03 6.133e-02
 7.548e-03 7.276e-02 1.374e-02 1.070e-02 2.281e-02 2.027e-02 9.020e-03
 3.876e-03 1.070e-02 2.349e-02 6.018e-03 3.726e-02 1.191e-02 3.199e-02
 1.058e-02 1.094e-02 2.696e-03 1.181e-02 2.068e-02 2.717e-02 6.871e-02
 5.308e-02 5.919e-03 5.217e-03 9.800e-02 2.152e-02 1.357e-02 1.398e-03
 1.768e-01 4.169e-03 1.056e-01 1.088e-02 1.153e-02 9.341e-03 4.878e-02
 2.416e-02 1.043e-02 1.247e-02 6.398e-02 1.078e-02 1.665e-02 5.133e-03
 1.623e-02 1.102e-02 2.211e-02 6.572e-03 1.663e-02 5.517e-03 1.647e-02
 3.084e-02 4.427e-02 4.220e-03 7.153e-03 9.628e-02 3.549e-03 9.906e-03
 3.697e-03 1.915e-02 6.631e-03 6.780e-02 4.283e-03 2.920e-02 1.409e-02
 6.502e-02 4.833e-02 1.447e-02 5.572e-03 3.181e-02 7.664e-03 6.448e-02
 4.430e-03 1.134e-02 1.546e-02 2.006e-02 5.257e-03 4.573e-02 1.278e-02
 3.075e-02 4.385e-02 4.785e-02 9.332e-03 4.032e-03 1.950e-01 7.670e-03
 1.456e-02 8.523e-03 2.909e-02 6.017e-03 1.450e-01 1.557e-02 1.425e-01
 1.545e-01 3.119e-01 3.542e-01 3.672e-02 2.128e-01 1.840e-01 1.096e-01
 6.434e-01 5.405e-02 2.574e-01 6.477e-02 1.344e-01 5.862e-02 2.139e-01
 1.249e-01 3.070e-01 3.222e-01 4.699e-01 1.915e-01 4.510e-02 1.799e-01
 1.594e-01 2.795e-02 1.697e-02 1.319e-01 7.660e-02 5.843e-01 1.247e-01
 1.931e-01 2.447e-01 2.537e-01 5.343e-01 1.923e-01 1.060e-01 1.175e-01
 3.330e-02 1.948e-01 5.507e-02 2.370e-01 1.216e-01 1.514e-01 1.370e-01
 1.776e-01 1.176e-01 2.933e-01 4.084e-01 2.661e-01 3.503e-01 3.477e-02
 2.370e-01 6.393e-02 7.341e-02 1.978e-02 2.778e-01 1.398e-02 1.798e-01
 8.314e-02 1.355e-02 1.071e-02 8.657e-03 9.876e-02 5.597e-03 7.626e-03
 2.125e-02 6.393e-03 1.610e-02 5.779e-03 1.728e-02 1.074e-02 2.718e-02
 6.143e-03 6.862e-03 5.025e-03 1.874e-02 1.963e-02 2.620e-02 1.170e-02
 6.813e-03 5.170e-03 1.291e-03 1.198e-02 3.460e-03 1.932e-01 6.382e-03
 2.565e-02 1.202e-02 8.550e-02 3.282e-02 1.933e-01 1.757e-01 7.620e-02
 1.922e-01 1.410e-01 8.583e-02 1.239e-01 9.920e-03 1.301e-01 4.212e-02
 9.578e-02 1.732e-02 1.883e-01 5.198e-02 1.986e-01 1.067e-01 5.689e-01
 2.158e-01 1.566e-02 3.693e-02 7.217e-01 2.540e-02 2.311e-03 2.997e-01
 2.122e-02 2.120e-01 7.260e-02 1.416e-01 1.036e-01 2.489e-01 2.025e-01
 8.835e-02 5.993e-02 2.873e-01 3.515e-02 3.713e-01 2.150e-02 1.136e-01
 9.591e-02 1.671e-01 2.415e-02 8.343e-02 6.540e-02 1.826e-01 1.553e-01
 1.940e-01 1.037e-01 6.428e-02 3.038e-02 2.247e-01 8.109e-02 4.430e-02
 1.979e-01 7.465e-02 1.365e-01 1.507e-01 1.407e-01 2.269e-01 3.200e-01
 4.052e-01 1.069e-01 2.184e-01 1.872e-01 4.969e-01 2.018e-01 6.474e-02
 4.420e-01 2.203e-01 1.610e-01 1.725e-01 8.355e-01 8.501e-02 3.082e-01
 7.894e-01 3.649e-01 2.614e-01 1.233e-01 7.701e-02 4.982e-01 6.387e-01
 4.757e-02 3.339e-01 2.774e-02 4.880e-01 2.375e-01 1.493e-02 1.257e-02
 9.476e-03 1.857e-02 8.465e-03 1.496e-02 1.250e-02 1.115e-02 2.566e-02
 5.017e-03 3.461e-02 2.120e-03 1.287e-02 1.272e-02 1.555e-02 2.618e-03
 3.728e-02 1.906e-02 6.421e-02 4.536e-02 1.003e-02 6.512e-03 1.801e-02
 5.833e-03 1.145e-02 5.550e-03 3.321e-03 1.274e-02 6.505e-03 9.804e-02
 2.051e-01 1.689e-01 2.693e-01 1.541e-01 2.031e-01 1.187e-01 1.698e-01
 1.123e-01 1.029e-01 6.478e-01 9.389e-02 1.557e-01 7.922e-02 1.683e-01
 6.201e-02 2.830e-01 2.522e-01 1.928e-01 3.341e-01 3.339e-02 1.477e-01
 3.651e-01 8.597e-02 2.759e-02 1.035e-01 4.858e-01 1.213e-01 1.472e-01
 1.621e-02 7.799e-03 2.582e-02 2.060e-02 1.084e-02 1.655e-02 9.577e-03
 1.842e-02 1.284e-02 1.185e-02 1.015e-02 1.304e-02 2.655e-02 1.926e-02
 1.695e-02 5.148e-03 2.931e-02 1.601e-02 2.672e-02 1.268e-02 3.283e-03
 1.332e-02 9.847e-02 1.011e-02 2.259e-02 4.022e-03 1.105e-01 1.440e-02
 2.874e-02 1.849e-01 2.564e-02 1.143e-01 1.706e-01 3.261e-02 8.345e-02
 1.987e-01 2.269e-02 1.337e-01 3.541e-02 3.411e-02 1.566e-02 1.117e-01
 1.438e-02 1.021e-01 1.680e-02 1.677e-01 2.044e-01 3.180e-01 1.102e-01
 2.267e-02 3.776e-02 1.948e-01 3.477e-02 9.325e-03 6.647e-03 3.729e-01
 1.467e-02 5.541e-02]
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 1. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]]
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.6895884773662552, 0.3103826183887006)
Iterations 2500
Achieves (6.086687062773559, 1e-05)-DP
