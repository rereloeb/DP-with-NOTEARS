samples  5000  graph  30 90 ER mlp  minibatch size  50  noise  0.6  minibatches per NN training  250 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 2.124612092558209
iteration 1 in outer loop, alpha = 2.124612092558209, rho = 1.0, h = 2.124612092558209
cuda
iteration 1 in inner loop,alpha 2.124612092558209 rho 1.0 h 1.3214139040848352
iteration 2 in inner loop,alpha 2.124612092558209 rho 10.0 h 0.5776919193926275
iteration 3 in inner loop,alpha 2.124612092558209 rho 100.0 h 0.1810572191900448
iteration 2 in outer loop, alpha = 20.23033401156269, rho = 100.0, h = 0.1810572191900448
cuda
iteration 1 in inner loop,alpha 20.23033401156269 rho 100.0 h 0.09514149314751208
iteration 2 in inner loop,alpha 20.23033401156269 rho 1000.0 h 0.03447628765414734
iteration 3 in outer loop, alpha = 54.70662166571003, rho = 1000.0, h = 0.03447628765414734
cuda
iteration 1 in inner loop,alpha 54.70662166571003 rho 1000.0 h 0.01760709621130019
iteration 2 in inner loop,alpha 54.70662166571003 rho 10000.0 h 0.006093244122013175
iteration 4 in outer loop, alpha = 115.63906288584178, rho = 10000.0, h = 0.006093244122013175
cuda
iteration 1 in inner loop,alpha 115.63906288584178 rho 10000.0 h 0.0029626795381432203
iteration 2 in inner loop,alpha 115.63906288584178 rho 100000.0 h 0.0008631062901258701
iteration 5 in outer loop, alpha = 201.9496918984288, rho = 100000.0, h = 0.0008631062901258701
cuda
iteration 1 in inner loop,alpha 201.9496918984288 rho 100000.0 h 0.00039958449686849917
iteration 6 in outer loop, alpha = 601.534188766928, rho = 1000000.0, h = 0.00039958449686849917
Threshold 0.3
[[0.005 0.001 0.001 2.035 0.001 0.001 0.001 0.    0.    0.    0.    0.002
  0.    0.    0.    0.217 0.    0.    0.984 0.256 0.    0.    1.71  0.
  0.    0.    0.062 0.    0.135 0.   ]
 [1.035 0.003 0.381 0.45  0.002 0.122 0.001 0.409 0.001 0.    0.    1.051
  0.    0.    0.003 1.598 0.002 0.001 0.992 0.359 0.001 0.001 0.251 0.003
  0.    0.001 0.479 0.    0.2   0.001]
 [0.34  0.001 0.003 0.296 0.001 0.105 0.001 0.284 0.    0.    0.    0.297
  0.    0.    0.    0.238 0.    0.001 0.151 0.204 0.    0.    0.188 0.001
  0.    0.    0.227 0.    0.164 0.   ]
 [0.    0.    0.    0.005 0.    0.    0.001 0.    0.    0.    0.    0.
  0.    0.    0.    1.713 0.    0.    0.906 1.118 0.    0.    0.226 0.
  0.    0.    0.03  0.    0.082 0.   ]
 [0.212 0.172 0.219 0.21  0.002 0.125 0.003 0.138 0.001 0.    0.    0.266
  0.    0.    0.001 0.24  0.    0.    0.104 0.267 0.    0.    0.068 0.001
  0.    0.    0.051 0.    0.18  0.   ]
 [0.414 0.    0.001 0.247 0.001 0.002 0.    0.    0.    0.    0.    0.001
  0.    0.    0.    0.139 0.    0.    0.848 1.168 0.    0.    0.093 0.
  0.    0.    0.051 0.    1.218 0.   ]
 [0.07  0.19  0.16  0.157 0.09  0.111 0.001 0.067 0.484 0.007 0.106 0.096
  0.001 0.008 0.    0.159 0.001 0.001 0.655 0.121 0.054 0.125 0.059 0.001
  0.001 0.002 0.063 0.    0.061 0.001]
 [1.003 0.001 0.002 0.385 0.001 2.01  0.003 0.002 0.    0.    0.    0.004
  0.    0.    0.    0.204 0.    0.    0.14  1.191 0.    0.001 0.145 0.
  0.    0.    0.026 0.    0.219 0.   ]
 [0.144 0.262 0.136 0.175 0.149 0.094 0.001 0.146 0.    0.005 0.003 0.13
  0.    0.037 0.004 0.249 0.002 0.004 0.112 1.079 0.112 0.001 0.099 0.016
  0.001 0.006 0.561 0.    0.141 0.002]
 [0.154 0.132 0.181 1.641 0.058 0.348 0.024 2.575 0.036 0.003 0.408 0.579
  0.003 3.449 0.017 0.302 0.003 0.473 0.157 0.167 0.298 0.1   0.363 0.135
  0.    0.441 0.178 0.003 0.292 0.279]
 [1.033 0.111 0.122 1.917 0.14  0.18  0.011 0.232 0.179 0.001 0.001 0.26
  0.003 0.097 0.003 1.175 0.003 0.06  0.264 0.1   2.781 1.116 1.465 0.068
  0.001 0.271 0.118 0.003 0.109 0.072]
 [0.188 0.    0.001 0.248 0.001 0.111 0.002 0.241 0.    0.    0.    0.003
  0.    0.    0.    0.2   0.    0.    0.154 0.429 0.    0.    1.467 0.002
  0.    0.    0.011 0.    0.115 0.   ]
 [1.087 0.847 0.054 0.187 0.009 1.828 0.581 0.101 0.145 0.033 0.131 0.234
  0.001 0.003 0.003 0.114 0.01  0.154 0.613 0.216 0.026 0.046 0.208 0.029
  0.003 3.14  0.108 0.005 1.075 0.475]
 [0.946 2.185 1.87  0.653 0.029 0.294 0.01  1.893 0.001 0.    0.002 1.88
  0.003 0.001 0.003 0.392 0.002 0.197 0.344 0.834 0.135 0.008 0.339 0.003
  0.    0.004 0.137 0.002 0.251 0.069]
 [0.149 0.072 1.69  0.148 0.094 0.139 0.392 0.071 0.003 0.001 0.014 0.08
  0.008 0.04  0.    1.449 0.017 0.062 0.078 0.736 0.028 0.008 0.127 0.005
  0.006 0.083 0.014 0.028 0.058 0.059]
 [0.    0.    0.    0.001 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.002 0.    0.    0.027 0.271 0.    0.    0.004 0.
  0.    0.    0.002 0.    0.082 0.   ]
 [0.148 0.045 1.47  0.156 0.015 0.114 0.659 0.142 0.048 0.022 0.032 0.155
  0.005 0.008 0.003 0.084 0.001 0.034 0.088 0.81  0.059 0.025 0.073 0.028
  0.013 0.012 0.467 0.005 0.142 1.963]
 [0.147 0.133 0.146 1.543 1.354 0.096 0.167 0.284 0.103 0.    0.002 0.312
  0.    0.001 0.003 1.196 0.    0.001 0.156 0.242 0.023 0.006 0.191 0.002
  0.    0.    0.082 0.    1.031 0.   ]
 [0.002 0.    0.    0.004 0.001 0.    0.003 0.    0.    0.    0.    0.001
  0.    0.    0.    0.097 0.    0.    0.008 0.128 0.    0.    0.01  0.
  0.    0.    0.014 0.    0.083 0.   ]
 [0.    0.    0.    0.001 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.009 0.003 0.    0.    0.001 0.
  0.    0.    0.001 0.    1.239 0.   ]
 [0.895 1.252 1.877 0.361 2.121 0.093 0.001 0.118 0.001 0.    0.    1.287
  0.    0.001 0.003 0.609 0.001 0.007 0.128 0.984 0.002 0.001 0.215 0.002
  0.    0.004 0.14  0.004 0.121 0.002]
 [0.772 0.232 0.208 0.307 0.139 0.027 0.005 0.145 0.219 0.    0.    0.26
  0.003 0.029 0.003 0.307 0.001 0.047 0.123 0.15  0.456 0.001 0.061 0.037
  0.    0.082 0.063 0.002 0.094 0.017]
 [0.    0.    0.002 0.003 0.001 0.    0.001 0.    0.    0.    0.    0.001
  0.    0.    0.    0.135 0.    0.    0.116 0.181 0.    0.    0.004 0.
  0.    0.    0.003 0.    0.335 0.   ]
 [1.177 0.078 0.094 0.22  0.11  0.028 0.074 0.272 0.003 0.001 0.004 0.115
  0.    0.048 0.003 0.085 0.006 0.194 0.098 0.106 0.085 0.004 0.116 0.001
  0.    0.    0.019 0.    0.171 0.099]
 [0.057 0.252 0.03  0.266 0.107 0.166 0.105 0.423 0.004 4.125 1.076 0.226
  0.016 0.337 0.003 0.03  0.011 0.168 0.073 0.094 0.106 0.015 0.197 0.002
  0.001 1.64  0.016 0.003 0.696 0.143]
 [0.473 0.377 0.217 0.271 0.096 1.948 0.066 0.145 0.062 0.001 0.002 0.067
  0.    0.029 0.002 0.134 0.003 0.423 0.21  0.173 0.141 0.007 0.074 0.273
  0.001 0.002 0.619 0.016 1.122 1.955]
 [0.009 0.005 0.001 0.021 0.009 0.011 0.003 0.003 0.    0.    0.    0.078
  0.    0.    0.002 0.252 0.    0.003 0.271 0.223 0.001 0.003 1.588 0.002
  0.    0.    0.005 0.001 1.138 0.001]
 [0.228 0.026 0.021 0.172 2.2   0.166 0.036 1.771 0.023 0.003 0.012 2.007
  0.002 0.037 0.003 0.155 0.023 1.025 0.128 0.323 0.005 0.032 0.134 1.506
  0.006 0.003 0.042 0.001 0.078 0.08 ]
 [0.    0.    0.    0.    0.    0.    0.001 0.    0.    0.    0.    0.
  0.    0.    0.    0.001 0.    0.    0.013 0.    0.    0.    0.001 0.
  0.    0.    0.002 0.    0.003 0.   ]
 [0.219 0.079 1.835 0.184 0.115 0.099 0.055 0.084 0.061 0.    0.001 0.125
  0.    0.001 0.004 0.174 0.    1.123 0.122 0.171 0.044 0.003 0.151 0.003
  0.    0.    0.777 0.001 0.274 0.001]]
[[0.    0.    0.    2.035 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.984 0.    0.    0.    1.71  0.
  0.    0.    0.    0.    0.    0.   ]
 [1.035 0.    0.381 0.45  0.    0.    0.    0.409 0.    0.    0.    1.051
  0.    0.    0.    1.598 0.    0.    0.992 0.359 0.    0.    0.    0.
  0.    0.    0.479 0.    0.    0.   ]
 [0.34  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    1.713 0.    0.    0.906 1.118 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.414 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.848 1.168 0.    0.    0.    0.
  0.    0.    0.    0.    1.218 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.484 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.655 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [1.003 0.    0.    0.385 0.    2.01  0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    1.191 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    1.079 0.    0.    0.    0.
  0.    0.    0.561 0.    0.    0.   ]
 [0.    0.    0.    1.641 0.    0.348 0.    2.575 0.    0.    0.408 0.579
  0.    3.449 0.    0.302 0.    0.473 0.    0.    0.    0.    0.363 0.
  0.    0.441 0.    0.    0.    0.   ]
 [1.033 0.    0.    1.917 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    1.175 0.    0.    0.    0.    2.781 1.116 1.465 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.429 0.    0.    1.467 0.
  0.    0.    0.    0.    0.    0.   ]
 [1.087 0.847 0.    0.    0.    1.828 0.581 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.613 0.    0.    0.    0.    0.
  0.    3.14  0.    0.    1.075 0.475]
 [0.946 2.185 1.87  0.653 0.    0.    0.    1.893 0.    0.    0.    1.88
  0.    0.    0.    0.392 0.    0.    0.344 0.834 0.    0.    0.339 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    1.69  0.    0.    0.    0.392 0.    0.    0.    0.    0.
  0.    0.    0.    1.449 0.    0.    0.    0.736 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    1.47  0.    0.    0.    0.659 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.81  0.    0.    0.    0.
  0.    0.    0.467 0.    0.    1.963]
 [0.    0.    0.    1.543 1.354 0.    0.    0.    0.    0.    0.    0.312
  0.    0.    0.    1.196 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    1.031 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    1.239 0.   ]
 [0.895 1.252 1.877 0.361 2.121 0.    0.    0.    0.    0.    0.    1.287
  0.    0.    0.    0.609 0.    0.    0.    0.984 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.772 0.    0.    0.307 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.307 0.    0.    0.    0.    0.456 0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.335 0.   ]
 [1.177 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.423 0.    4.125 1.076 0.
  0.    0.337 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    1.64  0.    0.    0.696 0.   ]
 [0.473 0.377 0.    0.    0.    1.948 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.423 0.    0.    0.    0.    0.    0.
  0.    0.    0.619 0.    1.122 1.955]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.588 0.
  0.    0.    0.    0.    1.138 0.   ]
 [0.    0.    0.    0.    2.2   0.    0.    1.771 0.    0.    0.    2.007
  0.    0.    0.    0.    0.    1.025 0.    0.323 0.    0.    0.    1.506
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    1.835 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    1.123 0.    0.    0.    0.    0.    0.
  0.    0.    0.777 0.    0.    0.   ]]
{'fdr': 0.29914529914529914, 'tpr': 0.9111111111111111, 'fpr': 0.10144927536231885, 'f1': 0.7922705314009661, 'shd': 42, 'npred': 117, 'ntrue': 90}
[8.888e-04 7.934e-04 2.035e+00 8.383e-04 6.880e-04 1.395e-03 4.787e-04
 3.409e-04 1.239e-05 4.311e-05 1.725e-03 5.279e-05 3.053e-05 1.592e-04
 2.174e-01 3.777e-05 3.007e-04 9.840e-01 2.557e-01 4.579e-04 1.743e-04
 1.710e+00 2.011e-05 1.885e-05 2.668e-05 6.206e-02 2.024e-05 1.354e-01
 2.369e-04 1.035e+00 3.813e-01 4.502e-01 1.921e-03 1.222e-01 1.022e-03
 4.094e-01 5.312e-04 3.762e-05 3.718e-05 1.051e+00 3.264e-04 2.733e-05
 3.252e-03 1.598e+00 1.675e-03 1.487e-03 9.922e-01 3.591e-01 6.875e-04
 8.575e-04 2.505e-01 2.995e-03 1.370e-05 6.782e-04 4.793e-01 4.226e-04
 1.998e-01 7.616e-04 3.402e-01 1.202e-03 2.964e-01 1.116e-03 1.047e-01
 8.538e-04 2.843e-01 4.147e-04 1.040e-04 1.410e-04 2.968e-01 1.837e-05
 2.197e-04 6.211e-05 2.379e-01 9.146e-05 9.722e-04 1.513e-01 2.037e-01
 2.577e-04 1.603e-04 1.885e-01 7.788e-04 5.024e-05 1.385e-05 2.268e-01
 1.121e-04 1.644e-01 1.538e-04 5.790e-05 1.602e-04 4.478e-04 1.329e-04
 1.876e-04 1.123e-03 5.597e-05 1.905e-04 4.427e-05 1.285e-04 2.365e-04
 1.507e-05 8.534e-05 9.069e-05 1.713e+00 2.643e-05 1.050e-04 9.063e-01
 1.118e+00 8.566e-05 2.820e-05 2.257e-01 1.110e-05 1.541e-05 2.856e-05
 2.974e-02 1.044e-05 8.209e-02 3.912e-05 2.121e-01 1.716e-01 2.186e-01
 2.104e-01 1.250e-01 2.824e-03 1.385e-01 5.929e-04 9.514e-05 5.644e-05
 2.662e-01 1.378e-04 3.949e-04 6.837e-04 2.398e-01 2.491e-05 2.823e-04
 1.036e-01 2.673e-01 4.207e-04 2.588e-04 6.807e-02 8.172e-04 1.754e-05
 9.937e-05 5.125e-02 9.070e-06 1.798e-01 1.519e-04 4.139e-01 4.621e-04
 8.818e-04 2.470e-01 1.067e-03 2.338e-04 4.869e-04 4.720e-05 7.749e-06
 3.776e-05 9.166e-04 2.462e-04 6.248e-05 6.060e-05 1.391e-01 8.298e-05
 2.144e-04 8.481e-01 1.168e+00 1.635e-05 3.433e-04 9.328e-02 9.190e-05
 1.608e-05 9.780e-05 5.128e-02 4.402e-05 1.218e+00 1.509e-04 7.025e-02
 1.896e-01 1.603e-01 1.568e-01 9.009e-02 1.108e-01 6.704e-02 4.836e-01
 7.421e-03 1.055e-01 9.581e-02 5.158e-04 7.703e-03 2.464e-04 1.587e-01
 5.157e-04 1.157e-03 6.554e-01 1.206e-01 5.410e-02 1.251e-01 5.920e-02
 1.443e-03 7.744e-04 1.837e-03 6.296e-02 4.050e-04 6.102e-02 9.899e-04
 1.003e+00 5.110e-04 2.192e-03 3.854e-01 8.809e-04 2.010e+00 3.079e-03
 1.045e-04 6.426e-06 3.050e-05 3.915e-03 1.585e-05 1.088e-04 8.191e-05
 2.043e-01 8.667e-05 1.872e-04 1.402e-01 1.191e+00 5.720e-05 9.468e-04
 1.454e-01 2.170e-04 5.930e-05 2.034e-04 2.609e-02 7.117e-05 2.186e-01
 4.087e-04 1.440e-01 2.624e-01 1.356e-01 1.754e-01 1.493e-01 9.418e-02
 1.134e-03 1.460e-01 4.777e-03 3.152e-03 1.298e-01 4.350e-04 3.743e-02
 3.982e-03 2.486e-01 1.609e-03 3.664e-03 1.119e-01 1.079e+00 1.116e-01
 1.213e-03 9.909e-02 1.557e-02 6.319e-04 5.527e-03 5.614e-01 2.396e-04
 1.405e-01 1.726e-03 1.545e-01 1.318e-01 1.814e-01 1.641e+00 5.767e-02
 3.480e-01 2.410e-02 2.575e+00 3.601e-02 4.076e-01 5.787e-01 2.596e-03
 3.449e+00 1.652e-02 3.021e-01 2.950e-03 4.730e-01 1.565e-01 1.668e-01
 2.983e-01 9.973e-02 3.633e-01 1.347e-01 4.811e-04 4.408e-01 1.782e-01
 2.506e-03 2.916e-01 2.785e-01 1.033e+00 1.114e-01 1.217e-01 1.917e+00
 1.401e-01 1.797e-01 1.126e-02 2.324e-01 1.786e-01 1.177e-03 2.605e-01
 3.495e-03 9.662e-02 2.788e-03 1.175e+00 2.926e-03 5.974e-02 2.637e-01
 9.979e-02 2.781e+00 1.116e+00 1.465e+00 6.790e-02 1.032e-03 2.712e-01
 1.182e-01 3.373e-03 1.091e-01 7.197e-02 1.879e-01 1.373e-04 1.240e-03
 2.477e-01 6.040e-04 1.106e-01 1.502e-03 2.411e-01 1.642e-04 2.975e-05
 3.365e-05 2.676e-05 5.737e-05 8.497e-05 2.003e-01 5.347e-05 2.195e-04
 1.542e-01 4.287e-01 2.383e-04 2.102e-04 1.467e+00 1.937e-03 6.863e-06
 1.764e-04 1.113e-02 1.788e-04 1.151e-01 9.652e-05 1.087e+00 8.466e-01
 5.369e-02 1.871e-01 9.256e-03 1.828e+00 5.813e-01 1.012e-01 1.450e-01
 3.333e-02 1.308e-01 2.336e-01 2.794e-03 2.635e-03 1.136e-01 9.675e-03
 1.537e-01 6.127e-01 2.162e-01 2.613e-02 4.575e-02 2.078e-01 2.862e-02
 3.446e-03 3.140e+00 1.076e-01 4.680e-03 1.075e+00 4.753e-01 9.461e-01
 2.185e+00 1.870e+00 6.534e-01 2.877e-02 2.936e-01 1.012e-02 1.893e+00
 6.408e-04 2.345e-04 1.815e-03 1.880e+00 3.482e-03 3.003e-03 3.924e-01
 2.071e-03 1.966e-01 3.443e-01 8.339e-01 1.350e-01 8.495e-03 3.392e-01
 3.192e-03 6.984e-05 3.802e-03 1.365e-01 1.987e-03 2.511e-01 6.948e-02
 1.491e-01 7.184e-02 1.690e+00 1.480e-01 9.428e-02 1.392e-01 3.920e-01
 7.051e-02 2.873e-03 1.263e-03 1.405e-02 7.965e-02 7.991e-03 3.977e-02
 1.449e+00 1.652e-02 6.217e-02 7.765e-02 7.356e-01 2.835e-02 7.964e-03
 1.270e-01 5.024e-03 6.051e-03 8.347e-02 1.390e-02 2.807e-02 5.786e-02
 5.890e-02 1.728e-05 7.302e-05 6.349e-05 7.952e-04 1.310e-04 5.423e-05
 2.126e-04 4.275e-05 2.844e-04 1.978e-05 1.209e-05 2.912e-04 1.064e-04
 1.013e-05 1.676e-05 3.666e-05 2.626e-05 2.746e-02 2.713e-01 3.307e-05
 6.202e-05 3.707e-03 2.061e-05 1.418e-05 2.502e-05 2.027e-03 4.708e-06
 8.195e-02 3.232e-05 1.476e-01 4.456e-02 1.470e+00 1.559e-01 1.538e-02
 1.140e-01 6.587e-01 1.419e-01 4.819e-02 2.206e-02 3.218e-02 1.550e-01
 5.282e-03 8.291e-03 3.312e-03 8.432e-02 3.378e-02 8.804e-02 8.104e-01
 5.895e-02 2.524e-02 7.298e-02 2.801e-02 1.321e-02 1.208e-02 4.672e-01
 5.171e-03 1.417e-01 1.963e+00 1.470e-01 1.327e-01 1.455e-01 1.543e+00
 1.354e+00 9.562e-02 1.669e-01 2.844e-01 1.033e-01 7.275e-05 1.857e-03
 3.116e-01 2.291e-05 1.161e-03 3.058e-03 1.196e+00 1.896e-05 1.564e-01
 2.416e-01 2.319e-02 6.117e-03 1.909e-01 1.763e-03 1.958e-05 8.756e-05
 8.209e-02 1.571e-05 1.031e+00 1.657e-04 1.507e-03 2.238e-04 1.989e-04
 3.940e-03 7.188e-04 1.919e-04 2.765e-03 2.062e-04 3.278e-04 1.938e-05
 1.516e-04 9.697e-04 4.476e-05 2.496e-05 5.817e-05 9.749e-02 8.752e-05
 1.202e-04 1.279e-01 8.854e-05 1.385e-04 9.828e-03 7.512e-05 1.178e-05
 3.386e-05 1.403e-02 1.368e-05 8.327e-02 9.544e-05 4.399e-05 6.436e-05
 2.565e-04 6.556e-04 1.277e-04 1.459e-04 1.681e-04 1.872e-05 2.140e-05
 5.776e-06 9.368e-06 2.363e-04 5.183e-05 1.485e-05 5.056e-05 4.776e-04
 7.575e-05 1.867e-05 9.438e-03 6.788e-05 2.562e-05 1.218e-03 3.287e-05
 1.008e-05 1.173e-05 1.079e-03 7.606e-06 1.239e+00 5.748e-06 8.951e-01
 1.252e+00 1.877e+00 3.606e-01 2.121e+00 9.338e-02 6.510e-04 1.179e-01
 7.916e-04 8.300e-05 7.093e-05 1.287e+00 2.468e-04 6.649e-04 2.989e-03
 6.089e-01 6.279e-04 6.895e-03 1.284e-01 9.843e-01 5.564e-04 2.147e-01
 2.162e-03 1.686e-05 3.861e-03 1.400e-01 3.553e-03 1.209e-01 2.244e-03
 7.723e-01 2.323e-01 2.084e-01 3.069e-01 1.386e-01 2.690e-02 4.625e-03
 1.449e-01 2.188e-01 9.006e-05 9.710e-05 2.604e-01 2.911e-03 2.939e-02
 2.731e-03 3.069e-01 1.425e-03 4.735e-02 1.229e-01 1.497e-01 4.562e-01
 6.071e-02 3.709e-02 3.407e-04 8.153e-02 6.293e-02 1.625e-03 9.410e-02
 1.652e-02 6.894e-05 4.339e-04 1.535e-03 3.233e-03 5.390e-04 2.609e-04
 6.739e-04 3.554e-05 3.820e-04 1.655e-05 7.867e-05 9.347e-04 5.770e-05
 1.101e-05 7.465e-05 1.350e-01 2.304e-04 2.411e-04 1.163e-01 1.813e-01
 2.768e-04 8.517e-06 4.098e-05 2.856e-05 1.111e-04 3.017e-03 7.225e-05
 3.349e-01 3.026e-04 1.177e+00 7.790e-02 9.372e-02 2.195e-01 1.100e-01
 2.796e-02 7.384e-02 2.723e-01 2.980e-03 1.214e-03 4.110e-03 1.155e-01
 8.207e-05 4.803e-02 3.411e-03 8.536e-02 5.648e-03 1.941e-01 9.806e-02
 1.064e-01 8.456e-02 3.511e-03 1.156e-01 1.377e-04 2.880e-04 1.901e-02
 1.468e-04 1.711e-01 9.895e-02 5.661e-02 2.523e-01 2.979e-02 2.657e-01
 1.068e-01 1.660e-01 1.047e-01 4.228e-01 4.108e-03 4.125e+00 1.076e+00
 2.255e-01 1.599e-02 3.370e-01 2.594e-03 3.026e-02 1.066e-02 1.679e-01
 7.255e-02 9.385e-02 1.063e-01 1.490e-02 1.974e-01 1.958e-03 1.640e+00
 1.606e-02 2.794e-03 6.959e-01 1.428e-01 4.730e-01 3.768e-01 2.167e-01
 2.713e-01 9.588e-02 1.948e+00 6.570e-02 1.447e-01 6.195e-02 1.013e-03
 1.875e-03 6.672e-02 1.835e-05 2.943e-02 2.033e-03 1.336e-01 2.883e-03
 4.228e-01 2.099e-01 1.732e-01 1.413e-01 7.143e-03 7.394e-02 2.729e-01
 5.245e-04 6.193e-01 1.571e-02 1.122e+00 1.955e+00 8.699e-03 4.598e-03
 5.286e-04 2.137e-02 9.225e-03 1.101e-02 2.665e-03 3.345e-03 3.421e-04
 6.249e-06 9.602e-05 7.760e-02 7.523e-05 8.300e-05 1.545e-03 2.523e-01
 1.660e-04 3.284e-03 2.708e-01 2.226e-01 1.406e-03 2.905e-03 1.588e+00
 1.708e-03 4.887e-05 1.801e-04 1.133e-03 1.138e+00 5.372e-04 2.276e-01
 2.552e-02 2.059e-02 1.723e-01 2.200e+00 1.663e-01 3.594e-02 1.771e+00
 2.288e-02 2.955e-03 1.174e-02 2.007e+00 2.295e-03 3.656e-02 2.683e-03
 1.555e-01 2.318e-02 1.025e+00 1.279e-01 3.235e-01 5.024e-03 3.154e-02
 1.342e-01 1.506e+00 5.949e-03 2.501e-03 4.162e-02 7.825e-02 7.991e-02
 1.080e-04 4.850e-04 3.301e-04 1.331e-04 2.234e-04 5.580e-05 5.841e-04
 8.699e-06 4.838e-05 7.048e-06 2.654e-05 2.025e-04 4.547e-05 7.481e-06
 1.519e-05 9.085e-04 6.898e-05 5.158e-05 1.287e-02 2.054e-04 1.403e-04
 3.055e-05 7.711e-04 2.925e-05 2.123e-05 1.054e-04 2.084e-03 9.777e-06
 3.613e-05 2.186e-01 7.928e-02 1.835e+00 1.840e-01 1.148e-01 9.944e-02
 5.499e-02 8.388e-02 6.086e-02 7.404e-05 8.424e-04 1.246e-01 6.736e-05
 1.287e-03 3.629e-03 1.740e-01 9.435e-05 1.123e+00 1.223e-01 1.708e-01
 4.420e-02 3.488e-03 1.509e-01 2.916e-03 5.085e-05 1.211e-04 7.773e-01
 6.913e-04 2.744e-01]
[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 1. 0. 0. 1. 0.]
 [1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
  0. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 0. 1. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0.]
aucroc, aucpr (0.9785754985754985, 0.9388938582560411)
cuda
9630
cuda
Objective function 982.29 = squared loss an data 726.28 + 0.5*rho*h**2 254.631624 + alpha*h 0.000000 + L2reg 0.55 + L1reg 0.82 ; SHD = 415 ; DAG False
||w||^2 75871542.06099917
exp ma of ||w||^2 40455567054.878876
||w|| 8710.427203128396
exp ma of ||w|| 70042.39309402916
||w||^2 0.15862267842584216
exp ma of ||w||^2 0.11183861962049711
||w|| 0.3982746268918498
exp ma of ||w|| 0.3254986414668977
||w||^2 0.05548157492200079
exp ma of ||w||^2 0.14673921302012607
||w|| 0.23554527149149224
exp ma of ||w|| 0.36523997440661155
||w||^2 0.07680932453618278
exp ma of ||w||^2 0.16186022402036568
||w|| 0.2771449522112621
exp ma of ||w|| 0.387080512703679
||w||^2 0.14522319884012877
exp ma of ||w||^2 0.19208313194447396
||w|| 0.3810816170325312
exp ma of ||w|| 0.41833577496470625
||w||^2 0.6043739236498136
exp ma of ||w||^2 0.1896303873772897
||w|| 0.7774148980112315
exp ma of ||w|| 0.41991555952128046
||w||^2 0.1596731023140923
exp ma of ||w||^2 0.24328423583659062
||w|| 0.39959116896409547
exp ma of ||w|| 0.46950491255940563
||w||^2 0.11575586133257465
exp ma of ||w||^2 0.25698319977069856
||w|| 0.34022913063489235
exp ma of ||w|| 0.4859291077037357
||w||^2 0.6046672672056701
exp ma of ||w||^2 0.3951247138822192
||w|| 0.7776035411478461
exp ma of ||w|| 0.5996358359115181
||w||^2 0.27970121201494474
exp ma of ||w||^2 0.408632345472723
||w|| 0.5288678587463458
exp ma of ||w|| 0.6138518625042486
||w||^2 0.355701131252186
exp ma of ||w||^2 0.4290683713048866
||w|| 0.5964068504403567
exp ma of ||w|| 0.6283996141366964
||w||^2 0.31961627043465307
exp ma of ||w||^2 0.45608289784520806
||w|| 0.5653461509859716
exp ma of ||w|| 0.6486277786689661
cuda
Objective function 61.08 = squared loss an data 48.08 + 0.5*rho*h**2 10.821215 + alpha*h 0.000000 + L2reg 1.59 + L1reg 0.59 ; SHD = 206 ; DAG False
Proportion of microbatches that were clipped  0.7676408848700146
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 4.652142431569345
iteration 1 in outer loop, alpha = 4.652142431569345, rho = 1.0, h = 4.652142431569345
cuda
9630
cuda
Objective function 82.72 = squared loss an data 48.08 + 0.5*rho*h**2 10.821215 + alpha*h 21.642429 + L2reg 1.59 + L1reg 0.59 ; SHD = 206 ; DAG False
||w||^2 2597666.8050605035
exp ma of ||w||^2 1297950956.7595534
||w|| 1611.7278942366493
exp ma of ||w|| 13655.753570674662
||w||^2 2.522494735001796
exp ma of ||w||^2 2411202.9601892526
||w|| 1.5882363599294016
exp ma of ||w|| 38.41580193825703
||w||^2 1.5573267682451368
exp ma of ||w||^2 814395.5920118269
||w|| 1.24792899166785
exp ma of ||w|| 13.8171692448263
||w||^2 3.5494966804645536
exp ma of ||w||^2 0.9741390860960686
||w|| 1.8840107962706991
exp ma of ||w|| 0.9482248028329898
||w||^2 0.6665249931727746
exp ma of ||w||^2 0.8044895276367552
||w|| 0.8164098193755233
exp ma of ||w|| 0.8647714450769365
||w||^2 2.2612265391998982
exp ma of ||w||^2 0.8178780276263381
||w|| 1.5037375233729782
exp ma of ||w|| 0.8736948680362118
||w||^2 0.6631365593249009
exp ma of ||w||^2 0.7583033090474923
||w|| 0.8143319712039438
exp ma of ||w|| 0.8458149267213187
||w||^2 0.5923583722984443
exp ma of ||w||^2 1.0033628329777857
||w|| 0.7696482133406433
exp ma of ||w|| 0.9671625766146467
cuda
Objective function 58.54 = squared loss an data 37.88 + 0.5*rho*h**2 4.372090 + alpha*h 13.756646 + L2reg 1.99 + L1reg 0.55 ; SHD = 181 ; DAG False
Proportion of microbatches that were clipped  0.768911326439215
iteration 1 in inner loop, alpha 4.652142431569345 rho 1.0 h 2.95705598092367
9630
cuda
Objective function 97.89 = squared loss an data 37.88 + 0.5*rho*h**2 43.720900 + alpha*h 13.756646 + L2reg 1.99 + L1reg 0.55 ; SHD = 181 ; DAG False
||w||^2 1269752.885544967
exp ma of ||w||^2 1348360673.380654
||w|| 1126.8331223144653
exp ma of ||w|| 10801.93326295205
||w||^2 2.028961445918888
exp ma of ||w||^2 1.6107294060877686
||w|| 1.42441617721749
exp ma of ||w|| 1.215313091875793
||w||^2 2.2304777241112843
exp ma of ||w||^2 1.4732496354970608
||w|| 1.493478397604493
exp ma of ||w|| 1.1784056078711709
||w||^2 5.746393108952178
exp ma of ||w||^2 1.5391267060252942
||w|| 2.397163554902372
exp ma of ||w|| 1.195895417291062
||w||^2 1.2482083841890894
exp ma of ||w||^2 1.456943623343433
||w|| 1.117232466494368
exp ma of ||w|| 1.1713228732244967
||w||^2 1.2383318888419985
exp ma of ||w||^2 1.4309852109200583
||w|| 1.1128036164759703
exp ma of ||w|| 1.1588106265783729
||w||^2 1.14694101649314
exp ma of ||w||^2 1.2885592499513256
||w|| 1.07095332134185
exp ma of ||w|| 1.1080983306568657
||w||^2 0.7298628262335305
exp ma of ||w||^2 1.3950137859697873
||w|| 0.8543200958853364
exp ma of ||w|| 1.143418452908411
||w||^2 1.116677560975012
exp ma of ||w||^2 1.3202249152058259
||w|| 1.0567296536839552
exp ma of ||w|| 1.1169591521514695
||w||^2 1.637449935105322
exp ma of ||w||^2 1.478658817012266
||w|| 1.2796288270843705
exp ma of ||w|| 1.1779579056420095
||w||^2 2.9091207677898474
exp ma of ||w||^2 1.5010838006706677
||w|| 1.7056144839294276
exp ma of ||w|| 1.1905061327498678
||w||^2 2.3181037559296604
exp ma of ||w||^2 1.534054991642283
||w|| 1.5225320213150397
exp ma of ||w|| 1.1965095294410157
||w||^2 1.0537266161322774
exp ma of ||w||^2 1.5183616750043727
||w|| 1.0265118684809627
exp ma of ||w|| 1.2036688129123352
cuda
Objective function 59.96 = squared loss an data 40.20 + 0.5*rho*h**2 10.350255 + alpha*h 6.693350 + L2reg 2.23 + L1reg 0.49 ; SHD = 152 ; DAG True
Proportion of microbatches that were clipped  0.7744010291043576
iteration 2 in inner loop, alpha 4.652142431569345 rho 10.0 h 1.4387671715165666
9630
cuda
Objective function 153.12 = squared loss an data 40.20 + 0.5*rho*h**2 103.502549 + alpha*h 6.693350 + L2reg 2.23 + L1reg 0.49 ; SHD = 152 ; DAG True
||w||^2 823483599507.0172
exp ma of ||w||^2 281872483512.36615
||w|| 907459.9712973665
exp ma of ||w|| 279640.76739035983
||w||^2 53.205349468097324
exp ma of ||w||^2 38757736.95711968
||w|| 7.294199714026024
exp ma of ||w|| 265.6792824443271
||w||^2 47.71188569091234
exp ma of ||w||^2 37986458.78484463
||w|| 6.907379075373838
exp ma of ||w|| 260.5172752859078
||w||^2 1.3372550819747886
exp ma of ||w||^2 148002.16902567257
||w|| 1.1563974584781775
exp ma of ||w|| 2.915964863224694
||w||^2 2.721505430710459
exp ma of ||w||^2 7407.9129120762
||w|| 1.6496985878367172
exp ma of ||w|| 1.6220392989417312
||w||^2 0.638817826693117
exp ma of ||w||^2 5.439190972256356
||w|| 0.799260800172958
exp ma of ||w|| 1.378740741509149
||w||^2 2.336913802966305
exp ma of ||w||^2 2.219424472661672
||w|| 1.5286967661921396
exp ma of ||w|| 1.4422467247880564
||w||^2 1.026197174799446
exp ma of ||w||^2 2.1617538454042298
||w|| 1.0130139065182897
exp ma of ||w|| 1.4269415429827532
||w||^2 1.7317220297538427
exp ma of ||w||^2 2.4891514003754627
||w|| 1.3159490984661386
exp ma of ||w|| 1.5302732257602525
||w||^2 0.9873223057376073
exp ma of ||w||^2 2.1722252025605693
||w|| 0.9936409340086625
exp ma of ||w|| 1.4301037136687416
||w||^2 2.1362583648059936
exp ma of ||w||^2 2.09404771545246
||w|| 1.461594459761665
exp ma of ||w|| 1.411281160709051
||w||^2 2.965339129311705
exp ma of ||w||^2 2.2200606810751147
||w|| 1.722016007275108
exp ma of ||w|| 1.4495661781385754
||w||^2 2.3842979229065864
exp ma of ||w||^2 2.1462294287488435
||w|| 1.5441171985657651
exp ma of ||w|| 1.4274232797691122
||w||^2 1.3466904654180054
exp ma of ||w||^2 2.01425946394967
||w|| 1.1604699330090398
exp ma of ||w|| 1.3824313654904012
||w||^2 1.3501553822954333
exp ma of ||w||^2 2.1805291616712803
||w|| 1.1619618678319152
exp ma of ||w|| 1.4314675196464703
||w||^2 2.7892555562594032
exp ma of ||w||^2 2.171763173921487
||w|| 1.670106450577149
exp ma of ||w|| 1.4381223775099468
||w||^2 1.072773248554951
exp ma of ||w||^2 2.180781959082473
||w|| 1.0357476761040554
exp ma of ||w|| 1.4285001551117482
cuda
Objective function 62.57 = squared loss an data 43.18 + 0.5*rho*h**2 14.093882 + alpha*h 2.469922 + L2reg 2.40 + L1reg 0.42 ; SHD = 139 ; DAG True
Proportion of microbatches that were clipped  0.7742302380372086
iteration 3 in inner loop, alpha 4.652142431569345 rho 100.0 h 0.5309215061896353
iteration 2 in outer loop, alpha = 57.744293050532875, rho = 100.0, h = 0.5309215061896353
cuda
9630
cuda
Objective function 90.76 = squared loss an data 43.18 + 0.5*rho*h**2 14.093882 + alpha*h 30.657687 + L2reg 2.40 + L1reg 0.42 ; SHD = 139 ; DAG True
||w||^2 102795145424.73933
exp ma of ||w||^2 240069044636.14706
||w|| 320616.82024613017
exp ma of ||w|| 414299.2771977957
||w||^2 385288802.27519816
exp ma of ||w||^2 15797720830.591042
||w|| 19628.774854157306
exp ma of ||w|| 64758.00984342827
||w||^2 6355275.991685019
exp ma of ||w||^2 3163149014.0401244
||w|| 2520.9672730293464
exp ma of ||w|| 16939.82521562297
||w||^2 9.128019925006056
exp ma of ||w||^2 5745448.246043587
||w|| 3.0212613135917348
exp ma of ||w|| 43.318261159415904
||w||^2 1.384264474779622
exp ma of ||w||^2 621.6023277534334
||w|| 1.1765476933722756
exp ma of ||w|| 1.5684919217777824
v before min max tensor([[-408.265,  199.821,  337.010,  ...,  -73.099, -324.827, -185.209],
        [-355.645, -220.480,    1.682,  ..., -212.043, -447.028, -346.252],
        [   2.710, -370.944, -225.925,  ..., -372.559, -305.027,   37.325],
        ...,
        [-281.637,  230.972, -384.869,  ..., -246.762, -258.520, -375.121],
        [ -56.758, -381.477, -374.064,  ..., -290.480, -295.858, -257.662],
        [-169.558, -403.928, -415.812,  ..., -126.165,  460.949, -362.327]],
       device='cuda:0')
v tensor([[1.000e-12, 1.000e+01, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.682e+00,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [2.710e+00, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e+01],
        ...,
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         1.000e-12]], device='cuda:0')
v before min max tensor([ 2.921e+02, -4.323e+02, -2.573e+02, -2.593e+02,  3.256e+01,  8.051e+00,
        -4.041e+02, -1.785e+01,  2.407e+02, -4.946e+02, -3.577e+02, -4.285e+02,
        -3.204e+02,  9.531e+01,  3.289e+02, -3.897e+02,  1.968e+02, -2.963e+02,
        -2.899e+02, -3.429e+02,  4.050e+01, -3.633e+02,  4.193e+02,  2.240e+02,
        -2.839e+02, -1.529e+02,  3.720e+02, -2.128e+02,  8.429e+02,  2.176e+00,
        -2.400e+02,  1.658e+03,  5.721e+02, -2.664e+02, -2.459e+02, -4.448e+02,
         4.146e+02, -2.079e+02, -1.525e+02, -4.165e+02, -2.048e+02,  1.966e+02,
        -1.072e+02, -1.797e+02, -1.702e+02, -3.082e+02, -2.766e+02, -8.392e+01,
        -2.452e+02, -2.841e+02,  3.620e+02,  1.478e+03, -2.897e+02, -2.707e+02,
        -1.967e+02, -2.627e+02, -4.260e+02,  7.360e+01,  1.198e+03, -1.661e+02,
        -2.781e+02,  6.079e+01, -3.143e+02, -4.308e+02, -9.777e+01, -1.160e+02,
        -2.565e+02,  1.134e+03, -2.223e+01, -2.378e+02, -2.103e+02, -4.655e+01,
        -2.842e+02, -1.551e+02,  1.756e+02, -2.845e+02, -3.443e+01, -4.714e+02,
        -9.468e+01,  7.326e+02, -1.834e+02, -3.332e+02, -2.326e+02, -2.600e+02,
        -3.460e+02, -3.508e+02,  1.319e+02,  3.951e+02,  4.768e+02, -3.091e+02,
        -3.159e+02, -3.219e+02, -3.734e+02, -3.248e+02,  3.502e+02, -3.351e+02,
        -2.722e+02, -2.601e+02, -4.345e+01, -3.504e+02, -1.062e+02, -3.673e+02,
         6.922e+02, -3.728e+02, -4.855e+02, -3.050e+02, -3.155e+02, -9.443e+01,
        -3.618e+02, -2.714e+02, -4.069e+02, -1.279e+02,  1.171e+02, -3.638e+02,
        -3.181e+02,  1.132e+02, -3.605e+02,  1.398e+03, -3.044e+02, -4.285e+02,
        -2.409e+02, -2.006e+02, -1.179e+02, -4.886e+01, -3.580e+02, -3.163e+02,
        -2.208e+02, -2.396e+02, -3.248e+02, -9.058e+01,  5.955e+02, -7.136e+01,
         8.703e+01,  1.568e+00,  2.980e+02, -3.137e+02, -4.092e+02, -6.086e+00,
         1.890e+02,  4.531e+02, -3.097e+02, -2.544e+02,  1.038e+03,  9.332e+02,
         1.480e+02, -3.358e+01, -3.582e+02,  2.336e+02, -2.507e+02, -3.517e+02,
        -1.325e+02, -2.368e+02, -3.572e+02, -2.370e+02,  3.853e+01,  7.186e+01,
        -1.917e+02, -3.082e+02,  6.260e+02,  2.422e+02, -2.282e+02, -3.521e+02,
        -2.398e+01, -1.826e+02, -3.085e+02, -3.795e+02, -3.824e+02, -5.045e+02,
        -1.914e+02,  7.343e+02, -3.095e+02,  1.651e+02,  1.028e+03, -4.641e+02,
        -2.588e+02, -3.992e+02,  6.913e+01, -1.559e+02, -3.132e+02, -2.751e+02,
        -3.358e+02,  3.186e+02, -2.285e+02, -1.249e+02, -1.860e+02,  3.156e+02,
        -3.351e+02,  2.966e+02, -4.006e+02, -3.416e+02,  1.110e+02,  2.119e+02,
         1.122e+03, -2.869e+02, -3.003e+02, -1.879e+02, -4.738e+02,  9.075e+01,
        -4.349e+02, -2.523e+02, -2.873e+02,  3.537e+02, -4.804e+02, -2.774e+02,
        -2.122e+02, -3.523e+02, -1.039e+02,  5.101e+01, -3.854e+02, -2.390e+02,
        -3.258e+00, -1.287e+02, -3.825e+02, -2.932e+02, -2.993e+02, -3.167e+02,
        -2.662e+02, -8.637e+01, -3.553e+02,  6.254e+01, -5.015e+01, -3.693e+02,
        -4.227e+02,  1.762e+02, -4.203e+02, -3.085e+02,  1.630e+02, -3.227e+02,
        -2.737e+01, -1.560e+02,  5.130e+02, -3.027e+02, -1.666e+02, -2.055e+01,
        -8.834e+01,  8.950e+01, -2.568e+02, -3.335e+02,  9.040e+02, -8.569e+01,
        -3.973e+02,  3.871e+02, -4.047e+02, -1.793e+02, -2.552e+02, -2.415e+02,
        -3.970e+02, -3.430e+01, -1.841e+02, -2.068e+02, -1.890e+02, -2.987e+02,
        -2.058e+02,  1.174e+03,  6.541e+01,  4.309e+01, -4.221e+02, -3.458e+02,
         4.699e+01, -3.240e+02, -3.714e+02, -3.049e+02, -4.829e+02, -4.096e+02,
        -4.456e+02, -3.117e+02,  1.180e+02, -2.236e+02, -3.562e+02, -3.290e+02,
        -1.891e+02, -3.630e+02,  1.383e+03, -2.803e+02, -3.580e+02, -2.815e+02,
        -3.948e+02, -3.181e+02,  1.809e+02,  2.781e+02,  3.518e+02, -3.778e+02,
        -3.466e+02, -1.597e+02, -2.340e+02, -4.162e+02, -2.157e+02,  2.267e+03,
         1.077e+02, -2.933e+02,  3.295e+02, -2.501e+02, -7.869e+01, -2.984e+02,
        -3.979e+02,  1.373e+02, -2.107e+02, -3.711e+02, -9.903e+01, -2.963e+02],
       device='cuda:0')
v tensor([1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 8.051e+00,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 2.176e+00,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.568e+00, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-2.608e+02],
         [-3.984e+02],
         [ 4.429e+02],
         [-3.815e+02],
         [-2.912e+02],
         [-1.176e+02],
         [ 1.966e+02],
         [ 3.586e+02],
         [-2.671e+02],
         [-1.046e+02]],

        [[ 6.153e+02],
         [-2.768e+02],
         [-1.447e+01],
         [-4.571e+02],
         [-4.845e+01],
         [-3.030e+02],
         [ 4.881e+02],
         [-4.530e+02],
         [ 8.598e+00],
         [ 4.900e+01]],

        [[ 2.517e+02],
         [-1.409e+02],
         [-4.491e+02],
         [-2.476e+02],
         [ 6.787e+02],
         [ 4.454e+02],
         [-2.905e+02],
         [-3.658e+02],
         [-1.914e+02],
         [ 6.133e+02]],

        [[-1.935e+02],
         [-4.597e+01],
         [ 1.789e+02],
         [-3.463e+02],
         [-3.964e+00],
         [-2.693e+02],
         [-1.747e+02],
         [ 5.021e+02],
         [-2.883e+02],
         [-2.581e+02]],

        [[-1.085e+02],
         [-5.899e+01],
         [ 5.622e+02],
         [-3.336e+02],
         [ 2.145e+03],
         [-3.767e+02],
         [-4.269e+02],
         [ 1.108e+03],
         [ 3.742e+01],
         [ 1.206e+03]],

        [[-2.073e+02],
         [ 4.994e+02],
         [-3.629e+02],
         [-2.269e+02],
         [-1.428e+02],
         [ 1.729e+02],
         [-3.893e+02],
         [-4.520e+02],
         [ 2.184e+01],
         [-2.752e+02]],

        [[-4.208e+02],
         [-1.897e+02],
         [-1.574e+02],
         [-2.764e+02],
         [-2.985e+02],
         [-5.446e+01],
         [-4.457e+02],
         [-3.147e+02],
         [-1.946e+02],
         [-1.640e+02]],

        [[-3.966e+02],
         [-3.775e+02],
         [-4.170e+02],
         [-4.973e+02],
         [ 8.122e+02],
         [-4.502e+02],
         [-4.348e+02],
         [ 1.283e+02],
         [-3.912e+02],
         [-4.560e+02]],

        [[-3.405e+02],
         [ 9.985e+01],
         [ 1.296e+02],
         [-4.364e+02],
         [ 5.964e+02],
         [ 4.134e+02],
         [-2.631e+02],
         [-3.261e+02],
         [-3.680e+02],
         [-1.666e+02]],

        [[-3.070e+02],
         [-3.185e+02],
         [-3.161e+02],
         [-2.090e+02],
         [-3.144e+02],
         [ 1.122e+02],
         [-4.315e+02],
         [-5.280e+01],
         [-2.134e+02],
         [-3.998e+02]],

        [[-3.858e+02],
         [-8.722e+01],
         [-3.084e+02],
         [-2.297e+02],
         [-3.662e+02],
         [ 2.885e+02],
         [-4.062e+02],
         [-2.913e+02],
         [-3.930e+02],
         [ 5.356e+02]],

        [[-8.346e+01],
         [-1.426e+02],
         [-4.027e+02],
         [ 8.767e+01],
         [ 1.963e+03],
         [ 1.395e+03],
         [-2.321e+02],
         [-1.730e+01],
         [-3.092e+02],
         [ 3.249e+03]],

        [[-2.866e+02],
         [ 9.395e+00],
         [-3.417e+02],
         [ 2.679e+01],
         [-3.017e+02],
         [ 5.113e+02],
         [-4.073e+02],
         [-1.188e+02],
         [ 1.827e+01],
         [-4.003e+02]],

        [[ 1.832e+01],
         [ 1.508e+03],
         [ 3.779e+02],
         [-3.820e+02],
         [-3.785e+02],
         [-1.871e+01],
         [-3.941e+02],
         [-1.876e+02],
         [-3.440e+02],
         [-1.442e+02]],

        [[-2.665e+02],
         [-2.897e+02],
         [-4.328e+02],
         [-1.850e+02],
         [ 1.469e+02],
         [ 1.137e+03],
         [-3.236e+02],
         [-3.582e+02],
         [-4.011e+02],
         [ 8.609e+00]],

        [[-2.123e+02],
         [-2.176e+02],
         [ 1.310e+02],
         [ 8.558e+02],
         [-2.629e+02],
         [-2.376e+02],
         [-3.812e+02],
         [-3.331e+02],
         [-4.062e+02],
         [ 9.806e+01]],

        [[-3.310e+02],
         [-3.552e+02],
         [-2.535e+02],
         [-2.447e+02],
         [-9.070e+01],
         [ 2.806e+02],
         [-3.872e+02],
         [-1.125e+02],
         [-2.391e+02],
         [ 3.257e+02]],

        [[-2.220e+02],
         [ 9.488e+02],
         [ 5.527e+02],
         [-4.451e+02],
         [-3.512e+02],
         [-3.169e+02],
         [ 6.624e+01],
         [-3.212e+02],
         [ 5.102e+02],
         [-4.056e+02]],

        [[-2.166e+02],
         [ 3.689e+01],
         [-2.933e+02],
         [ 4.155e+02],
         [-3.584e+02],
         [-2.570e+02],
         [-2.097e+02],
         [-2.569e+02],
         [-1.077e+02],
         [ 6.642e+01]],

        [[-4.173e+02],
         [-2.809e+02],
         [-2.802e+02],
         [-1.454e+02],
         [-2.801e+02],
         [ 1.601e+02],
         [-3.478e+02],
         [ 6.916e+02],
         [ 6.569e+01],
         [-3.968e+02]],

        [[ 9.052e+01],
         [-3.145e+02],
         [-2.528e+02],
         [-1.100e+02],
         [-1.669e+02],
         [-3.600e+02],
         [-1.747e+02],
         [-3.518e+02],
         [ 3.868e+02],
         [ 4.907e+00]],

        [[-3.243e+01],
         [-2.495e+02],
         [-4.306e+02],
         [-4.141e+02],
         [ 3.630e+02],
         [ 9.503e+01],
         [ 2.951e+01],
         [-3.173e+02],
         [-1.388e+02],
         [-1.288e+02]],

        [[-3.069e+02],
         [ 2.594e+02],
         [-4.633e+02],
         [ 1.150e+03],
         [-2.718e+02],
         [ 4.655e+02],
         [ 5.061e+02],
         [-3.697e+02],
         [ 2.619e+01],
         [-3.677e+02]],

        [[-3.859e+02],
         [-2.520e+02],
         [-3.192e+02],
         [-3.665e+02],
         [ 1.053e+03],
         [-4.063e+02],
         [ 1.254e+03],
         [-2.553e+02],
         [-4.310e+01],
         [-2.904e+02]],

        [[-1.614e+02],
         [-2.705e+02],
         [ 1.883e+03],
         [-3.189e+02],
         [ 3.285e+02],
         [-3.433e+01],
         [-2.523e+02],
         [ 1.453e+03],
         [-2.736e+02],
         [ 9.705e+02]],

        [[-4.435e+02],
         [-4.083e+02],
         [-7.801e+01],
         [-2.681e+02],
         [-2.035e+02],
         [-2.721e+02],
         [-3.199e+02],
         [-4.756e+02],
         [-7.010e+01],
         [-2.449e+02]],

        [[-2.904e+02],
         [-1.578e+02],
         [-3.866e+02],
         [-3.009e+02],
         [ 3.513e+03],
         [-4.112e+01],
         [ 2.589e+03],
         [-1.207e+01],
         [-2.928e+02],
         [-7.033e+01]],

        [[ 2.263e+00],
         [-2.566e+02],
         [-1.348e+02],
         [-3.738e+02],
         [ 1.577e+03],
         [-4.313e+02],
         [-1.189e+02],
         [-4.261e+02],
         [-1.406e+02],
         [ 1.645e+02]],

        [[ 6.723e+01],
         [-5.327e+01],
         [ 4.099e+02],
         [ 8.817e+02],
         [ 3.157e+02],
         [-2.373e+02],
         [ 1.385e+03],
         [ 8.224e+02],
         [ 5.454e+02],
         [-2.455e+02]],

        [[-3.393e+02],
         [-2.693e+01],
         [ 1.200e+03],
         [-2.783e+02],
         [-3.436e+02],
         [-2.823e+02],
         [-3.395e+02],
         [-2.209e+02],
         [ 4.049e+02],
         [-3.287e+01]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [8.598e+00],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [9.395e+00],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [8.609e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [4.907e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[2.263e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[-453.988],
        [ 480.989],
        [-475.461],
        [-418.695],
        [ 209.593],
        [-340.930],
        [-108.368],
        [-148.614],
        [ 414.740],
        [-443.814],
        [-298.304],
        [ 417.700],
        [-240.592],
        [-433.779],
        [-360.393],
        [-382.801],
        [-411.741],
        [-219.799],
        [ 519.652],
        [-389.427],
        [-104.085],
        [ 346.916],
        [  96.734],
        [-216.900],
        [-244.364],
        [-398.636],
        [-112.343],
        [ 175.195],
        [-328.363],
        [-316.311]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 0.016,  0.012,  0.029,  ..., -0.182,  0.022,  0.223],
        [ 0.027,  0.017,  0.219,  ...,  0.041,  0.038, -0.317],
        [ 0.019, -0.089, -0.197,  ..., -0.004, -0.121, -0.044],
        ...,
        [-0.133,  0.141, -0.300,  ...,  0.060,  0.048,  0.085],
        [-0.223,  0.167, -0.042,  ..., -0.040,  0.669, -0.103],
        [-0.053,  0.131, -0.064,  ...,  0.024, -0.339,  0.046]],
       device='cuda:0')
s after update for 1 param tensor([[1.763, 1.865, 2.144,  ..., 1.899, 1.649, 0.954],
        [1.823, 1.619, 1.380,  ..., 1.813, 1.948, 1.547],
        [1.391, 1.605, 1.493,  ..., 1.792, 1.318, 1.675],
        ...,
        [1.375, 2.207, 1.856,  ..., 1.320, 1.137, 2.125],
        [1.345, 1.741, 2.116,  ..., 1.271, 1.308, 1.613],
        [1.068, 1.765, 1.871,  ..., 1.958, 1.517, 2.119]], device='cuda:0')
b after update for 1 param tensor([[172.293, 177.188, 189.990,  ..., 178.831, 166.618, 126.743],
        [175.173, 165.124, 152.455,  ..., 174.692, 181.107, 161.369],
        [153.032, 164.375, 158.558,  ..., 173.692, 148.947, 167.944],
        ...,
        [152.153, 192.784, 176.756,  ..., 149.098, 138.370, 189.161],
        [150.499, 171.218, 188.762,  ..., 146.291, 148.398, 164.794],
        [134.079, 172.387, 177.507,  ..., 181.569, 159.840, 188.877]],
       device='cuda:0')
clipping threshold 1.3315648888789202
a after update for 1 param tensor([ 0.081, -0.020, -0.207,  0.034,  0.219,  0.090, -0.251, -0.335, -0.032,
         0.351, -0.248,  0.057, -0.184,  0.065,  0.121,  0.281,  0.253,  0.086,
        -0.215,  0.022,  0.107,  0.107, -0.343, -0.124, -0.087, -0.267,  0.037,
        -0.030,  0.047,  0.238, -0.061,  0.084,  0.090, -0.034, -0.285, -0.154,
         0.140,  0.062, -0.147,  0.111,  0.058, -0.235,  0.336,  0.022,  0.102,
        -0.065, -0.096,  0.081,  0.129,  0.224, -0.265,  0.205,  0.159, -0.185,
        -0.187,  0.146, -0.133,  0.052,  0.158, -0.151, -0.239, -0.395, -0.117,
        -0.062, -0.030, -0.027,  0.277,  0.070, -0.138,  0.047,  0.178,  0.003,
        -0.093, -0.025, -0.177,  0.139,  0.020,  0.164, -0.513,  0.055, -0.275,
        -0.523, -0.013, -0.148, -0.036,  0.017, -0.090,  0.024,  0.241, -0.280,
         0.180,  0.093, -0.162,  0.088,  0.041,  0.077,  0.096, -0.312,  0.034,
        -0.090,  0.063, -0.024, -0.212, -0.152,  0.160, -0.325, -0.270,  0.004,
         0.097,  0.153,  0.046,  0.076,  0.147,  0.132, -0.165,  0.283,  0.064,
        -0.020, -0.063,  0.013,  0.062, -0.087,  0.044,  0.093,  0.016,  0.534,
         0.044, -0.032, -0.400, -0.067, -0.138,  0.161, -0.378, -0.055, -0.198,
        -0.189,  0.057,  0.044,  0.205,  0.128, -0.021,  0.083,  0.005,  0.004,
        -0.011, -0.055, -0.292,  0.322,  0.088,  0.044, -0.026, -0.053,  0.444,
         0.016,  0.447,  0.109,  0.419, -0.039,  0.020, -0.155, -0.066, -0.220,
         0.368,  0.329, -0.057, -0.058, -0.040,  0.162,  0.298,  0.024,  0.016,
         0.132,  0.274, -0.206, -0.059, -0.003,  0.068, -0.252, -0.017, -0.009,
        -0.400, -0.021,  0.011,  0.100,  0.065,  0.138,  0.089,  0.264, -0.217,
        -0.040, -0.430, -0.018,  0.316,  0.241,  0.050, -0.058,  0.251, -0.140,
         0.137, -0.527, -0.138,  0.095, -0.297, -0.306,  0.216,  0.114, -0.064,
        -0.067,  0.143, -0.056, -0.083, -0.186,  0.150, -0.136,  0.168, -0.244,
         0.182, -0.329, -0.170, -0.261,  0.019, -0.003,  0.391, -0.354,  0.461,
        -0.191, -0.251,  0.170,  0.070, -0.138,  0.153,  0.173, -0.110,  0.137,
        -0.148, -0.091,  0.067, -0.084, -0.157,  0.222,  0.319, -0.004,  0.126,
        -0.331, -0.333, -0.067, -0.267,  0.068, -0.053, -0.108, -0.057, -0.083,
         0.094,  0.188,  0.118, -0.084, -0.077, -0.261, -0.036, -0.214, -0.014,
         0.018,  0.122, -0.191,  0.059,  0.046, -0.148, -0.127, -0.221,  0.031,
         0.006, -0.157,  0.457, -0.191, -0.041,  0.376,  0.014, -0.057, -0.482,
         0.293, -0.183, -0.158, -0.158,  0.223, -0.140, -0.533, -0.141,  0.640,
        -0.296,  0.410,  0.088, -0.065,  0.127,  0.088, -0.084, -0.447,  0.461,
        -0.336, -0.171, -0.183], device='cuda:0')
s after update for 1 param tensor([1.747, 1.961, 1.912, 1.161, 1.150, 1.948, 1.923, 1.699, 1.957, 2.140,
        1.571, 1.976, 1.395, 1.730, 2.158, 1.696, 1.424, 1.812, 1.577, 1.493,
        2.143, 1.731, 1.526, 2.023, 1.759, 2.183, 2.129, 1.475, 1.901, 2.008,
        1.578, 2.497, 1.574, 1.299, 1.621, 2.056, 1.889, 1.497, 1.818, 2.078,
        1.183, 1.655, 1.841, 1.849, 1.683, 2.147, 1.195, 1.293, 1.282, 1.802,
        1.836, 1.818, 1.882, 1.771, 1.875, 1.502, 1.853, 2.267, 2.133, 1.872,
        1.911, 1.729, 1.820, 1.893, 1.236, 1.655, 1.705, 2.225, 1.868, 1.627,
        1.786, 1.592, 1.456, 1.863, 2.188, 1.517, 1.418, 2.038, 1.491, 1.370,
        2.141, 1.452, 1.935, 1.136, 1.564, 1.595, 1.403, 1.736, 1.837, 1.441,
        1.365, 1.683, 1.623, 1.446, 1.883, 1.517, 1.745, 1.478, 1.828, 1.589,
        0.752, 1.925, 1.976, 1.677, 2.101, 1.514, 1.367, 0.911, 1.590, 1.371,
        2.191, 2.199, 1.953, 1.636, 1.514, 1.453, 1.708, 1.785, 1.332, 1.893,
        1.798, 1.872, 1.895, 1.175, 1.569, 1.706, 1.255, 1.949, 1.771, 1.518,
        2.505, 1.812, 2.024, 1.684, 1.753, 1.428, 2.079, 1.471, 2.061, 1.422,
        1.367, 1.468, 1.899, 1.596, 2.140, 1.375, 1.833, 1.889, 1.090, 1.526,
        1.805, 1.516, 2.131, 1.034, 1.504, 2.084, 1.206, 1.743, 1.948, 2.144,
        1.275, 1.584, 1.659, 2.088, 1.556, 1.820, 1.655, 2.213, 1.400, 1.749,
        1.340, 1.565, 1.690, 2.008, 1.786, 1.731, 2.159, 1.819, 1.679, 1.209,
        2.026, 1.667, 1.140, 1.554, 2.156, 1.998, 2.243, 1.787, 1.829, 1.791,
        2.024, 1.497, 2.183, 1.380, 1.444, 1.549, 2.110, 2.090, 1.892, 1.841,
        1.721, 1.924, 2.076, 1.656, 1.413, 1.590, 1.201, 1.938, 1.717, 1.067,
        1.238, 1.569, 1.683, 1.268, 1.723, 1.609, 2.189, 1.636, 1.579, 1.921,
        2.151, 1.676, 1.932, 2.087, 2.097, 1.566, 1.880, 1.482, 1.272, 1.322,
        1.955, 1.412, 1.516, 1.647, 1.279, 1.924, 1.806, 1.844, 1.832, 1.783,
        2.063, 2.044, 1.768, 1.106, 1.532, 1.481, 2.044, 1.360, 0.824, 1.444,
        1.462, 1.295, 1.585, 1.762, 1.568, 1.889, 1.926, 2.161, 1.832, 1.535,
        1.610, 1.370, 2.158, 1.769, 1.956, 1.410, 1.706, 1.718, 1.539, 1.463,
        1.384, 1.782, 1.779, 1.299, 1.699, 1.375, 1.849, 1.375, 1.878, 2.027,
        1.702, 1.702, 1.872, 0.933, 1.401, 1.818, 1.416, 1.900, 1.773, 1.648,
        1.680, 1.599, 1.640, 1.839, 1.837, 2.182, 1.353, 1.866, 0.947, 2.009],
       device='cuda:0')
b after update for 1 param tensor([171.502, 181.696, 179.428, 139.821, 139.148, 181.121, 179.919, 169.122,
        181.541, 189.807, 162.649, 182.415, 153.231, 170.683, 190.611, 168.971,
        154.841, 174.675, 162.948, 158.552, 189.942, 170.741, 160.303, 184.540,
        172.070, 191.714, 189.324, 157.564, 178.888, 183.888, 162.976, 205.048,
        162.793, 147.861, 165.207, 186.057, 178.360, 158.759, 174.962, 187.052,
        141.134, 166.922, 176.043, 176.425, 168.356, 190.138, 141.823, 147.565,
        146.916, 174.163, 175.840, 174.974, 178.002, 172.659, 177.656, 159.016,
        176.608, 195.368, 189.508, 177.543, 179.390, 170.629, 175.073, 178.544,
        144.232, 166.924, 169.422, 193.530, 177.366, 165.508, 173.399, 163.723,
        156.546, 177.115, 191.912, 159.827, 154.536, 185.224, 158.423, 151.849,
        189.877, 156.345, 180.516, 138.271, 162.280, 163.885, 153.709, 170.981,
        175.886, 155.739, 151.594, 168.339, 165.283, 156.021, 178.062, 159.823,
        171.422, 157.740, 175.444, 163.570, 112.558, 180.027, 182.412, 168.016,
        188.069, 159.645, 151.715, 123.816, 163.627, 151.904, 192.072, 192.418,
        181.321, 165.957, 159.635, 156.411, 169.568, 173.372, 149.777, 178.513,
        174.008, 177.538, 178.597, 140.644, 162.547, 169.492, 145.387, 181.144,
        172.693, 159.858, 205.384, 174.655, 184.577, 168.385, 171.778, 155.048,
        187.099, 157.354, 186.281, 154.753, 151.734, 157.223, 178.796, 163.925,
        189.812, 152.168, 175.686, 178.323, 135.475, 160.307, 174.343, 159.784,
        189.410, 131.914, 159.142, 187.307, 142.520, 171.327, 181.123, 190.002,
        146.493, 163.287, 167.145, 187.495, 161.875, 175.050, 166.950, 193.039,
        153.516, 171.581, 150.197, 162.329, 168.701, 183.885, 173.414, 170.739,
        190.654, 174.978, 168.111, 142.688, 184.699, 167.523, 138.557, 161.773,
        190.535, 183.389, 194.322, 173.440, 175.474, 173.664, 184.581, 158.748,
        191.727, 152.436, 155.898, 161.480, 188.481, 187.577, 178.500, 176.039,
        170.200, 179.981, 186.966, 166.961, 154.224, 163.636, 142.218, 180.650,
        170.013, 134.054, 144.351, 162.528, 168.356, 146.116, 170.326, 164.613,
        191.965, 165.976, 163.033, 179.864, 190.298, 167.986, 180.370, 187.464,
        187.902, 162.377, 177.934, 157.936, 146.326, 149.166, 181.437, 154.207,
        159.738, 166.523, 146.737, 180.005, 174.362, 176.204, 175.609, 173.241,
        186.392, 185.497, 172.522, 136.488, 160.622, 157.914, 185.532, 151.316,
        117.777, 155.946, 156.885, 147.677, 163.334, 172.230, 162.486, 178.315,
        180.075, 190.728, 175.624, 160.784, 164.651, 151.854, 190.633, 172.597,
        181.492, 154.059, 169.471, 170.099, 160.967, 156.953, 152.677, 173.209,
        173.079, 147.862, 169.150, 152.152, 176.457, 152.148, 177.837, 184.737,
        169.279, 169.275, 177.525, 125.304, 153.601, 174.947, 154.409, 178.840,
        172.758, 166.590, 168.201, 164.055, 166.174, 175.953, 175.870, 191.690,
        150.924, 177.246, 126.279, 183.905], device='cuda:0')
clipping threshold 1.3315648888789202
a after update for 1 param tensor([[[ 0.160],
         [-0.289],
         [-0.219],
         [-0.134],
         [-0.233],
         [ 0.274],
         [-0.175],
         [ 0.017],
         [ 0.023],
         [ 0.186]],

        [[-0.235],
         [ 0.269],
         [-0.148],
         [-0.095],
         [ 0.128],
         [ 0.319],
         [ 0.168],
         [-0.158],
         [-0.127],
         [-0.029]],

        [[-0.166],
         [-0.331],
         [-0.069],
         [-0.394],
         [ 0.225],
         [ 0.126],
         [-0.168],
         [-0.318],
         [ 0.405],
         [-0.209]],

        [[ 0.285],
         [ 0.055],
         [ 0.161],
         [ 0.093],
         [ 0.322],
         [ 0.216],
         [ 0.026],
         [ 0.087],
         [ 0.109],
         [-0.080]],

        [[ 0.162],
         [ 0.102],
         [-0.004],
         [ 0.041],
         [ 0.024],
         [-0.300],
         [ 0.078],
         [-0.024],
         [ 0.029],
         [ 0.229]],

        [[ 0.310],
         [-0.109],
         [-0.109],
         [-0.274],
         [-0.048],
         [-0.389],
         [-0.099],
         [ 0.344],
         [-0.165],
         [ 0.453]],

        [[ 0.127],
         [ 0.200],
         [-0.198],
         [-0.052],
         [-0.313],
         [ 0.282],
         [ 0.078],
         [ 0.321],
         [-0.257],
         [-0.046]],

        [[-0.028],
         [ 0.092],
         [ 0.264],
         [ 0.284],
         [-0.183],
         [ 0.298],
         [-0.317],
         [-0.169],
         [-0.082],
         [ 0.087]],

        [[-0.064],
         [ 0.048],
         [-0.113],
         [ 0.094],
         [ 0.168],
         [ 0.088],
         [-0.103],
         [ 0.530],
         [ 0.215],
         [ 0.264]],

        [[-0.153],
         [-0.299],
         [ 0.065],
         [ 0.024],
         [ 0.055],
         [ 0.045],
         [ 0.212],
         [ 0.098],
         [-0.023],
         [-0.132]],

        [[ 0.309],
         [ 0.027],
         [ 0.155],
         [ 0.107],
         [-0.094],
         [-0.213],
         [ 0.190],
         [-0.167],
         [-0.232],
         [-0.193]],

        [[ 0.384],
         [ 0.362],
         [ 0.141],
         [ 0.239],
         [-0.046],
         [ 0.284],
         [ 0.099],
         [-0.053],
         [ 0.175],
         [ 0.004]],

        [[ 0.086],
         [ 0.260],
         [ 0.110],
         [ 0.148],
         [-0.014],
         [-0.147],
         [-0.115],
         [ 0.126],
         [-0.191],
         [ 0.014]],

        [[-0.126],
         [ 0.162],
         [ 0.304],
         [ 0.122],
         [-0.184],
         [-0.334],
         [ 0.165],
         [ 0.059],
         [ 0.051],
         [-0.139]],

        [[ 0.349],
         [ 0.029],
         [ 0.107],
         [ 0.076],
         [ 0.123],
         [ 0.333],
         [-0.034],
         [-0.027],
         [ 0.215],
         [ 0.031]],

        [[ 0.014],
         [-0.353],
         [ 0.314],
         [ 0.372],
         [-0.058],
         [ 0.147],
         [-0.268],
         [ 0.229],
         [ 0.188],
         [-0.047]],

        [[-0.613],
         [ 0.174],
         [-0.191],
         [ 0.054],
         [ 0.153],
         [ 0.086],
         [ 0.387],
         [ 0.014],
         [ 0.056],
         [ 0.341]],

        [[-0.003],
         [ 0.083],
         [-0.049],
         [-0.212],
         [ 0.184],
         [ 0.343],
         [ 0.273],
         [-0.046],
         [ 0.066],
         [-0.091]],

        [[ 0.022],
         [-0.441],
         [ 0.169],
         [ 0.214],
         [ 0.056],
         [-0.379],
         [ 0.231],
         [-0.243],
         [ 0.173],
         [ 0.309]],

        [[ 0.611],
         [ 0.144],
         [-0.128],
         [-0.234],
         [-0.086],
         [-0.189],
         [ 0.042],
         [ 0.041],
         [-0.022],
         [ 0.143]],

        [[-0.260],
         [-0.207],
         [ 0.126],
         [ 0.029],
         [ 0.091],
         [-0.146],
         [-0.157],
         [-0.420],
         [-0.091],
         [-0.068]],

        [[ 0.033],
         [-0.033],
         [ 0.119],
         [ 0.068],
         [-0.314],
         [-0.375],
         [ 0.077],
         [-0.247],
         [ 0.093],
         [-0.060]],

        [[ 0.125],
         [ 0.365],
         [ 0.316],
         [ 0.194],
         [ 0.124],
         [ 0.087],
         [ 0.076],
         [ 0.183],
         [-0.403],
         [-0.027]],

        [[-0.095],
         [-0.183],
         [ 0.010],
         [-0.002],
         [-0.039],
         [-0.043],
         [ 0.254],
         [-0.076],
         [-0.122],
         [ 0.159]],

        [[-0.184],
         [ 0.026],
         [ 0.150],
         [-0.131],
         [ 0.002],
         [-0.190],
         [ 0.119],
         [ 0.030],
         [ 0.083],
         [ 0.099]],

        [[-0.128],
         [-0.293],
         [-0.055],
         [ 0.318],
         [-0.176],
         [ 0.170],
         [-0.042],
         [-0.257],
         [ 0.123],
         [ 0.191]],

        [[ 0.029],
         [ 0.189],
         [ 0.022],
         [ 0.133],
         [-0.214],
         [-0.593],
         [ 0.221],
         [ 0.038],
         [-0.299],
         [-0.056]],

        [[ 0.146],
         [ 0.264],
         [-0.022],
         [ 0.109],
         [ 0.175],
         [-0.048],
         [ 0.068],
         [ 0.167],
         [-0.089],
         [ 0.033]],

        [[ 0.110],
         [ 0.302],
         [-0.046],
         [-0.162],
         [-0.188],
         [ 0.002],
         [-0.084],
         [ 0.119],
         [-0.220],
         [ 0.099]],

        [[ 0.035],
         [-0.221],
         [-0.059],
         [-0.007],
         [ 0.211],
         [ 0.117],
         [-0.033],
         [ 0.268],
         [ 0.468],
         [-0.301]]], device='cuda:0')
s after update for 1 param tensor([[[1.606],
         [1.723],
         [2.052],
         [1.654],
         [1.278],
         [1.354],
         [2.158],
         [1.250],
         [1.308],
         [0.994]],

        [[2.329],
         [1.374],
         [1.244],
         [1.974],
         [1.082],
         [1.533],
         [2.178],
         [1.960],
         [1.444],
         [1.839]],

        [[1.776],
         [1.492],
         [1.944],
         [1.079],
         [1.475],
         [1.782],
         [1.402],
         [1.583],
         [1.435],
         [2.212]],

        [[1.159],
         [1.357],
         [2.255],
         [1.573],
         [1.660],
         [1.529],
         [1.118],
         [2.434],
         [1.693],
         [1.210]],

        [[1.754],
         [1.501],
         [1.931],
         [1.501],
         [1.822],
         [1.627],
         [1.853],
         [1.533],
         [1.917],
         [1.878]],

        [[1.620],
         [1.789],
         [1.602],
         [2.083],
         [1.581],
         [1.626],
         [1.858],
         [1.963],
         [1.956],
         [1.719]],

        [[1.822],
         [1.318],
         [1.190],
         [1.662],
         [1.289],
         [1.294],
         [1.977],
         [1.650],
         [1.041],
         [1.726]],

        [[1.719],
         [1.731],
         [1.964],
         [2.159],
         [2.128],
         [1.952],
         [2.011],
         [2.057],
         [1.709],
         [2.070]],

        [[1.607],
         [1.493],
         [2.046],
         [1.939],
         [2.160],
         [1.699],
         [1.441],
         [1.451],
         [1.673],
         [1.618]],

        [[1.380],
         [2.341],
         [1.657],
         [1.376],
         [1.739],
         [2.273],
         [2.229],
         [1.858],
         [1.639],
         [1.736]],

        [[1.666],
         [1.236],
         [1.655],
         [1.365],
         [1.746],
         [2.272],
         [1.828],
         [1.618],
         [1.697],
         [2.092]],

        [[1.698],
         [1.588],
         [2.257],
         [1.728],
         [2.088],
         [1.698],
         [1.399],
         [1.958],
         [1.373],
         [1.879]],

        [[1.510],
         [1.833],
         [2.246],
         [2.373],
         [1.306],
         [1.631],
         [1.760],
         [1.314],
         [1.895],
         [1.829]],

        [[1.459],
         [1.747],
         [1.909],
         [1.662],
         [1.789],
         [1.474],
         [1.839],
         [1.482],
         [1.645],
         [1.532]],

        [[1.523],
         [1.757],
         [1.870],
         [1.557],
         [1.808],
         [1.915],
         [1.913],
         [1.590],
         [1.759],
         [2.065]],

        [[1.830],
         [1.223],
         [1.787],
         [2.063],
         [1.619],
         [1.636],
         [1.668],
         [1.784],
         [1.770],
         [1.611]],

        [[1.615],
         [1.535],
         [1.814],
         [1.471],
         [1.716],
         [1.930],
         [1.672],
         [1.493],
         [1.824],
         [1.732]],

        [[1.557],
         [2.155],
         [1.859],
         [1.937],
         [1.747],
         [1.562],
         [1.600],
         [1.402],
         [2.209],
         [1.836]],

        [[0.941],
         [2.127],
         [1.797],
         [1.653],
         [1.887],
         [2.211],
         [1.445],
         [1.272],
         [2.065],
         [2.029]],

        [[1.942],
         [1.560],
         [1.494],
         [1.699],
         [1.277],
         [1.848],
         [1.510],
         [1.728],
         [1.902],
         [1.716]],

        [[1.856],
         [1.995],
         [1.583],
         [1.751],
         [1.828],
         [1.587],
         [1.682],
         [1.769],
         [1.586],
         [1.911]],

        [[1.596],
         [2.013],
         [1.886],
         [1.815],
         [2.160],
         [2.151],
         [2.513],
         [1.575],
         [1.115],
         [2.204]],

        [[1.824],
         [2.072],
         [2.070],
         [2.073],
         [1.585],
         [2.042],
         [1.879],
         [1.818],
         [1.765],
         [1.958]],

        [[1.668],
         [1.192],
         [1.857],
         [1.906],
         [1.469],
         [1.755],
         [2.024],
         [1.193],
         [1.652],
         [1.330]],

        [[1.191],
         [1.175],
         [1.965],
         [1.570],
         [1.587],
         [1.714],
         [1.090],
         [2.383],
         [1.603],
         [2.159]],

        [[1.998],
         [1.780],
         [1.048],
         [1.631],
         [1.207],
         [1.775],
         [1.414],
         [2.164],
         [1.649],
         [1.773]],

        [[1.686],
         [1.303],
         [1.856],
         [1.587],
         [2.269],
         [1.238],
         [2.362],
         [1.725],
         [1.548],
         [1.594]],

        [[1.419],
         [1.633],
         [1.133],
         [1.615],
         [2.179],
         [1.863],
         [1.834],
         [1.870],
         [1.215],
         [1.473]],

        [[1.600],
         [1.203],
         [1.741],
         [1.780],
         [2.032],
         [1.971],
         [1.668],
         [2.029],
         [1.769],
         [1.228]],

        [[1.467],
         [1.526],
         [2.284],
         [1.386],
         [1.790],
         [1.219],
         [1.770],
         [2.021],
         [1.566],
         [2.082]]], device='cuda:0')
b after update for 1 param tensor([[[164.462],
         [170.316],
         [185.865],
         [166.900],
         [146.694],
         [151.010],
         [190.599],
         [145.098],
         [148.425],
         [129.339]],

        [[198.017],
         [152.118],
         [144.724],
         [182.299],
         [134.983],
         [160.652],
         [191.491],
         [181.658],
         [155.941],
         [175.949]],

        [[172.913],
         [158.469],
         [180.934],
         [134.769],
         [157.568],
         [173.233],
         [153.626],
         [163.262],
         [155.430],
         [192.972]],

        [[139.716],
         [151.126],
         [194.851],
         [162.713],
         [167.195],
         [160.471],
         [137.210],
         [202.416],
         [168.808],
         [142.733]],

        [[171.843],
         [158.983],
         [180.322],
         [158.996],
         [175.137],
         [165.507],
         [176.629],
         [160.632],
         [179.652],
         [177.803]],

        [[165.149],
         [173.539],
         [164.257],
         [187.276],
         [163.178],
         [165.454],
         [176.864],
         [181.800],
         [181.454],
         [170.100]],

        [[175.152],
         [148.989],
         [141.567],
         [167.298],
         [147.339],
         [147.609],
         [182.433],
         [166.659],
         [132.386],
         [170.494]],

        [[170.099],
         [170.739],
         [181.844],
         [190.656],
         [189.269],
         [181.292],
         [184.001],
         [186.108],
         [169.633],
         [186.704]],

        [[164.506],
         [158.534],
         [185.611],
         [180.690],
         [190.712],
         [169.125],
         [155.744],
         [156.299],
         [167.821],
         [165.074]],

        [[152.431],
         [198.535],
         [167.019],
         [152.188],
         [171.135],
         [195.643],
         [193.708],
         [176.884],
         [166.098],
         [170.951]],

        [[167.483],
         [144.238],
         [166.912],
         [151.611],
         [171.430],
         [195.594],
         [175.422],
         [165.053],
         [169.048],
         [187.688]],

        [[169.077],
         [163.514],
         [194.949],
         [170.574],
         [187.514],
         [169.086],
         [153.451],
         [181.559],
         [152.031],
         [177.857]],

        [[159.423],
         [175.667],
         [194.462],
         [199.897],
         [148.298],
         [165.694],
         [172.150],
         [148.747],
         [178.628],
         [175.473]],

        [[156.734],
         [171.487],
         [179.285],
         [167.278],
         [173.556],
         [157.538],
         [175.938],
         [157.941],
         [166.433],
         [160.628]],

        [[160.147],
         [171.976],
         [177.459],
         [161.911],
         [174.481],
         [179.576],
         [179.470],
         [163.628],
         [172.102],
         [186.480]],

        [[175.543],
         [143.518],
         [173.469],
         [186.380],
         [165.103],
         [165.957],
         [167.570],
         [173.289],
         [172.607],
         [164.695]],

        [[164.897],
         [160.767],
         [174.781],
         [157.359],
         [169.997],
         [180.248],
         [167.802],
         [158.526],
         [175.247],
         [170.781]],

        [[161.911],
         [190.481],
         [176.913],
         [180.588],
         [171.493],
         [162.169],
         [164.144],
         [153.629],
         [192.852],
         [175.794]],

        [[125.875],
         [189.240],
         [173.946],
         [166.840],
         [178.264],
         [192.923],
         [155.975],
         [146.334],
         [186.472],
         [184.829]],

        [[180.830],
         [162.076],
         [158.609],
         [169.140],
         [146.610],
         [176.382],
         [159.455],
         [170.564],
         [178.930],
         [169.993]],

        [[176.766],
         [183.275],
         [163.270],
         [171.718],
         [175.417],
         [163.442],
         [168.282],
         [172.559],
         [163.395],
         [179.373]],

        [[163.917],
         [184.081],
         [178.200],
         [174.811],
         [190.717],
         [190.317],
         [205.685],
         [162.846],
         [137.020],
         [192.655]],

        [[175.261],
         [186.754],
         [186.693],
         [186.804],
         [163.365],
         [185.415],
         [177.864],
         [174.942],
         [172.392],
         [181.567]],

        [[167.602],
         [141.658],
         [176.802],
         [179.129],
         [157.253],
         [171.890],
         [184.599],
         [141.710],
         [166.783],
         [149.652]],

        [[141.605],
         [140.652],
         [181.892],
         [162.595],
         [163.462],
         [169.852],
         [135.466],
         [200.309],
         [164.274],
         [190.659]],

        [[183.410],
         [173.124],
         [132.831],
         [165.730],
         [142.570],
         [172.851],
         [154.292],
         [190.878],
         [166.603],
         [172.762]],

        [[168.498],
         [148.112],
         [176.772],
         [163.453],
         [195.474],
         [144.358],
         [199.425],
         [170.407],
         [161.458],
         [163.827]],

        [[154.542],
         [165.802],
         [138.089],
         [164.914],
         [191.527],
         [177.100],
         [175.741],
         [177.446],
         [143.041],
         [157.494]],

        [[164.129],
         [142.320],
         [171.188],
         [173.138],
         [184.965],
         [182.150],
         [167.592],
         [184.811],
         [172.559],
         [143.804]],

        [[157.171],
         [160.310],
         [196.100],
         [152.780],
         [173.615],
         [143.277],
         [172.622],
         [184.471],
         [162.363],
         [187.217]]], device='cuda:0')
clipping threshold 1.3315648888789202
a after update for 1 param tensor([[ 0.224],
        [-0.409],
        [-0.009],
        [ 0.164],
        [ 0.144],
        [-0.121],
        [-0.127],
        [ 0.031],
        [ 0.170],
        [-0.413],
        [-0.017],
        [ 0.415],
        [ 0.008],
        [-0.067],
        [-0.006],
        [ 0.155],
        [ 0.040],
        [ 0.237],
        [ 0.015],
        [-0.058],
        [ 0.522],
        [ 0.295],
        [-0.053],
        [-0.145],
        [ 0.015],
        [ 0.015],
        [-0.180],
        [ 0.147],
        [-0.031],
        [ 0.260]], device='cuda:0')
s after update for 1 param tensor([[2.073],
        [1.763],
        [2.058],
        [1.814],
        [1.554],
        [2.009],
        [1.665],
        [1.442],
        [1.743],
        [1.920],
        [1.921],
        [2.002],
        [1.594],
        [2.141],
        [1.829],
        [1.854],
        [1.984],
        [1.586],
        [1.962],
        [1.827],
        [1.322],
        [1.742],
        [2.191],
        [1.734],
        [1.501],
        [1.994],
        [1.526],
        [1.868],
        [1.499],
        [1.390]], device='cuda:0')
b after update for 1 param tensor([[186.839],
        [172.276],
        [186.165],
        [174.780],
        [161.766],
        [183.928],
        [167.405],
        [155.790],
        [171.314],
        [179.812],
        [179.826],
        [183.607],
        [163.841],
        [189.852],
        [175.475],
        [176.677],
        [182.783],
        [163.426],
        [181.751],
        [175.370],
        [149.199],
        [171.264],
        [192.050],
        [170.876],
        [158.973],
        [183.206],
        [160.265],
        [177.355],
        [158.887],
        [153.001]], device='cuda:0')
clipping threshold 1.3315648888789202
||w||^2 2.666206343387456
exp ma of ||w||^2 2.520019386525359
||w|| 1.6328522111285688
exp ma of ||w|| 1.5413901227006004
||w||^2 2.1856955107246865
exp ma of ||w||^2 2.5508346908244617
||w|| 1.4784097912029284
exp ma of ||w|| 1.5580106917927377
||w||^2 1.5328232390316623
exp ma of ||w||^2 2.5140234244418505
||w|| 1.238072388445709
exp ma of ||w|| 1.5471416871014099
||w||^2 1.019162566344835
exp ma of ||w||^2 2.5263687494965468
||w|| 1.0095358172669433
exp ma of ||w|| 1.5438588778710158
||w||^2 0.9745185383901702
exp ma of ||w||^2 2.595259466264188
||w|| 0.9871770552389122
exp ma of ||w|| 1.5662894726326573
||w||^2 1.8303580280421192
exp ma of ||w||^2 2.3971451082570545
||w|| 1.3529072503472361
exp ma of ||w|| 1.5103578183035191
||w||^2 3.9090977316579454
exp ma of ||w||^2 2.5446269060413407
||w|| 1.9771438318083856
exp ma of ||w|| 1.556573543892077
||w||^2 2.5919994245254343
exp ma of ||w||^2 2.4147336159627932
||w|| 1.609968765077582
exp ma of ||w|| 1.5125883530424915
||w||^2 2.0628728539878916
exp ma of ||w||^2 2.6058958615240986
||w|| 1.4362704668647517
exp ma of ||w|| 1.5758692199772497
||w||^2 2.2605114527691335
exp ma of ||w||^2 2.424491019907718
||w|| 1.5034997348749795
exp ma of ||w|| 1.5167431687989346
cuda
Objective function 74.92 = squared loss an data 44.26 + 0.5*rho*h**2 6.648882 + alpha*h 21.057091 + L2reg 2.54 + L1reg 0.41 ; SHD = 149 ; DAG True
Proportion of microbatches that were clipped  0.7753517709849588
iteration 1 in inner loop, alpha 57.744293050532875 rho 100.0 h 0.3646609915165193
9630
cuda
Objective function 134.76 = squared loss an data 44.26 + 0.5*rho*h**2 66.488819 + alpha*h 21.057091 + L2reg 2.54 + L1reg 0.41 ; SHD = 149 ; DAG True
||w||^2 3222137418.919651
exp ma of ||w||^2 107686303097.04207
||w|| 56763.874241630576
exp ma of ||w|| 234884.44194615618
||w||^2 33633.15261627872
exp ma of ||w||^2 912863031.6649095
||w|| 183.3934366772124
exp ma of ||w|| 3977.755167903846
||w||^2 2.1350799593869927
exp ma of ||w||^2 2.8573238308576605
||w|| 1.4611912809030148
exp ma of ||w|| 1.6529369191256074
||w||^2 1.9826882704869793
exp ma of ||w||^2 2.8357838701503773
||w|| 1.4080796392558836
exp ma of ||w|| 1.6481900943849923
||w||^2 4.378989933396704
exp ma of ||w||^2 2.920528233859911
||w|| 2.092603625485893
exp ma of ||w|| 1.6685219833132336
||w||^2 1.237547700776044
exp ma of ||w||^2 2.916355706081172
||w|| 1.1124512127621795
exp ma of ||w|| 1.6628885870561423
||w||^2 1.322436651507421
exp ma of ||w||^2 2.829331307939543
||w|| 1.1499724568473024
exp ma of ||w|| 1.6390473730548347
||w||^2 0.8812772968498577
exp ma of ||w||^2 3.005727807011783
||w|| 0.9387637066109116
exp ma of ||w|| 1.6868128039677863
||w||^2 1.295029324550746
exp ma of ||w||^2 2.738517833258445
||w|| 1.1379935520690554
exp ma of ||w|| 1.6097727545469656
||w||^2 3.1859824059176134
exp ma of ||w||^2 2.7991127237325455
||w|| 1.7849320451820045
exp ma of ||w|| 1.6315718250985463
||w||^2 3.3697305247504925
exp ma of ||w||^2 2.9152724755266135
||w|| 1.8356825773402363
exp ma of ||w|| 1.6686410986133442
||w||^2 2.51095283419949
exp ma of ||w||^2 2.7221036526495537
||w|| 1.5845986350491061
exp ma of ||w|| 1.6124317240459554
||w||^2 2.012352936187724
exp ma of ||w||^2 2.8540699706072092
||w|| 1.4185742617810757
exp ma of ||w|| 1.6500456091653062
||w||^2 3.3964544698553247
exp ma of ||w||^2 2.7543455384454765
||w|| 1.84294722383885
exp ma of ||w|| 1.6141024553718206
cuda
Objective function 72.42 = squared loss an data 45.08 + 0.5*rho*h**2 14.415443 + alpha*h 9.804785 + L2reg 2.73 + L1reg 0.39 ; SHD = 141 ; DAG True
Proportion of microbatches that were clipped  0.7792114695340502
iteration 2 in inner loop, alpha 57.744293050532875 rho 1000.0 h 0.16979660310501998
9630
cuda
Objective function 202.16 = squared loss an data 45.08 + 0.5*rho*h**2 144.154432 + alpha*h 9.804785 + L2reg 2.73 + L1reg 0.39 ; SHD = 141 ; DAG True
||w||^2 94641420930.51613
exp ma of ||w||^2 973055773689.202
||w|| 307638.4581461104
exp ma of ||w|| 712083.2186796524
||w||^2 165380631.27898073
exp ma of ||w||^2 34570079676.41199
||w|| 12860.04009632088
exp ma of ||w|| 59969.039378899775
||w||^2 3.575637438801106
exp ma of ||w||^2 127.98921091925713
||w|| 1.8909355987978824
exp ma of ||w|| 1.9458986818095403
||w||^2 3.9258085390198363
exp ma of ||w||^2 44.326304856955396
||w|| 1.9813653219484377
exp ma of ||w|| 1.9800307017079208
||w||^2 5.225222389681442
exp ma of ||w||^2 23.80258689634392
||w|| 2.285874534982496
exp ma of ||w|| 1.986730686894185
||w||^2 3.1967239378475365
exp ma of ||w||^2 3.507599687048938
||w|| 1.7879384603077189
exp ma of ||w|| 1.8100862004152214
||w||^2 2.4338652547216606
exp ma of ||w||^2 3.2844536930059554
||w|| 1.5600850152224592
exp ma of ||w|| 1.7864326935500248
||w||^2 3.880970238717217
exp ma of ||w||^2 3.3245266722884987
||w|| 1.9700178270049278
exp ma of ||w|| 1.7907094260963727
||w||^2 3.3159596263158586
exp ma of ||w||^2 3.2210929302579716
||w|| 1.8209776567316411
exp ma of ||w|| 1.759591296414074
||w||^2 2.6589611591246753
exp ma of ||w||^2 3.4172378248332667
||w|| 1.6306321348252264
exp ma of ||w|| 1.8042760607034867
||w||^2 3.671597116091661
exp ma of ||w||^2 3.5658410642047023
||w|| 1.916141204632806
exp ma of ||w|| 1.842569240764902
||w||^2 2.117589677302386
exp ma of ||w||^2 3.396817545174398
||w|| 1.4551940342450507
exp ma of ||w|| 1.7987061238197717
v before min max tensor([[ 293.557, -232.658,   78.268,  ..., -208.668, -176.831,  -38.665],
        [ 192.523,  294.327, -149.037,  ..., -273.372, -593.145, -396.915],
        [-605.026,  341.971, -337.195,  ..., 5371.121, -527.050, -409.176],
        ...,
        [1332.863, -413.478, -532.404,  ..., -437.757, -375.214, -442.856],
        [-449.003, 1081.638,  592.410,  ...,  729.046, -180.392, 1231.390],
        [ 191.610,  912.644, -576.554,  ..., -290.706,  235.541, -259.888]],
       device='cuda:0')
v tensor([[1.000e+01, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e+01, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.000e+01],
        [1.000e+01, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         1.000e-12]], device='cuda:0')
v before min max tensor([  41.618,  183.687, -563.417, -485.210,  -63.473,  -49.832,  204.698,
        -506.158, -478.337,  632.455,  523.894,  279.900, -229.064, -325.531,
        -499.032, 1008.149, -432.074, -308.702,  209.660, 1146.951,  234.295,
        -327.610, -155.287, -568.822,  428.653,  378.650, -505.297,  -64.863,
         144.017, -471.762,  448.284, -132.101, -165.929, -404.442,  510.480,
         -92.942, -335.707, -375.077, -347.965,  724.106, -209.918,   59.320,
        -283.443, -281.650,  553.237,  366.725, 2632.572, -297.485, 2997.002,
        -121.515, -184.818,  275.445, -313.441, -506.855,  223.826, -316.334,
         363.637, -542.856, -514.678, -507.647, -350.506, -483.369, -149.720,
        -103.215, -360.921, -417.577,  151.576, -376.884, 1177.499, -226.810,
        1274.808, -478.089, -303.750, -308.741, -302.750, -351.957,  584.370,
        -390.015, -476.725, -349.849, -442.316, -510.974, -487.765,  590.674,
        -411.154, -343.315, -195.229,  300.028, -357.624, -150.483, -125.929,
         225.600,  -43.271, -199.878,   60.844, -487.062, -360.277, -437.174,
        -278.989, -253.210,   12.737, 2076.747, -370.032,  127.305, -322.248,
        -467.434, -559.767, -240.210, -531.932,  211.424, -380.566, -202.161,
         -85.178,  452.901, -122.733,  791.161,  497.273,  308.469, -406.033,
        -375.065, -339.944,  483.020, -479.814, -462.655, -454.297, -132.511,
        -255.474, -265.055, 1228.480, -236.120,  353.495,  830.420, -481.308,
        -304.785,  469.095, -420.136, -467.293, -247.983, -221.600, -466.559,
        -347.021, -200.604, -300.412,  304.348, -139.666, -347.355, -252.397,
        -563.680, -295.334, -509.508, -366.155, -215.853, 2297.351, -406.251,
        -436.896,    7.824,  514.147, -628.208,  129.788, -489.011,  -34.968,
        -397.435, -139.310, -346.016, -276.775, -334.446, -170.932, -564.312,
        -503.462, -359.188, 2590.159, -511.943,  796.848, -390.976, -320.728,
        -284.984, -235.175, -367.208,  131.088, -363.198, -497.878,   93.907,
        -435.681, -390.692, -380.040, -371.701, -222.696, -294.703, -383.993,
        -439.434,  950.730, -229.151, 1337.735, -467.625,   64.812,    9.731,
        -485.115,  516.700, -189.032, -298.389, -374.536,   32.776, -519.859,
           6.027,  171.909, -205.421, -328.956, 1492.837,  283.883, -356.252,
        -344.322, -358.465, -296.863,   40.543,   32.200, -144.794, -425.572,
        -112.616, -323.569,  238.532,  942.884, -381.642, -439.363, -149.028,
        1391.076,  468.998, -487.179, -238.034, -473.362, -344.436, -417.182,
        -391.599, -281.909,  808.800,  161.804, -351.277, 1103.157, -413.793,
        -472.976, 1584.073, 1277.839,  652.117, -409.086, -549.637, -145.346,
          37.341, -641.494, -213.507, -519.249, -565.292,  232.315, -432.120,
         -51.673, -413.573, -486.362, -477.045, -490.340,  439.003, -452.612,
        -332.882,   67.844, -375.695,  665.731, -227.935, -349.845, -358.666,
          27.792, -177.355,  186.939, -361.429, -437.097, -258.584, -251.966,
         773.156, -415.756,  348.524, -447.320, -242.791, -175.749, -462.399,
         128.384, -343.259, -501.006, -431.385,    3.411,  305.993,   12.789,
        -178.337, -288.722,  649.173, -505.436, -432.334,    8.792, 1168.201,
        -447.918, -228.234, -284.263,  -35.798,  664.630, -151.816],
       device='cuda:0')
v tensor([1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 7.824e+00,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 9.731e+00, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 6.027e+00,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 3.411e+00, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 8.792e+00, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-386.858],
         [-321.995],
         [-285.433],
         [-184.746],
         [ 229.238],
         [ 565.112],
         [-354.884],
         [-409.499],
         [-444.356],
         [ 795.371]],

        [[-442.516],
         [-194.320],
         [ 556.014],
         [-390.785],
         [-131.984],
         [ 656.896],
         [2083.278],
         [-590.511],
         [-597.878],
         [-364.732]],

        [[  21.062],
         [-351.564],
         [-333.517],
         [-444.241],
         [-426.291],
         [2143.783],
         [-398.543],
         [ -89.836],
         [-177.346],
         [ 933.100]],

        [[ -12.122],
         [-365.604],
         [-271.968],
         [-331.044],
         [ 329.217],
         [-291.432],
         [1147.032],
         [ 351.876],
         [-486.119],
         [-309.908]],

        [[-262.381],
         [-249.194],
         [ 217.917],
         [-495.808],
         [-233.172],
         [-447.615],
         [-487.520],
         [ 350.029],
         [-440.225],
         [-117.194]],

        [[5069.666],
         [-286.820],
         [1751.099],
         [-388.442],
         [-506.133],
         [1698.345],
         [-459.333],
         [ -71.541],
         [ 915.769],
         [-206.130]],

        [[ 376.753],
         [-459.016],
         [ -56.146],
         [3776.963],
         [ 961.856],
         [-360.794],
         [-321.486],
         [-144.492],
         [ 227.979],
         [-225.565]],

        [[-204.838],
         [-204.844],
         [-351.003],
         [-369.223],
         [-221.761],
         [ 104.143],
         [-501.121],
         [  75.019],
         [-418.962],
         [ 212.516]],

        [[1220.900],
         [  96.178],
         [-388.959],
         [-564.830],
         [  46.425],
         [-561.692],
         [-470.311],
         [-407.281],
         [-374.372],
         [1172.659]],

        [[ 193.798],
         [  56.754],
         [-406.497],
         [-149.047],
         [-439.263],
         [-205.272],
         [-412.324],
         [-373.792],
         [-347.850],
         [4466.441]],

        [[-568.796],
         [-372.849],
         [-415.297],
         [ -35.922],
         [-444.581],
         [-481.235],
         [ 373.555],
         [-201.353],
         [ 344.418],
         [ 596.374]],

        [[1803.771],
         [-363.060],
         [-276.652],
         [-317.112],
         [-250.288],
         [-506.369],
         [ 953.848],
         [-446.315],
         [1198.895],
         [ 217.327]],

        [[-241.481],
         [ -73.105],
         [ 388.282],
         [-289.629],
         [-249.974],
         [-112.439],
         [-297.041],
         [1013.987],
         [-262.892],
         [ 307.247]],

        [[-422.240],
         [-156.948],
         [-423.621],
         [-481.913],
         [-321.423],
         [ 129.768],
         [ 659.344],
         [-332.578],
         [ -56.456],
         [-301.603]],

        [[ -74.468],
         [-410.047],
         [ 333.088],
         [  95.233],
         [ 127.833],
         [-582.089],
         [-288.327],
         [ 155.248],
         [-434.432],
         [1393.839]],

        [[-455.175],
         [1032.414],
         [-121.187],
         [-379.928],
         [-120.564],
         [-361.334],
         [-428.375],
         [-293.256],
         [1524.601],
         [  33.052]],

        [[-329.834],
         [-351.808],
         [-366.490],
         [-324.949],
         [-502.400],
         [-388.023],
         [ 153.402],
         [-505.627],
         [ 517.235],
         [2527.371]],

        [[-284.081],
         [ -36.956],
         [ 491.521],
         [-116.762],
         [-265.683],
         [-532.116],
         [-614.443],
         [-299.002],
         [ 589.735],
         [ 193.885]],

        [[-310.251],
         [-405.524],
         [-444.471],
         [ 355.577],
         [  72.639],
         [  69.953],
         [-500.814],
         [ -97.761],
         [-422.915],
         [-456.695]],

        [[-310.751],
         [ 358.506],
         [-449.565],
         [-575.624],
         [-228.607],
         [-347.911],
         [-207.021],
         [-177.355],
         [-212.637],
         [-158.043]],

        [[ 134.171],
         [-344.291],
         [ 326.368],
         [2413.448],
         [ 343.254],
         [-438.520],
         [1277.978],
         [-278.461],
         [ -62.262],
         [ 635.619]],

        [[-414.127],
         [ 578.758],
         [-486.558],
         [-356.948],
         [-590.046],
         [ 521.225],
         [ 117.667],
         [-249.587],
         [2224.132],
         [-313.644]],

        [[ 424.119],
         [-186.121],
         [-316.232],
         [-243.474],
         [-408.183],
         [-450.633],
         [-490.700],
         [-216.924],
         [ 639.451],
         [ 155.598]],

        [[-412.650],
         [-220.817],
         [-428.489],
         [ 985.599],
         [ 986.348],
         [-431.430],
         [-364.409],
         [-481.219],
         [-211.329],
         [ 472.831]],

        [[ -91.816],
         [-459.313],
         [-242.522],
         [1670.410],
         [ 165.742],
         [-290.632],
         [-569.489],
         [-306.757],
         [1495.273],
         [  74.367]],

        [[-436.292],
         [-553.307],
         [-120.885],
         [-189.557],
         [-516.330],
         [-363.629],
         [-381.888],
         [4227.421],
         [  13.845],
         [1363.400]],

        [[-511.555],
         [-378.446],
         [1567.027],
         [ 645.009],
         [-430.554],
         [-531.695],
         [-316.148],
         [-249.740],
         [-495.944],
         [ 434.812]],

        [[  88.457],
         [ -65.607],
         [-311.365],
         [ -68.155],
         [1770.721],
         [1537.258],
         [-269.251],
         [  44.659],
         [  89.358],
         [  15.240]],

        [[-484.349],
         [-204.139],
         [ 482.975],
         [ 191.743],
         [2285.491],
         [-547.286],
         [ 669.097],
         [ 495.224],
         [-362.615],
         [-108.551]],

        [[1609.394],
         [1508.230],
         [-179.944],
         [-505.526],
         [-266.123],
         [ 326.886],
         [1809.952],
         [-454.207],
         [-175.825],
         [-128.525]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[ 411.150],
        [ 336.461],
        [ -51.929],
        [ 448.710],
        [3491.824],
        [-259.093],
        [-380.810],
        [-400.662],
        [-487.274],
        [ 163.028],
        [-256.440],
        [ 269.166],
        [-203.731],
        [-411.342],
        [-511.113],
        [ 162.076],
        [-341.437],
        [-292.197],
        [-497.736],
        [ -89.567],
        [-134.139],
        [-307.578],
        [-493.665],
        [-507.175],
        [ 463.578],
        [-323.468],
        [-503.861],
        [ 159.127],
        [-203.840],
        [ -14.404]], device='cuda:0')
v tensor([[1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-0.044, -0.118,  0.129,  ..., -0.196,  0.125, -0.117],
        [ 0.094,  0.304,  0.126,  ..., -0.288,  0.035,  0.119],
        [ 0.097, -0.294,  0.199,  ..., -0.223, -0.056,  0.193],
        ...,
        [ 0.029,  0.097, -0.022,  ...,  0.306, -0.051, -0.008],
        [ 0.167,  0.112,  0.010,  ..., -0.046, -0.039, -0.012],
        [-0.009,  0.051,  0.027,  ...,  0.376,  0.066, -0.110]],
       device='cuda:0')
s after update for 1 param tensor([[1.750, 0.909, 1.803,  ..., 1.880, 1.811, 1.711],
        [2.504, 1.866, 1.210,  ..., 1.517, 2.238, 1.436],
        [2.205, 1.541, 1.697,  ..., 2.464, 1.894, 1.627],
        ...,
        [1.927, 1.779, 1.913,  ..., 1.961, 1.599, 1.971],
        [1.888, 1.578, 2.161,  ..., 1.668, 1.494, 1.613],
        [2.238, 1.937, 2.080,  ..., 1.772, 1.719, 2.255]], device='cuda:0')
b after update for 1 param tensor([[176.037, 126.894, 178.710,  ..., 182.468, 179.085, 174.099],
        [210.581, 181.795, 146.425,  ..., 163.931, 199.105, 159.468],
        [197.629, 165.230, 173.373,  ..., 208.887, 183.179, 169.739],
        ...,
        [184.744, 177.501, 184.076,  ..., 186.353, 168.304, 186.822],
        [182.860, 167.202, 195.638,  ..., 171.870, 162.696, 169.030],
        [199.107, 185.209, 191.944,  ..., 177.139, 174.512, 199.864]],
       device='cuda:0')
clipping threshold 1.428237589973016
a after update for 1 param tensor([-1.450e-01,  2.426e-01, -1.690e-01, -9.405e-02, -2.313e-01,  8.336e-02,
        -1.207e-01,  3.418e-01,  1.660e-01, -6.214e-02,  3.060e-02,  1.335e-01,
        -4.488e-01,  4.494e-01,  1.923e-01,  8.607e-02,  1.689e-02,  3.209e-02,
         3.476e-01, -1.172e-03, -1.430e-01,  8.519e-02,  5.851e-01,  4.565e-01,
         3.676e-01, -1.243e-02, -3.113e-01, -7.131e-02,  1.059e-01,  2.432e-01,
        -3.569e-01,  4.149e-01, -2.416e-01,  1.835e-02,  2.577e-01, -8.970e-02,
         1.616e-01, -4.644e-01, -3.258e-01,  1.581e-01, -1.229e-01, -1.849e-01,
        -2.722e-01, -3.298e-01,  6.527e-02,  2.073e-01,  3.270e-01, -6.746e-03,
        -3.547e-01,  6.971e-02, -1.427e-02,  4.036e-01, -5.878e-02,  6.398e-02,
        -3.661e-01,  2.402e-01, -2.288e-01,  2.088e-01,  6.190e-02,  1.801e-01,
        -2.662e-01,  1.647e-02, -2.170e-01, -2.821e-01, -6.138e-01,  6.065e-01,
         2.244e-03, -9.750e-02,  3.537e-01, -2.653e-02, -2.942e-02, -3.469e-01,
         2.331e-01,  1.304e-01,  1.000e-01,  3.216e-01, -4.656e-02,  2.762e-01,
        -1.497e-01, -2.601e-02, -7.254e-02,  1.062e-01, -6.536e-02,  3.315e-01,
        -2.709e-01, -4.037e-01,  9.593e-02, -1.626e-01, -2.666e-01, -5.168e-01,
         6.916e-02,  2.213e-01, -5.911e-04,  1.997e-02, -1.616e-01, -1.073e-01,
         6.376e-02, -1.787e-01, -6.118e-02,  3.167e-01,  1.642e-02,  7.049e-01,
        -3.159e-02, -2.955e-01,  1.163e-01, -1.205e-03, -1.599e-01,  2.191e-01,
         1.965e-01, -3.181e-01,  1.518e-01,  1.323e-01, -4.280e-01, -2.381e-01,
        -2.271e-01,  1.401e-01,  2.996e-01, -1.387e-01,  1.841e-01, -1.234e-01,
        -2.415e-01, -2.931e-02, -1.261e-01,  1.087e-02,  2.934e-02,  5.867e-01,
         5.213e-02,  4.906e-02, -1.823e-03, -7.285e-02, -4.572e-02,  8.187e-03,
         5.135e-02,  3.050e-01,  5.374e-02, -2.724e-01, -4.197e-02,  3.860e-01,
         3.524e-02, -1.216e-01, -2.123e-01, -1.061e-01, -3.049e-01,  2.213e-01,
         2.761e-03, -7.261e-02,  2.470e-01, -1.169e-01,  2.089e-02,  2.111e-01,
         1.181e-01,  2.076e-03,  3.594e-01, -1.110e-01,  9.749e-02, -3.231e-02,
         9.829e-02, -9.392e-02, -3.953e-01, -3.064e-01,  2.255e-02,  7.199e-02,
         1.312e-01,  8.988e-02,  6.741e-03,  2.698e-02, -2.158e-01, -9.171e-02,
        -7.171e-03,  1.777e-01, -5.290e-02, -5.654e-02, -7.101e-02, -4.088e-01,
        -3.953e-02,  3.316e-01,  1.052e-01, -5.028e-02,  9.892e-02,  1.861e-01,
        -3.799e-02, -6.209e-02,  1.265e-01,  1.120e-01, -1.775e-01, -2.253e-01,
        -1.745e-01,  4.283e-01, -1.984e-01,  2.737e-01,  6.660e-02,  2.099e-01,
         1.111e-01, -1.684e-01, -1.874e-01,  3.148e-01,  3.418e-01,  3.078e-01,
         1.660e-01,  2.978e-01,  2.651e-01, -2.210e-01,  3.188e-01, -8.851e-02,
         5.439e-01,  3.872e-01,  2.047e-01, -1.392e-01, -3.133e-02,  9.989e-02,
         6.855e-02,  4.815e-01,  2.707e-01, -2.060e-01,  1.571e-01,  5.469e-02,
        -2.634e-01, -2.408e-01,  1.973e-01, -2.095e-01, -2.522e-01, -1.028e-01,
         2.990e-01, -5.905e-02,  8.846e-03,  2.165e-01,  2.324e-01,  1.115e-01,
         8.735e-02,  3.055e-01,  2.419e-02, -1.751e-01, -2.083e-01,  6.095e-02,
        -1.102e-01, -3.632e-01,  9.145e-02, -1.668e-01, -2.793e-02,  1.751e-01,
         3.697e-01,  2.248e-01,  1.052e-01,  2.344e-01, -3.436e-01,  1.687e-01,
         1.931e-01,  2.591e-01, -5.753e-01,  4.935e-02, -3.554e-01, -7.466e-02,
         5.395e-01,  1.191e-01, -7.022e-02,  2.500e-01, -5.845e-03,  4.447e-01,
         2.469e-01, -1.857e-01,  3.745e-02, -1.190e-01,  7.857e-03, -7.160e-02,
        -3.506e-01, -4.884e-01, -3.033e-01,  1.124e-01,  4.927e-02, -2.515e-01,
         1.611e-01,  1.563e-02, -4.725e-01, -1.271e-01,  3.626e-02, -3.347e-01,
         1.434e-01, -1.020e-02, -3.572e-02, -5.287e-01,  1.024e-01, -2.357e-01,
        -1.004e-01, -4.737e-03,  1.226e-01, -3.087e-01,  1.171e-01,  2.410e-01,
         1.510e-01, -4.176e-01,  1.878e-02, -4.378e-01, -6.254e-01, -4.285e-02,
        -6.283e-02,  2.179e-01, -3.861e-01,  1.360e-01,  5.024e-01,  3.049e-01],
       device='cuda:0')
s after update for 1 param tensor([1.884, 1.874, 2.028, 1.768, 1.352, 1.611, 2.296, 1.826, 1.767, 2.246,
        2.272, 1.644, 1.516, 1.363, 1.940, 1.639, 1.564, 1.972, 1.842, 1.770,
        2.110, 1.244, 1.753, 2.077, 1.791, 2.097, 2.056, 1.911, 1.741, 1.916,
        2.008, 1.261, 0.693, 1.490, 2.037, 2.202, 1.302, 1.814, 1.324, 2.165,
        1.661, 1.774, 1.820, 1.318, 2.365, 1.631, 1.860, 2.316, 2.109, 1.524,
        2.099, 1.793, 1.684, 2.119, 1.942, 2.169, 2.011, 1.987, 2.039, 1.828,
        1.581, 1.878, 1.193, 1.845, 1.530, 1.667, 2.049, 1.368, 2.115, 1.645,
        1.909, 1.724, 1.295, 1.727, 1.584, 1.547, 2.306, 1.440, 1.718, 1.984,
        1.621, 1.948, 1.827, 1.995, 1.829, 1.532, 1.692, 2.016, 1.319, 1.547,
        1.857, 2.061, 1.184, 1.129, 1.727, 1.750, 1.493, 1.774, 1.770, 1.796,
        2.159, 2.070, 1.422, 1.727, 1.345, 1.865, 2.015, 1.864, 1.929, 2.474,
        1.956, 1.378, 1.336, 2.436, 1.199, 2.253, 2.304, 1.663, 1.747, 1.633,
        1.675, 2.056, 1.755, 1.663, 1.632, 1.532, 1.431, 1.786, 1.988, 1.281,
        1.776, 2.187, 1.731, 2.023, 1.844, 1.613, 1.744, 1.603, 0.802, 1.679,
        2.155, 1.538, 1.651, 1.706, 2.073, 2.195, 1.311, 2.043, 1.689, 1.872,
        1.860, 1.631, 2.171, 1.669, 1.593, 1.753, 2.185, 2.329, 1.600, 1.758,
        1.427, 1.523, 1.271, 1.607, 0.994, 1.691, 1.502, 2.066, 1.872, 1.594,
        1.904, 1.940, 1.799, 1.423, 1.275, 1.856, 1.493, 1.471, 1.643, 1.478,
        1.830, 1.791, 2.137, 1.403, 1.723, 1.387, 1.388, 1.214, 1.886, 1.757,
        1.747, 1.545, 2.452, 2.027, 1.975, 2.318, 1.746, 1.521, 1.599, 1.681,
        1.794, 2.157, 1.997, 1.959, 2.012, 1.663, 1.784, 1.673, 1.773, 1.279,
        1.377, 2.032, 1.703, 2.020, 1.353, 1.324, 1.620, 0.765, 1.346, 2.230,
        2.064, 2.339, 2.082, 1.787, 1.979, 2.064, 1.865, 1.683, 1.763, 1.577,
        1.728, 1.678, 1.313, 1.543, 1.965, 1.397, 2.139, 1.620, 2.014, 2.061,
        2.164, 2.124, 1.470, 1.976, 1.975, 1.903, 2.304, 1.517, 1.879, 2.115,
        1.819, 1.702, 1.638, 1.775, 1.750, 2.044, 1.909, 1.720, 1.634, 1.596,
        1.789, 1.350, 2.010, 1.937, 1.419, 1.502, 1.990, 0.861, 2.325, 1.565,
        1.731, 1.819, 1.191, 2.095, 1.658, 1.653, 1.769, 1.133, 1.395, 1.904,
        1.656, 1.388, 1.915, 1.550, 2.314, 1.398, 1.785, 1.438, 1.498, 2.126,
        1.891, 1.560, 1.841, 2.027, 1.615, 1.192, 1.711, 1.646, 1.852, 1.402],
       device='cuda:0')
b after update for 1 param tensor([182.666, 182.168, 189.541, 176.943, 154.746, 168.914, 201.680, 179.842,
        176.925, 199.430, 200.603, 170.646, 163.881, 155.372, 185.375, 170.367,
        166.414, 186.904, 180.620, 177.042, 193.342, 148.453, 176.202, 191.821,
        178.089, 192.701, 190.824, 183.964, 175.612, 184.222, 188.607, 149.442,
        110.781, 162.446, 189.936, 197.468, 151.868, 179.257, 153.126, 195.804,
        171.499, 177.279, 179.521, 152.776, 204.679, 169.988, 181.483, 202.515,
        193.292, 164.298, 192.816, 178.213, 172.704, 193.720, 185.470, 195.984,
        188.719, 187.602, 190.044, 179.949, 167.350, 182.395, 145.342, 180.795,
        164.620, 171.830, 190.519, 155.686, 193.551, 170.704, 183.871, 174.722,
        151.433, 174.876, 167.505, 165.507, 202.113, 159.701, 174.416, 187.472,
        169.455, 185.736, 179.868, 187.971, 179.973, 164.730, 173.137, 188.954,
        152.821, 165.507, 181.367, 191.071, 144.785, 141.434, 174.898, 176.081,
        162.631, 177.267, 177.038, 178.374, 195.558, 191.458, 158.702, 174.921,
        154.344, 181.745, 188.896, 181.696, 184.858, 209.330, 186.140, 156.237,
        153.844, 207.715, 145.727, 199.770, 201.995, 171.638, 175.926, 170.078,
        172.240, 190.825, 176.290, 171.604, 170.013, 164.736, 159.227, 177.840,
        187.628, 150.640, 177.384, 196.806, 175.092, 189.299, 180.711, 169.017,
        175.774, 168.501, 119.160, 172.468, 195.383, 165.046, 171.017, 173.824,
        191.597, 197.157, 152.385, 190.242, 172.980, 182.091, 181.516, 169.981,
        196.083, 171.929, 167.990, 176.212, 196.745, 203.093, 168.323, 176.436,
        158.986, 164.239, 150.069, 168.718, 132.691, 173.086, 163.080, 191.298,
        182.105, 168.051, 183.618, 185.392, 178.521, 158.740, 150.282, 181.294,
        162.626, 161.433, 170.602, 161.781, 180.055, 178.120, 194.557, 157.658,
        174.688, 156.756, 156.798, 146.654, 182.787, 176.427, 175.926, 165.431,
        208.397, 189.484, 187.016, 202.627, 175.866, 164.142, 168.280, 172.561,
        178.234, 195.459, 188.078, 186.289, 188.784, 171.620, 177.757, 172.122,
        177.227, 150.541, 156.167, 189.699, 173.659, 189.137, 154.799, 153.112,
        169.407, 116.435, 154.391, 198.726, 191.211, 203.521, 192.031, 177.901,
        187.207, 191.207, 181.749, 172.663, 176.726, 167.119, 174.956, 172.385,
        152.502, 165.316, 186.540, 157.302, 194.637, 169.394, 188.876, 191.052,
        195.770, 193.976, 161.332, 187.087, 187.051, 183.609, 202.027, 163.931,
        182.416, 193.528, 179.481, 173.620, 170.314, 177.307, 176.049, 190.252,
        183.875, 174.557, 170.115, 168.151, 178.029, 154.611, 188.697, 185.228,
        158.552, 163.081, 187.728, 123.506, 202.949, 166.517, 175.077, 179.477,
        145.251, 192.643, 171.359, 171.090, 177.001, 141.640, 157.209, 183.635,
        171.283, 156.813, 184.180, 165.680, 202.456, 157.371, 177.807, 159.617,
        162.914, 194.060, 183.023, 166.213, 180.561, 189.492, 169.145, 145.272,
        174.082, 170.748, 181.108, 157.573], device='cuda:0')
clipping threshold 1.428237589973016
a after update for 1 param tensor([[[ 3.581e-02],
         [ 4.002e-01],
         [-5.767e-02],
         [ 1.178e-01],
         [ 4.494e-02],
         [-6.133e-02],
         [-3.154e-01],
         [-3.694e-03],
         [ 9.017e-02],
         [ 3.075e-01]],

        [[ 4.679e-02],
         [-3.496e-01],
         [ 6.977e-01],
         [-2.853e-01],
         [ 1.628e-01],
         [-4.730e-02],
         [ 5.454e-02],
         [-1.459e-01],
         [-3.258e-01],
         [ 2.809e-01]],

        [[-2.774e-01],
         [ 4.528e-02],
         [ 3.087e-01],
         [ 3.026e-01],
         [ 4.279e-02],
         [ 1.137e-01],
         [ 5.267e-02],
         [ 2.596e-02],
         [-3.370e-01],
         [-1.718e-01]],

        [[ 5.428e-02],
         [-4.134e-01],
         [-3.264e-01],
         [ 3.865e-01],
         [-5.925e-03],
         [ 4.492e-01],
         [-2.277e-04],
         [ 1.474e-01],
         [ 2.711e-01],
         [ 1.327e-01]],

        [[ 3.365e-01],
         [-4.530e-01],
         [ 2.017e-01],
         [ 9.664e-02],
         [ 2.460e-01],
         [ 3.636e-01],
         [-7.785e-02],
         [-5.026e-02],
         [ 2.921e-01],
         [ 2.875e-01]],

        [[-6.705e-02],
         [-2.871e-01],
         [-9.735e-02],
         [-4.085e-02],
         [-2.453e-01],
         [-4.023e-01],
         [-1.666e-01],
         [-2.244e-01],
         [-5.947e-02],
         [-1.519e-01]],

        [[-2.317e-01],
         [ 1.330e-01],
         [-1.940e-01],
         [-2.135e-01],
         [ 3.811e-01],
         [ 1.476e-01],
         [ 2.732e-01],
         [-1.120e-01],
         [-1.545e-01],
         [ 8.214e-02]],

        [[ 3.530e-02],
         [ 3.037e-01],
         [ 1.500e-01],
         [-2.827e-01],
         [ 1.113e-01],
         [-2.643e-01],
         [-1.060e-01],
         [ 2.580e-01],
         [-2.915e-01],
         [ 1.755e-01]],

        [[-3.195e-03],
         [ 1.739e-01],
         [-3.029e-01],
         [-7.609e-03],
         [ 2.274e-01],
         [ 7.110e-01],
         [ 1.073e-01],
         [ 2.572e-01],
         [-3.906e-02],
         [-7.473e-02]],

        [[ 2.285e-01],
         [ 3.786e-02],
         [-1.263e-02],
         [ 2.077e-01],
         [ 1.676e-01],
         [ 1.197e-01],
         [ 1.540e-01],
         [ 1.540e-01],
         [ 2.221e-01],
         [ 3.764e-01]],

        [[ 4.744e-01],
         [-2.552e-01],
         [ 4.875e-01],
         [-1.281e-01],
         [-8.614e-02],
         [ 2.585e-01],
         [ 2.335e-01],
         [-1.110e-01],
         [ 2.085e-01],
         [ 3.911e-01]],

        [[-3.465e-01],
         [-1.905e-01],
         [ 9.479e-02],
         [ 1.255e-01],
         [-2.585e-01],
         [-2.960e-02],
         [-8.612e-02],
         [ 4.631e-01],
         [ 5.115e-01],
         [-3.369e-01]],

        [[-8.818e-02],
         [ 3.560e-01],
         [-1.941e-01],
         [ 3.843e-01],
         [ 2.245e-01],
         [-2.120e-01],
         [-9.885e-02],
         [ 4.116e-01],
         [ 2.975e-01],
         [-1.696e-01]],

        [[ 2.254e-01],
         [ 1.994e-01],
         [ 3.213e-02],
         [ 1.018e-01],
         [ 2.851e-01],
         [ 7.317e-02],
         [ 3.914e-01],
         [ 1.276e-01],
         [-2.816e-02],
         [-2.389e-01]],

        [[-2.936e-01],
         [ 6.064e-02],
         [-2.225e-01],
         [-3.204e-01],
         [-5.086e-02],
         [-1.034e-01],
         [ 2.541e-01],
         [ 4.318e-01],
         [ 9.277e-02],
         [-9.864e-02]],

        [[ 3.650e-01],
         [-9.862e-02],
         [-1.672e-02],
         [ 1.114e-01],
         [-3.990e-01],
         [ 1.913e-01],
         [-2.668e-01],
         [ 2.178e-01],
         [ 2.877e-02],
         [-4.900e-02]],

        [[ 8.775e-01],
         [-9.724e-02],
         [-2.108e-01],
         [ 8.641e-02],
         [ 4.314e-01],
         [ 3.868e-01],
         [ 1.052e-01],
         [ 7.031e-02],
         [-3.437e-01],
         [ 7.329e-02]],

        [[-3.541e-02],
         [ 2.676e-02],
         [ 2.245e-02],
         [-1.812e-01],
         [-9.631e-02],
         [ 2.141e-01],
         [ 4.458e-01],
         [-3.378e-01],
         [ 2.731e-01],
         [-4.042e-01]],

        [[-1.262e-01],
         [ 1.175e-01],
         [-2.043e-01],
         [-1.941e-01],
         [ 4.942e-02],
         [ 2.948e-01],
         [ 5.577e-01],
         [-2.284e-02],
         [ 9.156e-03],
         [ 3.427e-01]],

        [[ 1.447e-01],
         [ 9.775e-02],
         [ 2.116e-02],
         [ 3.138e-01],
         [ 1.886e-02],
         [ 6.392e-02],
         [ 1.526e-01],
         [-6.146e-02],
         [-2.148e-01],
         [ 2.785e-01]],

        [[-8.618e-02],
         [ 2.448e-01],
         [ 3.729e-01],
         [-5.498e-02],
         [ 1.713e-01],
         [ 2.251e-01],
         [-6.740e-02],
         [ 1.047e-01],
         [ 1.362e-03],
         [ 3.107e-01]],

        [[-5.129e-01],
         [ 1.348e-01],
         [ 1.900e-01],
         [-2.316e-01],
         [ 7.923e-02],
         [-2.092e-01],
         [-8.575e-02],
         [-1.218e-01],
         [ 1.191e-02],
         [-3.353e-01]],

        [[-7.112e-02],
         [ 3.861e-01],
         [ 1.110e-01],
         [ 2.575e-02],
         [-1.503e-02],
         [-2.025e-01],
         [-1.405e-01],
         [-6.788e-02],
         [ 3.387e-01],
         [ 8.556e-02]],

        [[ 5.500e-01],
         [ 1.674e-01],
         [ 3.354e-02],
         [ 3.036e-01],
         [-2.131e-01],
         [-1.889e-01],
         [-2.415e-01],
         [-1.813e-01],
         [-4.449e-01],
         [ 4.096e-01]],

        [[-2.063e-01],
         [ 1.160e-01],
         [ 1.947e-01],
         [ 2.262e-01],
         [ 1.606e-01],
         [-1.177e-03],
         [-1.948e-01],
         [-2.889e-01],
         [ 4.104e-02],
         [-8.988e-02]],

        [[-5.305e-02],
         [ 9.110e-02],
         [-4.424e-01],
         [-1.480e-01],
         [ 1.420e-01],
         [-2.648e-01],
         [ 1.695e-01],
         [-1.425e-01],
         [ 9.273e-02],
         [ 3.767e-01]],

        [[-3.227e-02],
         [ 4.620e-02],
         [-7.590e-02],
         [-3.162e-01],
         [ 1.538e-02],
         [-2.533e-01],
         [-2.069e-02],
         [-4.268e-01],
         [-4.377e-01],
         [ 3.432e-01]],

        [[-1.930e-01],
         [ 3.225e-02],
         [-6.566e-01],
         [ 4.237e-01],
         [-5.195e-02],
         [-3.645e-01],
         [-2.984e-01],
         [ 7.549e-02],
         [-2.939e-01],
         [ 6.152e-01]],

        [[-3.006e-01],
         [-2.347e-02],
         [-1.729e-01],
         [-1.109e-01],
         [ 4.803e-02],
         [-2.076e-01],
         [-3.140e-01],
         [ 8.729e-02],
         [-4.082e-02],
         [ 1.121e-01]],

        [[-1.113e-01],
         [-1.518e-01],
         [-2.366e-02],
         [ 1.521e-01],
         [ 3.793e-01],
         [-1.814e-01],
         [ 5.118e-01],
         [ 1.284e-01],
         [ 7.612e-02],
         [ 6.634e-02]]], device='cuda:0')
s after update for 1 param tensor([[[1.777],
         [1.210],
         [1.221],
         [1.917],
         [1.640],
         [2.141],
         [1.411],
         [1.624],
         [1.694],
         [1.953]],

        [[1.665],
         [1.921],
         [1.998],
         [1.516],
         [1.222],
         [2.172],
         [2.091],
         [2.122],
         [2.169],
         [1.557]],

        [[1.700],
         [1.276],
         [1.857],
         [1.704],
         [1.777],
         [1.916],
         [1.753],
         [2.002],
         [0.695],
         [1.889]],

        [[1.914],
         [1.588],
         [1.156],
         [1.190],
         [1.925],
         [1.266],
         [1.726],
         [1.939],
         [1.848],
         [1.307]],

        [[1.576],
         [1.245],
         [1.616],
         [1.917],
         [1.293],
         [1.714],
         [1.753],
         [2.028],
         [1.800],
         [1.416]],

        [[2.196],
         [1.095],
         [2.030],
         [1.504],
         [1.836],
         [2.117],
         [2.064],
         [1.659],
         [1.885],
         [1.928]],

        [[1.859],
         [1.649],
         [1.795],
         [2.244],
         [1.977],
         [1.515],
         [1.817],
         [1.186],
         [1.813],
         [0.857]],

        [[1.104],
         [1.403],
         [1.496],
         [1.638],
         [1.522],
         [1.839],
         [1.834],
         [2.021],
         [1.516],
         [1.720]],

        [[2.102],
         [1.682],
         [1.620],
         [2.254],
         [1.818],
         [2.051],
         [1.739],
         [1.965],
         [1.671],
         [2.073]],

        [[1.549],
         [1.807],
         [1.633],
         [0.929],
         [1.753],
         [1.773],
         [1.792],
         [1.850],
         [1.978],
         [2.088]],

        [[2.228],
         [1.442],
         [1.889],
         [1.143],
         [1.600],
         [1.728],
         [2.258],
         [2.122],
         [2.385],
         [1.738]],

        [[2.426],
         [1.305],
         [1.346],
         [1.222],
         [1.560],
         [1.928],
         [1.274],
         [1.728],
         [1.938],
         [1.780]],

        [[1.057],
         [1.344],
         [2.070],
         [1.554],
         [1.693],
         [1.162],
         [1.276],
         [1.921],
         [2.142],
         [2.012]],

        [[1.519],
         [1.559],
         [1.552],
         [1.813],
         [1.977],
         [2.370],
         [1.926],
         [1.283],
         [1.999],
         [1.753]],

        [[2.005],
         [1.573],
         [2.229],
         [2.113],
         [1.215],
         [2.263],
         [1.320],
         [1.653],
         [1.953],
         [1.919]],

        [[1.714],
         [2.025],
         [1.810],
         [1.968],
         [1.680],
         [1.453],
         [1.638],
         [1.164],
         [2.136],
         [1.519]],

        [[1.194],
         [1.773],
         [1.680],
         [1.394],
         [2.124],
         [2.001],
         [1.609],
         [1.866],
         [2.580],
         [2.227]],

        [[1.446],
         [1.592],
         [1.809],
         [2.041],
         [1.316],
         [1.914],
         [2.272],
         [1.523],
         [1.899],
         [1.965]],

        [[1.129],
         [2.108],
         [1.675],
         [2.182],
         [2.046],
         [1.871],
         [1.802],
         [0.936],
         [1.532],
         [1.806]],

        [[1.379],
         [1.628],
         [1.800],
         [2.073],
         [1.992],
         [1.692],
         [1.980],
         [1.346],
         [0.809],
         [1.165]],

        [[1.785],
         [1.936],
         [2.067],
         [1.965],
         [2.301],
         [1.639],
         [1.771],
         [1.203],
         [1.447],
         [2.099]],

        [[1.616],
         [1.706],
         [2.123],
         [1.704],
         [2.120],
         [2.066],
         [1.698],
         [1.267],
         [1.700],
         [1.777]],

        [[1.608],
         [1.870],
         [1.259],
         [1.408],
         [1.472],
         [1.722],
         [1.767],
         [1.139],
         [2.140],
         [1.866]],

        [[1.605],
         [2.118],
         [1.544],
         [2.100],
         [2.244],
         [2.358],
         [1.397],
         [2.025],
         [0.981],
         [1.712]],

        [[1.851],
         [1.821],
         [0.945],
         [1.557],
         [2.067],
         [1.048],
         [2.046],
         [1.598],
         [1.775],
         [1.862]],

        [[1.631],
         [2.229],
         [1.495],
         [1.319],
         [1.871],
         [1.647],
         [1.374],
         [2.281],
         [1.634],
         [2.110]],

        [[1.931],
         [1.380],
         [2.042],
         [2.359],
         [1.556],
         [2.076],
         [1.642],
         [1.381],
         [2.136],
         [2.029]],

        [[1.609],
         [1.677],
         [1.975],
         [1.938],
         [1.749],
         [2.299],
         [1.887],
         [2.040],
         [1.669],
         [2.122]],

        [[1.774],
         [1.109],
         [1.925],
         [2.068],
         [2.265],
         [1.968],
         [1.810],
         [1.508],
         [1.777],
         [1.507]],

        [[2.003],
         [2.362],
         [2.024],
         [1.816],
         [1.505],
         [1.498],
         [1.556],
         [2.068],
         [1.585],
         [1.271]]], device='cuda:0')
b after update for 1 param tensor([[[177.386],
         [146.372],
         [147.039],
         [184.247],
         [170.427],
         [194.734],
         [158.072],
         [169.584],
         [173.235],
         [186.009]],

        [[171.742],
         [184.475],
         [188.103],
         [163.842],
         [147.120],
         [196.118],
         [192.433],
         [193.850],
         [195.983],
         [166.056]],

        [[173.534],
         [150.326],
         [181.350],
         [173.720],
         [177.412],
         [184.241],
         [176.183],
         [188.284],
         [110.985],
         [182.901]],

        [[184.126],
         [167.702],
         [143.114],
         [145.157],
         [184.668],
         [149.726],
         [174.843],
         [185.329],
         [180.933],
         [152.138]],

        [[167.095],
         [148.502],
         [169.164],
         [184.249],
         [151.354],
         [174.262],
         [176.218],
         [189.542],
         [178.544],
         [158.350]],

        [[197.241],
         [139.280],
         [189.599],
         [163.203],
         [180.330],
         [193.620],
         [191.211],
         [171.407],
         [182.715],
         [184.792]],

        [[181.476],
         [170.900],
         [178.314],
         [199.370],
         [187.112],
         [163.816],
         [179.406],
         [144.963],
         [179.186],
         [123.222]],

        [[139.862],
         [157.664],
         [162.800],
         [170.321],
         [164.181],
         [180.487],
         [180.223],
         [189.198],
         [163.867],
         [174.558]],

        [[192.947],
         [172.586],
         [169.393],
         [199.794],
         [179.441],
         [190.620],
         [175.500],
         [186.544],
         [172.054],
         [191.614]],

        [[165.658],
         [178.898],
         [170.095],
         [128.307],
         [176.208],
         [177.223],
         [178.173],
         [181.035],
         [187.166],
         [192.306]],

        [[198.652],
         [159.792],
         [182.910],
         [142.298],
         [168.353],
         [174.969],
         [199.969],
         [193.871],
         [205.544],
         [175.435]],

        [[207.279],
         [152.044],
         [154.408],
         [147.134],
         [166.251],
         [184.813],
         [150.236],
         [174.935],
         [185.290],
         [177.548]],

        [[136.819],
         [154.271],
         [191.488],
         [165.916],
         [173.178],
         [143.459],
         [150.358],
         [184.460],
         [194.774],
         [188.759]],

        [[164.015],
         [166.166],
         [165.801],
         [179.218],
         [187.110],
         [204.898],
         [184.709],
         [150.766],
         [188.175],
         [176.211]],

        [[188.436],
         [166.905],
         [198.708],
         [193.469],
         [146.668],
         [200.219],
         [152.933],
         [171.126],
         [185.996],
         [184.348]],

        [[174.262],
         [189.366],
         [179.066],
         [186.717],
         [172.497],
         [160.443],
         [170.323],
         [143.609],
         [194.510],
         [164.050]],

        [[145.416],
         [177.203],
         [172.510],
         [157.110],
         [193.979],
         [188.250],
         [168.826],
         [181.800],
         [213.774],
         [198.594]],

        [[160.018],
         [167.902],
         [178.984],
         [190.116],
         [152.693],
         [184.112],
         [200.625],
         [164.265],
         [183.395],
         [186.554]],

        [[141.417],
         [193.210],
         [172.268],
         [196.585],
         [190.385],
         [182.028],
         [178.663],
         [128.755],
         [164.745],
         [178.857]],

        [[156.300],
         [169.785],
         [178.573],
         [191.638],
         [187.838],
         [173.134],
         [187.252],
         [154.400],
         [119.708],
         [143.678]],

        [[177.800],
         [185.169],
         [191.347],
         [186.537],
         [201.868],
         [170.360],
         [177.095],
         [145.949],
         [160.092],
         [192.809]],

        [[169.195],
         [173.828],
         [193.896],
         [173.747],
         [193.755],
         [191.279],
         [173.426],
         [149.820],
         [173.519],
         [177.404]],

        [[168.763],
         [182.013],
         [149.346],
         [157.892],
         [161.463],
         [174.639],
         [176.914],
         [142.057],
         [194.668],
         [181.788]],

        [[168.580],
         [193.696],
         [165.369],
         [192.877],
         [199.350],
         [204.360],
         [157.299],
         [189.375],
         [131.790],
         [174.147]],

        [[181.080],
         [179.605],
         [129.345],
         [166.052],
         [191.353],
         [136.239],
         [190.342],
         [168.249],
         [177.302],
         [181.601]],

        [[169.977],
         [198.688],
         [162.745],
         [152.858],
         [182.042],
         [170.793],
         [155.977],
         [201.014],
         [170.116],
         [193.318]],

        [[184.919],
         [156.324],
         [190.159],
         [204.404],
         [165.998],
         [191.752],
         [170.547],
         [156.389],
         [194.513],
         [189.592]],

        [[168.836],
         [172.340],
         [187.051],
         [185.263],
         [176.006],
         [201.771],
         [182.796],
         [190.087],
         [171.951],
         [193.886]],

        [[177.267],
         [140.125],
         [184.672],
         [191.372],
         [200.284],
         [186.719],
         [179.074],
         [163.407],
         [177.386],
         [163.353]],

        [[188.345],
         [204.558],
         [189.326],
         [179.369],
         [163.278],
         [162.909],
         [166.037],
         [191.387],
         [167.535],
         [150.029]]], device='cuda:0')
clipping threshold 1.428237589973016
a after update for 1 param tensor([[-0.131],
        [-0.197],
        [-0.394],
        [-0.101],
        [ 0.118],
        [ 0.128],
        [ 0.226],
        [ 0.051],
        [ 0.124],
        [ 0.104],
        [-0.316],
        [ 0.250],
        [-0.166],
        [-0.021],
        [-0.042],
        [-0.135],
        [-0.324],
        [-0.052],
        [ 0.047],
        [ 0.245],
        [ 0.249],
        [ 0.346],
        [ 0.247],
        [-0.039],
        [-0.049],
        [ 0.212],
        [-0.192],
        [-0.258],
        [ 0.479],
        [-0.024]], device='cuda:0')
s after update for 1 param tensor([[2.105],
        [2.172],
        [1.570],
        [2.225],
        [2.224],
        [1.630],
        [1.455],
        [1.496],
        [1.812],
        [1.613],
        [1.184],
        [1.753],
        [1.777],
        [1.730],
        [1.836],
        [2.025],
        [1.280],
        [1.644],
        [1.845],
        [1.777],
        [1.829],
        [1.615],
        [1.776],
        [1.841],
        [2.279],
        [1.344],
        [1.916],
        [1.649],
        [1.675],
        [2.137]], device='cuda:0')
b after update for 1 param tensor([[193.073],
        [196.117],
        [166.777],
        [198.514],
        [198.468],
        [169.939],
        [160.523],
        [162.767],
        [179.154],
        [169.007],
        [144.804],
        [176.212],
        [177.430],
        [175.061],
        [180.332],
        [189.370],
        [150.567],
        [170.658],
        [180.764],
        [177.392],
        [179.992],
        [169.117],
        [177.381],
        [180.571],
        [200.905],
        [154.297],
        [184.233],
        [170.911],
        [172.259],
        [194.562]], device='cuda:0')
clipping threshold 1.428237589973016
cuda
Objective function 70.02 = squared loss an data 45.84 + 0.5*rho*h**2 17.536325 + alpha*h 3.419742 + L2reg 2.88 + L1reg 0.35 ; SHD = 138 ; DAG True
Proportion of microbatches that were clipped  0.779921856311299
iteration 3 in inner loop, alpha 57.744293050532875 rho 10000.0 h 0.0592221663026713
iteration 3 in outer loop, alpha = 649.9659560772459, rho = 10000.0, h = 0.0592221663026713
cuda
9630
cuda
Objective function 105.09 = squared loss an data 45.84 + 0.5*rho*h**2 17.536325 + alpha*h 38.492392 + L2reg 2.88 + L1reg 0.35 ; SHD = 138 ; DAG True
||w||^2 2294308834974.1675
exp ma of ||w||^2 401232903718.8513
||w|| 1514697.6051259101
exp ma of ||w|| 306041.5569222776
||w||^2 6.63038739228077
exp ma of ||w||^2 463.8230244044676
||w|| 2.5749538621654504
exp ma of ||w|| 2.172349147778495
||w||^2 2.518323493132865
exp ma of ||w||^2 3.848635245197993
||w|| 1.5869226487554031
exp ma of ||w|| 1.9308579954984901
||w||^2 6.53061289595968
exp ma of ||w||^2 4.042957337757733
||w|| 2.5555063873838546
exp ma of ||w|| 1.9701460680092238
||w||^2 2.4251722891545144
exp ma of ||w||^2 3.780599846871413
||w|| 1.5572964679708596
exp ma of ||w|| 1.9055145668320779
||w||^2 5.270791075572719
exp ma of ||w||^2 3.8300603362067296
||w|| 2.2958203491503246
exp ma of ||w|| 1.9130521442329071
||w||^2 5.891131166544497
exp ma of ||w||^2 3.9009731045534637
||w|| 2.427165253241834
exp ma of ||w|| 1.9336941944535417
||w||^2 2.809276675525576
exp ma of ||w||^2 4.041732913974478
||w|| 1.676089697935518
exp ma of ||w|| 1.9670701735008362
||w||^2 3.380296168255569
exp ma of ||w||^2 3.993996049852216
||w|| 1.8385581764675192
exp ma of ||w|| 1.9616405897656108
||w||^2 7.343281440890186
exp ma of ||w||^2 3.828013550047489
||w|| 2.709848970125491
exp ma of ||w|| 1.922614072858108
||w||^2 2.4269250678120295
exp ma of ||w||^2 3.9312181222913134
||w|| 1.5578591296429949
exp ma of ||w|| 1.9592671633241006
cuda
Objective function 83.71 = squared loss an data 45.11 + 0.5*rho*h**2 8.465765 + alpha*h 26.744760 + L2reg 3.03 + L1reg 0.35 ; SHD = 146 ; DAG True
Proportion of microbatches that were clipped  0.7823150869945181
iteration 1 in inner loop, alpha 649.9659560772459 rho 10000.0 h 0.04114793981403864
9630
cuda
Objective function 159.90 = squared loss an data 45.11 + 0.5*rho*h**2 84.657648 + alpha*h 26.744760 + L2reg 3.03 + L1reg 0.35 ; SHD = 146 ; DAG True
||w||^2 10.95316303715703
exp ma of ||w||^2 50799.21394498496
||w|| 3.309556320287816
exp ma of ||w|| 3.5708474461234987
||w||^2 8.371750628064145
exp ma of ||w||^2 52.834812005859376
||w|| 2.8933977652690865
exp ma of ||w|| 2.482365911988322
||w||^2 6.1021512318839655
exp ma of ||w||^2 4.715911835374432
||w|| 2.4702532728212234
exp ma of ||w|| 2.143047252513218
||w||^2 4.520878822338909
exp ma of ||w||^2 4.742122354655861
||w|| 2.126235834130097
exp ma of ||w|| 2.148112751501984
||w||^2 7.903806937876387
exp ma of ||w||^2 4.775293779655744
||w|| 2.811371006800132
exp ma of ||w|| 2.15566031661188
v before min max tensor([[ 2687.737,   933.982,  -419.349,  ...,  -857.515,    62.018,
          -618.642],
        [ 6413.074,  -852.429,   947.529,  ...,  -832.059,  -425.683,
           699.116],
        [14329.499,  -218.470,  -620.597,  ...,  -186.509,   891.987,
            68.303],
        ...,
        [  557.035,  3234.522,  6417.132,  ...,  -605.855,   206.738,
          -880.913],
        [ -640.530,  -685.281,  -780.394,  ...,  -483.487,  1859.467,
          -671.725],
        [ 3518.675,  -753.640,  6994.973,  ...,  1951.828,  -589.646,
          -123.408]], device='cuda:0')
v tensor([[1.000e+01, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e+01],
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         1.000e+01],
        ...,
        [1.000e+01, 1.000e+01, 1.000e+01,  ..., 1.000e-12, 1.000e+01,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e+01,
         1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([ 9.838e+02, -6.635e+02,  3.110e+02, -4.395e+02,  4.775e+02, -7.424e+02,
        -5.837e+02, -5.006e+02, -7.515e+02,  1.774e+03,  4.552e+02, -6.375e+02,
         1.415e+03, -6.760e+02,  1.197e+03,  3.331e+02, -5.441e+02, -4.742e+02,
         2.401e+03, -1.733e+02, -3.647e+02, -9.913e+01, -1.474e+02, -6.329e+02,
        -3.597e+02, -6.120e+02, -3.465e+02,  5.313e+02, -3.093e+01,  3.076e+02,
         1.028e+04, -4.760e+02, -2.369e+02,  1.225e+03, -4.136e+02, -1.946e+02,
         4.533e+03, -1.004e+03, -4.738e+02,  8.322e+03,  1.073e+02,  3.876e+03,
        -9.472e+02, -6.698e+02,  1.144e+01, -6.361e+02,  2.237e+03,  1.031e+02,
        -1.031e+02, -4.701e+02, -1.019e+02, -8.002e+02, -9.940e+02, -1.046e+03,
        -8.549e+02, -5.495e+02,  2.131e+02,  2.774e+03,  2.269e+03, -9.120e+02,
        -2.613e+02,  2.697e+03,  1.497e+03, -5.924e+02, -8.592e+02, -8.154e+02,
         2.275e+02, -6.973e+02, -5.647e+02, -8.347e+02, -2.088e+02, -5.908e+02,
        -6.440e+01, -6.533e+02,  3.866e+03, -7.110e+02,  1.308e+03, -5.685e+02,
        -5.473e+02, -5.608e+02, -5.735e+02, -7.032e+02, -2.801e+02,  1.308e+02,
         6.146e+03,  2.010e+02,  7.740e+03,  4.365e+02, -6.116e+02, -1.989e+02,
        -8.328e+02, -6.490e+02, -5.159e+02, -6.612e+02, -5.089e+02, -6.931e+02,
         1.401e+03, -7.333e+02,  1.229e+04, -7.466e+02, -7.665e+02, -7.406e+02,
         2.629e+03,  3.113e+02,  2.592e+02,  3.163e+01,  1.685e+02, -7.970e+02,
         1.152e+03, -3.847e+02, -2.687e+02,  2.874e+03, -6.232e+02,  3.010e+02,
        -2.236e+02, -7.078e+02, -2.544e+02, -6.705e+02, -5.833e+02, -5.994e+02,
         6.756e+03, -2.725e+02,  1.182e+03,  2.820e+03, -5.931e+02, -6.569e+02,
        -6.504e+02, -2.424e+02, -6.960e+02, -8.347e+02,  7.577e+01,  3.823e+02,
        -9.462e+02, -6.638e+02,  4.470e+03,  3.332e+02, -9.199e+02, -7.169e+02,
        -7.037e+02, -3.373e+02,  1.112e+03, -6.017e+02, -6.772e+02, -7.276e+02,
         1.170e+03, -7.485e+02,  1.040e+03, -6.418e+02, -4.189e+02, -8.018e+02,
        -5.350e+02, -6.911e+02, -7.261e+02,  1.447e+03, -1.195e+02, -4.365e+02,
         2.133e+02, -7.990e+02, -4.706e+02, -7.991e+02, -7.113e+02, -3.123e+02,
         1.034e+03, -4.486e+02,  8.048e+02, -7.032e+02, -7.093e+02,  2.745e+02,
         6.638e+02, -3.633e+02,  2.221e+02, -6.929e+02,  1.183e+03, -7.480e+02,
        -8.248e+02,  6.387e+01, -7.015e+02,  7.304e+02, -7.072e+02, -4.566e+02,
        -6.032e+02,  3.872e+02, -1.156e+02, -5.472e+02, -6.861e+02,  1.940e+03,
        -5.143e+02, -4.480e+02,  4.751e+02,  2.747e+03, -3.883e+02, -7.534e+02,
        -5.661e+02, -7.008e+02, -7.000e+02,  6.664e+03, -6.547e+02, -4.587e+02,
        -2.622e+02,  2.192e+03,  3.122e+02, -2.917e+02,  6.956e+02,  6.462e+02,
         3.165e+03, -8.318e+02,  1.782e+03, -7.101e+02, -5.391e+01,  1.985e+03,
         3.620e+02, -2.106e+02,  3.797e+03,  1.513e+03, -5.845e+02,  3.322e+03,
        -8.361e+02, -7.161e+02, -2.967e+02,  2.516e+03,  1.239e+03, -8.980e+01,
        -8.058e+02, -3.722e+02,  3.913e+03,  4.539e+03, -6.496e+02, -7.953e+02,
         1.799e+03, -8.104e+02,  2.717e+03, -3.842e+02, -3.825e+02, -5.695e+02,
        -1.510e+02,  1.421e+03,  1.467e+01,  4.145e+02,  8.468e+02,  2.705e+02,
        -9.239e+02, -5.912e+02, -2.600e+02,  7.417e+03,  1.354e+03,  2.335e+02,
        -3.081e+02,  1.449e+02, -3.353e+02,  2.445e+01, -5.418e+02,  1.034e+03,
        -4.727e+02, -5.968e+02,  3.416e+02,  1.340e+03, -7.882e+02,  4.676e+01,
        -4.397e+02, -9.427e+02,  8.110e+02, -3.167e+01,  5.440e+02, -6.394e+02,
         1.770e+03, -4.874e+02,  1.985e+03, -9.523e+02,  2.878e+02,  7.814e+02,
        -6.611e+02, -6.580e+02,  2.389e+03,  1.698e+02,  4.597e+01,  1.340e+03,
        -7.316e+02,  1.033e+03, -1.601e+02, -6.648e+02, -3.336e+02,  7.211e+02,
         1.782e+03,  3.489e+03, -2.099e+02, -8.821e+02,  1.482e+03, -6.069e+02,
        -3.144e+02, -6.826e+02, -6.515e+02, -8.524e+02, -7.195e+02, -6.641e+02,
        -5.662e+02,  2.313e+02, -3.646e+02, -7.805e+02,  4.770e+02, -6.683e+02],
       device='cuda:0')
v tensor([1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12],
       device='cuda:0')
v before min max tensor([[[-6.798e+02],
         [ 1.414e+03],
         [ 2.793e+03],
         [ 5.395e+01],
         [-9.165e+02],
         [-6.340e+02],
         [-3.826e+02],
         [ 6.994e+01],
         [ 1.075e+02],
         [-3.187e+02]],

        [[-7.481e+01],
         [ 9.291e+01],
         [-6.197e+02],
         [-2.180e+02],
         [-2.672e+02],
         [ 1.180e+02],
         [ 8.045e+02],
         [ 4.947e+03],
         [ 2.123e+03],
         [-1.609e+02]],

        [[ 4.870e+02],
         [-6.445e+02],
         [-5.730e+02],
         [ 1.917e+03],
         [ 1.318e+03],
         [ 1.447e+03],
         [-9.087e+02],
         [-4.369e+02],
         [-2.283e+02],
         [ 9.227e+02]],

        [[-7.471e+02],
         [-7.342e+02],
         [ 3.187e+03],
         [ 2.634e+03],
         [-2.689e+02],
         [-4.900e+02],
         [-6.754e+02],
         [ 1.816e+02],
         [-5.359e+02],
         [-3.265e+02]],

        [[ 2.210e+03],
         [-6.989e+02],
         [-2.962e+02],
         [-8.584e+02],
         [-9.361e+02],
         [-5.739e+02],
         [-4.967e+02],
         [-7.532e+02],
         [-8.139e+02],
         [-2.983e+02]],

        [[ 8.296e+03],
         [ 1.520e+03],
         [ 3.863e+01],
         [ 9.829e+02],
         [-5.203e+02],
         [ 2.285e+03],
         [ 5.064e+02],
         [ 1.894e+01],
         [ 1.239e+03],
         [ 2.021e+03]],

        [[-4.256e+02],
         [-9.266e+02],
         [-4.283e+02],
         [-7.514e+02],
         [ 2.048e+03],
         [ 1.188e+02],
         [-5.132e+02],
         [ 1.092e+03],
         [ 1.381e+03],
         [-5.614e+02]],

        [[ 1.086e+03],
         [ 1.671e+03],
         [-5.080e+02],
         [ 2.341e+03],
         [-6.217e+01],
         [-4.518e+02],
         [-6.309e+02],
         [-2.589e+02],
         [-6.480e+02],
         [ 4.588e+02]],

        [[-6.461e+02],
         [-7.743e+02],
         [-6.027e+02],
         [ 5.942e+02],
         [ 6.730e+02],
         [-5.589e+02],
         [-7.533e+02],
         [ 6.910e+01],
         [-5.310e+02],
         [-1.308e+02]],

        [[-6.374e+02],
         [-6.875e+02],
         [ 3.156e+03],
         [ 2.526e+03],
         [ 1.250e+02],
         [ 5.081e+03],
         [ 6.840e+01],
         [ 4.959e+03],
         [-6.235e+02],
         [ 3.705e+03]],

        [[ 1.225e+03],
         [ 9.252e+02],
         [-7.643e+02],
         [ 1.186e+03],
         [-8.175e+02],
         [-7.890e+02],
         [ 1.538e+03],
         [-1.831e+02],
         [-4.848e+02],
         [-5.857e+02]],

        [[-6.598e+02],
         [-3.677e+02],
         [-8.085e+02],
         [ 1.268e+03],
         [ 1.200e+02],
         [-3.756e+02],
         [-4.525e+02],
         [-6.585e+02],
         [ 8.686e+02],
         [-3.605e+02]],

        [[ 2.703e+03],
         [ 1.156e+02],
         [ 1.141e+03],
         [-7.867e+02],
         [ 1.925e+02],
         [ 3.951e+02],
         [-6.896e+02],
         [-5.471e+02],
         [ 6.767e+02],
         [-9.550e+01]],

        [[-2.621e+02],
         [ 1.996e+03],
         [ 2.796e+02],
         [-4.922e+02],
         [-7.018e+02],
         [-2.405e+02],
         [-3.915e+02],
         [ 7.874e+02],
         [ 1.618e+03],
         [ 1.082e+03]],

        [[-6.685e+02],
         [-7.140e+02],
         [-8.023e+02],
         [-1.744e+02],
         [ 3.874e+03],
         [ 4.424e+03],
         [-6.704e+02],
         [-5.613e+02],
         [ 2.023e+03],
         [ 1.839e+03]],

        [[-7.903e+02],
         [ 7.175e+02],
         [ 9.543e+02],
         [-7.449e+01],
         [ 8.025e+02],
         [-6.404e+02],
         [ 1.819e+03],
         [-7.985e+02],
         [-3.445e+02],
         [ 2.600e+03]],

        [[ 1.213e+03],
         [ 4.089e+02],
         [-4.275e+02],
         [-9.118e+02],
         [-7.780e+02],
         [ 2.993e+03],
         [-7.768e+02],
         [-1.352e+02],
         [-2.067e+02],
         [-3.034e+02]],

        [[ 7.731e+02],
         [ 2.062e+03],
         [ 2.373e+02],
         [-1.960e+02],
         [-2.123e+02],
         [-5.173e+02],
         [ 2.444e+02],
         [ 4.406e+02],
         [ 5.033e+02],
         [-8.182e+02]],

        [[-4.168e+02],
         [-4.185e+02],
         [-5.353e+02],
         [ 4.685e+03],
         [-6.418e+02],
         [ 1.085e+03],
         [-2.358e+02],
         [ 1.970e+03],
         [-3.941e+02],
         [-8.094e+02]],

        [[ 4.087e+02],
         [-3.522e+02],
         [-2.340e+02],
         [-7.577e+02],
         [-5.379e+02],
         [ 3.938e+02],
         [-5.206e+02],
         [-6.197e+02],
         [ 7.661e+01],
         [ 1.769e+03]],

        [[-8.773e+02],
         [-2.526e+02],
         [-8.351e+02],
         [-7.987e+02],
         [-7.642e+02],
         [-4.682e+02],
         [-4.449e+02],
         [-7.956e+02],
         [ 5.235e+01],
         [ 1.651e+03]],

        [[-3.536e+02],
         [-8.377e+02],
         [ 5.911e+02],
         [-8.333e+02],
         [ 6.709e+00],
         [ 3.068e+02],
         [ 1.748e+03],
         [-7.015e+02],
         [-5.222e+02],
         [ 1.691e+03]],

        [[-4.015e+02],
         [-5.334e+02],
         [-7.516e+02],
         [-6.843e+02],
         [-4.635e+02],
         [-5.035e+02],
         [ 2.247e+03],
         [-3.879e+01],
         [-9.713e+02],
         [-2.833e+02]],

        [[-7.330e+02],
         [ 8.874e+02],
         [-4.237e+02],
         [-4.271e+02],
         [-7.850e+02],
         [-2.765e+02],
         [-2.659e+02],
         [ 7.387e+02],
         [ 1.255e+02],
         [ 1.195e+03]],

        [[-4.422e+02],
         [-5.489e+02],
         [-4.869e+02],
         [-5.753e+02],
         [-3.571e+02],
         [ 5.069e+02],
         [ 2.913e+02],
         [-7.376e+02],
         [-5.816e+02],
         [ 6.288e+02]],

        [[-7.517e+02],
         [-8.132e+02],
         [-8.077e+02],
         [ 7.467e+02],
         [-7.811e+02],
         [-6.823e+02],
         [-4.232e+02],
         [ 9.311e+02],
         [-2.501e+02],
         [ 1.046e+03]],

        [[-4.284e+02],
         [-4.544e+02],
         [ 2.226e+02],
         [ 1.831e+03],
         [-8.886e+00],
         [-1.383e+02],
         [ 4.541e+03],
         [-8.928e+02],
         [ 1.970e+03],
         [-2.059e+02]],

        [[-4.104e+02],
         [-6.486e+02],
         [-7.211e+02],
         [-7.349e+02],
         [-8.307e+02],
         [ 4.124e+03],
         [ 5.860e+02],
         [-5.805e+02],
         [ 1.353e+02],
         [ 7.520e+02]],

        [[ 1.610e+03],
         [-7.336e+02],
         [-8.081e+02],
         [ 8.081e+01],
         [-8.831e+02],
         [-9.212e+02],
         [-5.873e+02],
         [-9.166e+02],
         [ 3.018e+02],
         [ 9.759e+02]],

        [[ 8.268e+02],
         [ 1.877e+01],
         [-1.821e+02],
         [ 4.611e+01],
         [ 1.370e+03],
         [-2.461e+02],
         [-7.108e+02],
         [ 2.032e+03],
         [-8.751e+02],
         [-5.321e+02]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [6.709e+00],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[-3.297e+02],
        [-3.420e+02],
        [-1.855e+02],
        [ 9.017e+01],
        [ 1.368e+03],
        [-4.320e+02],
        [-6.297e+02],
        [ 7.190e+02],
        [-6.106e+02],
        [ 1.705e+00],
        [-7.910e+01],
        [ 1.042e+03],
        [-6.843e+02],
        [-6.965e+02],
        [-6.504e+02],
        [ 4.886e+02],
        [-7.892e+02],
        [-4.853e+02],
        [ 1.610e+03],
        [-5.516e+02],
        [ 2.037e+03],
        [-9.689e+01],
        [ 8.029e+01],
        [ 1.868e+03],
        [ 1.024e+03],
        [-2.982e+02],
        [ 4.673e+01],
        [-4.322e+02],
        [-1.626e+02],
        [-9.317e+02]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.705e+00],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-0.081,  0.342,  0.255,  ..., -0.594, -0.072, -0.216],
        [-0.087, -0.175, -0.129,  ...,  0.028,  0.059, -0.063],
        [-0.198, -0.231,  0.012,  ..., -0.325, -0.035,  0.246],
        ...,
        [-0.257, -0.105, -0.173,  ...,  0.404,  0.090, -0.020],
        [-0.043,  0.007, -0.002,  ..., -0.814,  0.040,  0.050],
        [-0.083, -0.095,  0.020,  ..., -0.598,  0.079, -0.023]],
       device='cuda:0')
s after update for 1 param tensor([[2.699, 1.487, 2.057,  ..., 1.963, 1.628, 1.596],
        [1.831, 1.993, 1.844,  ..., 1.866, 1.032, 1.465],
        [2.930, 1.477, 1.658,  ..., 0.912, 1.370, 1.928],
        ...,
        [2.244, 1.894, 2.464,  ..., 1.611, 2.005, 1.960],
        [1.710, 1.566, 1.833,  ..., 1.880, 2.036, 1.705],
        [1.967, 1.850, 2.528,  ..., 1.809, 1.678, 2.181]], device='cuda:0')
b after update for 1 param tensor([[220.176, 163.422, 192.182,  ..., 187.758, 170.988, 169.307],
        [181.346, 189.179, 181.976,  ..., 183.035, 136.157, 162.191],
        [229.371, 162.871, 172.550,  ..., 127.955, 156.858, 186.090],
        ...,
        [200.744, 184.426, 210.375,  ..., 170.071, 189.740, 187.616],
        [175.246, 167.689, 181.410,  ..., 183.736, 191.193, 174.973],
        [187.943, 182.287, 213.051,  ..., 180.253, 173.613, 197.918]],
       device='cuda:0')
clipping threshold 1.8132745190278485
a after update for 1 param tensor([ 7.452e-02,  1.588e-01,  6.086e-01, -3.193e-01, -1.948e-01, -1.005e-02,
         1.942e-02,  8.194e-02, -7.031e-02, -1.427e-03, -8.634e-01, -6.772e-02,
         3.763e-01,  5.795e-02,  3.124e-02,  2.019e-01, -7.391e-01,  1.338e-01,
         3.440e-01,  3.216e-01,  9.122e-01,  2.026e-01,  8.218e-02,  1.961e-01,
        -1.709e-01, -1.171e-01, -3.205e-01,  3.103e-01, -1.714e-01,  4.497e-01,
        -1.904e-01,  6.043e-01, -6.330e-02, -6.812e-03, -2.163e-01, -7.311e-01,
        -2.092e-01,  8.581e-02,  2.145e-01,  7.344e-02, -1.879e-01, -1.913e-01,
         4.716e-01,  6.007e-01,  1.945e-01, -2.772e-01,  7.014e-01,  1.065e+00,
        -3.797e-01, -3.467e-01, -3.400e-02, -2.931e-01, -5.740e-02, -2.697e-01,
         5.418e-02,  2.441e-01, -3.260e-01, -2.402e-02,  7.249e-02, -4.006e-02,
        -1.021e-02, -3.390e-01,  4.663e-01,  2.546e-01,  3.959e-01, -7.006e-02,
         1.109e-01,  3.873e-02,  3.634e-01,  4.801e-02, -1.365e-02,  1.087e-01,
         6.620e-01,  1.333e-01,  2.829e-03,  1.673e-01, -7.350e-02,  4.691e-01,
        -2.344e-01,  4.974e-01,  4.534e-01, -1.834e-01, -1.397e-01, -7.681e-01,
        -6.931e-01,  4.811e-01, -3.994e-02, -2.163e-01,  8.477e-02,  6.149e-01,
         6.930e-02, -4.394e-01,  6.120e-02, -5.068e-01,  3.792e-01, -4.951e-01,
         1.058e-01,  3.243e-01, -4.949e-01,  4.139e-01,  1.195e-01, -3.349e-03,
        -5.546e-02,  1.575e-01, -4.916e-01, -4.316e-02,  2.747e-02, -2.332e-01,
         2.245e-01, -5.700e-01, -2.162e-02,  1.013e-01,  3.791e-01, -2.175e-01,
         2.420e-01,  3.685e-01, -2.673e-01,  1.346e-01,  2.737e-01,  1.003e-01,
         2.604e-01, -3.746e-01,  5.897e-01,  6.662e-02,  5.476e-01,  1.352e-01,
         8.269e-02,  5.800e-01, -5.476e-02, -2.531e-01, -1.494e+00,  1.070e-01,
        -4.177e-01,  1.357e-01, -1.234e-01, -3.472e-01,  3.782e-01, -5.424e-01,
         1.871e-01,  4.651e-01, -2.503e-01,  1.249e-01, -4.225e-02, -2.459e-01,
         2.497e-01, -1.570e-01,  4.172e-01, -9.039e-02,  4.743e-01,  7.320e-01,
        -1.776e-01, -1.907e-02, -1.736e-01, -2.459e-01, -2.545e-01, -2.469e-01,
        -2.043e-01, -3.143e-01, -1.518e-01,  3.400e-01, -4.017e-02, -6.062e-02,
         2.067e-01,  2.911e-01, -1.299e-01,  2.185e-01,  5.310e-01,  7.291e-02,
         1.099e-01, -1.991e-01,  8.490e-02,  2.615e-01,  2.066e-01,  2.315e-02,
        -2.128e-01, -4.055e-01,  2.482e-02,  6.271e-01, -5.951e-01,  1.866e-01,
         3.988e-01,  5.023e-01, -2.347e-02,  1.666e-02, -1.869e-01, -3.124e-01,
        -2.023e-01,  1.952e-02,  3.710e-01, -1.533e-01, -2.854e-01,  3.948e-01,
        -5.300e-02, -6.417e-01,  2.640e-01,  8.162e-02, -2.231e-02,  2.167e-01,
         4.000e-01, -2.653e-01, -1.776e-01,  2.049e-01, -4.203e-01, -4.460e-01,
         6.019e-02, -5.643e-01,  5.799e-01,  2.014e-01, -1.963e-01,  5.003e-02,
        -1.603e-01,  2.645e-03,  1.609e-01, -2.870e-01, -4.389e-01,  2.551e-01,
         6.092e-02,  3.675e-01,  1.582e-01, -1.577e-01, -3.751e-01, -2.310e-01,
         2.507e-01, -1.857e-01,  6.699e-01,  4.859e-01,  2.037e-01,  3.282e-02,
         4.452e-01, -5.461e-01, -3.428e-01,  1.327e-01, -6.352e-01, -1.231e-01,
        -4.519e-01,  4.889e-01, -2.507e-02,  5.244e-01,  4.589e-01, -3.320e-02,
        -1.368e-01, -3.282e-01, -3.506e-02, -2.158e-01, -1.750e-01,  5.404e-02,
         8.474e-02, -2.190e-02, -2.425e-01, -4.541e-01, -1.179e-01,  1.779e-01,
         4.833e-01, -2.402e-01, -7.746e-01,  2.434e-01, -5.940e-01, -4.135e-01,
        -6.741e-01,  1.634e-01,  6.951e-01, -2.757e-01, -5.574e-02,  7.735e-02,
         2.137e-01, -1.716e-02, -3.106e-01,  4.139e-01, -4.994e-01, -4.186e-01,
         7.242e-01, -4.460e-02,  1.870e-01,  7.542e-03, -9.840e-02,  1.853e-01,
         5.440e-01, -2.467e-01, -5.564e-02, -2.539e-01,  1.165e-01, -6.364e-01,
        -4.655e-01, -8.043e-02,  2.921e-01,  1.436e-01,  3.382e-01, -4.512e-01,
         4.723e-01,  2.126e-01, -3.345e-01, -4.405e-01,  3.516e-01, -1.164e-01,
         8.938e-02,  4.592e-01, -9.006e-02,  2.262e-01,  2.219e-01,  3.359e-01],
       device='cuda:0')
s after update for 1 param tensor([1.928, 1.793, 1.999, 1.734, 1.850, 1.849, 1.503, 2.056, 2.331, 1.996,
        1.498, 1.425, 1.571, 1.763, 1.812, 2.133, 1.322, 1.532, 1.815, 1.103,
        1.519, 1.730, 1.918, 1.698, 1.425, 1.512, 1.162, 1.589, 1.688, 2.116,
        2.383, 1.507, 1.613, 1.740, 1.653, 1.615, 1.759, 2.270, 1.535, 2.142,
        1.799, 1.838, 2.181, 1.987, 1.834, 1.473, 2.156, 1.576, 1.732, 1.797,
        1.877, 1.904, 2.237, 2.332, 1.976, 1.751, 1.851, 2.207, 2.018, 2.060,
        1.204, 1.978, 1.624, 1.523, 2.010, 1.823, 1.737, 2.006, 1.271, 2.023,
        0.947, 2.071, 1.545, 1.479, 2.037, 1.588, 2.306, 1.592, 1.458, 1.275,
        1.668, 1.936, 1.734, 1.740, 2.211, 1.608, 2.636, 2.075, 1.553, 1.118,
        1.932, 1.836, 1.707, 1.710, 1.202, 1.554, 1.998, 1.683, 2.597, 1.678,
        1.706, 1.699, 2.013, 1.642, 2.194, 1.863, 1.797, 1.788, 2.623, 1.530,
        1.287, 1.626, 1.396, 1.903, 1.791, 1.609, 1.410, 1.564, 1.338, 1.399,
        2.237, 1.498, 1.909, 1.842, 1.649, 1.487, 1.595, 1.393, 1.853, 1.925,
        2.431, 1.944, 2.194, 1.539, 1.927, 2.200, 2.067, 1.752, 1.803, 1.609,
        1.741, 1.468, 1.582, 1.695, 2.193, 1.684, 2.202, 1.439, 1.998, 1.786,
        1.575, 1.895, 1.617, 2.229, 1.451, 1.794, 2.163, 1.869, 1.870, 1.785,
        1.629, 1.287, 1.827, 1.777, 1.521, 1.739, 1.817, 2.340, 1.327, 1.896,
        2.218, 1.745, 1.223, 1.784, 1.842, 1.638, 1.561, 2.093, 1.591, 1.696,
        1.346, 2.072, 1.699, 1.217, 1.563, 1.926, 1.855, 2.040, 2.409, 1.912,
        1.529, 1.930, 1.723, 1.791, 1.645, 1.587, 1.491, 1.481, 1.452, 1.948,
        2.072, 1.510, 1.878, 2.013, 1.833, 1.931, 1.761, 1.826, 1.725, 1.921,
        1.514, 1.834, 2.082, 1.862, 1.604, 1.869, 1.944, 1.647, 2.066, 1.801,
        2.051, 2.021, 1.796, 1.837, 1.838, 2.154, 1.446, 1.777, 1.666, 1.829,
        2.007, 1.264, 1.835, 1.534, 1.390, 2.341, 1.611, 2.166, 1.865, 2.044,
        2.093, 1.792, 1.084, 1.995, 1.971, 2.243, 2.132, 1.598, 1.315, 1.831,
        1.529, 2.063, 1.237, 1.352, 1.737, 2.271, 1.773, 2.153, 1.224, 2.108,
        1.716, 1.547, 2.627, 2.288, 1.784, 1.089, 2.165, 2.228, 1.856, 1.923,
        1.471, 1.658, 1.881, 1.585, 2.261, 2.174, 1.637, 2.053, 1.102, 1.524,
        2.017, 1.977, 1.676, 2.089, 1.539, 1.972, 2.352, 1.965, 1.114, 1.568,
        1.475, 1.939, 1.777, 1.804, 1.440, 1.600, 1.514, 1.882, 2.059, 1.938],
       device='cuda:0')
b after update for 1 param tensor([186.087, 179.446, 189.456, 176.456, 182.293, 182.200, 164.290, 192.172,
        204.580, 189.328, 163.993, 159.973, 167.962, 177.913, 180.372, 195.735,
        154.054, 165.870, 180.562, 140.766, 165.154, 176.285, 185.614, 174.645,
        159.952, 164.806, 144.428, 168.937, 174.105, 194.944, 206.888, 164.488,
        170.178, 176.780, 172.298, 170.308, 177.718, 201.899, 166.046, 196.149,
        179.754, 181.659, 197.898, 188.894, 181.469, 162.669, 196.778, 168.213,
        176.381, 179.624, 183.588, 184.935, 200.430, 204.662, 188.385, 177.350,
        182.305, 199.093, 190.366, 192.345, 147.022, 188.459, 170.751, 165.404,
        189.977, 180.931, 176.593, 189.809, 151.108, 190.588, 130.432, 192.853,
        166.574, 162.957, 191.281, 168.895, 203.500, 169.090, 161.808, 151.323,
        173.054, 186.446, 176.443, 176.786, 199.266, 169.913, 217.560, 193.056,
        167.028, 141.710, 186.276, 181.569, 175.064, 175.262, 146.924, 167.073,
        189.409, 173.866, 215.976, 173.610, 175.057, 174.656, 190.131, 171.740,
        198.509, 182.887, 179.663, 179.202, 217.029, 165.769, 152.024, 170.900,
        158.332, 184.880, 179.360, 169.981, 159.126, 167.578, 154.986, 158.509,
        200.419, 164.013, 185.166, 181.856, 172.086, 163.440, 169.231, 158.173,
        182.405, 185.922, 208.938, 186.839, 198.476, 166.247, 186.029, 198.779,
        192.658, 177.388, 179.917, 169.975, 176.820, 162.348, 168.548, 174.491,
        198.443, 173.908, 198.868, 160.757, 189.431, 179.072, 168.190, 184.453,
        170.393, 200.063, 161.444, 179.499, 197.108, 183.224, 183.236, 179.045,
        171.021, 152.022, 181.154, 178.662, 165.256, 176.744, 180.643, 204.977,
        154.373, 184.546, 199.566, 177.041, 148.174, 179.009, 181.864, 171.526,
        167.458, 193.861, 169.030, 174.523, 155.476, 192.885, 174.684, 147.862,
        167.544, 185.980, 182.501, 191.400, 207.987, 185.307, 165.706, 186.161,
        175.888, 179.322, 171.901, 168.826, 163.644, 163.090, 161.470, 187.050,
        192.908, 164.678, 183.635, 190.147, 181.436, 186.206, 177.858, 181.107,
        176.032, 185.748, 164.904, 181.494, 193.350, 182.876, 169.704, 183.207,
        186.843, 171.981, 192.642, 179.825, 191.904, 190.490, 179.586, 181.622,
        181.680, 196.691, 161.155, 178.646, 172.963, 181.250, 189.838, 150.650,
        181.552, 165.950, 157.989, 205.046, 170.081, 197.216, 183.003, 191.587,
        193.872, 179.375, 139.508, 189.272, 188.129, 200.685, 195.657, 169.406,
        153.701, 181.318, 165.731, 192.492, 149.059, 155.827, 176.626, 201.946,
        178.425, 196.634, 148.236, 194.546, 175.554, 166.703, 217.201, 202.704,
        178.996, 139.857, 197.191, 200.042, 182.566, 185.857, 162.524, 172.565,
        183.804, 168.723, 201.518, 197.605, 171.449, 192.007, 140.652, 165.439,
        190.299, 188.445, 173.507, 193.707, 166.247, 188.181, 205.511, 187.861,
        141.460, 167.803, 162.766, 186.587, 178.652, 179.998, 160.808, 169.495,
        164.901, 183.831, 192.292, 186.570], device='cuda:0')
clipping threshold 1.8132745190278485
a after update for 1 param tensor([[[ 0.234],
         [ 0.390],
         [-0.181],
         [ 0.211],
         [-0.271],
         [ 0.006],
         [ 0.020],
         [ 0.164],
         [ 0.534],
         [ 0.049]],

        [[-0.173],
         [ 0.013],
         [ 0.399],
         [-0.253],
         [ 0.431],
         [ 0.295],
         [ 0.173],
         [ 0.339],
         [-0.506],
         [ 0.309]],

        [[-0.209],
         [ 0.050],
         [-0.710],
         [ 0.435],
         [ 0.041],
         [ 0.317],
         [ 0.124],
         [ 0.309],
         [ 0.086],
         [-0.143]],

        [[-0.309],
         [-0.196],
         [ 0.113],
         [ 0.522],
         [-0.449],
         [-0.043],
         [ 0.014],
         [-0.500],
         [ 0.042],
         [ 0.258]],

        [[-0.454],
         [-0.105],
         [ 0.377],
         [-0.019],
         [ 0.240],
         [ 0.042],
         [-0.225],
         [ 0.553],
         [-0.125],
         [ 0.552]],

        [[-0.675],
         [-0.895],
         [-0.193],
         [ 0.324],
         [-0.086],
         [ 0.035],
         [-0.135],
         [-0.127],
         [-0.107],
         [-0.117]],

        [[ 0.171],
         [ 0.501],
         [-0.134],
         [-0.008],
         [-0.049],
         [ 0.405],
         [ 0.094],
         [-0.853],
         [-0.163],
         [ 0.350]],

        [[ 0.064],
         [ 0.627],
         [ 0.387],
         [-0.308],
         [-0.031],
         [ 0.002],
         [-0.337],
         [ 0.527],
         [ 0.069],
         [ 0.238]],

        [[-0.474],
         [ 0.023],
         [ 0.098],
         [ 0.182],
         [-0.118],
         [ 0.222],
         [ 0.323],
         [ 0.128],
         [-0.489],
         [ 0.084]],

        [[-0.134],
         [-0.161],
         [-0.254],
         [ 0.206],
         [ 0.045],
         [ 0.151],
         [ 0.298],
         [-0.478],
         [-0.148],
         [-0.103]],

        [[ 0.175],
         [ 0.639],
         [-0.137],
         [-0.214],
         [ 0.101],
         [ 0.076],
         [ 0.053],
         [-0.190],
         [-0.496],
         [-0.137]],

        [[-0.607],
         [-0.346],
         [ 0.517],
         [ 0.501],
         [-0.112],
         [-0.145],
         [ 0.245],
         [ 0.269],
         [-0.240],
         [ 0.007]],

        [[ 0.380],
         [-0.145],
         [-0.472],
         [ 0.446],
         [ 0.112],
         [-0.440],
         [-0.158],
         [ 0.699],
         [-0.196],
         [ 0.304]],

        [[-0.722],
         [ 0.411],
         [ 0.212],
         [-0.408],
         [ 0.435],
         [-0.137],
         [ 0.196],
         [-0.507],
         [-0.429],
         [-0.210]],

        [[-0.418],
         [ 0.055],
         [ 0.605],
         [ 0.095],
         [ 0.197],
         [ 0.626],
         [ 0.079],
         [ 0.183],
         [ 0.629],
         [ 0.030]],

        [[ 0.252],
         [ 0.113],
         [-0.387],
         [-0.219],
         [ 0.531],
         [-0.420],
         [-0.210],
         [-0.302],
         [ 0.056],
         [-0.429]],

        [[ 0.518],
         [ 0.017],
         [-0.033],
         [-0.165],
         [ 0.320],
         [ 0.096],
         [ 0.142],
         [ 0.441],
         [-0.011],
         [ 0.213]],

        [[ 0.264],
         [-0.382],
         [ 0.306],
         [ 0.015],
         [-0.350],
         [ 0.214],
         [-0.229],
         [ 0.484],
         [-0.033],
         [ 0.110]],

        [[-0.012],
         [-0.299],
         [ 0.502],
         [-0.054],
         [ 0.227],
         [ 0.248],
         [ 0.307],
         [ 0.161],
         [-0.351],
         [-0.547]],

        [[-0.233],
         [ 0.046],
         [ 0.022],
         [-0.445],
         [-0.140],
         [ 0.022],
         [-0.171],
         [-0.301],
         [ 0.442],
         [-0.706]],

        [[ 0.867],
         [-0.092],
         [ 0.169],
         [-0.336],
         [ 0.036],
         [-0.079],
         [-0.457],
         [-0.086],
         [ 0.340],
         [-0.051]],

        [[ 0.255],
         [ 0.425],
         [ 0.409],
         [ 0.418],
         [-0.151],
         [ 0.104],
         [-0.255],
         [-0.449],
         [-0.141],
         [-0.659]],

        [[-0.362],
         [-0.323],
         [-0.617],
         [-0.731],
         [-0.113],
         [ 0.074],
         [ 0.392],
         [ 0.277],
         [ 0.273],
         [ 0.252]],

        [[-0.177],
         [-0.436],
         [-0.135],
         [ 0.066],
         [-0.257],
         [-0.493],
         [ 0.123],
         [ 0.013],
         [-0.264],
         [ 0.787]],

        [[ 0.309],
         [-0.062],
         [-0.146],
         [ 0.535],
         [ 0.271],
         [ 0.202],
         [-0.063],
         [ 0.302],
         [ 0.037],
         [-0.050]],

        [[ 0.583],
         [ 0.075],
         [-0.540],
         [ 0.440],
         [-0.216],
         [-0.126],
         [ 0.027],
         [-0.057],
         [ 0.310],
         [ 0.236]],

        [[-0.232],
         [ 0.262],
         [-0.126],
         [ 0.019],
         [-0.267],
         [ 0.203],
         [ 0.136],
         [-0.024],
         [-0.254],
         [ 0.060]],

        [[-0.308],
         [-0.093],
         [-1.536],
         [ 0.162],
         [-0.172],
         [ 0.312],
         [ 0.064],
         [ 0.203],
         [ 0.182],
         [ 0.068]],

        [[-0.351],
         [ 0.033],
         [-0.681],
         [ 0.191],
         [ 0.554],
         [-0.243],
         [ 0.021],
         [-0.154],
         [-0.372],
         [ 0.013]],

        [[ 0.229],
         [-0.230],
         [ 0.344],
         [ 0.210],
         [-0.552],
         [-0.118],
         [-0.019],
         [-0.008],
         [ 0.081],
         [ 0.542]]], device='cuda:0')
s after update for 1 param tensor([[[1.582],
         [1.766],
         [2.029],
         [2.014],
         [2.092],
         [1.786],
         [1.483],
         [1.680],
         [1.637],
         [1.494]],

        [[1.680],
         [2.082],
         [1.491],
         [1.637],
         [1.551],
         [1.726],
         [1.994],
         [1.931],
         [1.954],
         [2.046]],

        [[1.683],
         [1.760],
         [1.446],
         [2.311],
         [2.032],
         [1.781],
         [2.034],
         [1.117],
         [1.128],
         [2.169]],

        [[1.695],
         [1.677],
         [1.983],
         [2.119],
         [1.879],
         [1.759],
         [1.863],
         [1.690],
         [1.663],
         [1.326]],

        [[2.042],
         [1.568],
         [2.047],
         [1.975],
         [2.083],
         [1.623],
         [1.297],
         [1.931],
         [1.828],
         [1.496]],

        [[2.370],
         [1.590],
         [1.760],
         [1.446],
         [1.732],
         [1.647],
         [1.803],
         [2.259],
         [2.250],
         [1.817]],

        [[1.709],
         [2.064],
         [1.109],
         [1.894],
         [2.140],
         [2.254],
         [1.457],
         [1.273],
         [1.810],
         [1.941]],

        [[2.505],
         [2.245],
         [1.254],
         [2.006],
         [1.218],
         [1.805],
         [1.649],
         [0.911],
         [1.514],
         [2.083]],

        [[1.674],
         [1.726],
         [1.537],
         [1.906],
         [1.934],
         [1.670],
         [1.722],
         [2.100],
         [1.226],
         [1.875]],

        [[1.924],
         [1.613],
         [1.632],
         [2.018],
         [2.040],
         [1.921],
         [1.855],
         [1.864],
         [1.911],
         [1.574]],

        [[2.147],
         [1.992],
         [1.719],
         [2.258],
         [1.851],
         [2.054],
         [1.732],
         [1.322],
         [1.624],
         [1.634]],

        [[2.186],
         [1.404],
         [1.814],
         [1.967],
         [1.892],
         [1.511],
         [1.982],
         [1.751],
         [2.110],
         [1.530]],

        [[1.966],
         [1.194],
         [2.322],
         [1.756],
         [1.997],
         [1.995],
         [1.545],
         [1.421],
         [2.522],
         [1.719]],

        [[1.358],
         [2.146],
         [1.702],
         [1.796],
         [1.641],
         [1.453],
         [1.969],
         [1.871],
         [2.096],
         [2.109]],

        [[1.594],
         [1.596],
         [1.851],
         [1.507],
         [2.247],
         [2.148],
         [1.639],
         [1.596],
         [1.830],
         [2.110]],

        [[1.801],
         [2.432],
         [2.033],
         [1.728],
         [1.784],
         [1.427],
         [1.755],
         [1.777],
         [2.040],
         [1.896]],

        [[2.176],
         [1.996],
         [1.157],
         [2.137],
         [1.840],
         [2.269],
         [1.750],
         [2.002],
         [1.538],
         [1.590]],

        [[2.144],
         [2.260],
         [1.605],
         [1.277],
         [1.731],
         [1.368],
         [1.718],
         [1.593],
         [1.810],
         [1.988]],

        [[1.187],
         [1.305],
         [2.163],
         [2.067],
         [1.781],
         [2.325],
         [1.571],
         [1.868],
         [1.157],
         [1.851]],

        [[2.094],
         [1.863],
         [2.188],
         [1.935],
         [1.794],
         [2.103],
         [1.904],
         [1.433],
         [1.849],
         [2.244]],

        [[1.956],
         [1.896],
         [1.860],
         [1.949],
         [1.993],
         [1.542],
         [1.633],
         [1.773],
         [2.021],
         [1.937]],

        [[1.862],
         [1.890],
         [2.074],
         [1.914],
         [1.732],
         [2.069],
         [1.912],
         [1.574],
         [1.813],
         [2.076]],

        [[0.965],
         [1.276],
         [1.834],
         [1.586],
         [1.377],
         [1.601],
         [1.609],
         [1.041],
         [2.161],
         [1.941]],

        [[1.691],
         [2.144],
         [1.039],
         [1.886],
         [1.789],
         [1.170],
         [1.616],
         [2.296],
         [1.368],
         [1.719]],

        [[1.439],
         [1.388],
         [1.802],
         [1.349],
         [1.794],
         [2.124],
         [2.356],
         [1.665],
         [1.355],
         [1.647]],

        [[1.834],
         [1.976],
         [1.946],
         [1.945],
         [1.847],
         [1.625],
         [0.944],
         [1.969],
         [1.181],
         [1.896]],

        [[1.384],
         [1.331],
         [2.054],
         [2.283],
         [1.566],
         [1.422],
         [2.187],
         [2.011],
         [1.836],
         [1.607]],

        [[1.745],
         [1.872],
         [1.606],
         [1.640],
         [1.902],
         [2.092],
         [1.825],
         [1.591],
         [2.103],
         [1.392]],

        [[1.613],
         [1.950],
         [1.867],
         [1.846],
         [1.974],
         [2.053],
         [1.844],
         [2.069],
         [2.262],
         [1.749]],

        [[1.991],
         [2.045],
         [1.171],
         [2.085],
         [2.071],
         [1.617],
         [1.603],
         [2.399],
         [2.054],
         [1.186]]], device='cuda:0')
b after update for 1 param tensor([[[168.561],
         [178.068],
         [190.872],
         [190.189],
         [193.806],
         [179.067],
         [163.184],
         [173.687],
         [171.449],
         [163.797]],

        [[173.691],
         [193.376],
         [163.611],
         [171.471],
         [166.898],
         [176.035],
         [189.242],
         [186.199],
         [187.347],
         [191.671]],

        [[173.829],
         [177.792],
         [161.164],
         [203.702],
         [191.028],
         [178.843],
         [191.113],
         [141.649],
         [142.352],
         [197.358]],

        [[174.446],
         [173.539],
         [188.706],
         [195.083],
         [183.703],
         [177.750],
         [182.932],
         [174.227],
         [172.816],
         [154.335]],

        [[191.474],
         [167.820],
         [191.748],
         [188.307],
         [193.407],
         [170.720],
         [152.605],
         [186.239],
         [181.178],
         [163.896]],

        [[206.306],
         [168.990],
         [177.807],
         [161.133],
         [176.345],
         [171.974],
         [179.962],
         [201.424],
         [200.999],
         [180.628]],

        [[175.184],
         [192.534],
         [141.151],
         [184.412],
         [196.036],
         [201.196],
         [161.764],
         [151.175],
         [180.290],
         [186.684]],

        [[212.119],
         [200.787],
         [150.058],
         [189.789],
         [147.872],
         [180.049],
         [172.071],
         [127.923],
         [164.885],
         [193.390]],

        [[173.400],
         [176.083],
         [166.114],
         [185.009],
         [186.366],
         [173.195],
         [175.854],
         [194.215],
         [148.366],
         [183.524]],

        [[185.858],
         [170.176],
         [171.188],
         [190.366],
         [191.393],
         [185.729],
         [182.539],
         [182.961],
         [185.255],
         [168.117]],

        [[196.349],
         [189.122],
         [175.713],
         [201.359],
         [182.313],
         [192.048],
         [176.369],
         [154.056],
         [170.793],
         [171.310]],

        [[198.153],
         [158.800],
         [180.514],
         [187.928],
         [184.329],
         [164.702],
         [188.682],
         [177.330],
         [194.643],
         [165.760]],

        [[187.889],
         [146.417],
         [204.207],
         [177.591],
         [189.364],
         [189.300],
         [166.554],
         [159.727],
         [212.836],
         [175.720]],

        [[156.158],
         [196.305],
         [174.817],
         [179.585],
         [171.650],
         [161.534],
         [188.028],
         [183.311],
         [194.015],
         [194.630]],

        [[169.191],
         [169.315],
         [182.336],
         [164.510],
         [200.878],
         [196.410],
         [171.556],
         [169.306],
         [181.291],
         [194.656]],

        [[179.840],
         [208.977],
         [191.064],
         [176.138],
         [179.010],
         [160.100],
         [177.555],
         [178.654],
         [191.381],
         [184.511]],

        [[197.700],
         [189.310],
         [144.130],
         [195.906],
         [181.780],
         [201.877],
         [177.258],
         [189.619],
         [166.179],
         [168.993]],

        [[196.206],
         [201.454],
         [169.794],
         [151.464],
         [176.310],
         [156.765],
         [175.651],
         [169.140],
         [180.310],
         [188.945]],

        [[146.022],
         [153.079],
         [197.101],
         [192.654],
         [178.837],
         [204.315],
         [167.993],
         [183.176],
         [144.165],
         [182.315]],

        [[193.898],
         [182.935],
         [198.237],
         [186.400],
         [179.511],
         [194.331],
         [184.906],
         [160.423],
         [182.241],
         [200.736]],

        [[187.407],
         [184.545],
         [182.753],
         [187.073],
         [189.195],
         [166.414],
         [171.257],
         [178.415],
         [190.487],
         [186.524]],

        [[182.884],
         [184.242],
         [193.004],
         [185.407],
         [176.377],
         [192.758],
         [185.279],
         [168.140],
         [180.424],
         [193.086]],

        [[131.647],
         [151.401],
         [181.473],
         [168.781],
         [157.251],
         [169.572],
         [169.970],
         [136.746],
         [197.002],
         [186.681]],

        [[174.249],
         [196.221],
         [136.599],
         [184.047],
         [179.254],
         [144.978],
         [170.331],
         [203.040],
         [156.711],
         [175.685]],

        [[160.766],
         [157.866],
         [179.916],
         [155.620],
         [179.490],
         [195.302],
         [205.684],
         [172.940],
         [156.019],
         [171.969]],

        [[181.481],
         [188.399],
         [186.960],
         [186.893],
         [182.123],
         [170.830],
         [130.228],
         [188.026],
         [145.615],
         [184.510]],

        [[157.675],
         [154.589],
         [192.052],
         [202.502],
         [167.707],
         [159.812],
         [198.192],
         [190.054],
         [181.603],
         [169.866]],

        [[177.028],
         [183.372],
         [169.838],
         [171.625],
         [184.810],
         [193.828],
         [181.031],
         [169.026],
         [194.320],
         [158.125]],

        [[170.220],
         [187.140],
         [183.096],
         [182.082],
         [188.293],
         [191.996],
         [181.963],
         [192.776],
         [201.536],
         [177.207]],

        [[189.073],
         [191.640],
         [144.986],
         [193.498],
         [192.853],
         [170.425],
         [169.656],
         [207.545],
         [192.058],
         [145.955]]], device='cuda:0')
clipping threshold 1.8132745190278485
a after update for 1 param tensor([[-0.095],
        [-0.328],
        [-0.137],
        [-0.346],
        [ 0.123],
        [-0.591],
        [ 0.184],
        [-0.462],
        [-0.073],
        [ 0.195],
        [-0.298],
        [-0.138],
        [ 0.469],
        [ 0.243],
        [-0.598],
        [ 0.252],
        [-0.282],
        [-0.213],
        [-0.206],
        [-0.215],
        [-0.742],
        [-0.029],
        [ 0.128],
        [ 0.070],
        [ 0.772],
        [-0.135],
        [ 0.425],
        [-0.568],
        [-0.089],
        [-0.069]], device='cuda:0')
s after update for 1 param tensor([[1.789],
        [1.894],
        [1.142],
        [2.267],
        [1.978],
        [1.380],
        [2.122],
        [2.014],
        [2.018],
        [1.392],
        [1.771],
        [1.761],
        [1.536],
        [1.565],
        [1.535],
        [2.017],
        [1.976],
        [1.273],
        [1.744],
        [1.273],
        [2.373],
        [1.367],
        [1.524],
        [2.403],
        [1.714],
        [1.573],
        [1.811],
        [1.196],
        [1.418],
        [2.218]], device='cuda:0')
b after update for 1 param tensor([[179.227],
        [184.420],
        [143.202],
        [201.788],
        [188.495],
        [157.451],
        [195.207],
        [190.190],
        [190.352],
        [158.119],
        [178.350],
        [177.853],
        [166.111],
        [167.667],
        [166.028],
        [190.321],
        [188.390],
        [151.227],
        [176.997],
        [151.172],
        [206.421],
        [156.670],
        [165.423],
        [207.740],
        [175.433],
        [168.077],
        [180.343],
        [146.562],
        [159.599],
        [199.591]], device='cuda:0')
clipping threshold 1.8132745190278485
||w||^2 6.94943136263372
exp ma of ||w||^2 5.1565682653690015
||w|| 2.6361774148629906
exp ma of ||w|| 2.2273407822031146
||w||^2 5.344751509238887
exp ma of ||w||^2 4.721276928260865
||w|| 2.311871862634019
exp ma of ||w|| 2.1314169826146583
||w||^2 6.392194878991185
exp ma of ||w||^2 5.117607610163867
||w|| 2.5282790350337487
exp ma of ||w|| 2.2363680920044504
||w||^2 5.589634618211607
exp ma of ||w||^2 5.223792990901872
||w|| 2.3642408122295
exp ma of ||w|| 2.2582079542498192
||w||^2 5.826911824061779
exp ma of ||w||^2 5.047202881347154
||w|| 2.413899712925493
exp ma of ||w|| 2.2215857143495645
||w||^2 5.168368721360057
exp ma of ||w||^2 5.5183219139916835
||w|| 2.2734046541168285
exp ma of ||w|| 2.3269740908322936
||w||^2 4.8994991400499694
exp ma of ||w||^2 5.549915513887002
||w|| 2.2134812264959396
exp ma of ||w|| 2.332240353354209
||w||^2 4.344691246034591
exp ma of ||w||^2 5.851427478543367
||w|| 2.0843922965782116
exp ma of ||w|| 2.400812641161981
cuda
Objective function 79.42 = squared loss an data 46.46 + 0.5*rho*h**2 17.341009 + alpha*h 12.104387 + L2reg 3.16 + L1reg 0.35 ; SHD = 157 ; DAG True
Proportion of microbatches that were clipped  0.7794176626293414
iteration 2 in inner loop, alpha 649.9659560772459 rho 100000.0 h 0.018623108866894
iteration 4 in outer loop, alpha = 19273.074822971244, rho = 1000000.0, h = 0.018623108866894
Threshold 0.3
[[0.005 0.035 0.142 0.13  0.131 0.123 0.091 0.013 0.043 0.053 0.018 0.05
  0.228 0.037 0.056 0.04  0.132 0.151 0.965 0.301 0.015 0.02  0.142 0.191
  0.019 0.019 0.034 0.018 0.101 0.026]
 [0.283 0.006 0.195 0.308 0.114 0.374 0.318 0.033 0.086 0.105 0.044 0.088
  0.317 0.106 0.073 0.123 0.391 0.237 0.633 0.19  0.039 0.14  0.297 0.341
  0.04  0.116 0.018 0.02  0.345 0.055]
 [0.031 0.028 0.006 0.028 0.036 0.046 0.017 0.008 0.014 0.011 0.008 0.032
  0.101 0.006 0.021 0.04  0.026 0.042 0.115 0.038 0.017 0.019 0.067 0.045
  0.005 0.01  0.014 0.007 0.043 0.006]
 [0.041 0.014 0.146 0.003 0.101 0.101 0.072 0.017 0.049 0.031 0.004 0.03
  0.138 0.022 0.017 0.021 0.149 0.087 0.718 0.088 0.022 0.024 0.158 0.133
  0.009 0.025 0.018 0.01  0.067 0.019]
 [0.035 0.043 0.202 0.07  0.008 0.081 0.035 0.012 0.023 0.037 0.012 0.058
  0.096 0.087 0.037 0.047 0.077 0.025 0.274 0.285 0.006 0.018 0.102 0.185
  0.023 0.042 0.016 0.019 0.108 0.023]
 [0.047 0.016 0.131 0.094 0.067 0.006 0.054 0.007 0.031 0.047 0.011 0.02
  0.057 0.072 0.041 0.079 0.162 0.076 0.34  0.182 0.032 0.045 0.183 0.114
  0.028 0.009 0.023 0.008 0.093 0.052]
 [0.083 0.029 0.267 0.09  0.112 0.123 0.005 0.016 0.026 0.031 0.008 0.082
  0.216 0.047 0.053 0.049 0.199 0.147 0.338 0.11  0.037 0.033 0.145 0.281
  0.027 0.033 0.018 0.024 0.129 0.01 ]
 [0.343 0.236 0.884 0.442 0.406 1.088 0.473 0.005 0.141 0.19  0.02  0.32
  0.283 0.47  0.145 0.226 0.554 0.756 0.629 0.382 0.132 0.24  0.464 0.559
  0.071 0.129 0.08  0.069 0.384 0.259]
 [0.191 0.056 0.335 0.119 0.218 0.169 0.229 0.039 0.005 0.163 0.011 0.075
  0.514 0.146 0.067 0.13  0.386 0.105 0.31  0.347 0.029 0.039 0.315 0.253
  0.041 0.08  0.047 0.021 0.146 0.084]
 [0.123 0.039 0.45  0.236 0.2   0.137 0.124 0.034 0.048 0.006 0.006 0.167
  0.32  0.808 0.055 0.192 0.264 0.195 0.361 0.427 0.051 0.075 0.362 0.273
  0.004 0.031 0.053 0.016 0.217 0.052]
 [0.37  0.2   0.567 1.052 0.513 0.491 0.505 0.27  0.276 1.137 0.008 0.518
  0.472 0.827 0.252 0.528 0.65  0.278 0.889 0.677 0.195 0.364 0.972 0.743
  0.161 0.47  0.107 0.095 0.498 0.259]
 [0.114 0.062 0.15  0.197 0.102 0.372 0.069 0.01  0.048 0.033 0.011 0.004
  0.227 0.041 0.05  0.07  0.203 0.348 0.269 0.188 0.043 0.05  0.501 0.172
  0.024 0.084 0.034 0.004 0.08  0.055]
 [0.035 0.013 0.058 0.036 0.11  0.103 0.041 0.015 0.012 0.018 0.008 0.031
  0.005 0.027 0.014 0.025 0.054 0.092 0.291 0.116 0.025 0.012 0.099 0.103
  0.017 0.02  0.01  0.011 0.036 0.019]
 [0.122 0.063 0.689 0.249 0.077 0.072 0.103 0.013 0.042 0.006 0.007 0.222
  0.195 0.006 0.034 0.358 0.115 0.167 0.525 0.28  0.04  0.031 0.204 0.133
  0.009 0.014 0.032 0.024 0.147 0.036]
 [0.128 0.069 0.317 0.294 0.136 0.175 0.107 0.03  0.124 0.103 0.017 0.116
  0.282 0.181 0.005 0.308 0.276 0.28  0.781 0.263 0.108 0.062 0.292 0.237
  0.034 0.067 0.022 0.067 0.287 0.077]
 [0.18  0.044 0.165 0.254 0.133 0.053 0.082 0.024 0.032 0.032 0.008 0.051
  0.256 0.021 0.016 0.006 0.235 0.052 0.276 0.173 0.039 0.043 0.129 0.276
  0.02  0.035 0.018 0.014 0.129 0.019]
 [0.056 0.018 0.222 0.025 0.082 0.057 0.033 0.009 0.011 0.024 0.006 0.043
  0.12  0.048 0.013 0.029 0.005 0.086 0.461 0.068 0.016 0.015 0.123 0.12
  0.011 0.015 0.009 0.011 0.114 0.021]
 [0.043 0.043 0.081 0.07  0.18  0.069 0.037 0.008 0.069 0.03  0.017 0.014
  0.07  0.033 0.026 0.107 0.073 0.005 0.22  0.21  0.031 0.022 0.067 0.147
  0.015 0.014 0.006 0.008 0.146 0.048]
 [0.005 0.007 0.058 0.009 0.031 0.012 0.017 0.009 0.01  0.015 0.005 0.021
  0.016 0.01  0.005 0.014 0.014 0.022 0.003 0.027 0.006 0.01  0.038 0.013
  0.007 0.009 0.003 0.005 0.012 0.008]
 [0.02  0.017 0.133 0.078 0.039 0.033 0.044 0.01  0.017 0.013 0.007 0.043
  0.056 0.031 0.032 0.04  0.085 0.021 0.241 0.005 0.016 0.008 0.065 0.146
  0.011 0.007 0.009 0.008 0.054 0.019]
 [0.334 0.173 0.406 0.237 0.863 0.188 0.292 0.034 0.227 0.089 0.042 0.13
  0.22  0.164 0.046 0.127 0.332 0.164 0.686 0.258 0.003 0.087 0.133 0.287
  0.051 0.045 0.017 0.054 0.321 0.055]
 [0.293 0.063 0.177 0.204 0.403 0.172 0.19  0.013 0.217 0.073 0.02  0.111
  0.384 0.179 0.087 0.104 0.389 0.196 0.578 0.495 0.098 0.006 0.324 0.425
  0.024 0.036 0.022 0.017 0.259 0.074]
 [0.041 0.022 0.094 0.052 0.056 0.028 0.035 0.012 0.017 0.013 0.005 0.011
  0.1   0.026 0.026 0.041 0.037 0.073 0.137 0.083 0.051 0.021 0.007 0.114
  0.016 0.012 0.005 0.006 0.075 0.016]
 [0.051 0.014 0.12  0.057 0.036 0.064 0.02  0.012 0.022 0.016 0.006 0.031
  0.075 0.032 0.026 0.024 0.046 0.054 0.477 0.03  0.013 0.012 0.042 0.006
  0.021 0.015 0.02  0.008 0.046 0.005]
 [0.361 0.185 0.686 0.459 0.19  0.226 0.221 0.093 0.188 0.885 0.054 0.261
  0.414 0.385 0.111 0.449 0.427 0.298 0.75  0.254 0.141 0.239 0.309 0.231
  0.003 0.052 0.059 0.047 0.4   0.181]
 [0.218 0.047 0.465 0.384 0.071 0.566 0.101 0.044 0.079 0.299 0.022 0.106
  0.268 0.217 0.082 0.158 0.4   0.286 0.44  0.526 0.136 0.144 0.37  0.326
  0.1   0.005 0.055 0.019 0.284 0.08 ]
 [0.168 0.257 0.243 0.235 0.469 0.271 0.234 0.055 0.136 0.086 0.031 0.187
  0.647 0.154 0.227 0.266 0.66  0.733 1.281 0.467 0.238 0.331 1.274 0.345
  0.094 0.114 0.006 0.04  0.534 0.142]
 [0.363 0.369 0.4   0.581 0.314 0.654 0.211 0.081 0.27  0.29  0.072 0.95
  0.522 0.289 0.107 0.318 0.51  0.581 0.693 0.63  0.149 0.348 0.774 0.631
  0.12  0.336 0.175 0.003 0.389 0.224]
 [0.053 0.013 0.135 0.077 0.073 0.062 0.067 0.015 0.025 0.028 0.007 0.063
  0.11  0.058 0.028 0.048 0.061 0.051 0.417 0.097 0.021 0.028 0.089 0.168
  0.014 0.031 0.008 0.014 0.004 0.017]
 [0.238 0.115 0.757 0.302 0.214 0.092 0.794 0.032 0.064 0.13  0.023 0.154
  0.351 0.176 0.096 0.262 0.275 0.14  0.57  0.332 0.107 0.099 0.365 0.533
  0.038 0.068 0.046 0.028 0.327 0.004]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.965 0.301 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.308 0.    0.374 0.318 0.    0.    0.    0.    0.
  0.317 0.    0.    0.    0.391 0.    0.633 0.    0.    0.    0.    0.341
  0.    0.    0.    0.    0.345 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.718 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.34  0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.338 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.343 0.    0.884 0.442 0.406 1.088 0.473 0.    0.    0.    0.    0.32
  0.    0.47  0.    0.    0.554 0.756 0.629 0.382 0.    0.    0.464 0.559
  0.    0.    0.    0.    0.384 0.   ]
 [0.    0.    0.335 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.514 0.    0.    0.    0.386 0.    0.31  0.347 0.    0.    0.315 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.45  0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.32  0.808 0.    0.    0.    0.    0.361 0.427 0.    0.    0.362 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.37  0.    0.567 1.052 0.513 0.491 0.505 0.    0.    1.137 0.    0.518
  0.472 0.827 0.    0.528 0.65  0.    0.889 0.677 0.    0.364 0.972 0.743
  0.    0.47  0.    0.    0.498 0.   ]
 [0.    0.    0.    0.    0.    0.372 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.348 0.    0.    0.    0.    0.501 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.689 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.358 0.    0.    0.525 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.317 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.308 0.    0.    0.781 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.461 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.334 0.    0.406 0.    0.863 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.332 0.    0.686 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.321 0.   ]
 [0.    0.    0.    0.    0.403 0.    0.    0.    0.    0.    0.    0.
  0.384 0.    0.    0.    0.389 0.    0.578 0.495 0.    0.    0.324 0.425
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.477 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.361 0.    0.686 0.459 0.    0.    0.    0.    0.    0.885 0.    0.
  0.414 0.385 0.    0.449 0.427 0.    0.75  0.    0.    0.    0.309 0.
  0.    0.    0.    0.    0.4   0.   ]
 [0.    0.    0.465 0.384 0.    0.566 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.4   0.    0.44  0.526 0.    0.    0.37  0.326
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.469 0.    0.    0.    0.    0.    0.    0.
  0.647 0.    0.    0.    0.66  0.733 1.281 0.467 0.    0.331 1.274 0.345
  0.    0.    0.    0.    0.534 0.   ]
 [0.363 0.369 0.4   0.581 0.314 0.654 0.    0.    0.    0.    0.    0.95
  0.522 0.    0.    0.318 0.51  0.581 0.693 0.63  0.    0.348 0.774 0.631
  0.    0.336 0.    0.    0.389 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.417 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.757 0.302 0.    0.    0.794 0.    0.    0.    0.    0.
  0.351 0.    0.    0.    0.    0.    0.57  0.332 0.    0.    0.365 0.533
  0.    0.    0.    0.    0.327 0.   ]]
{'fdr': 0.75, 'tpr': 0.3888888888888889, 'fpr': 0.30434782608695654, 'f1': 0.30434782608695654, 'shd': 157, 'npred': 140, 'ntrue': 90}
[0.035 0.142 0.13  0.131 0.123 0.091 0.013 0.043 0.053 0.018 0.05  0.228
 0.037 0.056 0.04  0.132 0.151 0.965 0.301 0.015 0.02  0.142 0.191 0.019
 0.019 0.034 0.018 0.101 0.026 0.283 0.195 0.308 0.114 0.374 0.318 0.033
 0.086 0.105 0.044 0.088 0.317 0.106 0.073 0.123 0.391 0.237 0.633 0.19
 0.039 0.14  0.297 0.341 0.04  0.116 0.018 0.02  0.345 0.055 0.031 0.028
 0.028 0.036 0.046 0.017 0.008 0.014 0.011 0.008 0.032 0.101 0.006 0.021
 0.04  0.026 0.042 0.115 0.038 0.017 0.019 0.067 0.045 0.005 0.01  0.014
 0.007 0.043 0.006 0.041 0.014 0.146 0.101 0.101 0.072 0.017 0.049 0.031
 0.004 0.03  0.138 0.022 0.017 0.021 0.149 0.087 0.718 0.088 0.022 0.024
 0.158 0.133 0.009 0.025 0.018 0.01  0.067 0.019 0.035 0.043 0.202 0.07
 0.081 0.035 0.012 0.023 0.037 0.012 0.058 0.096 0.087 0.037 0.047 0.077
 0.025 0.274 0.285 0.006 0.018 0.102 0.185 0.023 0.042 0.016 0.019 0.108
 0.023 0.047 0.016 0.131 0.094 0.067 0.054 0.007 0.031 0.047 0.011 0.02
 0.057 0.072 0.041 0.079 0.162 0.076 0.34  0.182 0.032 0.045 0.183 0.114
 0.028 0.009 0.023 0.008 0.093 0.052 0.083 0.029 0.267 0.09  0.112 0.123
 0.016 0.026 0.031 0.008 0.082 0.216 0.047 0.053 0.049 0.199 0.147 0.338
 0.11  0.037 0.033 0.145 0.281 0.027 0.033 0.018 0.024 0.129 0.01  0.343
 0.236 0.884 0.442 0.406 1.088 0.473 0.141 0.19  0.02  0.32  0.283 0.47
 0.145 0.226 0.554 0.756 0.629 0.382 0.132 0.24  0.464 0.559 0.071 0.129
 0.08  0.069 0.384 0.259 0.191 0.056 0.335 0.119 0.218 0.169 0.229 0.039
 0.163 0.011 0.075 0.514 0.146 0.067 0.13  0.386 0.105 0.31  0.347 0.029
 0.039 0.315 0.253 0.041 0.08  0.047 0.021 0.146 0.084 0.123 0.039 0.45
 0.236 0.2   0.137 0.124 0.034 0.048 0.006 0.167 0.32  0.808 0.055 0.192
 0.264 0.195 0.361 0.427 0.051 0.075 0.362 0.273 0.004 0.031 0.053 0.016
 0.217 0.052 0.37  0.2   0.567 1.052 0.513 0.491 0.505 0.27  0.276 1.137
 0.518 0.472 0.827 0.252 0.528 0.65  0.278 0.889 0.677 0.195 0.364 0.972
 0.743 0.161 0.47  0.107 0.095 0.498 0.259 0.114 0.062 0.15  0.197 0.102
 0.372 0.069 0.01  0.048 0.033 0.011 0.227 0.041 0.05  0.07  0.203 0.348
 0.269 0.188 0.043 0.05  0.501 0.172 0.024 0.084 0.034 0.004 0.08  0.055
 0.035 0.013 0.058 0.036 0.11  0.103 0.041 0.015 0.012 0.018 0.008 0.031
 0.027 0.014 0.025 0.054 0.092 0.291 0.116 0.025 0.012 0.099 0.103 0.017
 0.02  0.01  0.011 0.036 0.019 0.122 0.063 0.689 0.249 0.077 0.072 0.103
 0.013 0.042 0.006 0.007 0.222 0.195 0.034 0.358 0.115 0.167 0.525 0.28
 0.04  0.031 0.204 0.133 0.009 0.014 0.032 0.024 0.147 0.036 0.128 0.069
 0.317 0.294 0.136 0.175 0.107 0.03  0.124 0.103 0.017 0.116 0.282 0.181
 0.308 0.276 0.28  0.781 0.263 0.108 0.062 0.292 0.237 0.034 0.067 0.022
 0.067 0.287 0.077 0.18  0.044 0.165 0.254 0.133 0.053 0.082 0.024 0.032
 0.032 0.008 0.051 0.256 0.021 0.016 0.235 0.052 0.276 0.173 0.039 0.043
 0.129 0.276 0.02  0.035 0.018 0.014 0.129 0.019 0.056 0.018 0.222 0.025
 0.082 0.057 0.033 0.009 0.011 0.024 0.006 0.043 0.12  0.048 0.013 0.029
 0.086 0.461 0.068 0.016 0.015 0.123 0.12  0.011 0.015 0.009 0.011 0.114
 0.021 0.043 0.043 0.081 0.07  0.18  0.069 0.037 0.008 0.069 0.03  0.017
 0.014 0.07  0.033 0.026 0.107 0.073 0.22  0.21  0.031 0.022 0.067 0.147
 0.015 0.014 0.006 0.008 0.146 0.048 0.005 0.007 0.058 0.009 0.031 0.012
 0.017 0.009 0.01  0.015 0.005 0.021 0.016 0.01  0.005 0.014 0.014 0.022
 0.027 0.006 0.01  0.038 0.013 0.007 0.009 0.003 0.005 0.012 0.008 0.02
 0.017 0.133 0.078 0.039 0.033 0.044 0.01  0.017 0.013 0.007 0.043 0.056
 0.031 0.032 0.04  0.085 0.021 0.241 0.016 0.008 0.065 0.146 0.011 0.007
 0.009 0.008 0.054 0.019 0.334 0.173 0.406 0.237 0.863 0.188 0.292 0.034
 0.227 0.089 0.042 0.13  0.22  0.164 0.046 0.127 0.332 0.164 0.686 0.258
 0.087 0.133 0.287 0.051 0.045 0.017 0.054 0.321 0.055 0.293 0.063 0.177
 0.204 0.403 0.172 0.19  0.013 0.217 0.073 0.02  0.111 0.384 0.179 0.087
 0.104 0.389 0.196 0.578 0.495 0.098 0.324 0.425 0.024 0.036 0.022 0.017
 0.259 0.074 0.041 0.022 0.094 0.052 0.056 0.028 0.035 0.012 0.017 0.013
 0.005 0.011 0.1   0.026 0.026 0.041 0.037 0.073 0.137 0.083 0.051 0.021
 0.114 0.016 0.012 0.005 0.006 0.075 0.016 0.051 0.014 0.12  0.057 0.036
 0.064 0.02  0.012 0.022 0.016 0.006 0.031 0.075 0.032 0.026 0.024 0.046
 0.054 0.477 0.03  0.013 0.012 0.042 0.021 0.015 0.02  0.008 0.046 0.005
 0.361 0.185 0.686 0.459 0.19  0.226 0.221 0.093 0.188 0.885 0.054 0.261
 0.414 0.385 0.111 0.449 0.427 0.298 0.75  0.254 0.141 0.239 0.309 0.231
 0.052 0.059 0.047 0.4   0.181 0.218 0.047 0.465 0.384 0.071 0.566 0.101
 0.044 0.079 0.299 0.022 0.106 0.268 0.217 0.082 0.158 0.4   0.286 0.44
 0.526 0.136 0.144 0.37  0.326 0.1   0.055 0.019 0.284 0.08  0.168 0.257
 0.243 0.235 0.469 0.271 0.234 0.055 0.136 0.086 0.031 0.187 0.647 0.154
 0.227 0.266 0.66  0.733 1.281 0.467 0.238 0.331 1.274 0.345 0.094 0.114
 0.04  0.534 0.142 0.363 0.369 0.4   0.581 0.314 0.654 0.211 0.081 0.27
 0.29  0.072 0.95  0.522 0.289 0.107 0.318 0.51  0.581 0.693 0.63  0.149
 0.348 0.774 0.631 0.12  0.336 0.175 0.389 0.224 0.053 0.013 0.135 0.077
 0.073 0.062 0.067 0.015 0.025 0.028 0.007 0.063 0.11  0.058 0.028 0.048
 0.061 0.051 0.417 0.097 0.021 0.028 0.089 0.168 0.014 0.031 0.008 0.014
 0.017 0.238 0.115 0.757 0.302 0.214 0.092 0.794 0.032 0.064 0.13  0.023
 0.154 0.351 0.176 0.096 0.262 0.275 0.14  0.57  0.332 0.107 0.099 0.365
 0.533 0.038 0.068 0.046 0.028 0.327]
[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 1. 0. 0. 1. 0.]
 [1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
  0. 1. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
  0. 0. 1. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0.]
aucroc, aucpr (0.7085897435897436, 0.29035942476165433)
Iterations 2250
Achieves (13.034436291409676, 1e-05)-DP
