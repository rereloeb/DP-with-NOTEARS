samples  5000  graph  10 2 RE mim  minibatch size  50  noise  0.6  minibatches per NN training  250 group clipping and quantile adaptive clipping  box penalty  0
cpu
max degree  2.0  complexity indicator 1  625.0  complexity indicator 2  1086.9565217391305
model created without box penalty
model created without box penalty
cpu
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.1601221069006407
iteration 1 in outer loop, alpha = 1.1601221069006407, rho = 1.0, h = 1.1601221069006407
model created without box penalty
cpu
iteration 1 in inner loop,alpha 1.1601221069006407 rho 1.0 h 0.697926845742554
iteration 2 in inner loop,alpha 1.1601221069006407 rho 10.0 h 0.29175731529299753
iteration 3 in inner loop,alpha 1.1601221069006407 rho 100.0 h 0.08501950555491611
iteration 2 in outer loop, alpha = 9.662072662392251, rho = 100.0, h = 0.08501950555491611
model created without box penalty
cpu
iteration 1 in inner loop,alpha 9.662072662392251 rho 100.0 h 0.040170488512167424
iteration 2 in inner loop,alpha 9.662072662392251 rho 1000.0 h 0.00868366913203289
iteration 3 in outer loop, alpha = 18.34574179442514, rho = 1000.0, h = 0.00868366913203289
model created without box penalty
cpu
iteration 1 in inner loop,alpha 18.34574179442514 rho 1000.0 h 0.0030868790422431402
iteration 2 in inner loop,alpha 18.34574179442514 rho 10000.0 h 0.0008995705368377571
iteration 4 in outer loop, alpha = 27.341447162802712, rho = 10000.0, h = 0.0008995705368377571
model created without box penalty
cpu
iteration 1 in inner loop,alpha 27.341447162802712 rho 10000.0 h 0.0006484053062099093
iteration 2 in inner loop,alpha 27.341447162802712 rho 100000.0 h 0.0002616647124735749
iteration 5 in outer loop, alpha = 289.0061596363776, rho = 1000000.0, h = 0.0002616647124735749
Threshold 0.3
[[0.01  0.    2.439 0.    0.313 0.    0.201 0.    0.    0.052]
 [3.167 0.    0.255 0.    0.057 0.    0.025 0.    0.    0.049]
 [0.001 0.    0.003 0.    0.02  0.    3.039 0.    0.    0.016]
 [2.626 0.    0.121 0.    0.976 0.006 0.072 0.    0.    0.013]
 [0.001 0.    0.015 0.    0.003 0.    0.011 0.    0.    0.001]
 [0.021 0.007 0.019 0.    0.045 0.    0.033 0.    0.005 0.045]
 [0.    0.    0.    0.    0.004 0.    0.009 0.    0.    0.001]
 [0.045 0.    0.003 0.    0.143 0.009 0.081 0.    0.    3.237]
 [0.04  0.    0.064 0.004 0.117 0.    2.722 0.    0.    2.883]
 [0.016 0.    0.012 0.    2.19  0.    0.301 0.    0.    0.008]]
[[0.    0.    2.439 0.    0.313 0.    0.    0.    0.    0.   ]
 [3.167 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    3.039 0.    0.    0.   ]
 [2.626 0.    0.    0.    0.976 0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    3.237]
 [0.    0.    0.    0.    0.    0.    2.722 0.    0.    2.883]
 [0.    0.    0.    0.    2.19  0.    0.301 0.    0.    0.   ]]
{'fdr': 0.18181818181818182, 'tpr': 1.0, 'fpr': 0.05555555555555555, 'f1': 0.8999999999999999, 'shd': 2, 'npred': 11, 'ntrue': 9}
[3.269e-06 2.439e+00 2.360e-05 3.127e-01 1.057e-04 2.009e-01 1.136e-04
 6.644e-05 5.173e-02 3.167e+00 2.553e-01 1.845e-04 5.678e-02 1.726e-04
 2.526e-02 1.867e-04 1.036e-04 4.862e-02 6.936e-04 1.064e-05 4.596e-06
 2.025e-02 6.305e-05 3.039e+00 1.164e-04 1.147e-04 1.567e-02 2.626e+00
 1.722e-04 1.206e-01 9.764e-01 5.872e-03 7.239e-02 3.245e-04 5.762e-05
 1.254e-02 9.900e-04 2.162e-05 1.487e-02 2.243e-05 6.487e-05 1.146e-02
 5.745e-06 4.002e-06 6.108e-04 2.138e-02 6.722e-03 1.936e-02 2.459e-04
 4.486e-02 3.297e-02 1.213e-04 5.333e-03 4.493e-02 7.180e-05 2.638e-05
 9.349e-05 2.986e-06 4.291e-03 1.041e-04 1.811e-04 4.376e-06 1.285e-03
 4.487e-02 1.554e-04 2.565e-03 8.778e-05 1.427e-01 8.665e-03 8.118e-02
 8.880e-05 3.237e+00 4.033e-02 3.416e-04 6.358e-02 4.082e-03 1.167e-01
 8.093e-05 2.722e+00 2.648e-04 2.883e+00 1.620e-02 1.016e-04 1.176e-02
 1.046e-04 2.190e+00 2.991e-05 3.007e-01 3.538e-06 1.440e-05]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (1.0, 1.0)
model created without box penalty
number of groups for clipping  4  noise multiplier modified for group clipping  1.2
cpu
noise_multiplier  1.2  noise_multiplier_b  2.5  noise_multiplier_delta  1.2361284651454938
cpu
[0.559 0.633 0.599 0.618 0.582 0.65  0.581 0.777 0.565 0.59  0.563 0.595
 0.599 0.652 0.572 0.425 0.563 0.623 0.674 0.547 0.67  0.464 0.587 0.633
 0.513 0.67  0.619 0.664 0.569 0.534 0.421 0.561 0.638 0.437 0.543 0.523
 0.602 0.65  0.636 0.545 0.456 0.5   0.452 0.503 0.559 0.545 0.595 0.518
 0.583 0.615 0.586 0.566 0.608 0.69  0.562 0.643 0.552 0.466 0.638 0.594
 0.626 0.59  0.652 0.749 0.536 0.64  0.519 0.682 0.581 0.683 0.469 0.408
 0.488 0.647 0.596 0.555 0.586 0.613 0.659 0.696 0.579 0.623 0.589 0.663
 0.464 0.539 0.399 0.605 0.732 0.502]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.49382716049382713, 0.11721121018714775)
Objective function 186.49 = squared loss an data 9.43 + 0.5*rho*h**2 176.710652 + alpha*h 0.000000 + L2reg 0.19 + L1reg 0.16 ; SHD = 55 ; DAG False
Grad norm per param group for one microbatch
norm  0.8632104657620738  clip  tensor([1.862])
norm  0.3352518751555919  clip  tensor([0.468])
norm  3.6559773294027473  clip  tensor([5.162])
norm  2.2767868379105973  clip  tensor([3.447])
Grad norm per param group for one microbatch
norm  1.773582540547478  clip  tensor([1.670])
norm  0.5619039800482281  clip  tensor([0.486])
norm  5.620982669120714  clip  tensor([5.238])
norm  3.5554683612625326  clip  tensor([3.337])
Grad norm per param group for one microbatch
norm  3.2751080301113427  clip  tensor([1.511])
norm  0.735560363873157  clip  tensor([0.449])
norm  7.791672103105709  clip  tensor([4.671])
norm  4.839521902308644  clip  tensor([2.922])
Grad norm per param group for one microbatch
norm  1.2579696077068747  clip  tensor([1.745])
norm  0.42808099198189203  clip  tensor([0.526])
norm  4.065109099426418  clip  tensor([5.216])
norm  2.5648284435929694  clip  tensor([3.276])
Grad norm per param group for one microbatch
norm  2.1573095256482286  clip  tensor([1.974])
norm  0.6145685542673814  clip  tensor([0.615])
norm  5.242495794595823  clip  tensor([5.178])
norm  3.2848823408013876  clip  tensor([3.223])
Grad norm per param group for one microbatch
norm  2.726560141351323  clip  tensor([2.207])
norm  0.728784340280054  clip  tensor([0.670])
norm  5.983372917466325  clip  tensor([4.903])
norm  3.6885226077599476  clip  tensor([2.998])
Grad norm per param group for one microbatch
norm  4.020865251031083  clip  tensor([2.544])
norm  0.9169658425543104  clip  tensor([0.750])
norm  6.404854474285788  clip  tensor([4.924])
norm  3.937963141360985  clip  tensor([3.018])
Grad norm per param group for one microbatch
norm  5.791830052719661  clip  tensor([2.766])
norm  1.2452234190104783  clip  tensor([0.865])
norm  5.690744898163643  clip  tensor([4.437])
norm  3.4996315240141325  clip  tensor([2.838])
Grad norm per param group for one microbatch
norm  3.5225098673534903  clip  tensor([2.814])
norm  0.9574218801225216  clip  tensor([0.867])
norm  5.46081915704796  clip  tensor([4.391])
norm  3.4311819407199415  clip  tensor([2.751])
Grad norm per param group for one microbatch
norm  2.7486193805499117  clip  tensor([2.994])
norm  0.9710614535333962  clip  tensor([0.935])
norm  4.340681950082865  clip  tensor([4.507])
norm  2.6674834403684526  clip  tensor([2.805])
Grad norm per param group for one microbatch
norm  3.352732202436657  clip  tensor([3.230])
norm  1.061002848735191  clip  tensor([0.968])
norm  4.916166696435488  clip  tensor([4.496])
norm  3.0603478713445  clip  tensor([2.779])
Grad norm per param group for one microbatch
norm  3.8479421588184666  clip  tensor([3.319])
norm  0.943976283535846  clip  tensor([1.009])
norm  4.959734707643651  clip  tensor([4.282])
norm  2.9933636907633683  clip  tensor([2.729])
Grad norm per param group for one microbatch
norm  8.407992865844522  clip  tensor([3.385])
norm  1.6451209072269346  clip  tensor([0.982])
norm  6.407391970996097  clip  tensor([4.443])
norm  4.1185443703505396  clip  tensor([2.782])
Grad norm per param group for one microbatch
norm  4.46051517086599  clip  tensor([3.489])
norm  1.422846072734894  clip  tensor([1.098])
norm  4.545810382695177  clip  tensor([4.503])
norm  2.8061982863908326  clip  tensor([2.725])
Grad norm per param group for one microbatch
norm  11.289977838929108  clip  tensor([3.601])
norm  2.2500628074675806  clip  tensor([1.055])
norm  7.485529124495026  clip  tensor([4.055])
norm  4.692973382686206  clip  tensor([2.571])
Grad norm per param group for one microbatch
norm  7.691330561658246  clip  tensor([3.932])
norm  1.964191885977569  clip  tensor([1.136])
norm  5.677727792843083  clip  tensor([4.414])
norm  3.903699103612113  clip  tensor([2.744])
Grad norm per param group for one microbatch
norm  3.3110518171726904  clip  tensor([3.852])
norm  1.0437285834055208  clip  tensor([1.121])
norm  3.552003047694358  clip  tensor([4.234])
norm  2.2193541843158267  clip  tensor([2.602])
cpu
[0.211 0.253 0.16  0.241 0.22  0.357 0.258 0.267 0.229 0.508 0.23  0.28
 0.22  0.236 0.211 0.266 0.273 0.323 0.287 0.236 0.374 0.126 0.305 0.222
 0.306 0.242 0.246 0.679 0.241 0.183 0.258 0.352 0.289 0.319 0.304 0.228
 0.278 0.243 0.309 0.253 0.146 0.393 0.237 0.205 0.389 0.2   0.281 0.2
 0.22  0.288 0.158 0.123 0.302 0.195 0.184 0.186 0.299 0.17  0.167 0.313
 0.215 0.121 0.327 0.201 0.17  0.135 0.157 0.326 0.349 0.24  0.223 0.781
 0.148 0.205 0.179 0.249 0.325 0.294 0.813 0.185 0.575 0.154 0.218 0.198
 0.268 0.283 0.221 0.177 0.141 0.157]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.8271604938271605, 0.6428803490207)
Objective function 5.94 = squared loss an data 5.14 + 0.5*rho*h**2 0.467718 + alpha*h 0.000000 + L2reg 0.26 + L1reg 0.07 ; SHD = 25 ; DAG False
Proportion of microbatches that were clipped up to now since start  [0.7896543270409414, 0.7769061044373621, 0.7901446432949252, 0.7840974094957914]
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 0.9671797432253797
iteration 1 in outer loop, alpha = 0.9671797432253797, rho = 1.0, h = 0.9671797432253797
cpu
noise_multiplier  1.2  noise_multiplier_b  2.5  noise_multiplier_delta  1.2361284651454938
cpu
[0.211 0.253 0.16  0.241 0.22  0.357 0.258 0.267 0.229 0.508 0.23  0.28
 0.22  0.236 0.211 0.266 0.273 0.323 0.287 0.236 0.374 0.126 0.305 0.222
 0.306 0.242 0.246 0.679 0.241 0.183 0.258 0.352 0.289 0.319 0.304 0.228
 0.278 0.243 0.309 0.253 0.146 0.393 0.237 0.205 0.389 0.2   0.281 0.2
 0.22  0.288 0.158 0.123 0.302 0.195 0.184 0.186 0.299 0.17  0.167 0.313
 0.215 0.121 0.327 0.201 0.17  0.135 0.157 0.326 0.349 0.24  0.223 0.781
 0.148 0.205 0.179 0.249 0.325 0.294 0.813 0.185 0.575 0.154 0.218 0.198
 0.268 0.283 0.221 0.177 0.141 0.157]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.8271604938271605, 0.6428803490207)
Objective function 6.87 = squared loss an data 5.14 + 0.5*rho*h**2 0.467718 + alpha*h 0.935437 + L2reg 0.26 + L1reg 0.07 ; SHD = 25 ; DAG False
Grad norm per param group for one microbatch
norm  2.9774499060721187  clip  tensor([1.916])
norm  0.9073106336754343  clip  tensor([1.274])
norm  3.2739205757996075  clip  tensor([1.840])
norm  2.0285948883834393  clip  tensor([1.830])
Grad norm per param group for one microbatch
norm  5.928404707111937  clip  tensor([4.819])
norm  1.7660283339617318  clip  tensor([1.440])
norm  4.728077002726297  clip  tensor([4.099])
norm  2.9421758740300237  clip  tensor([2.589])
Grad norm per param group for one microbatch
norm  3.802555011692104  clip  tensor([4.945])
norm  1.200992265225848  clip  tensor([1.461])
norm  3.20267265713826  clip  tensor([4.159])
norm  2.0193348189471974  clip  tensor([2.596])
Grad norm per param group for one microbatch
norm  9.395271448978646  clip  tensor([4.848])
norm  2.098914634295359  clip  tensor([1.494])
norm  6.427779193069256  clip  tensor([3.969])
norm  4.0552338156002  clip  tensor([2.532])
Grad norm per param group for one microbatch
norm  8.126533451195149  clip  tensor([5.103])
norm  2.2544591434998305  clip  tensor([1.491])
norm  5.383039376391343  clip  tensor([3.854])
norm  3.3749260511494117  clip  tensor([2.451])
Grad norm per param group for one microbatch
norm  12.250383490341374  clip  tensor([5.176])
norm  2.5572148977322122  clip  tensor([1.507])
norm  5.973901122201657  clip  tensor([4.082])
norm  3.7489946724091454  clip  tensor([2.572])
Grad norm per param group for one microbatch
norm  11.484928067410637  clip  tensor([5.266])
norm  2.195788368305575  clip  tensor([1.638])
norm  6.184892504739337  clip  tensor([3.826])
norm  3.8945975783555222  clip  tensor([2.477])
Grad norm per param group for one microbatch
norm  4.4270633259914405  clip  tensor([5.202])
norm  1.3164280274368423  clip  tensor([1.516])
norm  3.762817685709706  clip  tensor([3.712])
norm  2.219420697680943  clip  tensor([2.324])
Grad norm per param group for one microbatch
norm  8.290176036353962  clip  tensor([5.266])
norm  1.9985812599657533  clip  tensor([1.540])
norm  6.302019370011584  clip  tensor([3.830])
norm  3.8579418299264536  clip  tensor([2.403])
Grad norm per param group for one microbatch
norm  8.759312659116722  clip  tensor([5.314])
norm  1.8973856491101102  clip  tensor([1.623])
norm  5.5673517127951575  clip  tensor([4.025])
norm  3.3883284262774107  clip  tensor([2.527])
Grad norm per param group for one microbatch
norm  7.230928258981752  clip  tensor([4.977])
norm  2.2744140844455663  clip  tensor([1.561])
norm  4.456254681728428  clip  tensor([3.662])
norm  2.759946110356606  clip  tensor([2.295])
Grad norm per param group for one microbatch
norm  7.899068635158344  clip  tensor([5.280])
norm  2.1916413949204268  clip  tensor([1.529])
norm  6.1275163186224315  clip  tensor([3.577])
norm  3.7580174804470343  clip  tensor([2.277])
Grad norm per param group for one microbatch
norm  5.090147490358125  clip  tensor([5.443])
norm  1.4439522505035514  clip  tensor([1.687])
norm  2.9968218988120507  clip  tensor([3.958])
norm  1.8527950695570483  clip  tensor([2.442])
cpu
[0.355 0.345 0.347 0.212 0.167 0.177 0.179 0.182 0.164 0.255 0.216 0.19
 0.364 0.216 0.193 0.135 0.298 0.248 0.276 0.288 0.223 0.19  0.185 0.181
 0.147 0.181 0.163 0.304 0.172 0.207 0.158 0.18  0.322 0.218 0.136 0.295
 0.246 0.142 0.287 0.298 0.4   0.208 0.216 0.205 0.239 0.188 0.184 0.243
 0.181 0.158 0.089 0.172 0.306 0.226 0.201 0.234 0.306 0.233 0.173 0.462
 0.199 0.275 0.245 0.337 0.283 0.366 0.213 0.275 0.411 0.257 0.387 0.467
 0.19  0.127 0.244 0.333 0.219 0.158 0.33  0.153 0.285 0.137 0.111 0.228
 0.175 0.319 0.234 0.198 0.215 0.242]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.7064471879286695, 0.29874378526339307)
Objective function 5.97 = squared loss an data 4.48 + 0.5*rho*h**2 0.246012 + alpha*h 0.678422 + L2reg 0.50 + L1reg 0.06 ; SHD = 18 ; DAG False
Proportion of microbatches that were clipped up to now since start  [0.7927352155974435, 0.7810856726802039, 0.7887711350214384, 0.7849688536526171]
iteration 1 in inner loop, alpha 0.9671797432253797 rho 1.0 h 0.7014436793477046
noise_multiplier  1.2  noise_multiplier_b  2.5  noise_multiplier_delta  1.2361284651454938
cpu
[0.355 0.345 0.347 0.212 0.167 0.177 0.179 0.182 0.164 0.255 0.216 0.19
 0.364 0.216 0.193 0.135 0.298 0.248 0.276 0.288 0.223 0.19  0.185 0.181
 0.147 0.181 0.163 0.304 0.172 0.207 0.158 0.18  0.322 0.218 0.136 0.295
 0.246 0.142 0.287 0.298 0.4   0.208 0.216 0.205 0.239 0.188 0.184 0.243
 0.181 0.158 0.089 0.172 0.306 0.226 0.201 0.234 0.306 0.233 0.173 0.462
 0.199 0.275 0.245 0.337 0.283 0.366 0.213 0.275 0.411 0.257 0.387 0.467
 0.19  0.127 0.244 0.333 0.219 0.158 0.33  0.153 0.285 0.137 0.111 0.228
 0.175 0.319 0.234 0.198 0.215 0.242]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.7064471879286695, 0.29874378526339307)
Objective function 8.18 = squared loss an data 4.48 + 0.5*rho*h**2 2.460116 + alpha*h 0.678422 + L2reg 0.50 + L1reg 0.06 ; SHD = 18 ; DAG False
Grad norm per param group for one microbatch
norm  3.7267732266567317  clip  tensor([2.494])
norm  1.5687285932357453  clip  tensor([1.816])
norm  3.0593502423834478  clip  tensor([2.556])
norm  1.9357464049176982  clip  tensor([2.331])
Grad norm per param group for one microbatch
norm  5.769343279753533  clip  tensor([2.740])
norm  1.8440624334979685  clip  tensor([1.905])
norm  3.53264227443695  clip  tensor([2.801])
norm  2.270818283809028  clip  tensor([2.436])
Grad norm per param group for one microbatch
norm  12.982951979357265  clip  tensor([6.798])
norm  2.4412572130398114  clip  tensor([2.059])
norm  5.653229804842953  clip  tensor([4.238])
norm  3.5193788176289065  clip  tensor([2.649])
Grad norm per param group for one microbatch
norm  8.351696633969599  clip  tensor([6.920])
norm  2.5055324522642946  clip  tensor([2.081])
norm  4.824439678408096  clip  tensor([4.180])
norm  2.9992012319395402  clip  tensor([2.695])
Grad norm per param group for one microbatch
norm  9.492606749183036  clip  tensor([7.286])
norm  2.1872515776196653  clip  tensor([2.140])
norm  6.458977789133705  clip  tensor([4.291])
norm  3.875231907206783  clip  tensor([2.660])
Grad norm per param group for one microbatch
norm  11.392637793827943  clip  tensor([7.067])
norm  3.337746866064009  clip  tensor([2.122])
norm  5.284381323074974  clip  tensor([4.220])
norm  3.2814290599135627  clip  tensor([2.623])
Grad norm per param group for one microbatch
norm  14.519503531353143  clip  tensor([7.114])
norm  2.8412733076561185  clip  tensor([2.060])
norm  6.091792114888325  clip  tensor([4.344])
norm  3.6687795500756186  clip  tensor([2.711])
Grad norm per param group for one microbatch
norm  19.830168434182166  clip  tensor([5.963])
norm  3.8215530996786864  clip  tensor([1.830])
norm  9.080208542284442  clip  tensor([3.649])
norm  5.440398380000974  clip  tensor([2.308])
Grad norm per param group for one microbatch
norm  12.550461554577058  clip  tensor([6.427])
norm  3.278751589754111  clip  tensor([1.927])
norm  5.926124990978292  clip  tensor([3.882])
norm  3.7158808000401775  clip  tensor([2.458])
Grad norm per param group for one microbatch
norm  13.217072177683155  clip  tensor([6.948])
norm  3.473320283607037  clip  tensor([1.971])
norm  6.027760116325054  clip  tensor([3.914])
norm  3.8083877539931157  clip  tensor([2.490])
Grad norm per param group for one microbatch
norm  11.434037293544408  clip  tensor([7.227])
norm  3.1911577890965726  clip  tensor([2.054])
norm  5.004603156090371  clip  tensor([4.148])
norm  3.1408111894572244  clip  tensor([2.607])
Grad norm per param group for one microbatch
norm  10.167740309537423  clip  tensor([6.634])
norm  2.400463884788216  clip  tensor([2.031])
norm  5.098513563430074  clip  tensor([3.940])
norm  3.0727452851904693  clip  tensor([2.443])
Grad norm per param group for one microbatch
norm  8.177224911570049  clip  tensor([6.829])
norm  2.0952637516603216  clip  tensor([2.123])
norm  4.6376234355189565  clip  tensor([4.206])
norm  2.8647259140088526  clip  tensor([2.650])
cpu
[0.311 0.293 0.174 0.153 0.155 0.273 0.109 0.287 0.186 0.201 0.205 0.172
 0.352 0.241 0.193 0.203 0.277 0.205 0.207 0.136 0.119 0.223 0.327 0.221
 0.146 0.241 0.165 0.384 0.204 0.389 0.188 0.144 0.167 0.208 0.16  0.243
 0.139 0.108 0.177 0.225 0.177 0.113 0.221 0.202 0.259 0.168 0.182 0.091
 0.244 0.258 0.13  0.109 0.449 0.189 0.112 0.182 0.223 0.227 0.199 0.281
 0.153 0.18  0.184 0.315 0.243 0.275 0.241 0.223 0.463 0.172 0.327 0.457
 0.132 0.125 0.179 0.177 0.14  0.123 0.346 0.158 0.206 0.259 0.195 0.18
 0.156 0.277 0.123 0.154 0.158 0.185]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.7846364883401922, 0.30442133087481926)
Objective function 6.60 = squared loss an data 5.32 + 0.5*rho*h**2 0.348790 + alpha*h 0.255449 + L2reg 0.63 + L1reg 0.05 ; SHD = 13 ; DAG True
Proportion of microbatches that were clipped up to now since start  [0.7974939369442199, 0.7847210994341148, 0.7915925626515764, 0.7877930476960388]
iteration 2 in inner loop, alpha 0.9671797432253797 rho 10.0 h 0.2641173512838897
noise_multiplier  1.2  noise_multiplier_b  2.5  noise_multiplier_delta  1.2361284651454938
cpu
[0.311 0.293 0.174 0.153 0.155 0.273 0.109 0.287 0.186 0.201 0.205 0.172
 0.352 0.241 0.193 0.203 0.277 0.205 0.207 0.136 0.119 0.223 0.327 0.221
 0.146 0.241 0.165 0.384 0.204 0.389 0.188 0.144 0.167 0.208 0.16  0.243
 0.139 0.108 0.177 0.225 0.177 0.113 0.221 0.202 0.259 0.168 0.182 0.091
 0.244 0.258 0.13  0.109 0.449 0.189 0.112 0.182 0.223 0.227 0.199 0.281
 0.153 0.18  0.184 0.315 0.243 0.275 0.241 0.223 0.463 0.172 0.327 0.457
 0.132 0.125 0.179 0.177 0.14  0.123 0.346 0.158 0.206 0.259 0.195 0.18
 0.156 0.277 0.123 0.154 0.158 0.185]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.7846364883401922, 0.30442133087481926)
Objective function 9.74 = squared loss an data 5.32 + 0.5*rho*h**2 3.487899 + alpha*h 0.255449 + L2reg 0.63 + L1reg 0.05 ; SHD = 13 ; DAG True
Grad norm per param group for one microbatch
norm  12.243213252927664  clip  tensor([1.198])
norm  3.0302318432371305  clip  tensor([1.203])
norm  4.446410708210875  clip  tensor([1.214])
norm  2.77083778785762  clip  tensor([1.190])
Grad norm per param group for one microbatch
norm  19.624708330107694  clip  tensor([1.303])
norm  4.079881604887625  clip  tensor([1.321])
norm  6.665479974212222  clip  tensor([1.334])
norm  4.054694662562894  clip  tensor([1.299])
Grad norm per param group for one microbatch
norm  16.766816075876953  clip  tensor([7.603])
norm  3.4393889972893406  clip  tensor([2.477])
norm  6.261902415109723  clip  tensor([4.749])
norm  3.9949833770988556  clip  tensor([3.011])
Grad norm per param group for one microbatch
norm  9.737273380006933  clip  tensor([7.843])
norm  2.8660022505121425  clip  tensor([2.428])
norm  4.608725834300987  clip  tensor([4.462])
norm  2.947966535676961  clip  tensor([2.841])
Grad norm per param group for one microbatch
norm  9.597049776055986  clip  tensor([9.306])
norm  2.588153011032306  clip  tensor([2.620])
norm  4.59204414708583  clip  tensor([4.810])
norm  2.8835811174569375  clip  tensor([3.019])
Grad norm per param group for one microbatch
norm  26.028948024472864  clip  tensor([8.943])
norm  4.526889966948995  clip  tensor([2.351])
norm  7.653045851228989  clip  tensor([4.397])
norm  4.76878165943893  clip  tensor([2.815])
Grad norm per param group for one microbatch
norm  28.151743599769244  clip  tensor([8.464])
norm  4.54757890387396  clip  tensor([2.428])
norm  8.223937708732107  clip  tensor([4.390])
norm  5.037184071358091  clip  tensor([2.745])
Grad norm per param group for one microbatch
norm  6.272968011715698  clip  tensor([8.341])
norm  1.6012975991743499  clip  tensor([2.428])
norm  4.225135450423816  clip  tensor([4.540])
norm  2.6318636220734737  clip  tensor([2.843])
Grad norm per param group for one microbatch
norm  11.39170508734034  clip  tensor([8.137])
norm  2.7883726287571267  clip  tensor([2.367])
norm  5.52592359960715  clip  tensor([4.498])
norm  3.4668293051476318  clip  tensor([2.844])
Grad norm per param group for one microbatch
norm  28.4236922949247  clip  tensor([7.488])
norm  4.98741578312309  clip  tensor([2.239])
norm  7.181010903813484  clip  tensor([4.337])
norm  4.52516970304485  clip  tensor([2.637])
Grad norm per param group for one microbatch
norm  23.563701278617906  clip  tensor([7.547])
norm  4.401532888232029  clip  tensor([2.224])
norm  7.359401180996548  clip  tensor([4.334])
norm  4.724831932579926  clip  tensor([2.623])
Grad norm per param group for one microbatch
norm  4.061914060529775  clip  tensor([7.625])
norm  1.2779164813025286  clip  tensor([2.305])
norm  2.2734156426666754  clip  tensor([4.370])
norm  1.3991726621410632  clip  tensor([2.700])
Grad norm per param group for one microbatch
norm  7.8089057667054105  clip  tensor([7.588])
norm  2.3897153354882668  clip  tensor([2.211])
norm  4.392355745822486  clip  tensor([4.284])
norm  2.747811462850599  clip  tensor([2.689])
Grad norm per param group for one microbatch
norm  25.67535205837114  clip  tensor([7.841])
norm  4.744096458438196  clip  tensor([2.297])
norm  7.44278534061293  clip  tensor([4.502])
norm  4.633104290327482  clip  tensor([2.731])
Grad norm per param group for one microbatch
norm  13.831800318163124  clip  tensor([8.492])
norm  3.1449098590057845  clip  tensor([2.544])
norm  5.788159300592624  clip  tensor([4.577])
norm  3.537073957808838  clip  tensor([2.811])
Grad norm per param group for one microbatch
norm  9.361610492348722  clip  tensor([8.492])
norm  2.9959385674263497  clip  tensor([2.544])
norm  4.573922191540941  clip  tensor([4.577])
norm  2.849058965007553  clip  tensor([2.811])
Grad norm per param group for one microbatch
norm  8.415802183185297  clip  tensor([8.577])
norm  2.265169073848843  clip  tensor([2.515])
norm  4.368657090996511  clip  tensor([4.683])
norm  2.7447604086497375  clip  tensor([2.892])
Grad norm per param group for one microbatch
norm  15.444926089202616  clip  tensor([8.577])
norm  2.7342976027708934  clip  tensor([2.515])
norm  5.928038708854098  clip  tensor([4.683])
norm  3.6342048141311594  clip  tensor([2.892])
Grad norm per param group for one microbatch
norm  7.782757666345078  clip  tensor([8.248])
norm  2.5554909231859897  clip  tensor([2.529])
norm  4.131789366991759  clip  tensor([4.539])
norm  2.563908819352341  clip  tensor([2.849])
Grad norm per param group for one microbatch
norm  8.523165644684743  clip  tensor([7.571])
norm  2.1912861923632554  clip  tensor([2.283])
norm  5.640008098080515  clip  tensor([4.346])
norm  3.4117301963290965  clip  tensor([2.661])
cpu
[0.113 0.246 0.058 0.153 0.137 0.187 0.057 0.129 0.125 0.36  0.155 0.124
 0.2   0.232 0.172 0.123 0.294 0.246 0.192 0.253 0.172 0.113 0.087 0.31
 0.141 0.3   0.192 0.391 0.237 0.132 0.208 0.2   0.062 0.116 0.176 0.219
 0.177 0.13  0.285 0.196 0.22  0.152 0.082 0.225 0.195 0.209 0.133 0.208
 0.215 0.13  0.075 0.044 0.079 0.097 0.114 0.143 0.131 0.226 0.125 0.334
 0.123 0.079 0.092 0.423 0.176 0.18  0.198 0.178 0.575 0.261 0.371 0.632
 0.139 0.114 0.091 0.096 0.099 0.189 0.423 0.056 0.245 0.165 0.058 0.15
 0.116 0.252 0.224 0.188 0.061 0.149]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9218106995884775, 0.5552248677248677)
Objective function 7.36 = squared loss an data 6.21 + 0.5*rho*h**2 0.378346 + alpha*h 0.084133 + L2reg 0.64 + L1reg 0.05 ; SHD = 8 ; DAG True
Proportion of microbatches that were clipped up to now since start  [0.7965045715672789, 0.785905008495833, 0.7917307225503681, 0.7885751274374949]
iteration 3 in inner loop, alpha 0.9671797432253797 rho 100.0 h 0.08698807016808274
iteration 2 in outer loop, alpha = 9.665986760033654, rho = 100.0, h = 0.08698807016808274
cpu
noise_multiplier  1.2  noise_multiplier_b  2.5  noise_multiplier_delta  1.2361284651454938
cpu
[0.113 0.246 0.058 0.153 0.137 0.187 0.057 0.129 0.125 0.36  0.155 0.124
 0.2   0.232 0.172 0.123 0.294 0.246 0.192 0.253 0.172 0.113 0.087 0.31
 0.141 0.3   0.192 0.391 0.237 0.132 0.208 0.2   0.062 0.116 0.176 0.219
 0.177 0.13  0.285 0.196 0.22  0.152 0.082 0.225 0.195 0.209 0.133 0.208
 0.215 0.13  0.075 0.044 0.079 0.097 0.114 0.143 0.131 0.226 0.125 0.334
 0.123 0.079 0.092 0.423 0.176 0.18  0.198 0.178 0.575 0.261 0.371 0.632
 0.139 0.114 0.091 0.096 0.099 0.189 0.423 0.056 0.245 0.165 0.058 0.15
 0.116 0.252 0.224 0.188 0.061 0.149]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9218106995884775, 0.5552248677248677)
Objective function 8.12 = squared loss an data 6.21 + 0.5*rho*h**2 0.378346 + alpha*h 0.840826 + L2reg 0.64 + L1reg 0.05 ; SHD = 8 ; DAG True
Grad norm per param group for one microbatch
norm  13.997281355764619  clip  tensor([9.374])
norm  3.3865872855999166  clip  tensor([2.639])
norm  6.771983056004813  clip  tensor([4.761])
norm  4.091408251246826  clip  tensor([2.935])
Grad norm per param group for one microbatch
norm  6.707050887779502  clip  tensor([9.138])
norm  2.5702559664391798  clip  tensor([2.614])
norm  4.194098667780454  clip  tensor([4.830])
norm  2.5963804512580237  clip  tensor([2.939])
Grad norm per param group for one microbatch
norm  15.819001576158104  clip  tensor([8.520])
norm  3.5211204348925755  clip  tensor([2.471])
norm  7.759690939543744  clip  tensor([4.799])
norm  4.55171134983624  clip  tensor([2.981])
Grad norm per param group for one microbatch
norm  15.349820845162984  clip  tensor([8.497])
norm  4.362605612285154  clip  tensor([2.518])
norm  6.213029251559905  clip  tensor([4.688])
norm  3.9104762506689  clip  tensor([2.931])
Grad norm per param group for one microbatch
norm  11.501952885599074  clip  tensor([8.583])
norm  2.8691201542560743  clip  tensor([2.465])
norm  5.01603259762506  clip  tensor([4.567])
norm  3.1757990261227365  clip  tensor([2.854])
Grad norm per param group for one microbatch
norm  11.747149801087165  clip  tensor([8.133])
norm  2.522401211094224  clip  tensor([2.384])
norm  6.749035630560331  clip  tensor([4.375])
norm  4.06862961022003  clip  tensor([2.697])
Grad norm per param group for one microbatch
norm  8.616647748887884  clip  tensor([7.695])
norm  2.3063607383430345  clip  tensor([2.296])
norm  5.541500284983456  clip  tensor([4.435])
norm  3.5421755694114876  clip  tensor([2.697])
Grad norm per param group for one microbatch
norm  17.191731389643465  clip  tensor([8.747])
norm  4.083126863375909  clip  tensor([2.417])
norm  6.4072934248402005  clip  tensor([4.656])
norm  3.967003358003974  clip  tensor([2.846])
Grad norm per param group for one microbatch
norm  10.91440317655194  clip  tensor([8.457])
norm  3.107014710593397  clip  tensor([2.513])
norm  5.676492296840456  clip  tensor([4.667])
norm  3.4527704342099184  clip  tensor([2.846])
Grad norm per param group for one microbatch
norm  14.13997971748157  clip  tensor([8.918])
norm  3.10354824358858  clip  tensor([2.554])
norm  5.625518385348403  clip  tensor([4.713])
norm  3.438612002550048  clip  tensor([2.947])
Grad norm per param group for one microbatch
norm  25.82814720280427  clip  tensor([8.519])
norm  4.913804511608387  clip  tensor([2.417])
norm  7.674884336778746  clip  tensor([4.454])
norm  4.7558104259718395  clip  tensor([2.818])
Grad norm per param group for one microbatch
norm  5.699659617949718  clip  tensor([8.440])
norm  2.185264529233218  clip  tensor([2.443])
norm  3.7125973369587926  clip  tensor([4.691])
norm  2.301341861890226  clip  tensor([2.906])
Grad norm per param group for one microbatch
norm  12.632470152469246  clip  tensor([8.955])
norm  3.391733626016075  clip  tensor([2.525])
norm  5.477114899646893  clip  tensor([4.671])
norm  3.455923808643017  clip  tensor([2.876])
cpu
[0.077 0.254 0.081 0.16  0.293 0.173 0.051 0.13  0.105 0.41  0.112 0.145
 0.386 0.206 0.152 0.151 0.14  0.229 0.201 0.212 0.163 0.169 0.189 0.293
 0.104 0.152 0.155 0.45  0.149 0.122 0.247 0.19  0.167 0.09  0.147 0.102
 0.163 0.082 0.135 0.097 0.277 0.246 0.145 0.104 0.153 0.09  0.08  0.159
 0.168 0.081 0.076 0.055 0.087 0.133 0.123 0.102 0.153 0.089 0.083 0.375
 0.105 0.058 0.111 0.394 0.141 0.216 0.138 0.172 0.495 0.24  0.109 0.671
 0.16  0.19  0.121 0.119 0.136 0.176 0.585 0.144 0.375 0.144 0.05  0.139
 0.184 0.284 0.179 0.244 0.05  0.097]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.962962962962963, 0.7178130511463845)
Objective function 7.90 = squared loss an data 6.56 + 0.5*rho*h**2 0.137140 + alpha*h 0.506224 + L2reg 0.65 + L1reg 0.04 ; SHD = 8 ; DAG True
Proportion of microbatches that were clipped up to now since start  [0.8026232114467409, 0.7891891891891892, 0.7973767885532591, 0.7926868044515103]
iteration 1 in inner loop, alpha 9.665986760033654 rho 100.0 h 0.052371675085924
noise_multiplier  1.2  noise_multiplier_b  2.5  noise_multiplier_delta  1.2361284651454938
cpu
[0.077 0.254 0.081 0.16  0.293 0.173 0.051 0.13  0.105 0.41  0.112 0.145
 0.386 0.206 0.152 0.151 0.14  0.229 0.201 0.212 0.163 0.169 0.189 0.293
 0.104 0.152 0.155 0.45  0.149 0.122 0.247 0.19  0.167 0.09  0.147 0.102
 0.163 0.082 0.135 0.097 0.277 0.246 0.145 0.104 0.153 0.09  0.08  0.159
 0.168 0.081 0.076 0.055 0.087 0.133 0.123 0.102 0.153 0.089 0.083 0.375
 0.105 0.058 0.111 0.394 0.141 0.216 0.138 0.172 0.495 0.24  0.109 0.671
 0.16  0.19  0.121 0.119 0.136 0.176 0.585 0.144 0.375 0.144 0.05  0.139
 0.184 0.284 0.179 0.244 0.05  0.097]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.962962962962963, 0.7178130511463845)
Objective function 9.14 = squared loss an data 6.56 + 0.5*rho*h**2 1.371396 + alpha*h 0.506224 + L2reg 0.65 + L1reg 0.04 ; SHD = 8 ; DAG True
Grad norm per param group for one microbatch
norm  9.487378994151829  clip  tensor([9.133])
norm  2.4399032719564415  clip  tensor([2.530])
norm  5.257701017200121  clip  tensor([4.607])
norm  3.216864471617146  clip  tensor([2.792])
Grad norm per param group for one microbatch
norm  15.419793218191883  clip  tensor([9.510])
norm  3.650069687278922  clip  tensor([2.632])
norm  5.292311149053301  clip  tensor([4.644])
norm  3.330482253909017  clip  tensor([2.942])
Grad norm per param group for one microbatch
norm  12.006621592921197  clip  tensor([9.300])
norm  3.370875349496528  clip  tensor([2.452])
norm  5.454789028257848  clip  tensor([4.585])
norm  3.4690182710836943  clip  tensor([2.849])
Grad norm per param group for one microbatch
norm  11.077057994423637  clip  tensor([9.673])
norm  2.642418921886023  clip  tensor([2.581])
norm  5.506455155472117  clip  tensor([4.837])
norm  3.3091301583846477  clip  tensor([3.048])
Grad norm per param group for one microbatch
norm  17.421067108238184  clip  tensor([9.581])
norm  3.9434527523817278  clip  tensor([2.481])
norm  6.774272530480356  clip  tensor([4.852])
norm  4.1306184831322925  clip  tensor([2.990])
Grad norm per param group for one microbatch
norm  11.338793517532906  clip  tensor([8.623])
norm  3.419397292270271  clip  tensor([2.401])
norm  4.8167585156828805  clip  tensor([4.517])
norm  3.0038902311280125  clip  tensor([2.848])
Grad norm per param group for one microbatch
norm  8.767471676818378  clip  tensor([8.856])
norm  3.07941432816946  clip  tensor([2.556])
norm  4.285904826899388  clip  tensor([4.781])
norm  2.686726498531414  clip  tensor([2.965])
Grad norm per param group for one microbatch
norm  9.106180684936938  clip  tensor([8.567])
norm  2.6143861275724345  clip  tensor([2.345])
norm  4.5184143329114566  clip  tensor([4.397])
norm  2.7710113735733595  clip  tensor([2.787])
Grad norm per param group for one microbatch
norm  14.108668616990931  clip  tensor([9.787])
norm  3.1322367942714493  clip  tensor([2.685])
norm  5.266317570880028  clip  tensor([4.971])
norm  3.212792598590452  clip  tensor([3.140])
Grad norm per param group for one microbatch
norm  14.971760667083073  clip  tensor([10.495])
norm  3.5093350735050253  clip  tensor([2.886])
norm  6.7481040024144585  clip  tensor([5.085])
norm  4.190420377252192  clip  tensor([3.198])
Grad norm per param group for one microbatch
norm  16.35349131821246  clip  tensor([9.052])
norm  3.8660359474510866  clip  tensor([2.551])
norm  7.364626267632591  clip  tensor([4.852])
norm  4.509254014545888  clip  tensor([3.040])
Grad norm per param group for one microbatch
norm  18.516731772635875  clip  tensor([9.036])
norm  4.054399544875713  clip  tensor([2.513])
norm  7.583731940869191  clip  tensor([4.908])
norm  4.654109161438017  clip  tensor([3.051])
Grad norm per param group for one microbatch
norm  15.686121349350115  clip  tensor([9.014])
norm  4.100999569322308  clip  tensor([2.491])
norm  6.093898840364047  clip  tensor([4.799])
norm  3.8841685307380165  clip  tensor([2.915])
Grad norm per param group for one microbatch
norm  16.133594649403637  clip  tensor([9.104])
norm  4.14454556712615  clip  tensor([2.553])
norm  7.000472059478411  clip  tensor([4.833])
norm  4.3563138886656905  clip  tensor([3.024])
Grad norm per param group for one microbatch
norm  11.317526720399584  clip  tensor([8.415])
norm  2.990580844175454  clip  tensor([2.520])
norm  5.224566414465895  clip  tensor([4.612])
norm  3.3212195189172555  clip  tensor([2.889])
Grad norm per param group for one microbatch
norm  15.460121053010598  clip  tensor([8.962])
norm  3.1140796550120196  clip  tensor([2.717])
norm  5.895150066895606  clip  tensor([4.820])
norm  3.6909745872545887  clip  tensor([3.029])
Grad norm per param group for one microbatch
norm  8.815326900623802  clip  tensor([8.713])
norm  2.8850823721090166  clip  tensor([2.411])
norm  5.098150500201487  clip  tensor([4.774])
norm  3.2034054724687424  clip  tensor([2.916])
cpu
[0.031 0.19  0.029 0.167 0.257 0.216 0.079 0.086 0.212 0.728 0.218 0.147
 0.189 0.308 0.183 0.167 0.121 0.128 0.209 0.064 0.098 0.181 0.261 0.258
 0.132 0.108 0.07  0.658 0.078 0.163 0.541 0.242 0.244 0.153 0.166 0.128
 0.112 0.104 0.099 0.044 0.152 0.135 0.058 0.099 0.16  0.081 0.043 0.059
 0.055 0.082 0.078 0.077 0.101 0.051 0.057 0.045 0.094 0.066 0.129 0.21
 0.053 0.042 0.073 0.135 0.115 0.108 0.138 0.303 0.195 0.228 0.116 0.709
 0.156 0.083 0.17  0.127 0.18  0.141 0.484 0.149 0.361 0.078 0.098 0.154
 0.037 0.196 0.254 0.168 0.024 0.035]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9588477366255144, 0.830250747642052)
Objective function 8.12 = squared loss an data 7.07 + 0.5*rho*h**2 0.200672 + alpha*h 0.193644 + L2reg 0.62 + L1reg 0.04 ; SHD = 5 ; DAG True
Proportion of microbatches that were clipped up to now since start  [0.8035870169034204, 0.7914451234029045, 0.7957304975795572, 0.7927148638996905]
iteration 2 in inner loop, alpha 9.665986760033654 rho 1000.0 h 0.02003359391486015
iteration 3 in outer loop, alpha = 29.699580674893802, rho = 1000.0, h = 0.02003359391486015
cpu
noise_multiplier  1.2  noise_multiplier_b  2.5  noise_multiplier_delta  1.2361284651454938
cpu
[0.031 0.19  0.029 0.167 0.257 0.216 0.079 0.086 0.212 0.728 0.218 0.147
 0.189 0.308 0.183 0.167 0.121 0.128 0.209 0.064 0.098 0.181 0.261 0.258
 0.132 0.108 0.07  0.658 0.078 0.163 0.541 0.242 0.244 0.153 0.166 0.128
 0.112 0.104 0.099 0.044 0.152 0.135 0.058 0.099 0.16  0.081 0.043 0.059
 0.055 0.082 0.078 0.077 0.101 0.051 0.057 0.045 0.094 0.066 0.129 0.21
 0.053 0.042 0.073 0.135 0.115 0.108 0.138 0.303 0.195 0.228 0.116 0.709
 0.156 0.083 0.17  0.127 0.18  0.141 0.484 0.149 0.361 0.078 0.098 0.154
 0.037 0.196 0.254 0.168 0.024 0.035]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9588477366255144, 0.830250747642052)
Objective function 8.52 = squared loss an data 7.07 + 0.5*rho*h**2 0.200672 + alpha*h 0.594989 + L2reg 0.62 + L1reg 0.04 ; SHD = 5 ; DAG True
Grad norm per param group for one microbatch
norm  28.062640409337735  clip  tensor([9.507])
norm  4.514011319514293  clip  tensor([2.586])
norm  7.558075711309356  clip  tensor([4.986])
norm  4.694982511975738  clip  tensor([3.080])
Grad norm per param group for one microbatch
norm  10.008208324804219  clip  tensor([9.511])
norm  3.188579032313678  clip  tensor([2.417])
norm  4.868512067396948  clip  tensor([4.727])
norm  3.078771424263068  clip  tensor([2.996])
Grad norm per param group for one microbatch
norm  12.213928614569985  clip  tensor([10.244])
norm  3.389122852085357  clip  tensor([2.583])
norm  6.00094808560748  clip  tensor([5.043])
norm  3.5885944050711536  clip  tensor([3.073])
Grad norm per param group for one microbatch
norm  9.589539577812603  clip  tensor([9.221])
norm  2.511945909991599  clip  tensor([2.394])
norm  5.272694678219866  clip  tensor([4.861])
norm  3.14652972354725  clip  tensor([3.041])
Grad norm per param group for one microbatch
norm  16.979535208142337  clip  tensor([8.702])
norm  3.7887164019482205  clip  tensor([2.373])
norm  5.8363605306423585  clip  tensor([4.651])
norm  3.631526980860239  clip  tensor([2.867])
Grad norm per param group for one microbatch
norm  14.45980604090943  clip  tensor([8.717])
norm  3.2013548040351836  clip  tensor([2.380])
norm  5.067112010484102  clip  tensor([4.644])
norm  3.150625458154986  clip  tensor([2.879])
cpu
[0.018 0.221 0.032 0.048 0.27  0.18  0.11  0.103 0.068 0.682 0.241 0.142
 0.357 0.354 0.133 0.228 0.101 0.425 0.146 0.076 0.159 0.237 0.138 0.369
 0.123 0.094 0.13  0.593 0.096 0.092 0.533 0.188 0.264 0.115 0.149 0.181
 0.212 0.045 0.069 0.019 0.105 0.194 0.065 0.062 0.106 0.051 0.038 0.069
 0.056 0.092 0.138 0.044 0.055 0.046 0.068 0.059 0.074 0.057 0.058 0.069
 0.053 0.03  0.083 0.108 0.062 0.168 0.081 0.297 0.333 0.204 0.148 0.76
 0.141 0.131 0.188 0.075 0.155 0.218 0.573 0.075 0.505 0.09  0.042 0.068
 0.048 0.247 0.178 0.158 0.016 0.02 ]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9753086419753086, 0.8757797270955168)
Objective function 8.22 = squared loss an data 7.13 + 0.5*rho*h**2 0.081303 + alpha*h 0.378720 + L2reg 0.60 + L1reg 0.04 ; SHD = 6 ; DAG True
Proportion of microbatches that were clipped up to now since start  [0.8023889690556357, 0.7879589546256213, 0.7950136283469617, 0.789642456309123]
iteration 1 in inner loop, alpha 29.699580674893802 rho 1000.0 h 0.01275167894429785
noise_multiplier  1.2  noise_multiplier_b  2.5  noise_multiplier_delta  1.2361284651454938
cpu
[0.018 0.221 0.032 0.048 0.27  0.18  0.11  0.103 0.068 0.682 0.241 0.142
 0.357 0.354 0.133 0.228 0.101 0.425 0.146 0.076 0.159 0.237 0.138 0.369
 0.123 0.094 0.13  0.593 0.096 0.092 0.533 0.188 0.264 0.115 0.149 0.181
 0.212 0.045 0.069 0.019 0.105 0.194 0.065 0.062 0.106 0.051 0.038 0.069
 0.056 0.092 0.138 0.044 0.055 0.046 0.068 0.059 0.074 0.057 0.058 0.069
 0.053 0.03  0.083 0.108 0.062 0.168 0.081 0.297 0.333 0.204 0.148 0.76
 0.141 0.131 0.188 0.075 0.155 0.218 0.573 0.075 0.505 0.09  0.042 0.068
 0.048 0.247 0.178 0.158 0.016 0.02 ]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9753086419753086, 0.8757797270955168)
Objective function 8.95 = squared loss an data 7.13 + 0.5*rho*h**2 0.813027 + alpha*h 0.378720 + L2reg 0.60 + L1reg 0.04 ; SHD = 6 ; DAG True
Grad norm per param group for one microbatch
norm  22.703956606826935  clip  tensor([10.708])
norm  4.3814637440106  clip  tensor([2.540])
norm  6.7703340202646585  clip  tensor([4.760])
norm  4.276694333650653  clip  tensor([3.001])
Grad norm per param group for one microbatch
norm  12.833824218451683  clip  tensor([11.524])
norm  2.873876915821154  clip  tensor([2.478])
norm  4.886485805311807  clip  tensor([4.827])
norm  2.989115710360878  clip  tensor([3.031])
Grad norm per param group for one microbatch
norm  8.872877093097285  clip  tensor([9.791])
norm  2.3726563463054977  clip  tensor([2.333])
norm  4.843660507011588  clip  tensor([4.830])
norm  2.945703501737926  clip  tensor([2.924])
Grad norm per param group for one microbatch
norm  16.68430617702272  clip  tensor([9.793])
norm  3.4930926861879077  clip  tensor([2.449])
norm  6.671389684457838  clip  tensor([4.846])
norm  3.9541313033103966  clip  tensor([3.013])
Grad norm per param group for one microbatch
norm  23.843406920853823  clip  tensor([9.853])
norm  4.675932451603096  clip  tensor([2.472])
norm  7.083113609211187  clip  tensor([4.802])
norm  4.463486841682348  clip  tensor([2.992])
Grad norm per param group for one microbatch
norm  21.10378914066404  clip  tensor([9.369])
norm  4.047156623441966  clip  tensor([2.262])
norm  7.569828906639347  clip  tensor([4.709])
norm  4.5402488940009125  clip  tensor([2.894])
Grad norm per param group for one microbatch
norm  11.894872837011725  clip  tensor([9.369])
norm  2.727345554514474  clip  tensor([2.262])
norm  5.543527290862708  clip  tensor([4.709])
norm  3.4262440101192  clip  tensor([2.894])
Grad norm per param group for one microbatch
norm  8.78015301809924  clip  tensor([10.581])
norm  1.8012451050082157  clip  tensor([2.501])
norm  4.503992699976488  clip  tensor([5.162])
norm  2.791982658201886  clip  tensor([3.221])
Grad norm per param group for one microbatch
norm  25.506378111416716  clip  tensor([9.980])
norm  4.546409976473392  clip  tensor([2.388])
norm  8.110868494278574  clip  tensor([4.954])
norm  5.080409947011969  clip  tensor([3.096])
Grad norm per param group for one microbatch
norm  18.295016812214648  clip  tensor([9.466])
norm  3.946402028710148  clip  tensor([2.346])
norm  7.003104825571099  clip  tensor([4.720])
norm  4.38817183233104  clip  tensor([2.887])
Grad norm per param group for one microbatch
norm  30.405732415412924  clip  tensor([9.125])
norm  6.166600054870893  clip  tensor([2.351])
norm  7.910052679093037  clip  tensor([4.835])
norm  5.046733310399425  clip  tensor([2.958])
cpu
[0.01  0.221 0.008 0.112 0.165 0.079 0.049 0.048 0.11  0.954 0.342 0.037
 0.306 0.497 0.307 0.139 0.048 0.365 0.091 0.024 0.039 0.182 0.101 0.456
 0.085 0.045 0.177 0.681 0.198 0.197 0.407 0.518 0.237 0.064 0.122 0.175
 0.093 0.027 0.05  0.019 0.143 0.065 0.035 0.038 0.038 0.071 0.018 0.099
 0.022 0.062 0.069 0.051 0.025 0.053 0.114 0.029 0.023 0.05  0.172 0.135
 0.031 0.014 0.067 0.158 0.042 0.147 0.136 0.201 0.166 0.295 0.095 0.732
 0.181 0.221 0.097 0.113 0.172 0.341 0.673 0.118 0.541 0.056 0.027 0.042
 0.027 0.326 0.179 0.2   0.013 0.018]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9753086419753085, 0.8492402659069327)
Objective function 8.19 = squared loss an data 7.33 + 0.5*rho*h**2 0.139488 + alpha*h 0.156868 + L2reg 0.52 + L1reg 0.04 ; SHD = 8 ; DAG True
Proportion of microbatches that were clipped up to now since start  [0.8016958643308535, 0.7878569714422846, 0.7947364210863131, 0.7896968242540596]
iteration 2 in inner loop, alpha 29.699580674893802 rho 10000.0 h 0.0052818258143965124
noise_multiplier  1.2  noise_multiplier_b  2.5  noise_multiplier_delta  1.2361284651454938
cpu
[0.01  0.221 0.008 0.112 0.165 0.079 0.049 0.048 0.11  0.954 0.342 0.037
 0.306 0.497 0.307 0.139 0.048 0.365 0.091 0.024 0.039 0.182 0.101 0.456
 0.085 0.045 0.177 0.681 0.198 0.197 0.407 0.518 0.237 0.064 0.122 0.175
 0.093 0.027 0.05  0.019 0.143 0.065 0.035 0.038 0.038 0.071 0.018 0.099
 0.022 0.062 0.069 0.051 0.025 0.053 0.114 0.029 0.023 0.05  0.172 0.135
 0.031 0.014 0.067 0.158 0.042 0.147 0.136 0.201 0.166 0.295 0.095 0.732
 0.181 0.221 0.097 0.113 0.172 0.341 0.673 0.118 0.541 0.056 0.027 0.042
 0.027 0.326 0.179 0.2   0.013 0.018]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9753086419753085, 0.8492402659069327)
Objective function 9.44 = squared loss an data 7.33 + 0.5*rho*h**2 1.394884 + alpha*h 0.156868 + L2reg 0.52 + L1reg 0.04 ; SHD = 8 ; DAG True
Grad norm per param group for one microbatch
norm  22.666541511400112  clip  tensor([2.467])
norm  2.4714609558589644  clip  tensor([2.071])
norm  4.880761441000383  clip  tensor([2.476])
norm  3.0269971085087235  clip  tensor([2.432])
Grad norm per param group for one microbatch
norm  18.50622887419147  clip  tensor([15.614])
norm  1.3580683518960257  clip  tensor([2.278])
norm  4.358944203472327  clip  tensor([4.722])
norm  2.7855220845170363  clip  tensor([2.903])
Grad norm per param group for one microbatch
norm  18.562365045676135  clip  tensor([17.737])
norm  2.7121678702335754  clip  tensor([2.369])
norm  5.191569216924238  clip  tensor([5.023])
norm  3.327839086854213  clip  tensor([3.153])
Grad norm per param group for one microbatch
norm  14.9015565397663  clip  tensor([16.670])
norm  2.789403495447679  clip  tensor([2.175])
norm  5.016264200384771  clip  tensor([4.762])
norm  3.284562435339779  clip  tensor([2.940])
Grad norm per param group for one microbatch
norm  13.113006160432771  clip  tensor([11.491])
norm  2.5259625565522943  clip  tensor([2.323])
norm  5.6349187057158865  clip  tensor([5.191])
norm  3.437089269026502  clip  tensor([3.214])
Grad norm per param group for one microbatch
norm  20.142885772280447  clip  tensor([11.255])
norm  3.539942149277255  clip  tensor([2.167])
norm  8.354533652221805  clip  tensor([4.740])
norm  5.063142788908385  clip  tensor([2.906])
Grad norm per param group for one microbatch
norm  11.054239656774861  clip  tensor([10.864])
norm  2.115776359274554  clip  tensor([2.237])
norm  4.908631581300762  clip  tensor([4.920])
norm  3.074597384159941  clip  tensor([3.081])
Grad norm per param group for one microbatch
norm  10.471877833484072  clip  tensor([10.155])
norm  1.807231725825962  clip  tensor([2.154])
norm  4.703519734740592  clip  tensor([4.848])
norm  2.894398749653369  clip  tensor([3.025])
Grad norm per param group for one microbatch
norm  25.155966010453536  clip  tensor([9.914])
norm  3.927532890982527  clip  tensor([2.101])
norm  7.945680813888039  clip  tensor([4.902])
norm  4.883698807959516  clip  tensor([3.002])
Grad norm per param group for one microbatch
norm  11.691954655881313  clip  tensor([10.579])
norm  2.516741683485412  clip  tensor([2.088])
norm  5.109936439535855  clip  tensor([4.627])
norm  3.1365738951606623  clip  tensor([2.841])
Grad norm per param group for one microbatch
norm  12.752473968694021  clip  tensor([11.465])
norm  2.9740049803767357  clip  tensor([2.166])
norm  5.54997000548069  clip  tensor([4.962])
norm  3.5775504704243963  clip  tensor([3.089])
Grad norm per param group for one microbatch
norm  15.560156842164632  clip  tensor([10.660])
norm  3.1392458923732502  clip  tensor([2.137])
norm  6.273563941953082  clip  tensor([5.023])
norm  3.8804878987654727  clip  tensor([3.198])
Grad norm per param group for one microbatch
norm  13.277669154724048  clip  tensor([11.450])
norm  2.338100503832752  clip  tensor([2.100])
norm  7.721552643113214  clip  tensor([4.846])
norm  4.633182693024063  clip  tensor([3.055])
Grad norm per param group for one microbatch
norm  16.3353490982263  clip  tensor([11.679])
norm  3.241013270576012  clip  tensor([2.039])
norm  6.038402174800832  clip  tensor([4.812])
norm  3.7107662845874505  clip  tensor([2.966])
cpu
[0.006 0.339 0.008 0.076 0.221 0.117 0.046 0.014 0.082 1.143 0.317 0.025
 0.433 0.612 0.311 0.189 0.045 0.237 0.031 0.017 0.02  0.108 0.141 0.584
 0.018 0.038 0.077 0.799 0.187 0.299 0.544 0.462 0.194 0.081 0.117 0.282
 0.074 0.011 0.061 0.011 0.167 0.088 0.02  0.022 0.015 0.026 0.008 0.039
 0.015 0.043 0.053 0.038 0.013 0.046 0.041 0.015 0.01  0.026 0.07  0.06
 0.03  0.008 0.036 0.17  0.047 0.235 0.111 0.33  0.156 0.21  0.075 0.993
 0.218 0.17  0.175 0.046 0.246 0.509 0.834 0.086 0.664 0.089 0.025 0.068
 0.015 0.379 0.119 0.138 0.005 0.008]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9862825788751715, 0.8990130240130241)
Objective function 8.24 = squared loss an data 7.48 + 0.5*rho*h**2 0.206489 + alpha*h 0.060355 + L2reg 0.45 + L1reg 0.04 ; SHD = 7 ; DAG True
Proportion of microbatches that were clipped up to now since start  [0.8005506518746457, 0.7846789213701514, 0.7912381569357843, 0.7892137015142927]
iteration 3 in inner loop, alpha 29.699580674893802 rho 100000.0 h 0.0020321884166421
iteration 4 in outer loop, alpha = 232.9184223391038, rho = 100000.0, h = 0.0020321884166421
cpu
noise_multiplier  1.2  noise_multiplier_b  2.5  noise_multiplier_delta  1.2361284651454938
cpu
[0.006 0.339 0.008 0.076 0.221 0.117 0.046 0.014 0.082 1.143 0.317 0.025
 0.433 0.612 0.311 0.189 0.045 0.237 0.031 0.017 0.02  0.108 0.141 0.584
 0.018 0.038 0.077 0.799 0.187 0.299 0.544 0.462 0.194 0.081 0.117 0.282
 0.074 0.011 0.061 0.011 0.167 0.088 0.02  0.022 0.015 0.026 0.008 0.039
 0.015 0.043 0.053 0.038 0.013 0.046 0.041 0.015 0.01  0.026 0.07  0.06
 0.03  0.008 0.036 0.17  0.047 0.235 0.111 0.33  0.156 0.21  0.075 0.993
 0.218 0.17  0.175 0.046 0.246 0.509 0.834 0.086 0.664 0.089 0.025 0.068
 0.015 0.379 0.119 0.138 0.005 0.008]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9862825788751715, 0.8990130240130241)
Objective function 8.65 = squared loss an data 7.48 + 0.5*rho*h**2 0.206489 + alpha*h 0.473334 + L2reg 0.45 + L1reg 0.04 ; SHD = 7 ; DAG True
Grad norm per param group for one microbatch
norm  21.467505886682115  clip  tensor([4.658])
norm  2.40816367120593  clip  tensor([2.020])
norm  5.21233019261593  clip  tensor([4.284])
norm  3.1912872453313663  clip  tensor([3.114])
Grad norm per param group for one microbatch
norm  29.19674056610028  clip  tensor([22.259])
norm  3.95982464589043  clip  tensor([2.114])
norm  7.513883357213416  clip  tensor([4.749])
norm  4.45123282143784  clip  tensor([2.939])
Grad norm per param group for one microbatch
norm  21.886996328681633  clip  tensor([22.285])
norm  2.6813946024935906  clip  tensor([1.949])
norm  6.10434716541518  clip  tensor([4.735])
norm  3.64868806748097  clip  tensor([3.000])
Grad norm per param group for one microbatch
norm  24.695063809575633  clip  tensor([17.654])
norm  3.1453176847056397  clip  tensor([2.079])
norm  6.458218654314864  clip  tensor([5.085])
norm  3.8257113912675216  clip  tensor([3.135])
Grad norm per param group for one microbatch
norm  18.775373195052413  clip  tensor([18.476])
norm  2.105868191387645  clip  tensor([2.018])
norm  3.863965933369766  clip  tensor([4.835])
norm  2.405669491581343  clip  tensor([3.006])
Grad norm per param group for one microbatch
norm  15.817493790352705  clip  tensor([14.352])
norm  3.291375502867246  clip  tensor([1.978])
norm  6.123167225458729  clip  tensor([4.858])
norm  3.7354095883902434  clip  tensor([2.971])
Grad norm per param group for one microbatch
norm  30.653459741501045  clip  tensor([11.402])
norm  4.961374267350475  clip  tensor([1.989])
norm  11.195082227542912  clip  tensor([5.035])
norm  6.63997433343267  clip  tensor([3.112])
Grad norm per param group for one microbatch
norm  18.28581041025387  clip  tensor([10.943])
norm  3.2342664142068522  clip  tensor([1.987])
norm  7.563081627024348  clip  tensor([4.794])
norm  4.573674578264864  clip  tensor([3.088])
Grad norm per param group for one microbatch
norm  16.78970837160284  clip  tensor([9.920])
norm  3.413901722553499  clip  tensor([1.919])
norm  6.84639018915062  clip  tensor([4.811])
norm  4.272168311032053  clip  tensor([2.946])
Grad norm per param group for one microbatch
norm  10.914076802280704  clip  tensor([10.199])
norm  2.1567950441271906  clip  tensor([1.885])
norm  4.4244352351430685  clip  tensor([5.051])
norm  2.75190125337755  clip  tensor([3.112])
Grad norm per param group for one microbatch
norm  12.32720072134114  clip  tensor([12.136])
norm  2.32552091580684  clip  tensor([1.969])
norm  5.205657241671375  clip  tensor([4.998])
norm  3.2014675745750836  clip  tensor([3.111])
Grad norm per param group for one microbatch
norm  16.373146132886045  clip  tensor([12.136])
norm  2.8799675461014043  clip  tensor([1.969])
norm  7.164145053406031  clip  tensor([4.998])
norm  4.260632483731529  clip  tensor([3.111])
Grad norm per param group for one microbatch
norm  16.911948155592572  clip  tensor([13.838])
norm  2.4391435798730927  clip  tensor([2.167])
norm  6.345614797107334  clip  tensor([5.283])
norm  3.8947313950094347  clip  tensor([3.197])
cpu
[0.005 0.548 0.003 0.228 0.171 0.194 0.043 0.041 0.109 1.042 0.327 0.019
 0.412 0.597 0.257 0.185 0.112 0.347 0.007 0.01  0.006 0.135 0.278 0.565
 0.009 0.029 0.119 0.833 0.154 0.437 0.53  0.373 0.229 0.073 0.107 0.293
 0.024 0.008 0.033 0.004 0.251 0.063 0.012 0.01  0.005 0.023 0.007 0.017
 0.009 0.015 0.076 0.02  0.005 0.024 0.018 0.006 0.008 0.016 0.084 0.043
 0.011 0.004 0.113 0.11  0.034 0.356 0.062 0.227 0.227 0.247 0.105 0.959
 0.148 0.049 0.196 0.041 0.306 0.493 1.064 0.056 0.717 0.044 0.008 0.054
 0.012 0.532 0.148 0.053 0.004 0.005]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9945130315500685, 0.9467813051146385)
Objective function 8.21 = squared loss an data 7.49 + 0.5*rho*h**2 0.047851 + alpha*h 0.227858 + L2reg 0.41 + L1reg 0.04 ; SHD = 9 ; DAG True
Proportion of microbatches that were clipped up to now since start  [0.8062193385029277, 0.7898401645830037, 0.7989397056496281, 0.7934799810096534]
iteration 1 in inner loop, alpha 232.9184223391038 rho 100000.0 h 0.000978272974462513
iteration 5 in outer loop, alpha = 1211.1913968016167, rho = 1000000.0, h = 0.000978272974462513
Threshold 0.3
[[0.005 0.005 0.548 0.003 0.228 0.171 0.194 0.043 0.041 0.109]
 [1.042 0.003 0.327 0.019 0.412 0.597 0.257 0.185 0.112 0.347]
 [0.007 0.01  0.004 0.006 0.135 0.278 0.565 0.009 0.029 0.119]
 [0.833 0.154 0.437 0.005 0.53  0.373 0.229 0.073 0.107 0.293]
 [0.024 0.008 0.033 0.004 0.004 0.251 0.063 0.012 0.01  0.005]
 [0.023 0.007 0.017 0.009 0.015 0.004 0.076 0.02  0.005 0.024]
 [0.018 0.006 0.008 0.016 0.084 0.043 0.004 0.011 0.004 0.113]
 [0.11  0.034 0.356 0.062 0.227 0.227 0.247 0.004 0.105 0.959]
 [0.148 0.049 0.196 0.041 0.306 0.493 1.064 0.056 0.003 0.717]
 [0.044 0.008 0.054 0.012 0.532 0.148 0.053 0.004 0.005 0.005]]
[[0.    0.    0.548 0.    0.    0.    0.    0.    0.    0.   ]
 [1.042 0.    0.327 0.    0.412 0.597 0.    0.    0.    0.347]
 [0.    0.    0.    0.    0.    0.    0.565 0.    0.    0.   ]
 [0.833 0.    0.437 0.    0.53  0.373 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.356 0.    0.    0.    0.    0.    0.    0.959]
 [0.    0.    0.    0.    0.306 0.493 1.064 0.    0.    0.717]
 [0.    0.    0.    0.    0.532 0.    0.    0.    0.    0.   ]]
{'fdr': 0.5, 'tpr': 1.0, 'fpr': 0.25, 'f1': 0.6666666666666666, 'shd': 9, 'npred': 18, 'ntrue': 9}
[0.005 0.548 0.003 0.228 0.171 0.194 0.043 0.041 0.109 1.042 0.327 0.019
 0.412 0.597 0.257 0.185 0.112 0.347 0.007 0.01  0.006 0.135 0.278 0.565
 0.009 0.029 0.119 0.833 0.154 0.437 0.53  0.373 0.229 0.073 0.107 0.293
 0.024 0.008 0.033 0.004 0.251 0.063 0.012 0.01  0.005 0.023 0.007 0.017
 0.009 0.015 0.076 0.02  0.005 0.024 0.018 0.006 0.008 0.016 0.084 0.043
 0.011 0.004 0.113 0.11  0.034 0.356 0.062 0.227 0.227 0.247 0.105 0.959
 0.148 0.049 0.196 0.041 0.306 0.493 1.064 0.056 0.717 0.044 0.008 0.054
 0.012 0.532 0.148 0.053 0.004 0.005]
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]
[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
aucroc, aucpr (0.9945130315500685, 0.9467813051146385)
Iterations 2500
Achieves (13.610683049707138, 1e-05)-DP
