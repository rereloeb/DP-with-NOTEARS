samples  5000  graph  20 40 ER mlp  minibatch size  50  noise  0.8  minibatches per NN training  250 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.5517662197542386
iteration 1 in outer loop, alpha = 1.5517662197542386, rho = 1.0, h = 1.5517662197542386
cuda
iteration 1 in inner loop,alpha 1.5517662197542386 rho 1.0 h 1.0406699191678186
iteration 2 in inner loop,alpha 1.5517662197542386 rho 10.0 h 0.44918801208686077
iteration 3 in inner loop,alpha 1.5517662197542386 rho 100.0 h 0.13963813850863005
iteration 2 in outer loop, alpha = 15.515580070617244, rho = 100.0, h = 0.13963813850863005
cuda
iteration 1 in inner loop,alpha 15.515580070617244 rho 100.0 h 0.07521116673818184
iteration 2 in inner loop,alpha 15.515580070617244 rho 1000.0 h 0.02522314537808512
iteration 3 in outer loop, alpha = 40.73872544870237, rho = 1000.0, h = 0.02522314537808512
cuda
iteration 1 in inner loop,alpha 40.73872544870237 rho 1000.0 h 0.009344006354545797
iteration 2 in inner loop,alpha 40.73872544870237 rho 10000.0 h 0.0028014157932219064
iteration 4 in outer loop, alpha = 68.75288338092143, rho = 10000.0, h = 0.0028014157932219064
cuda
iteration 1 in inner loop,alpha 68.75288338092143 rho 10000.0 h 0.0010933473459573406
iteration 2 in inner loop,alpha 68.75288338092143 rho 100000.0 h 0.0004560567225979639
iteration 5 in outer loop, alpha = 114.35855564071782, rho = 100000.0, h = 0.0004560567225979639
cuda
iteration 1 in inner loop,alpha 114.35855564071782 rho 100000.0 h 0.00025513167339497045
iteration 6 in outer loop, alpha = 369.4902290356883, rho = 1000000.0, h = 0.00025513167339497045
Threshold 0.3
[[0.    0.011 0.043 2.298 0.035 0.032 0.042 0.004 1.993 0.015 1.835 0.001
  0.092 0.002 0.234 0.821 0.003 0.001 0.035 0.216]
 [0.03  0.005 0.211 0.06  0.39  0.122 0.033 0.002 3.053 0.057 0.015 0.01
  0.612 0.004 1.818 1.627 0.285 0.    0.217 0.305]
 [0.004 0.001 0.003 0.071 0.127 1.134 0.    0.    2.294 0.078 0.06  0.
  2.258 0.005 1.395 0.885 0.    0.    3.75  2.198]
 [0.    0.    0.    0.003 0.001 0.001 0.    0.    0.    0.    0.    0.
  0.    0.    0.137 1.487 0.    0.    0.    0.001]
 [0.    0.    0.    1.698 0.001 0.171 0.    0.    0.001 0.038 0.022 0.
  0.432 0.006 0.122 0.384 0.001 0.    0.037 0.185]
 [0.001 0.    0.    0.139 0.003 0.001 0.    0.    0.001 0.046 0.065 0.
  0.313 0.    1.907 0.411 0.    0.    0.001 0.098]
 [0.003 0.019 0.58  0.054 0.212 0.109 0.006 0.    0.035 0.001 0.017 0.
  0.034 0.003 0.053 1.597 0.008 0.004 0.057 0.023]
 [0.003 0.013 0.617 0.049 0.187 0.103 4.439 0.001 0.149 0.009 0.004 0.049
  0.021 0.003 0.139 0.277 0.064 0.006 0.065 0.049]
 [0.    0.    0.    0.064 0.988 0.12  0.001 0.    0.003 0.054 0.045 0.
  0.366 0.    0.308 0.461 0.001 0.    0.018 0.251]
 [0.    0.    0.    0.102 0.    0.    0.    0.    0.    0.002 0.84  0.
  0.    0.    0.171 0.177 0.    0.    0.    0.176]
 [0.    0.    0.    0.102 0.    0.    0.    0.    0.    0.    0.002 0.
  0.    0.    1.239 0.222 0.    0.    0.    2.295]
 [0.004 0.001 2.731 0.07  0.018 0.211 3.585 0.005 0.22  0.013 0.016 0.001
  0.24  0.002 0.557 0.346 0.008 0.028 0.21  0.146]
 [0.001 0.    0.    0.138 0.    0.001 0.    0.    0.    3.19  0.123 0.
  0.002 0.    0.336 0.629 0.    0.    0.    0.418]
 [0.005 0.009 0.017 0.05  0.03  0.119 0.003 0.014 0.094 0.022 0.077 0.028
  0.271 0.    0.172 0.192 0.006 0.023 2.623 0.236]
 [0.    0.001 0.    0.007 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.004 0.223 0.    0.    0.    0.004]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.006 0.007 0.    0.    0.    0.   ]
 [0.005 0.007 0.332 0.072 0.336 0.214 0.033 0.002 0.269 0.058 0.057 0.01
  0.407 0.003 1.781 1.544 0.003 0.    0.331 0.443]
 [0.005 4.268 0.01  0.054 0.214 0.009 0.018 0.003 0.593 0.004 0.005 0.003
  1.326 0.003 0.179 0.169 3.    0.001 1.423 0.996]
 [0.008 0.001 0.    0.069 0.015 1.21  0.    0.    0.082 0.055 0.016 0.
  0.941 0.    0.469 1.293 0.    0.    0.003 0.493]
 [0.    0.    0.    2.129 0.    0.001 0.    0.    0.    0.    0.    0.
  0.    0.    0.221 0.371 0.    0.    0.    0.003]]
[[0.    0.    0.    2.298 0.    0.    0.    0.    1.993 0.    1.835 0.
  0.    0.    0.    0.821 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.39  0.    0.    0.    3.053 0.    0.    0.
  0.612 0.    1.818 1.627 0.    0.    0.    0.305]
 [0.    0.    0.    0.    0.    1.134 0.    0.    2.294 0.    0.    0.
  2.258 0.    1.395 0.885 0.    0.    3.75  2.198]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    1.487 0.    0.    0.    0.   ]
 [0.    0.    0.    1.698 0.    0.    0.    0.    0.    0.    0.    0.
  0.432 0.    0.    0.384 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.313 0.    1.907 0.411 0.    0.    0.    0.   ]
 [0.    0.    0.58  0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    1.597 0.    0.    0.    0.   ]
 [0.    0.    0.617 0.    0.    0.    4.439 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.988 0.    0.    0.    0.    0.    0.    0.
  0.366 0.    0.308 0.461 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.84  0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    1.239 0.    0.    0.    0.    2.295]
 [0.    0.    2.731 0.    0.    0.    3.585 0.    0.    0.    0.    0.
  0.    0.    0.557 0.346 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    3.19  0.    0.
  0.    0.    0.336 0.629 0.    0.    0.    0.418]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    2.623 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.332 0.    0.336 0.    0.    0.    0.    0.    0.    0.
  0.407 0.    1.781 1.544 0.    0.    0.331 0.443]
 [0.    4.268 0.    0.    0.    0.    0.    0.    0.593 0.    0.    0.
  1.326 0.    0.    0.    3.    0.    1.423 0.996]
 [0.    0.    0.    0.    0.    1.21  0.    0.    0.    0.    0.    0.
  0.941 0.    0.469 1.293 0.    0.    0.    0.493]
 [0.    0.    0.    2.129 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.371 0.    0.    0.    0.   ]]
{'fdr': 0.375, 'tpr': 1.0, 'fpr': 0.16, 'f1': 0.7692307692307693, 'shd': 24, 'npred': 64, 'ntrue': 40}
[1.144e-02 4.260e-02 2.298e+00 3.539e-02 3.227e-02 4.182e-02 4.411e-03
 1.993e+00 1.451e-02 1.835e+00 1.307e-03 9.180e-02 2.402e-03 2.341e-01
 8.213e-01 3.009e-03 1.469e-03 3.470e-02 2.161e-01 2.979e-02 2.108e-01
 5.999e-02 3.897e-01 1.217e-01 3.308e-02 2.106e-03 3.053e+00 5.671e-02
 1.506e-02 9.680e-03 6.118e-01 4.209e-03 1.818e+00 1.627e+00 2.853e-01
 3.999e-04 2.166e-01 3.048e-01 3.679e-03 9.726e-04 7.145e-02 1.274e-01
 1.134e+00 4.109e-04 6.883e-05 2.294e+00 7.756e-02 6.036e-02 1.664e-04
 2.258e+00 4.527e-03 1.395e+00 8.848e-01 3.975e-04 7.264e-05 3.750e+00
 2.198e+00 1.227e-05 2.186e-04 1.997e-04 5.604e-04 1.021e-03 2.975e-04
 8.533e-05 4.880e-04 3.349e-05 6.362e-05 9.440e-05 3.669e-05 3.837e-05
 1.373e-01 1.487e+00 3.453e-04 9.470e-05 3.002e-04 1.096e-03 1.228e-05
 1.940e-04 2.018e-04 1.698e+00 1.708e-01 4.853e-04 2.919e-05 6.861e-04
 3.812e-02 2.224e-02 5.448e-05 4.321e-01 5.577e-03 1.217e-01 3.838e-01
 7.081e-04 3.439e-05 3.718e-02 1.854e-01 6.702e-04 1.587e-04 1.015e-04
 1.388e-01 2.523e-03 1.527e-04 1.574e-05 6.724e-04 4.648e-02 6.536e-02
 3.502e-05 3.126e-01 3.663e-05 1.907e+00 4.110e-01 3.145e-04 1.987e-05
 7.891e-04 9.768e-02 2.716e-03 1.886e-02 5.804e-01 5.373e-02 2.117e-01
 1.089e-01 2.032e-04 3.454e-02 1.146e-03 1.691e-02 2.700e-05 3.379e-02
 2.906e-03 5.298e-02 1.597e+00 8.125e-03 3.936e-03 5.707e-02 2.313e-02
 3.206e-03 1.308e-02 6.172e-01 4.876e-02 1.865e-01 1.028e-01 4.439e+00
 1.487e-01 8.948e-03 3.695e-03 4.884e-02 2.089e-02 3.358e-03 1.385e-01
 2.774e-01 6.433e-02 6.409e-03 6.459e-02 4.909e-02 5.576e-05 3.323e-04
 3.845e-04 6.398e-02 9.876e-01 1.203e-01 6.946e-04 2.549e-05 5.445e-02
 4.528e-02 8.799e-05 3.659e-01 3.102e-04 3.078e-01 4.613e-01 5.184e-04
 3.504e-05 1.784e-02 2.506e-01 8.706e-05 6.501e-05 5.444e-05 1.020e-01
 9.242e-05 2.048e-04 3.416e-05 1.194e-05 7.504e-05 8.405e-01 6.239e-05
 3.973e-04 1.642e-04 1.705e-01 1.769e-01 1.778e-04 1.264e-05 3.859e-05
 1.761e-01 6.843e-05 6.669e-05 2.968e-05 1.024e-01 4.256e-04 4.277e-04
 3.359e-04 2.456e-05 8.666e-05 1.189e-04 2.257e-05 1.948e-05 5.042e-05
 1.239e+00 2.224e-01 3.420e-04 4.139e-05 7.381e-05 2.295e+00 4.090e-03
 1.283e-03 2.731e+00 7.035e-02 1.831e-02 2.111e-01 3.585e+00 5.285e-03
 2.197e-01 1.259e-02 1.551e-02 2.397e-01 1.742e-03 5.569e-01 3.458e-01
 8.183e-03 2.804e-02 2.104e-01 1.457e-01 8.066e-04 1.911e-04 1.836e-04
 1.383e-01 1.056e-04 1.025e-03 6.564e-05 1.921e-05 3.833e-04 3.190e+00
 1.226e-01 5.272e-05 6.053e-05 3.357e-01 6.287e-01 4.650e-04 3.938e-05
 2.638e-04 4.182e-01 4.637e-03 8.738e-03 1.666e-02 4.997e-02 2.958e-02
 1.193e-01 2.769e-03 1.367e-02 9.437e-02 2.231e-02 7.677e-02 2.753e-02
 2.713e-01 1.722e-01 1.923e-01 5.899e-03 2.264e-02 2.623e+00 2.358e-01
 3.963e-05 5.533e-04 1.029e-04 6.544e-03 4.153e-04 1.384e-04 1.826e-04
 8.521e-06 3.142e-04 2.886e-04 2.237e-04 3.361e-05 7.785e-05 2.128e-04
 2.235e-01 3.816e-04 8.482e-05 4.104e-05 4.367e-03 9.112e-06 3.084e-04
 5.484e-05 1.364e-04 3.264e-05 1.615e-04 4.002e-04 4.264e-05 6.122e-05
 7.413e-05 5.908e-05 5.443e-05 3.505e-05 2.331e-05 5.732e-03 4.646e-05
 3.228e-05 4.838e-05 1.327e-04 5.238e-03 6.571e-03 3.325e-01 7.174e-02
 3.359e-01 2.142e-01 3.333e-02 2.470e-03 2.688e-01 5.800e-02 5.667e-02
 1.037e-02 4.072e-01 2.662e-03 1.781e+00 1.544e+00 4.061e-04 3.307e-01
 4.427e-01 4.724e-03 4.268e+00 9.868e-03 5.414e-02 2.141e-01 8.779e-03
 1.779e-02 2.909e-03 5.934e-01 4.119e-03 5.086e-03 3.310e-03 1.326e+00
 2.746e-03 1.790e-01 1.694e-01 3.000e+00 1.423e+00 9.961e-01 8.006e-03
 1.063e-03 4.438e-04 6.879e-02 1.542e-02 1.210e+00 1.385e-04 2.616e-05
 8.217e-02 5.456e-02 1.584e-02 9.774e-05 9.412e-01 9.161e-05 4.692e-01
 1.293e+00 2.759e-04 1.629e-05 4.929e-01 3.850e-05 7.477e-05 1.957e-04
 2.129e+00 2.551e-04 8.736e-04 1.483e-04 2.972e-05 2.155e-04 1.766e-04
 5.387e-05 7.319e-05 4.985e-05 6.984e-05 2.206e-01 3.712e-01 2.121e-04
 1.046e-04 1.449e-04]
[[0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.9991176470588236, 0.9926635435845963)
cuda
4420
cuda
Objective function 737.19 = squared loss an data 521.17 + 0.5*rho*h**2 215.201283 + alpha*h 0.000000 + L2reg 0.37 + L1reg 0.45 ; SHD = 208 ; DAG False
v before min max tensor([[-7.229e-03, -6.606e-06, -2.102e-03,  ..., -2.342e-04,  5.531e-03,
         -1.888e-04],
        [-9.164e-03, -2.392e-03, -1.821e-02,  ..., -9.890e-04, -8.541e-04,
         -2.086e-04],
        [-4.781e-03,  6.060e-04, -6.201e-03,  ..., -6.719e-04, -9.897e-06,
         -4.271e-04],
        ...,
        [ 1.056e-01, -2.603e-02, -1.317e-03,  ...,  1.390e-05,  2.353e-04,
         -5.112e-03],
        [-1.792e-03, -3.005e-03, -2.231e-04,  ..., -5.160e-04, -1.721e-05,
          2.116e-03],
        [ 1.065e-02, -2.336e-05, -1.975e-03,  ..., -1.475e-04,  3.004e-03,
         -1.007e-02]], device='cuda:0')
v tensor([[1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 5.531e-03,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 6.060e-04, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        ...,
        [1.056e-01, 1.000e-12, 1.000e-12,  ..., 1.390e-05, 2.353e-04,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         2.116e-03],
        [1.065e-02, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 3.004e-03,
         1.000e-12]], device='cuda:0')
v before min max tensor([-1.531e-04,  5.257e-03, -2.262e-05, -1.733e-04, -7.312e-05, -4.823e-02,
        -4.260e-04, -9.915e-04, -1.384e-03, -1.128e-03, -1.629e-04, -5.133e-06,
         2.150e-05, -6.964e-03, -4.621e-04, -6.455e-03,  3.196e-04, -4.939e-04,
         6.438e-04,  5.334e-06, -2.353e-04, -5.403e-03, -1.639e-04, -1.237e-07,
         8.085e-02, -1.432e-04, -4.583e-03, -3.580e-06,  6.394e-04, -1.511e-04,
        -5.350e-03, -1.033e-02, -8.954e-03, -6.754e-05,  9.519e-06, -3.900e-03,
        -1.756e-04, -1.515e-02, -1.556e-03, -1.012e-03, -1.177e-04, -6.669e-03,
        -2.566e-04, -5.665e-03, -1.910e-03, -5.022e-05,  9.048e-05, -7.346e-04,
        -4.790e-04,  5.995e-03, -2.875e-02, -5.955e-04, -3.973e-05, -3.498e-05,
        -6.778e-03,  1.078e-03, -9.492e-04, -5.463e-04, -1.133e-03, -6.088e-03,
        -1.959e-05, -4.913e-03,  4.127e-04, -5.189e-04, -2.021e-03, -1.023e-05,
         1.479e-04, -4.299e-02, -1.583e-02, -2.071e-04, -1.332e-03, -3.529e-03,
        -2.657e-06, -9.035e-05,  7.005e-04, -1.200e-04,  3.402e-04, -9.378e-05,
        -1.430e-03, -1.517e-05,  2.297e-04,  5.175e-03, -7.949e-04, -1.208e-03,
        -5.634e-02, -6.164e-04, -2.408e-03, -6.199e-04, -1.827e-04, -1.179e-03,
         4.174e-03,  4.663e-03, -2.583e-04,  1.558e-02, -4.034e-05, -1.980e-04,
        -2.020e-04, -1.391e-04, -9.052e-03,  3.653e-05,  2.137e-05,  7.487e-05,
        -3.913e-03, -6.121e-04, -5.539e-03, -6.352e-04,  5.847e-02, -2.410e-04,
        -1.169e-04, -2.998e-03, -5.048e-04,  4.242e-05,  2.264e-04, -8.824e-03,
        -1.860e-03, -5.687e-04, -1.679e-04,  3.251e-05, -7.346e-03,  5.974e-04,
        -1.652e-05,  6.695e-05, -5.834e-04,  2.144e-04, -3.087e-04,  2.627e-06,
         2.038e-04,  4.185e-03, -1.547e-03, -1.328e-02,  1.762e-02,  2.865e-02,
         3.891e-04, -6.825e-04,  1.193e-04, -2.340e-03, -3.128e-05,  1.404e-06,
         1.923e-04, -1.215e-04,  9.326e-06,  5.401e-05, -1.232e-05, -7.308e-04,
        -3.319e-04,  1.244e-05,  9.882e-06,  8.436e-02, -2.193e-02, -2.106e-04,
        -4.172e-03, -2.428e-03,  2.945e-05, -4.297e-02, -1.455e-02,  2.374e-03,
        -8.171e-03,  2.318e-04, -8.480e-04, -1.065e-03, -8.034e-03, -6.451e-05,
        -5.750e-03, -4.777e-04, -7.794e-03,  9.959e-04,  1.078e-02, -6.038e-05,
         1.042e-02,  5.946e-05, -2.590e-04, -5.242e-02, -4.860e-05, -5.335e-04,
        -9.093e-06,  5.880e-03, -1.012e-04, -5.986e-04, -4.761e-05,  5.898e-06,
        -2.703e-03, -2.700e-06, -2.304e-04, -3.820e-06, -1.715e-03,  3.620e-02,
        -1.343e-03,  1.624e-02,  4.844e-03, -1.112e-04, -4.158e-03, -1.378e-03,
        -3.502e-03, -5.834e-04, -1.345e-03, -1.012e-03,  2.547e-03,  1.712e-05,
         1.414e-03, -2.050e-03], device='cuda:0')
v tensor([1.000e-12, 5.257e-03, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        2.150e-05, 1.000e-12, 1.000e-12, 1.000e-12, 3.196e-04, 1.000e-12,
        6.438e-04, 5.334e-06, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        8.085e-02, 1.000e-12, 1.000e-12, 1.000e-12, 6.394e-04, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 9.519e-06, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 9.048e-05, 1.000e-12,
        1.000e-12, 5.995e-03, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.078e-03, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 4.127e-04, 1.000e-12, 1.000e-12, 1.000e-12,
        1.479e-04, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 7.005e-04, 1.000e-12, 3.402e-04, 1.000e-12,
        1.000e-12, 1.000e-12, 2.297e-04, 5.175e-03, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        4.174e-03, 4.663e-03, 1.000e-12, 1.558e-02, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 3.653e-05, 2.137e-05, 7.487e-05,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.847e-02, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 4.242e-05, 2.264e-04, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 3.251e-05, 1.000e-12, 5.974e-04,
        1.000e-12, 6.695e-05, 1.000e-12, 2.144e-04, 1.000e-12, 2.627e-06,
        2.038e-04, 4.185e-03, 1.000e-12, 1.000e-12, 1.762e-02, 2.865e-02,
        3.891e-04, 1.000e-12, 1.193e-04, 1.000e-12, 1.000e-12, 1.404e-06,
        1.923e-04, 1.000e-12, 9.326e-06, 5.401e-05, 1.000e-12, 1.000e-12,
        1.000e-12, 1.244e-05, 9.882e-06, 8.436e-02, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 2.945e-05, 1.000e-12, 1.000e-12, 2.374e-03,
        1.000e-12, 2.318e-04, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 9.959e-04, 1.078e-02, 1.000e-12,
        1.042e-02, 5.946e-05, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 5.880e-03, 1.000e-12, 1.000e-12, 1.000e-12, 5.898e-06,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 3.620e-02,
        1.000e-12, 1.624e-02, 4.844e-03, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.547e-03, 1.712e-05,
        1.414e-03, 1.000e-12], device='cuda:0')
v before min max tensor([[[ 2.098e-03],
         [-8.739e-03],
         [ 1.348e-04],
         [-6.518e-03],
         [-4.388e-02],
         [-4.903e-03],
         [-3.949e-03],
         [-7.258e-04],
         [ 8.847e-04],
         [ 2.765e-05]],

        [[ 3.948e-05],
         [-1.974e-03],
         [-7.192e-02],
         [ 5.449e-04],
         [-2.603e-03],
         [ 1.476e-02],
         [-5.193e-02],
         [ 1.422e-03],
         [ 2.767e-01],
         [ 3.517e-02]],

        [[-1.327e-03],
         [ 2.263e-02],
         [-1.131e-03],
         [-1.985e-02],
         [-6.401e-03],
         [-1.029e-02],
         [-1.421e-03],
         [-2.422e-03],
         [ 6.168e-04],
         [ 3.406e-02]],

        [[ 1.310e-01],
         [ 7.571e-02],
         [-5.125e-03],
         [-4.838e-03],
         [ 5.111e-02],
         [ 1.149e-01],
         [ 4.396e-04],
         [-3.849e-03],
         [-2.139e-02],
         [-2.035e-02]],

        [[ 9.576e-03],
         [ 4.780e-03],
         [ 2.159e-01],
         [ 2.033e-04],
         [-5.892e-02],
         [-1.860e-02],
         [ 4.433e-02],
         [-7.022e-02],
         [-2.670e-04],
         [ 3.040e-01]],

        [[ 6.961e-01],
         [ 7.037e-03],
         [-3.651e-02],
         [-7.681e-04],
         [ 4.220e-04],
         [-6.620e-02],
         [-4.623e-03],
         [ 2.115e-01],
         [ 5.843e-04],
         [-6.422e-04]],

        [[ 1.433e-04],
         [-2.840e-02],
         [-1.494e-02],
         [-4.836e-04],
         [-7.659e-02],
         [ 3.321e-02],
         [-6.781e-02],
         [-5.572e-03],
         [-4.323e-02],
         [-3.473e-02]],

        [[-8.020e-05],
         [ 3.463e-03],
         [-3.572e-03],
         [-1.120e-03],
         [-6.136e-03],
         [-1.185e-03],
         [ 7.669e-03],
         [ 2.213e-03],
         [-1.513e-03],
         [-4.460e-05]],

        [[ 4.876e-01],
         [ 8.747e-02],
         [-2.223e-02],
         [-3.880e-04],
         [-5.953e-03],
         [-3.235e-03],
         [ 9.155e-02],
         [ 7.773e-03],
         [ 3.007e-02],
         [ 4.016e-03]],

        [[-2.648e-05],
         [-1.163e-02],
         [ 1.397e-02],
         [-3.982e-03],
         [ 8.302e-03],
         [ 2.043e-02],
         [ 5.051e-02],
         [-1.099e-01],
         [-5.544e-02],
         [-3.854e-02]],

        [[-4.016e-03],
         [ 2.411e-02],
         [-5.400e-03],
         [-2.125e-02],
         [-6.970e-02],
         [ 2.120e-03],
         [-2.609e-04],
         [-3.237e-04],
         [ 5.043e-03],
         [ 1.528e-01]],

        [[ 2.347e-03],
         [ 3.387e-04],
         [-1.042e-03],
         [-2.498e-04],
         [-2.493e-03],
         [-1.368e-03],
         [-8.120e-04],
         [-1.393e-04],
         [-1.409e-04],
         [-7.211e-04]],

        [[ 2.869e-02],
         [-7.247e-03],
         [ 9.528e-02],
         [-1.219e-02],
         [-5.540e-03],
         [ 7.049e-04],
         [ 5.874e-02],
         [-1.264e-02],
         [-1.619e-02],
         [ 8.284e-02]],

        [[-2.706e-03],
         [-7.303e-04],
         [-2.007e-02],
         [-2.363e-03],
         [ 3.163e-04],
         [ 2.007e-06],
         [ 9.254e-05],
         [ 2.930e-03],
         [-1.369e-04],
         [-4.626e-04]],

        [[ 1.795e-01],
         [-1.135e-02],
         [-5.528e-03],
         [ 1.383e-01],
         [ 8.701e-04],
         [ 2.324e-02],
         [-2.861e-02],
         [ 2.937e-01],
         [ 7.820e-05],
         [ 2.863e-04]],

        [[-5.380e-03],
         [-2.216e-02],
         [ 3.983e-01],
         [-2.704e-02],
         [ 2.256e-01],
         [ 1.527e-02],
         [ 2.491e-01],
         [ 1.494e-02],
         [ 2.979e-03],
         [ 2.130e-01]],

        [[ 4.160e-02],
         [-1.310e-03],
         [ 1.857e-02],
         [-1.944e-02],
         [-2.855e-03],
         [-5.028e-05],
         [-8.289e-03],
         [-8.435e-03],
         [-1.559e-02],
         [-6.829e-02]],

        [[-8.223e-04],
         [-1.676e-03],
         [-7.239e-03],
         [-7.317e-03],
         [-2.186e-02],
         [-6.967e-03],
         [-3.600e-03],
         [-9.295e-05],
         [ 7.830e-03],
         [ 7.490e-03]],

        [[-2.819e-02],
         [ 1.037e-01],
         [ 1.952e-03],
         [ 1.041e-02],
         [-3.254e-02],
         [-6.661e-03],
         [-1.586e-02],
         [ 1.239e-02],
         [ 1.105e-02],
         [-8.515e-03]],

        [[-1.100e-02],
         [-2.935e-02],
         [-1.002e-02],
         [ 3.664e-02],
         [ 1.716e-02],
         [-7.570e-02],
         [-3.838e-03],
         [ 8.241e-02],
         [-1.334e-03],
         [ 1.002e-01]]], device='cuda:0')
v tensor([[[2.098e-03],
         [1.000e-12],
         [1.348e-04],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [8.847e-04],
         [2.765e-05]],

        [[3.948e-05],
         [1.000e-12],
         [1.000e-12],
         [5.449e-04],
         [1.000e-12],
         [1.476e-02],
         [1.000e-12],
         [1.422e-03],
         [2.767e-01],
         [3.517e-02]],

        [[1.000e-12],
         [2.263e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.168e-04],
         [3.406e-02]],

        [[1.310e-01],
         [7.571e-02],
         [1.000e-12],
         [1.000e-12],
         [5.111e-02],
         [1.149e-01],
         [4.396e-04],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[9.576e-03],
         [4.780e-03],
         [2.159e-01],
         [2.033e-04],
         [1.000e-12],
         [1.000e-12],
         [4.433e-02],
         [1.000e-12],
         [1.000e-12],
         [3.040e-01]],

        [[6.961e-01],
         [7.037e-03],
         [1.000e-12],
         [1.000e-12],
         [4.220e-04],
         [1.000e-12],
         [1.000e-12],
         [2.115e-01],
         [5.843e-04],
         [1.000e-12]],

        [[1.433e-04],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.321e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [3.463e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.669e-03],
         [2.213e-03],
         [1.000e-12],
         [1.000e-12]],

        [[4.876e-01],
         [8.747e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [9.155e-02],
         [7.773e-03],
         [3.007e-02],
         [4.016e-03]],

        [[1.000e-12],
         [1.000e-12],
         [1.397e-02],
         [1.000e-12],
         [8.302e-03],
         [2.043e-02],
         [5.051e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [2.411e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.120e-03],
         [1.000e-12],
         [1.000e-12],
         [5.043e-03],
         [1.528e-01]],

        [[2.347e-03],
         [3.387e-04],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[2.869e-02],
         [1.000e-12],
         [9.528e-02],
         [1.000e-12],
         [1.000e-12],
         [7.049e-04],
         [5.874e-02],
         [1.000e-12],
         [1.000e-12],
         [8.284e-02]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.163e-04],
         [2.007e-06],
         [9.254e-05],
         [2.930e-03],
         [1.000e-12],
         [1.000e-12]],

        [[1.795e-01],
         [1.000e-12],
         [1.000e-12],
         [1.383e-01],
         [8.701e-04],
         [2.324e-02],
         [1.000e-12],
         [2.937e-01],
         [7.820e-05],
         [2.863e-04]],

        [[1.000e-12],
         [1.000e-12],
         [3.983e-01],
         [1.000e-12],
         [2.256e-01],
         [1.527e-02],
         [2.491e-01],
         [1.494e-02],
         [2.979e-03],
         [2.130e-01]],

        [[4.160e-02],
         [1.000e-12],
         [1.857e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.830e-03],
         [7.490e-03]],

        [[1.000e-12],
         [1.037e-01],
         [1.952e-03],
         [1.041e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.239e-02],
         [1.105e-02],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.664e-02],
         [1.716e-02],
         [1.000e-12],
         [1.000e-12],
         [8.241e-02],
         [1.000e-12],
         [1.002e-01]]], device='cuda:0')
v before min max tensor([[ 1.199e-03],
        [ 3.277e-01],
        [-4.425e-03],
        [ 6.010e-01],
        [-2.949e-02],
        [ 3.354e-01],
        [ 3.939e-01],
        [-2.927e-03],
        [-9.672e-02],
        [ 7.696e-02],
        [ 1.472e-01],
        [-5.817e-04],
        [ 2.496e-02],
        [-3.385e-06],
        [-8.802e-02],
        [ 2.968e-01],
        [ 3.343e-02],
        [-2.268e-05],
        [-1.988e-03],
        [-5.002e-02]], device='cuda:0')
v tensor([[1.199e-03],
        [3.277e-01],
        [1.000e-12],
        [6.010e-01],
        [1.000e-12],
        [3.354e-01],
        [3.939e-01],
        [1.000e-12],
        [1.000e-12],
        [7.696e-02],
        [1.472e-01],
        [1.000e-12],
        [2.496e-02],
        [1.000e-12],
        [1.000e-12],
        [2.968e-01],
        [3.343e-02],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[-4.884e-06, -6.642e-06, -2.863e-05,  ...,  5.834e-05,  5.758e-05,
         -6.284e-05],
        [-4.890e-05, -2.699e-05,  6.829e-05,  ..., -3.207e-05,  5.798e-07,
          3.302e-06],
        [ 8.640e-05, -1.336e-05, -3.388e-05,  ...,  8.872e-06, -1.513e-04,
          8.103e-06],
        ...,
        [ 8.532e-04, -3.961e-06, -1.099e-04,  ..., -7.925e-06,  2.820e-05,
          1.454e-04],
        [-2.435e-05,  1.773e-05, -1.711e-05,  ..., -1.562e-04,  5.048e-05,
         -1.167e-04],
        [ 1.050e-04,  2.397e-05,  1.980e-06,  ..., -1.195e-05,  1.510e-04,
         -3.742e-04]], device='cuda:0')
s after update for 1 param tensor([[4.122e-03, 5.473e-05, 1.112e-03,  ..., 2.240e-04, 2.354e-02,
         7.712e-04],
        [4.464e-03, 1.209e-03, 1.480e-02,  ..., 6.994e-04, 8.543e-04,
         1.232e-04],
        [2.681e-03, 7.794e-03, 3.612e-03,  ..., 3.277e-04, 5.535e-03,
         2.211e-04],
        ...,
        [1.134e-01, 1.436e-02, 1.713e-03,  ..., 1.180e-03, 4.851e-03,
         3.386e-03],
        [1.646e-03, 1.486e-03, 1.500e-04,  ..., 3.604e-03, 2.985e-04,
         1.539e-02],
        [3.287e-02, 1.064e-04, 1.236e-03,  ..., 7.507e-05, 1.761e-02,
         2.202e-02]], device='cuda:0')
b after update for 1 param tensor([[0.435, 0.050, 0.226,  ..., 0.101, 1.040, 0.188],
        [0.453, 0.236, 0.824,  ..., 0.179, 0.198, 0.075],
        [0.351, 0.598, 0.407,  ..., 0.123, 0.504, 0.101],
        ...,
        [2.281, 0.812, 0.280,  ..., 0.233, 0.472, 0.394],
        [0.275, 0.261, 0.083,  ..., 0.407, 0.117, 0.841],
        [1.229, 0.070, 0.238,  ..., 0.059, 0.899, 1.005]], device='cuda:0')
clipping threshold 2.782537623814828
a after update for 1 param tensor([ 1.886e-05,  2.433e-04, -9.757e-06,  1.265e-05,  3.239e-06, -4.069e-05,
         4.598e-05,  5.192e-05, -1.909e-05,  1.461e-05, -2.177e-05,  1.005e-06,
         1.327e-05, -4.875e-05, -6.393e-05, -4.402e-05,  3.527e-05, -3.039e-05,
         4.467e-05, -7.016e-06, -1.679e-05, -2.868e-05, -2.997e-05, -2.992e-06,
        -6.450e-04, -2.511e-05,  2.482e-05,  2.859e-06, -7.167e-05, -1.270e-05,
         5.044e-05, -1.102e-04,  1.654e-04, -6.036e-06,  3.051e-05, -1.146e-06,
         1.528e-05,  3.551e-05, -1.488e-05,  2.840e-05, -5.257e-05,  1.788e-05,
        -2.397e-05, -7.868e-05, -4.539e-05, -7.836e-06, -1.005e-05, -2.656e-06,
         1.067e-05,  1.489e-04, -5.302e-04,  1.278e-04, -1.438e-06, -7.613e-06,
         1.118e-05,  5.816e-05, -3.689e-05,  3.767e-05, -1.794e-05, -1.038e-04,
        -1.026e-05,  2.603e-05, -3.416e-04, -2.060e-05, -8.508e-05, -8.169e-07,
         2.613e-05,  7.940e-05, -1.951e-04,  7.761e-06, -5.611e-06,  9.191e-05,
         2.774e-06, -5.275e-06,  3.920e-05,  5.070e-06,  5.580e-05, -7.659e-06,
        -1.511e-06,  4.800e-06,  2.281e-05,  2.289e-04,  2.251e-05,  3.644e-06,
        -2.688e-04,  4.751e-05,  9.568e-06,  3.798e-05, -2.071e-05,  3.296e-05,
        -1.032e-04, -1.267e-04, -3.665e-05, -2.039e-04,  6.360e-06, -1.242e-05,
         2.370e-06,  8.331e-06, -8.244e-05, -1.696e-05, -9.939e-06, -2.302e-05,
        -3.557e-05,  5.764e-06,  6.491e-05,  3.454e-05,  5.000e-04,  2.054e-05,
         8.363e-06,  1.494e-04, -2.180e-06, -9.496e-06, -5.648e-05,  4.680e-05,
        -1.886e-05,  2.150e-05,  1.686e-05, -3.402e-05, -5.870e-05, -4.076e-05,
        -3.077e-06,  1.328e-05, -1.999e-05,  2.856e-05,  7.497e-06, -5.794e-06,
         4.719e-05, -6.685e-05,  9.524e-05, -1.643e-05, -2.390e-04,  2.877e-04,
        -4.260e-05, -3.792e-05,  2.417e-05, -8.228e-06,  5.086e-06,  3.716e-06,
        -5.256e-05, -5.184e-05, -9.952e-07,  1.603e-05,  4.330e-06, -3.350e-05,
         2.338e-05, -1.975e-05, -3.947e-05, -6.272e-04,  5.027e-06, -1.673e-05,
        -2.245e-05, -7.921e-06,  7.173e-05,  2.614e-04, -2.150e-04, -9.304e-05,
        -3.050e-04,  1.077e-05, -8.554e-07,  3.796e-06,  2.670e-05, -8.389e-06,
         1.269e-04,  2.735e-05, -2.110e-05,  4.811e-05,  1.869e-04,  1.607e-05,
        -1.793e-04,  2.540e-05,  3.065e-05, -1.566e-04, -1.928e-06,  1.033e-05,
         6.558e-06,  1.056e-04, -1.298e-05, -7.439e-07, -2.695e-06, -5.387e-06,
         6.486e-05,  3.492e-05,  6.948e-06,  1.235e-06, -1.422e-05,  3.003e-04,
         1.335e-06,  1.664e-04, -1.210e-04, -1.861e-06, -7.900e-05,  5.176e-05,
         1.773e-05,  1.958e-05,  1.432e-04,  5.336e-06, -7.631e-05, -2.433e-05,
        -5.408e-05,  1.011e-05], device='cuda:0')
s after update for 1 param tensor([8.002e-05, 2.340e-02, 4.586e-05, 8.657e-05, 3.543e-05, 2.830e-02,
        2.727e-04, 1.119e-03, 8.721e-04, 5.493e-04, 1.194e-04, 2.925e-06,
        1.466e-03, 3.645e-03, 7.784e-04, 3.298e-03, 5.653e-03, 2.963e-04,
        8.079e-03, 7.310e-04, 3.229e-04, 4.338e-03, 4.072e-04, 3.210e-06,
        9.163e-02, 3.012e-04, 2.873e-03, 1.882e-06, 7.997e-03, 8.479e-05,
        2.666e-03, 6.087e-03, 7.840e-03, 4.291e-05, 1.009e-03, 2.065e-03,
        8.510e-05, 7.625e-03, 9.808e-04, 6.178e-04, 2.313e-04, 3.723e-03,
        1.299e-04, 4.843e-03, 1.106e-03, 2.481e-05, 3.008e-03, 3.560e-04,
        2.485e-04, 2.452e-02, 3.484e-02, 2.261e-03, 2.113e-05, 3.645e-05,
        3.816e-03, 1.039e-02, 8.854e-04, 5.063e-04, 5.619e-04, 3.603e-03,
        6.325e-05, 2.388e-03, 1.249e-02, 3.714e-04, 2.573e-03, 5.042e-06,
        3.847e-03, 2.148e-02, 1.053e-02, 2.396e-04, 8.501e-04, 1.843e-03,
        1.882e-06, 4.524e-05, 8.371e-03, 5.869e-05, 5.837e-03, 4.682e-05,
        8.355e-04, 1.210e-05, 4.794e-03, 2.351e-02, 4.231e-04, 6.415e-04,
        2.745e-02, 4.313e-04, 1.168e-03, 4.062e-04, 9.303e-05, 1.055e-03,
        2.043e-02, 2.162e-02, 2.007e-04, 3.978e-02, 2.486e-05, 9.713e-05,
        1.665e-04, 6.916e-05, 4.975e-03, 2.060e-03, 1.462e-03, 2.736e-03,
        3.035e-03, 3.024e-04, 3.049e-03, 5.617e-04, 7.731e-02, 1.872e-04,
        6.377e-05, 1.931e-03, 2.466e-04, 2.060e-03, 4.859e-03, 5.069e-03,
        9.306e-04, 1.165e-03, 8.156e-05, 1.806e-03, 5.144e-03, 7.730e-03,
        1.029e-05, 2.587e-03, 3.243e-04, 4.632e-03, 1.496e-04, 5.125e-04,
        4.531e-03, 2.069e-02, 1.387e-03, 7.051e-03, 4.259e-02, 5.361e-02,
        6.241e-03, 5.117e-04, 3.454e-03, 1.157e-03, 1.656e-05, 3.747e-04,
        4.387e-03, 3.513e-04, 9.756e-04, 2.325e-03, 7.587e-06, 7.757e-04,
        2.596e-04, 1.186e-03, 1.000e-03, 9.445e-02, 1.189e-02, 1.257e-04,
        2.240e-03, 1.423e-03, 1.861e-03, 2.571e-02, 1.223e-02, 1.541e-02,
        1.197e-02, 4.816e-03, 6.287e-04, 5.235e-04, 3.900e-03, 3.153e-05,
        5.449e-03, 3.984e-04, 5.922e-03, 9.982e-03, 3.317e-02, 4.130e-05,
        3.230e-02, 2.444e-03, 2.521e-03, 2.545e-02, 2.515e-05, 2.721e-04,
        1.704e-05, 2.429e-02, 5.265e-05, 3.177e-04, 2.306e-05, 7.680e-04,
        1.327e-03, 1.201e-04, 1.274e-04, 1.882e-06, 8.694e-04, 6.342e-02,
        6.680e-04, 4.637e-02, 2.202e-02, 6.258e-05, 6.203e-03, 1.094e-03,
        1.753e-03, 2.825e-04, 6.790e-03, 4.987e-04, 1.596e-02, 1.315e-03,
        1.190e-02, 1.059e-03], device='cuda:0')
b after update for 1 param tensor([0.061, 1.036, 0.046, 0.063, 0.040, 1.140, 0.112, 0.227, 0.200, 0.159,
        0.074, 0.012, 0.259, 0.409, 0.189, 0.389, 0.509, 0.117, 0.609, 0.183,
        0.122, 0.446, 0.137, 0.012, 2.051, 0.118, 0.363, 0.009, 0.606, 0.062,
        0.350, 0.529, 0.600, 0.044, 0.215, 0.308, 0.063, 0.592, 0.212, 0.168,
        0.103, 0.413, 0.077, 0.472, 0.225, 0.034, 0.372, 0.128, 0.107, 1.061,
        1.265, 0.322, 0.031, 0.041, 0.419, 0.690, 0.202, 0.152, 0.161, 0.407,
        0.054, 0.331, 0.757, 0.131, 0.344, 0.015, 0.420, 0.993, 0.695, 0.105,
        0.198, 0.291, 0.009, 0.046, 0.620, 0.052, 0.518, 0.046, 0.196, 0.024,
        0.469, 1.039, 0.139, 0.172, 1.123, 0.141, 0.232, 0.137, 0.065, 0.220,
        0.969, 0.996, 0.096, 1.351, 0.034, 0.067, 0.087, 0.056, 0.478, 0.308,
        0.259, 0.354, 0.373, 0.118, 0.374, 0.161, 1.884, 0.093, 0.054, 0.298,
        0.106, 0.307, 0.472, 0.482, 0.207, 0.231, 0.061, 0.288, 0.486, 0.596,
        0.022, 0.345, 0.122, 0.461, 0.083, 0.153, 0.456, 0.975, 0.252, 0.569,
        1.398, 1.569, 0.535, 0.153, 0.398, 0.230, 0.028, 0.131, 0.449, 0.127,
        0.212, 0.327, 0.019, 0.189, 0.109, 0.233, 0.214, 2.082, 0.739, 0.076,
        0.321, 0.256, 0.292, 1.087, 0.749, 0.841, 0.741, 0.470, 0.170, 0.155,
        0.423, 0.038, 0.500, 0.135, 0.521, 0.677, 1.234, 0.044, 1.218, 0.335,
        0.340, 1.081, 0.034, 0.112, 0.028, 1.056, 0.049, 0.121, 0.033, 0.188,
        0.247, 0.074, 0.076, 0.009, 0.200, 1.706, 0.175, 1.459, 1.005, 0.054,
        0.534, 0.224, 0.284, 0.114, 0.558, 0.151, 0.856, 0.246, 0.739, 0.221],
       device='cuda:0')
clipping threshold 2.782537623814828
a after update for 1 param tensor([[[ 1.352e-04],
         [-2.243e-05],
         [ 3.564e-05],
         [-1.102e-04],
         [-2.872e-04],
         [ 1.246e-04],
         [ 1.577e-04],
         [ 6.857e-05],
         [ 1.189e-04],
         [-1.172e-05]],

        [[ 1.704e-05],
         [-2.206e-05],
         [-3.118e-04],
         [ 8.926e-05],
         [-4.424e-04],
         [ 2.149e-04],
         [-1.271e-05],
         [-1.822e-04],
         [-1.438e-03],
         [ 1.408e-04]],

        [[-3.729e-05],
         [-1.835e-04],
         [-3.452e-05],
         [-2.481e-04],
         [ 9.696e-05],
         [-1.569e-04],
         [-2.732e-05],
         [-8.009e-05],
         [-7.030e-05],
         [-4.862e-04]],

        [[-7.424e-04],
         [-8.543e-04],
         [ 5.211e-05],
         [-6.774e-04],
         [-9.122e-04],
         [-1.174e-03],
         [-6.054e-05],
         [ 7.142e-05],
         [-3.476e-04],
         [-5.120e-04]],

        [[ 9.293e-04],
         [-1.217e-04],
         [ 9.412e-04],
         [ 3.983e-05],
         [ 8.626e-05],
         [ 5.059e-04],
         [ 3.161e-04],
         [ 2.686e-04],
         [ 5.214e-06],
         [ 1.574e-03]],

        [[ 1.689e-03],
         [ 2.026e-04],
         [ 8.191e-04],
         [-4.475e-07],
         [ 9.460e-05],
         [ 1.055e-03],
         [ 3.764e-05],
         [ 1.093e-03],
         [ 9.377e-05],
         [ 3.926e-05]],

        [[-1.960e-05],
         [ 5.976e-04],
         [ 1.430e-04],
         [ 1.951e-06],
         [ 1.251e-03],
         [ 3.089e-04],
         [ 2.035e-05],
         [ 1.604e-04],
         [ 1.874e-04],
         [ 3.491e-04]],

        [[-1.916e-05],
         [ 1.357e-04],
         [ 2.746e-05],
         [-5.310e-06],
         [ 1.818e-05],
         [ 4.400e-06],
         [-1.838e-04],
         [ 9.611e-05],
         [ 2.472e-05],
         [ 6.368e-06]],

        [[-1.444e-03],
         [-6.045e-04],
         [-1.404e-04],
         [ 5.055e-05],
         [-7.536e-05],
         [-8.583e-05],
         [-5.480e-04],
         [-2.118e-04],
         [-4.603e-04],
         [-1.545e-04]],

        [[ 1.244e-05],
         [ 3.787e-04],
         [ 3.077e-04],
         [ 1.985e-05],
         [ 2.817e-04],
         [ 2.485e-04],
         [ 4.660e-04],
         [ 3.498e-04],
         [ 6.559e-05],
         [-1.478e-05]],

        [[ 2.923e-04],
         [ 4.712e-04],
         [-2.804e-05],
         [ 5.865e-04],
         [ 5.627e-04],
         [ 9.120e-05],
         [-6.230e-06],
         [ 1.321e-05],
         [ 1.333e-04],
         [ 9.004e-04]],

        [[-1.212e-04],
         [ 3.935e-05],
         [-4.667e-05],
         [-1.833e-06],
         [ 2.245e-05],
         [ 7.056e-05],
         [ 2.564e-05],
         [-7.404e-06],
         [ 1.878e-05],
         [-9.530e-06]],

        [[ 3.205e-04],
         [-1.491e-04],
         [ 5.422e-04],
         [-2.540e-05],
         [-5.120e-05],
         [ 3.393e-05],
         [ 5.133e-04],
         [ 2.880e-05],
         [ 1.601e-04],
         [ 5.753e-04]],

        [[-6.525e-06],
         [ 1.003e-05],
         [ 1.748e-05],
         [ 1.277e-05],
         [-3.658e-05],
         [ 4.564e-06],
         [ 6.809e-05],
         [ 7.107e-05],
         [ 3.575e-05],
         [-8.382e-06]],

        [[ 1.288e-03],
         [ 5.416e-06],
         [ 4.974e-05],
         [ 8.713e-04],
         [ 1.025e-04],
         [ 4.270e-04],
         [ 5.349e-04],
         [ 1.039e-03],
         [ 6.597e-05],
         [ 5.762e-05]],

        [[-1.187e-04],
         [ 1.223e-04],
         [-1.460e-03],
         [-3.514e-04],
         [-1.294e-03],
         [-1.547e-04],
         [-1.249e-03],
         [-2.915e-04],
         [-8.409e-05],
         [-1.038e-03]],

        [[-3.993e-04],
         [ 1.226e-05],
         [-7.531e-04],
         [ 2.286e-05],
         [-2.971e-04],
         [-2.544e-06],
         [-3.870e-04],
         [ 1.185e-04],
         [-2.471e-04],
         [-8.816e-04]],

        [[-1.790e-05],
         [ 3.716e-07],
         [-1.052e-04],
         [ 3.117e-05],
         [-2.775e-05],
         [-3.747e-05],
         [ 2.508e-05],
         [-2.170e-05],
         [ 1.339e-04],
         [ 3.429e-04]],

        [[ 2.646e-04],
         [-6.563e-04],
         [-3.279e-04],
         [ 1.805e-04],
         [-2.886e-04],
         [-2.676e-04],
         [-2.466e-04],
         [-2.563e-04],
         [-2.770e-04],
         [-9.647e-05]],

        [[-3.606e-04],
         [-2.344e-04],
         [-4.491e-04],
         [-5.927e-04],
         [-1.081e-03],
         [-4.874e-04],
         [-4.155e-05],
         [-8.002e-04],
         [ 2.785e-05],
         [-5.660e-04]]], device='cuda:0')
s after update for 1 param tensor([[[1.480e-02],
         [5.216e-03],
         [3.672e-03],
         [5.338e-03],
         [2.779e-02],
         [3.960e-03],
         [3.994e-03],
         [8.578e-04],
         [9.496e-03],
         [1.664e-03]],

        [[1.987e-03],
         [9.888e-04],
         [3.787e-02],
         [7.408e-03],
         [1.220e-02],
         [3.846e-02],
         [2.767e-02],
         [1.247e-02],
         [1.712e-01],
         [7.368e-02]],

        [[6.438e-04],
         [4.778e-02],
         [6.562e-04],
         [1.587e-02],
         [2.107e-02],
         [1.268e-02],
         [7.030e-04],
         [1.586e-03],
         [7.858e-03],
         [5.936e-02]],

        [[1.149e-01],
         [8.961e-02],
         [3.541e-03],
         [2.286e-02],
         [8.245e-02],
         [1.165e-01],
         [6.633e-03],
         [5.757e-03],
         [1.122e-02],
         [2.973e-02]],

        [[5.018e-02],
         [2.215e-02],
         [1.472e-01],
         [4.529e-03],
         [2.867e-02],
         [1.708e-02],
         [6.872e-02],
         [4.455e-02],
         [1.348e-04],
         [1.942e-01]],

        [[2.704e-01],
         [2.684e-02],
         [4.703e-02],
         [6.403e-04],
         [6.526e-03],
         [7.241e-02],
         [2.266e-03],
         [1.525e-01],
         [7.667e-03],
         [3.180e-04]],

        [[3.838e-03],
         [3.777e-02],
         [7.445e-03],
         [2.539e-04],
         [1.067e-01],
         [5.800e-02],
         [4.043e-02],
         [3.931e-03],
         [2.597e-02],
         [2.557e-02]],

        [[6.050e-05],
         [1.864e-02],
         [1.732e-03],
         [5.542e-04],
         [3.277e-03],
         [5.908e-04],
         [2.771e-02],
         [1.488e-02],
         [7.683e-04],
         [3.689e-05]],

        [[2.221e-01],
         [9.416e-02],
         [1.099e-02],
         [6.463e-04],
         [3.363e-03],
         [1.580e-03],
         [9.582e-02],
         [2.815e-02],
         [5.598e-02],
         [2.009e-02]],

        [[2.358e-05],
         [2.072e-02],
         [4.039e-02],
         [1.935e-03],
         [2.912e-02],
         [4.520e-02],
         [7.115e-02],
         [5.398e-02],
         [4.770e-02],
         [1.917e-02]],

        [[4.790e-03],
         [5.013e-02],
         [2.615e-03],
         [2.837e-02],
         [3.707e-02],
         [1.456e-02],
         [1.267e-04],
         [1.881e-04],
         [2.249e-02],
         [1.247e-01]],

        [[1.544e-02],
         [5.831e-03],
         [5.222e-04],
         [1.525e-04],
         [1.544e-03],
         [1.114e-03],
         [4.351e-04],
         [8.398e-04],
         [1.196e-04],
         [7.085e-04]],

        [[6.158e-02],
         [4.254e-03],
         [9.781e-02],
         [2.025e-02],
         [2.722e-03],
         [8.396e-03],
         [7.679e-02],
         [6.297e-03],
         [8.525e-03],
         [9.192e-02]],

        [[1.313e-03],
         [4.723e-04],
         [1.224e-02],
         [1.213e-03],
         [5.634e-03],
         [4.480e-04],
         [3.072e-03],
         [1.718e-02],
         [3.593e-04],
         [4.216e-04]],

        [[1.408e-01],
         [5.855e-03],
         [2.678e-03],
         [1.202e-01],
         [9.362e-03],
         [4.928e-02],
         [2.581e-02],
         [1.734e-01],
         [2.814e-03],
         [5.355e-03]],

        [[2.678e-03],
         [1.376e-02],
         [2.038e-01],
         [1.541e-02],
         [1.613e-01],
         [3.934e-02],
         [1.626e-01],
         [3.900e-02],
         [1.740e-02],
         [1.490e-01]],

        [[6.461e-02],
         [7.037e-04],
         [5.233e-02],
         [1.803e-02],
         [7.750e-03],
         [2.573e-05],
         [9.016e-03],
         [4.817e-03],
         [1.202e-02],
         [6.600e-02]],

        [[3.989e-04],
         [9.668e-04],
         [3.584e-03],
         [3.899e-03],
         [1.107e-02],
         [3.423e-03],
         [2.620e-03],
         [5.982e-05],
         [2.803e-02],
         [3.103e-02]],

        [[2.058e-02],
         [1.019e-01],
         [1.510e-02],
         [3.342e-02],
         [1.584e-02],
         [5.762e-03],
         [8.358e-03],
         [3.616e-02],
         [3.339e-02],
         [3.335e-02]],

        [[8.802e-03],
         [1.599e-02],
         [1.529e-02],
         [6.203e-02],
         [7.235e-02],
         [4.000e-02],
         [2.140e-03],
         [9.579e-02],
         [8.546e-04],
         [1.005e-01]]], device='cuda:0')
b after update for 1 param tensor([[[0.824],
         [0.489],
         [0.411],
         [0.495],
         [1.129],
         [0.426],
         [0.428],
         [0.198],
         [0.660],
         [0.276]],

        [[0.302],
         [0.213],
         [1.318],
         [0.583],
         [0.748],
         [1.329],
         [1.127],
         [0.757],
         [2.803],
         [1.839]],

        [[0.172],
         [1.481],
         [0.174],
         [0.853],
         [0.983],
         [0.763],
         [0.180],
         [0.270],
         [0.601],
         [1.651]],

        [[2.296],
         [2.028],
         [0.403],
         [1.024],
         [1.946],
         [2.313],
         [0.552],
         [0.514],
         [0.718],
         [1.168]],

        [[1.518],
         [1.008],
         [2.600],
         [0.456],
         [1.147],
         [0.886],
         [1.776],
         [1.430],
         [0.079],
         [2.986]],

        [[3.523],
         [1.110],
         [1.469],
         [0.171],
         [0.547],
         [1.823],
         [0.323],
         [2.646],
         [0.593],
         [0.121]],

        [[0.420],
         [1.317],
         [0.585],
         [0.108],
         [2.213],
         [1.632],
         [1.362],
         [0.425],
         [1.092],
         [1.083]],

        [[0.053],
         [0.925],
         [0.282],
         [0.160],
         [0.388],
         [0.165],
         [1.128],
         [0.827],
         [0.188],
         [0.041]],

        [[3.193],
         [2.079],
         [0.710],
         [0.172],
         [0.393],
         [0.269],
         [2.097],
         [1.137],
         [1.603],
         [0.960]],

        [[0.033],
         [0.975],
         [1.362],
         [0.298],
         [1.156],
         [1.441],
         [1.807],
         [1.574],
         [1.480],
         [0.938]],

        [[0.469],
         [1.517],
         [0.346],
         [1.141],
         [1.305],
         [0.818],
         [0.076],
         [0.093],
         [1.016],
         [2.393]],

        [[0.842],
         [0.517],
         [0.155],
         [0.084],
         [0.266],
         [0.226],
         [0.141],
         [0.196],
         [0.074],
         [0.180]],

        [[1.681],
         [0.442],
         [2.119],
         [0.964],
         [0.354],
         [0.621],
         [1.878],
         [0.538],
         [0.626],
         [2.054]],

        [[0.246],
         [0.147],
         [0.750],
         [0.236],
         [0.509],
         [0.143],
         [0.376],
         [0.888],
         [0.128],
         [0.139]],

        [[2.543],
         [0.518],
         [0.351],
         [2.349],
         [0.656],
         [1.504],
         [1.089],
         [2.821],
         [0.359],
         [0.496]],

        [[0.351],
         [0.795],
         [3.059],
         [0.841],
         [2.722],
         [1.344],
         [2.733],
         [1.338],
         [0.894],
         [2.615]],

        [[1.722],
         [0.180],
         [1.550],
         [0.910],
         [0.596],
         [0.034],
         [0.643],
         [0.470],
         [0.743],
         [1.741]],

        [[0.135],
         [0.211],
         [0.406],
         [0.423],
         [0.713],
         [0.396],
         [0.347],
         [0.052],
         [1.134],
         [1.194]],

        [[0.972],
         [2.163],
         [0.832],
         [1.239],
         [0.853],
         [0.514],
         [0.619],
         [1.288],
         [1.238],
         [1.237]],

        [[0.636],
         [0.857],
         [0.838],
         [1.687],
         [1.822],
         [1.355],
         [0.313],
         [2.097],
         [0.198],
         [2.148]]], device='cuda:0')
clipping threshold 2.782537623814828
a after update for 1 param tensor([[ 5.957e-05],
        [-2.076e-03],
        [-4.233e-05],
        [-1.778e-03],
        [ 3.120e-04],
        [ 1.433e-03],
        [ 1.222e-03],
        [ 1.461e-05],
        [-5.051e-04],
        [ 5.866e-04],
        [ 7.340e-04],
        [ 2.374e-06],
        [ 4.157e-04],
        [ 1.320e-05],
        [ 3.921e-04],
        [-1.303e-03],
        [-8.082e-04],
        [-1.244e-05],
        [-2.338e-04],
        [-1.461e-04]], device='cuda:0')
s after update for 1 param tensor([[1.095e-02],
        [2.151e-01],
        [2.981e-03],
        [2.547e-01],
        [2.515e-02],
        [1.939e-01],
        [2.006e-01],
        [1.605e-03],
        [4.696e-02],
        [8.808e-02],
        [1.246e-01],
        [3.467e-04],
        [5.037e-02],
        [2.968e-05],
        [4.448e-02],
        [1.762e-01],
        [6.289e-02],
        [6.761e-05],
        [9.890e-03],
        [5.753e-02]], device='cuda:0')
b after update for 1 param tensor([[0.709],
        [3.143],
        [0.370],
        [3.420],
        [1.075],
        [2.984],
        [3.035],
        [0.271],
        [1.468],
        [2.011],
        [2.392],
        [0.126],
        [1.521],
        [0.037],
        [1.429],
        [2.844],
        [1.699],
        [0.056],
        [0.674],
        [1.625]], device='cuda:0')
clipping threshold 2.782537623814828
||w||^2 0.1329282064546279
exp ma of ||w||^2 0.17910458818801375
||w|| 0.3645932068136047
exp ma of ||w|| 0.4054271187628712
||w||^2 0.14254920357334822
exp ma of ||w||^2 0.17181580200335478
||w|| 0.377556887863734
exp ma of ||w|| 0.39578266953177366
||w||^2 0.17268368917265803
exp ma of ||w||^2 0.19376733220822467
||w|| 0.41555227008483303
exp ma of ||w|| 0.42535641970458
||w||^2 0.158866942574967
exp ma of ||w||^2 0.20209889572303946
||w|| 0.39858116184155895
exp ma of ||w|| 0.4381432848759736
||w||^2 0.15811661299462923
exp ma of ||w||^2 0.45062950709798905
||w|| 0.3976387971446313
exp ma of ||w|| 0.6255984194889278
||w||^2 0.9260532594253312
exp ma of ||w||^2 0.5271600286595459
||w|| 0.9623166108019393
exp ma of ||w|| 0.7019699372792174
||w||^2 0.7853586917138312
exp ma of ||w||^2 0.551759792617296
||w|| 0.8862046556602099
exp ma of ||w|| 0.7186201446424088
v before min max tensor([[-56.448,  -0.279, -42.500,  ..., -40.144, -32.744,  10.045],
        [-70.735,  24.242, -10.587,  ..., -20.773, -47.066, -43.004],
        [-46.160,  19.237, -47.492,  ..., -45.676, -54.573, -13.403],
        ...,
        [-40.400, -46.941, -33.997,  ..., -36.019, -29.321, -29.193],
        [-55.420, -48.225,   2.126,  ..., -18.241, -50.787,   4.782],
        [-25.253, -54.372,  26.615,  ..., 184.136, -55.343,   7.080]],
       device='cuda:0')
v tensor([[1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e+01],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 2.126e+00,  ..., 1.000e-12, 1.000e-12,
         4.782e+00],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         7.080e+00]], device='cuda:0')
v before min max tensor([-62.518, -36.762, -61.611, -43.434,  54.151, -53.166, -47.622, -41.290,
        -57.446, -28.087, -14.815,  -2.945,   4.568, -45.619, -43.997, -56.637,
        -49.949,  54.320, -24.670,  26.355, -38.600,  48.276, 120.908, 116.793,
        -55.418,  -9.629, -27.905,  -1.460, -62.160, -69.154, -19.762, -61.267,
        -55.151, -50.528, -54.215, -47.073, -62.630, -50.159, -22.170, -42.370,
         90.279, -21.057,  -0.819, -59.575,  40.286, -22.001,   0.936, -10.306,
        -42.648, -10.288, -43.192, -33.128, -47.696, -57.498, -73.348,  89.222,
        -24.949, -46.053, -31.856, -65.346, -62.335, 292.145,  71.089, -46.681,
        -58.367, -52.497, -49.377, 159.186, -43.627, 150.135,  86.382, -59.609,
         10.675, -25.341, -44.534, 146.173, -36.088, -10.838,  24.456, -22.085,
          7.338, -14.399, -17.000, -43.530, -47.359, -27.912,  17.943, -63.044,
        -63.997, -20.990,  95.823,  46.930, -67.707, -63.755, -22.828, -49.164,
          3.011, -54.538,   2.660, -27.560,  27.180, -40.491,  -6.226, -23.011,
        126.322,  41.969, -28.695, -51.497, -46.972, -41.052,  -7.509, -42.443,
        -58.274, -30.232, -47.585, -42.384, -29.281, -14.195,  55.958, -70.816,
         83.881, -13.076, -30.885, -57.566, -64.681, -60.155, -50.598, -61.200,
        -49.733, -63.326, -25.345, -52.341, 121.926,  56.438, -22.910, -61.609,
        -68.113, -23.262, -18.608,  20.727, -12.157,  -9.944, -54.981,  24.261,
        -33.322, -61.963, -43.163, -54.917, -41.529, -55.970, -67.132,  -0.942,
        -20.993, -15.274, -20.161,  82.865, -35.203, -46.790, 136.129,   9.544,
        -59.599,  19.502,  12.163,  21.683,  76.570,  -9.357, -35.673,  -5.114,
         55.374, -46.388, -49.228, -37.177, -58.414,  40.330, -43.415, -56.976,
        -58.208, -28.782, -15.487, -75.372, -41.799, -51.580, -15.309,  24.627,
        -44.654, -39.068, -43.266, -30.156, -24.847, 209.616, -59.037, -56.207,
          2.064, -49.634, -31.649, -20.745, -49.386,  11.019, -42.000, -53.389],
       device='cuda:0')
v tensor([1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        4.568e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 9.361e-01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 7.338e+00, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        3.011e+00, 1.000e-12, 2.660e+00, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 9.544e+00, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        2.064e+00, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12], device='cuda:0')
v before min max tensor([[[-38.413],
         [-34.090],
         [-43.913],
         [ 20.129],
         [-38.727],
         [170.542],
         [-36.198],
         [-57.802],
         [-23.847],
         [ 58.504]],

        [[200.364],
         [-41.101],
         [ 54.051],
         [  5.171],
         [-45.902],
         [-62.046],
         [ 10.011],
         [-79.066],
         [162.713],
         [-69.768]],

        [[-50.773],
         [349.039],
         [ 57.874],
         [-60.515],
         [-63.022],
         [-23.575],
         [-45.457],
         [-42.115],
         [ 14.110],
         [116.807]],

        [[-26.606],
         [111.587],
         [111.578],
         [-64.118],
         [-69.623],
         [-52.749],
         [-50.231],
         [-69.638],
         [-17.145],
         [-51.193]],

        [[ 24.844],
         [  2.566],
         [-76.832],
         [-40.934],
         [ -9.644],
         [552.619],
         [-22.353],
         [-71.435],
         [  3.641],
         [-60.856]],

        [[-52.189],
         [345.166],
         [-21.923],
         [-34.456],
         [-62.776],
         [-87.488],
         [ 34.464],
         [-34.646],
         [-16.113],
         [-21.609]],

        [[-35.556],
         [-31.034],
         [-54.706],
         [-71.274],
         [-43.245],
         [-80.057],
         [-45.977],
         [-73.891],
         [  6.393],
         [ 46.324]],

        [[209.527],
         [ 25.806],
         [-67.543],
         [  3.637],
         [-39.474],
         [  7.263],
         [147.758],
         [ 20.031],
         [-39.769],
         [  1.916]],

        [[ 13.726],
         [ 36.801],
         [-13.225],
         [-55.651],
         [-34.736],
         [ 13.190],
         [-50.135],
         [264.253],
         [-71.285],
         [ 87.157]],

        [[-37.058],
         [-33.087],
         [ -0.720],
         [-49.170],
         [-23.936],
         [-42.670],
         [-36.146],
         [270.759],
         [ 17.254],
         [-51.527]],

        [[-52.185],
         [ 95.705],
         [  2.099],
         [-26.689],
         [-44.593],
         [-35.766],
         [  7.648],
         [-33.884],
         [-33.629],
         [-55.127]],

        [[ -7.701],
         [-28.129],
         [ 11.053],
         [-43.933],
         [-64.274],
         [-43.890],
         [-80.311],
         [124.919],
         [-27.913],
         [-45.831]],

        [[-39.201],
         [-51.355],
         [ 45.723],
         [-49.656],
         [-48.608],
         [ 24.013],
         [-23.232],
         [-26.639],
         [-48.946],
         [-72.112]],

        [[-35.390],
         [122.644],
         [-41.312],
         [-60.693],
         [-21.867],
         [-46.045],
         [-30.853],
         [114.459],
         [ 48.960],
         [-11.728]],

        [[107.753],
         [ -2.585],
         [-55.001],
         [ -7.969],
         [-57.957],
         [-67.493],
         [  2.257],
         [-31.807],
         [-31.821],
         [-48.779]],

        [[-32.078],
         [-56.051],
         [322.690],
         [-51.891],
         [107.080],
         [120.418],
         [-96.219],
         [ 60.030],
         [-21.275],
         [ 67.563]],

        [[-44.020],
         [-45.227],
         [-27.564],
         [-40.604],
         [ 10.531],
         [ 77.485],
         [116.338],
         [-31.966],
         [-30.912],
         [ 98.133]],

        [[-37.767],
         [-56.355],
         [102.116],
         [-58.319],
         [-36.216],
         [ -1.875],
         [-37.407],
         [-17.278],
         [ 43.357],
         [-17.304]],

        [[133.736],
         [ 14.288],
         [-48.186],
         [-46.321],
         [-75.361],
         [-41.803],
         [ 72.746],
         [ 12.275],
         [-31.371],
         [ 56.751]],

        [[-60.951],
         [ 14.354],
         [-18.169],
         [-20.228],
         [-56.868],
         [ 39.549],
         [-55.153],
         [-65.726],
         [ 31.610],
         [ 26.840]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [5.171e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [2.566e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [3.641e+00],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [6.393e+00],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [3.637e+00],
         [1.000e-12],
         [7.263e+00],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.916e+00]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [2.099e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [7.648e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [2.257e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]]], device='cuda:0')
v before min max tensor([[134.189],
        [-29.796],
        [-21.130],
        [-57.772],
        [-61.942],
        [207.468],
        [-52.556],
        [-14.931],
        [-28.920],
        [-46.572],
        [131.933],
        [ 25.690],
        [-45.288],
        [-16.312],
        [-15.005],
        [203.146],
        [  1.004],
        [-25.590],
        [-47.413],
        [ 75.068]], device='cuda:0')
v tensor([[1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.004e+00],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01]], device='cuda:0')
a after update for 1 param tensor([[-0.025, -0.037, -0.050,  ...,  0.022, -0.057, -0.006],
        [-0.071, -0.003,  0.145,  ...,  0.033,  0.001, -0.032],
        [ 0.051, -0.041, -0.024,  ..., -0.055, -0.122,  0.086],
        ...,
        [-0.051, -0.027, -0.050,  ..., -0.001, -0.029,  0.072],
        [-0.005, -0.066, -0.072,  ..., -0.013, -0.069, -0.087],
        [ 0.018, -0.008,  0.027,  ...,  0.058, -0.071,  0.007]],
       device='cuda:0')
s after update for 1 param tensor([[1.725, 1.551, 1.776,  ..., 1.246, 1.350, 1.360],
        [2.104, 1.960, 1.262,  ..., 0.794, 1.602, 1.328],
        [1.696, 2.122, 1.375,  ..., 1.637, 1.552, 1.717],
        ...,
        [1.205, 1.436, 1.519,  ..., 1.720, 1.046, 1.847],
        [1.638, 1.916, 1.760,  ..., 1.662, 1.768, 1.604],
        [1.257, 1.622, 1.704,  ..., 1.622, 1.577, 1.521]], device='cuda:0')
b after update for 1 param tensor([[111.980, 106.206, 113.619,  ...,  95.171,  99.073,  99.440],
        [123.692, 119.367,  95.783,  ...,  75.992, 107.912,  98.259],
        [111.049, 124.214,  99.991,  ..., 109.092, 106.212, 111.716],
        ...,
        [ 93.609, 102.162, 105.076,  ..., 111.814,  87.224, 115.888],
        [109.114, 118.031, 113.123,  ..., 109.938, 113.367, 108.007],
        [ 95.615, 108.583, 111.293,  ..., 108.606, 107.082, 105.157]],
       device='cuda:0')
clipping threshold 0.5930796193793991
a after update for 1 param tensor([ 0.063, -0.115, -0.011,  0.006, -0.040, -0.009,  0.019, -0.059,  0.044,
        -0.024, -0.013, -0.010,  0.031, -0.036, -0.019,  0.020, -0.013, -0.069,
         0.026,  0.068, -0.054,  0.073, -0.054,  0.086, -0.007,  0.092, -0.093,
         0.014,  0.100,  0.001,  0.030, -0.082, -0.128, -0.084, -0.060, -0.017,
         0.077, -0.116, -0.028, -0.050, -0.006, -0.160, -0.011, -0.115, -0.042,
        -0.079,  0.087, -0.045, -0.108, -0.075, -0.001, -0.018, -0.002, -0.045,
         0.089,  0.032,  0.045, -0.157,  0.027, -0.043,  0.005, -0.006,  0.070,
        -0.024, -0.037, -0.056, -0.049,  0.033, -0.057, -0.100, -0.079,  0.019,
         0.056,  0.051, -0.038,  0.070, -0.103,  0.019,  0.059, -0.052, -0.027,
        -0.058, -0.024,  0.099,  0.042, -0.011, -0.024, -0.031,  0.022, -0.003,
         0.073, -0.005, -0.092,  0.043,  0.023, -0.028, -0.075,  0.007, -0.011,
        -0.051, -0.001, -0.015,  0.070,  0.026,  0.020, -0.040, -0.029, -0.076,
        -0.029,  0.024,  0.036,  0.003,  0.037, -0.020,  0.088, -0.050, -0.078,
        -0.020, -0.047,  0.015, -0.091,  0.014, -0.072,  0.010, -0.107, -0.067,
        -0.110,  0.137,  0.027, -0.027,  0.054,  0.010,  0.100,  0.019, -0.046,
        -0.085,  0.061,  0.016, -0.032,  0.039,  0.054,  0.085, -0.030, -0.014,
        -0.090, -0.049, -0.125,  0.004, -0.002, -0.010, -0.049,  0.030,  0.026,
         0.010, -0.036, -0.054, -0.022,  0.076, -0.038,  0.034, -0.045, -0.030,
        -0.099, -0.003, -0.002,  0.105,  0.013, -0.041,  0.079,  0.012, -0.063,
        -0.036, -0.063, -0.002, -0.004,  0.011, -0.044,  0.037, -0.014, -0.012,
         0.041,  0.106, -0.148,  0.019, -0.062, -0.068,  0.022, -0.015,  0.003,
         0.006,  0.002, -0.168,  0.095, -0.028, -0.017,  0.023,  0.057,  0.043,
        -0.107,  0.074], device='cuda:0')
s after update for 1 param tensor([1.935, 1.748, 1.931, 1.514, 1.724, 1.541, 1.753, 1.542, 1.715, 0.788,
        1.655, 0.875, 1.808, 1.615, 1.627, 1.601, 1.407, 1.972, 1.300, 2.031,
        2.045, 1.557, 2.097, 2.163, 1.561, 1.536, 1.709, 1.399, 1.752, 2.219,
        1.995, 1.862, 1.570, 1.756, 1.845, 1.354, 1.950, 1.493, 1.659, 1.602,
        1.724, 1.691, 1.683, 1.894, 1.707, 1.539, 1.859, 1.342, 1.306, 1.523,
        1.380, 1.273, 1.804, 1.850, 2.074, 1.968, 0.844, 1.297, 1.603, 2.056,
        1.825, 1.850, 2.115, 1.690, 1.873, 1.556, 1.765, 1.763, 1.224, 1.959,
        1.887, 1.737, 1.775, 1.386, 1.257, 1.740, 1.856, 0.367, 2.181, 0.813,
        1.665, 1.852, 1.596, 1.459, 1.705, 1.771, 1.895, 1.790, 1.825, 1.164,
        2.055, 2.317, 1.902, 2.151, 1.845, 1.378, 1.692, 1.546, 2.018, 1.468,
        1.680, 1.384, 1.283, 1.189, 1.631, 2.133, 1.377, 1.702, 1.466, 1.265,
        1.140, 1.270, 1.634, 0.868, 1.708, 1.258, 1.798, 1.571, 1.741, 1.999,
        2.127, 1.011, 1.286, 1.927, 1.964, 2.002, 1.693, 1.726, 1.940, 1.775,
        1.822, 1.562, 1.763, 2.072, 1.438, 1.783, 1.956, 1.043, 1.563, 2.100,
        1.053, 0.955, 1.543, 1.515, 1.667, 1.739, 2.070, 1.559, 1.436, 1.578,
        1.904, 1.080, 0.660, 1.329, 1.268, 2.183, 1.383, 1.440, 1.846, 2.485,
        1.680, 1.770, 1.990, 1.620, 2.018, 1.723, 1.652, 1.779, 1.919, 1.337,
        1.510, 1.135, 1.659, 1.992, 1.890, 1.665, 1.692, 1.482, 2.079, 2.185,
        1.392, 1.484, 1.161, 2.134, 1.780, 1.717, 1.397, 1.225, 0.877, 1.817,
        1.745, 2.068, 1.867, 1.486, 1.568, 0.759, 1.473, 1.847, 1.179, 1.530],
       device='cuda:0')
b after update for 1 param tensor([118.625, 112.743, 118.493, 104.912, 111.949, 105.856, 112.902, 105.892,
        111.652,  75.686, 109.711,  79.770, 114.641, 108.346, 108.772, 107.899,
        101.134, 119.731,  97.222, 121.516, 121.931, 106.393, 123.480, 125.420,
        106.546, 105.663, 111.472, 100.842, 112.878, 127.031, 120.440, 116.362,
        106.842, 113.002, 115.808,  99.224, 119.078, 104.197, 109.813, 107.920,
        111.972, 110.895, 110.622, 117.344, 111.417, 105.765, 116.263,  98.797,
         97.451, 105.229, 100.151,  96.209, 114.530, 115.990, 122.794, 119.616,
         78.357,  97.118, 107.946, 122.278, 115.185, 115.990, 123.993, 110.855,
        116.682, 106.366, 113.267, 113.233,  94.352, 119.332, 117.132, 112.368,
        113.614, 100.381,  95.588, 112.488, 116.180,  51.661, 125.922,  76.903,
        110.015, 116.043, 107.730, 103.011, 111.343, 113.485, 117.382, 114.087,
        115.207,  91.985, 122.225, 129.801, 117.611, 125.064, 115.834, 100.105,
        110.922, 106.034, 121.138, 103.307, 110.518, 100.316,  96.576,  92.961,
        108.888, 124.521, 100.050, 111.236, 103.251,  95.919,  91.033,  96.089,
        108.982,  79.435, 111.427,  95.640, 114.338, 106.864, 112.523, 120.567,
        124.356,  85.751,  96.697, 118.353, 119.504, 120.658, 110.946, 112.022,
        118.757, 113.601, 115.112, 106.565, 113.216, 122.728, 102.242, 113.859,
        119.257,  87.090, 106.611, 123.552,  87.513,  83.327, 105.907, 104.962,
        110.094, 112.456, 122.683, 106.451, 102.175, 107.103, 117.667,  88.609,
         69.259,  98.293,  96.009, 125.994, 100.286, 102.320, 115.846, 134.412,
        110.527, 113.444, 120.278, 108.523, 121.142, 111.931, 109.593, 113.736,
        118.136,  98.597, 104.788,  90.822, 109.834, 120.337, 117.222, 110.034,
        110.909, 103.821, 122.951, 126.032, 100.585, 103.857,  91.866, 124.562,
        113.770, 111.734, 100.798,  94.393,  79.870, 114.951, 112.636, 122.616,
        116.502, 103.941, 106.786,  74.294, 103.497, 115.870,  92.602, 105.479],
       device='cuda:0')
clipping threshold 0.5930796193793991
a after update for 1 param tensor([[[-4.198e-02],
         [ 3.003e-02],
         [-1.093e-01],
         [ 1.144e-01],
         [ 7.652e-02],
         [ 3.955e-03],
         [ 3.744e-02],
         [-9.856e-02],
         [ 1.128e-01],
         [ 3.242e-02]],

        [[-5.336e-01],
         [-1.250e-01],
         [-3.425e+00],
         [-2.984e+00],
         [-3.251e+00],
         [-3.194e-02],
         [-1.008e+00],
         [-3.092e+00],
         [-3.381e+00],
         [-3.262e+00]],

        [[-1.904e-01],
         [-2.447e-01],
         [ 4.310e-02],
         [-1.403e-01],
         [-3.835e-01],
         [ 1.644e-01],
         [-1.760e-01],
         [ 2.578e-02],
         [ 1.479e-01],
         [-3.556e-01]],

        [[-1.645e+00],
         [-1.526e+00],
         [-6.641e-01],
         [-1.517e+00],
         [-1.645e+00],
         [-1.656e+00],
         [-1.822e-02],
         [-1.533e+00],
         [-1.678e+00],
         [-1.560e+00]],

        [[ 1.825e+00],
         [ 4.967e-02],
         [ 1.773e+00],
         [-1.314e-01],
         [ 1.825e+00],
         [ 1.700e+00],
         [ 1.701e-02],
         [ 1.903e+00],
         [-4.129e-02],
         [ 1.857e+00]],

        [[ 1.412e+00],
         [ 1.396e+00],
         [ 1.270e+00],
         [ 2.375e-01],
         [ 4.946e-01],
         [ 1.206e+00],
         [ 5.039e-01],
         [ 1.277e+00],
         [ 4.534e-02],
         [ 1.040e-01]],

        [[ 5.487e-01],
         [ 9.508e-01],
         [-6.944e-02],
         [ 7.289e-01],
         [ 1.003e+00],
         [ 1.120e+00],
         [ 1.127e+00],
         [ 6.649e-01],
         [ 9.793e-01],
         [ 1.165e+00]],

        [[-2.150e-02],
         [ 1.705e-02],
         [ 1.780e-01],
         [ 5.931e-02],
         [ 6.222e-02],
         [ 5.393e-02],
         [-5.287e-02],
         [-6.236e-02],
         [ 5.484e-02],
         [ 4.546e-02]],

        [[-2.880e+00],
         [-2.337e+00],
         [-4.456e-01],
         [ 2.550e-02],
         [ 1.227e-02],
         [-8.777e-02],
         [-1.448e-01],
         [ 2.930e-02],
         [-2.669e+00],
         [-2.167e+00]],

        [[ 5.282e-01],
         [ 6.457e-01],
         [ 4.113e-01],
         [-2.899e-02],
         [ 6.231e-01],
         [ 4.057e-01],
         [ 5.407e-01],
         [ 6.750e-01],
         [-1.950e-02],
         [-1.223e-01]],

        [[ 4.792e-01],
         [ 5.625e-01],
         [ 1.819e-03],
         [ 4.108e-01],
         [ 5.103e-01],
         [ 2.517e-01],
         [ 2.565e-01],
         [-3.028e-02],
         [ 8.499e-02],
         [ 3.676e-01]],

        [[-3.609e-02],
         [-9.356e-02],
         [-2.190e-02],
         [ 2.915e-02],
         [ 7.586e-02],
         [ 5.306e-02],
         [ 1.428e-01],
         [-3.511e-02],
         [ 1.387e-01],
         [ 5.493e-02]],

        [[ 5.278e-01],
         [ 5.329e-02],
         [ 1.256e-01],
         [-9.401e-02],
         [-4.795e-02],
         [ 1.275e-01],
         [ 3.458e-01],
         [ 1.952e-01],
         [-1.517e-01],
         [ 2.732e-01]],

        [[-5.677e-02],
         [ 1.175e-01],
         [ 1.889e-02],
         [ 3.549e-02],
         [ 1.523e-02],
         [-5.045e-03],
         [ 2.110e-03],
         [-1.198e-01],
         [-4.241e-02],
         [ 7.290e-02]],

        [[ 2.190e+00],
         [ 5.356e-02],
         [ 1.280e+00],
         [ 2.206e+00],
         [ 8.404e-01],
         [ 1.118e-01],
         [ 2.066e+00],
         [ 2.351e+00],
         [ 1.655e-02],
         [ 1.108e+00]],

        [[-6.376e-01],
         [ 5.178e-02],
         [-1.753e+00],
         [-8.372e-01],
         [-1.743e+00],
         [-1.796e+00],
         [-1.737e+00],
         [-1.246e+00],
         [-4.296e-02],
         [-1.850e+00]],

        [[-3.813e-01],
         [ 2.514e-01],
         [-7.674e-01],
         [-8.255e-01],
         [-4.658e-01],
         [-2.066e-01],
         [-8.076e-01],
         [-1.075e-01],
         [-7.544e-01],
         [-3.607e-01]],

        [[-1.877e-01],
         [-4.664e-02],
         [-7.532e-02],
         [ 1.281e-01],
         [-1.606e-01],
         [ 4.777e-02],
         [ 1.139e-01],
         [ 6.982e-03],
         [-9.220e-02],
         [ 9.280e-02]],

        [[ 2.647e-01],
         [-5.792e-01],
         [-7.475e-01],
         [-2.866e-01],
         [-3.310e-01],
         [-5.163e-01],
         [-1.782e-01],
         [-8.192e-01],
         [-7.210e-01],
         [-2.945e-01]],

        [[-9.966e-01],
         [-9.191e-02],
         [-9.097e-01],
         [-9.215e-01],
         [-8.355e-01],
         [-8.611e-01],
         [-3.818e-01],
         [-8.866e-01],
         [-3.797e-02],
         [-7.967e-01]]], device='cuda:0')
s after update for 1 param tensor([[[1.479],
         [1.356],
         [1.831],
         [1.904],
         [1.198],
         [1.891],
         [1.765],
         [1.829],
         [1.431],
         [1.520]],

        [[2.577],
         [1.293],
         [2.303],
         [2.395],
         [2.144],
         [1.743],
         [2.238],
         [2.245],
         [2.704],
         [2.064]],

        [[1.523],
         [2.421],
         [2.010],
         [1.780],
         [2.070],
         [1.375],
         [1.452],
         [1.195],
         [1.615],
         [1.693]],

        [[2.308],
         [2.476],
         [2.421],
         [1.954],
         [2.405],
         [2.036],
         [1.408],
         [2.091],
         [1.903],
         [1.464]],

        [[2.358],
         [1.738],
         [2.184],
         [1.597],
         [2.496],
         [2.540],
         [1.156],
         [2.186],
         [1.502],
         [1.742]],

        [[2.325],
         [2.173],
         [2.127],
         [1.264],
         [1.878],
         [2.528],
         [2.141],
         [2.432],
         [1.732],
         [1.059]],

        [[1.736],
         [0.935],
         [1.576],
         [2.044],
         [1.862],
         [2.303],
         [1.496],
         [2.145],
         [1.687],
         [1.991]],

        [[2.402],
         [1.619],
         [1.936],
         [1.986],
         [1.108],
         [1.183],
         [2.055],
         [1.644],
         [1.124],
         [1.650]],

        [[2.184],
         [2.277],
         [2.081],
         [1.768],
         [1.273],
         [1.851],
         [1.835],
         [1.858],
         [2.084],
         [1.918]],

        [[1.933],
         [1.639],
         [1.169],
         [1.379],
         [1.165],
         [1.222],
         [1.204],
         [2.422],
         [2.121],
         [1.561]],

        [[1.671],
         [2.124],
         [1.317],
         [1.246],
         [1.490],
         [1.383],
         [1.473],
         [1.170],
         [1.252],
         [1.857]],

        [[1.620],
         [1.498],
         [2.016],
         [1.522],
         [2.011],
         [1.400],
         [2.338],
         [1.710],
         [1.859],
         [1.325]],

        [[1.274],
         [1.452],
         [1.839],
         [1.891],
         [1.649],
         [1.677],
         [1.397],
         [1.416],
         [1.406],
         [2.060]],

        [[1.517],
         [1.712],
         [1.635],
         [1.703],
         [1.376],
         [1.751],
         [0.963],
         [1.880],
         [1.639],
         [1.193]],

        [[2.314],
         [1.767],
         [1.729],
         [2.046],
         [1.940],
         [1.922],
         [1.874],
         [1.459],
         [1.283],
         [1.370]],

        [[1.578],
         [1.590],
         [2.425],
         [1.761],
         [2.380],
         [2.469],
         [2.717],
         [2.179],
         [1.555],
         [2.270]],

        [[1.452],
         [1.301],
         [1.496],
         [1.250],
         [1.707],
         [2.161],
         [1.799],
         [1.029],
         [1.574],
         [1.689]],

        [[1.494],
         [1.688],
         [1.714],
         [1.924],
         [1.795],
         [1.466],
         [1.411],
         [1.141],
         [1.627],
         [1.644]],

        [[2.211],
         [1.785],
         [1.561],
         [1.298],
         [2.112],
         [1.203],
         [2.464],
         [2.007],
         [1.032],
         [2.007]],

        [[1.727],
         [1.580],
         [1.465],
         [1.430],
         [1.727],
         [1.898],
         [1.658],
         [2.008],
         [1.778],
         [1.786]]], device='cuda:0')
b after update for 1 param tensor([[[103.701],
         [ 99.299],
         [115.386],
         [117.646],
         [ 93.318],
         [117.251],
         [113.287],
         [115.311],
         [102.015],
         [105.125]],

        [[136.873],
         [ 96.968],
         [129.389],
         [131.968],
         [124.841],
         [112.559],
         [127.559],
         [127.770],
         [140.218],
         [122.505]],

        [[105.219],
         [132.675],
         [120.886],
         [113.749],
         [122.688],
         [ 99.976],
         [102.757],
         [ 93.217],
         [108.366],
         [110.945]],

        [[129.529],
         [134.179],
         [132.675],
         [119.183],
         [132.239],
         [121.661],
         [101.190],
         [123.302],
         [117.632],
         [103.182]],

        [[130.946],
         [112.422],
         [126.004],
         [107.749],
         [134.701],
         [135.899],
         [ 91.690],
         [126.067],
         [104.506],
         [112.547]],

        [[130.017],
         [125.683],
         [124.354],
         [ 95.874],
         [116.859],
         [135.573],
         [124.770],
         [132.964],
         [112.206],
         [ 87.733]],

        [[112.361],
         [ 82.435],
         [107.056],
         [121.921],
         [116.346],
         [129.401],
         [104.280],
         [124.892],
         [110.766],
         [120.316]],

        [[132.140],
         [108.481],
         [118.650],
         [120.178],
         [ 89.741],
         [ 92.725],
         [122.221],
         [109.324],
         [ 90.397],
         [109.520]],

        [[126.017],
         [128.662],
         [122.993],
         [113.384],
         [ 96.189],
         [116.001],
         [115.503],
         [116.224],
         [123.093],
         [118.075]],

        [[118.549],
         [109.148],
         [ 92.198],
         [100.118],
         [ 92.034],
         [ 94.243],
         [ 93.549],
         [132.705],
         [124.187],
         [106.548]],

        [[110.240],
         [124.260],
         [ 97.863],
         [ 95.181],
         [104.072],
         [100.283],
         [103.503],
         [ 92.221],
         [ 95.406],
         [116.185]],

        [[108.545],
         [104.379],
         [121.080],
         [105.199],
         [120.922],
         [100.896],
         [130.375],
         [111.499],
         [116.271],
         [ 98.155]],

        [[ 96.252],
         [102.751],
         [115.618],
         [117.264],
         [109.481],
         [110.412],
         [100.767],
         [101.466],
         [101.108],
         [122.375]],

        [[105.025],
         [111.559],
         [109.020],
         [111.266],
         [100.005],
         [112.840],
         [ 83.662],
         [116.923],
         [109.166],
         [ 93.130]],

        [[129.697],
         [113.360],
         [112.136],
         [121.955],
         [118.766],
         [118.213],
         [116.731],
         [103.012],
         [ 96.595],
         [ 99.789]],

        [[107.121],
         [107.532],
         [132.775],
         [113.150],
         [131.537],
         [133.980],
         [140.554],
         [125.858],
         [106.324],
         [128.460]],

        [[102.734],
         [ 97.262],
         [104.306],
         [ 95.343],
         [111.410],
         [125.336],
         [114.366],
         [ 86.497],
         [106.984],
         [110.808]],

        [[104.235],
         [110.794],
         [111.635],
         [118.275],
         [114.233],
         [103.247],
         [101.291],
         [ 91.089],
         [108.752],
         [109.319]],

        [[126.781],
         [113.917],
         [106.532],
         [ 97.164],
         [123.927],
         [ 93.535],
         [133.843],
         [120.788],
         [ 86.626],
         [120.795]],

        [[112.043],
         [107.189],
         [103.207],
         [101.962],
         [112.066],
         [117.468],
         [109.779],
         [120.839],
         [113.714],
         [113.965]]], device='cuda:0')
clipping threshold 0.5930796193793991
a after update for 1 param tensor([[ 2.939e-03],
        [-3.427e+00],
        [-1.419e-01],
        [-1.618e+00],
        [ 1.883e+00],
        [ 1.360e+00],
        [ 9.117e-01],
        [-4.851e-02],
        [-2.543e+00],
        [ 6.323e-01],
        [ 4.100e-01],
        [-3.221e-02],
        [ 2.928e-01],
        [ 2.231e-02],
        [ 2.134e+00],
        [-1.840e+00],
        [-5.369e-01],
        [ 6.215e-02],
        [-9.674e-03],
        [-1.074e+00]], device='cuda:0')
s after update for 1 param tensor([[1.755],
        [2.230],
        [1.389],
        [2.496],
        [2.420],
        [2.260],
        [1.501],
        [0.924],
        [1.928],
        [1.777],
        [2.003],
        [1.749],
        [1.538],
        [1.690],
        [1.804],
        [2.515],
        [1.994],
        [1.389],
        [2.339],
        [1.871]], device='cuda:0')
b after update for 1 param tensor([[112.947],
        [127.338],
        [100.498],
        [134.710],
        [132.645],
        [128.181],
        [104.469],
        [ 81.948],
        [118.402],
        [113.658],
        [120.684],
        [112.754],
        [105.745],
        [110.846],
        [114.534],
        [135.221],
        [120.405],
        [100.497],
        [130.402],
        [116.624]], device='cuda:0')
clipping threshold 0.5930796193793991
||w||^2 0.5072722027723947
exp ma of ||w||^2 0.7232547745677184
||w|| 0.7122304421831425
exp ma of ||w|| 0.8212830334017934
||w||^2 0.43465693562577035
exp ma of ||w||^2 0.812291869259461
||w|| 0.6592851701849287
exp ma of ||w|| 0.8730812514661485
||w||^2 3.034681707929391
exp ma of ||w||^2 0.8726005746235862
||w|| 1.7420337849563627
exp ma of ||w|| 0.8828471671956547
||w||^2 0.7047469404146709
exp ma of ||w||^2 0.9036355909754956
||w|| 0.8394920728718472
exp ma of ||w|| 0.8998099645751151
||w||^2 0.4236788271590729
exp ma of ||w||^2 0.866875824448501
||w|| 0.6509061584891273
exp ma of ||w|| 0.8973217885127418
cuda
Objective function 46.19 = squared loss an data 36.44 + 0.5*rho*h**2 8.386094 + alpha*h 0.000000 + L2reg 1.07 + L1reg 0.30 ; SHD = 137 ; DAG False
Proportion of microbatches that were clipped  0.7705540300436117
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 4.095386211587446
iteration 1 in outer loop, alpha = 4.095386211587446, rho = 1.0, h = 4.095386211587446
cuda
4420
cuda
Objective function 62.96 = squared loss an data 36.44 + 0.5*rho*h**2 8.386094 + alpha*h 16.772188 + L2reg 1.07 + L1reg 0.30 ; SHD = 137 ; DAG False
||w||^2 111446131438.17085
exp ma of ||w||^2 140525583193.77975
||w|| 333835.4855885918
exp ma of ||w|| 287442.74851452914
||w||^2 3131.1342994410115
exp ma of ||w||^2 111898552.64901964
||w|| 55.9565393804961
exp ma of ||w|| 1255.411791992945
||w||^2 2.3008861939880836
exp ma of ||w||^2 2407031.411112375
||w|| 1.516867230178068
exp ma of ||w|| 31.716069005744078
||w||^2 1.9531507268737804
exp ma of ||w||^2 1.492907251127872
||w|| 1.397551690233238
exp ma of ||w|| 1.1703874070432845
||w||^2 0.7768188810722505
exp ma of ||w||^2 1.1980048289537177
||w|| 0.8813732926928581
exp ma of ||w|| 1.0510987509657959
||w||^2 1.756208698996269
exp ma of ||w||^2 1.4256424265766807
||w|| 1.3252202454672466
exp ma of ||w|| 1.1478134249791907
||w||^2 1.0478243417397837
exp ma of ||w||^2 1.4962709498507514
||w|| 1.0236329135680347
exp ma of ||w|| 1.1796143634671974
||w||^2 1.1757743703377828
exp ma of ||w||^2 1.4474787702629044
||w|| 1.0843313010043483
exp ma of ||w|| 1.1566808809997586
||w||^2 0.7387190085448692
exp ma of ||w||^2 1.2722605738971946
||w|| 0.8594876430437317
exp ma of ||w|| 1.0896230018526267
||w||^2 0.8271278868683699
exp ma of ||w||^2 1.2703194260999118
||w|| 0.9094657150593253
exp ma of ||w|| 1.0822227627438226
||w||^2 1.419036560095478
exp ma of ||w||^2 1.5109230363021018
||w|| 1.1912332097853375
exp ma of ||w|| 1.1777917864618261
||w||^2 2.0847814521319656
exp ma of ||w||^2 1.4664798970520256
||w|| 1.4438772288986226
exp ma of ||w|| 1.1640666460939648
cuda
Objective function 37.48 = squared loss an data 24.62 + 0.5*rho*h**2 2.314917 + alpha*h 8.812063 + L2reg 1.47 + L1reg 0.27 ; SHD = 95 ; DAG False
Proportion of microbatches that were clipped  0.7695188471871692
iteration 1 in inner loop, alpha 4.095386211587446 rho 1.0 h 2.1517050159722224
4420
cuda
Objective function 58.32 = squared loss an data 24.62 + 0.5*rho*h**2 23.149172 + alpha*h 8.812063 + L2reg 1.47 + L1reg 0.27 ; SHD = 95 ; DAG False
||w||^2 608.8871422772006
exp ma of ||w||^2 35214697.86141941
||w|| 24.675638639702935
exp ma of ||w|| 330.45720284075253
||w||^2 3.352800008579677
exp ma of ||w||^2 5.5559529715648575
||w|| 1.8310652660622662
exp ma of ||w|| 1.6830150608266325
v before min max tensor([[-2.410e+02, -2.299e+02,  3.358e+02,  ...,  2.994e+01, -2.487e+02,
          9.424e+02],
        [-1.350e+02, -5.688e+01,  2.627e+03,  ..., -5.845e+01,  8.212e+02,
         -2.798e+02],
        [ 5.905e+02,  4.046e+01,  3.857e+02,  ...,  2.473e+02, -3.771e+01,
          4.457e+01],
        ...,
        [-1.337e+02, -2.594e+02, -8.568e+01,  ...,  2.306e-02, -2.095e+02,
         -1.748e+02],
        [-8.980e+01, -2.287e+02, -2.150e+02,  ..., -1.305e+02, -5.815e+01,
         -2.443e+02],
        [-6.478e+01, -8.634e+01, -1.834e+02,  ..., -4.771e+01, -1.469e+02,
         -2.271e+02]], device='cuda:0')
v tensor([[1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.000e+01],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e+01,
         1.000e-12],
        [1.000e+01, 1.000e+01, 1.000e+01,  ..., 1.000e+01, 1.000e-12,
         1.000e+01],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 2.306e-02, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([-1.432e+02,  2.768e+02, -3.138e+01, -2.994e+02, -2.089e+02, -1.159e+02,
         3.138e+02, -1.849e+02,  1.176e+02, -2.106e-01,  2.245e+02, -1.597e+02,
        -2.227e+02, -1.065e+02, -1.884e+02, -5.140e+01,  1.062e+03, -2.266e+02,
         6.514e+02,  1.044e+00, -1.048e+02,  2.721e+02,  1.217e+02, -2.172e+02,
         1.980e+02, -8.190e+01, -2.507e+02, -1.947e+02,  4.307e+02,  1.837e+02,
        -9.732e+01, -2.255e+02,  6.133e+01,  2.559e+01, -1.627e+02, -2.143e+02,
        -2.800e+02,  1.474e+02, -1.750e+02, -2.116e+02,  9.594e+02, -1.874e+02,
        -2.849e+02, -2.077e+02, -2.231e+02, -2.481e+02, -2.351e+01, -1.143e+02,
         6.121e+02, -1.269e+02, -2.285e+02,  8.896e+01,  7.818e+01, -2.057e+02,
        -2.255e+02,  8.732e+01,  5.212e+01, -2.364e+02,  2.210e+02,  1.425e+02,
         1.674e+02, -2.304e+02, -2.026e+02, -2.830e+02, -6.893e+01, -1.854e+02,
        -1.927e+02,  5.288e+02,  1.340e+02,  8.962e+01, -2.905e+02, -1.428e+02,
        -6.166e+01,  3.580e+02, -1.781e+02, -1.599e+02,  3.452e+01, -1.706e+02,
         4.873e+02,  1.993e+02, -2.460e+02, -2.531e+02,  4.253e+02, -1.329e+00,
        -1.975e+02, -1.072e+02, -1.751e+02,  1.839e+02,  5.894e+02,  8.156e+02,
         3.170e+03,  3.891e+02,  1.512e+03, -2.037e+02,  2.273e+02,  3.971e+02,
        -2.278e+02, -1.613e+02,  3.576e+02, -1.362e+02, -2.737e+02, -2.781e+02,
        -1.419e+02,  1.401e+03, -1.865e+02, -2.650e+02,  2.496e+02, -3.545e+01,
        -2.812e+01,  4.105e+02, -2.694e+02, -2.626e+02, -8.490e+01,  3.353e+01,
         2.259e+02, -1.625e+02, -1.571e+02, -2.468e+02, -2.659e+02,  1.219e+03,
        -2.149e+02, -1.606e+02,  8.028e+01,  1.123e+03, -2.444e+02, -1.965e+02,
        -2.326e+02,  4.272e+02, -2.173e+02,  1.185e+02, -3.002e+02, -2.595e+02,
         2.043e+02, -2.039e+02, -2.110e+02,  5.001e+02, -2.336e+02, -2.719e+02,
        -1.659e+02, -1.959e+02, -1.041e+02,  4.102e+02, -2.783e+02, -3.341e+01,
        -1.802e+00, -1.840e+02, -2.304e+02,  2.164e+02, -1.453e+02, -1.923e+02,
        -2.088e+02, -2.111e+02, -1.543e+02, -1.859e+02, -9.449e+00,  5.214e+01,
        -1.371e+02, -2.579e+02,  8.649e+02, -1.698e+02, -7.969e+01,  3.103e+02,
        -1.684e+02, -1.937e+02, -2.007e+02, -2.578e+02, -1.966e+02,  1.118e+02,
         2.728e+02, -3.002e+02, -2.455e+02,  3.324e+02, -1.413e+02, -3.591e+01,
        -1.626e+02, -2.002e+02, -1.203e+02, -1.621e+02, -2.685e+02, -1.740e+02,
        -2.876e+02, -2.222e+02, -2.468e+02,  5.783e+02, -2.502e+02, -2.274e+02,
         8.140e+01, -9.071e+01, -1.889e+02, -1.788e+02, -2.377e+02, -1.758e+02,
        -1.854e+02,  1.727e+02, -2.905e+02, -1.033e+02, -6.260e+01, -2.247e+02,
        -3.245e+01, -4.020e+01], device='cuda:0')
v tensor([1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.044e+00, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e+01,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12], device='cuda:0')
v before min max tensor([[[  41.552],
         [ -68.696],
         [ -89.397],
         [-177.761],
         [-177.542],
         [ 159.486],
         [-290.023],
         [  22.533],
         [  75.245],
         [  12.954]],

        [[  35.415],
         [-150.502],
         [-265.499],
         [ 324.500],
         [ -77.779],
         [  -3.640],
         [  58.085],
         [ 832.713],
         [-178.207],
         [ 218.037]],

        [[ -59.467],
         [-222.105],
         [-137.997],
         [ 167.712],
         [-217.417],
         [ -38.497],
         [  -3.659],
         [-278.941],
         [ 399.475],
         [-232.008]],

        [[-187.648],
         [ -27.867],
         [-316.305],
         [-243.843],
         [-191.364],
         [1967.988],
         [-185.269],
         [  -5.971],
         [-289.813],
         [-192.898]],

        [[ -38.255],
         [-196.712],
         [-214.356],
         [-293.544],
         [ -15.655],
         [ 110.683],
         [ 145.782],
         [-111.228],
         [2068.285],
         [   5.097]],

        [[-230.883],
         [-168.211],
         [ 188.065],
         [  23.646],
         [-108.407],
         [-225.144],
         [ 197.974],
         [ 915.738],
         [-161.318],
         [-247.435]],

        [[ -57.064],
         [ -20.639],
         [-173.362],
         [-148.195],
         [ -44.361],
         [-138.910],
         [-246.400],
         [-182.635],
         [-101.157],
         [-122.395]],

        [[  17.783],
         [ 115.907],
         [-191.692],
         [-204.982],
         [ -33.202],
         [ 751.714],
         [ -26.915],
         [-290.161],
         [-221.487],
         [ 782.254]],

        [[-137.300],
         [-176.401],
         [ 260.560],
         [-222.824],
         [  88.500],
         [ 108.673],
         [ 589.819],
         [-206.336],
         [-175.743],
         [ 262.856]],

        [[-176.832],
         [ -94.609],
         [-257.417],
         [-239.868],
         [ 297.043],
         [  79.661],
         [  92.639],
         [ -59.478],
         [-237.619],
         [ 154.978]],

        [[-177.589],
         [ 414.198],
         [ 956.776],
         [-289.514],
         [-228.254],
         [ -47.601],
         [-219.880],
         [-238.113],
         [-270.572],
         [ 313.104]],

        [[-215.863],
         [ 469.443],
         [ -68.845],
         [-255.949],
         [ 424.390],
         [-219.473],
         [  92.473],
         [-120.208],
         [ -10.417],
         [-247.645]],

        [[-129.325],
         [  97.815],
         [-210.168],
         [-237.998],
         [-292.850],
         [ -79.168],
         [ -87.431],
         [ -85.658],
         [ -21.343],
         [ 347.643]],

        [[-212.228],
         [ -80.749],
         [  23.916],
         [-269.760],
         [ 222.802],
         [-136.381],
         [-262.077],
         [ 134.720],
         [ -25.481],
         [-218.584]],

        [[-223.576],
         [ 969.250],
         [-224.994],
         [-293.738],
         [ -92.677],
         [-158.121],
         [-132.020],
         [3001.791],
         [ 458.552],
         [  81.099]],

        [[ -81.586],
         [-228.591],
         [-261.572],
         [ 437.241],
         [  35.722],
         [ 548.976],
         [1009.598],
         [-256.135],
         [-189.290],
         [ 149.404]],

        [[-161.969],
         [-230.723],
         [-214.740],
         [ -43.568],
         [  66.928],
         [-138.402],
         [-187.420],
         [-253.373],
         [ 193.524],
         [-196.648]],

        [[  94.593],
         [-257.553],
         [ -14.014],
         [ 379.425],
         [-271.952],
         [-278.911],
         [-182.300],
         [-142.505],
         [-177.234],
         [ 149.764]],

        [[-144.054],
         [ 129.405],
         [  83.818],
         [-232.164],
         [-232.619],
         [ -87.287],
         [  39.818],
         [ -86.676],
         [-218.299],
         [-173.674]],

        [[-262.770],
         [ 264.526],
         [-216.288],
         [-234.908],
         [-153.394],
         [-171.037],
         [ 530.384],
         [-210.466],
         [-189.088],
         [-228.807]]], device='cuda:0')
v tensor([[[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [5.097e+00]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[  61.765],
        [-231.230],
        [ -66.851],
        [ -58.523],
        [ 528.417],
        [ 386.699],
        [-130.329],
        [-159.671],
        [ 128.138],
        [-242.108],
        [ 263.615],
        [1472.435],
        [ 380.198],
        [-183.474],
        [ 773.025],
        [-310.820],
        [ 990.908],
        [-164.434],
        [ -83.482],
        [-186.613]], device='cuda:0')
v tensor([[1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 0.038,  0.025, -0.356,  ..., -0.387,  0.164, -0.186],
        [-0.103, -0.280,  0.065,  ...,  0.459,  0.041,  0.106],
        [-0.039, -0.027,  0.148,  ..., -0.107,  0.076, -0.069],
        ...,
        [-0.005, -0.171, -0.046,  ...,  0.074,  0.183,  0.180],
        [ 0.047,  0.020,  0.103,  ...,  0.111, -0.030,  0.040],
        [ 0.072,  0.075, -0.242,  ..., -0.048,  0.072, -0.024]],
       device='cuda:0')
s after update for 1 param tensor([[1.616, 1.616, 2.089,  ..., 1.950, 1.654, 1.764],
        [1.554, 1.558, 2.246,  ..., 1.345, 1.938, 2.097],
        [1.779, 1.810, 1.711,  ..., 1.878, 1.070, 1.639],
        ...,
        [1.295, 1.920, 2.153,  ..., 1.335, 1.899, 2.019],
        [1.406, 1.668, 1.495,  ..., 1.403, 1.277, 1.629],
        [2.130, 1.945, 1.242,  ..., 1.373, 1.617, 1.534]], device='cuda:0')
b after update for 1 param tensor([[111.708, 111.712, 127.011,  ..., 122.704, 113.033, 116.721],
        [109.543, 109.674, 131.710,  ..., 101.921, 122.345, 127.257],
        [117.220, 118.239, 114.946,  ..., 120.428,  90.880, 112.520],
        ...,
        [ 99.987, 121.776, 128.937,  ..., 101.541, 121.088, 124.864],
        [104.185, 113.509, 107.450,  ..., 104.084,  99.313, 112.153],
        [128.259, 122.569,  97.928,  ..., 102.958, 111.745, 108.847]],
       device='cuda:0')
clipping threshold 1.1905679707815189
a after update for 1 param tensor([-0.099,  0.024,  0.064, -0.050, -0.035, -0.120,  0.181,  0.187,  0.174,
         0.075, -0.103,  0.145,  0.188, -0.165,  0.355,  0.030,  0.186,  0.118,
        -0.023,  0.030,  0.070,  0.239, -0.118,  0.107, -0.004,  0.283, -0.171,
        -0.046,  0.228,  0.217, -0.054, -0.110, -0.069, -0.123,  0.122, -0.239,
        -0.098, -0.066, -0.088, -0.165,  0.370,  0.006, -0.386, -0.018,  0.046,
        -0.223,  0.017, -0.017, -0.175,  0.187,  0.133,  0.329,  0.013, -0.222,
        -0.077,  0.198,  0.232, -0.269,  0.030, -0.206, -0.036,  0.113, -0.245,
        -0.336,  0.337, -0.004,  0.446,  0.023, -0.216,  0.002,  0.024, -0.454,
        -0.087, -0.069,  0.216,  0.164,  0.122,  0.242,  0.119,  0.209,  0.077,
        -0.108, -0.009,  0.352, -0.225,  0.078, -0.100, -0.246,  0.184, -0.031,
        -0.140,  0.145, -0.287,  0.054,  0.171,  0.107, -0.260, -0.300, -0.130,
        -0.146, -0.092,  0.171, -0.026,  0.181, -0.208, -0.023, -0.031, -0.093,
        -0.183,  0.404, -0.305,  0.077, -0.369, -0.040,  0.115, -0.072,  0.445,
        -0.087, -0.040, -0.322,  0.261,  0.086,  0.051, -0.057, -0.072, -0.176,
         0.397,  0.124,  0.131,  0.125, -0.002, -0.044,  0.052,  0.164, -0.065,
        -0.093,  0.072, -0.129,  0.468,  0.295, -0.006,  0.133,  0.231, -0.176,
        -0.221, -0.037, -0.007,  0.110, -0.038,  0.062,  0.170,  0.109, -0.358,
         0.253, -0.038,  0.079,  0.121, -0.133,  0.138,  0.046,  0.148,  0.206,
         0.264, -0.082,  0.128,  0.401,  0.126,  0.323,  0.225, -0.015, -0.390,
         0.184,  0.166, -0.054,  0.266,  0.272, -0.041,  0.297, -0.002,  0.112,
         0.239,  0.026,  0.253,  0.201,  0.133,  0.143, -0.186,  0.128, -0.156,
        -0.110, -0.034,  0.188,  0.066, -0.237, -0.222, -0.065, -0.262,  0.113,
        -0.069,  0.275], device='cuda:0')
s after update for 1 param tensor([1.278, 1.731, 0.837, 1.997, 1.596, 1.534, 1.774, 2.027, 2.035, 1.565,
        1.210, 1.283, 1.797, 1.618, 1.395, 1.895, 1.744, 1.521, 1.650, 1.221,
        1.681, 1.988, 2.050, 1.587, 2.015, 1.962, 1.667, 2.001, 1.795, 1.850,
        1.253, 1.780, 2.329, 2.288, 1.529, 1.429, 1.883, 1.566, 1.642, 1.522,
        1.916, 1.440, 1.898, 1.847, 1.704, 1.650, 2.161, 1.451, 2.006, 2.047,
        1.944, 1.752, 1.739, 1.565, 1.927, 1.203, 1.706, 1.754, 2.033, 2.052,
        2.239, 1.612, 1.433, 1.905, 1.247, 1.430, 1.306, 1.895, 2.264, 1.809,
        1.931, 1.607, 1.481, 2.100, 1.639, 1.923, 2.252, 1.643, 2.299, 2.259,
        1.839, 1.741, 1.956, 1.491, 1.700, 1.231, 1.414, 2.138, 2.000, 2.029,
        2.051, 1.720, 2.246, 1.477, 1.695, 1.920, 1.738, 1.723, 2.121, 1.166,
        1.819, 1.890, 1.385, 1.921, 1.594, 1.901, 2.101, 1.813, 1.727, 2.050,
        1.797, 1.751, 1.865, 1.517, 2.059, 1.116, 1.629, 1.697, 2.217, 2.292,
        1.567, 1.129, 1.956, 2.466, 1.626, 1.437, 1.836, 2.060, 2.028, 2.084,
        2.005, 1.726, 2.014, 1.755, 1.402, 2.184, 1.914, 1.808, 1.104, 2.063,
        1.805, 1.858, 1.853, 1.557, 1.772, 1.223, 1.533, 2.158, 1.029, 1.468,
        1.556, 1.403, 1.254, 1.489, 1.605, 1.811, 1.598, 1.760, 2.018, 1.602,
        1.558, 1.910, 1.837, 1.558, 1.836, 1.891, 1.743, 1.773, 2.120, 2.014,
        1.655, 1.723, 1.081, 1.802, 1.459, 2.029, 1.756, 1.498, 1.807, 1.500,
        1.929, 2.004, 1.751, 1.688, 1.888, 1.528, 1.826, 1.619, 1.325, 1.292,
        1.580, 1.700, 1.238, 2.169, 1.955, 2.050, 1.892, 1.700, 0.978, 2.011],
       device='cuda:0')
b after update for 1 param tensor([ 99.363, 115.603,  80.376, 124.180, 111.027, 108.832, 117.032, 125.102,
        125.373, 109.922,  96.676,  99.532, 117.791, 111.792, 103.809, 120.958,
        116.068, 108.374, 112.888,  97.102, 113.934, 123.895, 125.817, 110.715,
        124.736, 123.097, 113.474, 124.309, 117.742, 119.523,  98.366, 117.233,
        134.112, 132.927, 108.677, 105.068, 120.575, 109.954, 112.607, 108.421,
        121.625, 105.461, 121.060, 119.430, 114.714, 112.867, 129.188, 105.849,
        124.452, 125.740, 122.529, 116.310, 115.892, 109.931, 121.992,  96.385,
        114.779, 116.375, 125.285, 125.869, 131.479, 111.560, 105.188, 121.300,
         98.147, 105.098, 100.413, 120.985, 132.220, 118.181, 122.107, 111.389,
        106.958, 127.347, 112.498, 121.878, 131.887, 112.649, 133.251, 132.087,
        119.166, 115.960, 122.905, 107.321, 114.576,  97.503, 104.483, 128.495,
        124.277, 125.183, 125.851, 115.257, 131.713, 106.801, 114.403, 121.780,
        115.844, 115.352, 127.992,  94.872, 118.508, 120.803, 103.419, 121.809,
        110.936, 121.160, 127.390, 118.313, 115.472, 125.827, 117.817, 116.292,
        120.008, 108.244, 126.102,  92.832, 112.176, 114.480, 130.854, 133.047,
        109.992,  93.365, 122.917, 137.992, 112.059, 105.340, 119.084, 126.128,
        125.154, 126.869, 124.436, 115.437, 124.700, 116.427, 104.050, 129.880,
        121.580, 118.166,  92.347, 126.221, 118.065, 119.771, 119.637, 109.643,
        116.988,  97.172, 108.789, 129.082,  89.135, 106.487, 109.636, 104.087,
         98.390, 107.244, 111.343, 118.275, 111.072, 116.581, 124.827, 111.211,
        109.690, 121.438, 119.099, 109.706, 119.060, 120.833, 116.007, 117.017,
        127.962, 124.723, 113.048, 115.345,  91.369, 117.982, 106.162, 125.174,
        116.447, 107.566, 118.139, 107.611, 122.059, 124.400, 116.292, 114.161,
        120.762, 108.625, 118.763, 111.826, 101.137,  99.885, 110.453, 114.593,
         97.790, 129.413, 122.873, 125.829, 120.888, 114.578,  86.901, 124.604],
       device='cuda:0')
clipping threshold 1.1905679707815189
a after update for 1 param tensor([[[-1.286e-01],
         [-2.268e-01],
         [ 5.228e-02],
         [ 5.436e-01],
         [ 9.458e-02],
         [-1.364e-01],
         [ 1.817e-01],
         [-1.648e-01],
         [-4.342e-02],
         [-3.161e-01]],

        [[-1.162e-01],
         [-1.484e-01],
         [-3.274e-01],
         [-4.292e-01],
         [ 3.095e-01],
         [ 1.915e-01],
         [-1.243e-01],
         [ 1.659e-01],
         [ 3.430e-02],
         [ 2.609e-01]],

        [[-9.288e-03],
         [-3.144e-02],
         [ 7.706e-03],
         [-3.849e-01],
         [-6.766e-02],
         [ 1.411e-01],
         [ 1.792e-01],
         [-6.073e-02],
         [ 1.440e-02],
         [-2.960e-01]],

        [[-8.164e-02],
         [-3.514e-01],
         [-1.567e-01],
         [-8.367e-02],
         [-1.347e-01],
         [-8.484e-02],
         [ 7.741e-02],
         [-1.677e-01],
         [-2.481e-01],
         [-2.401e-01]],

        [[-1.779e-01],
         [ 4.537e-01],
         [-9.172e-02],
         [ 2.365e-01],
         [ 8.199e-02],
         [ 1.340e-01],
         [ 1.177e-01],
         [-6.878e-02],
         [-8.847e-02],
         [-7.332e-02]],

        [[-1.895e-02],
         [ 3.697e-02],
         [-1.032e-01],
         [-1.821e-03],
         [-4.891e-01],
         [ 1.940e-02],
         [-4.599e-02],
         [ 8.496e-02],
         [ 1.108e-01],
         [ 1.097e-01]],

        [[-2.160e-01],
         [-7.017e-02],
         [ 6.264e-03],
         [ 3.843e-02],
         [-3.303e-04],
         [ 1.973e-01],
         [ 2.503e-01],
         [-5.298e-02],
         [ 5.840e-01],
         [-1.184e-01]],

        [[ 2.174e-01],
         [-1.506e-01],
         [ 1.931e-01],
         [ 1.200e-01],
         [ 2.690e-01],
         [ 6.665e-02],
         [-7.793e-02],
         [ 5.902e-02],
         [-1.672e-01],
         [-2.618e-01]],

        [[-2.604e-01],
         [ 2.177e-01],
         [-2.105e-01],
         [-1.673e-02],
         [ 1.661e-01],
         [ 1.270e-01],
         [ 4.983e-01],
         [ 2.270e-02],
         [-5.040e-02],
         [-1.596e-01]],

        [[ 7.604e-02],
         [-5.932e-02],
         [ 1.746e-01],
         [ 2.837e-01],
         [-9.230e-03],
         [ 1.451e-01],
         [ 7.754e-02],
         [ 9.064e-02],
         [-5.160e-02],
         [ 1.721e-01]],

        [[-2.566e-01],
         [ 1.288e-01],
         [ 6.596e-02],
         [-2.438e-01],
         [-1.801e-01],
         [ 1.028e-01],
         [ 1.563e-01],
         [ 4.275e-01],
         [ 4.642e-01],
         [-1.315e-01]],

        [[ 3.485e-02],
         [ 8.809e-02],
         [-9.395e-02],
         [ 9.580e-02],
         [ 3.309e-03],
         [ 1.108e-01],
         [-6.434e-01],
         [ 1.731e-01],
         [-2.866e-01],
         [-4.970e-02]],

        [[-2.110e-01],
         [ 1.343e-01],
         [-4.650e-02],
         [ 1.877e-01],
         [ 1.321e-01],
         [-4.837e-01],
         [ 2.131e-02],
         [-8.238e-02],
         [ 3.115e-01],
         [-7.866e-02]],

        [[-1.811e-01],
         [ 3.662e-02],
         [-6.145e-02],
         [-5.046e-01],
         [ 9.650e-02],
         [ 2.207e-01],
         [-1.833e-01],
         [-1.536e-01],
         [ 1.243e-01],
         [-2.407e-01]],

        [[ 1.976e-01],
         [-1.371e-01],
         [ 1.901e-01],
         [ 3.770e-02],
         [ 3.257e-01],
         [ 3.044e-02],
         [-2.964e-01],
         [-4.531e-02],
         [ 9.293e-02],
         [ 3.368e-01]],

        [[-8.407e-02],
         [ 9.842e-03],
         [ 8.015e-02],
         [ 8.065e-02],
         [-2.520e-01],
         [-5.518e-01],
         [ 2.943e-01],
         [-1.086e-01],
         [-9.310e-02],
         [ 2.762e-01]],

        [[-1.800e-01],
         [ 4.188e-02],
         [-1.115e-01],
         [-1.397e-02],
         [-2.052e-01],
         [-1.500e-01],
         [-1.782e-01],
         [ 4.796e-02],
         [-3.031e-02],
         [-1.583e-02]],

        [[-1.651e-01],
         [ 3.409e-01],
         [-1.493e-01],
         [-4.026e-02],
         [ 3.597e-01],
         [ 2.641e-01],
         [ 1.538e-01],
         [ 3.969e-01],
         [-7.318e-02],
         [ 4.426e-01]],

        [[ 3.830e-01],
         [-2.610e-01],
         [-2.223e-01],
         [-2.022e-01],
         [-1.939e-01],
         [ 3.429e-01],
         [ 2.101e-01],
         [-1.180e-01],
         [-1.198e-01],
         [-9.243e-02]],

        [[-2.544e-01],
         [-1.780e-02],
         [-8.899e-03],
         [-1.746e-03],
         [ 5.836e-01],
         [ 7.928e-02],
         [-8.761e-02],
         [ 8.441e-02],
         [ 9.723e-03],
         [ 1.215e-01]]], device='cuda:0')
s after update for 1 param tensor([[[1.866],
         [1.369],
         [1.934],
         [1.472],
         [1.699],
         [2.076],
         [1.957],
         [2.274],
         [2.068],
         [1.826]],

        [[1.662],
         [1.983],
         [1.766],
         [2.308],
         [1.391],
         [1.167],
         [1.806],
         [1.447],
         [1.755],
         [2.467]],

        [[1.892],
         [1.618],
         [1.856],
         [1.940],
         [1.459],
         [1.490],
         [1.380],
         [1.892],
         [1.825],
         [1.718]],

        [[1.353],
         [1.347],
         [2.144],
         [1.806],
         [1.578],
         [2.199],
         [1.407],
         [1.458],
         [1.931],
         [1.373]],

        [[2.206],
         [1.694],
         [1.569],
         [2.034],
         [1.473],
         [2.064],
         [1.878],
         [1.460],
         [2.043],
         [1.714]],

        [[1.968],
         [1.373],
         [2.018],
         [2.071],
         [2.310],
         [1.497],
         [1.584],
         [1.874],
         [1.464],
         [1.645]],

        [[1.076],
         [1.465],
         [1.160],
         [1.141],
         [1.733],
         [1.688],
         [1.664],
         [1.475],
         [1.543],
         [1.359]],

        [[2.292],
         [1.658],
         [1.549],
         [1.684],
         [1.803],
         [1.893],
         [1.428],
         [1.955],
         [1.778],
         [1.785]],

        [[1.031],
         [1.949],
         [1.880],
         [1.531],
         [2.261],
         [1.784],
         [1.972],
         [2.362],
         [1.171],
         [1.974]],

        [[1.318],
         [1.436],
         [1.781],
         [1.743],
         [1.772],
         [1.679],
         [2.252],
         [1.357],
         [1.721],
         [1.859]],

        [[2.200],
         [1.362],
         [2.227],
         [2.123],
         [1.565],
         [1.770],
         [1.508],
         [1.966],
         [2.033],
         [2.019]],

        [[1.465],
         [1.718],
         [1.579],
         [1.716],
         [2.099],
         [1.773],
         [1.697],
         [1.333],
         [1.540],
         [1.767]],

        [[2.007],
         [2.086],
         [1.664],
         [1.694],
         [2.005],
         [1.599],
         [1.239],
         [1.890],
         [1.650],
         [1.957]],

        [[1.604],
         [1.809],
         [2.093],
         [2.038],
         [1.740],
         [1.666],
         [1.867],
         [1.925],
         [1.764],
         [1.590]],

        [[1.486],
         [1.753],
         [1.578],
         [1.976],
         [1.953],
         [1.136],
         [1.561],
         [2.064],
         [2.223],
         [2.067]],

        [[1.622],
         [1.739],
         [1.850],
         [1.928],
         [2.201],
         [1.574],
         [1.942],
         [1.810],
         [1.369],
         [1.620]],

        [[1.524],
         [1.814],
         [1.895],
         [1.635],
         [2.139],
         [1.583],
         [1.249],
         [1.815],
         [2.209],
         [1.368]],

        [[1.995],
         [1.739],
         [1.621],
         [2.232],
         [2.013],
         [1.854],
         [1.311],
         [1.856],
         [1.745],
         [1.782]],

        [[1.823],
         [2.096],
         [2.363],
         [1.599],
         [1.608],
         [1.533],
         [1.656],
         [1.647],
         [1.759],
         [2.019]],

        [[1.753],
         [1.885],
         [2.166],
         [2.224],
         [2.149],
         [1.540],
         [2.027],
         [1.647],
         [1.454],
         [1.680]]], device='cuda:0')
b after update for 1 param tensor([[[120.027],
         [102.826],
         [122.195],
         [106.602],
         [114.533],
         [126.608],
         [122.931],
         [132.521],
         [126.360],
         [118.750]],

        [[113.287],
         [123.759],
         [116.788],
         [133.514],
         [103.644],
         [ 94.923],
         [118.094],
         [105.712],
         [116.401],
         [138.031]],

        [[120.866],
         [111.771],
         [119.723],
         [122.390],
         [106.146],
         [107.274],
         [103.217],
         [120.889],
         [118.724],
         [115.172]],

        [[102.208],
         [102.005],
         [128.681],
         [118.090],
         [110.403],
         [130.302],
         [104.237],
         [106.109],
         [122.120],
         [102.981]],

        [[130.535],
         [114.381],
         [110.073],
         [125.343],
         [106.645],
         [126.244],
         [120.413],
         [106.194],
         [125.604],
         [115.046]],

        [[123.288],
         [102.966],
         [124.844],
         [126.451],
         [133.573],
         [107.518],
         [110.596],
         [120.298],
         [106.318],
         [112.711]],

        [[ 91.146],
         [106.376],
         [ 94.645],
         [ 93.876],
         [115.691],
         [114.164],
         [113.365],
         [106.739],
         [109.148],
         [102.442]],

        [[133.043],
         [113.144],
         [109.358],
         [114.026],
         [117.986],
         [120.902],
         [105.025],
         [122.884],
         [117.180],
         [117.411]],

        [[ 89.211],
         [122.669],
         [120.499],
         [108.726],
         [132.147],
         [117.367],
         [123.402],
         [135.065],
         [ 95.082],
         [123.463]],

        [[100.905],
         [105.317],
         [117.281],
         [116.021],
         [116.974],
         [113.852],
         [131.872],
         [102.385],
         [115.294],
         [119.810]],

        [[130.341],
         [102.546],
         [131.152],
         [128.051],
         [109.945],
         [116.922],
         [107.918],
         [123.230],
         [125.295],
         [124.858]],

        [[106.352],
         [115.169],
         [110.437],
         [115.121],
         [127.323],
         [117.008],
         [114.479],
         [101.463],
         [109.042],
         [116.807]],

        [[124.508],
         [126.930],
         [113.372],
         [114.360],
         [124.423],
         [111.133],
         [ 97.799],
         [120.815],
         [112.892],
         [122.950]],

        [[111.286],
         [118.197],
         [127.130],
         [125.452],
         [115.911],
         [113.426],
         [120.074],
         [121.937],
         [116.702],
         [110.825]],

        [[107.119],
         [116.365],
         [110.396],
         [123.542],
         [122.805],
         [ 93.662],
         [109.789],
         [126.240],
         [131.022],
         [126.352]],

        [[111.929],
         [115.893],
         [119.524],
         [122.030],
         [130.359],
         [110.240],
         [122.455],
         [118.226],
         [102.813],
         [111.858]],

        [[108.497],
         [118.354],
         [120.977],
         [112.374],
         [128.520],
         [110.561],
         [ 98.203],
         [118.393],
         [130.600],
         [102.794]],

        [[124.129],
         [115.895],
         [111.874],
         [131.280],
         [124.677],
         [119.651],
         [100.638],
         [119.722],
         [116.099],
         [117.305]],

        [[118.660],
         [127.211],
         [135.095],
         [111.107],
         [111.444],
         [108.814],
         [113.083],
         [112.788],
         [116.554],
         [124.881]],

        [[116.362],
         [120.666],
         [129.323],
         [131.061],
         [128.814],
         [109.067],
         [125.114],
         [112.776],
         [105.976],
         [113.919]]], device='cuda:0')
clipping threshold 1.1905679707815189
a after update for 1 param tensor([[ 0.060],
        [-0.127],
        [ 0.027],
        [-0.095],
        [ 0.172],
        [-0.246],
        [ 0.093],
        [ 0.005],
        [-0.099],
        [-0.104],
        [ 0.082],
        [ 0.413],
        [ 0.108],
        [-0.112],
        [-0.312],
        [-0.170],
        [-0.166],
        [-0.052],
        [-0.378],
        [ 0.057]], device='cuda:0')
s after update for 1 param tensor([[2.234],
        [1.568],
        [1.374],
        [1.681],
        [1.927],
        [1.991],
        [1.305],
        [1.892],
        [1.747],
        [1.615],
        [1.913],
        [2.435],
        [2.046],
        [1.883],
        [2.204],
        [2.117],
        [2.025],
        [1.411],
        [1.577],
        [1.594]], device='cuda:0')
b after update for 1 param tensor([[131.344],
        [110.055],
        [102.991],
        [113.948],
        [121.983],
        [124.011],
        [100.399],
        [120.867],
        [116.137],
        [111.664],
        [121.554],
        [137.123],
        [125.687],
        [120.584],
        [130.470],
        [127.874],
        [125.062],
        [104.398],
        [110.349],
        [110.939]], device='cuda:0')
clipping threshold 1.1905679707815189
||w||^2 1.3612874346418204
exp ma of ||w||^2 2.7606928841941603
||w|| 1.1667422314469553
exp ma of ||w|| 1.574510752089511
||w||^2 3.571841311378156
exp ma of ||w||^2 2.4254751813599693
||w|| 1.8899315626175874
exp ma of ||w|| 1.4953192908352677
v before min max tensor([[-118.236,   93.119,  123.217,  ..., 1051.362,  323.297, -179.969],
        [-106.560,  502.279, -238.384,  ..., -192.421, -130.463, -216.634],
        [-126.573, -243.018, 1003.369,  ..., -190.692,  -92.173,  -89.651],
        ...,
        [-210.263, -213.103, -168.731,  ..., -256.927, -141.391, -299.830],
        [ 168.605,  -13.738, -164.456,  ...,  -78.870, -108.483,  -52.330],
        [ 492.692, -243.879, -110.647,  ..., -129.830, -266.704,  -15.754]],
       device='cuda:0')
v tensor([[1.000e-12, 1.000e+01, 1.000e+01,  ..., 1.000e+01, 1.000e+01,
         1.000e-12],
        [1.000e-12, 1.000e+01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e-12, 1.000e-12, 1.000e+01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        ...,
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [1.000e+01, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([ 1.745e+02, -2.022e+02, -2.624e+02, -1.837e+02, -2.104e+02,  1.880e+02,
        -1.960e+02, -1.804e+02,  2.029e+02, -2.713e+02, -1.342e+02, -2.881e+02,
        -8.305e+00, -5.759e+01, -1.996e+02, -2.675e+02, -1.018e+02, -1.395e+02,
        -2.117e+02,  2.196e+02,  9.129e+02, -9.626e+01, -2.159e+02, -2.828e+01,
        -6.059e+01, -1.754e+02,  9.026e+01, -2.217e+02,  5.546e+03, -1.818e+02,
        -1.985e+02, -4.607e+01,  8.065e+02, -2.235e+02, -1.477e+02, -2.599e+02,
        -1.454e+02, -1.760e+02, -1.016e+02, -2.225e+02, -3.018e+02, -2.172e+02,
        -2.378e+02, -1.700e+02, -1.086e+02, -2.645e+02, -2.330e+02, -2.079e+02,
         4.047e+01,  6.561e+01, -1.863e+01, -2.566e+02,  1.307e+03, -1.177e+02,
        -2.084e+02, -9.462e+01,  1.336e+01, -2.238e+02, -1.874e+02, -8.871e+01,
        -1.111e+02,  2.067e+01, -1.938e+02,  4.245e+02, -1.195e+02, -2.778e+02,
        -2.088e+02,  3.215e+02,  2.683e+01, -2.330e+02, -2.186e+02, -1.175e+02,
        -2.363e+02,  3.285e+02, -1.630e+02, -1.571e+02,  5.192e+02, -1.795e+02,
         2.263e+02,  1.084e+02,  4.631e+01, -2.221e+02,  2.148e+01, -1.260e+02,
        -1.805e+02, -1.920e+02,  2.667e+02, -2.372e+02, -2.634e+02, -2.355e+02,
        -2.155e+02, -7.661e+01, -2.229e+02,  2.179e+02,  4.154e+02, -1.763e+02,
        -6.091e+01,  5.158e+02, -7.628e+01, -3.780e+01, -2.499e+02, -2.037e+02,
        -1.694e+02,  5.682e+02, -1.577e+02, -7.015e+00, -2.215e+02,  2.826e-01,
        -2.287e+02, -1.365e+02, -3.353e+01, -9.582e+01, -2.112e+02,  6.699e+02,
        -2.322e+02,  2.739e+02, -7.104e+01,  1.266e+02, -2.751e+02, -2.160e+02,
        -2.147e+02,  9.895e+01,  4.618e+02, -1.636e+02,  9.202e+02,  1.742e+02,
        -1.710e+02, -6.666e+01, -2.415e+02,  1.347e+02, -1.123e+02,  9.678e+01,
         3.216e+02, -1.368e+02,  1.788e+01, -1.775e+02, -2.366e+02,  6.701e+01,
         8.050e+01, -2.006e+02, -1.807e+02, -2.223e+02,  2.214e+02, -2.703e+02,
        -2.809e+02,  1.662e+02, -2.614e+02, -4.801e+01, -1.790e+02, -1.988e+02,
        -7.038e+01, -1.589e+02, -8.959e+00,  1.159e+03, -1.225e+02,  5.053e+02,
        -1.980e+02, -1.878e+02, -2.136e+02, -9.100e+01, -2.066e+02, -1.983e+02,
         2.694e+02, -1.501e+02,  4.999e+01, -1.936e+02, -1.802e+02,  7.328e+01,
        -8.330e+01, -1.918e+02, -2.461e+02, -1.498e+02,  7.676e+01, -1.213e+02,
        -1.388e+02,  1.970e+02, -1.848e+02, -1.737e+02, -4.951e+01,  1.032e+02,
         7.738e+01, -1.049e+02, -2.490e+02, -2.199e+00, -2.581e+02,  3.705e+02,
        -1.372e+02,  1.497e+03, -2.400e+02, -2.160e+02, -2.170e+02, -1.657e+02,
         2.260e+02, -1.893e+02, -2.431e+02, -2.012e+02, -2.864e+02, -2.769e+02,
        -2.448e+02, -2.168e+01], device='cuda:0')
v tensor([1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e+01, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 2.826e-01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e+01, 1.000e-12, 1.000e+01, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01, 1.000e-12,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e+01,
        1.000e-12, 1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e+01, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12], device='cuda:0')
v before min max tensor([[[-284.855],
         [-161.781],
         [ 219.840],
         [-190.132],
         [-189.163],
         [-247.450],
         [-242.424],
         [-143.527],
         [  -4.717],
         [  92.731]],

        [[  72.378],
         [ 679.431],
         [ -94.159],
         [-156.647],
         [ 531.544],
         [ 826.331],
         [-261.699],
         [-145.319],
         [-193.141],
         [ 454.732]],

        [[ 150.830],
         [-181.375],
         [-270.778],
         [  53.171],
         [ 116.664],
         [-276.637],
         [  -3.805],
         [ 314.761],
         [-213.441],
         [ 158.447]],

        [[-186.416],
         [  42.127],
         [ 156.102],
         [ 245.666],
         [-259.416],
         [-121.330],
         [-174.451],
         [-186.626],
         [ 868.791],
         [-224.406]],

        [[-275.660],
         [-223.253],
         [-160.658],
         [ -38.719],
         [ -66.955],
         [ -23.961],
         [-238.554],
         [-188.382],
         [ -61.538],
         [-182.576]],

        [[-184.823],
         [ 224.546],
         [ -78.254],
         [ 153.246],
         [-295.936],
         [-166.046],
         [ -60.904],
         [ 673.001],
         [ 917.039],
         [-170.343]],

        [[ 210.306],
         [-173.711],
         [ -19.758],
         [ 463.895],
         [-201.556],
         [-187.857],
         [-204.189],
         [ 449.729],
         [   9.137],
         [-128.099]],

        [[ 249.629],
         [ 326.707],
         [ 663.300],
         [-244.172],
         [-225.798],
         [ 353.411],
         [ 358.983],
         [ 245.566],
         [ 386.008],
         [-245.282]],

        [[-211.813],
         [ -45.671],
         [ 360.839],
         [-118.802],
         [1029.301],
         [-105.063],
         [-145.074],
         [-180.744],
         [-139.483],
         [-209.655]],

        [[-233.072],
         [-189.397],
         [-125.392],
         [  39.799],
         [ -74.040],
         [ -60.973],
         [ -79.601],
         [-241.471],
         [  73.674],
         [-204.361]],

        [[-210.917],
         [ -69.092],
         [  84.065],
         [-144.649],
         [-156.084],
         [-144.448],
         [-156.453],
         [-259.099],
         [-128.445],
         [-208.775]],

        [[-216.752],
         [-138.385],
         [ -78.238],
         [ 358.216],
         [ -83.203],
         [ 311.231],
         [-305.612],
         [-203.425],
         [ -29.300],
         [ -63.995]],

        [[  50.171],
         [-133.897],
         [ -57.436],
         [-242.309],
         [ 191.333],
         [-171.868],
         [  55.710],
         [-160.188],
         [-190.413],
         [ 130.246]],

        [[ 143.688],
         [ 574.311],
         [-243.283],
         [  69.663],
         [1179.459],
         [-263.946],
         [-185.159],
         [ 659.219],
         [-152.274],
         [ 552.445]],

        [[-171.369],
         [-180.282],
         [-228.150],
         [-123.676],
         [-202.900],
         [ -52.609],
         [ -61.167],
         [  26.793],
         [  40.631],
         [-128.191]],

        [[-112.053],
         [  57.921],
         [ -61.557],
         [-236.480],
         [-122.040],
         [-164.039],
         [ -38.845],
         [-228.769],
         [-194.424],
         [ 844.574]],

        [[-191.307],
         [-219.624],
         [-227.223],
         [-259.632],
         [  33.222],
         [ -73.960],
         [-281.980],
         [-194.850],
         [ 603.586],
         [ -19.535]],

        [[  99.706],
         [-250.731],
         [-249.914],
         [-105.007],
         [-235.578],
         [ 456.105],
         [-231.846],
         [-212.384],
         [-126.056],
         [-268.469]],

        [[-262.489],
         [ 195.322],
         [-117.926],
         [-201.671],
         [  59.401],
         [-102.017],
         [ 200.707],
         [ -97.193],
         [  53.289],
         [ 205.282]],

        [[-101.241],
         [-172.753],
         [-187.007],
         [-239.737],
         [ 664.846],
         [  67.042],
         [-204.620],
         [-200.400],
         [-129.895],
         [-207.917]]], device='cuda:0')
v tensor([[[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [9.137e+00],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12]],

        [[1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e+01],
         [1.000e+01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[ -78.773],
        [ 277.579],
        [ 741.711],
        [-189.236],
        [ -77.685],
        [ -91.147],
        [ -16.557],
        [ -73.000],
        [-130.160],
        [-139.206],
        [ -81.569],
        [ -62.925],
        [ 750.424],
        [ -78.353],
        [-113.525],
        [-201.363],
        [-195.225],
        [-252.548],
        [-130.242],
        [-276.055]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e+01],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e+01],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 0.016, -0.136, -0.409,  ..., -0.334,  0.198, -0.261],
        [-0.187, -0.238, -0.123,  ...,  0.303,  0.141,  0.100],
        [-0.037, -0.204,  0.080,  ..., -0.168,  0.081, -0.186],
        ...,
        [-0.139, -0.275, -0.090,  ...,  0.114,  0.123,  0.081],
        [ 0.042, -0.045,  0.177,  ..., -0.062, -0.020, -0.017],
        [-0.027,  0.086, -0.130,  ...,  0.015, -0.208, -0.088]],
       device='cuda:0')
s after update for 1 param tensor([[1.639, 1.372, 1.574,  ..., 2.345, 1.570, 1.647],
        [1.620, 1.705, 2.110,  ..., 1.987, 1.742, 2.073],
        [1.909, 1.961, 2.017,  ..., 1.364, 0.998, 1.381],
        ...,
        [1.420, 1.776, 1.570,  ..., 1.736, 1.431, 2.052],
        [2.058, 0.765, 1.551,  ..., 1.231, 1.261, 1.561],
        [2.289, 1.843, 1.617,  ..., 0.895, 1.814, 1.283]], device='cuda:0')
b after update for 1 param tensor([[110.567, 101.130, 108.353,  ..., 132.231, 108.200, 110.833],
        [109.924, 112.753, 125.430,  ..., 121.738, 113.966, 124.330],
        [119.306, 120.935, 122.626,  ..., 100.834,  86.280, 101.491],
        ...,
        [102.900, 115.090, 108.205,  ..., 113.791, 103.290, 123.693],
        [123.884,  75.517, 107.557,  ...,  95.804,  96.966, 107.884],
        [130.659, 117.227, 109.800,  ...,  81.697, 116.319,  97.823]],
       device='cuda:0')
clipping threshold 1.1986662869034894
a after update for 1 param tensor([-4.188e-02,  5.464e-02,  4.523e-02, -8.481e-02,  9.683e-02, -2.203e-01,
         1.923e-01,  1.236e-01,  1.199e-01,  1.934e-02, -7.683e-02,  1.097e-01,
         2.743e-01, -2.435e-01,  2.118e-01,  9.617e-02,  1.372e-01,  1.461e-01,
        -1.240e-02, -8.520e-02,  1.130e-01,  1.615e-01, -1.835e-01,  8.013e-02,
         1.499e-01,  4.014e-01, -1.287e-01,  5.370e-02,  2.399e-01,  5.841e-02,
        -1.475e-01, -1.800e-01,  3.255e-02, -1.446e-01, -3.787e-02, -2.509e-01,
        -6.660e-02, -8.720e-02, -1.442e-01, -7.171e-02,  1.949e-01,  3.394e-02,
        -2.760e-01, -1.538e-02,  1.506e-01, -2.346e-01,  8.358e-02,  1.569e-01,
        -2.293e-01,  1.018e-01,  6.765e-02,  1.779e-01,  4.780e-02, -2.465e-01,
        -1.660e-01,  1.218e-01,  2.488e-01, -7.006e-02, -8.545e-02, -2.864e-01,
        -1.595e-01,  1.396e-01, -2.580e-01, -2.487e-01,  3.162e-01, -1.347e-01,
         2.944e-01,  8.840e-02, -1.268e-01, -1.245e-03,  1.923e-01, -4.774e-01,
        -6.803e-02, -7.762e-03,  9.244e-02,  4.724e-03, -1.499e-02,  1.792e-01,
        -1.216e-01,  2.235e-01,  1.880e-01, -1.361e-01,  3.982e-02,  3.378e-01,
        -3.169e-01, -8.754e-02,  3.061e-02, -4.371e-03,  1.346e-01, -1.094e-01,
        -2.019e-01,  1.242e-01, -2.904e-01,  5.805e-02, -3.467e-02,  1.598e-01,
        -1.620e-01, -1.575e-01, -6.622e-02, -2.710e-01, -2.178e-01,  1.814e-01,
        -1.931e-01,  9.571e-02, -6.519e-02, -3.042e-02, -1.773e-01,  1.666e-02,
        -4.862e-02,  4.428e-01, -2.496e-01,  1.423e-02, -2.662e-01, -1.606e-01,
         1.693e-01, -7.595e-02,  3.432e-01, -8.401e-02,  1.091e-01, -2.788e-01,
         9.493e-02, -4.467e-03,  2.542e-02, -6.854e-03,  2.297e-02, -2.593e-02,
         5.300e-01,  3.193e-02,  2.803e-02, -5.719e-02, -3.573e-02,  6.300e-02,
        -6.956e-02,  1.518e-01,  1.886e-02, -3.685e-02, -6.627e-02, -2.195e-01,
         4.155e-01,  2.396e-01,  1.340e-01, -6.375e-03,  2.300e-01,  3.735e-02,
         4.396e-02, -1.331e-04, -1.562e-01,  9.912e-02,  6.753e-03,  8.800e-02,
         8.573e-02,  8.703e-02, -4.161e-01,  6.221e-02, -1.562e-01,  8.880e-02,
         7.722e-02, -1.745e-01,  1.481e-01,  1.793e-01,  1.645e-01,  1.523e-01,
         3.152e-01, -1.211e-01,  2.731e-02,  2.097e-01,  5.478e-02,  1.520e-01,
         2.294e-01,  3.012e-02, -3.967e-01,  2.364e-01,  1.294e-01, -2.696e-02,
         2.455e-01,  2.191e-01, -1.002e-01,  3.188e-01, -2.073e-01,  3.662e-02,
         3.501e-01,  2.288e-01,  7.666e-02,  2.017e-01,  1.245e-01,  1.004e-01,
        -2.326e-03,  1.368e-02, -4.329e-02, -1.770e-01, -1.241e-01,  3.668e-01,
         2.320e-01, -2.392e-01, -2.960e-01, -1.137e-01, -8.344e-02,  4.791e-02,
        -9.471e-02,  2.303e-01], device='cuda:0')
s after update for 1 param tensor([1.739, 1.644, 1.776, 1.492, 1.420, 1.615, 1.813, 2.162, 1.679, 1.844,
        1.057, 1.965, 1.905, 1.405, 1.458, 2.082, 1.893, 1.727, 1.961, 1.757,
        2.043, 1.518, 1.558, 2.043, 1.221, 1.803, 1.682, 1.520, 2.276, 1.725,
        1.433, 1.286, 1.988, 1.865, 1.985, 1.818, 1.051, 1.299, 1.894, 1.599,
        2.050, 1.798, 1.652, 1.652, 1.145, 1.819, 1.784, 1.525, 1.472, 1.894,
        1.334, 1.809, 1.990, 1.394, 1.409, 1.592, 1.980, 1.511, 1.269, 1.136,
        1.562, 1.770, 1.308, 1.998, 1.519, 2.128, 1.514, 2.338, 1.528, 2.065,
        1.627, 1.838, 1.610, 1.792, 1.600, 1.094, 1.536, 1.868, 2.250, 2.153,
        1.841, 1.828, 2.015, 1.359, 1.689, 1.616, 2.216, 1.607, 1.892, 1.791,
        1.477, 0.920, 1.739, 1.896, 1.893, 1.396, 1.689, 1.885, 1.567, 1.298,
        2.049, 1.573, 1.697, 1.805, 1.752, 1.328, 1.742, 1.616, 1.546, 1.987,
        1.089, 1.518, 2.005, 2.229, 1.787, 1.756, 1.681, 2.232, 1.917, 1.571,
        1.528, 1.508, 1.717, 1.287, 2.088, 1.888, 1.405, 2.020, 1.646, 1.936,
        1.273, 2.014, 1.568, 1.892, 1.851, 1.543, 1.597, 2.238, 2.015, 1.730,
        1.868, 1.530, 1.624, 2.424, 2.095, 2.264, 1.943, 1.688, 1.366, 1.599,
        1.330, 1.238, 1.653, 1.995, 1.781, 1.912, 1.369, 1.335, 1.929, 1.764,
        1.497, 1.391, 2.074, 1.230, 1.492, 1.641, 1.351, 1.923, 1.848, 1.473,
        1.903, 1.307, 1.457, 1.098, 1.385, 2.015, 1.572, 1.566, 1.470, 1.867,
        2.112, 2.117, 1.712, 1.915, 1.795, 2.089, 1.103, 1.833, 1.639, 1.506,
        1.676, 1.711, 1.514, 1.447, 1.660, 1.365, 1.942, 1.870, 1.756, 1.120],
       device='cuda:0')
b after update for 1 param tensor([113.868, 110.734, 115.094, 105.493, 102.890, 109.750, 116.257, 126.984,
        111.908, 117.257,  88.799, 121.038, 119.200, 102.355, 104.271, 124.592,
        118.793, 113.481, 120.929, 114.463, 123.415, 106.382, 107.797, 123.422,
         95.430, 115.954, 111.996, 106.452, 130.274, 113.425, 103.362,  97.931,
        121.761, 117.929, 121.657, 116.440,  88.540,  98.416, 118.836, 109.205,
        123.627, 115.788, 110.983, 111.002,  92.413, 116.460, 115.348, 106.654,
        104.770, 118.843,  99.753, 116.148, 121.804, 101.939, 102.515, 108.938,
        121.498, 106.130,  97.272,  92.046, 107.927, 114.894,  98.759, 122.063,
        106.444, 125.967, 106.241, 132.040, 106.732, 124.075, 110.130, 117.076,
        109.573, 115.582, 109.237,  90.302, 107.033, 118.033, 129.536, 126.720,
        117.159, 116.736, 122.564, 100.665, 112.231, 109.758, 128.545, 109.470,
        118.776, 115.561, 104.945,  82.814, 113.858, 118.911, 118.811, 102.043,
        112.218, 118.568, 108.080,  98.379, 123.598, 108.319, 112.480, 116.015,
        114.309,  99.500, 113.977, 109.761, 107.373, 121.708,  90.121, 106.393,
        122.286, 128.912, 115.421, 114.415, 111.942, 129.005, 119.559, 108.219,
        106.754, 106.046, 113.154,  97.945, 124.767, 118.645, 102.342, 122.740,
        110.779, 120.155,  97.420, 122.550, 108.133, 118.772, 117.489, 107.270,
        109.128, 129.192, 122.569, 113.582, 118.010, 106.825, 110.037, 134.448,
        124.985, 129.933, 120.361, 112.186, 100.941, 109.206,  99.598,  96.098,
        111.017, 121.964, 115.251, 119.413, 101.038,  99.764, 119.940, 114.686,
        105.663, 101.840, 124.349,  95.752, 105.472, 110.613, 100.356, 119.736,
        117.400, 104.793, 119.132,  98.722, 104.241,  90.492, 101.630, 122.587,
        108.270, 108.078, 104.708, 118.000, 125.503, 125.646, 112.992, 119.487,
        115.688, 124.794,  90.673, 116.898, 110.540, 105.988, 111.805, 112.952,
        106.264, 103.878, 111.247, 100.900, 120.327, 118.072, 114.415,  91.380],
       device='cuda:0')
clipping threshold 1.1986662869034894
a after update for 1 param tensor([[[-0.221],
         [-0.176],
         [ 0.087],
         [ 0.496],
         [-0.042],
         [-0.165],
         [ 0.124],
         [-0.204],
         [ 0.050],
         [-0.166]],

        [[-0.152],
         [-0.118],
         [-0.303],
         [-0.440],
         [ 0.212],
         [-0.014],
         [-0.075],
         [ 0.105],
         [-0.023],
         [ 0.184]],

        [[-0.007],
         [-0.025],
         [ 0.044],
         [-0.422],
         [-0.149],
         [ 0.264],
         [ 0.164],
         [ 0.047],
         [ 0.113],
         [-0.218]],

        [[ 0.004],
         [-0.154],
         [-0.202],
         [-0.170],
         [-0.202],
         [-0.025],
         [-0.251],
         [-0.238],
         [-0.232],
         [-0.242]],

        [[-0.062],
         [ 0.447],
         [-0.183],
         [ 0.023],
         [ 0.094],
         [ 0.314],
         [ 0.108],
         [-0.137],
         [-0.089],
         [-0.011]],

        [[-0.059],
         [ 0.024],
         [-0.035],
         [ 0.033],
         [-0.473],
         [ 0.197],
         [-0.048],
         [ 0.213],
         [ 0.064],
         [-0.041]],

        [[-0.114],
         [ 0.069],
         [ 0.202],
         [ 0.196],
         [ 0.051],
         [ 0.299],
         [ 0.343],
         [ 0.129],
         [ 0.452],
         [-0.052]],

        [[ 0.236],
         [-0.205],
         [ 0.194],
         [ 0.223],
         [ 0.187],
         [ 0.033],
         [ 0.122],
         [ 0.069],
         [-0.011],
         [-0.220]],

        [[-0.134],
         [ 0.189],
         [-0.181],
         [-0.020],
         [ 0.068],
         [ 0.253],
         [ 0.475],
         [ 0.129],
         [ 0.049],
         [-0.331]],

        [[ 0.074],
         [-0.075],
         [ 0.083],
         [ 0.254],
         [ 0.055],
         [ 0.182],
         [ 0.012],
         [ 0.175],
         [-0.100],
         [ 0.118]],

        [[-0.198],
         [ 0.164],
         [ 0.096],
         [-0.340],
         [-0.168],
         [ 0.058],
         [ 0.241],
         [ 0.269],
         [ 0.267],
         [ 0.054]],

        [[-0.135],
         [ 0.183],
         [-0.114],
         [ 0.057],
         [-0.013],
         [ 0.225],
         [-0.524],
         [ 0.246],
         [-0.184],
         [-0.041]],

        [[-0.068],
         [ 0.058],
         [ 0.046],
         [ 0.245],
         [ 0.069],
         [-0.514],
         [-0.056],
         [-0.018],
         [ 0.376],
         [-0.087]],

        [[-0.213],
         [ 0.027],
         [ 0.002],
         [-0.359],
         [ 0.055],
         [-0.031],
         [-0.063],
         [-0.203],
         [ 0.064],
         [-0.159]],

        [[ 0.240],
         [-0.078],
         [ 0.196],
         [ 0.054],
         [ 0.364],
         [ 0.022],
         [-0.241],
         [-0.096],
         [ 0.043],
         [ 0.275]],

        [[-0.148],
         [ 0.073],
         [ 0.062],
         [ 0.001],
         [-0.279],
         [-0.432],
         [ 0.192],
         [-0.125],
         [-0.068],
         [ 0.211]],

        [[-0.187],
         [ 0.086],
         [-0.079],
         [-0.084],
         [-0.104],
         [-0.043],
         [-0.236],
         [ 0.114],
         [-0.198],
         [-0.087]],

        [[-0.061],
         [ 0.444],
         [-0.170],
         [ 0.299],
         [ 0.268],
         [ 0.036],
         [ 0.167],
         [ 0.361],
         [-0.030],
         [ 0.366]],

        [[ 0.381],
         [-0.150],
         [-0.143],
         [-0.220],
         [-0.147],
         [ 0.173],
         [ 0.209],
         [-0.206],
         [ 0.061],
         [-0.044]],

        [[-0.141],
         [-0.120],
         [ 0.001],
         [ 0.102],
         [ 0.416],
         [ 0.080],
         [-0.033],
         [ 0.110],
         [-0.136],
         [ 0.163]]], device='cuda:0')
s after update for 1 param tensor([[[1.926],
         [1.106],
         [2.017],
         [1.348],
         [1.649],
         [1.675],
         [1.706],
         [1.415],
         [1.319],
         [2.026]],

        [[1.772],
         [2.054],
         [0.642],
         [1.336],
         [1.454],
         [2.381],
         [2.024],
         [1.164],
         [1.704],
         [1.966]],

        [[1.711],
         [1.341],
         [2.117],
         [1.563],
         [1.706],
         [1.873],
         [1.575],
         [1.828],
         [1.668],
         [1.648]],

        [[1.622],
         [2.191],
         [1.758],
         [2.053],
         [1.766],
         [1.751],
         [2.394],
         [1.427],
         [2.180],
         [1.822]],

        [[2.022],
         [1.872],
         [1.560],
         [1.807],
         [1.242],
         [1.470],
         [1.698],
         [1.699],
         [1.463],
         [1.397]],

        [[1.478],
         [1.635],
         [1.962],
         [1.907],
         [2.017],
         [1.623],
         [1.531],
         [1.994],
         [2.074],
         [1.614]],

        [[2.177],
         [1.320],
         [1.182],
         [1.760],
         [1.418],
         [1.861],
         [1.745],
         [1.422],
         [2.096],
         [1.466]],

        [[1.925],
         [1.924],
         [2.010],
         [1.656],
         [1.524],
         [1.632],
         [2.027],
         [2.382],
         [1.637],
         [1.693]],

        [[1.501],
         [1.787],
         [1.843],
         [1.951],
         [1.958],
         [1.540],
         [1.638],
         [1.378],
         [1.500],
         [1.421]],

        [[1.574],
         [1.609],
         [1.217],
         [2.098],
         [1.680],
         [1.140],
         [0.748],
         [1.804],
         [1.464],
         [1.711]],

        [[1.965],
         [1.269],
         [1.981],
         [1.124],
         [1.727],
         [1.483],
         [1.632],
         [1.860],
         [1.397],
         [1.469]],

        [[1.666],
         [0.995],
         [1.379],
         [1.776],
         [0.877],
         [1.917],
         [2.071],
         [1.461],
         [1.395],
         [1.316]],

        [[1.831],
         [1.669],
         [1.209],
         [1.862],
         [2.129],
         [1.187],
         [1.546],
         [1.387],
         [1.292],
         [1.878]],

        [[1.385],
         [1.879],
         [1.882],
         [1.596],
         [1.906],
         [1.866],
         [1.541],
         [1.729],
         [1.836],
         [2.059]],

        [[1.278],
         [1.464],
         [1.561],
         [1.417],
         [1.463],
         [1.256],
         [1.612],
         [1.703],
         [2.033],
         [1.594]],

        [[1.414],
         [2.023],
         [1.357],
         [1.608],
         [1.761],
         [1.548],
         [1.888],
         [1.878],
         [1.547],
         [2.245]],

        [[1.337],
         [1.486],
         [1.743],
         [2.001],
         [2.042],
         [1.479],
         [1.970],
         [1.870],
         [2.021],
         [1.613]],

        [[1.744],
         [1.708],
         [1.758],
         [1.984],
         [1.855],
         [2.258],
         [1.600],
         [1.434],
         [1.010],
         [1.826]],

        [[1.813],
         [1.835],
         [1.844],
         [1.807],
         [1.943],
         [1.606],
         [1.973],
         [1.257],
         [1.649],
         [1.871]],

        [[1.456],
         [1.671],
         [1.336],
         [1.618],
         [1.781],
         [2.111],
         [1.967],
         [1.952],
         [1.013],
         [1.448]]], device='cuda:0')
b after update for 1 param tensor([[[119.836],
         [ 90.802],
         [122.638],
         [100.265],
         [110.879],
         [111.774],
         [112.782],
         [102.715],
         [ 99.171],
         [122.924]],

        [[114.965],
         [123.744],
         [ 69.164],
         [ 99.795],
         [104.109],
         [133.243],
         [122.843],
         [ 93.173],
         [112.719],
         [121.070]],

        [[112.949],
         [100.000],
         [125.634],
         [107.952],
         [112.789],
         [118.166],
         [108.376],
         [116.744],
         [111.530],
         [110.849]],

        [[109.977],
         [127.826],
         [114.502],
         [123.736],
         [114.751],
         [114.262],
         [133.614],
         [103.140],
         [127.492],
         [116.547]],

        [[122.790],
         [118.157],
         [107.850],
         [116.075],
         [ 96.230],
         [104.691],
         [112.534],
         [112.572],
         [104.456],
         [102.081]],

        [[104.963],
         [110.405],
         [120.950],
         [119.242],
         [122.640],
         [110.005],
         [106.849],
         [121.938],
         [124.371],
         [109.693]],

        [[127.416],
         [ 99.212],
         [ 93.900],
         [114.557],
         [102.814],
         [117.804],
         [114.065],
         [102.989],
         [125.004],
         [104.541]],

        [[119.803],
         [119.792],
         [122.438],
         [111.124],
         [106.618],
         [110.319],
         [122.945],
         [133.282],
         [110.500],
         [112.373]],

        [[105.800],
         [115.446],
         [117.232],
         [120.620],
         [120.819],
         [107.172],
         [110.533],
         [101.358],
         [105.769],
         [102.931]],

        [[108.325],
         [109.518],
         [ 95.263],
         [125.072],
         [111.941],
         [ 92.189],
         [ 74.662],
         [115.993],
         [104.485],
         [112.964]],

        [[121.058],
         [ 97.259],
         [121.531],
         [ 91.554],
         [113.487],
         [105.155],
         [110.302],
         [117.770],
         [102.056],
         [104.671]],

        [[111.463],
         [ 86.146],
         [101.392],
         [115.094],
         [ 80.875],
         [119.564],
         [124.266],
         [104.370],
         [101.993],
         [ 99.051]],

        [[116.842],
         [111.545],
         [ 94.938],
         [117.826],
         [125.989],
         [ 94.073],
         [107.360],
         [101.711],
         [ 98.155],
         [118.322]],

        [[101.610],
         [118.357],
         [118.464],
         [109.081],
         [119.221],
         [117.965],
         [107.198],
         [113.551],
         [117.006],
         [123.915]],

        [[ 97.619],
         [104.469],
         [107.879],
         [102.781],
         [104.430],
         [ 96.774],
         [109.652],
         [112.679],
         [123.129],
         [109.011]],

        [[102.675],
         [122.822],
         [100.593],
         [109.500],
         [114.580],
         [107.432],
         [118.655],
         [118.351],
         [107.390],
         [129.378]],

        [[ 99.831],
         [105.260],
         [114.016],
         [122.138],
         [123.390],
         [105.029],
         [121.200],
         [118.085],
         [122.769],
         [109.682]],

        [[114.034],
         [112.869],
         [114.486],
         [121.620],
         [117.614],
         [129.752],
         [109.243],
         [103.403],
         [ 86.799],
         [116.692]],

        [[116.266],
         [116.970],
         [117.259],
         [116.076],
         [120.364],
         [109.439],
         [121.283],
         [ 96.806],
         [110.896],
         [118.116]],

        [[104.206],
         [111.623],
         [ 99.798],
         [109.858],
         [115.254],
         [125.474],
         [121.109],
         [120.638],
         [ 86.903],
         [103.904]]], device='cuda:0')
clipping threshold 1.1986662869034894
a after update for 1 param tensor([[ 0.169],
        [-0.183],
        [ 0.063],
        [-0.134],
        [ 0.037],
        [-0.176],
        [ 0.163],
        [ 0.014],
        [-0.010],
        [ 0.028],
        [ 0.080],
        [ 0.200],
        [ 0.085],
        [-0.020],
        [-0.193],
        [-0.110],
        [-0.333],
        [-0.054],
        [-0.384],
        [-0.038]], device='cuda:0')
s after update for 1 param tensor([[1.708],
        [1.849],
        [1.714],
        [1.507],
        [0.943],
        [1.509],
        [1.871],
        [1.122],
        [1.654],
        [1.613],
        [0.887],
        [1.860],
        [2.346],
        [1.522],
        [1.405],
        [1.820],
        [1.410],
        [1.985],
        [1.989],
        [1.917]], device='cuda:0')
b after update for 1 param tensor([[112.868],
        [117.431],
        [113.054],
        [105.995],
        [ 83.844],
        [106.075],
        [118.119],
        [ 91.461],
        [111.057],
        [109.684],
        [ 81.345],
        [117.782],
        [132.252],
        [106.534],
        [102.367],
        [116.510],
        [102.521],
        [121.662],
        [121.772],
        [119.572]], device='cuda:0')
clipping threshold 1.1986662869034894
||w||^2 3.152290888738716
exp ma of ||w||^2 2.377731603877754
||w|| 1.7754692024191003
exp ma of ||w|| 1.4828475244090034
||w||^2 4.914799924767488
exp ma of ||w||^2 2.374444382532436
||w|| 2.2169348039054935
exp ma of ||w|| 1.474269988170101
||w||^2 1.4430105603090186
exp ma of ||w||^2 2.3885113432092027
||w|| 1.2012537451800176
exp ma of ||w|| 1.4851590580559928
||w||^2 0.6989913954763531
exp ma of ||w||^2 2.0339372876765665
||w|| 0.8360570527639565
exp ma of ||w|| 1.3775271905237017
||w||^2 4.054722355749789
exp ma of ||w||^2 2.291043137376966
||w|| 2.013634116653219
exp ma of ||w|| 1.4588169901212602
||w||^2 1.5547492348434206
exp ma of ||w||^2 2.4087686081206816
||w|| 1.2468958396126841
exp ma of ||w|| 1.4909420299807643
||w||^2 1.0422690270964792
exp ma of ||w||^2 2.3311190699571007
||w|| 1.0209157786499723
exp ma of ||w|| 1.4695092271753247
cuda
Objective function 39.15 = squared loss an data 27.17 + 0.5*rho*h**2 5.673398 + alpha*h 4.362460 + L2reg 1.69 + L1reg 0.25 ; SHD = 92 ; DAG False
Proportion of microbatches that were clipped  0.7740458015267175
iteration 2 in inner loop, alpha 4.095386211587446 rho 10.0 h 1.0652134439872754
4420
cuda
Objective function 90.21 = squared loss an data 27.17 + 0.5*rho*h**2 56.733984 + alpha*h 4.362460 + L2reg 1.69 + L1reg 0.25 ; SHD = 92 ; DAG False
||w||^2 100003168.82995698
exp ma of ||w||^2 8552400256.361125
||w|| 10000.158440242683
exp ma of ||w|| 37761.853087221694
||w||^2 4.270338167842377
exp ma of ||w||^2 54.04203256595026
||w|| 2.0664796558017158
exp ma of ||w|| 2.0057885395321757
||w||^2 2.2807192880846805
exp ma of ||w||^2 3.539622536990265
||w|| 1.5102050483575666
exp ma of ||w|| 1.8057882499346976
||w||^2 9.146069214348426
exp ma of ||w||^2 3.464651007760723
||w|| 3.024246883828836
exp ma of ||w|| 1.792299377001233
||w||^2 3.46859214849722
exp ma of ||w||^2 3.3071396972966625
||w|| 1.8624156755400283
exp ma of ||w|| 1.7433866380915926
||w||^2 2.2703139191855763
exp ma of ||w||^2 3.2104394845508293
||w|| 1.506756091471203
exp ma of ||w|| 1.7429400944197684
||w||^2 5.031935000811532
exp ma of ||w||^2 3.3547770190687936
||w|| 2.2431974948299875
exp ma of ||w|| 1.7755691072838988
||w||^2 1.6958670139880012
exp ma of ||w||^2 3.1991169420307455
||w|| 1.3022545887759434
exp ma of ||w|| 1.7262335057807285
cuda
Objective function 41.60 = squared loss an data 29.79 + 0.5*rho*h**2 8.060554 + alpha*h 1.644343 + L2reg 1.88 + L1reg 0.23 ; SHD = 90 ; DAG True
Proportion of microbatches that were clipped  0.7763350105502353
iteration 3 in inner loop, alpha 4.095386211587446 rho 100.0 h 0.4015110016661012
iteration 2 in outer loop, alpha = 44.24648637819757, rho = 100.0, h = 0.4015110016661012
cuda
4420
cuda
Objective function 57.72 = squared loss an data 29.79 + 0.5*rho*h**2 8.060554 + alpha*h 17.765451 + L2reg 1.88 + L1reg 0.23 ; SHD = 90 ; DAG True
||w||^2 4251520536.860905
exp ma of ||w||^2 77240889806.37352
||w|| 65203.68499449173
exp ma of ||w|| 196824.4645617636
||w||^2 34607.23609041906
exp ma of ||w||^2 791018934.6317801
||w|| 186.03020209207713
exp ma of ||w|| 4276.775345674887
||w||^2 2.2693219141992036
exp ma of ||w||^2 1222588.1002978135
||w|| 1.5064268698477215
exp ma of ||w|| 10.361612718734898
||w||^2 7.970543999202938
exp ma of ||w||^2 69716.76260548978
||w|| 2.8232151882566336
exp ma of ||w|| 2.544662442279885
||w||^2 1.001268187081778
exp ma of ||w||^2 3.4807462773548323
||w|| 1.0006338926309553
exp ma of ||w|| 1.7811504245711107
||w||^2 6.164868778159913
exp ma of ||w||^2 3.4292800078694206
||w|| 2.482915378775506
exp ma of ||w|| 1.797629057788144
||w||^2 1.445436669847564
exp ma of ||w||^2 3.270371921797288
||w|| 1.202263145009263
exp ma of ||w|| 1.7565540218693763
||w||^2 1.552590808042683
exp ma of ||w||^2 2.9644847802318837
||w|| 1.2460300189171538
exp ma of ||w|| 1.6718939090875256
||w||^2 4.7844744178671
exp ma of ||w||^2 3.1761972140465495
||w|| 2.1873441471033086
exp ma of ||w|| 1.7287731982261159
||w||^2 0.7708193839632179
exp ma of ||w||^2 3.0584805491710068
||w|| 0.8779632019414128
exp ma of ||w|| 1.6967139243317373
||w||^2 5.518589276799313
exp ma of ||w||^2 3.2783684409431233
||w|| 2.349167783875667
exp ma of ||w|| 1.754574141395208
||w||^2 3.3706007661585238
exp ma of ||w||^2 3.2813080501971426
||w|| 1.8359195968665196
exp ma of ||w|| 1.7699574269636216
||w||^2 5.649348211503112
exp ma of ||w||^2 3.3025429825700963
||w|| 2.3768357561058173
exp ma of ||w|| 1.7630379411889026
||w||^2 2.793250205836471
exp ma of ||w||^2 3.1965352640220406
||w|| 1.671301949330662
exp ma of ||w|| 1.7223983090610226
||w||^2 2.5766288403894313
exp ma of ||w||^2 2.956055480143779
||w|| 1.6051881012483962
exp ma of ||w|| 1.654096376159033
cuda
Objective function 44.52 = squared loss an data 28.37 + 0.5*rho*h**2 3.010610 + alpha*h 10.857280 + L2reg 2.05 + L1reg 0.23 ; SHD = 84 ; DAG True
Proportion of microbatches that were clipped  0.774073474672277
iteration 1 in inner loop, alpha 44.24648637819757 rho 100.0 h 0.2453817381043244
4420
cuda
Objective function 71.61 = squared loss an data 28.37 + 0.5*rho*h**2 30.106099 + alpha*h 10.857280 + L2reg 2.05 + L1reg 0.23 ; SHD = 84 ; DAG True
||w||^2 10.403417145141026
exp ma of ||w||^2 1390562.419387281
||w|| 3.2254328616700465
exp ma of ||w|| 10.155765934636111
||w||^2 3.5841592003423908
exp ma of ||w||^2 12734.896323732648
||w|| 1.8931875766395656
exp ma of ||w|| 2.251328789547753
||w||^2 1.828418121295377
exp ma of ||w||^2 3.615200085580496
||w|| 1.3521901202476585
exp ma of ||w|| 1.8461875198715425
||w||^2 2.10313347887489
exp ma of ||w||^2 3.9604232773926853
||w|| 1.4502184245398657
exp ma of ||w|| 1.9283989940876654
||w||^2 3.5542336390757874
exp ma of ||w||^2 3.6434194530000177
||w|| 1.885267524537509
exp ma of ||w|| 1.872661773959384
||w||^2 2.0450515590005427
exp ma of ||w||^2 3.5780262099071063
||w|| 1.430052991675673
exp ma of ||w|| 1.8447574258169679
cuda
Objective function 42.93 = squared loss an data 28.96 + 0.5*rho*h**2 6.464029 + alpha*h 5.030897 + L2reg 2.25 + L1reg 0.23 ; SHD = 82 ; DAG True
Proportion of microbatches that were clipped  0.7798457011055436
iteration 2 in inner loop, alpha 44.24648637819757 rho 1000.0 h 0.11370161585079686
4420
cuda
Objective function 101.10 = squared loss an data 28.96 + 0.5*rho*h**2 64.640287 + alpha*h 5.030897 + L2reg 2.25 + L1reg 0.23 ; SHD = 82 ; DAG True
||w||^2 3288203408077.8755
exp ma of ||w||^2 2697920038242.4053
||w|| 1813340.4004978975
exp ma of ||w|| 1038587.7897124431
||w||^2 3489208870.576835
exp ma of ||w||^2 306156789552.1569
||w|| 59069.525735160896
exp ma of ||w|| 284297.5077808193
||w||^2 1952.7744846055045
exp ma of ||w||^2 1081345835.4099839
||w|| 44.19020801722373
exp ma of ||w|| 1811.0308621026395
||w||^2 5.822905113611444
exp ma of ||w||^2 305767.1270118008
||w|| 2.413069645412549
exp ma of ||w|| 3.294616271455728
||w||^2 2.888282507294612
exp ma of ||w||^2 4.316104396076863
||w|| 1.6994947800139346
exp ma of ||w|| 1.9837594030713621
||w||^2 2.8147200293047128
exp ma of ||w||^2 4.064329134961287
||w|| 1.6777127374210141
exp ma of ||w|| 1.957990607936177
||w||^2 4.620098208717693
exp ma of ||w||^2 4.109234115491949
||w|| 2.1494413713143454
exp ma of ||w|| 1.9755388101767817
||w||^2 5.550944350524259
exp ma of ||w||^2 3.8284683185127455
||w|| 2.3560442165893787
exp ma of ||w|| 1.91898375711563
||w||^2 3.1582429417944926
exp ma of ||w||^2 3.7351450772756762
||w|| 1.777144603512751
exp ma of ||w|| 1.8933112540928778
||w||^2 2.5565889842292817
exp ma of ||w||^2 3.970173179292671
||w|| 1.598933702262005
exp ma of ||w|| 1.9402906447675523
||w||^2 2.3678135639759557
exp ma of ||w||^2 3.9046198703323634
||w|| 1.5387701465702912
exp ma of ||w|| 1.9208720405805941
||w||^2 5.076668215120235
exp ma of ||w||^2 3.753804062831074
||w|| 2.2531462924364756
exp ma of ||w|| 1.8968387121606927
cuda
Objective function 39.02 = squared loss an data 27.98 + 0.5*rho*h**2 6.777838 + alpha*h 1.629069 + L2reg 2.41 + L1reg 0.23 ; SHD = 84 ; DAG True
Proportion of microbatches that were clipped  0.7794082462716325
iteration 3 in inner loop, alpha 44.24648637819757 rho 10000.0 h 0.03681803329899935
iteration 3 in outer loop, alpha = 412.4268193681911, rho = 10000.0, h = 0.03681803329899935
cuda
4420
cuda
Objective function 52.58 = squared loss an data 27.98 + 0.5*rho*h**2 6.777838 + alpha*h 15.184744 + L2reg 2.41 + L1reg 0.23 ; SHD = 84 ; DAG True
||w||^2 6.820272493091828
exp ma of ||w||^2 235523.13611942015
||w|| 2.611565142417824
exp ma of ||w|| 3.0139261318539505
||w||^2 6.82166675218735
exp ma of ||w||^2 1477.2182542590488
||w|| 2.61183206814438
exp ma of ||w|| 2.3383820619600066
||w||^2 4.043104655706585
exp ma of ||w||^2 8.597895264249644
||w|| 2.0107472878774657
exp ma of ||w|| 2.078016838919146
||w||^2 5.829273221724537
exp ma of ||w||^2 3.834393164355115
||w|| 2.4143887884358097
exp ma of ||w|| 1.9193832324267097
||w||^2 2.5086115440587258
exp ma of ||w||^2 3.572612259355435
||w|| 1.5838596983504334
exp ma of ||w|| 1.8554802705309597
||w||^2 3.7506079577966154
exp ma of ||w||^2 4.152997558294929
||w|| 1.9366486407700845
exp ma of ||w|| 2.0062387427177604
||w||^2 2.24121547797778
exp ma of ||w||^2 4.0345619250870115
||w|| 1.4970689623319895
exp ma of ||w|| 1.973336655056102
||w||^2 1.9660124525881326
exp ma of ||w||^2 3.767169763823476
||w|| 1.4021456602607778
exp ma of ||w|| 1.908060646340062
||w||^2 3.045144894221187
exp ma of ||w||^2 3.8829611988426653
||w|| 1.7450343533068875
exp ma of ||w|| 1.9352498127856448
||w||^2 3.629445488001082
exp ma of ||w||^2 3.6900050938838573
||w|| 1.9051103611080074
exp ma of ||w|| 1.8851485221286006
||w||^2 2.4394483782099927
exp ma of ||w||^2 3.8460423694301875
||w|| 1.5618733553684796
exp ma of ||w|| 1.929148844264182
||w||^2 1.9239603154406082
exp ma of ||w||^2 3.8995677782480227
||w|| 1.3870689656396356
exp ma of ||w|| 1.9396246797312986
cuda
Objective function 43.05 = squared loss an data 26.85 + 0.5*rho*h**2 3.124780 + alpha*h 10.310307 + L2reg 2.54 + L1reg 0.23 ; SHD = 80 ; DAG True
Proportion of microbatches that were clipped  0.7785828025477707
iteration 1 in inner loop, alpha 412.4268193681911 rho 10000.0 h 0.024999119180577623
4420
cuda
Objective function 71.17 = squared loss an data 26.85 + 0.5*rho*h**2 31.247798 + alpha*h 10.310307 + L2reg 2.54 + L1reg 0.23 ; SHD = 80 ; DAG True
||w||^2 134.04946701234707
exp ma of ||w||^2 10196806295.89114
||w|| 11.57797335514066
exp ma of ||w|| 745.4536704657652
||w||^2 14.016855867807102
exp ma of ||w||^2 24865.820241239697
||w|| 3.74390916927843
exp ma of ||w|| 3.96508489919491
||w||^2 8.768787068984707
exp ma of ||w||^2 292.2449689301282
||w|| 2.9612137830600322
exp ma of ||w|| 2.8830741793951
||w||^2 2.261998539327048
exp ma of ||w||^2 4.222171237228835
||w|| 1.5039941952438007
exp ma of ||w|| 2.005577729991489
||w||^2 5.757918752424001
exp ma of ||w||^2 3.843693695527075
||w|| 2.3995663675806096
exp ma of ||w|| 1.9235693394442237
||w||^2 3.172974165782768
exp ma of ||w||^2 3.951309495323752
||w|| 1.7812844146241127
exp ma of ||w|| 1.9465597359986055
||w||^2 2.696051179426764
exp ma of ||w||^2 4.043989310863909
||w|| 1.6419656450202496
exp ma of ||w|| 1.9755582292931635
||w||^2 6.678029201164414
exp ma of ||w||^2 4.155725330811138
||w|| 2.584188306057516
exp ma of ||w|| 1.9976767834213403
||w||^2 3.2425496827828617
exp ma of ||w||^2 4.433181652697113
||w|| 1.8007081059357903
exp ma of ||w|| 2.075939359744395
||w||^2 2.985711094197995
exp ma of ||w||^2 4.059914624124217
||w|| 1.7279210323964447
exp ma of ||w|| 1.9851151649865568
||w||^2 5.188230936926276
exp ma of ||w||^2 4.568605315626768
||w|| 2.2777688506356997
exp ma of ||w|| 2.1102661360521453
cuda
Objective function 39.33 = squared loss an data 25.99 + 0.5*rho*h**2 5.950251 + alpha*h 4.499140 + L2reg 2.67 + L1reg 0.22 ; SHD = 73 ; DAG True
Proportion of microbatches that were clipped  0.7818956507757858
iteration 2 in inner loop, alpha 412.4268193681911 rho 100000.0 h 0.010908942272610744
iteration 4 in outer loop, alpha = 11321.369091978935, rho = 1000000.0, h = 0.010908942272610744
Threshold 0.3
[[0.007 0.138 0.008 0.188 0.062 0.11  0.066 0.009 0.248 0.063 0.152 0.052
  0.046 0.086 0.488 0.264 0.068 0.015 0.419 0.044]
 [0.053 0.006 0.015 0.112 0.034 0.209 0.118 0.008 1.039 0.198 0.066 0.049
  0.058 0.052 0.543 0.577 0.011 0.003 0.213 0.012]
 [0.817 0.377 0.008 0.547 0.289 0.761 0.797 0.097 1.374 1.125 0.176 0.553
  0.796 0.592 0.674 0.658 0.224 0.056 3.025 0.748]
 [0.021 0.066 0.011 0.008 0.008 0.081 0.067 0.012 0.131 0.493 0.052 0.039
  0.041 0.067 0.236 0.182 0.053 0.009 0.101 0.005]
 [0.139 0.114 0.036 0.841 0.008 0.326 0.164 0.011 1.204 0.441 0.543 0.284
  0.122 0.145 0.214 0.281 0.148 0.02  0.288 0.221]
 [0.079 0.033 0.011 0.057 0.026 0.007 0.094 0.014 0.202 0.214 0.036 0.021
  0.042 0.085 0.122 0.099 0.027 0.006 0.499 0.02 ]
 [0.083 0.057 0.011 0.086 0.038 0.05  0.006 0.002 0.209 0.092 0.062 0.067
  0.011 0.048 0.108 0.538 0.056 0.009 0.17  0.018]
 [0.64  0.771 0.054 0.589 0.462 0.476 3.588 0.008 0.989 0.721 0.802 0.19
  0.18  0.525 1.362 1.02  0.456 0.153 0.711 0.243]
 [0.039 0.003 0.004 0.043 0.005 0.031 0.039 0.004 0.005 0.127 0.02  0.011
  0.01  0.02  0.068 0.05  0.011 0.002 0.096 0.007]
 [0.062 0.02  0.006 0.013 0.015 0.035 0.055 0.01  0.057 0.008 0.023 0.012
  0.005 0.054 0.098 0.081 0.03  0.007 0.109 0.008]
 [0.046 0.108 0.031 0.162 0.011 0.194 0.103 0.014 0.413 0.176 0.006 0.045
  0.024 0.108 0.136 0.086 0.091 0.01  0.112 0.029]
 [0.138 0.139 0.016 0.213 0.017 0.376 0.12  0.026 0.598 0.688 0.172 0.005
  0.163 0.285 0.321 0.253 0.21  0.023 0.49  0.083]
 [0.144 0.069 0.007 0.127 0.06  0.165 0.389 0.03  0.478 1.226 0.364 0.045
  0.004 0.23  0.282 0.39  0.114 0.008 0.302 0.144]
 [0.124 0.123 0.009 0.105 0.03  0.094 0.15  0.012 0.326 0.106 0.091 0.035
  0.041 0.006 0.126 0.263 0.076 0.009 0.693 0.025]
 [0.018 0.014 0.009 0.029 0.018 0.068 0.064 0.003 0.115 0.072 0.047 0.028
  0.027 0.047 0.008 0.195 0.011 0.003 0.094 0.018]
 [0.018 0.012 0.009 0.033 0.019 0.07  0.014 0.003 0.169 0.093 0.056 0.019
  0.016 0.028 0.037 0.013 0.012 0.005 0.075 0.004]
 [0.114 0.561 0.029 0.126 0.028 0.248 0.124 0.015 0.34  0.236 0.067 0.06
  0.07  0.088 0.726 0.332 0.009 0.003 0.426 0.075]
 [0.434 1.922 0.153 0.461 0.347 0.826 0.546 0.048 1.215 0.704 0.586 0.317
  0.617 0.641 0.794 0.824 2.625 0.007 0.875 0.353]
 [0.019 0.029 0.001 0.052 0.015 0.011 0.042 0.007 0.064 0.058 0.058 0.014
  0.022 0.012 0.076 0.151 0.016 0.004 0.007 0.023]
 [0.135 0.479 0.004 1.145 0.033 0.326 0.332 0.049 0.554 0.558 0.248 0.095
  0.07  0.347 0.376 0.578 0.075 0.022 0.227 0.004]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.488 0.    0.    0.    0.419 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    1.039 0.    0.    0.
  0.    0.    0.543 0.577 0.    0.    0.    0.   ]
 [0.817 0.377 0.    0.547 0.    0.761 0.797 0.    1.374 1.125 0.    0.553
  0.796 0.592 0.674 0.658 0.    0.    3.025 0.748]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.493 0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.841 0.    0.326 0.    0.    1.204 0.441 0.543 0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.499 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.538 0.    0.    0.    0.   ]
 [0.64  0.771 0.    0.589 0.462 0.476 3.588 0.    0.989 0.721 0.802 0.
  0.    0.525 1.362 1.02  0.456 0.    0.711 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.413 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.376 0.    0.    0.598 0.688 0.    0.
  0.    0.    0.321 0.    0.    0.    0.49  0.   ]
 [0.    0.    0.    0.    0.    0.    0.389 0.    0.478 1.226 0.364 0.
  0.    0.    0.    0.39  0.    0.    0.302 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.326 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.693 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.561 0.    0.    0.    0.    0.    0.    0.34  0.    0.    0.
  0.    0.    0.726 0.332 0.    0.    0.426 0.   ]
 [0.434 1.922 0.    0.461 0.347 0.826 0.546 0.    1.215 0.704 0.586 0.317
  0.617 0.641 0.794 0.824 2.625 0.    0.875 0.353]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.   ]
 [0.    0.479 0.    1.145 0.    0.326 0.332 0.    0.554 0.558 0.    0.
  0.    0.347 0.376 0.578 0.    0.    0.    0.   ]]
{'fdr': 0.7093023255813954, 'tpr': 0.625, 'fpr': 0.4066666666666667, 'f1': 0.3968253968253968, 'shd': 73, 'npred': 86, 'ntrue': 40}
[1.378e-01 8.461e-03 1.885e-01 6.193e-02 1.102e-01 6.629e-02 8.885e-03
 2.480e-01 6.324e-02 1.516e-01 5.172e-02 4.586e-02 8.597e-02 4.877e-01
 2.639e-01 6.848e-02 1.512e-02 4.187e-01 4.373e-02 5.336e-02 1.487e-02
 1.122e-01 3.416e-02 2.085e-01 1.176e-01 8.472e-03 1.039e+00 1.983e-01
 6.614e-02 4.856e-02 5.762e-02 5.229e-02 5.428e-01 5.766e-01 1.137e-02
 3.454e-03 2.126e-01 1.235e-02 8.168e-01 3.773e-01 5.471e-01 2.893e-01
 7.610e-01 7.971e-01 9.685e-02 1.374e+00 1.125e+00 1.760e-01 5.531e-01
 7.961e-01 5.920e-01 6.743e-01 6.577e-01 2.238e-01 5.578e-02 3.025e+00
 7.482e-01 2.071e-02 6.609e-02 1.083e-02 7.815e-03 8.073e-02 6.695e-02
 1.230e-02 1.314e-01 4.929e-01 5.204e-02 3.906e-02 4.129e-02 6.699e-02
 2.360e-01 1.817e-01 5.291e-02 8.550e-03 1.013e-01 4.817e-03 1.394e-01
 1.137e-01 3.612e-02 8.411e-01 3.261e-01 1.636e-01 1.077e-02 1.204e+00
 4.405e-01 5.426e-01 2.841e-01 1.216e-01 1.449e-01 2.140e-01 2.813e-01
 1.480e-01 2.005e-02 2.881e-01 2.207e-01 7.925e-02 3.342e-02 1.137e-02
 5.729e-02 2.553e-02 9.387e-02 1.415e-02 2.025e-01 2.139e-01 3.610e-02
 2.109e-02 4.158e-02 8.520e-02 1.217e-01 9.911e-02 2.747e-02 6.119e-03
 4.988e-01 1.983e-02 8.317e-02 5.714e-02 1.115e-02 8.620e-02 3.792e-02
 5.043e-02 2.027e-03 2.086e-01 9.199e-02 6.188e-02 6.696e-02 1.051e-02
 4.848e-02 1.077e-01 5.380e-01 5.575e-02 9.354e-03 1.704e-01 1.812e-02
 6.404e-01 7.709e-01 5.441e-02 5.888e-01 4.622e-01 4.759e-01 3.588e+00
 9.886e-01 7.211e-01 8.016e-01 1.902e-01 1.802e-01 5.252e-01 1.362e+00
 1.020e+00 4.560e-01 1.527e-01 7.113e-01 2.427e-01 3.897e-02 3.329e-03
 4.144e-03 4.338e-02 5.156e-03 3.134e-02 3.854e-02 3.616e-03 1.265e-01
 1.973e-02 1.103e-02 1.027e-02 2.002e-02 6.836e-02 4.982e-02 1.088e-02
 2.127e-03 9.641e-02 6.529e-03 6.233e-02 2.044e-02 5.813e-03 1.260e-02
 1.475e-02 3.521e-02 5.481e-02 9.539e-03 5.701e-02 2.295e-02 1.198e-02
 4.968e-03 5.426e-02 9.765e-02 8.143e-02 2.958e-02 6.690e-03 1.089e-01
 7.500e-03 4.623e-02 1.081e-01 3.058e-02 1.615e-01 1.115e-02 1.944e-01
 1.030e-01 1.442e-02 4.134e-01 1.760e-01 4.467e-02 2.357e-02 1.080e-01
 1.359e-01 8.562e-02 9.125e-02 9.773e-03 1.124e-01 2.891e-02 1.383e-01
 1.386e-01 1.599e-02 2.133e-01 1.730e-02 3.765e-01 1.200e-01 2.564e-02
 5.978e-01 6.880e-01 1.721e-01 1.632e-01 2.849e-01 3.214e-01 2.533e-01
 2.105e-01 2.346e-02 4.897e-01 8.269e-02 1.445e-01 6.895e-02 7.016e-03
 1.273e-01 5.984e-02 1.653e-01 3.891e-01 2.985e-02 4.776e-01 1.226e+00
 3.637e-01 4.526e-02 2.304e-01 2.821e-01 3.904e-01 1.138e-01 8.270e-03
 3.020e-01 1.436e-01 1.237e-01 1.228e-01 9.495e-03 1.047e-01 3.033e-02
 9.366e-02 1.500e-01 1.210e-02 3.256e-01 1.056e-01 9.126e-02 3.465e-02
 4.059e-02 1.259e-01 2.626e-01 7.607e-02 9.320e-03 6.935e-01 2.478e-02
 1.797e-02 1.384e-02 9.414e-03 2.925e-02 1.827e-02 6.795e-02 6.442e-02
 2.902e-03 1.148e-01 7.239e-02 4.696e-02 2.756e-02 2.664e-02 4.733e-02
 1.949e-01 1.106e-02 3.219e-03 9.377e-02 1.756e-02 1.812e-02 1.220e-02
 8.730e-03 3.321e-02 1.940e-02 7.035e-02 1.391e-02 3.497e-03 1.691e-01
 9.307e-02 5.561e-02 1.887e-02 1.583e-02 2.768e-02 3.669e-02 1.172e-02
 5.042e-03 7.460e-02 4.418e-03 1.143e-01 5.612e-01 2.859e-02 1.263e-01
 2.845e-02 2.479e-01 1.245e-01 1.526e-02 3.402e-01 2.363e-01 6.679e-02
 6.033e-02 6.954e-02 8.804e-02 7.264e-01 3.317e-01 2.922e-03 4.263e-01
 7.489e-02 4.339e-01 1.922e+00 1.529e-01 4.610e-01 3.475e-01 8.264e-01
 5.461e-01 4.809e-02 1.215e+00 7.041e-01 5.861e-01 3.172e-01 6.172e-01
 6.412e-01 7.938e-01 8.235e-01 2.625e+00 8.753e-01 3.526e-01 1.902e-02
 2.866e-02 1.491e-03 5.216e-02 1.535e-02 1.066e-02 4.230e-02 7.343e-03
 6.413e-02 5.758e-02 5.782e-02 1.395e-02 2.212e-02 1.185e-02 7.621e-02
 1.508e-01 1.569e-02 4.122e-03 2.302e-02 1.346e-01 4.787e-01 4.200e-03
 1.145e+00 3.272e-02 3.260e-01 3.320e-01 4.864e-02 5.538e-01 5.575e-01
 2.478e-01 9.539e-02 6.969e-02 3.475e-01 3.760e-01 5.775e-01 7.512e-02
 2.191e-02 2.274e-01]
[[0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]
 [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.7913970588235294, 0.47497243206552847)
Iterations 2250
Achieves (5.825547298234785, 1e-05)-DP
