samples  5000  graph  15 30 ER mlp  minibatch size  75  noise  0.5  minibatches per NN training  56 adaclip_and_quantile
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 1.3401316691164595
iteration 1 in outer loop, alpha = 1.3401316691164595, rho = 1.0, h = 1.3401316691164595
cuda
iteration 1 in inner loop,alpha 1.3401316691164595 rho 1.0 h 0.8741315174292428
iteration 2 in inner loop,alpha 1.3401316691164595 rho 10.0 h 0.38347274229216843
iteration 3 in inner loop,alpha 1.3401316691164595 rho 100.0 h 0.13357487921889089
iteration 2 in outer loop, alpha = 14.697619591005548, rho = 100.0, h = 0.13357487921889089
cuda
iteration 1 in inner loop,alpha 14.697619591005548 rho 100.0 h 0.06991993740608571
iteration 2 in inner loop,alpha 14.697619591005548 rho 1000.0 h 0.02592698775515956
iteration 3 in outer loop, alpha = 40.62460734616511, rho = 1000.0, h = 0.02592698775515956
cuda
iteration 1 in inner loop,alpha 40.62460734616511 rho 1000.0 h 0.016465661543334065
iteration 2 in inner loop,alpha 40.62460734616511 rho 10000.0 h 0.006716475932055488
iteration 3 in inner loop,alpha 40.62460734616511 rho 100000.0 h 0.0012731165115322796
iteration 4 in outer loop, alpha = 167.93625849939306, rho = 100000.0, h = 0.0012731165115322796
cuda
iteration 1 in inner loop,alpha 167.93625849939306 rho 100000.0 h 0.00023061801773138768
iteration 5 in outer loop, alpha = 190.99806027253183, rho = 100000.0, h = 0.00023061801773138768
cuda
iteration 1 in inner loop,alpha 190.99806027253183 rho 100000.0 h 0.00012505071059898398
iteration 6 in outer loop, alpha = 316.0487708715158, rho = 1000000.0, h = 0.00012505071059898398
Threshold 0.3
[[0.002 0.    0.    0.004 0.209 0.    0.    0.    0.    2.757 0.252 0.
  0.    0.    0.005]
 [2.527 0.001 0.003 0.264 0.206 0.01  0.011 0.003 0.002 2.204 0.234 1.38
  0.    0.001 0.097]
 [0.028 0.07  0.    0.147 0.157 0.033 0.14  0.003 0.072 0.128 0.174 0.153
  0.006 0.002 0.005]
 [0.162 0.    0.001 0.001 0.193 0.    0.    0.    0.    0.22  0.378 0.001
  0.001 0.    1.023]
 [0.    0.    0.    0.    0.004 0.    0.    0.    0.    0.    0.001 0.
  0.    0.    0.001]
 [2.649 0.03  0.001 0.972 0.366 0.001 1.406 0.    0.05  1.759 1.399 1.504
  0.013 0.001 1.924]
 [0.421 0.042 0.    0.343 0.402 0.    0.001 0.    0.056 0.148 1.808 0.095
  0.004 0.001 0.167]
 [2.69  0.005 0.005 2.092 0.134 0.611 0.05  0.    0.004 0.316 0.174 0.063
  0.021 0.022 0.118]
 [0.107 0.381 0.002 0.648 0.415 0.002 0.003 0.002 0.003 2.341 2.235 1.075
  0.    0.    0.371]
 [0.    0.    0.    0.    2.814 0.    0.    0.    0.    0.002 0.33  0.
  0.    0.    0.001]
 [0.    0.    0.    0.001 3.134 0.    0.    0.    0.001 0.002 0.008 0.
  0.    0.    0.002]
 [0.375 0.    0.001 0.18  0.147 0.    0.003 0.    0.001 0.424 0.436 0.001
  0.    0.    0.034]
 [0.04  0.076 0.004 0.101 3.079 0.014 0.003 0.003 1.258 0.107 2.046 0.034
  0.001 0.017 0.014]
 [0.128 1.463 0.006 1.128 1.242 0.005 0.009 0.002 3.522 0.377 0.481 0.156
  0.011 0.002 0.562]
 [0.099 0.001 0.    0.    0.103 0.    0.    0.    0.    0.111 0.154 0.002
  0.    0.    0.001]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    2.757 0.    0.
  0.    0.    0.   ]
 [2.527 0.    0.    0.    0.    0.    0.    0.    0.    2.204 0.    1.38
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.378 0.
  0.    0.    1.023]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [2.649 0.    0.    0.972 0.366 0.    1.406 0.    0.    1.759 1.399 1.504
  0.    0.    1.924]
 [0.421 0.    0.    0.343 0.402 0.    0.    0.    0.    0.    1.808 0.
  0.    0.    0.   ]
 [2.69  0.    0.    2.092 0.    0.611 0.    0.    0.    0.316 0.    0.
  0.    0.    0.   ]
 [0.    0.381 0.    0.648 0.415 0.    0.    0.    0.    2.341 2.235 1.075
  0.    0.    0.371]
 [0.    0.    0.    0.    2.814 0.    0.    0.    0.    0.    0.33  0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    3.134 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.375 0.    0.    0.    0.    0.    0.    0.    0.    0.424 0.436 0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    3.079 0.    0.    0.    1.258 0.    2.046 0.
  0.    0.    0.   ]
 [0.    1.463 0.    1.128 1.242 0.    0.    0.    3.522 0.377 0.481 0.
  0.    0.    0.562]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]]
{'fdr': 0.35555555555555557, 'tpr': 0.9666666666666667, 'fpr': 0.21333333333333335, 'f1': 0.7733333333333333, 'shd': 17, 'npred': 45, 'ntrue': 30}
[5.274e-05 9.981e-05 3.996e-03 2.090e-01 6.295e-05 4.495e-05 2.472e-05
 2.683e-04 2.757e+00 2.520e-01 3.050e-04 9.277e-05 9.416e-05 4.978e-03
 2.527e+00 3.347e-03 2.640e-01 2.059e-01 9.643e-03 1.052e-02 2.586e-03
 1.555e-03 2.204e+00 2.337e-01 1.380e+00 1.678e-04 7.979e-04 9.719e-02
 2.758e-02 6.991e-02 1.468e-01 1.567e-01 3.306e-02 1.397e-01 2.519e-03
 7.195e-02 1.283e-01 1.736e-01 1.528e-01 5.569e-03 1.644e-03 5.394e-03
 1.616e-01 2.555e-04 7.111e-04 1.927e-01 4.930e-05 3.860e-04 1.612e-04
 8.570e-05 2.196e-01 3.781e-01 1.048e-03 5.260e-04 1.148e-04 1.023e+00
 6.544e-05 4.261e-06 2.526e-05 1.402e-04 8.837e-06 9.923e-05 3.675e-06
 1.439e-04 3.031e-04 7.524e-04 4.937e-05 1.680e-05 7.512e-05 5.551e-04
 2.649e+00 3.018e-02 7.452e-04 9.716e-01 3.659e-01 1.406e+00 1.252e-04
 4.952e-02 1.759e+00 1.399e+00 1.504e+00 1.298e-02 1.488e-03 1.924e+00
 4.208e-01 4.227e-02 1.855e-04 3.428e-01 4.022e-01 2.191e-04 2.701e-04
 5.641e-02 1.478e-01 1.808e+00 9.525e-02 4.407e-03 9.893e-04 1.668e-01
 2.690e+00 5.332e-03 4.721e-03 2.092e+00 1.338e-01 6.110e-01 4.997e-02
 4.477e-03 3.159e-01 1.736e-01 6.259e-02 2.099e-02 2.234e-02 1.177e-01
 1.075e-01 3.806e-01 1.754e-03 6.480e-01 4.152e-01 2.498e-03 2.907e-03
 2.369e-03 2.341e+00 2.235e+00 1.075e+00 2.590e-04 3.529e-04 3.710e-01
 1.919e-04 1.978e-05 2.648e-04 3.568e-04 2.814e+00 6.681e-06 4.931e-05
 2.016e-05 3.878e-04 3.302e-01 8.035e-05 1.603e-05 8.870e-05 1.437e-03
 2.542e-04 5.462e-05 2.904e-04 8.257e-04 3.134e+00 6.200e-05 4.124e-04
 9.566e-06 6.033e-04 1.575e-03 2.594e-04 1.159e-04 1.779e-04 1.600e-03
 3.750e-01 3.412e-04 5.230e-04 1.798e-01 1.473e-01 2.321e-04 3.384e-03
 5.441e-05 1.243e-03 4.236e-01 4.358e-01 7.633e-05 4.507e-04 3.424e-02
 4.015e-02 7.579e-02 4.421e-03 1.013e-01 3.079e+00 1.357e-02 2.986e-03
 2.656e-03 1.258e+00 1.072e-01 2.046e+00 3.414e-02 1.680e-02 1.400e-02
 1.278e-01 1.463e+00 5.998e-03 1.128e+00 1.242e+00 5.077e-03 9.221e-03
 2.136e-03 3.522e+00 3.770e-01 4.815e-01 1.559e-01 1.100e-02 5.624e-01
 9.924e-02 6.253e-04 4.766e-04 4.374e-05 1.033e-01 1.010e-04 1.977e-04
 4.675e-06 1.089e-04 1.114e-01 1.538e-01 2.094e-03 3.979e-05 7.684e-05]
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.]
 [0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.9796296296296296, 0.9716525070797934)
cuda
2565
cuda
Objective function 454.76 = squared loss an data 233.99 + 0.5*rho*h**2 220.188202 + alpha*h 0.000000 + L2reg 0.28 + L1reg 0.30 ; SHD = 120 ; DAG False
||w||^2 0.20759553424887284
exp ma of ||w||^2 9189.029683773799
||w|| 0.45562652935147757
exp ma of ||w|| 0.47879541692164834
||w||^2 0.23704184024707786
exp ma of ||w||^2 4829.823407440734
||w|| 0.48686942833482355
exp ma of ||w|| 0.467662424038217
||w||^2 0.14477091613916776
exp ma of ||w||^2 45.76368509090847
||w|| 0.38048773454497553
exp ma of ||w|| 0.43523678032377805
||w||^2 0.1024042681735714
exp ma of ||w||^2 0.2629021517382386
||w|| 0.32000666895171326
exp ma of ||w|| 0.4836690831148732
||w||^2 0.3300695292377338
exp ma of ||w||^2 0.24921965393940507
||w|| 0.574516778900089
exp ma of ||w|| 0.47693225877079826
cuda
Objective function 58.66 = squared loss an data 56.96 + 0.5*rho*h**2 1.313997 + alpha*h 0.000000 + L2reg 0.23 + L1reg 0.15 ; SHD = 52 ; DAG False
Proportion of microbatches that were clipped  0.7285918173168411
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 1.6211088508509022
iteration 1 in outer loop, alpha = 1.6211088508509022, rho = 1.0, h = 1.6211088508509022
cuda
2565
cuda
Objective function 61.29 = squared loss an data 56.96 + 0.5*rho*h**2 1.313997 + alpha*h 2.627994 + L2reg 0.23 + L1reg 0.15 ; SHD = 52 ; DAG False
||w||^2 50834100462.409515
exp ma of ||w||^2 26794878699.809647
||w|| 225464.18886911846
exp ma of ||w|| 109301.76829477395
||w||^2 9005085.819109851
exp ma of ||w||^2 283746509.61951375
||w|| 3000.8475168041864
exp ma of ||w|| 11770.319158407347
||w||^2 630.7013013448964
exp ma of ||w||^2 102469.03814046075
||w|| 25.113767167529772
exp ma of ||w|| 48.8593703355321
||w||^2 0.34808353068105974
exp ma of ||w||^2 0.45203254754132527
||w|| 0.5899860427849626
exp ma of ||w|| 0.6192333176104378
cuda
Objective function 25.22 = squared loss an data 22.04 + 0.5*rho*h**2 0.688824 + alpha*h 1.902748 + L2reg 0.45 + L1reg 0.15 ; SHD = 60 ; DAG False
Proportion of microbatches that were clipped  0.7277409860191317
iteration 1 in inner loop, alpha 1.6211088508509022 rho 1.0 h 1.173732496003126
2565
cuda
Objective function 31.42 = squared loss an data 22.04 + 0.5*rho*h**2 6.888240 + alpha*h 1.902748 + L2reg 0.45 + L1reg 0.15 ; SHD = 60 ; DAG False
||w||^2 24874676748.357086
exp ma of ||w||^2 38860445729.215645
||w|| 157717.0781759448
exp ma of ||w|| 169681.75470065104
||w||^2 11590093562.30146
exp ma of ||w||^2 27136293890.42302
||w|| 107657.29683723932
exp ma of ||w|| 147128.25797046983
||w||^2 6619087903.780139
exp ma of ||w||^2 22190991203.615677
||w|| 81357.77715609086
exp ma of ||w|| 133286.31108662635
||w||^2 39437.28202814012
exp ma of ||w||^2 4062281.5067974287
||w|| 198.5882222795202
exp ma of ||w|| 784.1267668673842
cuda
Objective function 20.58 = squared loss an data 17.54 + 0.5*rho*h**2 1.454818 + alpha*h 0.874443 + L2reg 0.58 + L1reg 0.13 ; SHD = 42 ; DAG False
Proportion of microbatches that were clipped  0.7370710488158531
iteration 2 in inner loop, alpha 1.6211088508509022 rho 10.0 h 0.5394103808302049
2565
cuda
Objective function 33.67 = squared loss an data 17.54 + 0.5*rho*h**2 14.548178 + alpha*h 0.874443 + L2reg 0.58 + L1reg 0.13 ; SHD = 42 ; DAG False
||w||^2 1502102668.2974663
exp ma of ||w||^2 6822236139.7395315
||w|| 38756.96928679365
exp ma of ||w|| 66573.78153521748
||w||^2 4759490437.619935
exp ma of ||w||^2 6006536699.534209
||w|| 68989.06027494457
exp ma of ||w|| 61934.16077651446
||w||^2 376265.4325408342
exp ma of ||w||^2 21909596.593758807
||w|| 613.4047868584286
exp ma of ||w|| 2310.346757323737
v before min max tensor([[ 5.468e-02, -9.099e-01, -1.855e-01,  ..., -5.933e-02, -3.265e-04,
         -8.334e-01],
        [ 5.269e+00, -8.391e-02, -3.014e-01,  ..., -9.601e-01,  1.708e+00,
         -1.252e+00],
        [ 3.517e+00,  1.758e-01, -7.248e-02,  ..., -9.761e-02, -4.971e-02,
          1.570e-02],
        ...,
        [-3.668e-02,  1.863e+00,  3.274e-01,  ...,  8.799e-02, -2.845e+00,
          8.615e-01],
        [-2.151e-02, -8.246e-01, -3.458e-01,  ...,  1.592e-03, -1.194e-01,
         -4.838e+00],
        [ 1.431e-02, -5.021e-03,  1.158e-01,  ..., -5.136e-01, -1.347e-02,
         -3.490e-01]], device='cuda:0')
v tensor([[5.468e-02, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.000e-12],
        [5.269e+00, 1.000e-12, 1.000e-12,  ..., 1.000e-12, 1.708e+00,
         1.000e-12],
        [3.517e+00, 1.758e-01, 1.000e-12,  ..., 1.000e-12, 1.000e-12,
         1.570e-02],
        ...,
        [1.000e-12, 1.863e+00, 3.274e-01,  ..., 8.799e-02, 1.000e-12,
         8.615e-01],
        [1.000e-12, 1.000e-12, 1.000e-12,  ..., 1.592e-03, 1.000e-12,
         1.000e-12],
        [1.431e-02, 1.000e-12, 1.158e-01,  ..., 1.000e-12, 1.000e-12,
         1.000e-12]], device='cuda:0')
v before min max tensor([-7.195e-02, -1.401e-01,  6.071e-01, -6.801e-02, -2.232e-03,  9.880e-02,
         1.180e-02,  1.341e+00,  2.045e-02, -2.559e+00, -5.928e+00, -3.463e-02,
         5.474e-03,  1.442e-01, -5.287e-03, -3.357e-02,  3.146e-02, -7.789e-02,
        -3.185e-02, -5.179e-02,  1.216e-02,  7.852e+00, -4.475e+00,  8.514e+00,
        -8.783e-02, -1.155e-01, -2.723e-02, -5.436e-02, -2.687e-01, -1.599e-01,
        -2.119e-03, -1.801e-01, -3.167e-02, -6.763e-01, -3.441e-01, -1.119e+00,
         3.691e-02, -2.533e-01,  6.210e-04, -4.171e-01, -6.024e-01,  4.087e-01,
         1.543e+00,  2.829e-01, -8.227e-02,  8.845e-02, -1.066e-01, -2.618e-01,
         2.221e+00, -1.180e+00,  8.108e-03, -8.027e-02,  3.594e-02,  4.514e-02,
        -5.471e-03, -3.056e-02,  8.156e-01, -9.702e-02, -7.223e-03, -6.960e-02,
         1.678e-02, -1.891e-03,  2.719e-02, -1.872e-02, -3.896e-03, -3.353e-01,
        -1.984e-03, -7.236e-01,  5.764e-03,  2.670e-02, -2.462e-03, -1.242e+00,
         3.891e-04,  2.640e+00,  1.279e+01, -2.231e+00, -1.626e-02,  3.009e+00,
        -5.334e-02, -1.408e+00, -3.199e+00, -2.788e-01, -4.185e-03, -5.436e-01,
         1.468e+00,  4.095e-03, -3.272e-02, -9.404e-03, -3.141e+00,  1.168e-01,
        -8.379e-03, -2.575e-01, -1.529e-01, -6.082e-01, -3.730e-01,  8.172e-02,
         1.447e-01, -6.909e-02, -4.750e-02, -3.182e-02,  5.266e-01, -6.883e-01,
        -1.358e+00, -3.147e+00, -2.731e-01, -4.510e-01,  8.011e+00, -4.582e-01,
        -1.164e-01, -2.050e-02, -6.935e-01, -8.154e-02, -1.356e-01,  2.709e-01,
         1.554e-01,  1.821e-02,  8.456e-03,  6.847e-02, -2.670e-01, -4.231e-01,
        -2.285e+00, -3.007e-02,  1.190e-02, -4.505e+00,  1.167e+01,  2.554e-04,
        -2.945e-02, -4.029e-01, -2.797e+00, -9.798e-01,  5.615e-03, -3.607e-01,
         2.597e+00, -9.799e-02,  7.859e-02, -1.860e-02, -6.952e-01, -4.900e-01,
        -1.108e-03, -2.879e-04, -1.999e-01,  1.243e-01, -7.843e-02, -1.688e-02,
        -1.748e+00, -2.878e-01,  1.948e-01,  2.088e-03, -6.700e-01,  1.728e-01],
       device='cuda:0')
v tensor([1.000e-12, 1.000e-12, 6.071e-01, 1.000e-12, 1.000e-12, 9.880e-02,
        1.180e-02, 1.341e+00, 2.045e-02, 1.000e-12, 1.000e-12, 1.000e-12,
        5.474e-03, 1.442e-01, 1.000e-12, 1.000e-12, 3.146e-02, 1.000e-12,
        1.000e-12, 1.000e-12, 1.216e-02, 7.852e+00, 1.000e-12, 8.514e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        3.691e-02, 1.000e-12, 6.210e-04, 1.000e-12, 1.000e-12, 4.087e-01,
        1.543e+00, 2.829e-01, 1.000e-12, 8.845e-02, 1.000e-12, 1.000e-12,
        2.221e+00, 1.000e-12, 8.108e-03, 1.000e-12, 3.594e-02, 4.514e-02,
        1.000e-12, 1.000e-12, 8.156e-01, 1.000e-12, 1.000e-12, 1.000e-12,
        1.678e-02, 1.000e-12, 2.719e-02, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 5.764e-03, 2.670e-02, 1.000e-12, 1.000e-12,
        3.891e-04, 2.640e+00, 1.000e+01, 1.000e-12, 1.000e-12, 3.009e+00,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12,
        1.468e+00, 4.095e-03, 1.000e-12, 1.000e-12, 1.000e-12, 1.168e-01,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 8.172e-02,
        1.447e-01, 1.000e-12, 1.000e-12, 1.000e-12, 5.266e-01, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 8.011e+00, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 2.709e-01,
        1.554e-01, 1.821e-02, 8.456e-03, 6.847e-02, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.190e-02, 1.000e-12, 1.000e+01, 2.554e-04,
        1.000e-12, 1.000e-12, 1.000e-12, 1.000e-12, 5.615e-03, 1.000e-12,
        2.597e+00, 1.000e-12, 7.859e-02, 1.000e-12, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.000e-12, 1.243e-01, 1.000e-12, 1.000e-12,
        1.000e-12, 1.000e-12, 1.948e-01, 2.088e-03, 1.000e-12, 1.728e-01],
       device='cuda:0')
v before min max tensor([[[-3.625e-02],
         [ 8.290e+00],
         [-7.581e-02],
         [ 6.443e-03],
         [ 3.774e-02],
         [-1.422e-01],
         [-3.612e+00],
         [ 2.454e-01],
         [-3.687e+00],
         [ 2.491e-01]],

        [[-1.149e+00],
         [ 6.560e-01],
         [-9.158e-02],
         [-1.129e-01],
         [ 8.660e-01],
         [ 1.299e+00],
         [-3.802e-02],
         [-7.299e-02],
         [-9.201e-01],
         [-2.293e-01]],

        [[-6.174e-02],
         [ 2.267e-03],
         [-7.451e-01],
         [-1.227e-01],
         [-1.481e-02],
         [ 1.705e+00],
         [ 9.085e-02],
         [ 2.352e-01],
         [-4.848e-02],
         [-8.611e-02]],

        [[-7.578e-01],
         [ 9.875e-01],
         [-5.445e+00],
         [-3.310e-01],
         [ 4.893e-02],
         [ 3.760e-02],
         [ 1.426e-01],
         [-3.011e-01],
         [-1.744e+00],
         [-1.672e-01]],

        [[ 9.749e-02],
         [ 5.312e+00],
         [ 1.003e-01],
         [ 3.569e-01],
         [ 2.917e+00],
         [-5.831e-01],
         [-1.453e+00],
         [-5.382e-01],
         [-1.075e+00],
         [-1.400e+00]],

        [[ 2.939e-01],
         [-5.881e-01],
         [-3.908e-01],
         [-8.681e-02],
         [-5.841e-01],
         [ 4.792e-03],
         [-2.146e-01],
         [ 1.741e+00],
         [-4.593e-03],
         [ 5.757e-02]],

        [[ 1.543e-01],
         [-1.264e-03],
         [ 1.107e-02],
         [ 4.508e-02],
         [ 3.131e-02],
         [ 8.810e-01],
         [-6.805e-01],
         [-2.227e-01],
         [ 6.929e-01],
         [-8.201e-02]],

        [[-1.342e-01],
         [-7.011e-03],
         [-2.979e-01],
         [ 1.445e-02],
         [-2.160e-02],
         [ 1.029e+00],
         [ 5.380e-02],
         [ 1.515e-01],
         [ 3.258e-02],
         [ 2.158e-01]],

        [[ 1.227e+00],
         [-2.821e-01],
         [-5.230e+00],
         [ 7.892e-01],
         [-6.952e-01],
         [-2.860e-01],
         [-4.585e-01],
         [-1.608e+00],
         [-5.620e-01],
         [-5.684e-02]],

        [[-3.448e-01],
         [-7.136e-01],
         [-3.319e-01],
         [ 1.591e-01],
         [-6.494e-01],
         [-2.613e+00],
         [ 1.619e-01],
         [ 2.211e-01],
         [ 6.433e-01],
         [ 1.309e+00]],

        [[ 9.778e-01],
         [-3.167e+00],
         [ 1.081e+00],
         [-2.694e-02],
         [-1.748e+00],
         [ 1.236e+00],
         [ 2.148e-01],
         [-2.686e-01],
         [ 2.742e-01],
         [ 1.762e-01]],

        [[-3.853e-02],
         [ 3.030e-02],
         [-1.955e-01],
         [-7.050e-01],
         [-6.739e-01],
         [ 5.641e-01],
         [ 1.721e-03],
         [-2.032e-03],
         [ 4.741e+00],
         [ 4.280e-01]],

        [[ 2.405e-02],
         [-5.189e-01],
         [-1.683e+00],
         [-8.028e-02],
         [-2.750e-01],
         [ 1.063e-01],
         [-3.879e-01],
         [-2.832e-01],
         [-2.862e-01],
         [ 3.985e-01]],

        [[-1.112e-02],
         [-1.908e-01],
         [-5.012e-04],
         [ 1.661e-02],
         [-2.203e-01],
         [-2.351e-01],
         [ 1.012e+00],
         [-3.641e-02],
         [-6.059e-01],
         [-1.221e+00]],

        [[-2.258e-02],
         [ 8.638e-02],
         [ 1.698e-01],
         [-1.603e+00],
         [ 1.533e-01],
         [ 8.042e-02],
         [-1.290e-01],
         [-4.484e-01],
         [-1.170e+00],
         [-1.099e+00]]], device='cuda:0')
v tensor([[[1.000e-12],
         [8.290e+00],
         [1.000e-12],
         [6.443e-03],
         [3.774e-02],
         [1.000e-12],
         [1.000e-12],
         [2.454e-01],
         [1.000e-12],
         [2.491e-01]],

        [[1.000e-12],
         [6.560e-01],
         [1.000e-12],
         [1.000e-12],
         [8.660e-01],
         [1.299e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [2.267e-03],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.705e+00],
         [9.085e-02],
         [2.352e-01],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [9.875e-01],
         [1.000e-12],
         [1.000e-12],
         [4.893e-02],
         [3.760e-02],
         [1.426e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[9.749e-02],
         [5.312e+00],
         [1.003e-01],
         [3.569e-01],
         [2.917e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[2.939e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [4.792e-03],
         [1.000e-12],
         [1.741e+00],
         [1.000e-12],
         [5.757e-02]],

        [[1.543e-01],
         [1.000e-12],
         [1.107e-02],
         [4.508e-02],
         [3.131e-02],
         [8.810e-01],
         [1.000e-12],
         [1.000e-12],
         [6.929e-01],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.445e-02],
         [1.000e-12],
         [1.029e+00],
         [5.380e-02],
         [1.515e-01],
         [3.258e-02],
         [2.158e-01]],

        [[1.227e+00],
         [1.000e-12],
         [1.000e-12],
         [7.892e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.591e-01],
         [1.000e-12],
         [1.000e-12],
         [1.619e-01],
         [2.211e-01],
         [6.433e-01],
         [1.309e+00]],

        [[9.778e-01],
         [1.000e-12],
         [1.081e+00],
         [1.000e-12],
         [1.000e-12],
         [1.236e+00],
         [2.148e-01],
         [1.000e-12],
         [2.742e-01],
         [1.762e-01]],

        [[1.000e-12],
         [3.030e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [5.641e-01],
         [1.721e-03],
         [1.000e-12],
         [4.741e+00],
         [4.280e-01]],

        [[2.405e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.063e-01],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [3.985e-01]],

        [[1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.661e-02],
         [1.000e-12],
         [1.000e-12],
         [1.012e+00],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]],

        [[1.000e-12],
         [8.638e-02],
         [1.698e-01],
         [1.000e-12],
         [1.533e-01],
         [8.042e-02],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12],
         [1.000e-12]]], device='cuda:0')
v before min max tensor([[-0.230],
        [-0.467],
        [ 1.827],
        [-0.211],
        [-0.123],
        [ 0.828],
        [ 0.040],
        [-0.100],
        [-1.724],
        [-0.253],
        [-0.579],
        [ 0.100],
        [ 0.065],
        [ 0.007],
        [-0.065]], device='cuda:0')
v tensor([[1.000e-12],
        [1.000e-12],
        [1.827e+00],
        [1.000e-12],
        [1.000e-12],
        [8.279e-01],
        [3.957e-02],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-12],
        [1.000e-01],
        [6.550e-02],
        [6.726e-03],
        [1.000e-12]], device='cuda:0')
a after update for 1 param tensor([[ 6.923e-04, -1.086e-04,  1.202e-03,  ...,  3.786e-04,  3.022e-06,
          1.929e-04],
        [ 2.594e-03, -5.612e-04, -1.047e-04,  ...,  1.461e-03, -1.712e-03,
          4.211e-04],
        [-2.025e-03,  5.877e-04,  4.469e-05,  ...,  1.063e-04,  1.812e-06,
         -4.252e-04],
        ...,
        [ 2.440e-04,  3.537e-03, -9.605e-04,  ...,  7.206e-04, -2.627e-04,
         -1.130e-03],
        [ 2.038e-05,  3.430e-04,  1.074e-04,  ...,  6.312e-05,  1.256e-05,
          2.985e-04],
        [-1.487e-04, -1.034e-05, -6.172e-04,  ..., -1.144e-05,  4.638e-05,
         -5.413e-04]], device='cuda:0')
s after update for 1 param tensor([[7.462e-02, 4.416e-02, 4.541e-02,  ..., 3.608e-03, 6.926e-05,
         3.915e-02],
        [7.261e-01, 5.003e-03, 1.694e-02,  ..., 7.273e-02, 4.330e-01,
         5.637e-02],
        [5.981e-01, 1.326e-01, 3.309e-03,  ..., 4.543e-03, 2.243e-03,
         4.817e-02],
        ...,
        [2.724e-03, 4.532e-01, 1.812e-01,  ..., 9.539e-02, 1.451e-01,
         2.938e-01],
        [1.659e-03, 3.844e-02, 1.701e-02,  ..., 1.262e-02, 7.377e-03,
         2.304e-01],
        [3.783e-02, 2.395e-04, 1.077e-01,  ..., 2.341e-02, 6.074e-04,
         2.205e-02]], device='cuda:0')
b after update for 1 param tensor([[ 4.619,  3.554,  3.603,  ...,  1.016,  0.141,  3.346],
        [14.409,  1.196,  2.201,  ...,  4.560, 11.127,  4.015],
        [13.078,  6.157,  0.973,  ...,  1.140,  0.801,  3.712],
        ...,
        [ 0.883, 11.384,  7.198,  ...,  5.223,  6.442,  9.166],
        [ 0.689,  3.315,  2.205,  ...,  1.900,  1.452,  8.116],
        [ 3.289,  0.262,  5.548,  ...,  2.587,  0.417,  2.511]],
       device='cuda:0')
clipping threshold 7.367486228985206
a after update for 1 param tensor([-1.489e-03,  1.117e-03,  1.388e-03,  1.114e-04, -5.312e-05, -9.465e-04,
         2.753e-04, -2.184e-03, -3.283e-04,  1.212e-03, -2.537e-03,  2.967e-04,
        -8.504e-05, -1.340e-03, -3.691e-05,  1.128e-04,  5.017e-04, -8.891e-04,
         1.110e-04, -6.115e-05,  1.523e-04,  4.833e-03,  2.497e-03, -3.621e-03,
        -1.365e-04, -1.909e-04, -5.872e-05, -8.969e-05, -5.110e-04, -3.020e-04,
        -6.999e-05,  6.478e-05, -2.019e-04,  1.221e-05,  1.192e-04, -8.474e-04,
        -2.979e-04, -2.102e-04, -2.306e-04, -1.200e-04,  9.355e-04, -1.681e-03,
        -2.037e-03, -6.450e-04, -1.699e-04,  8.083e-04, -1.617e-04, -1.044e-03,
        -2.375e-03,  2.300e-04, -5.233e-04, -6.844e-06, -2.805e-04, -3.008e-04,
         1.059e-04, -6.097e-05,  1.338e-03,  1.609e-04, -2.285e-04,  1.543e-03,
         3.914e-04, -7.907e-06, -2.781e-04,  1.187e-05, -7.999e-05,  8.539e-05,
         9.499e-06,  5.059e-04, -1.024e-04,  2.167e-04, -7.426e-05, -9.351e-04,
        -3.308e-05,  2.801e-03,  4.544e-03, -1.422e-05,  4.830e-05, -7.381e-04,
         5.926e-05, -6.316e-04, -1.482e-03,  8.855e-04,  2.201e-05, -6.275e-04,
         2.907e-03, -2.112e-04, -1.746e-04,  2.122e-04,  9.539e-04,  4.368e-04,
        -8.520e-05, -2.671e-04,  1.216e-04,  8.985e-04, -1.864e-05,  5.739e-04,
        -1.112e-03,  3.980e-04,  2.953e-04,  8.154e-05, -1.250e-03, -8.493e-05,
        -1.668e-05,  1.298e-03,  4.405e-04, -1.059e-03, -3.123e-03, -8.562e-04,
        -2.512e-04,  2.840e-05,  6.810e-04,  8.757e-05, -7.857e-04,  6.305e-04,
        -5.985e-04,  3.344e-04, -4.132e-04,  4.008e-04, -5.339e-04,  6.313e-04,
         3.109e-04, -6.385e-05, -8.489e-05, -3.015e-03, -4.077e-03, -3.568e-05,
         5.521e-05, -4.173e-04,  8.108e-04,  1.035e-03,  2.165e-04, -1.233e-03,
         2.568e-03, -4.518e-04, -5.815e-04,  2.718e-04, -6.631e-04, -1.217e-03,
         4.376e-06, -8.629e-06,  3.414e-05,  6.013e-04,  3.553e-04,  5.678e-05,
         2.367e-03,  3.704e-04,  8.056e-04, -5.981e-05,  9.819e-05, -6.082e-04],
       device='cuda:0')
s after update for 1 param tensor([5.043e-02, 1.939e-02, 2.474e-01, 3.097e-03, 5.744e-04, 9.983e-02,
        3.437e-02, 3.725e-01, 4.527e-02, 1.261e-01, 3.946e-01, 3.029e-03,
        2.340e-02, 1.339e-01, 2.980e-04, 1.542e-03, 5.644e-02, 4.229e-02,
        1.484e-03, 2.350e-03, 3.487e-02, 9.027e-01, 2.224e-01, 9.271e-01,
        3.966e-03, 7.792e-03, 1.226e-03, 3.331e-03, 1.338e-02, 7.366e-03,
        3.268e-04, 8.105e-03, 2.681e-03, 3.167e-02, 1.550e-02, 5.790e-02,
        6.076e-02, 1.211e-02, 8.213e-03, 2.107e-02, 4.216e-02, 2.411e-01,
        3.955e-01, 1.682e-01, 8.016e-03, 9.501e-02, 1.025e-02, 2.203e-02,
        4.779e-01, 6.294e-02, 3.127e-02, 3.971e-03, 5.995e-02, 6.719e-02,
        2.794e-04, 1.654e-03, 2.874e-01, 4.867e-03, 1.223e-03, 4.015e-02,
        4.102e-02, 1.026e-04, 5.215e-02, 9.016e-04, 3.412e-04, 2.328e-02,
        3.222e-04, 5.414e-02, 2.402e-02, 5.167e-02, 1.959e-04, 5.778e-02,
        6.238e-03, 5.184e-01, 1.003e+00, 1.155e-01, 7.317e-04, 8.202e-01,
        2.431e-03, 1.125e-01, 1.594e-01, 5.624e-02, 2.305e-04, 2.524e-02,
        4.037e-01, 2.025e-02, 4.691e-03, 1.294e-03, 1.412e-01, 1.083e-01,
        8.702e-04, 2.515e-02, 7.885e-03, 7.866e-02, 1.865e-02, 9.052e-02,
        1.210e-01, 6.992e-03, 3.230e-03, 1.508e-03, 2.298e-01, 3.298e-02,
        6.313e-02, 3.504e-01, 1.717e-02, 3.832e-02, 8.976e-01, 3.362e-02,
        5.343e-03, 1.303e-03, 4.332e-02, 5.115e-03, 3.269e-02, 1.647e-01,
        1.248e-01, 4.410e-02, 2.921e-02, 8.276e-02, 1.735e-02, 2.197e-02,
        1.029e-01, 1.406e-03, 3.450e-02, 3.265e-01, 1.006e+00, 5.056e-03,
        1.352e-03, 2.892e-02, 1.257e-01, 5.870e-02, 2.370e-02, 1.694e-01,
        5.129e-01, 6.732e-03, 8.889e-02, 1.553e-03, 3.126e-02, 7.178e-02,
        5.534e-05, 3.332e-05, 9.162e-03, 1.116e-01, 5.146e-03, 1.362e-03,
        1.195e-01, 1.897e-02, 1.396e-01, 1.445e-02, 3.044e-02, 1.315e-01],
       device='cuda:0')
b after update for 1 param tensor([ 3.798,  2.355,  8.411,  0.941,  0.405,  5.343,  3.135, 10.321,  3.598,
         6.005, 10.622,  0.931,  2.587,  6.187,  0.292,  0.664,  4.017,  3.477,
         0.651,  0.820,  3.158, 16.067,  7.975, 16.282,  1.065,  1.493,  0.592,
         0.976,  1.956,  1.451,  0.306,  1.522,  0.876,  3.009,  2.105,  4.069,
         4.168,  1.861,  1.532,  2.455,  3.472,  8.303, 10.635,  6.936,  1.514,
         5.212,  1.712,  2.510, 11.690,  4.242,  2.990,  1.066,  4.140,  4.383,
         0.283,  0.688,  9.065,  1.180,  0.591,  3.388,  3.425,  0.171,  3.862,
         0.508,  0.312,  2.580,  0.304,  3.934,  2.621,  3.844,  0.237,  4.065,
         1.336, 12.176, 16.935,  5.747,  0.457, 15.315,  0.834,  5.672,  6.751,
         4.010,  0.257,  2.687, 10.744,  2.406,  1.158,  0.608,  6.354,  5.565,
         0.499,  2.682,  1.502,  4.743,  2.309,  5.088,  5.883,  1.414,  0.961,
         0.657,  8.106,  3.071,  4.249, 10.009,  2.216,  3.310, 16.021,  3.100,
         1.236,  0.610,  3.520,  1.209,  3.058,  6.862,  5.974,  3.551,  2.890,
         4.865,  2.227,  2.507,  5.423,  0.634,  3.141,  9.662, 16.958,  1.202,
         0.622,  2.876,  5.996,  4.097,  2.603,  6.960, 12.111,  1.387,  5.042,
         0.666,  2.990,  4.531,  0.126,  0.098,  1.619,  5.649,  1.213,  0.624,
         5.845,  2.329,  6.319,  2.033,  2.950,  6.132], device='cuda:0')
clipping threshold 7.367486228985206
a after update for 1 param tensor([[[-3.440e-04],
         [-3.321e-03],
         [-2.050e-04],
         [-7.358e-05],
         [ 6.061e-04],
         [-5.678e-04],
         [ 6.711e-04],
         [ 1.856e-03],
         [-5.662e-04],
         [-1.078e-03]],

        [[ 1.881e-04],
         [ 7.399e-04],
         [-3.570e-04],
         [ 4.256e-04],
         [ 1.149e-03],
         [-1.924e-03],
         [ 6.417e-04],
         [ 5.390e-04],
         [ 6.778e-05],
         [-7.731e-05]],

        [[-2.977e-04],
         [-1.579e-04],
         [ 1.457e-03],
         [-3.878e-04],
         [-3.086e-04],
         [-2.315e-03],
         [ 9.855e-04],
         [-1.190e-03],
         [-5.759e-04],
         [ 1.793e-04]],

        [[-1.367e-03],
         [-1.346e-03],
         [-6.886e-04],
         [ 6.809e-04],
         [-4.080e-04],
         [-3.304e-04],
         [ 1.035e-03],
         [ 2.087e-04],
         [-3.266e-04],
         [ 9.922e-04]],

        [[ 1.001e-03],
         [ 2.809e-03],
         [ 9.776e-04],
         [ 1.203e-03],
         [ 1.966e-03],
         [-3.977e-04],
         [-9.042e-04],
         [ 1.561e-04],
         [-1.819e-03],
         [ 4.029e-04]],

        [[ 7.360e-04],
         [ 1.429e-03],
         [-9.328e-04],
         [ 1.916e-04],
         [-2.712e-04],
         [ 2.040e-04],
         [ 3.358e-05],
         [ 2.133e-03],
         [ 2.479e-04],
         [ 3.540e-04]],

        [[-2.178e-03],
         [ 4.134e-05],
         [ 2.127e-04],
         [ 4.725e-04],
         [ 2.163e-04],
         [-1.300e-03],
         [-5.364e-06],
         [ 8.144e-04],
         [ 1.217e-03],
         [ 9.809e-05]],

        [[ 4.755e-04],
         [ 3.098e-05],
         [ 2.206e-04],
         [-9.246e-05],
         [-1.146e-03],
         [-1.623e-03],
         [-4.138e-04],
         [ 5.374e-04],
         [ 1.184e-04],
         [ 5.639e-04]],

        [[ 1.469e-03],
         [ 1.798e-04],
         [ 1.104e-03],
         [-1.431e-03],
         [-2.390e-05],
         [ 1.506e-04],
         [-3.593e-04],
         [-9.915e-04],
         [-6.566e-05],
         [-1.384e-04]],

        [[-8.203e-04],
         [-1.464e-04],
         [ 6.435e-04],
         [-8.588e-04],
         [ 1.654e-03],
         [ 1.371e-03],
         [-2.046e-03],
         [ 1.247e-03],
         [ 1.544e-03],
         [ 1.813e-03]],

        [[-1.411e-03],
         [-1.045e-03],
         [-1.200e-03],
         [ 2.171e-04],
         [ 3.128e-04],
         [-2.016e-03],
         [-2.160e-04],
         [-4.216e-04],
         [-6.920e-04],
         [-8.964e-04]],

        [[-1.459e-04],
         [ 6.592e-04],
         [ 6.333e-04],
         [ 3.514e-04],
         [ 8.541e-04],
         [-2.419e-03],
         [-4.975e-04],
         [-1.737e-04],
         [ 3.527e-03],
         [ 1.274e-03]],

        [[-2.089e-04],
         [ 8.776e-06],
         [ 1.814e-03],
         [ 3.310e-04],
         [ 3.225e-04],
         [-5.355e-04],
         [-1.427e-04],
         [-7.579e-05],
         [ 5.735e-04],
         [-1.056e-03]],

        [[-7.340e-05],
         [ 1.349e-04],
         [ 3.443e-05],
         [ 1.770e-04],
         [ 1.475e-04],
         [-1.265e-04],
         [-2.005e-03],
         [-9.953e-05],
         [ 1.782e-04],
         [-1.161e-03]],

        [[-7.141e-05],
         [ 3.179e-04],
         [-6.296e-04],
         [-6.341e-04],
         [ 3.747e-04],
         [ 2.035e-04],
         [-6.539e-04],
         [-2.929e-04],
         [ 4.176e-05],
         [ 5.452e-04]]], device='cuda:0')
s after update for 1 param tensor([[[8.926e-03],
         [9.126e-01],
         [4.483e-03],
         [2.541e-02],
         [6.167e-02],
         [7.019e-02],
         [1.665e-01],
         [1.686e-01],
         [2.303e-01],
         [1.611e-01]],

        [[5.581e-02],
         [2.567e-01],
         [8.969e-03],
         [7.089e-03],
         [2.944e-01],
         [3.861e-01],
         [1.060e-02],
         [2.912e-02],
         [4.253e-02],
         [1.033e-02]],

        [[1.203e-02],
         [1.506e-02],
         [6.850e-02],
         [7.922e-03],
         [3.794e-03],
         [4.167e-01],
         [1.078e-01],
         [1.538e-01],
         [5.824e-03],
         [4.945e-03]],

        [[1.701e-01],
         [3.150e-01],
         [2.595e-01],
         [9.212e-02],
         [7.003e-02],
         [6.132e-02],
         [1.400e-01],
         [1.393e-02],
         [8.731e-02],
         [1.762e-02]],

        [[9.904e-02],
         [7.506e-01],
         [1.012e-01],
         [1.891e-01],
         [5.536e-01],
         [2.673e-02],
         [6.751e-02],
         [2.419e-02],
         [1.011e-01],
         [6.314e-02]],

        [[1.716e-01],
         [6.167e-02],
         [3.078e-02],
         [5.336e-03],
         [2.711e-02],
         [2.211e-02],
         [1.129e-02],
         [4.181e-01],
         [8.135e-04],
         [7.589e-02]],

        [[1.445e-01],
         [1.336e-04],
         [3.328e-02],
         [6.792e-02],
         [5.612e-02],
         [2.969e-01],
         [3.244e-02],
         [5.319e-02],
         [2.634e-01],
         [4.587e-03]],

        [[1.242e-02],
         [3.256e-04],
         [1.891e-02],
         [3.865e-02],
         [6.004e-02],
         [3.348e-01],
         [7.336e-02],
         [1.231e-01],
         [5.712e-02],
         [1.470e-01]],

        [[3.511e-01],
         [1.467e-02],
         [2.355e-01],
         [2.811e-01],
         [3.423e-02],
         [1.330e-02],
         [2.844e-02],
         [8.327e-02],
         [3.169e-02],
         [5.343e-03]],

        [[2.230e-02],
         [3.598e-02],
         [1.493e-02],
         [1.284e-01],
         [8.131e-02],
         [1.319e-01],
         [1.347e-01],
         [1.518e-01],
         [2.542e-01],
         [3.630e-01]],

        [[3.137e-01],
         [1.464e-01],
         [3.295e-01],
         [1.307e-03],
         [9.163e-02],
         [3.551e-01],
         [1.472e-01],
         [1.804e-02],
         [1.656e-01],
         [1.337e-01]],

        [[5.501e-03],
         [5.513e-02],
         [2.761e-02],
         [3.836e-02],
         [3.802e-02],
         [2.483e-01],
         [1.377e-02],
         [1.157e-03],
         [6.933e-01],
         [2.086e-01]],

        [[4.922e-02],
         [2.346e-02],
         [8.728e-02],
         [4.948e-03],
         [1.275e-02],
         [1.031e-01],
         [1.775e-02],
         [1.367e-02],
         [1.981e-02],
         [2.007e-01]],

        [[5.029e-04],
         [8.599e-03],
         [3.451e-05],
         [4.080e-02],
         [1.436e-02],
         [1.415e-02],
         [3.234e-01],
         [1.947e-03],
         [3.815e-02],
         [1.591e-01]],

        [[1.203e-03],
         [9.310e-02],
         [1.304e-01],
         [9.983e-02],
         [1.238e-01],
         [8.969e-02],
         [1.645e-02],
         [2.277e-02],
         [5.603e-02],
         [5.294e-02]]], device='cuda:0')
b after update for 1 param tensor([[[ 1.598],
         [16.154],
         [ 1.132],
         [ 2.696],
         [ 4.199],
         [ 4.480],
         [ 6.901],
         [ 6.943],
         [ 8.115],
         [ 6.787]],

        [[ 3.995],
         [ 8.567],
         [ 1.601],
         [ 1.424],
         [ 9.176],
         [10.508],
         [ 1.741],
         [ 2.886],
         [ 3.487],
         [ 1.719]],

        [[ 1.855],
         [ 2.075],
         [ 4.426],
         [ 1.505],
         [ 1.042],
         [10.916],
         [ 5.552],
         [ 6.632],
         [ 1.291],
         [ 1.189]],

        [[ 6.975],
         [ 9.491],
         [ 8.614],
         [ 5.132],
         [ 4.475],
         [ 4.187],
         [ 6.328],
         [ 1.996],
         [ 4.997],
         [ 2.245]],

        [[ 5.322],
         [14.650],
         [ 5.380],
         [ 7.354],
         [12.582],
         [ 2.764],
         [ 4.394],
         [ 2.630],
         [ 5.377],
         [ 4.249]],

        [[ 7.004],
         [ 4.199],
         [ 2.967],
         [ 1.235],
         [ 2.784],
         [ 2.514],
         [ 1.796],
         [10.934],
         [ 0.482],
         [ 4.658]],

        [[ 6.429],
         [ 0.195],
         [ 3.085],
         [ 4.407],
         [ 4.006],
         [ 9.214],
         [ 3.046],
         [ 3.900],
         [ 8.679],
         [ 1.145]],

        [[ 1.884],
         [ 0.305],
         [ 2.325],
         [ 3.325],
         [ 4.144],
         [ 9.784],
         [ 4.580],
         [ 5.933],
         [ 4.041],
         [ 6.483]],

        [[10.020],
         [ 2.048],
         [ 8.207],
         [ 8.966],
         [ 3.129],
         [ 1.950],
         [ 2.852],
         [ 4.880],
         [ 3.010],
         [ 1.236]],

        [[ 2.525],
         [ 3.207],
         [ 2.066],
         [ 6.060],
         [ 4.822],
         [ 6.141],
         [ 6.206],
         [ 6.589],
         [ 8.526],
         [10.188]],

        [[ 9.471],
         [ 6.469],
         [ 9.706],
         [ 0.611],
         [ 5.119],
         [10.077],
         [ 6.488],
         [ 2.271],
         [ 6.881],
         [ 6.183]],

        [[ 1.254],
         [ 3.971],
         [ 2.810],
         [ 3.312],
         [ 3.297],
         [ 8.426],
         [ 1.984],
         [ 0.575],
         [14.080],
         [ 7.724]],

        [[ 3.751],
         [ 2.590],
         [ 4.996],
         [ 1.190],
         [ 1.910],
         [ 5.430],
         [ 2.253],
         [ 1.977],
         [ 2.380],
         [ 7.575]],

        [[ 0.379],
         [ 1.568],
         [ 0.099],
         [ 3.416],
         [ 2.026],
         [ 2.012],
         [ 9.616],
         [ 0.746],
         [ 3.303],
         [ 6.745]],

        [[ 0.587],
         [ 5.160],
         [ 6.106],
         [ 5.343],
         [ 5.951],
         [ 5.064],
         [ 2.169],
         [ 2.552],
         [ 4.003],
         [ 3.891]]], device='cuda:0')
clipping threshold 7.367486228985206
a after update for 1 param tensor([[ 5.073e-04],
        [ 6.615e-05],
        [-1.700e-03],
        [-2.366e-04],
        [-6.246e-04],
        [ 1.157e-03],
        [ 5.381e-04],
        [ 8.163e-05],
        [ 5.150e-04],
        [ 1.987e-04],
        [ 6.359e-04],
        [-6.830e-04],
        [ 5.756e-04],
        [ 7.735e-05],
        [-2.201e-04]], device='cuda:0')
s after update for 1 param tensor([[0.012],
        [0.022],
        [0.428],
        [0.011],
        [0.009],
        [0.288],
        [0.063],
        [0.005],
        [0.087],
        [0.012],
        [0.032],
        [0.100],
        [0.081],
        [0.026],
        [0.004]], device='cuda:0')
b after update for 1 param tensor([[ 1.830],
        [ 2.501],
        [11.067],
        [ 1.770],
        [ 1.635],
        [ 9.080],
        [ 4.243],
        [ 1.143],
        [ 4.987],
        [ 1.840],
        [ 3.024],
        [ 5.353],
        [ 4.811],
        [ 2.723],
        [ 1.015]], device='cuda:0')
clipping threshold 7.367486228985206
||w||^2 0.18325214817042304
exp ma of ||w||^2 9.90882970591453
||w|| 0.4280796049456492
exp ma of ||w|| 0.8075577519945969
||w||^2 0.31125225435805476
exp ma of ||w||^2 2.1917983807762957
||w|| 0.5578998605108759
exp ma of ||w|| 0.7734971309290687
||w||^2 0.5703228766612133
exp ma of ||w||^2 0.9575488730383847
||w|| 0.7551972435471499
exp ma of ||w|| 0.8761085206866709
||w||^2 0.7571798040426231
exp ma of ||w||^2 0.6869420732701238
||w|| 0.8701607920623768
exp ma of ||w|| 0.7730099316262509
cuda
Objective function 18.92 = squared loss an data 16.68 + 0.5*rho*h**2 1.171718 + alpha*h 0.248164 + L2reg 0.71 + L1reg 0.11 ; SHD = 36 ; DAG True
Proportion of microbatches that were clipped  0.7491841491841492
iteration 3 in inner loop, alpha 1.6211088508509022 rho 100.0 h 0.15308288028236028
iteration 2 in outer loop, alpha = 16.92939687908693, rho = 100.0, h = 0.15308288028236028
cuda
2565
cuda
Objective function 21.27 = squared loss an data 16.68 + 0.5*rho*h**2 1.171718 + alpha*h 2.591601 + L2reg 0.71 + L1reg 0.11 ; SHD = 36 ; DAG True
||w||^2 2425.4243226492013
exp ma of ||w||^2 785559.9889906547
||w|| 49.24859716427668
exp ma of ||w|| 159.52445186939462
||w||^2 0.6576982124238407
exp ma of ||w||^2 64.98482325255736
||w|| 0.8109859508177936
exp ma of ||w|| 0.9517438543788888
||w||^2 0.24908659602729147
exp ma of ||w||^2 21.484526562547707
||w|| 0.49908576019286655
exp ma of ||w|| 0.9110264159423084
cuda
Objective function 19.56 = squared loss an data 16.54 + 0.5*rho*h**2 0.459750 + alpha*h 1.623370 + L2reg 0.82 + L1reg 0.11 ; SHD = 33 ; DAG True
Proportion of microbatches that were clipped  0.7428849428362929
iteration 1 in inner loop, alpha 16.92939687908693 rho 100.0 h 0.09589057687013636
2565
cuda
Objective function 23.70 = squared loss an data 16.54 + 0.5*rho*h**2 4.597501 + alpha*h 1.623370 + L2reg 0.82 + L1reg 0.11 ; SHD = 33 ; DAG True
||w||^2 6502084609.826737
exp ma of ||w||^2 20109380500.991154
||w|| 80635.50464793247
exp ma of ||w|| 118402.66285533324
||w||^2 658.4080409188301
exp ma of ||w||^2 883979.1461923816
||w|| 25.659462989681412
exp ma of ||w|| 133.47575622810288
||w||^2 4.254784232136639
exp ma of ||w||^2 33408.05513098017
||w|| 2.062712833173013
exp ma of ||w|| 8.613442119462954
||w||^2 0.31403548895210914
exp ma of ||w||^2 3.617213229674852
||w|| 0.5603886945256026
exp ma of ||w|| 0.9084281640652314
||w||^2 0.3973480009672388
exp ma of ||w||^2 0.8063566399142419
||w|| 0.6303554560462207
exp ma of ||w|| 0.8214021721392928
cuda
Objective function 18.64 = squared loss an data 16.32 + 0.5*rho*h**2 0.681611 + alpha*h 0.625065 + L2reg 0.91 + L1reg 0.11 ; SHD = 31 ; DAG True
Proportion of microbatches that were clipped  0.743393430476661
iteration 2 in inner loop, alpha 16.92939687908693 rho 1000.0 h 0.036921842611604916
iteration 3 in outer loop, alpha = 53.851239490691846, rho = 1000.0, h = 0.036921842611604916
cuda
2565
cuda
Objective function 20.00 = squared loss an data 16.32 + 0.5*rho*h**2 0.681611 + alpha*h 1.988287 + L2reg 0.91 + L1reg 0.11 ; SHD = 31 ; DAG True
||w||^2 456399467742.432
exp ma of ||w||^2 18983820529.457527
||w|| 675573.4362320887
exp ma of ||w|| 35949.29523984165
||w||^2 4309503309.787159
exp ma of ||w||^2 9535716643.195227
||w|| 65646.80730840731
exp ma of ||w|| 75493.2187966725
||w||^2 1870077.644792566
exp ma of ||w||^2 101740367.83866747
||w|| 1367.507822570886
exp ma of ||w|| 4702.911192919805
||w||^2 0.38273433932345263
exp ma of ||w||^2 0.9250293040727317
||w|| 0.618655266948769
exp ma of ||w|| 0.8730833011038778
cuda
Objective function 18.58 = squared loss an data 15.72 + 0.5*rho*h**2 0.356165 + alpha*h 1.437262 + L2reg 0.96 + L1reg 0.11 ; SHD = 32 ; DAG True
Proportion of microbatches that were clipped  0.7559281437125749
iteration 1 in inner loop, alpha 53.851239490691846 rho 1000.0 h 0.026689496152012993
2565
cuda
Objective function 21.79 = squared loss an data 15.72 + 0.5*rho*h**2 3.561646 + alpha*h 1.437262 + L2reg 0.96 + L1reg 0.11 ; SHD = 32 ; DAG True
||w||^2 43745967219.39723
exp ma of ||w||^2 213398091037.6562
||w|| 209155.36622185248
exp ma of ||w|| 390361.3255600047
||w||^2 0.772949073954886
exp ma of ||w||^2 2352.730846767327
||w|| 0.8791752236925732
exp ma of ||w|| 1.7752529253199545
||w||^2 4.073324532537588
exp ma of ||w||^2 511.7702328590937
||w|| 2.01824788679131
exp ma of ||w|| 1.2726662582701747
||w||^2 1.177838108686808
exp ma of ||w||^2 34.01928154170308
||w|| 1.08528250178781
exp ma of ||w|| 1.0439450100424577
||w||^2 0.9907669667083352
exp ma of ||w||^2 26.97044810331365
||w|| 0.9953727777613447
exp ma of ||w|| 1.0281728689941911
||w||^2 1.3639592619589882
exp ma of ||w||^2 1.0284842755340342
||w|| 1.1678866648605026
exp ma of ||w|| 0.8989527245682818
||w||^2 0.23403139288071187
exp ma of ||w||^2 1.1071886768832355
||w|| 0.48376791220657855
exp ma of ||w|| 0.9622324072424233
cuda
Objective function 18.05 = squared loss an data 15.88 + 0.5*rho*h**2 0.498563 + alpha*h 0.537738 + L2reg 1.02 + L1reg 0.10 ; SHD = 25 ; DAG True
Proportion of microbatches that were clipped  0.7562425683709869
iteration 2 in inner loop, alpha 53.851239490691846 rho 10000.0 h 0.009985614700070755
2565
cuda
Objective function 22.53 = squared loss an data 15.88 + 0.5*rho*h**2 4.985625 + alpha*h 0.537738 + L2reg 1.02 + L1reg 0.10 ; SHD = 25 ; DAG True
||w||^2 1.946405630292217
exp ma of ||w||^2 380.7306935425327
||w|| 1.3951364199576388
exp ma of ||w|| 1.1729840101969786
||w||^2 1.28770661684679
exp ma of ||w||^2 105.12122064328533
||w|| 1.1347716143994746
exp ma of ||w|| 1.136907615892776
cuda
Objective function 17.61 = squared loss an data 15.71 + 0.5*rho*h**2 0.562474 + alpha*h 0.180618 + L2reg 1.06 + L1reg 0.10 ; SHD = 25 ; DAG True
Proportion of microbatches that were clipped  0.7538498556304138
iteration 3 in inner loop, alpha 53.851239490691846 rho 100000.0 h 0.0033540247186838457
iteration 4 in outer loop, alpha = 389.2537113590764, rho = 100000.0, h = 0.0033540247186838457
cuda
2565
cuda
Objective function 18.73 = squared loss an data 15.71 + 0.5*rho*h**2 0.562474 + alpha*h 1.305567 + L2reg 1.06 + L1reg 0.10 ; SHD = 25 ; DAG True
||w||^2 19570665779.622166
exp ma of ||w||^2 3084548237633.249
||w|| 139895.19569885937
exp ma of ||w|| 673781.214559208
||w||^2 1.501497545907776
exp ma of ||w||^2 4243.573958424488
||w|| 1.2253560894318745
exp ma of ||w|| 1.3757514896241105
||w||^2 1.0388849105040714
exp ma of ||w||^2 240.96462510718985
||w|| 1.0192570384864024
exp ma of ||w|| 1.1829211097055505
||w||^2 0.6020151837266118
exp ma of ||w||^2 38.54658161788811
||w|| 0.7758963743481547
exp ma of ||w|| 1.0653147675015162
||w||^2 1.7614268670757138
exp ma of ||w||^2 13.465792918350846
||w|| 1.3271875779541165
exp ma of ||w|| 1.0169752673267762
||w||^2 0.6314482881094136
exp ma of ||w||^2 7.088412579425511
||w|| 0.7946372053392753
exp ma of ||w|| 1.0400559532267286
||w||^2 1.1003870551195576
exp ma of ||w||^2 1.0980304064264321
||w|| 1.0489933532294462
exp ma of ||w|| 0.989391577407305
||w||^2 0.39105432081574687
exp ma of ||w||^2 0.9715911716220317
||w|| 0.6253433623344433
exp ma of ||w|| 0.9329646922841158
cuda
Objective function 18.28 = squared loss an data 15.96 + 0.5*rho*h**2 0.243895 + alpha*h 0.859704 + L2reg 1.12 + L1reg 0.10 ; SHD = 27 ; DAG True
Proportion of microbatches that were clipped  0.7502443792766373
iteration 1 in inner loop, alpha 389.2537113590764 rho 100000.0 h 0.002208595542956715
iteration 5 in outer loop, alpha = 2597.8492543157913, rho = 1000000.0, h = 0.002208595542956715
Threshold 0.3
[[0.006 0.06  0.042 0.164 0.311 0.021 0.036 0.003 0.064 0.845 0.117 0.186
  0.021 0.012 0.133]
 [0.089 0.004 0.248 0.161 0.379 0.172 0.038 0.045 0.217 0.332 0.207 0.79
  0.056 0.003 0.035]
 [0.142 0.016 0.004 0.021 0.216 0.054 0.024 0.041 0.032 0.132 0.064 0.043
  0.025 0.011 0.15 ]
 [0.028 0.043 0.153 0.003 0.247 0.023 0.019 0.009 0.031 0.188 0.125 0.041
  0.034 0.008 0.215]
 [0.004 0.007 0.017 0.011 0.005 0.008 0.004 0.004 0.004 0.003 0.004 0.014
  0.002 0.003 0.012]
 [0.22  0.013 0.092 0.203 0.4   0.004 0.013 0.05  0.203 0.315 0.269 0.573
  0.023 0.021 0.04 ]
 [0.119 0.142 0.197 0.207 0.411 0.248 0.003 0.041 0.097 0.212 1.086 0.172
  0.026 0.036 0.136]
 [0.929 0.092 0.108 0.348 0.619 0.077 0.113 0.003 0.152 0.332 0.256 0.284
  0.037 0.038 0.179]
 [0.062 0.022 0.093 0.089 0.363 0.019 0.027 0.021 0.004 0.909 0.576 0.009
  0.015 0.002 0.043]
 [0.004 0.017 0.03  0.026 1.678 0.012 0.024 0.009 0.004 0.003 0.087 0.014
  0.019 0.002 0.026]
 [0.045 0.016 0.052 0.03  1.652 0.01  0.002 0.011 0.01  0.076 0.004 0.024
  0.003 0.005 0.033]
 [0.038 0.003 0.077 0.079 0.311 0.005 0.028 0.008 0.467 0.114 0.223 0.004
  0.021 0.002 0.026]
 [0.149 0.087 0.172 0.082 0.716 0.162 0.155 0.111 0.2   0.21  1.087 0.187
  0.004 0.054 0.135]
 [0.404 1.078 0.331 0.278 0.342 0.192 0.106 0.095 1.535 0.772 0.505 1.431
  0.092 0.003 0.161]
 [0.027 0.06  0.029 0.016 0.315 0.083 0.035 0.016 0.077 0.119 0.128 0.076
  0.019 0.025 0.004]]
[[0.    0.    0.    0.    0.311 0.    0.    0.    0.    0.845 0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.379 0.    0.    0.    0.    0.332 0.    0.79
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.4   0.    0.    0.    0.    0.315 0.    0.573
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.411 0.    0.    0.    0.    0.    1.086 0.
  0.    0.    0.   ]
 [0.929 0.    0.    0.348 0.619 0.    0.    0.    0.    0.332 0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.363 0.    0.    0.    0.    0.909 0.576 0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    1.678 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    1.652 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.311 0.    0.    0.    0.467 0.    0.    0.
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.716 0.    0.    0.    0.    0.    1.087 0.
  0.    0.    0.   ]
 [0.404 1.078 0.331 0.    0.342 0.    0.    0.    1.535 0.772 0.505 1.431
  0.    0.    0.   ]
 [0.    0.    0.    0.    0.315 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.   ]]
{'fdr': 0.46875, 'tpr': 0.5666666666666667, 'fpr': 0.2, 'f1': 0.5483870967741935, 'shd': 27, 'npred': 32, 'ntrue': 30}
[5.983e-02 4.245e-02 1.642e-01 3.106e-01 2.133e-02 3.580e-02 2.731e-03
 6.368e-02 8.448e-01 1.170e-01 1.857e-01 2.085e-02 1.234e-02 1.334e-01
 8.924e-02 2.482e-01 1.607e-01 3.791e-01 1.716e-01 3.833e-02 4.478e-02
 2.167e-01 3.322e-01 2.066e-01 7.901e-01 5.592e-02 2.529e-03 3.462e-02
 1.424e-01 1.633e-02 2.123e-02 2.163e-01 5.374e-02 2.357e-02 4.071e-02
 3.204e-02 1.321e-01 6.381e-02 4.282e-02 2.478e-02 1.077e-02 1.496e-01
 2.761e-02 4.306e-02 1.531e-01 2.467e-01 2.337e-02 1.942e-02 9.106e-03
 3.075e-02 1.880e-01 1.247e-01 4.094e-02 3.439e-02 8.438e-03 2.153e-01
 4.456e-03 6.851e-03 1.712e-02 1.055e-02 7.611e-03 3.888e-03 4.176e-03
 3.900e-03 2.609e-03 4.284e-03 1.423e-02 2.242e-03 2.588e-03 1.237e-02
 2.198e-01 1.279e-02 9.160e-02 2.029e-01 3.996e-01 1.330e-02 5.005e-02
 2.030e-01 3.155e-01 2.689e-01 5.735e-01 2.251e-02 2.072e-02 4.047e-02
 1.186e-01 1.419e-01 1.974e-01 2.068e-01 4.112e-01 2.477e-01 4.110e-02
 9.734e-02 2.117e-01 1.086e+00 1.716e-01 2.574e-02 3.615e-02 1.364e-01
 9.285e-01 9.213e-02 1.083e-01 3.478e-01 6.185e-01 7.713e-02 1.125e-01
 1.519e-01 3.318e-01 2.556e-01 2.838e-01 3.696e-02 3.764e-02 1.791e-01
 6.165e-02 2.194e-02 9.296e-02 8.895e-02 3.628e-01 1.868e-02 2.659e-02
 2.111e-02 9.094e-01 5.758e-01 9.433e-03 1.541e-02 1.560e-03 4.280e-02
 4.221e-03 1.655e-02 2.996e-02 2.556e-02 1.678e+00 1.154e-02 2.381e-02
 8.670e-03 4.198e-03 8.688e-02 1.428e-02 1.875e-02 2.395e-03 2.604e-02
 4.549e-02 1.551e-02 5.183e-02 2.970e-02 1.652e+00 1.001e-02 2.444e-03
 1.077e-02 9.891e-03 7.583e-02 2.405e-02 3.393e-03 4.582e-03 3.282e-02
 3.809e-02 2.930e-03 7.685e-02 7.883e-02 3.107e-01 4.708e-03 2.849e-02
 8.348e-03 4.667e-01 1.139e-01 2.229e-01 2.112e-02 2.034e-03 2.581e-02
 1.487e-01 8.746e-02 1.719e-01 8.195e-02 7.155e-01 1.625e-01 1.547e-01
 1.109e-01 1.996e-01 2.104e-01 1.087e+00 1.874e-01 5.391e-02 1.347e-01
 4.040e-01 1.078e+00 3.312e-01 2.783e-01 3.423e-01 1.917e-01 1.058e-01
 9.459e-02 1.535e+00 7.721e-01 5.051e-01 1.431e+00 9.245e-02 1.614e-01
 2.722e-02 5.954e-02 2.862e-02 1.572e-02 3.150e-01 8.250e-02 3.493e-02
 1.574e-02 7.719e-02 1.188e-01 1.281e-01 7.644e-02 1.898e-02 2.525e-02]
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.]
 [0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
aucroc, aucpr (0.8514814814814815, 0.6235020987221213)
Iterations 560
Achieves (18.221862723766286, 1e-05)-DP
