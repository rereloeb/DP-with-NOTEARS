samples  5000  graph  30 120 ER mlp  minibatch size  50  noise  0.8  minibatches per NN training  250 quantile adaptive clipping
cuda
cuda
iteration 1 in inner loop,alpha 0.0 rho 1.0 h 2.407192360868244
iteration 1 in outer loop, alpha = 2.407192360868244, rho = 1.0, h = 2.407192360868244
cuda
iteration 1 in inner loop,alpha 2.407192360868244 rho 1.0 h 1.519847643277938
iteration 2 in inner loop,alpha 2.407192360868244 rho 10.0 h 0.6718194604782539
iteration 3 in inner loop,alpha 2.407192360868244 rho 100.0 h 0.21603815036024088
iteration 2 in outer loop, alpha = 24.01100739689233, rho = 100.0, h = 0.21603815036024088
cuda
iteration 1 in inner loop,alpha 24.01100739689233 rho 100.0 h 0.12140117451551191
iteration 2 in inner loop,alpha 24.01100739689233 rho 1000.0 h 0.04312326551414003
iteration 3 in outer loop, alpha = 67.13427291103235, rho = 1000.0, h = 0.04312326551414003
cuda
iteration 1 in inner loop,alpha 67.13427291103235 rho 1000.0 h 0.021341988393228206
iteration 2 in inner loop,alpha 67.13427291103235 rho 10000.0 h 0.0077222241729622
iteration 4 in outer loop, alpha = 144.35651464065435, rho = 10000.0, h = 0.0077222241729622
cuda
iteration 1 in inner loop,alpha 144.35651464065435 rho 10000.0 h 0.0037948722092586706
iteration 2 in inner loop,alpha 144.35651464065435 rho 100000.0 h 0.0011345922469878644
iteration 5 in outer loop, alpha = 257.8157393394408, rho = 100000.0, h = 0.0011345922469878644
cuda
iteration 1 in inner loop,alpha 257.8157393394408 rho 100000.0 h 0.0005542166239429491
iteration 6 in outer loop, alpha = 812.03236328239, rho = 1000000.0, h = 0.0005542166239429491
Threshold 0.3
[[0.002 0.    0.001 1.959 0.008 0.164 0.16  0.    0.    0.    0.    0.014
  0.    0.    0.    0.949 0.    0.    0.737 0.16  0.    0.    0.209 0.
  0.    0.    0.161 0.    0.255 0.   ]
 [0.413 0.003 0.003 0.141 0.209 1.56  0.235 0.    1.008 0.    0.    0.129
  0.    0.    0.    0.854 0.    1.216 0.335 0.651 0.    0.001 1.089 0.001
  0.    0.    0.17  0.    0.265 0.113]
 [0.17  0.123 0.002 0.453 0.063 0.432 0.166 0.005 0.126 0.    0.    0.17
  0.    0.    0.    0.79  0.    0.294 0.069 0.068 0.    0.    0.175 0.
  0.    0.003 0.185 0.    0.232 0.004]
 [0.    0.    0.    0.002 0.001 0.001 0.118 0.    0.    0.    0.    0.
  0.    0.    0.    0.86  0.    0.    0.169 0.649 0.    0.    0.11  0.
  0.    0.    0.    0.    0.285 0.   ]
 [0.062 0.004 0.013 0.18  0.003 0.016 0.311 0.    0.139 0.    0.    0.023
  0.    0.    0.    0.138 0.    0.001 0.71  0.186 0.    0.001 1.474 0.
  0.    0.001 0.004 0.    0.16  0.003]
 [0.001 0.    0.    0.194 0.081 0.002 1.711 0.    0.001 0.    0.    0.
  0.    0.    0.    0.226 0.    0.    0.177 0.129 0.    0.    0.273 0.
  0.    0.    0.    0.    0.844 0.   ]
 [0.    0.    0.    0.002 0.    0.    0.004 0.    0.001 0.    0.    0.
  0.    0.    0.    0.999 0.    0.    0.01  0.001 0.    0.    0.001 0.
  0.    0.    0.    0.    0.183 0.   ]
 [0.433 0.739 0.107 0.191 2.194 0.177 0.15  0.002 1.398 0.    0.    0.14
  0.    0.    0.    0.546 0.    0.306 0.162 0.745 0.    0.002 0.314 0.001
  0.    0.006 0.165 0.    0.503 0.275]
 [1.215 0.    0.001 0.267 0.004 0.105 0.158 0.    0.002 0.    0.    0.251
  0.    0.    0.    0.08  0.    0.    0.281 0.902 0.    0.    0.141 0.
  0.    0.    0.109 0.    0.15  0.   ]
 [0.291 0.957 0.17  0.298 0.272 0.35  0.179 0.308 1.054 0.001 0.    0.21
  2.238 0.139 0.008 0.317 0.001 0.393 0.227 0.105 0.002 0.483 0.485 0.087
  0.    0.169 0.25  0.003 0.318 1.867]
 [1.674 1.8   0.314 0.163 0.128 0.327 0.246 1.96  0.277 1.274 0.002 0.062
  0.173 0.291 0.004 1.118 0.    0.284 0.224 0.171 0.019 0.09  0.277 0.02
  0.    0.209 0.077 0.016 1.076 0.411]
 [0.072 0.001 0.002 0.191 0.04  0.135 0.913 0.001 0.005 0.    0.    0.001
  0.    0.    0.    0.376 0.    0.    0.237 0.135 0.    0.    0.133 0.
  0.    0.    0.951 0.    0.186 0.   ]
 [0.152 1.62  0.099 0.234 2.334 0.387 0.32  1.369 0.864 0.    0.    1.778
  0.001 0.    0.    0.267 0.    0.182 0.628 0.12  0.    2.58  0.507 0.003
  0.    0.032 1.088 0.    0.319 0.261]
 [0.219 0.173 2.761 1.175 0.132 1.693 0.321 0.152 0.431 0.002 0.002 0.49
  0.287 0.001 0.    0.487 0.    1.743 0.396 0.228 0.    0.116 0.303 2.621
  0.    0.525 0.369 0.007 0.223 2.43 ]
 [0.208 0.864 0.065 0.309 0.228 0.243 0.495 0.279 0.264 0.024 0.018 0.69
  2.509 0.081 0.002 0.178 0.    0.173 0.201 0.169 0.368 0.627 0.996 3.578
  0.006 0.102 0.451 0.003 0.479 0.273]
 [0.    0.    0.    0.    0.    0.    0.001 0.    0.    0.    0.    0.
  0.    0.    0.    0.004 0.    0.    0.006 0.001 0.    0.    0.    0.
  0.    0.    0.    0.    0.192 0.   ]
 [0.207 0.234 0.149 0.092 0.345 1.074 0.557 0.334 0.558 0.129 0.077 0.128
  1.089 0.093 3.023 0.49  0.001 0.026 0.213 0.085 0.723 1.357 0.207 0.331
  0.002 0.053 0.137 0.005 0.252 0.149]
 [0.145 0.001 0.001 0.33  0.176 0.265 0.18  0.    1.097 0.    0.    0.214
  0.    0.    0.    0.217 0.    0.001 0.733 0.262 0.    0.    0.381 0.
  0.    0.    0.772 0.    0.152 0.001]
 [0.001 0.    0.001 0.001 0.    0.001 0.146 0.    0.    0.    0.    0.
  0.    0.    0.    0.158 0.    0.    0.012 0.001 0.    0.    0.006 0.
  0.    0.    0.001 0.    0.011 0.   ]
 [0.    0.    0.001 0.002 0.001 0.002 0.2   0.001 0.    0.    0.    0.
  0.    0.    0.    0.276 0.    0.    0.727 0.004 0.    0.    0.155 0.
  0.    0.    0.    0.    0.458 0.   ]
 [0.187 0.523 0.204 0.364 1.874 1.017 0.218 1.108 0.183 0.083 0.024 0.214
  0.225 3.744 0.001 0.183 0.001 0.214 0.236 0.056 0.001 1.73  0.707 0.074
  0.    2.437 0.249 0.003 0.218 0.149]
 [0.088 0.237 2.482 1.115 1.581 0.213 0.638 0.353 0.456 0.    0.    0.355
  0.    0.    0.    0.259 0.    2.291 0.31  0.222 0.    0.001 0.451 0.
  0.    0.004 0.315 0.    0.568 2.119]
 [0.001 0.001 0.001 0.003 0.    0.001 0.95  0.    0.002 0.    0.    0.
  0.    0.    0.    0.27  0.    0.    0.591 0.005 0.    0.    0.005 0.
  0.    0.    0.001 0.    0.118 0.   ]
 [2.074 0.293 0.106 0.26  0.202 0.156 1.031 0.164 0.517 0.002 0.001 2.155
  0.253 0.    0.    0.829 0.    0.086 0.81  0.816 0.    0.26  0.537 0.002
  0.    0.015 1.556 0.    0.125 0.127]
 [0.234 0.429 0.71  0.143 0.157 0.534 0.547 0.277 0.123 1.156 4.371 0.153
  0.187 2.16  0.042 0.143 0.012 0.398 0.167 0.077 0.031 0.119 0.912 0.104
  0.001 2.796 0.113 0.003 0.245 0.926]
 [0.218 1.734 0.168 0.085 0.167 0.24  0.169 0.108 0.191 0.003 0.004 0.098
  0.016 0.    0.    0.096 0.    0.116 0.329 0.152 0.    0.123 1.338 0.036
  0.    0.003 0.068 0.    0.109 0.121]
 [0.002 0.    0.001 1.573 0.098 1.778 0.413 0.    0.001 0.    0.    0.
  0.    0.    0.    0.818 0.    0.    0.93  0.22  0.    0.    1.38  0.
  0.    0.    0.003 0.    0.818 0.   ]
 [2.089 0.359 0.18  0.259 0.13  0.222 0.16  0.091 0.255 0.013 0.008 0.988
  0.008 0.016 0.021 0.211 0.017 0.119 0.164 0.063 0.002 0.053 0.937 0.03
  0.003 2.994 0.14  0.    0.133 0.095]
 [0.001 0.001 0.    0.004 0.003 0.001 0.005 0.001 0.001 0.    0.    0.001
  0.    0.    0.    0.033 0.    0.    0.099 0.01  0.    0.    0.003 0.
  0.    0.    0.001 0.    0.01  0.   ]
 [0.258 0.006 0.228 0.493 0.137 0.236 0.238 0.002 0.572 0.    0.    1.971
  0.    0.    0.    0.265 0.    0.322 0.66  0.185 0.    0.    0.188 0.001
  0.    0.001 0.748 0.    0.115 0.002]]
[[0.    0.    0.    1.959 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.949 0.    0.    0.737 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.413 0.    0.    0.    0.    1.56  0.    0.    1.008 0.    0.    0.
  0.    0.    0.    0.854 0.    1.216 0.335 0.651 0.    0.    1.089 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.453 0.    0.432 0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.79  0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.86  0.    0.    0.    0.649 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.311 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.71  0.    0.    0.    1.474 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    1.711 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.844 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.999 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.433 0.739 0.    0.    2.194 0.    0.    0.    1.398 0.    0.    0.
  0.    0.    0.    0.546 0.    0.306 0.    0.745 0.    0.    0.314 0.
  0.    0.    0.    0.    0.503 0.   ]
 [1.215 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.902 0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.957 0.    0.    0.    0.35  0.    0.308 1.054 0.    0.    0.
  2.238 0.    0.    0.317 0.    0.393 0.    0.    0.    0.483 0.485 0.
  0.    0.    0.    0.    0.318 1.867]
 [1.674 1.8   0.314 0.    0.    0.327 0.    1.96  0.    1.274 0.    0.
  0.    0.    0.    1.118 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    1.076 0.411]
 [0.    0.    0.    0.    0.    0.    0.913 0.    0.    0.    0.    0.
  0.    0.    0.    0.376 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.951 0.    0.    0.   ]
 [0.    1.62  0.    0.    2.334 0.387 0.32  1.369 0.864 0.    0.    1.778
  0.    0.    0.    0.    0.    0.    0.628 0.    0.    2.58  0.507 0.
  0.    0.    1.088 0.    0.319 0.   ]
 [0.    0.    2.761 1.175 0.    1.693 0.321 0.    0.431 0.    0.    0.49
  0.    0.    0.    0.487 0.    1.743 0.396 0.    0.    0.    0.303 2.621
  0.    0.525 0.369 0.    0.    2.43 ]
 [0.    0.864 0.    0.309 0.    0.    0.495 0.    0.    0.    0.    0.69
  2.509 0.    0.    0.    0.    0.    0.    0.    0.368 0.627 0.996 3.578
  0.    0.    0.451 0.    0.479 0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.345 1.074 0.557 0.334 0.558 0.    0.    0.
  1.089 0.    3.023 0.49  0.    0.    0.    0.    0.723 1.357 0.    0.331
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.33  0.    0.    0.    0.    1.097 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.733 0.    0.    0.    0.381 0.
  0.    0.    0.772 0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.727 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.458 0.   ]
 [0.    0.523 0.    0.364 1.874 1.017 0.    1.108 0.    0.    0.    0.
  0.    3.744 0.    0.    0.    0.    0.    0.    0.    1.73  0.707 0.
  0.    2.437 0.    0.    0.    0.   ]
 [0.    0.    2.482 1.115 1.581 0.    0.638 0.353 0.456 0.    0.    0.355
  0.    0.    0.    0.    0.    2.291 0.31  0.    0.    0.    0.451 0.
  0.    0.    0.315 0.    0.568 2.119]
 [0.    0.    0.    0.    0.    0.    0.95  0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.591 0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [2.074 0.    0.    0.    0.    0.    1.031 0.    0.517 0.    0.    2.155
  0.    0.    0.    0.829 0.    0.    0.81  0.816 0.    0.    0.537 0.
  0.    0.    1.556 0.    0.    0.   ]
 [0.    0.429 0.71  0.    0.    0.534 0.547 0.    0.    1.156 4.371 0.
  0.    2.16  0.    0.    0.    0.398 0.    0.    0.    0.    0.912 0.
  0.    2.796 0.    0.    0.    0.926]
 [0.    1.734 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.329 0.    0.    0.    1.338 0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    1.573 0.    1.778 0.413 0.    0.    0.    0.    0.
  0.    0.    0.    0.818 0.    0.    0.93  0.    0.    0.    1.38  0.
  0.    0.    0.    0.    0.818 0.   ]
 [2.089 0.359 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.988
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.937 0.
  0.    2.994 0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.493 0.    0.    0.    0.    0.572 0.    0.    1.971
  0.    0.    0.    0.    0.    0.322 0.66  0.    0.    0.    0.    0.
  0.    0.    0.748 0.    0.    0.   ]]
{'fdr': 0.3465909090909091, 'tpr': 0.9583333333333334, 'fpr': 0.19365079365079366, 'f1': 0.7770270270270269, 'shd': 66, 'npred': 176, 'ntrue': 120}
[2.665e-04 7.555e-04 1.959e+00 8.417e-03 1.642e-01 1.601e-01 5.491e-05
 4.782e-04 1.776e-05 1.252e-05 1.439e-02 1.434e-05 2.014e-05 3.924e-05
 9.495e-01 2.406e-05 7.928e-05 7.366e-01 1.602e-01 7.528e-07 4.130e-05
 2.085e-01 1.993e-04 2.248e-06 1.165e-04 1.613e-01 2.855e-05 2.552e-01
 1.115e-04 4.129e-01 2.798e-03 1.413e-01 2.089e-01 1.560e+00 2.349e-01
 1.527e-04 1.008e+00 1.707e-04 8.963e-05 1.288e-01 2.124e-04 1.056e-04
 1.086e-04 8.540e-01 5.102e-05 1.216e+00 3.352e-01 6.514e-01 1.439e-05
 1.124e-03 1.089e+00 6.614e-04 2.763e-07 3.826e-04 1.695e-01 1.327e-05
 2.649e-01 1.127e-01 1.696e-01 1.232e-01 4.529e-01 6.325e-02 4.323e-01
 1.659e-01 4.933e-03 1.255e-01 1.572e-06 2.539e-05 1.699e-01 2.820e-05
 2.219e-04 4.225e-06 7.899e-01 5.833e-06 2.940e-01 6.863e-02 6.846e-02
 1.829e-05 1.081e-04 1.751e-01 3.298e-04 1.824e-05 2.501e-03 1.852e-01
 1.247e-04 2.318e-01 3.861e-03 1.018e-04 8.889e-05 1.700e-04 8.149e-04
 1.444e-03 1.181e-01 4.464e-05 1.369e-04 4.075e-06 1.408e-05 7.076e-05
 1.575e-05 1.870e-05 1.961e-06 8.605e-01 4.578e-06 2.336e-05 1.688e-01
 6.489e-01 5.978e-06 1.300e-05 1.096e-01 2.118e-05 1.038e-05 3.883e-05
 5.759e-05 1.510e-05 2.845e-01 3.684e-05 6.152e-02 4.077e-03 1.292e-02
 1.800e-01 1.605e-02 3.110e-01 3.020e-04 1.385e-01 2.697e-05 7.060e-06
 2.323e-02 5.611e-05 2.451e-05 1.579e-05 1.383e-01 1.484e-06 7.415e-04
 7.101e-01 1.857e-01 6.251e-06 5.665e-04 1.474e+00 2.811e-04 8.492e-07
 5.031e-04 4.281e-03 1.269e-04 1.603e-01 3.244e-03 7.506e-04 3.649e-04
 6.086e-05 1.937e-01 8.116e-02 1.711e+00 3.675e-04 1.491e-03 2.487e-05
 3.587e-05 7.617e-05 5.856e-05 8.604e-06 6.703e-06 2.259e-01 3.042e-06
 1.833e-04 1.769e-01 1.285e-01 2.742e-06 1.341e-05 2.730e-01 2.838e-05
 1.634e-06 4.981e-05 7.250e-05 1.132e-05 8.443e-01 4.032e-05 4.255e-04
 1.387e-04 2.536e-04 1.528e-03 2.371e-04 3.288e-04 1.130e-04 7.880e-04
 2.172e-06 2.332e-05 1.175e-04 2.789e-05 6.077e-06 1.430e-05 9.988e-01
 9.746e-06 3.513e-05 1.022e-02 1.188e-03 1.908e-06 1.463e-05 6.519e-04
 9.933e-05 3.654e-06 1.477e-05 2.903e-05 8.438e-06 1.833e-01 1.429e-05
 4.328e-01 7.388e-01 1.069e-01 1.910e-01 2.194e+00 1.771e-01 1.501e-01
 1.398e+00 3.459e-05 3.823e-05 1.396e-01 1.790e-04 9.688e-05 1.861e-05
 5.456e-01 5.553e-06 3.058e-01 1.621e-01 7.450e-01 5.286e-06 1.540e-03
 3.141e-01 1.246e-03 5.943e-06 5.709e-03 1.647e-01 1.545e-04 5.025e-01
 2.746e-01 1.215e+00 2.542e-04 1.217e-03 2.672e-01 3.915e-03 1.054e-01
 1.582e-01 6.377e-05 3.908e-06 3.314e-05 2.511e-01 2.897e-05 9.011e-06
 1.093e-05 8.011e-02 1.204e-05 1.891e-04 2.813e-01 9.020e-01 4.930e-06
 5.798e-05 1.409e-01 1.745e-04 6.168e-07 2.156e-04 1.088e-01 1.334e-05
 1.504e-01 1.406e-04 2.910e-01 9.570e-01 1.696e-01 2.980e-01 2.724e-01
 3.504e-01 1.794e-01 3.078e-01 1.054e+00 1.070e-04 2.097e-01 2.238e+00
 1.393e-01 8.117e-03 3.170e-01 6.193e-04 3.925e-01 2.272e-01 1.048e-01
 2.168e-03 4.827e-01 4.846e-01 8.660e-02 3.017e-05 1.694e-01 2.505e-01
 3.231e-03 3.180e-01 1.867e+00 1.674e+00 1.800e+00 3.136e-01 1.628e-01
 1.280e-01 3.272e-01 2.458e-01 1.960e+00 2.768e-01 1.274e+00 6.185e-02
 1.730e-01 2.908e-01 4.457e-03 1.118e+00 2.570e-04 2.843e-01 2.242e-01
 1.707e-01 1.921e-02 8.952e-02 2.766e-01 1.997e-02 1.970e-04 2.092e-01
 7.712e-02 1.591e-02 1.076e+00 4.112e-01 7.174e-02 1.348e-03 2.418e-03
 1.908e-01 4.046e-02 1.346e-01 9.129e-01 7.411e-04 5.417e-03 2.537e-05
 1.826e-05 2.500e-05 1.181e-05 3.602e-06 3.761e-01 1.167e-05 1.566e-04
 2.371e-01 1.352e-01 2.362e-06 3.702e-05 1.327e-01 5.539e-05 4.454e-06
 4.642e-04 9.508e-01 6.228e-05 1.859e-01 2.322e-04 1.519e-01 1.620e+00
 9.918e-02 2.336e-01 2.334e+00 3.872e-01 3.204e-01 1.369e+00 8.639e-01
 1.699e-04 5.389e-05 1.778e+00 1.376e-04 7.899e-05 2.673e-01 2.471e-05
 1.823e-01 6.282e-01 1.198e-01 1.350e-04 2.580e+00 5.069e-01 3.299e-03
 7.992e-06 3.192e-02 1.088e+00 3.420e-04 3.188e-01 2.613e-01 2.187e-01
 1.729e-01 2.761e+00 1.175e+00 1.316e-01 1.693e+00 3.206e-01 1.520e-01
 4.315e-01 2.123e-03 1.532e-03 4.900e-01 2.867e-01 8.514e-05 4.867e-01
 1.542e-04 1.743e+00 3.959e-01 2.279e-01 1.150e-04 1.165e-01 3.028e-01
 2.621e+00 2.690e-04 5.254e-01 3.691e-01 6.691e-03 2.233e-01 2.430e+00
 2.083e-01 8.644e-01 6.494e-02 3.086e-01 2.276e-01 2.433e-01 4.945e-01
 2.795e-01 2.644e-01 2.433e-02 1.809e-02 6.899e-01 2.509e+00 8.085e-02
 1.775e-01 2.685e-04 1.728e-01 2.013e-01 1.688e-01 3.681e-01 6.271e-01
 9.958e-01 3.578e+00 5.717e-03 1.021e-01 4.508e-01 2.853e-03 4.792e-01
 2.730e-01 4.591e-05 3.740e-04 3.171e-04 1.660e-04 4.444e-04 2.178e-04
 1.186e-03 5.174e-05 9.262e-05 1.914e-05 3.666e-05 1.021e-04 4.197e-05
 1.328e-05 4.637e-06 7.970e-06 9.563e-05 6.298e-03 7.456e-04 2.956e-06
 1.398e-05 2.194e-04 3.005e-05 2.629e-06 1.316e-04 1.457e-04 2.602e-05
 1.918e-01 2.398e-05 2.070e-01 2.340e-01 1.489e-01 9.174e-02 3.455e-01
 1.074e+00 5.573e-01 3.341e-01 5.576e-01 1.285e-01 7.730e-02 1.279e-01
 1.089e+00 9.255e-02 3.023e+00 4.904e-01 2.644e-02 2.131e-01 8.487e-02
 7.232e-01 1.357e+00 2.067e-01 3.307e-01 1.862e-03 5.276e-02 1.375e-01
 5.004e-03 2.521e-01 1.487e-01 1.451e-01 5.577e-04 5.240e-04 3.304e-01
 1.759e-01 2.649e-01 1.798e-01 1.123e-04 1.097e+00 5.501e-06 1.570e-05
 2.137e-01 8.082e-06 1.166e-04 4.884e-06 2.169e-01 3.637e-07 7.329e-01
 2.617e-01 2.041e-05 1.229e-04 3.815e-01 9.754e-05 6.916e-06 1.350e-04
 7.717e-01 9.681e-06 1.524e-01 9.289e-04 8.952e-04 4.250e-04 1.345e-03
 7.305e-04 3.364e-04 1.394e-03 1.463e-01 4.305e-05 4.600e-04 2.791e-05
 6.508e-06 4.743e-04 4.555e-05 4.542e-05 6.034e-05 1.581e-01 4.835e-05
 2.753e-04 5.740e-04 4.223e-06 6.247e-05 5.683e-03 2.637e-04 9.175e-07
 3.832e-04 8.058e-04 1.545e-05 1.119e-02 4.536e-05 2.859e-04 2.833e-04
 5.024e-04 1.836e-03 8.803e-04 2.227e-03 1.998e-01 5.008e-04 1.876e-04
 6.678e-06 1.099e-05 4.844e-04 2.214e-05 5.477e-05 4.739e-05 2.762e-01
 3.073e-05 5.356e-05 7.266e-01 1.628e-05 7.915e-06 1.549e-01 2.191e-04
 1.693e-05 1.043e-04 1.024e-04 2.359e-05 4.577e-01 1.293e-04 1.865e-01
 5.229e-01 2.041e-01 3.639e-01 1.874e+00 1.017e+00 2.177e-01 1.108e+00
 1.834e-01 8.297e-02 2.421e-02 2.140e-01 2.246e-01 3.744e+00 7.469e-04
 1.833e-01 6.782e-04 2.136e-01 2.361e-01 5.551e-02 1.730e+00 7.073e-01
 7.418e-02 1.890e-04 2.437e+00 2.491e-01 2.719e-03 2.176e-01 1.492e-01
 8.787e-02 2.369e-01 2.482e+00 1.115e+00 1.581e+00 2.127e-01 6.378e-01
 3.531e-01 4.557e-01 2.681e-05 1.000e-05 3.554e-01 3.046e-05 1.828e-05
 3.944e-06 2.590e-01 6.076e-06 2.291e+00 3.098e-01 2.221e-01 5.822e-05
 4.512e-01 2.450e-04 1.219e-06 3.664e-03 3.150e-01 4.137e-05 5.680e-01
 2.119e+00 7.134e-04 7.101e-04 6.720e-04 3.448e-03 3.284e-04 9.006e-04
 9.504e-01 4.397e-05 1.529e-03 6.326e-06 2.105e-05 3.001e-04 2.881e-05
 1.140e-05 3.512e-06 2.697e-01 2.696e-06 9.193e-05 5.906e-01 4.958e-03
 2.710e-06 4.758e-05 2.123e-05 7.424e-06 1.500e-04 9.529e-04 3.618e-06
 1.177e-01 6.760e-05 2.074e+00 2.928e-01 1.065e-01 2.599e-01 2.018e-01
 1.558e-01 1.031e+00 1.642e-01 5.169e-01 1.622e-03 7.704e-04 2.155e+00
 2.531e-01 9.581e-05 1.905e-04 8.290e-01 6.525e-05 8.642e-02 8.100e-01
 8.163e-01 6.173e-06 2.604e-01 5.365e-01 6.507e-05 1.461e-02 1.556e+00
 7.144e-05 1.245e-01 1.267e-01 2.341e-01 4.287e-01 7.104e-01 1.433e-01
 1.574e-01 5.342e-01 5.470e-01 2.770e-01 1.225e-01 1.156e+00 4.371e+00
 1.533e-01 1.871e-01 2.160e+00 4.203e-02 1.432e-01 1.221e-02 3.981e-01
 1.674e-01 7.745e-02 3.143e-02 1.192e-01 9.120e-01 1.042e-01 2.796e+00
 1.128e-01 2.699e-03 2.449e-01 9.262e-01 2.182e-01 1.734e+00 1.676e-01
 8.543e-02 1.670e-01 2.397e-01 1.689e-01 1.082e-01 1.910e-01 2.839e-03
 4.233e-03 9.804e-02 1.588e-02 4.172e-04 1.527e-04 9.564e-02 8.440e-05
 1.162e-01 3.292e-01 1.523e-01 4.214e-05 1.233e-01 1.338e+00 3.612e-02
 4.073e-04 6.756e-02 8.453e-05 1.087e-01 1.208e-01 1.624e-03 1.440e-04
 6.752e-04 1.573e+00 9.754e-02 1.778e+00 4.126e-01 4.507e-04 9.942e-04
 1.215e-05 3.051e-05 4.765e-04 1.992e-05 4.217e-05 4.960e-06 8.180e-01
 6.731e-06 1.477e-04 9.302e-01 2.199e-01 3.591e-06 4.890e-05 1.380e+00
 3.959e-05 1.129e-06 1.362e-04 1.759e-05 8.175e-01 9.941e-05 2.089e+00
 3.590e-01 1.796e-01 2.586e-01 1.303e-01 2.216e-01 1.600e-01 9.146e-02
 2.555e-01 1.315e-02 7.690e-03 9.878e-01 8.467e-03 1.599e-02 2.070e-02
 2.109e-01 1.742e-02 1.195e-01 1.639e-01 6.328e-02 1.944e-03 5.251e-02
 9.365e-01 3.047e-02 3.013e-03 2.994e+00 1.403e-01 1.327e-01 9.463e-02
 1.000e-03 5.565e-04 4.881e-04 3.525e-03 3.182e-03 1.383e-03 4.672e-03
 1.398e-03 7.057e-04 1.266e-05 1.477e-04 1.017e-03 3.173e-05 3.204e-05
 3.728e-05 3.271e-02 4.449e-05 2.811e-04 9.943e-02 1.019e-02 1.157e-05
 1.194e-04 2.901e-03 1.449e-04 6.628e-05 6.452e-05 1.263e-03 4.900e-06
 1.982e-04 2.575e-01 5.977e-03 2.280e-01 4.934e-01 1.373e-01 2.357e-01
 2.381e-01 1.850e-03 5.716e-01 3.040e-05 5.204e-05 1.971e+00 4.179e-05
 1.162e-04 3.622e-06 2.653e-01 5.439e-06 3.224e-01 6.600e-01 1.849e-01
 2.057e-05 1.166e-04 1.881e-01 5.052e-04 2.369e-05 9.427e-04 7.476e-01
 6.324e-05 1.146e-01]
[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 1.]
 [1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 0. 1.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.
  0. 1. 1. 0. 0. 0.]
 [0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
  0. 1. 0. 0. 0. 1.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1.
 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0.]
aucroc, aucpr (0.9875666666666667, 0.9629081005131049)
cuda
noise_multiplier  0.8  noise_multiplier_b  2.5  noise_multiplier_delta  0.8104408984731079
cuda
Objective function 1220.30 = squared loss an data 964.29 + 0.5*rho*h**2 254.631624 + alpha*h 0.000000 + L2reg 0.55 + L1reg 0.82 ; SHD = 397 ; DAG False
total norm for a microbatch 130.856286781375 clip 1.8511579101054196
total norm for a microbatch 116.74748160580417 clip 93.14183265517896
total norm for a microbatch 153.5947980131296 clip 104.94604715622475
total norm for a microbatch 233.17464969674737 clip 107.91485091311826
total norm for a microbatch 95.84653480797498 clip 121.93034824088963
total norm for a microbatch 173.27020922919547 clip 110.5889959784441
total norm for a microbatch 213.788399893209 clip 119.87336898312411
total norm for a microbatch 150.55240593630117 clip 120.0672709880198
total norm for a microbatch 229.05875007420326 clip 154.98008627276022
total norm for a microbatch 181.13124020107296 clip 144.24061789033811
total norm for a microbatch 323.03838479581157 clip 150.59737917289254
total norm for a microbatch 180.97374134982906 clip 149.60501974069786
cuda
Objective function 101.11 = squared loss an data 78.36 + 0.5*rho*h**2 20.325333 + alpha*h 0.000000 + L2reg 1.80 + L1reg 0.63 ; SHD = 252 ; DAG False
Proportion of microbatches that were clipped  0.8242370418214112
iteration 1 in inner loop, alpha 0.0 rho 1.0 h 6.375787450834181
iteration 1 in outer loop, alpha = 6.375787450834181, rho = 1.0, h = 6.375787450834181
cuda
noise_multiplier  0.8  noise_multiplier_b  2.5  noise_multiplier_delta  0.8104408984731079
cuda
Objective function 141.76 = squared loss an data 78.36 + 0.5*rho*h**2 20.325333 + alpha*h 40.650666 + L2reg 1.80 + L1reg 0.63 ; SHD = 252 ; DAG False
total norm for a microbatch 193.80205611746163 clip 2.9274048785051345
total norm for a microbatch 161.84538512967083 clip 9.827362307325945
total norm for a microbatch 115.4745646854081 clip 12.751562309647179
total norm for a microbatch 224.41424760162397 clip 198.77466664843158
total norm for a microbatch 168.35753187719365 clip 214.68215786785333
total norm for a microbatch 214.07602601011808 clip 205.0817694256765
total norm for a microbatch 318.92546516208034 clip 197.83957318530773
total norm for a microbatch 213.52339561754934 clip 197.56031714884824
cuda
Objective function 108.34 = squared loss an data 68.43 + 0.5*rho*h**2 9.395606 + alpha*h 27.638293 + L2reg 2.29 + L1reg 0.59 ; SHD = 241 ; DAG False
Proportion of microbatches that were clipped  0.8256656624053416
iteration 1 in inner loop, alpha 6.375787450834181 rho 1.0 h 4.334883059441864
noise_multiplier  0.8  noise_multiplier_b  2.5  noise_multiplier_delta  0.8104408984731079
cuda
Objective function 192.90 = squared loss an data 68.43 + 0.5*rho*h**2 93.956056 + alpha*h 27.638293 + L2reg 2.29 + L1reg 0.59 ; SHD = 241 ; DAG False
total norm for a microbatch 275.66047692103314 clip 3.259756890234208
total norm for a microbatch 238.10660240919657 clip 235.16753178200145
total norm for a microbatch 497.0469843604002 clip 287.28697747549467
total norm for a microbatch 355.1652803624842 clip 266.18700712745357
total norm for a microbatch 293.73960345565996 clip 273.01903947083184
total norm for a microbatch 476.1393413093659 clip 254.72389785547455
total norm for a microbatch 336.68820400789286 clip 243.42677599592594
total norm for a microbatch 346.09598304653593 clip 256.1847980111505
total norm for a microbatch 227.17243069631382 clip 267.2925382949083
total norm for a microbatch 641.4144075624877 clip 261.85183874063097
total norm for a microbatch 310.97190503215666 clip 263.3042887147631
total norm for a microbatch 370.30598070014224 clip 264.34576499784686
total norm for a microbatch 492.96057912493717 clip 254.88095294589124
cuda
Objective function 106.73 = squared loss an data 69.85 + 0.5*rho*h**2 20.768510 + alpha*h 12.994258 + L2reg 2.58 + L1reg 0.54 ; SHD = 226 ; DAG False
Proportion of microbatches that were clipped  0.8306801736613604
iteration 2 in inner loop, alpha 6.375787450834181 rho 10.0 h 2.0380632995392816
noise_multiplier  0.8  noise_multiplier_b  2.5  noise_multiplier_delta  0.8104408984731079
cuda
Objective function 293.65 = squared loss an data 69.85 + 0.5*rho*h**2 207.685101 + alpha*h 12.994258 + L2reg 2.58 + L1reg 0.54 ; SHD = 226 ; DAG False
total norm for a microbatch 476.7960572632633 clip 1.0
total norm for a microbatch 304.0787090942781 clip 6.895783329617075
total norm for a microbatch 432.6643372917455 clip 6.895783329617075
total norm for a microbatch 883.0504417120279 clip 18.477762008719147
total norm for a microbatch 334.8542540464518 clip 31.29476782379229
total norm for a microbatch 367.1023560256805 clip 131.53104764267604
total norm for a microbatch 515.904186670218 clip 312.8422556080757
total norm for a microbatch 472.028836760816 clip 325.4180968733265
total norm for a microbatch 303.24509457455207 clip 314.20288649212597
total norm for a microbatch 384.97927460429537 clip 304.8530437678147
total norm for a microbatch 326.3565579917481 clip 310.05774551114905
total norm for a microbatch 556.2085272961584 clip 317.70058350498556
total norm for a microbatch 319.9557761984764 clip 314.8813632684098
total norm for a microbatch 586.8795803081847 clip 318.14195003191617
total norm for a microbatch 323.76997895648356 clip 306.5334194523789
total norm for a microbatch 293.39775306139796 clip 293.65656148514796
total norm for a microbatch 251.95039759769557 clip 310.5180994908702
cuda
Objective function 118.62 = squared loss an data 75.98 + 0.5*rho*h**2 34.108985 + alpha*h 5.266029 + L2reg 2.79 + L1reg 0.47 ; SHD = 205 ; DAG True
Proportion of microbatches that were clipped  0.83239905760013
iteration 3 in inner loop, alpha 6.375787450834181 rho 100.0 h 0.8259417072342607
iteration 2 in outer loop, alpha = 88.96995817426026, rho = 100.0, h = 0.8259417072342607
cuda
noise_multiplier  0.8  noise_multiplier_b  2.5  noise_multiplier_delta  0.8104408984731079
cuda
Objective function 186.84 = squared loss an data 75.98 + 0.5*rho*h**2 34.108985 + alpha*h 73.483999 + L2reg 2.79 + L1reg 0.47 ; SHD = 205 ; DAG True
total norm for a microbatch 297.71704720423395 clip 1.2929899128129856
total norm for a microbatch 742.9964253153375 clip 2.2065959255337204
total norm for a microbatch 418.90779180276354 clip 2.883073826190332
total norm for a microbatch 526.6617869984948 clip 9.253742714706249
total norm for a microbatch 319.7412945377811 clip 46.044480722296804
total norm for a microbatch 397.8384642896534 clip 366.04625010174914
total norm for a microbatch 475.2304624516873 clip 377.22767274698936
total norm for a microbatch 274.62059918074766 clip 369.866190374446
total norm for a microbatch 463.5349986592823 clip 360.829044192417
total norm for a microbatch 561.9337392654036 clip 364.63701583901695
total norm for a microbatch 384.851022448119 clip 365.6588432463923
total norm for a microbatch 566.7280005546402 clip 339.6548889762711
total norm for a microbatch 415.1007500591887 clip 352.8983070251817
total norm for a microbatch 591.2836524558243 clip 345.3647056661499
total norm for a microbatch 428.0473313091079 clip 341.84352971030427
cuda
Objective function 137.72 = squared loss an data 76.53 + 0.5*rho*h**2 12.791871 + alpha*h 45.001337 + L2reg 2.95 + L1reg 0.45 ; SHD = 198 ; DAG True
Proportion of microbatches that were clipped  0.8305838589681385
iteration 1 in inner loop, alpha 88.96995817426026 rho 100.0 h 0.5058037338138988
noise_multiplier  0.8  noise_multiplier_b  2.5  noise_multiplier_delta  0.8104408984731079
cuda
Objective function 252.85 = squared loss an data 76.53 + 0.5*rho*h**2 127.918709 + alpha*h 45.001337 + L2reg 2.95 + L1reg 0.45 ; SHD = 198 ; DAG True
total norm for a microbatch 456.0477365610056 clip 1.6994152444932447
total norm for a microbatch 497.9046179256093 clip 3.737997185022944
total norm for a microbatch 397.40086540057456 clip 384.1192337797131
total norm for a microbatch 602.2239225384408 clip 384.1192337797131
total norm for a microbatch 482.4128924038434 clip 437.7161206865734
total norm for a microbatch 421.95315071090846 clip 444.2549687043722
total norm for a microbatch 430.0662569354584 clip 450.1936674925688
total norm for a microbatch 521.6645606597872 clip 477.1635389947429
total norm for a microbatch 657.4479871999378 clip 421.0766993246537
total norm for a microbatch 485.7328607054252 clip 400.97950724206095
total norm for a microbatch 326.17479397715454 clip 410.1892567939701
total norm for a microbatch 591.2774843019776 clip 410.1892567939701
total norm for a microbatch 379.84110628034506 clip 365.1230397746421
total norm for a microbatch 451.7245417674699 clip 379.080715740938
cuda
Objective function 140.52 = squared loss an data 79.68 + 0.5*rho*h**2 33.971396 + alpha*h 23.190765 + L2reg 3.24 + L1reg 0.44 ; SHD = 206 ; DAG True
Proportion of microbatches that were clipped  0.8372759856630825
iteration 2 in inner loop, alpha 88.96995817426026 rho 1000.0 h 0.2606583833197931
noise_multiplier  0.8  noise_multiplier_b  2.5  noise_multiplier_delta  0.8104408984731079
cuda
Objective function 446.27 = squared loss an data 79.68 + 0.5*rho*h**2 339.713964 + alpha*h 23.190765 + L2reg 3.24 + L1reg 0.44 ; SHD = 206 ; DAG True
total norm for a microbatch 850.6447743908855 clip 1.3285360296189497
total norm for a microbatch 461.72417411578266 clip 2.342497264749504
total norm for a microbatch 659.740493613426 clip 87.65018397465717
total norm for a microbatch 830.5315177567193 clip 114.91415144227943
total norm for a microbatch 653.3691446369786 clip 124.55547421293674
total norm for a microbatch 926.0463647649764 clip 755.2038650610874
total norm for a microbatch 598.7168483686534 clip 618.728951521223
total norm for a microbatch 633.6208654303111 clip 558.3615686608168
total norm for a microbatch 922.747950094337 clip 437.02915011886654
total norm for a microbatch 617.7417147093719 clip 442.6655629452504
total norm for a microbatch 448.39443050862644 clip 454.5117729393602
total norm for a microbatch 445.0371109327622 clip 454.5117729393602
cuda
Objective function 131.30 = squared loss an data 82.40 + 0.5*rho*h**2 37.318668 + alpha*h 7.686373 + L2reg 3.47 + L1reg 0.42 ; SHD = 209 ; DAG True
Proportion of microbatches that were clipped  0.8376524998006538
iteration 3 in inner loop, alpha 88.96995817426026 rho 10000.0 h 0.08639290206138384
iteration 3 in outer loop, alpha = 952.8989787880986, rho = 10000.0, h = 0.08639290206138384
cuda
noise_multiplier  0.8  noise_multiplier_b  2.5  noise_multiplier_delta  0.8104408984731079
cuda
Objective function 205.93 = squared loss an data 82.40 + 0.5*rho*h**2 37.318668 + alpha*h 82.323708 + L2reg 3.47 + L1reg 0.42 ; SHD = 209 ; DAG True
total norm for a microbatch 614.5036896130404 clip 1.0
total norm for a microbatch 680.1039783260627 clip 64.33751086047766
total norm for a microbatch 932.6521784147724 clip 848.0724406696329
total norm for a microbatch 997.7932709288086 clip 993.181033127989
total norm for a microbatch 567.8236619086989 clip 589.2514651548128
total norm for a microbatch 527.2993390349665 clip 501.9207584496647
total norm for a microbatch 661.8254426112306 clip 474.52928450978465
total norm for a microbatch 610.5844983244241 clip 501.01255186228843
total norm for a microbatch 659.2811695771034 clip 506.6825662080655
total norm for a microbatch 447.25834137054846 clip 468.4211771568612
total norm for a microbatch 583.6295377810083 clip 532.3303279064025
cuda
Objective function 147.30 = squared loss an data 81.28 + 0.5*rho*h**2 13.135402 + alpha*h 48.840887 + L2reg 3.62 + L1reg 0.43 ; SHD = 216 ; DAG True
Proportion of microbatches that were clipped  0.8376896798283944
iteration 1 in inner loop, alpha 952.8989787880986 rho 10000.0 h 0.051255052824664915
noise_multiplier  0.8  noise_multiplier_b  2.5  noise_multiplier_delta  0.8104408984731079
cuda
Objective function 265.52 = squared loss an data 81.28 + 0.5*rho*h**2 131.354022 + alpha*h 48.840887 + L2reg 3.62 + L1reg 0.43 ; SHD = 216 ; DAG True
total norm for a microbatch 1727.6689532773871 clip 35.839554808996
total norm for a microbatch 2177.59328269312 clip 125.24951506921897
total norm for a microbatch 3903.494219051519 clip 959.7479506671381
total norm for a microbatch 4599.480753393572 clip 1058.3237124612149
total norm for a microbatch 4614.827183348783 clip 1058.3237124612149
total norm for a microbatch 10720.1627128257 clip 8934.609091020506
total norm for a microbatch 6180.711833582711 clip 6663.92518145743
total norm for a microbatch 649.2125447798354 clip 603.3890310550552
total norm for a microbatch 534.1388044247543 clip 431.7838943108811
total norm for a microbatch 433.0231551620155 clip 460.5116556144629
total norm for a microbatch 699.3150319201178 clip 438.6634977118803
total norm for a microbatch 635.9255978324206 clip 443.12735092793577
total norm for a microbatch 472.10658294779967 clip 449.15523978936096
cuda
Objective function 114.98 = squared loss an data 99.09 + 0.5*rho*h**2 3.636881 + alpha*h 8.126927 + L2reg 3.71 + L1reg 0.41 ; SHD = 225 ; DAG True
Proportion of microbatches that were clipped  0.8362877997914494
iteration 2 in inner loop, alpha 952.8989787880986 rho 100000.0 h 0.008528634837837501
iteration 4 in outer loop, alpha = 1805.7624625718486, rho = 100000.0, h = 0.008528634837837501
cuda
noise_multiplier  0.8  noise_multiplier_b  2.5  noise_multiplier_delta  0.8104408984731079
cuda
Objective function 122.25 = squared loss an data 99.09 + 0.5*rho*h**2 3.636881 + alpha*h 15.400689 + L2reg 3.71 + L1reg 0.41 ; SHD = 225 ; DAG True
total norm for a microbatch 6452.576565101329 clip 1.5800104281720568
total norm for a microbatch 5024.777454512309 clip 2.0639977664832068
total norm for a microbatch 2642.976315239741 clip 3.2480238231413754
total norm for a microbatch 4660.852933811123 clip 1102.0409157606516
total norm for a microbatch 7864.5994481931375 clip 8048.398480362954
total norm for a microbatch 11302.99113902839 clip 10396.388887949224
total norm for a microbatch 10822.782331501468 clip 9188.161238781831
total norm for a microbatch 10267.209480190317 clip 11046.620023851357
total norm for a microbatch 7857.548184250856 clip 7542.521729988448
total norm for a microbatch 5600.205985622834 clip 5188.109672723858
total norm for a microbatch 5376.110820678793 clip 5637.954348060796
total norm for a microbatch 877.6787962580528 clip 826.2863626365456
total norm for a microbatch 549.8949533197604 clip 453.11273262740633
total norm for a microbatch 713.6043714112295 clip 456.6200926022304
cuda
Objective function 116.12 = squared loss an data 99.05 + 0.5*rho*h**2 1.828213 + alpha*h 10.919154 + L2reg 3.90 + L1reg 0.43 ; SHD = 222 ; DAG True
Proportion of microbatches that were clipped  0.8336544637122671
iteration 1 in inner loop, alpha 1805.7624625718486 rho 100000.0 h 0.006046838684351741
iteration 5 in outer loop, alpha = 7852.601146923589, rho = 1000000.0, h = 0.006046838684351741
Threshold 0.3
[[0.002 0.057 0.129 0.012 0.287 0.012 0.041 0.007 0.057 0.027 0.016 0.193
  0.003 0.003 0.002 0.149 0.005 0.008 0.006 0.012 0.007 0.007 0.005 0.038
  0.006 0.007 0.013 0.004 0.108 0.073]
 [0.095 0.003 0.394 0.008 0.165 0.008 0.051 0.006 0.124 0.015 0.019 0.145
  0.001 0.004 0.003 0.034 0.003 0.005 0.008 0.007 0.008 0.005 0.006 0.041
  0.016 0.017 0.023 0.009 0.028 0.055]
 [0.024 0.009 0.003 0.005 0.137 0.005 0.024 0.003 0.018 0.006 0.013 0.036
  0.001 0.002 0.001 0.007 0.003 0.002 0.005 0.004 0.006 0.004 0.003 0.008
  0.004 0.005 0.003 0.003 0.014 0.021]
 [0.22  0.284 0.662 0.003 0.644 0.144 0.276 0.008 0.267 0.112 0.098 0.492
  0.017 0.018 0.01  0.254 0.019 0.088 0.071 0.067 0.043 0.014 0.018 0.154
  0.179 0.16  0.068 0.035 0.297 0.337]
 [0.013 0.021 0.026 0.004 0.003 0.004 0.02  0.002 0.012 0.006 0.012 0.042
  0.001 0.002 0.001 0.011 0.001 0.004 0.005 0.003 0.006 0.002 0.002 0.003
  0.008 0.004 0.006 0.002 0.008 0.022]
 [0.164 0.395 0.398 0.02  0.686 0.002 0.39  0.016 0.284 0.186 0.3   0.677
  0.002 0.03  0.014 0.386 0.014 0.106 0.115 0.024 0.026 0.07  0.014 0.125
  0.242 0.207 0.154 0.058 0.232 0.276]
 [0.08  0.095 0.204 0.009 0.18  0.009 0.002 0.005 0.084 0.004 0.02  0.12
  0.003 0.002 0.004 0.015 0.003 0.006 0.018 0.004 0.007 0.004 0.006 0.042
  0.013 0.02  0.006 0.006 0.201 0.034]
 [0.385 0.452 0.908 0.369 1.316 0.201 0.558 0.004 0.467 0.193 0.369 1.283
  0.048 0.058 0.024 0.438 0.08  0.176 0.162 0.122 0.166 0.135 0.25  0.331
  0.184 0.213 0.191 0.241 0.54  0.808]
 [0.096 0.026 0.193 0.008 0.236 0.007 0.057 0.006 0.002 0.01  0.027 0.129
  0.002 0.002 0.003 0.025 0.003 0.01  0.012 0.007 0.007 0.009 0.004 0.024
  0.007 0.004 0.012 0.027 0.099 0.144]
 [0.123 0.183 0.583 0.038 0.432 0.015 0.52  0.014 0.298 0.002 0.125 0.334
  0.003 0.006 0.006 0.179 0.009 0.016 0.02  0.017 0.018 0.014 0.01  0.159
  0.044 0.09  0.086 0.059 0.396 0.219]
 [0.185 0.21  0.326 0.04  0.26  0.009 0.167 0.008 0.139 0.023 0.003 0.576
  0.007 0.022 0.003 0.09  0.012 0.007 0.039 0.018 0.032 0.012 0.011 0.043
  0.092 0.016 0.025 0.042 0.097 0.13 ]
 [0.013 0.025 0.104 0.007 0.108 0.004 0.028 0.001 0.025 0.007 0.008 0.002
  0.001 0.003 0.001 0.054 0.002 0.003 0.005 0.003 0.008 0.003 0.005 0.012
  0.009 0.002 0.009 0.009 0.043 0.013]
 [0.636 1.607 1.719 0.223 1.826 0.832 1.034 0.091 1.09  0.738 0.437 1.452
  0.003 0.082 0.089 1.169 0.466 0.363 0.8   0.359 0.742 0.41  0.501 0.366
  0.304 0.668 0.302 0.8   0.805 0.931]
 [0.78  0.787 1.354 0.263 0.78  0.114 1.065 0.088 1.05  0.459 0.221 0.753
  0.064 0.004 0.083 1.185 0.26  0.259 0.43  0.174 0.663 0.113 0.223 0.486
  0.412 0.868 0.485 0.392 0.934 0.983]
 [0.727 0.863 1.434 0.287 1.373 0.26  0.603 0.143 0.791 0.39  0.823 1.242
  0.068 0.074 0.004 0.815 0.127 0.314 0.969 0.466 0.386 0.253 0.338 0.807
  0.746 0.247 0.572 0.619 0.612 0.677]
 [0.027 0.105 0.315 0.01  0.289 0.006 0.19  0.004 0.127 0.014 0.044 0.088
  0.002 0.002 0.002 0.002 0.006 0.008 0.01  0.011 0.009 0.011 0.004 0.015
  0.016 0.01  0.017 0.011 0.025 0.045]
 [0.629 0.745 0.686 0.174 1.089 0.178 1.134 0.053 0.673 0.187 0.282 1.339
  0.007 0.013 0.029 0.335 0.003 0.116 0.172 0.131 0.131 0.224 0.047 0.721
  0.214 0.355 0.268 0.137 0.687 0.696]
 [0.276 0.553 0.782 0.035 0.458 0.035 0.438 0.022 0.439 0.327 0.22  0.773
  0.009 0.015 0.008 0.388 0.025 0.002 0.074 0.016 0.042 0.082 0.035 0.138
  0.167 0.19  0.058 0.052 0.174 0.487]
 [0.603 0.417 0.534 0.087 0.482 0.023 0.167 0.017 0.324 0.171 0.102 0.624
  0.003 0.009 0.004 0.245 0.024 0.056 0.006 0.065 0.023 0.058 0.019 0.192
  0.176 0.053 0.066 0.081 0.33  0.19 ]
 [0.289 0.494 0.722 0.076 0.826 0.166 0.536 0.054 0.38  0.115 0.198 0.489
  0.008 0.017 0.009 0.303 0.03  0.172 0.085 0.003 0.097 0.046 0.063 0.152
  0.248 0.117 0.289 0.091 0.376 0.468]
 [0.336 0.464 0.49  0.082 0.582 0.112 0.556 0.017 0.601 0.196 0.138 0.42
  0.003 0.002 0.005 0.379 0.019 0.074 0.131 0.047 0.003 0.088 0.01  0.248
  0.113 0.141 0.151 0.078 0.106 0.519]
 [0.253 0.5   0.531 0.183 0.681 0.067 0.598 0.022 0.366 0.204 0.229 0.703
  0.005 0.028 0.016 0.278 0.014 0.059 0.066 0.089 0.055 0.003 0.072 0.083
  0.15  0.159 0.171 0.151 0.359 0.452]
 [0.519 0.512 0.891 0.183 1.318 0.226 0.429 0.012 0.52  0.272 0.411 0.576
  0.006 0.02  0.012 0.52  0.071 0.086 0.247 0.058 0.209 0.069 0.004 0.099
  0.184 0.169 0.137 0.033 0.495 0.421]
 [0.156 0.139 0.355 0.018 0.712 0.027 0.128 0.008 0.19  0.018 0.112 0.218
  0.008 0.007 0.003 0.223 0.003 0.016 0.054 0.026 0.011 0.037 0.032 0.005
  0.074 0.026 0.048 0.023 0.129 0.262]
 [0.454 0.232 0.641 0.015 0.4   0.018 0.22  0.019 0.357 0.089 0.049 0.264
  0.007 0.008 0.004 0.236 0.019 0.024 0.028 0.007 0.035 0.023 0.019 0.068
  0.002 0.066 0.042 0.035 0.165 0.218]
 [0.404 0.273 0.689 0.02  0.616 0.014 0.193 0.013 0.481 0.047 0.344 0.863
  0.004 0.004 0.014 0.26  0.006 0.021 0.097 0.028 0.037 0.015 0.038 0.092
  0.089 0.004 0.076 0.079 0.49  0.32 ]
 [0.251 0.196 0.897 0.076 0.356 0.019 0.36  0.012 0.39  0.049 0.142 0.423
  0.008 0.004 0.004 0.246 0.014 0.058 0.082 0.008 0.021 0.019 0.043 0.063
  0.104 0.069 0.003 0.018 0.248 0.25 ]
 [0.56  0.337 0.863 0.108 0.631 0.075 0.339 0.017 0.16  0.076 0.102 0.351
  0.004 0.006 0.005 0.29  0.033 0.076 0.041 0.028 0.07  0.025 0.089 0.172
  0.108 0.054 0.171 0.003 0.281 0.295]
 [0.033 0.186 0.286 0.008 0.353 0.016 0.022 0.005 0.053 0.006 0.111 0.146
  0.002 0.003 0.004 0.145 0.003 0.016 0.006 0.009 0.02  0.008 0.004 0.066
  0.016 0.009 0.015 0.015 0.005 0.053]
 [0.068 0.083 0.122 0.011 0.137 0.011 0.121 0.004 0.03  0.017 0.044 0.301
  0.004 0.003 0.003 0.055 0.005 0.006 0.019 0.006 0.007 0.005 0.008 0.019
  0.017 0.013 0.013 0.011 0.1   0.003]]
[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.394 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.662 0.    0.644 0.    0.    0.    0.    0.    0.    0.492
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.337]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.395 0.398 0.    0.686 0.    0.39  0.    0.    0.    0.3   0.677
  0.    0.    0.    0.386 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.385 0.452 0.908 0.369 1.316 0.    0.558 0.    0.467 0.    0.369 1.283
  0.    0.    0.    0.438 0.    0.    0.    0.    0.    0.    0.    0.331
  0.    0.    0.    0.    0.54  0.808]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.583 0.    0.432 0.    0.52  0.    0.    0.    0.    0.334
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.396 0.   ]
 [0.    0.    0.326 0.    0.    0.    0.    0.    0.    0.    0.    0.576
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.636 1.607 1.719 0.    1.826 0.832 1.034 0.    1.09  0.738 0.437 1.452
  0.    0.    0.    1.169 0.466 0.363 0.8   0.359 0.742 0.41  0.501 0.366
  0.304 0.668 0.302 0.8   0.805 0.931]
 [0.78  0.787 1.354 0.    0.78  0.    1.065 0.    1.05  0.459 0.    0.753
  0.    0.    0.    1.185 0.    0.    0.43  0.    0.663 0.    0.    0.486
  0.412 0.868 0.485 0.392 0.934 0.983]
 [0.727 0.863 1.434 0.    1.373 0.    0.603 0.    0.791 0.39  0.823 1.242
  0.    0.    0.    0.815 0.    0.314 0.969 0.466 0.386 0.    0.338 0.807
  0.746 0.    0.572 0.619 0.612 0.677]
 [0.    0.    0.315 0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.629 0.745 0.686 0.    1.089 0.    1.134 0.    0.673 0.    0.    1.339
  0.    0.    0.    0.335 0.    0.    0.    0.    0.    0.    0.    0.721
  0.    0.355 0.    0.    0.687 0.696]
 [0.    0.553 0.782 0.    0.458 0.    0.438 0.    0.439 0.327 0.    0.773
  0.    0.    0.    0.388 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.487]
 [0.603 0.417 0.534 0.    0.482 0.    0.    0.    0.324 0.    0.    0.624
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.33  0.   ]
 [0.    0.494 0.722 0.    0.826 0.    0.536 0.    0.38  0.    0.    0.489
  0.    0.    0.    0.303 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.376 0.468]
 [0.336 0.464 0.49  0.    0.582 0.    0.556 0.    0.601 0.    0.    0.42
  0.    0.    0.    0.379 0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.519]
 [0.    0.5   0.531 0.    0.681 0.    0.598 0.    0.366 0.    0.    0.703
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.359 0.452]
 [0.519 0.512 0.891 0.    1.318 0.    0.429 0.    0.52  0.    0.411 0.576
  0.    0.    0.    0.52  0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.495 0.421]
 [0.    0.    0.355 0.    0.712 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.454 0.    0.641 0.    0.4   0.    0.    0.    0.357 0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.404 0.    0.689 0.    0.616 0.    0.    0.    0.481 0.    0.344 0.863
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.49  0.32 ]
 [0.    0.    0.897 0.    0.356 0.    0.36  0.    0.39  0.    0.    0.423
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.56  0.337 0.863 0.    0.631 0.    0.339 0.    0.    0.    0.    0.351
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.353 0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.301
  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
  0.    0.    0.    0.    0.    0.   ]]
{'fdr': 0.8095238095238095, 'tpr': 0.3, 'fpr': 0.4857142857142857, 'f1': 0.23300970873786406, 'shd': 222, 'npred': 189, 'ntrue': 120}
[5.734e-02 1.287e-01 1.235e-02 2.868e-01 1.190e-02 4.146e-02 7.362e-03
 5.665e-02 2.657e-02 1.623e-02 1.934e-01 3.075e-03 2.961e-03 2.452e-03
 1.494e-01 4.802e-03 8.044e-03 5.941e-03 1.202e-02 7.188e-03 7.062e-03
 5.460e-03 3.817e-02 5.598e-03 6.767e-03 1.323e-02 4.212e-03 1.082e-01
 7.350e-02 9.455e-02 3.942e-01 8.032e-03 1.648e-01 7.578e-03 5.050e-02
 5.731e-03 1.243e-01 1.541e-02 1.861e-02 1.452e-01 9.789e-04 3.653e-03
 3.119e-03 3.361e-02 3.195e-03 5.330e-03 8.152e-03 7.059e-03 7.669e-03
 4.634e-03 6.176e-03 4.130e-02 1.643e-02 1.699e-02 2.324e-02 8.860e-03
 2.810e-02 5.496e-02 2.357e-02 9.014e-03 4.730e-03 1.371e-01 5.023e-03
 2.382e-02 2.823e-03 1.759e-02 6.138e-03 1.289e-02 3.644e-02 1.241e-03
 1.518e-03 1.195e-03 7.228e-03 2.720e-03 2.060e-03 4.756e-03 4.022e-03
 5.904e-03 4.404e-03 2.688e-03 7.797e-03 4.447e-03 5.021e-03 2.536e-03
 2.639e-03 1.354e-02 2.087e-02 2.204e-01 2.844e-01 6.619e-01 6.445e-01
 1.439e-01 2.763e-01 7.755e-03 2.673e-01 1.118e-01 9.791e-02 4.920e-01
 1.687e-02 1.830e-02 1.034e-02 2.537e-01 1.851e-02 8.777e-02 7.072e-02
 6.710e-02 4.296e-02 1.440e-02 1.777e-02 1.545e-01 1.786e-01 1.604e-01
 6.828e-02 3.485e-02 2.969e-01 3.374e-01 1.330e-02 2.141e-02 2.603e-02
 4.303e-03 3.620e-03 1.966e-02 1.830e-03 1.207e-02 6.173e-03 1.210e-02
 4.204e-02 6.033e-04 2.454e-03 1.328e-03 1.104e-02 1.283e-03 3.811e-03
 4.520e-03 3.091e-03 5.683e-03 2.112e-03 2.091e-03 3.291e-03 7.626e-03
 3.652e-03 5.907e-03 2.249e-03 8.290e-03 2.228e-02 1.639e-01 3.951e-01
 3.981e-01 2.030e-02 6.865e-01 3.899e-01 1.568e-02 2.841e-01 1.859e-01
 3.003e-01 6.771e-01 2.387e-03 3.047e-02 1.405e-02 3.855e-01 1.399e-02
 1.056e-01 1.154e-01 2.358e-02 2.619e-02 7.044e-02 1.417e-02 1.255e-01
 2.420e-01 2.068e-01 1.535e-01 5.831e-02 2.315e-01 2.759e-01 8.022e-02
 9.504e-02 2.037e-01 9.145e-03 1.801e-01 8.750e-03 4.909e-03 8.446e-02
 3.599e-03 1.999e-02 1.201e-01 2.596e-03 2.262e-03 4.270e-03 1.511e-02
 2.597e-03 6.478e-03 1.759e-02 3.913e-03 6.731e-03 4.336e-03 6.343e-03
 4.245e-02 1.273e-02 1.994e-02 5.998e-03 5.738e-03 2.014e-01 3.440e-02
 3.851e-01 4.521e-01 9.079e-01 3.694e-01 1.316e+00 2.013e-01 5.583e-01
 4.674e-01 1.929e-01 3.690e-01 1.283e+00 4.791e-02 5.786e-02 2.379e-02
 4.376e-01 8.030e-02 1.765e-01 1.615e-01 1.221e-01 1.664e-01 1.348e-01
 2.505e-01 3.306e-01 1.843e-01 2.135e-01 1.911e-01 2.408e-01 5.400e-01
 8.079e-01 9.576e-02 2.577e-02 1.933e-01 7.812e-03 2.361e-01 7.090e-03
 5.702e-02 6.226e-03 9.989e-03 2.681e-02 1.294e-01 2.125e-03 2.004e-03
 2.781e-03 2.527e-02 3.065e-03 9.759e-03 1.229e-02 7.268e-03 7.214e-03
 8.770e-03 4.407e-03 2.351e-02 7.076e-03 4.060e-03 1.177e-02 2.739e-02
 9.889e-02 1.441e-01 1.233e-01 1.825e-01 5.826e-01 3.774e-02 4.321e-01
 1.458e-02 5.199e-01 1.400e-02 2.982e-01 1.246e-01 3.339e-01 3.208e-03
 6.397e-03 6.380e-03 1.790e-01 8.789e-03 1.598e-02 2.033e-02 1.692e-02
 1.811e-02 1.433e-02 1.033e-02 1.594e-01 4.404e-02 9.047e-02 8.632e-02
 5.872e-02 3.956e-01 2.191e-01 1.855e-01 2.097e-01 3.263e-01 4.033e-02
 2.603e-01 9.043e-03 1.670e-01 7.938e-03 1.394e-01 2.251e-02 5.757e-01
 7.324e-03 2.182e-02 2.765e-03 9.050e-02 1.206e-02 6.833e-03 3.915e-02
 1.793e-02 3.232e-02 1.165e-02 1.096e-02 4.321e-02 9.195e-02 1.611e-02
 2.538e-02 4.180e-02 9.702e-02 1.295e-01 1.315e-02 2.549e-02 1.041e-01
 6.853e-03 1.080e-01 3.817e-03 2.758e-02 7.139e-04 2.534e-02 7.115e-03
 7.907e-03 1.300e-03 2.654e-03 1.125e-03 5.437e-02 1.937e-03 2.737e-03
 4.941e-03 3.080e-03 7.910e-03 2.813e-03 5.480e-03 1.234e-02 9.164e-03
 2.095e-03 9.404e-03 8.764e-03 4.323e-02 1.255e-02 6.362e-01 1.607e+00
 1.719e+00 2.225e-01 1.826e+00 8.320e-01 1.034e+00 9.143e-02 1.090e+00
 7.376e-01 4.375e-01 1.452e+00 8.150e-02 8.909e-02 1.169e+00 4.658e-01
 3.628e-01 8.001e-01 3.590e-01 7.425e-01 4.096e-01 5.011e-01 3.663e-01
 3.044e-01 6.679e-01 3.022e-01 8.001e-01 8.047e-01 9.313e-01 7.797e-01
 7.867e-01 1.354e+00 2.630e-01 7.802e-01 1.141e-01 1.065e+00 8.792e-02
 1.050e+00 4.593e-01 2.214e-01 7.534e-01 6.390e-02 8.346e-02 1.185e+00
 2.601e-01 2.586e-01 4.304e-01 1.739e-01 6.630e-01 1.128e-01 2.227e-01
 4.859e-01 4.124e-01 8.682e-01 4.851e-01 3.923e-01 9.341e-01 9.831e-01
 7.274e-01 8.633e-01 1.434e+00 2.871e-01 1.373e+00 2.596e-01 6.031e-01
 1.427e-01 7.909e-01 3.898e-01 8.232e-01 1.242e+00 6.807e-02 7.426e-02
 8.150e-01 1.268e-01 3.143e-01 9.687e-01 4.660e-01 3.858e-01 2.530e-01
 3.381e-01 8.066e-01 7.457e-01 2.475e-01 5.724e-01 6.188e-01 6.116e-01
 6.765e-01 2.652e-02 1.047e-01 3.150e-01 1.039e-02 2.890e-01 6.471e-03
 1.898e-01 4.432e-03 1.269e-01 1.377e-02 4.360e-02 8.788e-02 2.492e-03
 2.106e-03 2.464e-03 5.946e-03 7.790e-03 9.763e-03 1.116e-02 9.265e-03
 1.088e-02 4.142e-03 1.538e-02 1.579e-02 1.012e-02 1.677e-02 1.103e-02
 2.475e-02 4.455e-02 6.287e-01 7.453e-01 6.863e-01 1.744e-01 1.089e+00
 1.783e-01 1.134e+00 5.289e-02 6.732e-01 1.871e-01 2.824e-01 1.339e+00
 6.653e-03 1.321e-02 2.862e-02 3.346e-01 1.162e-01 1.723e-01 1.310e-01
 1.311e-01 2.244e-01 4.706e-02 7.214e-01 2.144e-01 3.546e-01 2.676e-01
 1.371e-01 6.870e-01 6.963e-01 2.757e-01 5.527e-01 7.823e-01 3.514e-02
 4.579e-01 3.525e-02 4.383e-01 2.245e-02 4.389e-01 3.269e-01 2.198e-01
 7.733e-01 9.418e-03 1.500e-02 8.214e-03 3.883e-01 2.451e-02 7.375e-02
 1.634e-02 4.150e-02 8.224e-02 3.497e-02 1.377e-01 1.673e-01 1.898e-01
 5.823e-02 5.182e-02 1.738e-01 4.871e-01 6.034e-01 4.173e-01 5.342e-01
 8.747e-02 4.823e-01 2.261e-02 1.665e-01 1.725e-02 3.241e-01 1.712e-01
 1.024e-01 6.240e-01 2.740e-03 8.992e-03 4.287e-03 2.452e-01 2.432e-02
 5.608e-02 6.547e-02 2.257e-02 5.844e-02 1.872e-02 1.921e-01 1.757e-01
 5.251e-02 6.598e-02 8.112e-02 3.300e-01 1.898e-01 2.887e-01 4.942e-01
 7.216e-01 7.619e-02 8.261e-01 1.658e-01 5.357e-01 5.431e-02 3.797e-01
 1.152e-01 1.975e-01 4.895e-01 7.894e-03 1.668e-02 9.420e-03 3.032e-01
 2.980e-02 1.720e-01 8.547e-02 9.667e-02 4.610e-02 6.326e-02 1.515e-01
 2.481e-01 1.168e-01 2.887e-01 9.116e-02 3.765e-01 4.682e-01 3.363e-01
 4.636e-01 4.904e-01 8.219e-02 5.818e-01 1.124e-01 5.561e-01 1.653e-02
 6.009e-01 1.959e-01 1.383e-01 4.199e-01 3.009e-03 2.331e-03 4.594e-03
 3.785e-01 1.921e-02 7.387e-02 1.307e-01 4.685e-02 8.792e-02 1.005e-02
 2.475e-01 1.127e-01 1.407e-01 1.511e-01 7.848e-02 1.061e-01 5.192e-01
 2.534e-01 4.998e-01 5.313e-01 1.833e-01 6.811e-01 6.688e-02 5.980e-01
 2.238e-02 3.661e-01 2.041e-01 2.287e-01 7.034e-01 4.798e-03 2.850e-02
 1.612e-02 2.784e-01 1.425e-02 5.887e-02 6.588e-02 8.876e-02 5.539e-02
 7.241e-02 8.324e-02 1.504e-01 1.590e-01 1.714e-01 1.506e-01 3.594e-01
 4.518e-01 5.187e-01 5.120e-01 8.909e-01 1.832e-01 1.318e+00 2.260e-01
 4.288e-01 1.172e-02 5.203e-01 2.717e-01 4.106e-01 5.758e-01 6.176e-03
 2.018e-02 1.150e-02 5.203e-01 7.142e-02 8.560e-02 2.466e-01 5.807e-02
 2.087e-01 6.931e-02 9.885e-02 1.845e-01 1.694e-01 1.372e-01 3.304e-02
 4.949e-01 4.210e-01 1.565e-01 1.389e-01 3.555e-01 1.827e-02 7.118e-01
 2.741e-02 1.283e-01 8.109e-03 1.900e-01 1.817e-02 1.124e-01 2.183e-01
 7.755e-03 7.433e-03 3.025e-03 2.230e-01 2.889e-03 1.637e-02 5.414e-02
 2.574e-02 1.112e-02 3.718e-02 3.178e-02 7.430e-02 2.635e-02 4.757e-02
 2.272e-02 1.293e-01 2.623e-01 4.545e-01 2.316e-01 6.407e-01 1.481e-02
 4.001e-01 1.830e-02 2.199e-01 1.950e-02 3.566e-01 8.904e-02 4.897e-02
 2.635e-01 7.100e-03 8.238e-03 4.062e-03 2.364e-01 1.885e-02 2.401e-02
 2.766e-02 6.684e-03 3.548e-02 2.260e-02 1.888e-02 6.750e-02 6.606e-02
 4.229e-02 3.547e-02 1.647e-01 2.180e-01 4.042e-01 2.725e-01 6.894e-01
 2.049e-02 6.164e-01 1.448e-02 1.927e-01 1.259e-02 4.806e-01 4.674e-02
 3.441e-01 8.632e-01 3.655e-03 3.531e-03 1.405e-02 2.604e-01 5.868e-03
 2.084e-02 9.670e-02 2.798e-02 3.667e-02 1.538e-02 3.825e-02 9.184e-02
 8.914e-02 7.573e-02 7.942e-02 4.900e-01 3.200e-01 2.509e-01 1.956e-01
 8.969e-01 7.610e-02 3.558e-01 1.937e-02 3.597e-01 1.185e-02 3.905e-01
 4.925e-02 1.425e-01 4.226e-01 7.991e-03 4.422e-03 4.240e-03 2.460e-01
 1.412e-02 5.773e-02 8.196e-02 8.255e-03 2.058e-02 1.943e-02 4.273e-02
 6.274e-02 1.041e-01 6.861e-02 1.753e-02 2.480e-01 2.505e-01 5.602e-01
 3.371e-01 8.632e-01 1.077e-01 6.310e-01 7.478e-02 3.389e-01 1.677e-02
 1.599e-01 7.562e-02 1.023e-01 3.506e-01 3.624e-03 5.933e-03 4.982e-03
 2.903e-01 3.337e-02 7.615e-02 4.084e-02 2.833e-02 6.956e-02 2.462e-02
 8.941e-02 1.723e-01 1.085e-01 5.417e-02 1.715e-01 2.810e-01 2.954e-01
 3.310e-02 1.855e-01 2.856e-01 8.173e-03 3.530e-01 1.563e-02 2.166e-02
 5.160e-03 5.319e-02 6.227e-03 1.109e-01 1.458e-01 1.964e-03 3.366e-03
 3.575e-03 1.448e-01 3.237e-03 1.594e-02 6.054e-03 9.232e-03 2.023e-02
 8.431e-03 3.729e-03 6.640e-02 1.608e-02 9.435e-03 1.541e-02 1.460e-02
 5.279e-02 6.775e-02 8.250e-02 1.224e-01 1.133e-02 1.366e-01 1.083e-02
 1.210e-01 3.969e-03 2.993e-02 1.661e-02 4.428e-02 3.012e-01 3.622e-03
 2.698e-03 2.993e-03 5.510e-02 4.774e-03 6.231e-03 1.924e-02 5.849e-03
 6.634e-03 5.267e-03 8.282e-03 1.861e-02 1.748e-02 1.282e-02 1.257e-02
 1.088e-02 1.001e-01]
[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 1.]
 [1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.
  0. 0. 0. 0. 0. 1.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.
  0. 1. 1. 0. 0. 0.]
 [0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]
 [0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
  0. 1. 0. 0. 0. 1.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.
  0. 0. 0. 0. 1. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
  0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
  0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.
  0. 0. 1. 0. 0. 0.]]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.
 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1.
 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 1. 0. 0.]
aucroc, aucpr (0.6119777777777777, 0.20966917077355857)
Iterations 2500
Achieves (6.086687062773559, 1e-05)-DP
